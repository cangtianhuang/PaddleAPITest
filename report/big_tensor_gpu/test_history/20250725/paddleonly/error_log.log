2025-07-25 15:51:07.492189 GPU 1 12436 test begin: paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([17409, 128, 1024],"float32"), Tensor([17409, 128, 1024],"float32"), None, Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
[cuda error] paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([17409, 128, 1024],"float32"), Tensor([17409, 128, 1024],"float32"), None, Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 15:58:17.617204 GPU 4 12837 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8777216, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([8777216, 256],"float32"), residual_alpha=0.69204696, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
[accuracy error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8777216, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([8777216, 256],"float32"), residual_alpha=0.69204696, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 907 / 2246967296 (0.0%)
Greatest absolute difference: 1 at index (8198, 85) (up to 0.01 allowed)
Greatest relative difference: inf at index (8198, 85) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8777216, 256]), dtype=torch.int8)
tensor([[  1,   2,  12,  ...,   1,   0,  24],
        [  0,   1,   4,  ...,   0,   0,  24],
        [  2,  -7,   8,  ...,   0,   0,  11],
        ...,
        [  2,  -7,  13,  ...,   1,   0,  15],
        [  2, -10,   6,  ...,   0,   0,   9],
        [  0,  -1,   9,  ...,   0,   0,   4]], dtype=torch.int8)
DESIRED: (shape=torch.Size([8777216, 256]), dtype=torch.int8)
tensor([[  1,   2,  12,  ...,   1,   0,  24],
        [  0,   1,   4,  ...,   0,   0,  24],
        [  2,  -7,   8,  ...,   0,   0,  11],
        ...,
        [  2,  -7,  13,  ...,   1,   0,  15],
        [  2, -10,   6,  ...,   0,   0,   9],
        [  0,  -1,   9,  ...,   0,   0,   4]], dtype=torch.int8)

2025-07-25 15:59:24.012215 GPU 3 14756 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([2281701379],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([2281701379],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 8 (100.0%)
Greatest absolute difference: 0.4577520489692688 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 2.570573091506958 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2, 4]), dtype=torch.float32)
tensor([[[-0.2797, -0.2364,  0.3441,  0.4916],
         [-0.2650,  0.3002, -0.3766,  0.2875]]])
DESIRED: (shape=torch.Size([1, 2, 4]), dtype=torch.float32)
tensor([[[ 0.1781,  0.1634,  0.5399,  0.5629],
         [-0.1749,  0.4280, -0.2067,  0.2391]]])

2025-07-25 15:59:28.582713 GPU 2 12624 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([2281701379],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )
/host_home/ningzhengsheng/paddle_env/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([2281701379],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 8 (100.0%)
Greatest absolute difference: 0.7704961895942688 at index (0, 1, 0) (up to 0.01 allowed)
Greatest relative difference: 3.424757480621338 at index (0, 0, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2, 4]), dtype=torch.float32)
tensor([[[ 0.3947, -0.0496, -0.0021,  0.2240],
         [ 0.2944, -0.2029,  0.0022,  0.1508]]])
DESIRED: (shape=torch.Size([1, 2, 4]), dtype=torch.float32)
tensor([[[-0.2669, -0.0113,  0.0201,  0.0506],
         [-0.4761, -0.2810, -0.4247, -0.3389]]])

2025-07-25 16:06:16.709095 GPU 3 20384 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:06:57.147037 GPU 6 19466 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:07:08.178060 GPU 3 20624 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:07:11.310104 GPU 4 19854 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:07:44.845839 GPU 6 20890 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:07:46.819902 GPU 1 18477 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:07:56.829722 GPU 7 21132 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:07:58.319551 GPU 4 21220 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:04.160291 GPU 3 21475 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:09.464752 GPU 5 19669 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:32.026515 GPU 2 19969 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:36.133342 GPU 1 21692 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:52.886881 GPU 4 21904 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:57.488124 GPU 7 22089 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:08:59.604840 GPU 5 22189 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:09:05.650596 GPU 3 22459 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:09:21.345215 GPU 2 22645 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:09:48.047407 GPU 6 22862 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:09:51.268679 GPU 7 23040 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:10:01.545759 GPU 5 23233 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:10:43.969335 GPU 1 23450 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:10:46.042619 GPU 7 23565 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:10:48.098936 GPU 6 23723 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:11:02.379511 GPU 4 23979 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:11:23.258066 GPU 3 24192 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:11:29.377003 GPU 2 24406 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:11:46.895563 GPU 7 24593 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
outputs format not support
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:11:49.722432 GPU 6 24708 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:12:17.568686 GPU 5 24966 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
[cuda error] paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 16:42:48.234939 GPU 7 34152 test begin: paddle.matmul(Tensor([3, 1431655765],"float32"), Tensor([3],"float32"), transpose_x=True, transpose_y=False, )
[cuda error] paddle.matmul(Tensor([3, 1431655765],"float32"), Tensor([3],"float32"), transpose_x=True, transpose_y=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1388)


2025-07-25 17:26:43.123560 GPU 3 50108 test begin: paddle.mode(Tensor([2, 107374183, 10],"float64"), 1, keepdim=True, )
element 1 of tensors does not require grad and does not have a grad_fn
terminate called after throwing an instance of 'thrust::system::detail::bad_alloc'
  what():  std::bad_alloc: cudaErrorMemoryAllocation: out of memory


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::ThrowExceptionToPython(std::__exception_ptr::exception_ptr)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753435835 (unix time) try "date -d @1753435835" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc3bc) received by PID 50108 (TID 0x7efd5d83e740) from PID 50108 ***]


2025-07-25 17:38:58.930633 GPU 1 50393 test begin: paddle.nanmedian(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,-1,], keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,-1,], keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 58 / 4294967320 (0.0%)
Greatest absolute difference: 0.49848783016204834 at index (0, 51631148, 2, 2) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 31440907, 1, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 107374183, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0097],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -0.2818,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.3067,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.2805,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2554,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.0127,  0.0000],
          [ 0.0000,  0.0000,  0.3725,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.1035,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.2933,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.4416,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.2348,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.2542,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.4028,  0.0000],
          [ 0.0000,  0.0000, -0.4946,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.1748,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0659,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2225]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.2798,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.1313,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  0.1261,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.0415,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0509],
          [ 0.0000,  0.0000,  0.1308,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.3297,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 107374183, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0097],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -0.2818,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.3067,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.2805,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2554,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.0127,  0.0000],
          [ 0.0000,  0.0000,  0.3725,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.1035,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.2933,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.4416,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.2348,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.2542,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.4028,  0.0000],
          [ 0.0000,  0.0000, -0.4946,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.1748,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0659,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2225]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.2798,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.1313,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  0.1261,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.0415,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0509],
          [ 0.0000,  0.0000,  0.1308,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.3297,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])

2025-07-25 17:39:32.814986 GPU 5 53352 test begin: paddle.nanmedian(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,3,], keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,3,], keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 52 / 4294967320 (0.0%)
Greatest absolute difference: 0.49602654576301575 at index (1, 88401600, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 3637304, 3, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 107374183, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.2846,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.2116,  0.0000],
          [ 0.0000,  0.0000, -0.3821,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -0.0510,  0.0000,  0.0000],
          [ 0.0000, -0.2404,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4855],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2386]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000, -0.3202],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2058,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.3248,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.2055,  0.0000,  0.0000],
          [ 0.0000, -0.2665,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.2486,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0299,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[-0.4182,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.4659,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.1156],
          [ 0.0000,  0.0000,  0.0000, -0.3523,  0.0000]],

         ...,

         [[ 0.0000, -0.1805,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3995,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.3762,  0.0000,  0.0000],
          [ 0.0000, -0.0283,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.1300,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0605]]]])
DESIRED: (shape=torch.Size([2, 107374183, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.2846,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.2116,  0.0000],
          [ 0.0000,  0.0000, -0.3821,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -0.0510,  0.0000,  0.0000],
          [ 0.0000, -0.2404,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4855],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2386]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000, -0.3202],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2058,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.3248,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.2055,  0.0000,  0.0000],
          [ 0.0000, -0.2665,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.2486,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0299,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[-0.4182,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.4659,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.1156],
          [ 0.0000,  0.0000,  0.0000, -0.3523,  0.0000]],

         ...,

         [[ 0.0000, -0.1805,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3995,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.3762,  0.0000,  0.0000],
          [ 0.0000, -0.0283,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.1300,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0605]]]])

2025-07-25 17:40:17.034757 GPU 6 52452 test begin: paddle.nanmedian(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,-1,], keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,-1,], keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 42 / 4294967310 (0.0%)
Greatest absolute difference: 0.4988250434398651 at index (0, 0, 77694639, 3) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 1, 33185727, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 143165577, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.3079],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0413,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0470,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4486],
          ...,
          [ 0.0000,  0.0000,  0.0000, -0.4939,  0.0000],
          [ 0.0000,  0.4033,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0797],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2860,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.4731],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.2381,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.2884,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3511,  0.0000]],

         [[ 0.1276,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4937]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0312,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.2526,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4802],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2539]]]])
DESIRED: (shape=torch.Size([2, 3, 143165577, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.3079],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0413,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0470,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4486],
          ...,
          [ 0.0000,  0.0000,  0.0000, -0.4939,  0.0000],
          [ 0.0000,  0.4033,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0797],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2860,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.4731],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.2381,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.2884,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3511,  0.0000]],

         [[ 0.1276,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4937]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0312,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.2526,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4802],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2539]]]])

2025-07-25 17:40:34.766742 GPU 2 54013 test begin: paddle.nanmedian(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,1,3,], keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,1,3,], keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 20 / 4294967310 (0.0%)
Greatest absolute difference: 0.47344857454299927 at index (0, 0, 112234670, 3) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 1, 7830247, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 143165577, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.3632,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.3807,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.4191,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0739],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0457,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4138]]]])
DESIRED: (shape=torch.Size([2, 3, 143165577, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.3632,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.3807,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.4191,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0739],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0457,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4138]]]])

2025-07-25 17:41:08.085947 GPU 1 50393 test begin: paddle.nanmedian(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,3,], keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,3,], keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 52 / 4294967310 (0.0%)
Greatest absolute difference: 0.4646552503108978 at index (0, 2, 92970842, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 1, 10132729, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 143165577, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.2542,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4028],
          [ 0.0000,  0.0000,  0.0000, -0.4946,  0.0000],
          ...,
          [ 0.0000,  0.0000, -0.4432,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0892,  0.0000],
          [-0.1685,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.1603,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0988,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0355,  0.0000],
          [ 0.0000,  0.0000,  0.2804,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3686,  0.0000],
          ...,
          [ 0.0000,  0.3297,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4416],
          [ 0.0000,  0.0000,  0.2348,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.4177,  0.0000],
          ...,
          [ 0.0000,  0.0000, -0.0300,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4155],
          [ 0.0000, -0.2314,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 3, 143165577, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.2542,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4028],
          [ 0.0000,  0.0000,  0.0000, -0.4946,  0.0000],
          ...,
          [ 0.0000,  0.0000, -0.4432,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0892,  0.0000],
          [-0.1685,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.1603,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0988,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0355,  0.0000],
          [ 0.0000,  0.0000,  0.2804,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3686,  0.0000],
          ...,
          [ 0.0000,  0.3297,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4416],
          [ 0.0000,  0.0000,  0.2348,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.4177,  0.0000],
          ...,
          [ 0.0000,  0.0000, -0.0300,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4155],
          [ 0.0000, -0.2314,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])

2025-07-25 17:43:25.357677 GPU 1 50393 test begin: paddle.nanmedian(Tensor([42949673, 100],"float32"), axis=1, mode="min", )
element 1 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.nanmedian(Tensor([42949673, 100],"float32"), axis=1, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 7 / 42949673 (0.0%)
Greatest absolute difference: 61 at index (17408279,) (up to 0.01 allowed)
Greatest relative difference: 2.7727272510528564 at index (17408279,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([42949673]), dtype=torch.int64)
tensor([77, 30, 21,  ...,  0, 19, 49])
DESIRED: (shape=torch.Size([42949673]), dtype=torch.int64)
tensor([77, 30, 21,  ...,  0, 19, 49])

2025-07-25 17:43:46.990750 GPU 6 52452 test begin: paddle.nanmedian(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(1,2,), keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(1,2,), keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 56 / 4294967340 (0.0%)
Greatest absolute difference: 0.4973367154598236 at index (44782948, 1, 0, 2) (up to 0.01 allowed)
Greatest relative difference: inf at index (4759233, 2, 3, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.1405,  0.0000, -0.3005, -0.1776],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0331,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.1395,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.2651,  0.0000],
          [-0.3127,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.4735,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.2965,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0475],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2769,  0.0000, -0.1358,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1485],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0915,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.3672,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.3627,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0187,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3062,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.4636,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4114]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0328,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2374],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.0676,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.4723,  0.0000],
          [ 0.0000,  0.0000,  0.2529,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.2576,  0.0000,  0.0000,  0.2860,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2539]],

         [[ 0.0000,  0.0000, -0.4802,  0.0000,  0.0000],
          [ 0.0000,  0.2492,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.1405,  0.0000, -0.3005, -0.1776],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.0331,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.1395,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.2651,  0.0000],
          [-0.3127,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.4735,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.2965,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0475],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.2769,  0.0000, -0.1358,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1485],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0915,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.3672,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.3627,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0187,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.3062,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.4636,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4114]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0328,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2374],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.0676,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000, -0.4723,  0.0000],
          [ 0.0000,  0.0000,  0.2529,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.2576,  0.0000,  0.0000,  0.2860,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2539]],

         [[ 0.0000,  0.0000, -0.4802,  0.0000,  0.0000],
          [ 0.0000,  0.2492,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])

2025-07-25 17:43:56.032553 GPU 1 50393 test begin: paddle.nanmedian(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(1,2,3,), keepdim=False, mode="min", )
[accuracy error] backward paddle.nanmedian(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(1,2,3,), keepdim=False, mode="min", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 16 / 4294967340 (0.0%)
Greatest absolute difference: 0.4531601369380951 at index (12820451, 1, 2, 4) (up to 0.01 allowed)
Greatest relative difference: inf at index (3322778, 0, 2, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2651],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4545],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.4846,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.3297,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4416],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.2348,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2651],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4545],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [-0.4846,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.3297,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4416],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.2348,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])

2025-07-25 18:13:20.515770 GPU 6 60892 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), list[2,3,5,], )
[accuracy error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), list[2,3,5,], )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 39627872 / 279392040 (14.2%)
Greatest absolute difference: 0.1843978613615036 at index (1, 2605705, 1, 0, 3) (up to 0.01 allowed)
Greatest relative difference: 9719848.0 at index (1, 4084338, 0, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 4656534, 2, 3, 5]), dtype=torch.float32)
tensor([[[[[ 6.8364e-02,  6.7747e-02, -2.0646e-02,  7.8493e-02,  1.3833e-01],
           [ 6.1597e-02,  3.0842e-02,  3.3595e-02,  1.8381e-02, -5.7787e-02],
           [-2.2911e-02, -8.8127e-02, -4.1360e-02, -7.5088e-02, -3.6401e-03]],

          [[ 1.2491e-01, -2.2565e-03, -6.0926e-02, -1.3764e-02,  9.0472e-02],
           [ 9.4979e-02,  9.2109e-02,  5.9774e-02, -1.5674e-02, -8.9198e-02],
           [ 4.8315e-02, -2.6944e-02,  2.5163e-03, -2.9855e-02, -1.8443e-02]]],


         [[[-1.4319e-02,  6.5660e-02,  1.6983e-02, -6.6871e-02, -2.7617e-02],
           [ 5.6651e-02,  8.8644e-02,  9.3711e-02,  6.4129e-02,  1.5435e-02],
           [ 6.4004e-02,  1.9800e-02,  6.1992e-02,  1.9405e-02, -3.6851e-02]],

          [[-6.1319e-03,  1.0082e-01, -2.3675e-02, -1.1513e-01, -1.1282e-01],
           [ 6.1864e-02,  1.0160e-01,  3.8474e-02, -1.6211e-02,  3.6668e-02],
           [ 8.2297e-02,  9.1110e-02,  4.8356e-02, -1.8767e-02, -7.3950e-02]]],


         [[[-1.3896e-01, -7.9720e-02,  3.8482e-02,  2.2920e-02,  8.9336e-04],
           [-1.0773e-01, -5.6203e-02, -4.0720e-02, -1.0675e-02,  1.0475e-01],
           [-3.1437e-02, -4.3453e-02, -4.0084e-04,  2.1944e-02,  3.9794e-02]],

          [[-7.4963e-02,  6.8782e-02, -9.2797e-03, -5.2765e-02, -6.8620e-03],
           [-3.9243e-03,  3.0687e-02,  2.0049e-02,  5.9178e-02, -3.2449e-03],
           [-4.9267e-02,  4.7244e-02,  5.8138e-02,  3.9104e-02,  1.6858e-02]]],


         ...,


         [[[-3.0097e-03, -4.9395e-02, -8.9964e-02, -1.0118e-01, -8.8518e-03],
           [ 1.7247e-03,  3.0021e-02, -2.9352e-02, -1.2020e-01,  1.4096e-02],
           [-7.4613e-04, -8.5381e-03, -1.8224e-02, -2.7977e-02, -4.2864e-03]],

          [[-1.6142e-01, -1.5103e-01, -5.1015e-02, -1.0883e-02,  7.9800e-02],
           [ 3.4586e-02,  8.0735e-02,  2.4974e-02, -3.2018e-02, -9.9674e-02],
           [ 3.6847e-02,  1.0672e-01, -2.9688e-02, -1.2469e-02,  2.7807e-02]]],


         [[[-1.1970e-01, -8.6743e-02, -6.7110e-02, -4.5861e-02, -9.8899e-02],
           [-8.4017e-02, -2.7343e-02, -1.0349e-02,  4.7001e-02,  1.0501e-03],
           [-4.5930e-02,  3.9301e-02,  1.8614e-02,  7.0105e-05,  9.1915e-03]],

          [[-1.2844e-02,  7.5088e-02,  1.0471e-01,  1.0018e-01, -2.6783e-02],
           [-7.3148e-02, -7.3957e-02, -2.4114e-02,  7.9286e-02,  6.8587e-02],
           [ 9.1758e-02,  1.6496e-02, -7.6753e-02, -1.0393e-01,  8.8558e-02]]],


         [[[-4.5749e-02,  6.0622e-02,  4.0123e-02,  6.2451e-04,  3.0410e-02],
           [-3.8959e-02,  8.7773e-02,  1.2698e-02,  9.2299e-02, -4.0367e-02],
           [ 6.5105e-03,  5.8399e-02,  4.6641e-02, -3.2934e-02, -4.9358e-02]],

          [[ 8.5519e-02, -1.3735e-02,  4.3381e-02,  9.4308e-02,  1.2942e-01],
           [ 6.4963e-02, -1.2667e-02, -1.0948e-02,  8.6271e-02,  9.3075e-02],
           [ 2.1144e-02, -4.2613e-02,  2.6833e-02, -1.2865e-02,  1.9146e-02]]]],



        [[[[-6.9563e-02, -7.0790e-03,  1.5527e-02, -3.0007e-02, -3.8996e-02],
           [ 7.0447e-03, -4.4954e-02,  2.3666e-02, -9.6230e-02, -5.6152e-02],
           [-1.4015e-03, -7.2402e-02,  3.4800e-02,  1.4671e-02,  1.3586e-01]],

          [[-9.2581e-03,  5.9122e-02,  4.6532e-02,  3.0310e-04, -9.5978e-02],
           [-3.0606e-02,  1.0826e-01,  9.9871e-02, -1.6092e-02, -4.4699e-02],
           [ 6.3336e-02,  4.0217e-02,  6.7331e-02,  5.3462e-02,  6.9387e-02]]],


         [[[ 1.1092e-01,  2.4189e-01,  4.6963e-03,  1.3329e-01,  1.2083e-01],
           [ 1.4603e-01,  1.4349e-01,  1.8503e-02, -7.7027e-03, -8.4444e-02],
           [-5.0652e-02, -1.5837e-02, -6.3753e-02, -1.0726e-01, -2.7746e-02]],

          [[ 9.6649e-02,  1.5554e-01,  7.1387e-02,  1.4506e-01,  5.9607e-02],
           [ 8.5110e-02,  6.3071e-02,  1.5145e-02,  1.7258e-02, -9.7519e-02],
           [ 7.2645e-02, -8.9955e-02, -9.9568e-02, -4.9998e-02, -4.3290e-02]]],


         [[[-6.1250e-03, -3.1107e-02, -8.4171e-02, -1.0025e-01, -2.0008e-03],
           [ 5.1464e-02,  2.8440e-02, -1.0077e-02,  4.6995e-02,  2.1541e-02],
           [ 7.6502e-03,  1.0228e-02,  1.3393e-02, -2.4171e-02,  4.7262e-02]],

          [[ 7.4684e-02,  2.0021e-01,  8.5148e-02, -6.6744e-02,  1.8619e-02],
           [-8.4205e-03,  4.9628e-02,  2.4580e-02, -2.1284e-02,  4.8260e-02],
           [ 6.2762e-03,  1.4208e-02,  2.5994e-02,  2.3549e-02,  5.6744e-03]]],


         ...,


         [[[ 6.7164e-02, -1.3518e-01, -3.3002e-02, -1.9510e-02,  7.9576e-03],
           [ 2.9094e-02, -1.4432e-02,  4.3151e-02,  5.7171e-02,  2.2347e-02],
           [-6.4507e-02, -3.0459e-02,  4.8040e-02,  6.8938e-02,  3.5159e-03]],

          [[-5.5211e-03,  5.4888e-02,  5.3286e-02, -5.4657e-03, -5.9180e-02],
           [-6.3104e-03, -4.2006e-03,  3.8350e-03,  3.3299e-02, -3.7756e-02],
           [ 5.3516e-02, -3.3235e-02,  7.2394e-02, -1.6015e-02,  2.3050e-02]]],


         [[[ 2.0909e-02, -3.6530e-02,  2.8041e-02, -9.9455e-03, -6.3990e-02],
           [-4.4185e-02, -4.7221e-02,  7.9639e-02,  3.8425e-02,  3.1943e-03],
           [-2.3039e-03, -3.0713e-02,  8.7278e-02,  9.3115e-02,  8.0780e-02]],

          [[-1.2798e-02, -4.0909e-02,  9.2200e-02, -2.6475e-03, -9.4415e-02],
           [-1.0242e-01, -1.2288e-01,  9.6089e-03, -7.4487e-03, -4.5101e-03],
           [-9.5499e-03, -3.8892e-02, -6.2984e-02, -3.9695e-02, -2.4723e-02]]],


         [[[ 1.5061e-01,  6.2049e-02,  1.8704e-02, -2.9817e-03, -9.0279e-02],
           [ 1.2786e-02, -5.4141e-02, -9.6059e-02, -7.9898e-02, -4.2788e-02],
           [ 2.6276e-02, -2.0514e-02,  2.7247e-03, -2.7918e-02,  8.9409e-03]],

          [[ 5.8854e-02, -4.4754e-02,  5.1267e-03, -4.8066e-02, -6.8904e-02],
           [ 2.4028e-02,  3.0663e-02,  5.1778e-02,  2.5359e-02, -1.1125e-02],
           [ 8.6125e-02,  1.2010e-01,  6.4408e-02, -1.2985e-01, -6.5519e-02]]]]])
DESIRED: (shape=torch.Size([2, 4656534, 2, 3, 5]), dtype=torch.float32)
tensor([[[[[ 6.8364e-02,  6.7747e-02, -2.0646e-02,  7.8493e-02,  1.3833e-01],
           [ 6.1597e-02,  3.0842e-02,  3.3595e-02,  1.8381e-02, -5.7787e-02],
           [-2.2911e-02, -8.8127e-02, -4.1360e-02, -7.5088e-02, -3.6401e-03]],

          [[ 1.2491e-01, -2.2565e-03, -6.0926e-02, -1.3764e-02,  9.0472e-02],
           [ 9.4979e-02,  9.2109e-02,  5.9774e-02, -1.5674e-02, -8.9198e-02],
           [ 4.8315e-02, -2.6944e-02,  2.5163e-03, -2.9855e-02, -1.8443e-02]]],


         [[[-1.4319e-02,  6.5660e-02,  1.6983e-02, -6.6871e-02, -2.7617e-02],
           [ 5.6651e-02,  8.8644e-02,  9.3711e-02,  6.4129e-02,  1.5435e-02],
           [ 6.4004e-02,  1.9800e-02,  6.1992e-02,  1.9405e-02, -3.6851e-02]],

          [[-6.1319e-03,  1.0082e-01, -2.3675e-02, -1.1513e-01, -1.1282e-01],
           [ 6.1864e-02,  1.0160e-01,  3.8474e-02, -1.6211e-02,  3.6668e-02],
           [ 8.2297e-02,  9.1110e-02,  4.8356e-02, -1.8767e-02, -7.3950e-02]]],


         [[[-1.3896e-01, -7.9720e-02,  3.8482e-02,  2.2920e-02,  8.9336e-04],
           [-1.0773e-01, -5.6203e-02, -4.0720e-02, -1.0675e-02,  1.0475e-01],
           [-3.1437e-02, -4.3453e-02, -4.0084e-04,  2.1944e-02,  3.9794e-02]],

          [[-7.4963e-02,  6.8782e-02, -9.2797e-03, -5.2765e-02, -6.8620e-03],
           [-3.9243e-03,  3.0687e-02,  2.0049e-02,  5.9178e-02, -3.2449e-03],
           [-4.9267e-02,  4.7244e-02,  5.8138e-02,  3.9104e-02,  1.6858e-02]]],


         ...,


         [[[-3.0097e-03, -4.9395e-02, -8.9964e-02, -1.0118e-01, -8.8518e-03],
           [ 1.7247e-03,  3.0021e-02, -2.9352e-02, -1.2020e-01,  1.4096e-02],
           [-7.4613e-04, -8.5381e-03, -1.8224e-02, -2.7977e-02, -4.2864e-03]],

          [[-1.6142e-01, -1.5103e-01, -5.1015e-02, -1.0883e-02,  7.9800e-02],
           [ 3.4586e-02,  8.0735e-02,  2.4974e-02, -3.2018e-02, -9.9674e-02],
           [ 3.6847e-02,  1.0672e-01, -2.9688e-02, -1.2469e-02,  2.7807e-02]]],


         [[[-1.1970e-01, -8.6743e-02, -6.7110e-02, -4.5861e-02, -9.8899e-02],
           [-8.4017e-02, -2.7343e-02, -1.0349e-02,  4.7001e-02,  1.0501e-03],
           [-4.5930e-02,  3.9301e-02,  1.8614e-02,  7.0105e-05,  9.1915e-03]],

          [[-1.2844e-02,  7.5088e-02,  1.0471e-01,  1.0018e-01, -2.6783e-02],
           [-7.3148e-02, -7.3957e-02, -2.4114e-02,  7.9286e-02,  6.8587e-02],
           [ 9.1758e-02,  1.6496e-02, -7.6753e-02, -1.0393e-01,  8.8558e-02]]],


         [[[-4.5749e-02,  6.0622e-02,  4.0123e-02,  6.2451e-04,  3.0410e-02],
           [-3.8959e-02,  8.7773e-02,  1.2698e-02,  9.2299e-02, -4.0367e-02],
           [ 6.5105e-03,  5.8399e-02,  4.6641e-02, -3.2934e-02, -4.9358e-02]],

          [[ 8.5519e-02, -1.3735e-02,  4.3381e-02,  9.4308e-02,  1.2942e-01],
           [ 6.4963e-02, -1.2667e-02, -1.0948e-02,  8.6271e-02,  9.3075e-02],
           [ 2.1144e-02, -4.2613e-02,  2.6833e-02, -1.2865e-02,  1.9146e-02]]]],



        [[[[-6.9563e-02, -7.0790e-03,  1.5527e-02, -3.0007e-02, -3.8996e-02],
           [ 7.0447e-03, -4.4954e-02,  2.3666e-02, -9.6230e-02, -5.6152e-02],
           [-1.4015e-03, -7.2402e-02,  3.4800e-02,  1.4671e-02,  1.3586e-01]],

          [[-9.2581e-03,  5.9122e-02,  4.6532e-02,  3.0310e-04, -9.5978e-02],
           [-3.0606e-02,  1.0826e-01,  9.9871e-02, -1.6092e-02, -4.4699e-02],
           [ 6.3336e-02,  4.0217e-02,  6.7331e-02,  5.3462e-02,  6.9387e-02]]],


         [[[ 1.1092e-01,  2.4189e-01,  4.6963e-03,  1.3329e-01,  1.2083e-01],
           [ 1.4603e-01,  1.4349e-01,  1.8503e-02, -7.7027e-03, -8.4444e-02],
           [-5.0652e-02, -1.5837e-02, -6.3753e-02, -1.0726e-01, -2.7746e-02]],

          [[ 9.6649e-02,  1.5554e-01,  7.1387e-02,  1.4506e-01,  5.9607e-02],
           [ 8.5110e-02,  6.3071e-02,  1.5145e-02,  1.7258e-02, -9.7519e-02],
           [ 7.2645e-02, -8.9955e-02, -9.9568e-02, -4.9998e-02, -4.3290e-02]]],


         [[[-6.1250e-03, -3.1107e-02, -8.4171e-02, -1.0025e-01, -2.0008e-03],
           [ 5.1464e-02,  2.8440e-02, -1.0077e-02,  4.6995e-02,  2.1541e-02],
           [ 7.6502e-03,  1.0228e-02,  1.3393e-02, -2.4171e-02,  4.7262e-02]],

          [[ 7.4684e-02,  2.0021e-01,  8.5148e-02, -6.6744e-02,  1.8619e-02],
           [-8.4205e-03,  4.9628e-02,  2.4580e-02, -2.1284e-02,  4.8260e-02],
           [ 6.2762e-03,  1.4208e-02,  2.5994e-02,  2.3549e-02,  5.6744e-03]]],


         ...,


         [[[ 7.4503e-02, -1.3068e-01, -3.6016e-02, -1.9687e-02, -6.3997e-04],
           [ 7.2849e-03, -2.0304e-02,  5.0490e-02,  6.1674e-02,  1.9333e-02],
           [-6.4685e-02, -1.5684e-02,  7.6398e-02,  7.2651e-02, -6.3546e-03]],

          [[-1.6385e-02,  5.4327e-02,  5.3719e-02,  1.7906e-02, -9.0133e-03],
           [ 3.2749e-03, -2.1410e-02, -1.1532e-02,  3.5752e-02, -3.7146e-02],
           [ 6.6780e-02, -7.2972e-03,  7.6004e-02, -2.5078e-02,  7.0606e-03]]],


         [[[ 3.4507e-02, -1.6007e-02,  1.7934e-02, -3.4175e-02, -6.9966e-02],
           [-3.6039e-02, -4.7843e-02,  9.0784e-02,  5.8339e-02, -6.9131e-03],
           [-2.6533e-02, -3.6689e-02,  9.5424e-02,  9.2492e-02,  9.1925e-02]],

          [[ 7.1156e-03, -4.9506e-02,  7.0391e-02, -8.5195e-03, -8.7075e-02],
           [-9.7919e-02, -1.2590e-01,  9.4315e-03, -1.6046e-02, -2.6319e-02],
           [-1.5422e-02, -3.1553e-02, -5.8481e-02, -4.2709e-02, -2.4901e-02]]],


         [[[ 1.6538e-01,  9.0407e-02,  2.2417e-02, -1.2852e-02, -1.0114e-01],
           [ 1.2225e-02, -5.3709e-02, -7.2687e-02, -2.9731e-02, -3.3202e-02],
           [ 9.0665e-03, -3.5881e-02,  5.1778e-03, -2.7308e-02,  2.2205e-02]],

          [[ 8.4792e-02, -4.1145e-02, -3.9370e-03, -6.4056e-02, -5.5307e-02],
           [ 4.4552e-02,  2.0555e-02,  2.7549e-02,  1.9383e-02, -2.9789e-03],
           [ 8.5503e-02,  1.3124e-01,  8.4321e-02, -1.3996e-01, -8.9748e-02]]]]])

2025-07-25 18:13:41.401719 GPU 6 60892 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), list[2,3,5,], )
[accuracy error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), list[2,3,5,], )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 39627872 / 279392040 (14.2%)
Greatest absolute difference: 0.1843978613615036 at index (2420746, 1, 1, 0, 3) (up to 0.01 allowed)
Greatest relative difference: 9719848.0 at index (2913624, 0, 0, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3104356, 3, 2, 3, 5]), dtype=torch.float32)
tensor([[[[[ 0.0684,  0.0677, -0.0206,  0.0785,  0.1383],
           [ 0.0616,  0.0308,  0.0336,  0.0184, -0.0578],
           [-0.0229, -0.0881, -0.0414, -0.0751, -0.0036]],

          [[ 0.1249, -0.0023, -0.0609, -0.0138,  0.0905],
           [ 0.0950,  0.0921,  0.0598, -0.0157, -0.0892],
           [ 0.0483, -0.0269,  0.0025, -0.0299, -0.0184]]],


         [[[-0.0143,  0.0657,  0.0170, -0.0669, -0.0276],
           [ 0.0567,  0.0886,  0.0937,  0.0641,  0.0154],
           [ 0.0640,  0.0198,  0.0620,  0.0194, -0.0369]],

          [[-0.0061,  0.1008, -0.0237, -0.1151, -0.1128],
           [ 0.0619,  0.1016,  0.0385, -0.0162,  0.0367],
           [ 0.0823,  0.0911,  0.0484, -0.0188, -0.0739]]],


         [[[-0.1390, -0.0797,  0.0385,  0.0229,  0.0009],
           [-0.1077, -0.0562, -0.0407, -0.0107,  0.1048],
           [-0.0314, -0.0435, -0.0004,  0.0219,  0.0398]],

          [[-0.0750,  0.0688, -0.0093, -0.0528, -0.0069],
           [-0.0039,  0.0307,  0.0200,  0.0592, -0.0032],
           [-0.0493,  0.0472,  0.0581,  0.0391,  0.0169]]]],



        [[[[-0.0503, -0.0496, -0.0971, -0.0396, -0.0315],
           [ 0.0832,  0.0253,  0.0059,  0.0782,  0.0721],
           [-0.0321,  0.0102,  0.0680,  0.0274, -0.0680]],

          [[-0.0809, -0.0691,  0.0105,  0.0335, -0.0181],
           [ 0.0360, -0.0030,  0.0508, -0.0568, -0.0354],
           [-0.0066,  0.0581, -0.0093, -0.1296, -0.1319]]],


         [[[ 0.0627, -0.0055,  0.0464, -0.0104,  0.0381],
           [ 0.0913,  0.0370,  0.1157,  0.0681,  0.0619],
           [ 0.0803, -0.0202,  0.0092,  0.0197, -0.0318]],

          [[-0.1285, -0.0333,  0.0268,  0.0411,  0.1090],
           [-0.0752,  0.0236,  0.1045,  0.0863,  0.0762],
           [-0.0814,  0.0476,  0.0997,  0.0372, -0.0540]]],


         [[[ 0.0473,  0.0032, -0.1023, -0.0793, -0.0694],
           [ 0.0249,  0.0126, -0.0574, -0.0932, -0.0388],
           [ 0.0050, -0.0573, -0.0303, -0.0120,  0.0856]],

          [[-0.0460,  0.0837,  0.0385, -0.0553, -0.1395],
           [-0.0052,  0.0463, -0.0022, -0.1083, -0.1087],
           [-0.0130, -0.0005, -0.0351, -0.0712, -0.0015]]]],



        [[[[-0.0281, -0.0845, -0.0653, -0.0264,  0.1155],
           [ 0.0105, -0.1148, -0.1028, -0.0789, -0.0510],
           [ 0.0143, -0.0303, -0.0683, -0.0224, -0.0462]],

          [[-0.0648, -0.0430, -0.0051, -0.0252,  0.0733],
           [ 0.0537, -0.0577,  0.0054, -0.0213, -0.0247],
           [ 0.0845, -0.0101, -0.0016, -0.0091, -0.0906]]],


         [[[-0.0451, -0.1179, -0.0903, -0.0465, -0.0085],
           [-0.0327, -0.1201,  0.0174,  0.0864,  0.0950],
           [-0.1304, -0.0908,  0.0144,  0.1890,  0.1247]],

          [[-0.0161,  0.0116,  0.0249,  0.0389,  0.0093],
           [-0.0219, -0.0616,  0.0153,  0.1056,  0.0278],
           [-0.1589, -0.0504, -0.0077,  0.1316,  0.0703]]],


         [[[ 0.1249,  0.0087,  0.0239,  0.1628,  0.1556],
           [ 0.0039, -0.1151,  0.0260,  0.1424,  0.0833],
           [ 0.0444, -0.0403,  0.0174,  0.0642, -0.0511]],

          [[ 0.1376,  0.0211,  0.0531,  0.0346, -0.0012],
           [-0.0289, -0.0518, -0.0202,  0.0175,  0.0109],
           [ 0.0296, -0.0400, -0.0482,  0.0174, -0.0121]]]],



        ...,



        [[[[-0.0212,  0.0018,  0.0750, -0.0610, -0.0931],
           [-0.0520, -0.0552, -0.0155,  0.0310,  0.0279],
           [ 0.0155,  0.0831,  0.0311,  0.0233, -0.0007]],

          [[ 0.0136, -0.0891,  0.0347,  0.0007, -0.0191],
           [ 0.0197,  0.0697,  0.0175,  0.0342,  0.0865],
           [ 0.0164,  0.0552,  0.0265,  0.0217, -0.0306]]],


         [[[ 0.0430, -0.0475, -0.0600, -0.0727, -0.0451],
           [ 0.0033, -0.0539, -0.0185, -0.0806, -0.1254],
           [-0.0146, -0.1806, -0.0200,  0.0487, -0.0203]],

          [[-0.0817, -0.0059, -0.1016, -0.1352,  0.0045],
           [-0.0049,  0.0024,  0.0138, -0.0366, -0.0883],
           [-0.0959, -0.1782,  0.0398,  0.0264, -0.0204]]],


         [[[-0.0522, -0.1458, -0.1054, -0.0339,  0.0115],
           [-0.0802, -0.0807,  0.0130,  0.0670, -0.0120],
           [-0.0343, -0.0329, -0.0631, -0.0247, -0.0445]],

          [[ 0.0696, -0.0277, -0.0209, -0.0598, -0.0534],
           [-0.0121,  0.0111,  0.0763,  0.1075, -0.0347],
           [-0.0805,  0.0504,  0.0577,  0.0645,  0.0748]]]],



        [[[[-0.0043,  0.0354,  0.0039, -0.0562, -0.1038],
           [-0.0561, -0.0082, -0.0728, -0.1217, -0.0467],
           [-0.0232,  0.0459, -0.0089,  0.0113,  0.1031]],

          [[ 0.0383, -0.0501, -0.0002,  0.0505, -0.0306],
           [ 0.0238, -0.0637, -0.0674, -0.0520, -0.0313],
           [-0.0959, -0.0826, -0.0835, -0.0453,  0.0543]]],


         [[[ 0.0426, -0.0225,  0.0527,  0.0770, -0.0357],
           [ 0.0576,  0.0341,  0.0458, -0.0092, -0.1909],
           [-0.0713,  0.0269,  0.0215, -0.0385, -0.1347]],

          [[ 0.0023, -0.0437, -0.0223, -0.0195,  0.0410],
           [ 0.0485, -0.0093, -0.0086,  0.0424, -0.0094],
           [-0.0020, -0.0270,  0.0442,  0.1105,  0.0604]]],


         [[[-0.0673, -0.1241, -0.0260, -0.0607,  0.0348],
           [-0.0375, -0.0500, -0.0137,  0.0660,  0.1758],
           [-0.0982, -0.0443,  0.0547, -0.0159,  0.0283]],

          [[ 0.0208, -0.0950, -0.0857, -0.0187,  0.0624],
           [-0.1073, -0.0986, -0.0233,  0.0076,  0.1319],
           [-0.0026,  0.0225,  0.0402,  0.0223,  0.0772]]]],



        [[[[ 0.0672, -0.1352, -0.0330, -0.0195,  0.0080],
           [ 0.0291, -0.0144,  0.0432,  0.0572,  0.0223],
           [-0.0645, -0.0305,  0.0480,  0.0689,  0.0035]],

          [[-0.0055,  0.0549,  0.0533, -0.0055, -0.0592],
           [-0.0063, -0.0042,  0.0038,  0.0333, -0.0378],
           [ 0.0535, -0.0332,  0.0724, -0.0160,  0.0230]]],


         [[[ 0.0209, -0.0365,  0.0280, -0.0099, -0.0640],
           [-0.0442, -0.0472,  0.0796,  0.0384,  0.0032],
           [-0.0023, -0.0307,  0.0873,  0.0931,  0.0808]],

          [[-0.0128, -0.0409,  0.0922, -0.0026, -0.0944],
           [-0.1024, -0.1229,  0.0096, -0.0074, -0.0045],
           [-0.0095, -0.0389, -0.0630, -0.0397, -0.0247]]],


         [[[ 0.1506,  0.0620,  0.0187, -0.0030, -0.0903],
           [ 0.0128, -0.0541, -0.0961, -0.0799, -0.0428],
           [ 0.0263, -0.0205,  0.0027, -0.0279,  0.0089]],

          [[ 0.0589, -0.0448,  0.0051, -0.0481, -0.0689],
           [ 0.0240,  0.0307,  0.0518,  0.0254, -0.0111],
           [ 0.0861,  0.1201,  0.0644, -0.1299, -0.0655]]]]])
DESIRED: (shape=torch.Size([3104356, 3, 2, 3, 5]), dtype=torch.float32)
tensor([[[[[ 0.0684,  0.0677, -0.0206,  0.0785,  0.1383],
           [ 0.0616,  0.0308,  0.0336,  0.0184, -0.0578],
           [-0.0229, -0.0881, -0.0414, -0.0751, -0.0036]],

          [[ 0.1249, -0.0023, -0.0609, -0.0138,  0.0905],
           [ 0.0950,  0.0921,  0.0598, -0.0157, -0.0892],
           [ 0.0483, -0.0269,  0.0025, -0.0299, -0.0184]]],


         [[[-0.0143,  0.0657,  0.0170, -0.0669, -0.0276],
           [ 0.0567,  0.0886,  0.0937,  0.0641,  0.0154],
           [ 0.0640,  0.0198,  0.0620,  0.0194, -0.0369]],

          [[-0.0061,  0.1008, -0.0237, -0.1151, -0.1128],
           [ 0.0619,  0.1016,  0.0385, -0.0162,  0.0367],
           [ 0.0823,  0.0911,  0.0484, -0.0188, -0.0739]]],


         [[[-0.1390, -0.0797,  0.0385,  0.0229,  0.0009],
           [-0.1077, -0.0562, -0.0407, -0.0107,  0.1048],
           [-0.0314, -0.0435, -0.0004,  0.0219,  0.0398]],

          [[-0.0750,  0.0688, -0.0093, -0.0528, -0.0069],
           [-0.0039,  0.0307,  0.0200,  0.0592, -0.0032],
           [-0.0493,  0.0472,  0.0581,  0.0391,  0.0169]]]],



        [[[[-0.0503, -0.0496, -0.0971, -0.0396, -0.0315],
           [ 0.0832,  0.0253,  0.0059,  0.0782,  0.0721],
           [-0.0321,  0.0102,  0.0680,  0.0274, -0.0680]],

          [[-0.0809, -0.0691,  0.0105,  0.0335, -0.0181],
           [ 0.0360, -0.0030,  0.0508, -0.0568, -0.0354],
           [-0.0066,  0.0581, -0.0093, -0.1296, -0.1319]]],


         [[[ 0.0627, -0.0055,  0.0464, -0.0104,  0.0381],
           [ 0.0913,  0.0370,  0.1157,  0.0681,  0.0619],
           [ 0.0803, -0.0202,  0.0092,  0.0197, -0.0318]],

          [[-0.1285, -0.0333,  0.0268,  0.0411,  0.1090],
           [-0.0752,  0.0236,  0.1045,  0.0863,  0.0762],
           [-0.0814,  0.0476,  0.0997,  0.0372, -0.0540]]],


         [[[ 0.0473,  0.0032, -0.1023, -0.0793, -0.0694],
           [ 0.0249,  0.0126, -0.0574, -0.0932, -0.0388],
           [ 0.0050, -0.0573, -0.0303, -0.0120,  0.0856]],

          [[-0.0460,  0.0837,  0.0385, -0.0553, -0.1395],
           [-0.0052,  0.0463, -0.0022, -0.1083, -0.1087],
           [-0.0130, -0.0005, -0.0351, -0.0712, -0.0015]]]],



        [[[[-0.0281, -0.0845, -0.0653, -0.0264,  0.1155],
           [ 0.0105, -0.1148, -0.1028, -0.0789, -0.0510],
           [ 0.0143, -0.0303, -0.0683, -0.0224, -0.0462]],

          [[-0.0648, -0.0430, -0.0051, -0.0252,  0.0733],
           [ 0.0537, -0.0577,  0.0054, -0.0213, -0.0247],
           [ 0.0845, -0.0101, -0.0016, -0.0091, -0.0906]]],


         [[[-0.0451, -0.1179, -0.0903, -0.0465, -0.0085],
           [-0.0327, -0.1201,  0.0174,  0.0864,  0.0950],
           [-0.1304, -0.0908,  0.0144,  0.1890,  0.1247]],

          [[-0.0161,  0.0116,  0.0249,  0.0389,  0.0093],
           [-0.0219, -0.0616,  0.0153,  0.1056,  0.0278],
           [-0.1589, -0.0504, -0.0077,  0.1316,  0.0703]]],


         [[[ 0.1249,  0.0087,  0.0239,  0.1628,  0.1556],
           [ 0.0039, -0.1151,  0.0260,  0.1424,  0.0833],
           [ 0.0444, -0.0403,  0.0174,  0.0642, -0.0511]],

          [[ 0.1376,  0.0211,  0.0531,  0.0346, -0.0012],
           [-0.0289, -0.0518, -0.0202,  0.0175,  0.0109],
           [ 0.0296, -0.0400, -0.0482,  0.0174, -0.0121]]]],



        ...,



        [[[[-0.0771, -0.0277,  0.0791, -0.0776, -0.1190],
           [-0.0571, -0.0619, -0.0412,  0.0068,  0.0416],
           [ 0.0325,  0.0706,  0.0153,  0.0045, -0.0465]],

          [[-0.0291, -0.0795,  0.0684,  0.0140, -0.0298],
           [ 0.0075,  0.0497, -0.0010,  0.0438,  0.1202],
           [ 0.0298,  0.0445,  0.0144,  0.0017, -0.0492]]],


         [[[ 0.0434, -0.0166, -0.0465, -0.0897, -0.0882],
           [-0.0252, -0.0562, -0.0181, -0.0497, -0.1119],
           [-0.0317, -0.2237, -0.0485,  0.0463, -0.0153]],

          [[-0.0680, -0.0083, -0.1127, -0.1758, -0.0243],
           [-0.0041,  0.0070, -0.0034, -0.0524, -0.0822],
           [-0.0934, -0.1786,  0.0429,  0.0463,  0.0162]]],


         [[[-0.0581, -0.1685, -0.1152, -0.0527, -0.0202],
           [-0.0650, -0.0269,  0.0229,  0.0383, -0.0243],
           [-0.0528, -0.0677, -0.0479,  0.0292, -0.0346]],

          [[ 0.0409, -0.0401, -0.0393, -0.0946, -0.0431],
           [ 0.0061,  0.0027,  0.0600,  0.0901, -0.0328],
           [-0.0775,  0.0608,  0.0759,  0.0561,  0.0585]]]],



        [[[[-0.0217,  0.0373,  0.0069, -0.0454, -0.0862],
           [-0.0544, -0.0134, -0.0810, -0.0945, -0.0164],
           [-0.0227,  0.0453,  0.0011,  0.0225,  0.1123]],

          [[ 0.0637, -0.0228,  0.0060,  0.0701, -0.0240],
           [ 0.0169, -0.0547, -0.0405, -0.0409, -0.0256],
           [-0.0757, -0.0861, -0.1015, -0.0455,  0.0559]]],


         [[[ 0.0264, -0.0168,  0.0729,  0.0735, -0.0536],
           [ 0.0574,  0.0357,  0.0295,  0.0011, -0.1727],
           [-0.0797,  0.0106,  0.0041, -0.0367, -0.1318]],

          [[ 0.0126, -0.0255, -0.0307, -0.0358,  0.0236],
           [ 0.0504, -0.0064,  0.0022,  0.0601, -0.0077],
           [-0.0072, -0.0353,  0.0714,  0.1408,  0.0609]]],


         [[[-0.0680, -0.1141, -0.0148, -0.0516,  0.0601],
           [-0.0102, -0.0438,  0.0058,  0.0725,  0.1690],
           [-0.0892, -0.0174,  0.0658, -0.0102,  0.0485]],

          [[ 0.0173, -0.1130, -0.0859, -0.0172,  0.0462],
           [-0.1016, -0.0784, -0.0268, -0.0104,  0.1317],
           [-0.0010,  0.0063,  0.0316,  0.0005,  0.0714]]]],



        [[[[ 0.0745, -0.1307, -0.0360, -0.0197, -0.0006],
           [ 0.0073, -0.0203,  0.0505,  0.0617,  0.0193],
           [-0.0647, -0.0157,  0.0764,  0.0727, -0.0064]],

          [[-0.0164,  0.0543,  0.0537,  0.0179, -0.0090],
           [ 0.0033, -0.0214, -0.0115,  0.0358, -0.0371],
           [ 0.0668, -0.0073,  0.0760, -0.0251,  0.0071]]],


         [[[ 0.0345, -0.0160,  0.0179, -0.0342, -0.0700],
           [-0.0360, -0.0478,  0.0908,  0.0583, -0.0069],
           [-0.0265, -0.0367,  0.0954,  0.0925,  0.0919]],

          [[ 0.0071, -0.0495,  0.0704, -0.0085, -0.0871],
           [-0.0979, -0.1259,  0.0094, -0.0160, -0.0263],
           [-0.0154, -0.0316, -0.0585, -0.0427, -0.0249]]],


         [[[ 0.1654,  0.0904,  0.0224, -0.0129, -0.1011],
           [ 0.0122, -0.0537, -0.0727, -0.0297, -0.0332],
           [ 0.0091, -0.0359,  0.0052, -0.0273,  0.0222]],

          [[ 0.0848, -0.0411, -0.0039, -0.0641, -0.0553],
           [ 0.0446,  0.0206,  0.0275,  0.0194, -0.0030],
           [ 0.0855,  0.1312,  0.0843, -0.1400, -0.0897]]]]])

2025-07-25 18:13:59.541473 GPU 6 60892 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
[accuracy error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 39627872 / 279392040 (14.2%)
Greatest absolute difference: 0.1843978613615036 at index (2420746, 1, 1, 0, 3) (up to 0.01 allowed)
Greatest relative difference: 9719848.0 at index (2913624, 0, 0, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3104356, 3, 2, 3, 5]), dtype=torch.float32)
tensor([[[[[ 0.0684,  0.0677, -0.0206,  0.0785,  0.1383],
           [ 0.0616,  0.0308,  0.0336,  0.0184, -0.0578],
           [-0.0229, -0.0881, -0.0414, -0.0751, -0.0036]],

          [[ 0.1249, -0.0023, -0.0609, -0.0138,  0.0905],
           [ 0.0950,  0.0921,  0.0598, -0.0157, -0.0892],
           [ 0.0483, -0.0269,  0.0025, -0.0299, -0.0184]]],


         [[[-0.0143,  0.0657,  0.0170, -0.0669, -0.0276],
           [ 0.0567,  0.0886,  0.0937,  0.0641,  0.0154],
           [ 0.0640,  0.0198,  0.0620,  0.0194, -0.0369]],

          [[-0.0061,  0.1008, -0.0237, -0.1151, -0.1128],
           [ 0.0619,  0.1016,  0.0385, -0.0162,  0.0367],
           [ 0.0823,  0.0911,  0.0484, -0.0188, -0.0739]]],


         [[[-0.1390, -0.0797,  0.0385,  0.0229,  0.0009],
           [-0.1077, -0.0562, -0.0407, -0.0107,  0.1048],
           [-0.0314, -0.0435, -0.0004,  0.0219,  0.0398]],

          [[-0.0750,  0.0688, -0.0093, -0.0528, -0.0069],
           [-0.0039,  0.0307,  0.0200,  0.0592, -0.0032],
           [-0.0493,  0.0472,  0.0581,  0.0391,  0.0169]]]],



        [[[[-0.0503, -0.0496, -0.0971, -0.0396, -0.0315],
           [ 0.0832,  0.0253,  0.0059,  0.0782,  0.0721],
           [-0.0321,  0.0102,  0.0680,  0.0274, -0.0680]],

          [[-0.0809, -0.0691,  0.0105,  0.0335, -0.0181],
           [ 0.0360, -0.0030,  0.0508, -0.0568, -0.0354],
           [-0.0066,  0.0581, -0.0093, -0.1296, -0.1319]]],


         [[[ 0.0627, -0.0055,  0.0464, -0.0104,  0.0381],
           [ 0.0913,  0.0370,  0.1157,  0.0681,  0.0619],
           [ 0.0803, -0.0202,  0.0092,  0.0197, -0.0318]],

          [[-0.1285, -0.0333,  0.0268,  0.0411,  0.1090],
           [-0.0752,  0.0236,  0.1045,  0.0863,  0.0762],
           [-0.0814,  0.0476,  0.0997,  0.0372, -0.0540]]],


         [[[ 0.0473,  0.0032, -0.1023, -0.0793, -0.0694],
           [ 0.0249,  0.0126, -0.0574, -0.0932, -0.0388],
           [ 0.0050, -0.0573, -0.0303, -0.0120,  0.0856]],

          [[-0.0460,  0.0837,  0.0385, -0.0553, -0.1395],
           [-0.0052,  0.0463, -0.0022, -0.1083, -0.1087],
           [-0.0130, -0.0005, -0.0351, -0.0712, -0.0015]]]],



        [[[[-0.0281, -0.0845, -0.0653, -0.0264,  0.1155],
           [ 0.0105, -0.1148, -0.1028, -0.0789, -0.0510],
           [ 0.0143, -0.0303, -0.0683, -0.0224, -0.0462]],

          [[-0.0648, -0.0430, -0.0051, -0.0252,  0.0733],
           [ 0.0537, -0.0577,  0.0054, -0.0213, -0.0247],
           [ 0.0845, -0.0101, -0.0016, -0.0091, -0.0906]]],


         [[[-0.0451, -0.1179, -0.0903, -0.0465, -0.0085],
           [-0.0327, -0.1201,  0.0174,  0.0864,  0.0950],
           [-0.1304, -0.0908,  0.0144,  0.1890,  0.1247]],

          [[-0.0161,  0.0116,  0.0249,  0.0389,  0.0093],
           [-0.0219, -0.0616,  0.0153,  0.1056,  0.0278],
           [-0.1589, -0.0504, -0.0077,  0.1316,  0.0703]]],


         [[[ 0.1249,  0.0087,  0.0239,  0.1628,  0.1556],
           [ 0.0039, -0.1151,  0.0260,  0.1424,  0.0833],
           [ 0.0444, -0.0403,  0.0174,  0.0642, -0.0511]],

          [[ 0.1376,  0.0211,  0.0531,  0.0346, -0.0012],
           [-0.0289, -0.0518, -0.0202,  0.0175,  0.0109],
           [ 0.0296, -0.0400, -0.0482,  0.0174, -0.0121]]]],



        ...,



        [[[[-0.0212,  0.0018,  0.0750, -0.0610, -0.0931],
           [-0.0520, -0.0552, -0.0155,  0.0310,  0.0279],
           [ 0.0155,  0.0831,  0.0311,  0.0233, -0.0007]],

          [[ 0.0136, -0.0891,  0.0347,  0.0007, -0.0191],
           [ 0.0197,  0.0697,  0.0175,  0.0342,  0.0865],
           [ 0.0164,  0.0552,  0.0265,  0.0217, -0.0306]]],


         [[[ 0.0430, -0.0475, -0.0600, -0.0727, -0.0451],
           [ 0.0033, -0.0539, -0.0185, -0.0806, -0.1254],
           [-0.0146, -0.1806, -0.0200,  0.0487, -0.0203]],

          [[-0.0817, -0.0059, -0.1016, -0.1352,  0.0045],
           [-0.0049,  0.0024,  0.0138, -0.0366, -0.0883],
           [-0.0959, -0.1782,  0.0398,  0.0264, -0.0204]]],


         [[[-0.0522, -0.1458, -0.1054, -0.0339,  0.0115],
           [-0.0802, -0.0807,  0.0130,  0.0670, -0.0120],
           [-0.0343, -0.0329, -0.0631, -0.0247, -0.0445]],

          [[ 0.0696, -0.0277, -0.0209, -0.0598, -0.0534],
           [-0.0121,  0.0111,  0.0763,  0.1075, -0.0347],
           [-0.0805,  0.0504,  0.0577,  0.0645,  0.0748]]]],



        [[[[-0.0043,  0.0354,  0.0039, -0.0562, -0.1038],
           [-0.0561, -0.0082, -0.0728, -0.1217, -0.0467],
           [-0.0232,  0.0459, -0.0089,  0.0113,  0.1031]],

          [[ 0.0383, -0.0501, -0.0002,  0.0505, -0.0306],
           [ 0.0238, -0.0637, -0.0674, -0.0520, -0.0313],
           [-0.0959, -0.0826, -0.0835, -0.0453,  0.0543]]],


         [[[ 0.0426, -0.0225,  0.0527,  0.0770, -0.0357],
           [ 0.0576,  0.0341,  0.0458, -0.0092, -0.1909],
           [-0.0713,  0.0269,  0.0215, -0.0385, -0.1347]],

          [[ 0.0023, -0.0437, -0.0223, -0.0195,  0.0410],
           [ 0.0485, -0.0093, -0.0086,  0.0424, -0.0094],
           [-0.0020, -0.0270,  0.0442,  0.1105,  0.0604]]],


         [[[-0.0673, -0.1241, -0.0260, -0.0607,  0.0348],
           [-0.0375, -0.0500, -0.0137,  0.0660,  0.1758],
           [-0.0982, -0.0443,  0.0547, -0.0159,  0.0283]],

          [[ 0.0208, -0.0950, -0.0857, -0.0187,  0.0624],
           [-0.1073, -0.0986, -0.0233,  0.0076,  0.1319],
           [-0.0026,  0.0225,  0.0402,  0.0223,  0.0772]]]],



        [[[[ 0.0672, -0.1352, -0.0330, -0.0195,  0.0080],
           [ 0.0291, -0.0144,  0.0432,  0.0572,  0.0223],
           [-0.0645, -0.0305,  0.0480,  0.0689,  0.0035]],

          [[-0.0055,  0.0549,  0.0533, -0.0055, -0.0592],
           [-0.0063, -0.0042,  0.0038,  0.0333, -0.0378],
           [ 0.0535, -0.0332,  0.0724, -0.0160,  0.0230]]],


         [[[ 0.0209, -0.0365,  0.0280, -0.0099, -0.0640],
           [-0.0442, -0.0472,  0.0796,  0.0384,  0.0032],
           [-0.0023, -0.0307,  0.0873,  0.0931,  0.0808]],

          [[-0.0128, -0.0409,  0.0922, -0.0026, -0.0944],
           [-0.1024, -0.1229,  0.0096, -0.0074, -0.0045],
           [-0.0095, -0.0389, -0.0630, -0.0397, -0.0247]]],


         [[[ 0.1506,  0.0620,  0.0187, -0.0030, -0.0903],
           [ 0.0128, -0.0541, -0.0961, -0.0799, -0.0428],
           [ 0.0263, -0.0205,  0.0027, -0.0279,  0.0089]],

          [[ 0.0589, -0.0448,  0.0051, -0.0481, -0.0689],
           [ 0.0240,  0.0307,  0.0518,  0.0254, -0.0111],
           [ 0.0861,  0.1201,  0.0644, -0.1299, -0.0655]]]]])
DESIRED: (shape=torch.Size([3104356, 3, 2, 3, 5]), dtype=torch.float32)
tensor([[[[[ 0.0684,  0.0677, -0.0206,  0.0785,  0.1383],
           [ 0.0616,  0.0308,  0.0336,  0.0184, -0.0578],
           [-0.0229, -0.0881, -0.0414, -0.0751, -0.0036]],

          [[ 0.1249, -0.0023, -0.0609, -0.0138,  0.0905],
           [ 0.0950,  0.0921,  0.0598, -0.0157, -0.0892],
           [ 0.0483, -0.0269,  0.0025, -0.0299, -0.0184]]],


         [[[-0.0143,  0.0657,  0.0170, -0.0669, -0.0276],
           [ 0.0567,  0.0886,  0.0937,  0.0641,  0.0154],
           [ 0.0640,  0.0198,  0.0620,  0.0194, -0.0369]],

          [[-0.0061,  0.1008, -0.0237, -0.1151, -0.1128],
           [ 0.0619,  0.1016,  0.0385, -0.0162,  0.0367],
           [ 0.0823,  0.0911,  0.0484, -0.0188, -0.0739]]],


         [[[-0.1390, -0.0797,  0.0385,  0.0229,  0.0009],
           [-0.1077, -0.0562, -0.0407, -0.0107,  0.1048],
           [-0.0314, -0.0435, -0.0004,  0.0219,  0.0398]],

          [[-0.0750,  0.0688, -0.0093, -0.0528, -0.0069],
           [-0.0039,  0.0307,  0.0200,  0.0592, -0.0032],
           [-0.0493,  0.0472,  0.0581,  0.0391,  0.0169]]]],



        [[[[-0.0503, -0.0496, -0.0971, -0.0396, -0.0315],
           [ 0.0832,  0.0253,  0.0059,  0.0782,  0.0721],
           [-0.0321,  0.0102,  0.0680,  0.0274, -0.0680]],

          [[-0.0809, -0.0691,  0.0105,  0.0335, -0.0181],
           [ 0.0360, -0.0030,  0.0508, -0.0568, -0.0354],
           [-0.0066,  0.0581, -0.0093, -0.1296, -0.1319]]],


         [[[ 0.0627, -0.0055,  0.0464, -0.0104,  0.0381],
           [ 0.0913,  0.0370,  0.1157,  0.0681,  0.0619],
           [ 0.0803, -0.0202,  0.0092,  0.0197, -0.0318]],

          [[-0.1285, -0.0333,  0.0268,  0.0411,  0.1090],
           [-0.0752,  0.0236,  0.1045,  0.0863,  0.0762],
           [-0.0814,  0.0476,  0.0997,  0.0372, -0.0540]]],


         [[[ 0.0473,  0.0032, -0.1023, -0.0793, -0.0694],
           [ 0.0249,  0.0126, -0.0574, -0.0932, -0.0388],
           [ 0.0050, -0.0573, -0.0303, -0.0120,  0.0856]],

          [[-0.0460,  0.0837,  0.0385, -0.0553, -0.1395],
           [-0.0052,  0.0463, -0.0022, -0.1083, -0.1087],
           [-0.0130, -0.0005, -0.0351, -0.0712, -0.0015]]]],



        [[[[-0.0281, -0.0845, -0.0653, -0.0264,  0.1155],
           [ 0.0105, -0.1148, -0.1028, -0.0789, -0.0510],
           [ 0.0143, -0.0303, -0.0683, -0.0224, -0.0462]],

          [[-0.0648, -0.0430, -0.0051, -0.0252,  0.0733],
           [ 0.0537, -0.0577,  0.0054, -0.0213, -0.0247],
           [ 0.0845, -0.0101, -0.0016, -0.0091, -0.0906]]],


         [[[-0.0451, -0.1179, -0.0903, -0.0465, -0.0085],
           [-0.0327, -0.1201,  0.0174,  0.0864,  0.0950],
           [-0.1304, -0.0908,  0.0144,  0.1890,  0.1247]],

          [[-0.0161,  0.0116,  0.0249,  0.0389,  0.0093],
           [-0.0219, -0.0616,  0.0153,  0.1056,  0.0278],
           [-0.1589, -0.0504, -0.0077,  0.1316,  0.0703]]],


         [[[ 0.1249,  0.0087,  0.0239,  0.1628,  0.1556],
           [ 0.0039, -0.1151,  0.0260,  0.1424,  0.0833],
           [ 0.0444, -0.0403,  0.0174,  0.0642, -0.0511]],

          [[ 0.1376,  0.0211,  0.0531,  0.0346, -0.0012],
           [-0.0289, -0.0518, -0.0202,  0.0175,  0.0109],
           [ 0.0296, -0.0400, -0.0482,  0.0174, -0.0121]]]],



        ...,



        [[[[-0.0771, -0.0277,  0.0791, -0.0776, -0.1190],
           [-0.0571, -0.0619, -0.0412,  0.0068,  0.0416],
           [ 0.0325,  0.0706,  0.0153,  0.0045, -0.0465]],

          [[-0.0291, -0.0795,  0.0684,  0.0140, -0.0298],
           [ 0.0075,  0.0497, -0.0010,  0.0438,  0.1202],
           [ 0.0298,  0.0445,  0.0144,  0.0017, -0.0492]]],


         [[[ 0.0434, -0.0166, -0.0465, -0.0897, -0.0882],
           [-0.0252, -0.0562, -0.0181, -0.0497, -0.1119],
           [-0.0317, -0.2237, -0.0485,  0.0463, -0.0153]],

          [[-0.0680, -0.0083, -0.1127, -0.1758, -0.0243],
           [-0.0041,  0.0070, -0.0034, -0.0524, -0.0822],
           [-0.0934, -0.1786,  0.0429,  0.0463,  0.0162]]],


         [[[-0.0581, -0.1685, -0.1152, -0.0527, -0.0202],
           [-0.0650, -0.0269,  0.0229,  0.0383, -0.0243],
           [-0.0528, -0.0677, -0.0479,  0.0292, -0.0346]],

          [[ 0.0409, -0.0401, -0.0393, -0.0946, -0.0431],
           [ 0.0061,  0.0027,  0.0600,  0.0901, -0.0328],
           [-0.0775,  0.0608,  0.0759,  0.0561,  0.0585]]]],



        [[[[-0.0217,  0.0373,  0.0069, -0.0454, -0.0862],
           [-0.0544, -0.0134, -0.0810, -0.0945, -0.0164],
           [-0.0227,  0.0453,  0.0011,  0.0225,  0.1123]],

          [[ 0.0637, -0.0228,  0.0060,  0.0701, -0.0240],
           [ 0.0169, -0.0547, -0.0405, -0.0409, -0.0256],
           [-0.0757, -0.0861, -0.1015, -0.0455,  0.0559]]],


         [[[ 0.0264, -0.0168,  0.0729,  0.0735, -0.0536],
           [ 0.0574,  0.0357,  0.0295,  0.0011, -0.1727],
           [-0.0797,  0.0106,  0.0041, -0.0367, -0.1318]],

          [[ 0.0126, -0.0255, -0.0307, -0.0358,  0.0236],
           [ 0.0504, -0.0064,  0.0022,  0.0601, -0.0077],
           [-0.0072, -0.0353,  0.0714,  0.1408,  0.0609]]],


         [[[-0.0680, -0.1141, -0.0148, -0.0516,  0.0601],
           [-0.0102, -0.0438,  0.0058,  0.0725,  0.1690],
           [-0.0892, -0.0174,  0.0658, -0.0102,  0.0485]],

          [[ 0.0173, -0.1130, -0.0859, -0.0172,  0.0462],
           [-0.1016, -0.0784, -0.0268, -0.0104,  0.1317],
           [-0.0010,  0.0063,  0.0316,  0.0005,  0.0714]]]],



        [[[[ 0.0745, -0.1307, -0.0360, -0.0197, -0.0006],
           [ 0.0073, -0.0203,  0.0505,  0.0617,  0.0193],
           [-0.0647, -0.0157,  0.0764,  0.0727, -0.0064]],

          [[-0.0164,  0.0543,  0.0537,  0.0179, -0.0090],
           [ 0.0033, -0.0214, -0.0115,  0.0358, -0.0371],
           [ 0.0668, -0.0073,  0.0760, -0.0251,  0.0071]]],


         [[[ 0.0345, -0.0160,  0.0179, -0.0342, -0.0700],
           [-0.0360, -0.0478,  0.0908,  0.0583, -0.0069],
           [-0.0265, -0.0367,  0.0954,  0.0925,  0.0919]],

          [[ 0.0071, -0.0495,  0.0704, -0.0085, -0.0871],
           [-0.0979, -0.1259,  0.0094, -0.0160, -0.0263],
           [-0.0154, -0.0316, -0.0585, -0.0427, -0.0249]]],


         [[[ 0.1654,  0.0904,  0.0224, -0.0129, -0.1011],
           [ 0.0122, -0.0537, -0.0727, -0.0297, -0.0332],
           [ 0.0091, -0.0359,  0.0052, -0.0273,  0.0222]],

          [[ 0.0848, -0.0411, -0.0039, -0.0641, -0.0553],
           [ 0.0446,  0.0206,  0.0275,  0.0194, -0.0030],
           [ 0.0855,  0.1312,  0.0843, -0.1400, -0.0897]]]]])

2025-07-25 18:38:35.665045 GPU 4 81428 test begin: paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:38:39.696514 GPU 5 81688 test begin: paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:42:52.342361 GPU 3 83661 test begin: paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:42:56.860646 GPU 5 83846 test begin: paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:45:04.551683 GPU 7 85042 test begin: paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:45:15.960618 GPU 6 85254 test begin: paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:47:40.887269 GPU 7 85042 test begin: paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 570425345],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 570425345],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:47:59.229897 GPU 7 85042 test begin: paddle.nn.functional.batch_norm(Tensor([2, 1, 380283564, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 1, 380283564, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:49:25.789011 GPU 1 88101 test begin: paddle.nn.functional.batch_norm(Tensor([2, 190141782, 2, 3],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 190141782, 2, 3],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:50:47.932050 GPU 1 88101 test begin: paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:50:55.012828 GPU 4 88346 test begin: paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:52:44.699305 GPU 4 88346 test begin: paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:52:59.423580 GPU 4 88346 test begin: paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:56:56.251638 GPU 3 91115 test begin: paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 18:57:01.860826 GPU 7 91300 test begin: paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 19:03:55.270538 GPU 7 96325 test begin: paddle.nn.functional.batch_norm(Tensor([380283564, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([380283564, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 19:03:59.744383 GPU 4 96495 test begin: paddle.nn.functional.batch_norm(Tensor([4, 1980644, 12, 24],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([4, 1980644, 12, 24],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 19:06:40.844034 GPU 6 98173 test begin: paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7922575],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7922575],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 19:09:13.183276 GPU 5 99530 test begin: paddle.nn.functional.batch_norm(Tensor([4, 6, 3961288, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.batch_norm(Tensor([4, 6, 3961288, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/batch_norm_kernel.cu:704)


2025-07-25 19:50:56.381085 GPU 5 122292 test begin: paddle.nn.functional.conv1d(Tensor([107375, 400, 100],"float32"), Tensor([256, 100, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv1d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv1d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753444324 (unix time) try "date -d @1753444324" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 122292 (TID 0x7fb01d432740) from PID 24 ***]


2025-07-25 20:08:46.922376 GPU 6 130157 test begin: paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
/host_home/ningzhengsheng/paddle_env/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return func(*args, **kwargs)


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
1   torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
2   torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&)
3   torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&)
4   torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&)
5   at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
6   at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
7   at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753445415 (unix time) try "date -d @1753445415" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 130157 (TID 0x7f3c72aff700) from PID 24 ***]


2025-07-25 20:16:48.482870 GPU 1 134793 test begin: paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([1, 32, 7],"float32"), bias=Tensor([1],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv1d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv1d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753445887 (unix time) try "date -d @1753445887" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 134793 (TID 0x7f63eface740) from PID 24 ***]


2025-07-25 20:17:54.621779 GPU 5 135383 test begin: paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv1d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv1d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753445946 (unix time) try "date -d @1753445946" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 135383 (TID 0x7f91cfdfd740) from PID 24 ***]


2025-07-25 20:19:10.830104 GPU 5 136368 test begin: paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv1d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv1d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753446033 (unix time) try "date -d @1753446033" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 136368 (TID 0x7f7b39a2b740) from PID 24 ***]


2025-07-25 20:20:31.367546 GPU 7 137384 test begin: paddle.nn.functional.conv1d(Tensor([8192, 256, 2048],"float32"), Tensor([20, 256, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv1d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv1d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753446113 (unix time) try "date -d @1753446113" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 137384 (TID 0x7f2374c05740) from PID 24 ***]


2025-07-25 20:20:37.752935 GPU 5 137581 test begin: paddle.nn.functional.conv1d(Tensor([8192, 256, 2048],"float32"), Tensor([256, 256, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv1d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv1d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753446113 (unix time) try "date -d @1753446113" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 137581 (TID 0x7f3ebee90740) from PID 24 ***]


2025-07-25 22:42:31.534882 GPU 3 163257 test begin: paddle.nn.functional.conv2d(Tensor([1009, 256, 129, 129],"float32"), Tensor([1009, 256, 3, 3],"float32"), bias=None, stride=2, padding=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
1   torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
2   torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&)
3   torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&)
4   torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&)
5   at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
6   at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
7   at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753454562 (unix time) try "date -d @1753454562" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 163257 (TID 0x7f5c659b5700) from PID 24 ***]


2025-07-25 22:42:46.810227 GPU 3 163606 test begin: paddle.nn.functional.conv2d(Tensor([1009, 256, 129, 129],"float32"), Tensor([512, 256, 3, 3],"float32"), bias=None, stride=2, padding=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
1   torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
2   torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&)
3   torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&)
4   torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&)
5   at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
6   at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
7   at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753454650 (unix time) try "date -d @1753454650" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 163606 (TID 0x7f27e96fd700) from PID 24 ***]


2025-07-25 22:48:57.971488 GPU 4 2599 test begin: paddle.nn.functional.conv2d(Tensor([1024, 256, 128, 128],"float32"), Tensor([256, 256, 3, 3],"float32"), bias=None, stride=1, padding=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455020 (unix time) try "date -d @1753455020" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 2599 (TID 0x7f7937e70740) from PID 24 ***]


2025-07-25 22:49:14.743196 GPU 7 1557 test begin: paddle.nn.functional.conv2d(Tensor([1024, 256, 128, 128],"float32"), Tensor([256, 256, 3, 3],"float32"), padding=1, groups=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753454957 (unix time) try "date -d @1753454957" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 1557 (TID 0x7f4b71bff740) from PID 24 ***]


2025-07-25 22:49:22.377331 GPU 7 2840 test begin: paddle.nn.functional.conv2d(Tensor([1024, 256, 128, 128],"float32"), Tensor([3, 256, 1, 1],"float32"), padding=0, groups=1, )
/host_home/ningzhengsheng/paddle_env/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return func(*args, **kwargs)


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
1   torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool)
2   torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&)
3   torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&)
4   torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&)
5   at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
6   at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>)
7   at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455049 (unix time) try "date -d @1753455049" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 2840 (TID 0x7f7b650b5700) from PID 24 ***]


2025-07-25 22:49:46.336198 GPU 3 2195 test begin: paddle.nn.functional.conv2d(Tensor([1024, 4096, 32, 32],"float32"), Tensor([1024, 512, 3, 3],"float32"), padding=1, groups=8, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753454989 (unix time) try "date -d @1753454989" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 2195 (TID 0x7fc9dea5d740) from PID 24 ***]


2025-07-25 22:51:45.223645 GPU 1 1959 test begin: paddle.nn.functional.conv2d(Tensor([128, 2048, 128, 128],"float32"), Tensor([128, 256, 3, 3],"float32"), padding=1, groups=8, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455108 (unix time) try "date -d @1753455108" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 1959 (TID 0x7efcb7ce0740) from PID 24 ***]


2025-07-25 22:51:50.633591 GPU 2 3359 test begin: paddle.nn.functional.conv2d(Tensor([128, 2048, 128, 128],"float32"), Tensor([2048, 256, 3, 3],"float32"), padding=1, groups=8, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455114 (unix time) try "date -d @1753455114" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 3359 (TID 0x7f38f56bd740) from PID 24 ***]


2025-07-25 22:53:27.090338 GPU 1 4255 test begin: paddle.nn.functional.conv2d(Tensor([24, 21179, 67, 67],"float32"), Tensor([1, 21179, 4, 4],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455208 (unix time) try "date -d @1753455208" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 4255 (TID 0x7f566049f740) from PID 24 ***]


2025-07-25 22:53:28.869423 GPU 7 3943 test begin: paddle.nn.functional.conv2d(Tensor([273, 128, 256, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455211 (unix time) try "date -d @1753455211" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 3943 (TID 0x7f1851d45740) from PID 24 ***]


2025-07-25 22:53:31.589231 GPU 2 4455 test begin: paddle.nn.functional.conv2d(Tensor([35, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv2d::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
3   at::native::conv2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455214 (unix time) try "date -d @1753455214" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 4455 (TID 0x7f517ff40740) from PID 24 ***]


2025-07-25 23:03:17.711308 GPU 4 13470 test begin: paddle.nn.functional.conv2d_transpose(Tensor([10496, 16, 172, 79],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv_transpose2d_input::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
3   at::native::conv_transpose2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution_transpose::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution_transpose(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753455837 (unix time) try "date -d @1753455837" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 13470 (TID 0x7fcb39672740) from PID 24 ***]


2025-07-25 23:10:21.147317 GPU 2 17260 test begin: paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 178956971, 3],"float64"), Tensor([2, 2, 178956971, 1],"float64"), groups=1, padding="SAME", )
/host_home/ningzhengsheng/paddle_env/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return func(*args, **kwargs)

2025-07-25 23:10:25.202018 GPU 4 17445 test begin: paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 178956971, 3],"float64"), Tensor([2, 2, 178956971, 1],"float64"), groups=1, padding="VALID", )
/host_home/ningzhengsheng/paddle_env/lib/python3.10/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return func(*args, **kwargs)

2025-07-25 23:17:43.106881 GPU 1 20224 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 16, 172, 12955],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv_transpose2d_input::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
3   at::native::conv_transpose2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution_transpose::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution_transpose(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753456708 (unix time) try "date -d @1753456708" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 20224 (TID 0x7fca1543f740) from PID 24 ***]


2025-07-25 23:17:44.631248 GPU 7 20324 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 16, 28206, 79],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv_transpose2d_input::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
3   at::native::conv_transpose2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution_transpose::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution_transpose(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753456717 (unix time) try "date -d @1753456717" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 20324 (TID 0x7fc4a2e03740) from PID 24 ***]


2025-07-25 23:18:32.984177 GPU 1 20596 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 2624, 172, 79],"float32"), Tensor([2624, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function(torch::PythonArgs&, _object*, _object*, _object*, _object*, char const*, char const*)
1   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
2   at::_ops::conv_transpose2d_input::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
3   at::native::conv_transpose2d_symint(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, c10::ArrayRef<c10::SymInt>)
4   at::_ops::convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
5   at::_ops::convolution::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt)
6   at::native::convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long)
7   at::_ops::_convolution::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool, bool)
8   at::native::_convolution(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, bool, bool, bool, bool)
9   at::_ops::cudnn_convolution_transpose::call(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::SymInt, bool, bool, bool)
10  at::native::cudnn_convolution_transpose(at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753456762 (unix time) try "date -d @1753456762" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 20596 (TID 0x7fa0d59b1740) from PID 24 ***]


2025-07-26 00:47:25.933451 GPU 7 61307 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=None, reduction="mean", )
[accuracy error] paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=None, reduction="mean", )
Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected inf but got nan.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
nan
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
inf

2025-07-26 00:47:40.706794 GPU 5 61472 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=None, reduction="none", )
[accuracy error] paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=None, reduction="none", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1431655766 / 1431655766 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 1]), dtype=torch.float16)
tensor([[nan],
        [nan],
        [nan],
        ...,
        [nan],
        [nan],
        [nan]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 1]), dtype=torch.float16)
tensor([[1.1299],
        [1.3359],
        [1.1562],
        ...,
        [1.1094],
        [1.1943],
        [1.0479]], dtype=torch.float16)

2025-07-26 00:48:17.109321 GPU 4 61632 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, label_smoothing=0.5986189939413826, axis=-1, weight=None, reduction="none", )
[accuracy error] paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, label_smoothing=0.5986189939413826, axis=-1, weight=None, reduction="none", )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1431655766 / 1431655766 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 1]), dtype=torch.float16)
tensor([[nan],
        [nan],
        [nan],
        ...,
        [nan],
        [nan],
        [nan]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 1]), dtype=torch.float16)
tensor([[1.1250],
        [1.0801],
        [1.1025],
        ...,
        [1.1221],
        [1.1562],
        [1.1172]], dtype=torch.float16)

2025-07-26 00:51:26.424088 GPU 7 61307 test begin: paddle.nn.functional.cross_entropy(Tensor([16, 142606337],"float32"), Tensor([16, 142606337],"float32"), soft_label=True, )
[paddle error] paddle.nn.functional.cross_entropy(Tensor([16, 142606337],"float32"), Tensor([16, 142606337],"float32"), soft_label=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/backends/gpu/cuda/cudnn_helper.h:248)


2025-07-26 00:53:06.240219 GPU 1 61953 test begin: paddle.nn.functional.cross_entropy(Tensor([5704254, 400],"float32"), Tensor([5704254, 400],"float32"), soft_label=True, )
[paddle error] paddle.nn.functional.cross_entropy(Tensor([5704254, 400],"float32"), Tensor([5704254, 400],"float32"), soft_label=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/backends/gpu/cuda/cudnn_helper.h:248)


2025-07-26 00:53:26.848816 GPU 3 62112 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 285212673],"float32"), Tensor([8, 285212673],"float32"), soft_label=True, )
[paddle error] paddle.nn.functional.cross_entropy(Tensor([8, 285212673],"float32"), Tensor([8, 285212673],"float32"), soft_label=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/backends/gpu/cuda/cudnn_helper.h:248)


2025-07-26 00:53:34.162058 GPU 5 61472 test begin: paddle.nn.functional.cross_entropy(input=Tensor([2, 1140850690],"float32"), label=Tensor([2, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.cross_entropy(input=Tensor([2, 1140850690],"float32"), label=Tensor([2, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, ) 
 list index out of range

2025-07-26 00:53:41.134926 GPU 5 61472 test begin: paddle.nn.functional.cross_entropy(input=Tensor([22369622, 102],"float32"), label=Tensor([22369622, 1],"int64"), reduction="none", use_softmax=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.cross_entropy(input=Tensor([22369622, 102],"float32"), label=Tensor([22369622, 1],"int64"), reduction="none", use_softmax=False, ) 
 list index out of range

2025-07-26 00:53:43.791092 GPU 7 62620 test begin: paddle.nn.functional.cross_entropy(input=Tensor([228170138, 10],"float32"), label=Tensor([228170138, 1],"int64"), reduction="none", use_softmax=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.cross_entropy(input=Tensor([228170138, 10],"float32"), label=Tensor([228170138, 1],"int64"), reduction="none", use_softmax=False, ) 
 list index out of range

2025-07-26 00:53:46.824519 GPU 5 61472 test begin: paddle.nn.functional.cross_entropy(input=Tensor([42107523, 102],"float16"), label=Tensor([42107523, 1],"int64"), reduction="none", use_softmax=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.cross_entropy(input=Tensor([42107523, 102],"float16"), label=Tensor([42107523, 1],"int64"), reduction="none", use_softmax=False, ) 
 list index out of range

2025-07-26 00:53:50.331419 GPU 6 62278 test begin: paddle.nn.functional.cross_entropy(input=Tensor([5704254, 400],"float32"), label=Tensor([5704254, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.cross_entropy(input=Tensor([5704254, 400],"float32"), label=Tensor([5704254, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, ) 
 list index out of range

2025-07-26 00:53:53.683056 GPU 5 61472 test begin: paddle.nn.functional.ctc_loss(Tensor([120445, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([120445, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:53:59.189139 GPU 5 61472 test begin: paddle.nn.functional.ctc_loss(Tensor([16777217, 4, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([16777217, 4, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:13.648675 GPU 5 61472 test begin: paddle.nn.functional.ctc_loss(Tensor([240890, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([240890, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:19.901205 GPU 5 61472 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 256, 356516],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 256, 356516],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:23.592462 GPU 1 61953 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 512, 178258],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 512, 178258],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:25.693350 GPU 5 61472 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 950709, 96],"float32"), Tensor([950709, 25],"int32"), Tensor([950709],"int64"), Tensor([950709],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 950709, 96],"float32"), Tensor([950709, 25],"int32"), Tensor([950709],"int64"), Tensor([950709],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:26.973181 GPU 1 61953 test begin: paddle.nn.functional.ctc_loss(Tensor([2691, 128, 6625],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([2691, 128, 6625],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:31.962942 GPU 1 61953 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 4, 142606337],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([4, 4, 142606337],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:42.473793 GPU 4 62789 test begin: paddle.nn.functional.ctc_loss(Tensor([40, 128, 445645],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([40, 128, 445645],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:54:55.677330 GPU 5 62947 test begin: paddle.nn.functional.ctc_loss(Tensor([40, 8611, 6625],"float32"), Tensor([8611, 25],"int32"), Tensor([8611],"int64"), Tensor([8611],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([40, 8611, 6625],"float32"), Tensor([8611, 25],"int32"), Tensor([8611],"int64"), Tensor([8611],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:55:17.189083 GPU 6 62278 test begin: paddle.nn.functional.ctc_loss(Tensor([50704476, 3, 15],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([50704476, 3, 15],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 00:55:17.574105 GPU 7 62620 test begin: paddle.nn.functional.ctc_loss(Tensor([92843, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
One of the differentiated Tensors does not require grad
[paddle error] paddle.nn.functional.ctc_loss(Tensor([92843, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/impl/warpctc_kernel_impl.h:200)


2025-07-26 01:09:19.771145 GPU 6 64435 test begin: paddle.nn.functional.instance_norm(Tensor([1048576, 32, 128],"float32"), )
[paddle error] paddle.nn.functional.instance_norm(Tensor([1048576, 32, 128],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:10:07.479573 GPU 3 65267 test begin: paddle.nn.functional.instance_norm(Tensor([1073742, 100, 4, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([1073742, 100, 4, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:10:12.058394 GPU 4 65425 test begin: paddle.nn.functional.instance_norm(Tensor([1431656, 100, 3, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([1431656, 100, 3, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:11:00.940710 GPU 5 65598 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 21474837],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 21474837],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:11:06.571478 GPU 6 64435 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 2147484, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 2147484, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:12:09.461726 GPU 2 65106 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 3579140],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 3579140],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:12:21.121130 GPU 1 64919 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 7158279],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 7158279],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:12:29.991541 GPU 6 64435 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 4, 2684355],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 4, 2684355],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:12:38.280320 GPU 7 64119 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 4, 5368710],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 4, 5368710],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:13:05.403924 GPU 3 65267 test begin: paddle.nn.functional.instance_norm(Tensor([2, 100, 4294968, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 100, 4294968, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:13:12.352430 GPU 5 65598 test begin: paddle.nn.functional.instance_norm(Tensor([2, 16777216, 128],"float32"), )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 16777216, 128],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:13:20.179535 GPU 7 64119 test begin: paddle.nn.functional.instance_norm(Tensor([2, 32, 67108864],"float32"), )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2, 32, 67108864],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:13:51.563580 GPU 6 64435 test begin: paddle.nn.functional.instance_norm(Tensor([2147484, 100, 4, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2147484, 100, 4, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:13:54.339634 GPU 5 65598 test begin: paddle.nn.functional.instance_norm(Tensor([2684355, 100, 16],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2684355, 100, 16],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:03.196839 GPU 7 64119 test begin: paddle.nn.functional.instance_norm(Tensor([2684355, 100, 4, 4],"float16"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2684355, 100, 4, 4],"float16"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:05.372883 GPU 1 64919 test begin: paddle.nn.functional.instance_norm(Tensor([2684355, 100, 4, 4],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2684355, 100, 4, 4],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:27.366722 GPU 4 65425 test begin: paddle.nn.functional.instance_norm(Tensor([2863312, 100, 3, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([2863312, 100, 3, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:32.834057 GPU 6 64435 test begin: paddle.nn.functional.instance_norm(Tensor([4, 100, 10737419],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([4, 100, 10737419],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:37.337886 GPU 5 65598 test begin: paddle.nn.functional.instance_norm(Tensor([4, 100, 2684355, 4],"float16"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([4, 100, 2684355, 4],"float16"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:44.295419 GPU 1 64919 test begin: paddle.nn.functional.instance_norm(Tensor([4, 100, 2684355, 4],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([4, 100, 2684355, 4],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:49.790019 GPU 2 65106 test begin: paddle.nn.functional.instance_norm(Tensor([4, 100, 4, 2684355],"float16"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([4, 100, 4, 2684355],"float16"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:14:53.212889 GPU 3 65267 test begin: paddle.nn.functional.instance_norm(Tensor([4, 100, 4, 2684355],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", )
[paddle error] paddle.nn.functional.instance_norm(Tensor([4, 100, 4, 2684355],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, "NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:15:09.820743 GPU 6 64435 test begin: paddle.nn.functional.instance_norm(Tensor([65536, 32, 32, 64],"float32"), None, None, Tensor([32],"float32"), Tensor([32],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([65536, 32, 32, 64],"float32"), None, None, Tensor([32],"float32"), Tensor([32],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:15:11.299764 GPU 4 65425 test begin: paddle.nn.functional.instance_norm(Tensor([8, 32, 262144, 64],"float32"), None, None, Tensor([32],"float32"), Tensor([32],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([8, 32, 262144, 64],"float32"), None, None, Tensor([32],"float32"), Tensor([32],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:15:22.676827 GPU 1 64919 test begin: paddle.nn.functional.instance_norm(Tensor([8, 32, 32, 524288],"float32"), None, None, Tensor([32],"float32"), Tensor([32],"float32"), True, 0.9, 1e-05, )
[paddle error] paddle.nn.functional.instance_norm(Tensor([8, 32, 32, 524288],"float32"), None, None, Tensor([32],"float32"), Tensor([32],"float32"), True, 0.9, 1e-05, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:15:56.090847 GPU 4 65425 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 1, 1073741825],"float64"), )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 1, 1073741825],"float64"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:16:33.875957 GPU 3 65761 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 178956971, 3],"float64"), )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 178956971, 3],"float64"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:16:44.621217 GPU 6 65919 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 178956971, 3],"float64"), weight=None, bias=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 178956971, 3],"float64"), weight=None, bias=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:16:51.517595 GPU 7 66077 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 178956971, 3],"float64"), weight=None, bias=None, data_format="NCHW", use_input_stats=True, )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 178956971, 3],"float64"), weight=None, bias=None, data_format="NCHW", use_input_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:16:58.561009 GPU 1 66235 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 268435457],"float64"), )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 268435457],"float64"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:17:23.291075 GPU 4 65425 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 268435457],"float64"), weight=None, bias=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 268435457],"float64"), weight=None, bias=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:17:27.816070 GPU 2 66395 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 268435457],"float64"), weight=None, bias=None, data_format="NCHW", use_input_stats=True, )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 268435457],"float64"), weight=None, bias=None, data_format="NCHW", use_input_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:18:32.378378 GPU 5 66556 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 536870912],"float32"), )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 2, 536870912],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:18:50.059907 GPU 4 65425 test begin: paddle.nn.functional.instance_norm(x=Tensor([2, 2, 357913942, 3],"float32"), )
[paddle error] paddle.nn.functional.instance_norm(x=Tensor([2, 2, 357913942, 3],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/kernels/gpu/instance_norm_kernel.cu:123)


2025-07-26 01:20:24.186654 GPU 6 66721 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 16, 268435456],"float32"), size=tuple(256,256,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464130 (unix time) try "date -d @1753464130" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x104a1) received by PID 66721 (TID 0x7effee5fa740) from PID 66721 ***]


2025-07-26 01:20:35.234499 GPU 2 66395 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 256, 16777216],"float32"), tuple(1024,1024,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464124 (unix time) try "date -d @1753464124" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1035b) received by PID 66395 (TID 0x7fc5b4890740) from PID 66395 ***]


2025-07-26 01:20:45.351465 GPU 3 67037 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 32, 134217728],"float32"), size=tuple(256,256,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464140 (unix time) try "date -d @1753464140" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x105dd) received by PID 67037 (TID 0x7fde38fb0740) from PID 67037 ***]


2025-07-26 01:20:46.309478 GPU 7 67124 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 4194304, 1024],"float32"), tuple(429,640,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464151 (unix time) try "date -d @1753464151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10634) received by PID 67124 (TID 0x7f7438200740) from PID 67124 ***]


2025-07-26 01:22:52.479246 GPU 5 66556 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 5835554, 736],"float32"), size=list[368,368,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464196 (unix time) try "date -d @1753464196" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x103fc) received by PID 66556 (TID 0x7f1feb55d740) from PID 66556 ***]


2025-07-26 01:22:56.485754 GPU 4 66879 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 6100806, 704],"float32"), size=list[352,352,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464195 (unix time) try "date -d @1753464195" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1053f) received by PID 66879 (TID 0x7fbbb56c5740) from PID 66879 ***]


2025-07-26 01:23:21.886747 GPU 4 68044 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 64, 67108864],"float32"), size=tuple(256,256,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464305 (unix time) try "date -d @1753464305" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x109cc) received by PID 68044 (TID 0x7fba93204740) from PID 68044 ***]


2025-07-26 01:23:41.566687 GPU 1 66235 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 686, 6260886],"float32"), tuple(429,640,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464243 (unix time) try "date -d @1753464243" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x102bb) received by PID 66235 (TID 0x7f7902682740) from PID 66235 ***]


2025-07-26 01:23:48.958929 GPU 2 67389 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 704, 6100806],"float32"), size=list[352,352,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464248 (unix time) try "date -d @1753464248" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1073d) received by PID 67389 (TID 0x7efd370b5740) from PID 67389 ***]


2025-07-26 01:24:14.297928 GPU 2 68540 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 736, 5835554],"float32"), size=list[368,368,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464348 (unix time) try "date -d @1753464348" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10bbc) received by PID 68540 (TID 0x7f8c1862b740) from PID 68540 ***]


2025-07-26 01:24:51.103085 GPU 3 67720 test begin: paddle.nn.functional.interpolate(Tensor([1, 1, 768, 5592406],"float32"), size=list[384,384,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464314 (unix time) try "date -d @1753464314" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10888) received by PID 67720 (TID 0x7f088f02a740) from PID 67720 ***]


2025-07-26 01:25:05.278769 GPU 6 67555 test begin: paddle.nn.functional.interpolate(Tensor([1, 100, 55925, 768],"float32"), size=list[384,384,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464325 (unix time) try "date -d @1753464325" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x107e3) received by PID 67555 (TID 0x7f5b41af3740) from PID 67555 ***]


2025-07-26 01:25:11.468980 GPU 4 68709 test begin: paddle.nn.functional.interpolate(Tensor([1, 100, 58356, 736],"float32"), size=list[368,368,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464407 (unix time) try "date -d @1753464407" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10c65) received by PID 68709 (TID 0x7fd54fe60740) from PID 68709 ***]


2025-07-26 01:25:13.106817 GPU 7 67885 test begin: paddle.nn.functional.interpolate(Tensor([1, 100, 61009, 704],"float32"), size=list[352,352,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464338 (unix time) try "date -d @1753464338" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1092d) received by PID 67885 (TID 0x7f0cb78ad740) from PID 67885 ***]


2025-07-26 01:25:16.421768 GPU 5 68130 test begin: paddle.nn.functional.interpolate(Tensor([1, 100, 704, 61009],"float32"), size=list[352,352,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464341 (unix time) try "date -d @1753464341" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10a22) received by PID 68130 (TID 0x7f72be6f0740) from PID 68130 ***]


2025-07-26 01:25:20.414052 GPU 3 68875 test begin: paddle.nn.functional.interpolate(Tensor([1, 100, 736, 58356],"float32"), size=list[368,368,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464409 (unix time) try "date -d @1753464409" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10d0b) received by PID 68875 (TID 0x7fd177b19740) from PID 68875 ***]


2025-07-26 01:25:32.059929 GPU 6 69035 test begin: paddle.nn.functional.interpolate(Tensor([1, 100, 768, 55925],"float32"), size=list[384,384,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464438 (unix time) try "date -d @1753464438" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10dab) received by PID 69035 (TID 0x7fbff875f740) from PID 69035 ***]


2025-07-26 01:25:45.210954 GPU 7 69209 test begin: paddle.nn.functional.interpolate(Tensor([1, 1048576, 64, 64],"float32"), size=tuple(16,16,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464435 (unix time) try "date -d @1753464435" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10e59) received by PID 69209 (TID 0x7f8d7e0f3740) from PID 69209 ***]


2025-07-26 01:27:07.000467 GPU 1 68381 test begin: paddle.nn.functional.interpolate(Tensor([1, 1101274, 50, 78],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464458 (unix time) try "date -d @1753464458" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10b1d) received by PID 68381 (TID 0x7f2212986740) from PID 68381 ***]


2025-07-26 01:27:13.694067 GPU 2 69532 test begin: paddle.nn.functional.interpolate(Tensor([1, 1130255, 50, 76],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464470 (unix time) try "date -d @1753464470" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10f9c) received by PID 69532 (TID 0x7f57d89c6740) from PID 69532 ***]


2025-07-26 01:27:17.554071 GPU 5 69297 test begin: paddle.nn.functional.interpolate(Tensor([1, 1130255, 76, 50],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464469 (unix time) try "date -d @1753464469" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10eb1) received by PID 69297 (TID 0x7f198a2c6740) from PID 69297 ***]


2025-07-26 01:27:24.173033 GPU 6 70225 test begin: paddle.nn.functional.interpolate(Tensor([1, 1263226, 50, 68],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464558 (unix time) try "date -d @1753464558" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11251) received by PID 70225 (TID 0x7fa38157c740) from PID 70225 ***]


2025-07-26 01:27:55.926338 GPU 5 70541 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 1, 33554432],"float32"), list[16,32,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464574 (unix time) try "date -d @1753464574" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1138d) received by PID 70541 (TID 0x7f17e519d740) from PID 70541 ***]


2025-07-26 01:28:23.080683 GPU 3 69799 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 1048576, 32],"float32"), list[16,32,], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464521 (unix time) try "date -d @1753464521" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x110a7) received by PID 69799 (TID 0x7f3cda21e740) from PID 69799 ***]


2025-07-26 01:28:24.534980 GPU 4 69710 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 1048576, 32],"float32"), list[32,64,], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464527 (unix time) try "date -d @1753464527" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1104e) received by PID 69710 (TID 0x7fc96881d740) from PID 69710 ***]


2025-07-26 01:28:47.525003 GPU 3 70878 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 128, 139265],"float32"), list[256,256,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464614 (unix time) try "date -d @1753464614" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x114de) received by PID 70878 (TID 0x7ff3f82f0740) from PID 70878 ***]


2025-07-26 01:28:52.522663 GPU 4 71036 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 128, 262144],"float32"), list[256,256,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464618 (unix time) try "date -d @1753464618" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1157c) received by PID 71036 (TID 0x7fcc24b96740) from PID 71036 ***]


2025-07-26 01:29:25.382195 GPU 6 71372 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 16, 2097152],"float32"), list[16,32,], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464652 (unix time) try "date -d @1753464652" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x116cc) received by PID 71372 (TID 0x7fc9e567c740) from PID 71372 ***]


2025-07-26 01:29:40.222127 GPU 5 71537 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 16, 2097152],"float32"), list[32,64,], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464686 (unix time) try "date -d @1753464686" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11771) received by PID 71537 (TID 0x7f01b0775740) from PID 71537 ***]


2025-07-26 01:30:23.926629 GPU 4 72038 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 2, 16777216],"float32"), list[16,32,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464718 (unix time) try "date -d @1753464718" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11966) received by PID 72038 (TID 0x7f7ab3e13740) from PID 72038 ***]


2025-07-26 01:30:32.718117 GPU 2 70629 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 2, 8912897],"float32"), list[128,128,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464644 (unix time) try "date -d @1753464644" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x113e5) received by PID 70629 (TID 0x7fc1c9a3d740) from PID 70629 ***]


2025-07-26 01:30:49.147033 GPU 2 72205 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 3, 11184811],"float32"), list[128,128,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464735 (unix time) try "date -d @1753464735" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11a0d) received by PID 72205 (TID 0x7f309f692740) from PID 72205 ***]


2025-07-26 01:30:58.460948 GPU 6 72370 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 32, 1048576],"float32"), list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464757 (unix time) try "date -d @1753464757" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11ab2) received by PID 72370 (TID 0x7f4333eaf740) from PID 72370 ***]


2025-07-26 01:31:38.935755 GPU 1 71203 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 364723, 92],"float32"), size=list[92,92,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464720 (unix time) try "date -d @1753464720" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11623) received by PID 71203 (TID 0x7f48014fb740) from PID 71203 ***]


2025-07-26 01:32:03.431529 GPU 4 72874 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 4, 8388608],"float32"), list[16,32,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464831 (unix time) try "date -d @1753464831" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11caa) received by PID 72874 (TID 0x7f17e70a1740) from PID 72874 ***]


2025-07-26 01:32:21.265474 GPU 2 73198 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 6, 5592406],"float32"), list[128,128,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464845 (unix time) try "date -d @1753464845" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11dee) received by PID 73198 (TID 0x7f78925b3740) from PID 73198 ***]


2025-07-26 01:32:52.054496 GPU 3 73525 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 92, 364723],"float32"), size=list[92,92,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464880 (unix time) try "date -d @1753464880" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11f35) received by PID 73525 (TID 0x7feab92e9740) from PID 73525 ***]


2025-07-26 01:33:50.375792 GPU 7 71704 test begin: paddle.nn.functional.interpolate(Tensor([1, 14514, 544, 544],"float32"), size=list[272,272,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464870 (unix time) try "date -d @1753464870" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11818) received by PID 71704 (TID 0x7fef87781740) from PID 71704 ***]


2025-07-26 01:34:24.095259 GPU 6 73365 test begin: paddle.nn.functional.interpolate(Tensor([1, 17825793, 128],"float32"), size=list[64,], mode="linear", align_mode=1, align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464910 (unix time) try "date -d @1753464910" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11e95) received by PID 73365 (TID 0x7fcf0164f740) from PID 73365 ***]


2025-07-26 01:34:29.602783 GPU 5 74044 test begin: paddle.nn.functional.interpolate(Tensor([1, 17825793, 128],"float32"), size=list[64,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NCW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464997 (unix time) try "date -d @1753464997" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1213c) received by PID 74044 (TID 0x7f6d32b0e740) from PID 74044 ***]


2025-07-26 01:34:36.584611 GPU 7 74202 test begin: paddle.nn.functional.interpolate(Tensor([1, 19, 128, 1766023],"float32"), list[1024,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464978 (unix time) try "date -d @1753464978" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x121da) received by PID 74202 (TID 0x7f9b34265740) from PID 74202 ***]


2025-07-26 01:34:40.871513 GPU 1 73032 test begin: paddle.nn.functional.interpolate(Tensor([1, 19, 128, 1766023],"float32"), list[512,1024,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753464904 (unix time) try "date -d @1753464904" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11d48) received by PID 73032 (TID 0x7f70917dc740) from PID 73032 ***]


2025-07-26 01:35:16.744296 GPU 6 74684 test begin: paddle.nn.functional.interpolate(Tensor([1, 19, 256, 883012],"float32"), list[1024,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465020 (unix time) try "date -d @1753465020" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x123bc) received by PID 74684 (TID 0x7f66024dc740) from PID 74684 ***]


2025-07-26 01:35:22.593413 GPU 4 74843 test begin: paddle.nn.functional.interpolate(Tensor([1, 19, 256, 883012],"float32"), size=list[1024,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465026 (unix time) try "date -d @1753465026" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1245b) received by PID 74843 (TID 0x7f1017a06740) from PID 74843 ***]


2025-07-26 01:35:24.662983 GPU 2 74931 test begin: paddle.nn.functional.interpolate(Tensor([1, 19, 64, 3532046],"float32"), list[512,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465012 (unix time) try "date -d @1753465012" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x124b3) received by PID 74931 (TID 0x7fd0cdc9d740) from PID 74931 ***]


2025-07-26 01:36:58.941423 GPU 2 75524 test begin: paddle.nn.functional.interpolate(Tensor([1, 192, 1398102, 16],"float32"), size=tuple(24,24,), mode="bicubic", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465123 (unix time) try "date -d @1753465123" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12704) received by PID 75524 (TID 0x7f57b4455740) from PID 75524 ***]


2025-07-26 01:37:06.337432 GPU 6 75689 test begin: paddle.nn.functional.interpolate(Tensor([1, 192, 16, 1398102],"float32"), size=tuple(24,24,), mode="bicubic", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465128 (unix time) try "date -d @1753465128" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x127a9) received by PID 75689 (TID 0x7f099150f740) from PID 75689 ***]


2025-07-26 01:37:34.803267 GPU 1 74526 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 124, 17318417],"float32"), list[496,512,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465081 (unix time) try "date -d @1753465081" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1231e) received by PID 74526 (TID 0x7f715dfdf740) from PID 74526 ***]


2025-07-26 01:37:50.907055 GPU 3 74367 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 124, 17318417],"float32"), size=list[496,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465093 (unix time) try "date -d @1753465093" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1227f) received by PID 74367 (TID 0x7f4e9cc59740) from PID 74367 ***]


2025-07-26 01:38:07.100167 GPU 1 76016 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 128, 16777216],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465187 (unix time) try "date -d @1753465187" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x128f0) received by PID 76016 (TID 0x7f149e1df740) from PID 76016 ***]


2025-07-26 01:38:18.084213 GPU 3 76189 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 128, 16777216],"float32"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465203 (unix time) try "date -d @1753465203" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1299d) received by PID 76189 (TID 0x7f7db212c740) from PID 76189 ***]


2025-07-26 01:38:39.354053 GPU 4 76351 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 128, 16777216],"float32"), size=list[512,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465207 (unix time) try "date -d @1753465207" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12a3f) received by PID 76351 (TID 0x7f938d365740) from PID 76351 ***]


2025-07-26 01:40:13.641664 GPU 7 75179 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 3947581, 544],"float32"), size=list[272,272,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465240 (unix time) try "date -d @1753465240" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x125ab) received by PID 75179 (TID 0x7fdcd1522740) from PID 75179 ***]


2025-07-26 01:40:46.845695 GPU 7 77359 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 544, 3947581],"float32"), size=list[272,272,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465339 (unix time) try "date -d @1753465339" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12e2f) received by PID 77359 (TID 0x7fe5e4f9e740) from PID 77359 ***]


2025-07-26 01:40:55.312150 GPU 2 76516 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 62, 34636834],"float32"), list[496,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465340 (unix time) try "date -d @1753465340" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12ae4) received by PID 76516 (TID 0x7f3c8b11c740) from PID 76516 ***]


2025-07-26 01:41:05.948391 GPU 6 76681 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 64, 33554432],"float32"), list[512,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465290 (unix time) try "date -d @1753465290" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12b89) received by PID 76681 (TID 0x7f561eaac740) from PID 76681 ***]


2025-07-26 01:41:08.802400 GPU 5 75350 test begin: paddle.nn.functional.interpolate(Tensor([1, 200, 39476, 544],"float32"), size=list[272,272,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465291 (unix time) try "date -d @1753465291" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12656) received by PID 75350 (TID 0x7f6f7a711740) from PID 75350 ***]


2025-07-26 01:41:25.935589 GPU 4 77185 test begin: paddle.nn.functional.interpolate(Tensor([1, 200, 544, 39476],"float32"), size=list[272,272,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465309 (unix time) try "date -d @1753465309" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12d81) received by PID 77185 (TID 0x7f0ec503a740) from PID 77185 ***]


2025-07-26 01:41:35.374556 GPU 6 77530 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1, 16777216],"float16"), list[64,64,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465390 (unix time) try "date -d @1753465390" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12eda) received by PID 77530 (TID 0x7fa43c9bb740) from PID 77530 ***]


2025-07-26 01:41:37.156957 GPU 5 77618 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1, 16777216],"float32"), list[62,64,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465390 (unix time) try "date -d @1753465390" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12f32) received by PID 77618 (TID 0x7f02a115c740) from PID 77618 ***]


2025-07-26 01:41:56.147115 GPU 4 77860 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1, 16777216],"float32"), list[64,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465415 (unix time) try "date -d @1753465415" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13024) received by PID 77860 (TID 0x7f30c57d7740) from PID 77860 ***]


2025-07-26 01:42:15.248960 GPU 1 76852 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1, 16777216],"float32"), list[64,64,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465359 (unix time) try "date -d @1753465359" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12c34) received by PID 76852 (TID 0x7fe044ad7740) from PID 76852 ***]


2025-07-26 01:42:21.929727 GPU 3 77018 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1, 16777217],"float16"), list[64,64,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465430 (unix time) try "date -d @1753465430" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12cda) received by PID 77018 (TID 0x7f419f6a4740) from PID 77018 ***]


2025-07-26 01:42:45.495204 GPU 1 78344 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 128, 131072],"float32"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465455 (unix time) try "date -d @1753465455" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13208) received by PID 78344 (TID 0x7f1c3e30c740) from PID 78344 ***]


2025-07-26 01:43:15.572592 GPU 6 78520 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1290556, 13],"float32"), size=list[38,25,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465494 (unix time) try "date -d @1753465494" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x132b8) received by PID 78520 (TID 0x7fafd3103740) from PID 78520 ***]


2025-07-26 01:43:16.455624 GPU 5 78607 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 13, 1290556],"float32"), size=list[25,34,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465485 (unix time) try "date -d @1753465485" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1330f) received by PID 78607 (TID 0x7fa10cb72740) from PID 78607 ***]


2025-07-26 01:43:41.177353 GPU 4 78844 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 13, 1290556],"float32"), size=list[25,38,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465525 (unix time) try "date -d @1753465525" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x133fc) received by PID 78844 (TID 0x7fbfc2822740) from PID 78844 ***]


2025-07-26 01:43:56.169707 GPU 3 79006 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 13, 1290556],"float32"), size=list[25,39,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465536 (unix time) try "date -d @1753465536" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1349e) received by PID 79006 (TID 0x7f55d4869740) from PID 79006 ***]


2025-07-26 01:44:21.428420 GPU 1 79188 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 131072, 128],"float32"), list[128,256,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465560 (unix time) try "date -d @1753465560" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13554) received by PID 79188 (TID 0x7f15bcd00740) from PID 79188 ***]


2025-07-26 01:44:50.680689 GPU 2 78115 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 131072, 128],"float32"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465513 (unix time) try "date -d @1753465513" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13123) received by PID 78115 (TID 0x7f849cdd0740) from PID 78115 ***]


2025-07-26 01:44:51.777233 GPU 5 79356 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 16, 1048576],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465581 (unix time) try "date -d @1753465581" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x135fc) received by PID 79356 (TID 0x7ff6207ee740) from PID 79356 ***]


2025-07-26 01:44:52.275267 GPU 7 78027 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 16, 1048576],"float32"), size=list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465519 (unix time) try "date -d @1753465519" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x130cb) received by PID 78027 (TID 0x7f8fa7c54740) from PID 78027 ***]


2025-07-26 01:46:05.942487 GPU 1 80340 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 19, 883012],"float32"), size=list[38,25,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465673 (unix time) try "date -d @1753465673" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x139d4) received by PID 80340 (TID 0x7ff5fe354740) from PID 80340 ***]


2025-07-26 01:46:27.289189 GPU 5 80505 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 190651, 88],"float32"), size=list[88,88,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465688 (unix time) try "date -d @1753465688" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13a79) received by PID 80505 (TID 0x7f940a136740) from PID 80505 ***]


2025-07-26 01:47:22.689052 GPU 6 79522 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 200, 83887],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465751 (unix time) try "date -d @1753465751" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x136a2) received by PID 79522 (TID 0x7f8e268fc740) from PID 79522 ***]


2025-07-26 01:47:51.284486 GPU 2 79682 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 262144, 64],"float16"), list[128,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465765 (unix time) try "date -d @1753465765" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13742) received by PID 79682 (TID 0x7fc8edfd1740) from PID 79682 ***]


2025-07-26 01:47:58.607239 GPU 1 80719 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 262144, 64],"float32"), list[124,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465772 (unix time) try "date -d @1753465772" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13b4f) received by PID 80719 (TID 0x7f183e3a8740) from PID 80719 ***]


2025-07-26 01:48:04.005426 GPU 4 80006 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 262144, 64],"float32"), list[128,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465711 (unix time) try "date -d @1753465711" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13886) received by PID 80006 (TID 0x7f29d08bf740) from PID 80006 ***]


2025-07-26 01:48:05.272759 GPU 3 80172 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 262144, 64],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465770 (unix time) try "date -d @1753465770" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1392c) received by PID 80172 (TID 0x7f6a5411c740) from PID 80172 ***]


2025-07-26 01:48:06.673786 GPU 7 79841 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 262144, 64],"float32"), size=list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465709 (unix time) try "date -d @1753465709" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x137e1) received by PID 79841 (TID 0x7f5d267ac740) from PID 79841 ***]


2025-07-26 01:48:34.989183 GPU 7 81042 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 304, 55189],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465836 (unix time) try "date -d @1753465836" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13c92) received by PID 81042 (TID 0x7fb9e7b38740) from PID 81042 ***]


2025-07-26 01:48:36.913706 GPU 4 81130 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 31, 541201],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465819 (unix time) try "date -d @1753465819" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13cea) received by PID 81130 (TID 0x7f9fe9c94740) from PID 81130 ***]


2025-07-26 01:49:18.970647 GPU 6 81360 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 32, 524288],"float32"), size=list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465854 (unix time) try "date -d @1753465854" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13dd0) received by PID 81360 (TID 0x7f63f6e49740) from PID 81360 ***]


2025-07-26 01:49:30.627529 GPU 2 81519 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 32, 524288],"float32"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465861 (unix time) try "date -d @1753465861" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13e6f) received by PID 81519 (TID 0x7f08242db740) from PID 81519 ***]


2025-07-26 01:50:37.844787 GPU 5 80884 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 53774, 312],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465877 (unix time) try "date -d @1753465877" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13bf4) received by PID 80884 (TID 0x7f862be30740) from PID 80884 ***]


2025-07-26 01:50:42.068100 GPU 7 82187 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 55189, 304],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465963 (unix time) try "date -d @1753465963" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1410b) received by PID 82187 (TID 0x7f7635499740) from PID 82187 ***]


2025-07-26 01:51:00.738948 GPU 6 82356 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 61681, 272],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465980 (unix time) try "date -d @1753465980" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x141b4) received by PID 82356 (TID 0x7f0107fba740) from PID 82356 ***]


2025-07-26 01:51:07.967287 GPU 2 82522 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 62, 270601],"float32"), list[124,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465961 (unix time) try "date -d @1753465961" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1425a) received by PID 82522 (TID 0x7fa9f53cb740) from PID 82522 ***]


2025-07-26 01:51:24.268504 GPU 5 82694 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 62, 270601],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465986 (unix time) try "date -d @1753465986" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14306) received by PID 82694 (TID 0x7fbf1df9c740) from PID 82694 ***]


2025-07-26 01:51:55.919415 GPU 3 81685 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 64, 262144],"float16"), list[128,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466008 (unix time) try "date -d @1753466008" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13f15) received by PID 81685 (TID 0x7fc2fe8b7740) from PID 81685 ***]


2025-07-26 01:52:04.565428 GPU 1 81773 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 64, 262144],"float32"), list[128,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465951 (unix time) try "date -d @1753465951" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13f6d) received by PID 81773 (TID 0x7f4e01844740) from PID 81773 ***]


2025-07-26 01:52:37.230517 GPU 1 82874 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 64, 262144],"float32"), list[128,256,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466054 (unix time) try "date -d @1753466054" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x143ba) received by PID 82874 (TID 0x7f01328b3740) from PID 82874 ***]


2025-07-26 01:52:46.931070 GPU 2 83040 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 64, 262144],"float32"), size=list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466061 (unix time) try "date -d @1753466061" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14460) received by PID 83040 (TID 0x7fc67bb8d740) from PID 83040 ***]


2025-07-26 01:52:49.427730 GPU 7 83129 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 64, 262144],"float32"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466075 (unix time) try "date -d @1753466075" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x144b9) received by PID 83129 (TID 0x7f304faf4740) from PID 83129 ***]


2025-07-26 01:52:50.113665 GPU 4 82019 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 838861, 20],"float32"), size=list[25,39,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753465992 (unix time) try "date -d @1753465992" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14063) received by PID 82019 (TID 0x7fb4e13d8740) from PID 82019 ***]


2025-07-26 01:53:06.223288 GPU 6 83364 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 83887, 200],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466094 (unix time) try "date -d @1753466094" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x145a4) received by PID 83364 (TID 0x7fe42cc3a740) from PID 83364 ***]


2025-07-26 01:53:12.259407 GPU 5 83529 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 88, 190651],"float32"), size=list[88,88,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466095 (unix time) try "date -d @1753466095" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14649) received by PID 83529 (TID 0x7f24f99db740) from PID 83529 ***]


2025-07-26 01:53:19.006908 GPU 4 83687 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 883012, 19],"float32"), size=list[25,38,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466093 (unix time) try "date -d @1753466093" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x146e7) received by PID 83687 (TID 0x7faa69397740) from PID 83687 ***]


2025-07-26 01:53:33.611668 GPU 3 83845 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 986896, 17],"float32"), size=list[25,34,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466118 (unix time) try "date -d @1753466118" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14785) received by PID 83845 (TID 0x7f57a2e4d740) from PID 83845 ***]


2025-07-26 01:54:20.783870 GPU 1 84017 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 100, 166472],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466153 (unix time) try "date -d @1753466153" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14831) received by PID 84017 (TID 0x7fc89380b740) from PID 84017 ***]


2025-07-26 01:54:26.668915 GPU 2 84183 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 100, 166472],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466168 (unix time) try "date -d @1753466168" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x148d7) received by PID 84183 (TID 0x7f39d564c740) from PID 84183 ***]


2025-07-26 01:54:40.635208 GPU 7 84352 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 106713, 156],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466181 (unix time) try "date -d @1753466181" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14980) received by PID 84352 (TID 0x7f45f9a95740) from PID 84352 ***]


2025-07-26 01:54:59.621163 GPU 4 84532 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 106713, 156],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466202 (unix time) try "date -d @1753466202" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a34) received by PID 84532 (TID 0x7f0b27ee3740) from PID 84532 ***]


2025-07-26 01:54:59.856474 GPU 6 84596 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 109521, 152],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466202 (unix time) try "date -d @1753466202" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a74) received by PID 84596 (TID 0x7fe4322b6740) from PID 84596 ***]


2025-07-26 01:55:00.744583 GPU 5 84707 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 109521, 152],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466190 (unix time) try "date -d @1753466190" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14ae3) received by PID 84707 (TID 0x7f5ced2f4740) from PID 84707 ***]


2025-07-26 01:55:23.988513 GPU 3 85014 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 122406, 136],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466213 (unix time) try "date -d @1753466213" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14c16) received by PID 85014 (TID 0x7f30b0f5d740) from PID 85014 ***]


2025-07-26 01:55:59.436750 GPU 1 85184 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 122406, 136],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466255 (unix time) try "date -d @1753466255" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14cc0) received by PID 85184 (TID 0x7fe45f957740) from PID 85184 ***]


2025-07-26 01:56:13.443538 GPU 2 85352 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 152, 109521],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466276 (unix time) try "date -d @1753466276" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14d68) received by PID 85352 (TID 0x7feee02fc740) from PID 85352 ***]


2025-07-26 01:56:27.187212 GPU 7 85521 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 152, 109521],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466276 (unix time) try "date -d @1753466276" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14e11) received by PID 85521 (TID 0x7f8d0ebb0740) from PID 85521 ***]


2025-07-26 01:56:36.020490 GPU 5 85686 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 166472, 100],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466297 (unix time) try "date -d @1753466297" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14eb6) received by PID 85686 (TID 0x7fa203e9d740) from PID 85686 ***]


2025-07-26 01:56:47.280510 GPU 4 85860 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 166472, 100],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466301 (unix time) try "date -d @1753466301" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14f64) received by PID 85860 (TID 0x7efc5b6a9740) from PID 85860 ***]


2025-07-26 01:56:48.460058 GPU 6 85948 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 213426, 78],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466309 (unix time) try "date -d @1753466309" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14fbc) received by PID 85948 (TID 0x7f0c07a71740) from PID 85948 ***]


2025-07-26 01:56:59.040619 GPU 3 86183 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 219042, 76],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466311 (unix time) try "date -d @1753466311" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x150a7) received by PID 86183 (TID 0x7f53bbf2d740) from PID 86183 ***]


2025-07-26 01:57:41.681718 GPU 1 86354 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 244812, 68],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466360 (unix time) try "date -d @1753466360" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15152) received by PID 86354 (TID 0x7fddb87bc740) from PID 86354 ***]


2025-07-26 01:58:02.987813 GPU 2 86528 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 25, 665887],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466380 (unix time) try "date -d @1753466380" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15200) received by PID 86528 (TID 0x7fdb4ef6f740) from PID 86528 ***]


2025-07-26 01:58:03.008557 GPU 7 86593 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 25, 665887],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466374 (unix time) try "date -d @1753466374" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15241) received by PID 86593 (TID 0x7f1558c5d740) from PID 86593 ***]


2025-07-26 01:58:22.517602 GPU 5 86857 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 332944, 50],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466404 (unix time) try "date -d @1753466404" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15349) received by PID 86857 (TID 0x7ff8f8f50740) from PID 86857 ***]


2025-07-26 01:58:26.977164 GPU 4 87022 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 38, 438084],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466392 (unix time) try "date -d @1753466392" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x153ee) received by PID 87022 (TID 0x7f15fb6b0740) from PID 87022 ***]


2025-07-26 01:58:35.014678 GPU 6 87194 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 38, 438084],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466414 (unix time) try "date -d @1753466414" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1549a) received by PID 87194 (TID 0x7f5362151740) from PID 87194 ***]


2025-07-26 01:58:37.771160 GPU 3 87282 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 426851, 39],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466420 (unix time) try "date -d @1753466420" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x154f2) received by PID 87282 (TID 0x7fa1b0ce1740) from PID 87282 ***]


2025-07-26 01:59:26.356793 GPU 1 87523 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 426851, 39],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466453 (unix time) try "date -d @1753466453" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x155e3) received by PID 87523 (TID 0x7fae3811b740) from PID 87523 ***]


2025-07-26 01:59:40.472171 GPU 7 87691 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 438084, 38],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466477 (unix time) try "date -d @1753466477" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1568b) received by PID 87691 (TID 0x7ff1397e2740) from PID 87691 ***]


2025-07-26 01:59:46.496398 GPU 2 87856 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 438084, 38],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466490 (unix time) try "date -d @1753466490" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15730) received by PID 87856 (TID 0x7f84f2fd7740) from PID 87856 ***]


2025-07-26 01:59:58.060721 GPU 4 88025 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 489623, 34],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466488 (unix time) try "date -d @1753466488" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x157d9) received by PID 88025 (TID 0x7f1425b24740) from PID 88025 ***]


2025-07-26 02:00:10.832642 GPU 5 88191 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 489623, 34],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466505 (unix time) try "date -d @1753466505" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1587f) received by PID 88191 (TID 0x7f24cd7a5740) from PID 88191 ***]


2025-07-26 02:00:19.469754 GPU 6 88356 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 50, 332944],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466519 (unix time) try "date -d @1753466519" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15924) received by PID 88356 (TID 0x7f4e4228c740) from PID 88356 ***]


2025-07-26 02:00:26.097611 GPU 3 88521 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 665887, 25],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466525 (unix time) try "date -d @1753466525" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x159c9) received by PID 88521 (TID 0x7f3be90e0740) from PID 88521 ***]


2025-07-26 02:00:59.713428 GPU 1 88689 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 665887, 25],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466561 (unix time) try "date -d @1753466561" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15a71) received by PID 88689 (TID 0x7f013172f740) from PID 88689 ***]


2025-07-26 02:01:23.854696 GPU 7 88859 test begin: paddle.nn.functional.interpolate(Tensor([1, 258, 76, 219042],"float32"), size=list[24,24,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466583 (unix time) try "date -d @1753466583" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15b1b) received by PID 88859 (TID 0x7f8aa91cf740) from PID 88859 ***]


2025-07-26 02:01:33.796133 GPU 4 89033 test begin: paddle.nn.functional.interpolate(Tensor([1, 275319, 100, 156],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466602 (unix time) try "date -d @1753466602" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15bc9) received by PID 89033 (TID 0x7fd7043c4740) from PID 89033 ***]


2025-07-26 02:01:37.356442 GPU 2 89192 test begin: paddle.nn.functional.interpolate(Tensor([1, 275319, 100, 156],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466595 (unix time) try "date -d @1753466595" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15c68) received by PID 89192 (TID 0x7f4fbee61740) from PID 89192 ***]


2025-07-26 02:01:50.458945 GPU 5 89359 test begin: paddle.nn.functional.interpolate(Tensor([1, 282564, 100, 152],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466616 (unix time) try "date -d @1753466616" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15d0f) received by PID 89359 (TID 0x7f175b6fc740) from PID 89359 ***]


2025-07-26 02:02:06.068289 GPU 6 89525 test begin: paddle.nn.functional.interpolate(Tensor([1, 282564, 100, 152],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466632 (unix time) try "date -d @1753466632" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15db5) received by PID 89525 (TID 0x7fea8b7b5740) from PID 89525 ***]


2025-07-26 02:02:11.329714 GPU 3 89690 test begin: paddle.nn.functional.interpolate(Tensor([1, 282564, 152, 100],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466640 (unix time) try "date -d @1753466640" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15e5a) received by PID 89690 (TID 0x7f4e7429f740) from PID 89690 ***]


2025-07-26 02:02:47.254853 GPU 1 89859 test begin: paddle.nn.functional.interpolate(Tensor([1, 282564, 152, 100],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466667 (unix time) try "date -d @1753466667" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15f03) received by PID 89859 (TID 0x7f51fe23e740) from PID 89859 ***]


2025-07-26 02:03:09.350038 GPU 7 90029 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 1431655765],"float32"), size=list[64,], mode="linear", align_mode=1, align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466674 (unix time) try "date -d @1753466674" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15fad) received by PID 90029 (TID 0x7ff0533f4740) from PID 90029 ***]


2025-07-26 02:03:21.690704 GPU 2 90196 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 1431655765],"float32"), size=list[64,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NCW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466707 (unix time) try "date -d @1753466707" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16054) received by PID 90196 (TID 0x7f89a1bc5740) from PID 90196 ***]


2025-07-26 02:03:28.677038 GPU 4 90361 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 181, 7909701],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466697 (unix time) try "date -d @1753466697" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x160f9) received by PID 90361 (TID 0x7f1abe5df740) from PID 90361 ***]


2025-07-26 02:03:42.047588 GPU 5 90529 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 182, 7866241],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466711 (unix time) try "date -d @1753466711" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x161a1) received by PID 90529 (TID 0x7f6abaac1740) from PID 90529 ***]


2025-07-26 02:03:57.679608 GPU 6 90695 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 200, 7158279],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466728 (unix time) try "date -d @1753466728" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16247) received by PID 90695 (TID 0x7f92ddbe4740) from PID 90695 ***]


2025-07-26 02:04:05.743600 GPU 3 90861 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 212, 6753094],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466746 (unix time) try "date -d @1753466746" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x162ed) received by PID 90861 (TID 0x7f864efe7740) from PID 90861 ***]


2025-07-26 02:04:34.228437 GPU 1 91028 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 22369622, 64],"float32"), size=tuple(16,16,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466762 (unix time) try "date -d @1753466762" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16394) received by PID 91028 (TID 0x7f6fec421740) from PID 91028 ***]


2025-07-26 02:04:40.454442 GPU 7 91188 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 22369622, 64],"float32"), size=tuple(64,64,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466779 (unix time) try "date -d @1753466779" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16434) received by PID 91188 (TID 0x7fa040b46740) from PID 91188 ***]


2025-07-26 02:05:02.988682 GPU 4 91358 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 227, 6306854],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466808 (unix time) try "date -d @1753466808" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x164de) received by PID 91358 (TID 0x7f6a7a363740) from PID 91358 ***]


2025-07-26 02:05:13.827089 GPU 2 91517 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 235, 6092153],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466816 (unix time) try "date -d @1753466816" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1657d) received by PID 91517 (TID 0x7f172262f740) from PID 91517 ***]


2025-07-26 02:05:16.689173 GPU 5 91613 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 250, 5726624],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466850 (unix time) try "date -d @1753466850" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x165dd) received by PID 91613 (TID 0x7f4df7419740) from PID 91613 ***]


2025-07-26 02:05:34.216623 GPU 6 91849 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 256, 5592406],"float32"), size=tuple(180,160,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466838 (unix time) try "date -d @1753466838" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x166c9) received by PID 91849 (TID 0x7fe2ec8a4740) from PID 91849 ***]


2025-07-26 02:05:52.168744 GPU 3 92016 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 28, 51130564],"float32"), size=tuple(46,40,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466843 (unix time) try "date -d @1753466843" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16770) received by PID 92016 (TID 0x7f880a733740) from PID 92016 ***]


2025-07-26 02:06:08.331090 GPU 1 92176 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 280, 5113057],"float32"), size=tuple(256,200,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466871 (unix time) try "date -d @1753466871" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16810) received by PID 92176 (TID 0x7f0cb042d740) from PID 92176 ***]


2025-07-26 02:06:25.500611 GPU 7 92335 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 280, 5113057],"float32"), size=tuple(300,375,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466870 (unix time) try "date -d @1753466870" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x168af) received by PID 92335 (TID 0x7fefcbae2740) from PID 92335 ***]


2025-07-26 02:06:54.078365 GPU 4 92504 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 374, 3827957],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466918 (unix time) try "date -d @1753466918" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16958) received by PID 92504 (TID 0x7f5e20cb1740) from PID 92504 ***]


2025-07-26 02:07:02.280652 GPU 2 92672 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 4090446, 350],"float32"), size=tuple(300,375,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466910 (unix time) try "date -d @1753466910" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16a00) received by PID 92672 (TID 0x7fb491818740) from PID 92672 ***]


2025-07-26 02:07:24.693180 GPU 6 92839 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 4820390, 297],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466935 (unix time) try "date -d @1753466935" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16aa7) received by PID 92839 (TID 0x7f33bf335740) from PID 92839 ***]


2025-07-26 02:07:29.194667 GPU 3 92998 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 5113057, 280],"float32"), size=tuple(256,200,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466938 (unix time) try "date -d @1753466938" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16b46) received by PID 92998 (TID 0x7ff6033e5740) from PID 92998 ***]


2025-07-26 02:07:35.957834 GPU 5 93165 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 5187159, 276],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466946 (unix time) try "date -d @1753466946" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16bed) received by PID 93165 (TID 0x7fa3bc588740) from PID 93165 ***]


2025-07-26 02:07:56.602881 GPU 7 93338 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 5225022, 274],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466977 (unix time) try "date -d @1753466977" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16c9a) received by PID 93338 (TID 0x7fc3be0fb740) from PID 93338 ***]


2025-07-26 02:07:57.820198 GPU 1 93426 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 5506369, 260],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753466981 (unix time) try "date -d @1753466981" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16cf2) received by PID 93426 (TID 0x7fbe8677f740) from PID 93426 ***]


2025-07-26 02:08:35.597024 GPU 2 93667 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 5658719, 253],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467007 (unix time) try "date -d @1753467007" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16de3) received by PID 93667 (TID 0x7f00ad11e740) from PID 93667 ***]


2025-07-26 02:08:43.648491 GPU 4 93834 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 59652324, 24],"float32"), size=tuple(46,40,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467027 (unix time) try "date -d @1753467027" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16e8a) received by PID 93834 (TID 0x7f107590a740) from PID 93834 ***]


2025-07-26 02:09:00.978041 GPU 6 94008 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 64, 22369622],"float32"), size=tuple(16,16,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467044 (unix time) try "date -d @1753467044" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16f38) received by PID 94008 (TID 0x7f6fdeb45740) from PID 94008 ***]


2025-07-26 02:09:03.175310 GPU 3 94096 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 64, 22369622],"float32"), size=tuple(64,64,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467035 (unix time) try "date -d @1753467035" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16f90) received by PID 94096 (TID 0x7f5bca225740) from PID 94096 ***]


2025-07-26 02:09:12.434771 GPU 5 94331 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 6817409, 210],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467046 (unix time) try "date -d @1753467046" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1707b) received by PID 94331 (TID 0x7f93b2dc7740) from PID 94331 ***]


2025-07-26 02:09:42.850892 GPU 7 94501 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 7017921, 204],"float32"), size=tuple(280,280,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467090 (unix time) try "date -d @1753467090" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17125) received by PID 94501 (TID 0x7fbf33f9e740) from PID 94501 ***]


2025-07-26 02:09:46.766065 GPU 1 94666 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 7158279, 200],"float32"), size=tuple(180,160,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467085 (unix time) try "date -d @1753467085" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x171ca) received by PID 94666 (TID 0x7f73c816e740) from PID 94666 ***]


2025-07-26 02:10:13.103578 GPU 2 94835 test begin: paddle.nn.functional.interpolate(Tensor([1, 3, 8892272, 161],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467102 (unix time) try "date -d @1753467102" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17273) received by PID 94835 (TID 0x7fdf8edd4740) from PID 94835 ***]


2025-07-26 02:10:33.518981 GPU 4 94998 test begin: paddle.nn.functional.interpolate(Tensor([1, 315807, 100, 136],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467142 (unix time) try "date -d @1753467142" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17316) received by PID 94998 (TID 0x7ff74805d740) from PID 94998 ***]


2025-07-26 02:10:40.506394 GPU 3 95156 test begin: paddle.nn.functional.interpolate(Tensor([1, 315807, 100, 136],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467151 (unix time) try "date -d @1753467151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x173b4) received by PID 95156 (TID 0x7f381efe0740) from PID 95156 ***]


2025-07-26 02:11:31.306260 GPU 1 95650 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 2, 35651585],"float32"), list[32,32,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467180 (unix time) try "date -d @1753467180" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x175a2) received by PID 95650 (TID 0x7efcf202c740) from PID 95650 ***]


2025-07-26 02:11:47.588084 GPU 2 95980 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 2, 67108864],"float32"), size=tuple(2,2,), mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467199 (unix time) try "date -d @1753467199" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x176ec) received by PID 95980 (TID 0x7f2dbdcd8740) from PID 95980 ***]


2025-07-26 02:12:15.500629 GPU 5 96302 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 3, 44739243],"float32"), list[32,32,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467239 (unix time) try "date -d @1753467239" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1782e) received by PID 96302 (TID 0x7f222cbde740) from PID 96302 ***]


2025-07-26 02:12:51.371266 GPU 7 96792 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 6, 22369622],"float32"), list[32,32,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467262 (unix time) try "date -d @1753467262" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a18) received by PID 96792 (TID 0x7fc708d6d740) from PID 96792 ***]


2025-07-26 02:13:26.401433 GPU 2 97113 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 67108864, 2],"float32"), size=tuple(2,2,), mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467292 (unix time) try "date -d @1753467292" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17b59) received by PID 97113 (TID 0x7f799aa7c740) from PID 97113 ***]


2025-07-26 02:14:04.534279 GPU 6 96142 test begin: paddle.nn.functional.interpolate(Tensor([1, 38667, 374, 297],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467289 (unix time) try "date -d @1753467289" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1778e) received by PID 96142 (TID 0x7f337c049740) from PID 96142 ***]


2025-07-26 02:14:28.657211 GPU 1 97538 test begin: paddle.nn.functional.interpolate(Tensor([1, 4405095, 25, 39],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467383 (unix time) try "date -d @1753467383" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17d02) received by PID 97538 (TID 0x7f2f57238740) from PID 97538 ***]


2025-07-26 02:14:31.848604 GPU 4 96467 test begin: paddle.nn.functional.interpolate(Tensor([1, 4405095, 25, 39],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467312 (unix time) try "date -d @1753467312" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x178d3) received by PID 96467 (TID 0x7f7229c55740) from PID 96467 ***]


2025-07-26 02:14:55.542131 GPU 6 97777 test begin: paddle.nn.functional.interpolate(Tensor([1, 4521019, 25, 38],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467401 (unix time) try "date -d @1753467401" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17df1) received by PID 97777 (TID 0x7f99b3aec740) from PID 97777 ***]


2025-07-26 02:14:57.736085 GPU 2 97865 test begin: paddle.nn.functional.interpolate(Tensor([1, 4521019, 25, 38],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467425 (unix time) try "date -d @1753467425" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17e49) received by PID 97865 (TID 0x7fe2b9db8740) from PID 97865 ***]


2025-07-26 02:15:16.596686 GPU 3 96632 test begin: paddle.nn.functional.interpolate(Tensor([1, 4521019, 38, 25],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467354 (unix time) try "date -d @1753467354" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17978) received by PID 96632 (TID 0x7f4595dfa740) from PID 96632 ***]


2025-07-26 02:15:18.885692 GPU 4 98094 test begin: paddle.nn.functional.interpolate(Tensor([1, 4521019, 38, 25],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467425 (unix time) try "date -d @1753467425" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17f2e) received by PID 98094 (TID 0x7f2c9795a740) from PID 98094 ***]


2025-07-26 02:15:24.929809 GPU 5 97284 test begin: paddle.nn.functional.interpolate(Tensor([1, 5052903, 25, 34],"float32"), size=list[12,12,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467360 (unix time) try "date -d @1753467360" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c04) received by PID 97284 (TID 0x7fa38b284740) from PID 97284 ***]


2025-07-26 02:15:52.061569 GPU 7 97452 test begin: paddle.nn.functional.interpolate(Tensor([1, 5052903, 25, 34],"float32"), size=list[16,16,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467401 (unix time) try "date -d @1753467401" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17cac) received by PID 97452 (TID 0x7efd0eb4c740) from PID 97452 ***]


2025-07-26 02:16:00.477293 GPU 3 98263 test begin: paddle.nn.functional.interpolate(Tensor([1, 54783, 280, 280],"float32"), size=tuple(256,200,), mode="bilinear", data_format="NCHW", )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 02:16:29.909744 GPU 1 98597 test begin: paddle.nn.functional.interpolate(Tensor([1, 6115, 686, 1024],"float32"), tuple(429,640,), mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467526 (unix time) try "date -d @1753467526" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18125) received by PID 98597 (TID 0x7f335a96f740) from PID 98597 ***]


2025-07-26 02:16:46.765403 GPU 7 98835 test begin: paddle.nn.functional.interpolate(Tensor([1, 64, 1048576, 64],"float32"), list[64,128,], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467509 (unix time) try "date -d @1753467509" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18213) received by PID 98835 (TID 0x7f798dbe7740) from PID 98835 ***]


2025-07-26 02:17:10.365447 GPU 4 99102 test begin: paddle.nn.functional.interpolate(Tensor([1, 64, 32, 2097152],"float32"), list[64,128,], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467522 (unix time) try "date -d @1753467522" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1831e) received by PID 99102 (TID 0x7f62e3788740) from PID 99102 ***]


2025-07-26 02:17:12.320337 GPU 2 99190 test begin: paddle.nn.functional.interpolate(Tensor([1, 64, 699051, 96],"float32"), size=list[96,96,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467519 (unix time) try "date -d @1753467519" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18376) received by PID 99190 (TID 0x7fba456d2740) from PID 99190 ***]


2025-07-26 02:17:17.397787 GPU 3 99419 test begin: paddle.nn.functional.interpolate(Tensor([1, 64, 729445, 92],"float32"), size=list[92,92,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467543 (unix time) try "date -d @1753467543" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1845b) received by PID 99419 (TID 0x7f4965bbf740) from PID 99419 ***]


2025-07-26 02:17:37.831131 GPU 5 98422 test begin: paddle.nn.functional.interpolate(Tensor([1, 64, 92, 729445],"float32"), size=list[92,92,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467482 (unix time) try "date -d @1753467482" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18076) received by PID 98422 (TID 0x7f48da2a7740) from PID 98422 ***]


2025-07-26 02:18:36.284508 GPU 7 99777 test begin: paddle.nn.functional.interpolate(Tensor([1, 68830, 200, 312],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467622 (unix time) try "date -d @1753467622" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x185c1) received by PID 99777 (TID 0x7f7336de1740) from PID 99777 ***]


2025-07-26 02:18:45.035825 GPU 2 99943 test begin: paddle.nn.functional.interpolate(Tensor([1, 70295, 235, 260],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 02:18:48.599908 GPU 4 100109 test begin: paddle.nn.functional.interpolate(Tensor([1, 70641, 200, 304],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467640 (unix time) try "date -d @1753467640" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1870d) received by PID 100109 (TID 0x7f0ba8631740) from PID 100109 ***]


2025-07-26 02:18:52.614348 GPU 1 100267 test begin: paddle.nn.functional.interpolate(Tensor([1, 70641, 304, 200],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467636 (unix time) try "date -d @1753467636" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x187ab) received by PID 100267 (TID 0x7fa8344fd740) from PID 100267 ***]


2025-07-26 02:19:10.105547 GPU 3 100432 test begin: paddle.nn.functional.interpolate(Tensor([1, 7282, 768, 768],"float32"), size=list[384,384,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467671 (unix time) try "date -d @1753467671" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18850) received by PID 100432 (TID 0x7ff6712c8740) from PID 100432 ***]


2025-07-26 02:19:30.027090 GPU 5 99592 test begin: paddle.nn.functional.interpolate(Tensor([1, 768, 14, 399458],"float32"), size=tuple(28,28,), align_corners=False, mode="bicubic", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467592 (unix time) try "date -d @1753467592" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18508) received by PID 99592 (TID 0x7f1f2d4d6740) from PID 99592 ***]


2025-07-26 02:19:34.443289 GPU 6 98771 test begin: paddle.nn.functional.interpolate(Tensor([1, 768, 16, 349526],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([1, 768, 16, 349526],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 1 / 4294975488 (0.0%)
Greatest absolute difference: 0.56438148021698 at index (0, 0, 0, 6826) (up to 0.5 allowed)
Greatest relative difference: 24.325273513793945 at index (0, 0, 0, 6826) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([1, 768, 16, 349526]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
DESIRED: (shape=torch.Size([1, 768, 16, 349526]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])

2025-07-26 02:19:57.601005 GPU 5 100605 test begin: paddle.nn.functional.interpolate(Tensor([1, 768, 16, 349526],"float32"), size=list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467706 (unix time) try "date -d @1753467706" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x188fd) received by PID 100605 (TID 0x7f1c71b9e740) from PID 100605 ***]


2025-07-26 02:20:42.588416 GPU 1 101107 test begin: paddle.nn.functional.interpolate(Tensor([1, 768, 31, 180401],"float32"), size=list[124,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467735 (unix time) try "date -d @1753467735" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18af3) received by PID 101107 (TID 0x7f5182498740) from PID 101107 ***]


2025-07-26 02:20:46.326472 GPU 4 101265 test begin: paddle.nn.functional.interpolate(Tensor([1, 768, 32, 174763],"float32"), size=list[128,128,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467738 (unix time) try "date -d @1753467738" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18b91) received by PID 101265 (TID 0x7fcb3a145740) from PID 101265 ***]


2025-07-26 02:21:52.550635 GPU 5 101602 test begin: paddle.nn.functional.interpolate(Tensor([1, 768, 399458, 14],"float32"), size=tuple(28,28,), align_corners=False, mode="bicubic", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467800 (unix time) try "date -d @1753467800" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18ce2) received by PID 101602 (TID 0x7faa6a0aa740) from PID 101602 ***]


2025-07-26 02:22:12.167746 GPU 6 98771 test begin: paddle.nn.functional.interpolate(Tensor([1, 78952, 200, 272],"float32"), scale_factor=0.5, align_corners=False, align_mode=0, mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467773 (unix time) try "date -d @1753467773" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x181d3) received by PID 98771 (TID 0x7f83515bf740) from PID 98771 ***]


2025-07-26 02:22:22.069122 GPU 1 101791 test begin: paddle.nn.functional.interpolate(Tensor([1, 7929, 736, 736],"float32"), size=list[368,368,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467847 (unix time) try "date -d @1753467847" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18d9f) received by PID 101791 (TID 0x7fce707e7740) from PID 101791 ***]


2025-07-26 02:22:25.278408 GPU 4 101951 test begin: paddle.nn.functional.interpolate(Tensor([1, 81809, 250, 210],"float32"), size=tuple(224,224,), mode="bilinear", data_format="NCHW", )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 02:22:33.367003 GPU 2 100775 test begin: paddle.nn.functional.interpolate(Tensor([1, 83887, 256, 200],"float32"), size=tuple(180,160,), mode="bilinear", data_format="NCHW", )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 02:22:55.562384 GPU 7 100934 test begin: paddle.nn.functional.interpolate(Tensor([1, 8666, 704, 704],"float32"), size=list[352,352,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467818 (unix time) try "date -d @1753467818" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18a46) received by PID 100934 (TID 0x7fe231b89740) from PID 100934 ***]


2025-07-26 02:25:35.907034 GPU 4 102763 test begin: paddle.nn.functional.interpolate(Tensor([1068, 258, 100, 156],"float32"), size=list[36,36,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467963 (unix time) try "date -d @1753467963" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1916b) received by PID 102763 (TID 0x7f87dc714740) from PID 102763 ***]


2025-07-26 02:25:40.810223 GPU 3 101430 test begin: paddle.nn.functional.interpolate(Tensor([1068, 258, 100, 156],"float32"), size=list[40,40,], mode="bilinear", align_corners=False, align_mode=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753467968 (unix time) try "date -d @1753467968" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18c36) received by PID 101430 (TID 0x7f8f4ba89740) from PID 101430 ***]


2025-07-26 02:51:02.753435 GPU 3 103456 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([107374183, 8, 4]) != torch.Size([107374183, 7, 4]).
ACTUAL: (shape=torch.Size([107374183, 8, 4]), dtype=torch.float32)
tensor([[[-0.4018,  0.0108, -0.1707,  0.0674],
         [-0.0825,  0.2362, -0.0604, -0.0044],
         [ 0.0178, -0.1443,  0.2581,  0.3112],
         ...,
         [ 0.1169,  0.1675, -0.1766,  0.1110],
         [-0.0049, -0.1206,  0.3444,  0.2834],
         [-0.4339, -0.1651, -0.2872, -0.0122]],

        [[ 0.3124,  0.0352,  0.2601, -0.0732],
         [-0.1372, -0.0892, -0.3314, -0.1974],
         [ 0.3276, -0.1845,  0.1007, -0.4000],
         ...,
         [ 0.0335,  0.2816, -0.3268, -0.1122],
         [ 0.2829,  0.1521,  0.1044, -0.0731],
         [ 0.0636, -0.2618, -0.1398,  0.3918]],

        [[ 0.1032,  0.4019, -0.3039, -0.2428],
         [-0.0679, -0.0590,  0.0934,  0.0607],
         [-0.1137, -0.2458,  0.4288,  0.0496],
         ...,
         [ 0.3193,  0.2471, -0.0889, -0.1082],
         [-0.1964, -0.0589,  0.2230,  0.1613],
         [-0.4191,  0.1290,  0.1087, -0.3541]],

        ...,

        [[-0.3523,  0.0893,  0.1552, -0.1678],
         [ 0.1519,  0.2701, -0.2746,  0.3845],
         [ 0.1139,  0.2550,  0.0151,  0.3245],
         ...,
         [ 0.4297, -0.2634, -0.2966,  0.2751],
         [ 0.0672, -0.2162, -0.4146,  0.1825],
         [-0.0720, -0.3562, -0.1711,  0.0983]],

        [[-0.3998, -0.3703,  0.3908,  0.0687],
         [-0.3495,  0.1603, -0.1037, -0.1271],
         [-0.3819,  0.1771,  0.1371,  0.0426],
         ...,
         [ 0.4421,  0.0041, -0.4639, -0.0935],
         [-0.0876, -0.0054, -0.4502, -0.1474],
         [-0.1175, -0.0643,  0.0299,  0.0759]],

        [[ 0.2833, -0.3553,  0.3053,  0.2567],
         [ 0.2442, -0.1554, -0.0995,  0.0531],
         [-0.2731, -0.3766,  0.3639,  0.1929],
         ...,
         [-0.0044, -0.0118,  0.2389, -0.1611],
         [-0.1865,  0.0717,  0.0896, -0.0935],
         [-0.0797, -0.4077,  0.2379, -0.1555]]])
DESIRED: (shape=torch.Size([107374183, 7, 4]), dtype=torch.float32)
tensor([[[-0.4018,  0.0108, -0.1707,  0.0674],
         [-0.0825,  0.2362, -0.0604, -0.0044],
         [ 0.0178, -0.1443,  0.2581,  0.3112],
         ...,
         [-0.3793,  0.1252,  0.2005,  0.2788],
         [ 0.1169,  0.1675, -0.1766,  0.1110],
         [-0.0049, -0.1206,  0.3444,  0.2834]],

        [[ 0.3124,  0.0352,  0.2601, -0.0732],
         [-0.1372, -0.0892, -0.3314, -0.1974],
         [ 0.3276, -0.1845,  0.1007, -0.4000],
         ...,
         [ 0.0214,  0.1207, -0.1085,  0.2116],
         [ 0.0335,  0.2816, -0.3268, -0.1122],
         [ 0.2829,  0.1521,  0.1044, -0.0731]],

        [[ 0.1032,  0.4019, -0.3039, -0.2428],
         [-0.0679, -0.0590,  0.0934,  0.0607],
         [-0.1137, -0.2458,  0.4288,  0.0496],
         ...,
         [ 0.0343,  0.1057, -0.0415,  0.1152],
         [ 0.3193,  0.2471, -0.0889, -0.1082],
         [-0.1964, -0.0589,  0.2230,  0.1613]],

        ...,

        [[-0.3523,  0.0893,  0.1552, -0.1678],
         [ 0.1519,  0.2701, -0.2746,  0.3845],
         [ 0.1139,  0.2550,  0.0151,  0.3245],
         ...,
         [-0.1246, -0.0665, -0.1689, -0.0390],
         [ 0.4297, -0.2634, -0.2966,  0.2751],
         [ 0.0672, -0.2162, -0.4146,  0.1825]],

        [[-0.3998, -0.3703,  0.3908,  0.0687],
         [-0.3495,  0.1603, -0.1037, -0.1271],
         [-0.3819,  0.1771,  0.1371,  0.0426],
         ...,
         [ 0.4108,  0.1970, -0.4576,  0.3686],
         [ 0.4421,  0.0041, -0.4639, -0.0935],
         [-0.0876, -0.0054, -0.4502, -0.1474]],

        [[ 0.2833, -0.3553,  0.3053,  0.2567],
         [ 0.2442, -0.1554, -0.0995,  0.0531],
         [-0.2731, -0.3766,  0.3639,  0.1929],
         ...,
         [ 0.1948, -0.4628,  0.2077,  0.2881],
         [-0.0044, -0.0118,  0.2389, -0.1611],
         [-0.1865,  0.0717,  0.0896, -0.0935]]])

2025-07-26 02:51:02.908772 GPU 2 103114 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([107374183, 8, 4]) != torch.Size([107374183, 7, 4]).
ACTUAL: (shape=torch.Size([107374183, 8, 4]), dtype=torch.float32)
tensor([[[ 0.2090,  0.2643,  0.3727,  0.2996],
         [ 0.2368, -0.1639,  0.0902, -0.0451],
         [-0.1366, -0.1404,  0.0392,  0.0295],
         ...,
         [-0.0138,  0.2323, -0.3953,  0.0120],
         [ 0.2372, -0.0791, -0.0747,  0.3464],
         [-0.2134,  0.3360,  0.2026, -0.2160]],

        [[ 0.4815, -0.0117, -0.0833, -0.4697],
         [ 0.2394,  0.1380,  0.3359, -0.1069],
         [ 0.2288, -0.1868,  0.0863, -0.0873],
         ...,
         [ 0.2450,  0.1000, -0.0773, -0.2388],
         [-0.3054, -0.0154, -0.0076,  0.1385],
         [ 0.1301,  0.1882,  0.1432, -0.0201]],

        [[ 0.2103, -0.0485,  0.2410, -0.4190],
         [-0.0297,  0.1047,  0.1966, -0.0757],
         [ 0.1336, -0.3659, -0.1076,  0.1350],
         ...,
         [-0.1150, -0.3051,  0.0344,  0.1952],
         [ 0.1697, -0.1914, -0.2295, -0.3811],
         [ 0.1006,  0.1924, -0.2526, -0.3036]],

        ...,

        [[ 0.3665,  0.2293,  0.3033, -0.0344],
         [-0.1140, -0.2000, -0.0533,  0.4292],
         [ 0.0027, -0.3245,  0.0739,  0.2722],
         ...,
         [ 0.0962,  0.2213,  0.0541,  0.0162],
         [ 0.3103, -0.2262,  0.2231, -0.0977],
         [-0.2018,  0.2835,  0.1350, -0.4128]],

        [[-0.1318,  0.0934, -0.1291, -0.0427],
         [-0.3374, -0.4496, -0.1788, -0.1659],
         [ 0.2863, -0.1980, -0.0737, -0.0009],
         ...,
         [ 0.2454,  0.2204,  0.0691,  0.4559],
         [-0.2458, -0.0384, -0.1113, -0.0097],
         [ 0.0312,  0.3918,  0.0030,  0.0959]],

        [[-0.0047, -0.1309, -0.3578, -0.0572],
         [-0.0747, -0.2486,  0.4298, -0.3205],
         [-0.2470, -0.1159,  0.2831, -0.3655],
         ...,
         [ 0.3812,  0.4081,  0.2779, -0.2816],
         [ 0.0976, -0.0604,  0.1147, -0.1026],
         [ 0.1690, -0.3650,  0.1953, -0.2153]]])
DESIRED: (shape=torch.Size([107374183, 7, 4]), dtype=torch.float32)
tensor([[[ 0.2421,  0.2026,  0.3383,  0.2364],
         [ 0.1182, -0.1313,  0.0864,  0.0352],
         [-0.0521, -0.1835,  0.0321, -0.0723],
         ...,
         [ 0.2651,  0.4796,  0.1839, -0.3559],
         [-0.0061,  0.1127, -0.3787,  0.0898],
         [ 0.2883,  0.0225, -0.0193,  0.3132]],

        [[ 0.4446,  0.0156, -0.0322, -0.4317],
         [ 0.2660,  0.1037,  0.3411, -0.0775],
         [ 0.1862, -0.2166,  0.0162, -0.1265],
         ...,
         [ 0.0803, -0.4098, -0.0434,  0.0638],
         [ 0.1561,  0.1069, -0.0660, -0.1642],
         [-0.3095, -0.0545, -0.0072,  0.1209]],

        [[ 0.1591, -0.0146,  0.2622, -0.3998],
         [ 0.0550,  0.0457,  0.0894,  0.0190],
         [ 0.0474, -0.3950, -0.0228,  0.0456],
         ...,
         [ 0.1967,  0.1822, -0.1676, -0.1753],
         [-0.1149, -0.2869, -0.0474,  0.1018],
         [ 0.2407, -0.1904, -0.1728, -0.3852]],

        ...,

        [[ 0.3046,  0.1815,  0.2479,  0.0322],
         [-0.1068, -0.2236, -0.0100,  0.3946],
         [ 0.0211, -0.3202,  0.0407,  0.2848],
         ...,
         [ 0.4063, -0.3145, -0.2237, -0.3737],
         [ 0.1241,  0.1074,  0.0900,  0.0140],
         [ 0.3219, -0.1671,  0.2117, -0.1230]],

        [[-0.1774,  0.0259, -0.1448, -0.0789],
         [-0.2578, -0.4511, -0.1408, -0.0827],
         [ 0.3229, -0.1329, -0.1044, -0.0844],
         ...,
         [ 0.3573,  0.1332,  0.1773,  0.4689],
         [ 0.1647,  0.1335, -0.0197,  0.4468],
         [-0.2476,  0.0273, -0.0232, -0.1125]],

        [[-0.0117, -0.1483, -0.2510, -0.0874],
         [-0.0816, -0.2381,  0.3964, -0.3313],
         [-0.2797, -0.0986,  0.2965, -0.3605],
         ...,
         [ 0.3624, -0.3253,  0.4424,  0.2233],
         [ 0.3890,  0.3852,  0.2441, -0.2188],
         [ 0.0149, -0.1432,  0.1245, -0.1520]]])

2025-07-26 02:51:11.416148 GPU 5 102442 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([107374183, 8, 4]) != torch.Size([107374183, 7, 4]).
ACTUAL: (shape=torch.Size([107374183, 8, 4]), dtype=torch.float32)
tensor([[[ 0.2049,  0.3727,  0.4834, -0.0459],
         [ 0.0643,  0.2195, -0.1860,  0.3153],
         [ 0.1992,  0.1138, -0.2111,  0.0201],
         ...,
         [ 0.4215, -0.0152, -0.2342,  0.1435],
         [-0.1323, -0.1296,  0.1858, -0.1474],
         [ 0.3218, -0.2313, -0.1944,  0.0624]],

        [[ 0.0994, -0.4926, -0.4462, -0.1395],
         [-0.1200, -0.0378, -0.3845,  0.2223],
         [ 0.1044, -0.1000, -0.1927, -0.1967],
         ...,
         [-0.0522, -0.0055,  0.2841,  0.2925],
         [-0.0164,  0.3087,  0.1168, -0.1486],
         [-0.3477,  0.1165,  0.3557,  0.4763]],

        [[ 0.0921, -0.0053,  0.3763,  0.1861],
         [-0.1960, -0.0934,  0.1106, -0.1683],
         [ 0.3391, -0.0538, -0.0277, -0.0545],
         ...,
         [ 0.3034, -0.1153,  0.2311,  0.3020],
         [-0.1730, -0.2308, -0.2329, -0.1611],
         [-0.4069,  0.2028,  0.4313, -0.4294]],

        ...,

        [[ 0.0971, -0.3846, -0.0659, -0.1160],
         [-0.1898,  0.1817, -0.2220, -0.1410],
         [-0.0403,  0.3020, -0.0527, -0.1779],
         ...,
         [ 0.0033,  0.2973, -0.1059, -0.0327],
         [ 0.1012,  0.3819, -0.2970,  0.1210],
         [-0.3905,  0.4380, -0.2225, -0.1949]],

        [[-0.1160,  0.3048, -0.4472,  0.0042],
         [ 0.0887,  0.0045, -0.0920, -0.0464],
         [ 0.1330, -0.1000, -0.3240, -0.2423],
         ...,
         [ 0.1141,  0.0912,  0.1373, -0.4079],
         [-0.0247, -0.2163,  0.1940,  0.0581],
         [ 0.2104, -0.3840,  0.4159, -0.0386]],

        [[-0.0756, -0.2808, -0.3985, -0.3075],
         [-0.1253,  0.3097, -0.2018,  0.1301],
         [ 0.0647, -0.0527, -0.2147, -0.3517],
         ...,
         [-0.2225, -0.2633, -0.1526, -0.1630],
         [-0.0617, -0.0128, -0.2246,  0.2340],
         [ 0.2642, -0.1724,  0.4572, -0.3647]]])
DESIRED: (shape=torch.Size([107374183, 7, 4]), dtype=torch.float32)
tensor([[[ 0.2049,  0.3727,  0.4834, -0.0459],
         [ 0.0475,  0.2005, -0.1766,  0.2019],
         [ 0.3423,  0.0820, -0.2534,  0.0821],
         ...,
         [ 0.4607, -0.1190, -0.4654,  0.0979],
         [ 0.0181, -0.0538,  0.1523, -0.0419],
         [ 0.3218, -0.2313, -0.1944,  0.0624]],

        [[ 0.0994, -0.4926, -0.4462, -0.1395],
         [ 0.0404,  0.0659, -0.3428,  0.1187],
         [-0.1282, -0.4058, -0.1532, -0.2519],
         ...,
         [ 0.1512, -0.0045,  0.2579,  0.4937],
         [-0.1085,  0.2140,  0.1775, -0.0968],
         [-0.3477,  0.1165,  0.3557,  0.4763]],

        [[ 0.0921, -0.0053,  0.3763,  0.1861],
         [-0.0257,  0.0525,  0.1417, -0.1208],
         [ 0.3148, -0.3890, -0.2093, -0.0880],
         ...,
         [ 0.2638, -0.3053,  0.1005,  0.3990],
         [-0.0142, -0.1201, -0.0414, -0.0609],
         [-0.4069,  0.2028,  0.4313, -0.4294]],

        ...,

        [[ 0.0971, -0.3846, -0.0659, -0.1160],
         [-0.0023,  0.2170, -0.0985, -0.0277],
         [-0.3968,  0.3039, -0.2346, -0.4889],
         ...,
         [-0.2454,  0.2670, -0.2306,  0.2146],
         [ 0.1712,  0.3686, -0.1898, -0.0240],
         [-0.3905,  0.4380, -0.2225, -0.1949]],

        [[-0.1160,  0.3048, -0.4472,  0.0042],
         [-0.0102,  0.1223, -0.1553, -0.0938],
         [ 0.4134, -0.4728, -0.3396, -0.2706],
         ...,
         [ 0.2071, -0.1527,  0.2152, -0.3597],
         [-0.0202, -0.0265,  0.1458, -0.1009],
         [ 0.2104, -0.3840,  0.4159, -0.0386]],

        [[-0.0756, -0.2808, -0.3985, -0.3075],
         [-0.1154,  0.2690, -0.2487,  0.0385],
         [ 0.1823, -0.2228, -0.1071, -0.4841],
         ...,
         [-0.4634, -0.3499,  0.0998, -0.1552],
         [-0.0136, -0.0533, -0.3040,  0.1118],
         [ 0.2642, -0.1724,  0.4572, -0.3647]]])

2025-07-26 02:54:36.029565 GPU 7 102603 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([107374183, 8, 4]) != torch.Size([107374183, 7, 4]).
ACTUAL: (shape=torch.Size([107374183, 8, 4]), dtype=torch.float32)
tensor([[[ 0.1950, -0.2344,  0.0269, -0.0186],
         [-0.0706, -0.1494,  0.1851,  0.1383],
         [ 0.2252,  0.1054,  0.0894,  0.1246],
         ...,
         [-0.3449, -0.2931,  0.3999, -0.3313],
         [ 0.1350, -0.3728, -0.0011,  0.2331],
         [-0.0782, -0.1451, -0.1188, -0.2912]],

        [[ 0.3625, -0.3965, -0.3299,  0.4316],
         [ 0.2842,  0.1217, -0.2351, -0.3477],
         [ 0.0691,  0.0549,  0.0027, -0.1048],
         ...,
         [-0.0678, -0.2330,  0.1279, -0.2979],
         [ 0.2767,  0.0355, -0.2640, -0.1281],
         [ 0.4026,  0.0740,  0.2679, -0.0207]],

        [[-0.0676,  0.2146,  0.3151,  0.3504],
         [ 0.2336,  0.2391, -0.2128, -0.1808],
         [ 0.0202,  0.1341, -0.0218,  0.2416],
         ...,
         [ 0.2112, -0.1915,  0.1651,  0.0960],
         [-0.0836, -0.0320, -0.1218,  0.2409],
         [-0.0815, -0.2964,  0.1331,  0.4679]],

        ...,

        [[ 0.0098, -0.0252, -0.2940,  0.3848],
         [ 0.0619,  0.2564,  0.2631, -0.1180],
         [ 0.0928,  0.1617,  0.2946, -0.1131],
         ...,
         [-0.0068, -0.2118,  0.1308,  0.1171],
         [ 0.2612,  0.0401, -0.2654, -0.0674],
         [-0.1549, -0.1083,  0.0069,  0.1419]],

        [[ 0.4109, -0.3165, -0.4297, -0.4802],
         [-0.1081, -0.4183,  0.4048, -0.1991],
         [-0.0633, -0.1383,  0.3545, -0.0149],
         ...,
         [ 0.0814,  0.4490,  0.0343,  0.2876],
         [-0.2627, -0.0853, -0.3580, -0.2898],
         [-0.4214,  0.4532,  0.2143,  0.4077]],

        [[ 0.4435,  0.3041,  0.4728, -0.3419],
         [ 0.0086, -0.1989,  0.2125, -0.3406],
         [-0.1985,  0.4864,  0.0707, -0.1576],
         ...,
         [-0.2760, -0.3125, -0.4522,  0.2579],
         [-0.2935, -0.3627, -0.1081,  0.2051],
         [ 0.4028, -0.2138, -0.0767, -0.2431]]])
DESIRED: (shape=torch.Size([107374183, 7, 4]), dtype=torch.float32)
tensor([[[ 0.1950, -0.2344,  0.0269, -0.0186],
         [-0.0217, -0.0412,  0.1411,  0.1450],
         [ 0.3249,  0.0259,  0.1277,  0.0976],
         ...,
         [-0.3610, -0.2719,  0.3413, -0.4035],
         [-0.0025, -0.3574,  0.1426,  0.0927],
         [-0.0782, -0.1451, -0.1188, -0.2912]],

        [[ 0.3625, -0.3965, -0.3299,  0.4316],
         [ 0.2543,  0.1630, -0.1742, -0.2996],
         [-0.0173, -0.0986,  0.0287, -0.0429],
         ...,
         [-0.3503, -0.4193,  0.1750, -0.3109],
         [ 0.2863,  0.0295, -0.1652, -0.1738],
         [ 0.4026,  0.0740,  0.2679, -0.0207]],

        [[-0.0676,  0.2146,  0.3151,  0.3504],
         [ 0.2450,  0.1558, -0.2983, -0.0871],
         [-0.1684,  0.2636,  0.3350,  0.3242],
         ...,
         [ 0.4027, -0.1033,  0.1534, -0.0879],
         [-0.0718, -0.1151, -0.0310,  0.2709],
         [-0.0815, -0.2964,  0.1331,  0.4679]],

        ...,

        [[ 0.0098, -0.0252, -0.2940,  0.3848],
         [ 0.0354,  0.3100,  0.1927, -0.1783],
         [ 0.1821, -0.0433,  0.4940,  0.0413],
         ...,
         [-0.2232, -0.3053,  0.4780,  0.2932],
         [ 0.2673,  0.0019, -0.2854, -0.0825],
         [-0.1549, -0.1083,  0.0069,  0.1419]],

        [[ 0.4109, -0.3165, -0.4297, -0.4802],
         [-0.0941, -0.3743,  0.3800, -0.2065],
         [-0.0646, -0.0384,  0.3789,  0.1418],
         ...,
         [ 0.0008,  0.4624,  0.4040,  0.4397],
         [-0.1272,  0.0697, -0.3882, -0.1774],
         [-0.4214,  0.4532,  0.2143,  0.4077]],

        [[ 0.4435,  0.3041,  0.4728, -0.3419],
         [-0.1145,  0.0104,  0.2157, -0.2768],
         [-0.0461,  0.4771, -0.0437, -0.1798],
         ...,
         [-0.4273, -0.2947, -0.4452,  0.2463],
         [-0.2277, -0.3548, -0.2141,  0.2255],
         [ 0.4028, -0.2138, -0.0767, -0.2431]]])

2025-07-26 03:11:20.398377 GPU 7 102603 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753470717 (unix time) try "date -d @1753470717" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x190cb) received by PID 102603 (TID 0x7f8ba9d04740) from PID 102603 ***]


2025-07-26 03:11:22.148613 GPU 1 102930 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753470720 (unix time) try "date -d @1753470720" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19212) received by PID 102930 (TID 0x7f191dcf3740) from PID 102930 ***]


2025-07-26 03:12:02.869117 GPU 7 104280 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:12:05.591639 GPU 2 103114 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:12:06.815441 GPU 1 104438 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:12:08.453511 GPU 6 102276 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:12:29.750451 GPU 2 104598 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:12:35.635745 GPU 6 104756 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:13:35.617691 GPU 3 103960 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:13:47.807092 GPU 5 102442 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:13:52.339365 GPU 1 105091 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:14:00.242052 GPU 3 105250 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:14:03.491590 GPU 2 105409 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:14:11.922065 GPU 5 105567 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:15:24.524073 GPU 4 104119 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:15:31.359237 GPU 3 106051 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 03:15:37.626738 GPU 2 106211 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471052 (unix time) try "date -d @1753471052" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19ee3) received by PID 106211 (TID 0x7f77cd80a740) from PID 106211 ***]


2025-07-26 03:15:51.050153 GPU 4 106369 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471055 (unix time) try "date -d @1753471055" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19f81) received by PID 106369 (TID 0x7fc1bc5c7740) from PID 106369 ***]


2025-07-26 03:15:52.847751 GPU 5 106458 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471066 (unix time) try "date -d @1753471066" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19fda) received by PID 106458 (TID 0x7fbdcc0b3740) from PID 106458 ***]


2025-07-26 03:16:43.327975 GPU 7 104931 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471036 (unix time) try "date -d @1753471036" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x199e3) received by PID 104931 (TID 0x7f3c1337b740) from PID 104931 ***]


2025-07-26 03:17:05.308785 GPU 3 106708 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471122 (unix time) try "date -d @1753471122" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a0d4) received by PID 106708 (TID 0x7f2e4791c740) from PID 106708 ***]


2025-07-26 03:17:21.349296 GPU 7 106869 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471137 (unix time) try "date -d @1753471137" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a175) received by PID 106869 (TID 0x7fae36365740) from PID 106869 ***]


2025-07-26 03:17:38.387742 GPU 2 107042 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 41846845 / 2281701400 (1.8%)
Greatest absolute difference: 1.5242247581481934 at index (4382256, 1, 5, 9) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 0, 5) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([11408507, 2, 10, 10]), dtype=torch.float32)
tensor([[[[ 0.2753,  0.4166,  0.1150,  ...,  0.8961,  0.6602,  0.5445],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.1105, -0.7035, -0.5876,  ...,  0.2098,  0.0057,  0.4218],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[-0.5560, -0.0528,  0.5327,  ...,  0.4325,  0.5081, -0.0480],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.0158,  0.0145,  0.0522,  ...,  0.1407,  0.4282, -0.3063],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[-0.5354, -0.0933, -0.4186,  ..., -0.6626, -0.3147,  0.2682],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.2707, -0.2873,  0.0859,  ..., -0.5256, -0.4336, -0.5650],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([11408507, 2, 10, 10]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2985,  0.5224, -0.0454,  ...,  0.7722,  0.7642,  0.3120],
          ...,
          [-0.3337, -0.1096,  0.4777,  ..., -0.0173,  0.1080,  0.0633],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.3423, -0.6429, -0.6215,  ...,  0.2013, -0.0341,  0.4087],
          ...,
          [ 0.1826,  0.5495, -0.0483,  ...,  0.3823, -0.7038, -0.1081],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.6706,  0.1747,  0.6856,  ...,  0.4604,  0.5136, -0.1970],
          ...,
          [ 0.3448,  0.1752,  0.4914,  ...,  0.3609,  0.8256, -0.2753],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1536,  0.3220, -0.1513,  ...,  0.2358,  0.4736, -0.4374],
          ...,
          [-0.2553,  0.0502,  0.0533,  ...,  0.5090,  0.0159,  0.0197],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.6315, -0.0121, -0.5411,  ..., -0.6990,  0.0206,  0.1497],
          ...,
          [ 0.0661,  0.4514,  0.1798,  ...,  0.0197,  0.3686, -0.1829],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2599, -0.3348,  0.1261,  ..., -0.5485, -0.3388, -0.5071],
          ...,
          [ 0.5804, -0.3397,  0.5996,  ..., -0.9755,  0.1791, -0.4764],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0781,  0.1272, -0.2446,  ...,  0.4967,  0.0665, -0.3930],
          ...,
          [ 0.2366,  0.3412, -0.2202,  ...,  0.6292,  0.0674, -0.1739],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.1673, -0.3006, -0.5787,  ..., -0.0662, -0.2335, -0.2745],
          ...,
          [ 0.5416, -0.1772,  0.1234,  ..., -0.7924, -0.3149,  0.2507],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.4105,  0.0694, -0.4906,  ...,  0.0690,  0.4553, -0.3285],
          ...,
          [-0.4952,  0.6103, -0.0966,  ..., -0.1015, -0.3493,  0.0166],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2746, -0.5809,  0.2529,  ..., -0.3932, -0.1959, -0.0636],
          ...,
          [ 0.4940,  0.1216, -0.3405,  ..., -0.4343, -0.7342, -0.7809],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2846,  0.3204,  0.0937,  ..., -0.1988, -0.3474, -0.2661],
          ...,
          [ 0.6305, -0.7370, -0.8554,  ...,  0.0116,  0.7540, -0.4372],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2065,  0.1140,  0.3534,  ..., -0.0352,  0.3375,  0.0226],
          ...,
          [-0.0912,  0.1919,  0.0984,  ..., -0.5250, -0.2085, -0.2879],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])

2025-07-26 03:17:50.907475 GPU 5 107365 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471188 (unix time) try "date -d @1753471188" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a365) received by PID 107365 (TID 0x7f5fa1774740) from PID 107365 ***]


2025-07-26 03:18:25.669934 GPU 6 105726 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471150 (unix time) try "date -d @1753471150" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19cfe) received by PID 105726 (TID 0x7fa5299b2740) from PID 105726 ***]


2025-07-26 03:19:02.379583 GPU 7 107709 test begin: paddle.nn.functional.interpolate(Tensor([16, 160, 4, 222823],"float32"), size=list[8,6,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471235 (unix time) try "date -d @1753471235" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a4bd) received by PID 107709 (TID 0x7fd067c42740) from PID 107709 ***]


2025-07-26 03:19:15.931629 GPU 6 107870 test begin: paddle.nn.functional.interpolate(Tensor([16, 160, 8, 111412],"float32"), size=list[16,12,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471249 (unix time) try "date -d @1753471249" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a55e) received by PID 107870 (TID 0x7fa253fc4740) from PID 107870 ***]


2025-07-26 03:20:10.544933 GPU 2 107042 test begin: paddle.nn.functional.interpolate(Tensor([16, 40, 16, 222823],"float32"), size=list[32,24,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471225 (unix time) try "date -d @1753471225" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a222) received by PID 107042 (TID 0x7f95d4ffb740) from PID 107042 ***]


2025-07-26 03:20:39.056439 GPU 3 107542 test begin: paddle.nn.functional.interpolate(Tensor([16, 40, 32, 111412],"float32"), size=list[64,48,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471253 (unix time) try "date -d @1753471253" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a416) received by PID 107542 (TID 0x7f8c1d534740) from PID 107542 ***]


2025-07-26 03:20:42.221354 GPU 1 105890 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 10, 2147484],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471370 (unix time) try "date -d @1753471370" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19da2) received by PID 105890 (TID 0x7f64cc52e740) from PID 105890 ***]


2025-07-26 03:20:54.668551 GPU 6 108551 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 10, 2147484],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471393 (unix time) try "date -d @1753471393" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a807) received by PID 108551 (TID 0x7f1503171740) from PID 108551 ***]


2025-07-26 03:25:10.032754 GPU 7 108385 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 5368710, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471520 (unix time) try "date -d @1753471520" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a761) received by PID 108385 (TID 0x7f7a411d0740) from PID 108385 ***]


2025-07-26 03:25:25.587769 GPU 7 109225 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 5368710, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471620 (unix time) try "date -d @1753471620" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1aaa9) received by PID 109225 (TID 0x7f1306e5c740) from PID 109225 ***]


2025-07-26 03:27:04.768583 GPU 7 109385 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 6, 64424512, 2]) != torch.Size([2, 6, 64424509, 2]).
ACTUAL: (shape=torch.Size([2, 6, 64424512, 2]), dtype=torch.float16)
tensor([[[[ 0.0837,  0.0194],
          [ 0.0969,  0.1926],
          [ 0.3123, -0.0766],
          ...,
          [ 0.1813, -0.1653],
          [-0.0584, -0.2252],
          [-0.0584, -0.2252]],

         [[ 0.0457, -0.0778],
          [-0.0782,  0.4131],
          [-0.0699, -0.0030],
          ...,
          [-0.1159,  0.4834],
          [ 0.3875,  0.2086],
          [ 0.3875,  0.2086]],

         [[-0.0901,  0.2067],
          [ 0.3376,  0.2319],
          [ 0.0127, -0.4333],
          ...,
          [ 0.0444,  0.1189],
          [-0.3792, -0.0594],
          [-0.3792, -0.0594]],

         [[ 0.1608, -0.1251],
          [-0.2129, -0.4133],
          [-0.4265,  0.2434],
          ...,
          [ 0.0670,  0.0641],
          [ 0.0528, -0.2037],
          [ 0.0528, -0.2037]],

         [[-0.3254,  0.2522],
          [-0.1450,  0.2991],
          [ 0.2993, -0.0756],
          ...,
          [-0.2230, -0.1674],
          [ 0.3098,  0.4202],
          [ 0.3098,  0.4202]],

         [[ 0.2211, -0.0742],
          [-0.2812,  0.3911],
          [ 0.1920, -0.2754],
          ...,
          [-0.0719,  0.1271],
          [ 0.2256, -0.0757],
          [ 0.2256, -0.0757]]],


        [[[ 0.1469,  0.0591],
          [ 0.0802,  0.1663],
          [-0.1479,  0.3494],
          ...,
          [-0.1223, -0.3550],
          [-0.1288, -0.4675],
          [-0.1288, -0.4675]],

         [[ 0.1917,  0.1190],
          [ 0.2201, -0.2986],
          [ 0.5088,  0.0962],
          ...,
          [-0.4534,  0.3762],
          [-0.1636, -0.0724],
          [-0.1636, -0.0724]],

         [[ 0.3975,  0.0944],
          [-0.2231,  0.2637],
          [ 0.2222,  0.2886],
          ...,
          [-0.1058,  0.0406],
          [-0.3760, -0.0533],
          [-0.3760, -0.0533]],

         [[-0.0179, -0.1080],
          [-0.0085,  0.4783],
          [-0.0352, -0.2373],
          ...,
          [-0.1492, -0.0262],
          [ 0.2443,  0.2747],
          [ 0.2443,  0.2747]],

         [[-0.2186,  0.1819],
          [ 0.3359,  0.1069],
          [-0.2791,  0.3750],
          ...,
          [-0.1054,  0.3052],
          [-0.0183, -0.3218],
          [-0.0183, -0.3218]],

         [[-0.0653,  0.1821],
          [-0.1220, -0.1675],
          [ 0.2722,  0.1633],
          ...,
          [-0.1277, -0.1653],
          [ 0.3662, -0.2622],
          [ 0.3662, -0.2622]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 6, 64424509, 2]), dtype=torch.float16)
tensor([[[[ 0.0837,  0.0194],
          [ 0.0969,  0.1926],
          [ 0.3125, -0.0765],
          ...,
          [-0.4490,  0.1250],
          [ 0.1812, -0.1653],
          [ 0.1812, -0.1653]],

         [[ 0.0457, -0.0778],
          [-0.0782,  0.4131],
          [-0.0701, -0.0030],
          ...,
          [-0.1423, -0.4453],
          [-0.1159,  0.4834],
          [-0.1159,  0.4834]],

         [[-0.0900,  0.2068],
          [ 0.3376,  0.2318],
          [ 0.0128, -0.4336],
          ...,
          [ 0.2827,  0.2571],
          [ 0.0445,  0.1189],
          [ 0.0445,  0.1189]],

         [[ 0.1608, -0.1251],
          [-0.2128, -0.4133],
          [-0.4263,  0.2437],
          ...,
          [ 0.4155,  0.1816],
          [ 0.0670,  0.0641],
          [ 0.0670,  0.0641]],

         [[-0.3254,  0.2522],
          [-0.1450,  0.2991],
          [ 0.2993, -0.0755],
          ...,
          [-0.3796,  0.3562],
          [-0.2230, -0.1674],
          [-0.2230, -0.1674]],

         [[ 0.2211, -0.0742],
          [-0.2812,  0.3911],
          [ 0.1920, -0.2754],
          ...,
          [ 0.2605,  0.0885],
          [-0.0720,  0.1273],
          [-0.0720,  0.1273]]],


        [[[ 0.1469,  0.0592],
          [ 0.0801,  0.1663],
          [-0.1479,  0.3494],
          ...,
          [-0.4590, -0.1559],
          [-0.1223, -0.3550],
          [-0.1223, -0.3550]],

         [[ 0.1917,  0.1190],
          [ 0.2201, -0.2986],
          [ 0.5088,  0.0962],
          ...,
          [-0.3086, -0.3425],
          [-0.4534,  0.3762],
          [-0.4534,  0.3762]],

         [[ 0.3975,  0.0944],
          [-0.2231,  0.2637],
          [ 0.2223,  0.2886],
          ...,
          [ 0.2808,  0.1665],
          [-0.1058,  0.0406],
          [-0.1058,  0.0406]],

         [[-0.0179, -0.1080],
          [-0.0085,  0.4783],
          [-0.0352, -0.2374],
          ...,
          [-0.5728, -0.1285],
          [-0.1492, -0.0263],
          [-0.1492, -0.0263]],

         [[-0.2186,  0.1818],
          [ 0.3359,  0.1069],
          [-0.2791,  0.3750],
          ...,
          [-0.0651,  0.4741],
          [-0.1054,  0.3052],
          [-0.1054,  0.3052]],

         [[-0.0653,  0.1821],
          [-0.1219, -0.1675],
          [ 0.2722,  0.1635],
          ...,
          [-0.0286, -0.1232],
          [-0.1276, -0.1653],
          [-0.1276, -0.1653]]]], dtype=torch.float16)

2025-07-26 03:28:56.223374 GPU 7 109385 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 6, 64424512, 2]) != torch.Size([2, 6, 64424509, 2]).
ACTUAL: (shape=torch.Size([2, 6, 64424512, 2]), dtype=torch.float16)
tensor([[[[ 0.2257,  0.1653],
          [-0.2708,  0.0600],
          [ 0.2189, -0.3479],
          ...,
          [ 0.3215, -0.1455],
          [-0.2932, -0.3440],
          [-0.2932, -0.3440]],

         [[ 0.2194,  0.2017],
          [-0.0817,  0.1595],
          [ 0.3096, -0.0670],
          ...,
          [-0.1313,  0.3955],
          [ 0.4622,  0.1896],
          [ 0.4622,  0.1896]],

         [[-0.2260,  0.0502],
          [ 0.3142,  0.3091],
          [-0.0710, -0.0838],
          ...,
          [ 0.0323,  0.1368],
          [-0.3630, -0.0256],
          [-0.3630, -0.0256]],

         [[ 0.1637, -0.0898],
          [-0.1388, -0.3689],
          [-0.2812, -0.0424],
          ...,
          [ 0.0680,  0.0281],
          [ 0.0926, -0.1355],
          [ 0.0926, -0.1355]],

         [[-0.2490,  0.1324],
          [-0.2472,  0.4583],
          [ 0.1761, -0.1897],
          ...,
          [-0.1781, -0.2235],
          [ 0.2402,  0.4299],
          [ 0.2402,  0.4299]],

         [[ 0.3186, -0.1040],
          [-0.2712,  0.3447],
          [ 0.4939, -0.2250],
          ...,
          [-0.1906,  0.4026],
          [ 0.3525, -0.2910],
          [ 0.3525, -0.2910]]],


        [[[ 0.1516, -0.4080],
          [ 0.4709,  0.3938],
          [-0.1203,  0.2903],
          ...,
          [ 0.0331, -0.3064],
          [-0.4619, -0.4211],
          [-0.4619, -0.4211]],

         [[ 0.1647,  0.4429],
          [ 0.0487, -0.4197],
          [ 0.4670,  0.1141],
          ...,
          [-0.5210,  0.2871],
          [-0.0385, -0.1582],
          [-0.0385, -0.1582]],

         [[ 0.4009,  0.0267],
          [-0.0680,  0.3098],
          [ 0.0497,  0.0138],
          ...,
          [-0.0710,  0.0258],
          [-0.3445, -0.0443],
          [-0.3445, -0.0443]],

         [[ 0.1081, -0.0110],
          [-0.1104,  0.2125],
          [ 0.0646,  0.0336],
          ...,
          [-0.1853, -0.0924],
          [ 0.2080,  0.2939],
          [ 0.2080,  0.2939]],

         [[-0.1741,  0.4026],
          [ 0.1230, -0.0814],
          [-0.1483,  0.4771],
          ...,
          [-0.1370,  0.3257],
          [ 0.0100, -0.3867],
          [ 0.0100, -0.3867]],

         [[-0.1671,  0.1532],
          [ 0.0439,  0.0155],
          [ 0.2319, -0.2197],
          ...,
          [ 0.0247, -0.1979],
          [ 0.4644, -0.2283],
          [ 0.4644, -0.2283]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 6, 64424509, 2]), dtype=torch.float16)
tensor([[[[ 0.2257,  0.1653],
          [-0.2708,  0.0601],
          [ 0.2189, -0.3479],
          ...,
          [ 0.3215, -0.1455],
          [-0.2932, -0.3440],
          [-0.2932, -0.3440]],

         [[ 0.2194,  0.2017],
          [-0.0818,  0.1597],
          [ 0.3096, -0.0670],
          ...,
          [-0.1313,  0.3955],
          [ 0.4619,  0.1896],
          [ 0.4619,  0.1896]],

         [[-0.2261,  0.0501],
          [ 0.3142,  0.3091],
          [-0.0711, -0.0839],
          ...,
          [ 0.0323,  0.1368],
          [-0.3630, -0.0255],
          [-0.3630, -0.0255]],

         [[ 0.1636, -0.0897],
          [-0.1388, -0.3691],
          [-0.2810, -0.0424],
          ...,
          [ 0.0680,  0.0280],
          [ 0.0927, -0.1354],
          [ 0.0927, -0.1354]],

         [[-0.2490,  0.1324],
          [-0.2472,  0.4583],
          [ 0.1761, -0.1897],
          ...,
          [-0.1781, -0.2235],
          [ 0.2401,  0.4299],
          [ 0.2401,  0.4299]],

         [[ 0.3186, -0.1040],
          [-0.2712,  0.3450],
          [ 0.4939, -0.2250],
          ...,
          [-0.1906,  0.4026],
          [ 0.3525, -0.2910],
          [ 0.3525, -0.2910]]],


        [[[ 0.1516, -0.4080],
          [ 0.4709,  0.3938],
          [-0.1203,  0.2905],
          ...,
          [ 0.0331, -0.3064],
          [-0.4619, -0.4211],
          [-0.4619, -0.4211]],

         [[ 0.1648,  0.4429],
          [ 0.0489, -0.4197],
          [ 0.4673,  0.1141],
          ...,
          [-0.5210,  0.2871],
          [-0.0386, -0.1581],
          [-0.0386, -0.1581]],

         [[ 0.4009,  0.0267],
          [-0.0681,  0.3098],
          [ 0.0497,  0.0139],
          ...,
          [-0.0710,  0.0258],
          [-0.3445, -0.0443],
          [-0.3445, -0.0443]],

         [[ 0.1081, -0.0111],
          [-0.1103,  0.2128],
          [ 0.0646,  0.0336],
          ...,
          [-0.1853, -0.0925],
          [ 0.2080,  0.2942],
          [ 0.2080,  0.2942]],

         [[-0.1741,  0.4026],
          [ 0.1231, -0.0813],
          [-0.1483,  0.4771],
          ...,
          [-0.1371,  0.3257],
          [ 0.0100, -0.3867],
          [ 0.0100, -0.3867]],

         [[-0.1671,  0.1532],
          [ 0.0439,  0.0154],
          [ 0.2319, -0.2196],
          ...,
          [ 0.0247, -0.1979],
          [ 0.4644, -0.2283],
          [ 0.4644, -0.2283]]]], dtype=torch.float16)

2025-07-26 03:29:16.633637 GPU 7 109385 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 6, 64424512, 2]) != torch.Size([2, 6, 64424509, 2]).
ACTUAL: (shape=torch.Size([2, 6, 64424512, 2]), dtype=torch.float16)
tensor([[[[ 0.2257,  0.1653],
          [-0.2162,  0.0102],
          [ 0.1810, -0.2622],
          ...,
          [ 0.3215, -0.1455],
          [-0.2932, -0.3440],
          [-0.2932, -0.3440]],

         [[ 0.1608,  0.1400],
          [ 0.0679,  0.1464],
          [ 0.1919, -0.0019],
          ...,
          [-0.1183,  0.2874],
          [ 0.4060,  0.1589],
          [ 0.4060,  0.1589]],

         [[-0.2546, -0.1632],
          [ 0.0848,  0.2603],
          [-0.1825, -0.0532],
          ...,
          [-0.0214,  0.2395],
          [-0.2095,  0.0782],
          [-0.2095,  0.0782]],

         [[ 0.4607, -0.1888],
          [-0.1863, -0.2344],
          [-0.4531, -0.0828],
          ...,
          [ 0.0698,  0.1998],
          [-0.1509, -0.4678],
          [-0.1509, -0.4678]],

         [[-0.3291,  0.1582],
          [-0.1240,  0.1410],
          [ 0.1482, -0.1210],
          ...,
          [-0.1400, -0.1998],
          [ 0.3354,  0.4297],
          [ 0.3354,  0.4297]],

         [[ 0.0644,  0.0343],
          [-0.1074,  0.2197],
          [ 0.1995, -0.0055],
          ...,
          [ 0.0197, -0.1500],
          [ 0.1199,  0.1675],
          [ 0.1199,  0.1675]]],


        [[[ 0.1516, -0.4080],
          [ 0.4041,  0.3391],
          [-0.0714,  0.2756],
          ...,
          [ 0.0331, -0.3064],
          [-0.4619, -0.4211],
          [-0.4619, -0.4211]],

         [[ 0.1248,  0.3855],
          [ 0.0235, -0.2131],
          [ 0.2822,  0.0576],
          ...,
          [-0.4553,  0.1390],
          [ 0.0518, -0.2130],
          [ 0.0518, -0.2130]],

         [[ 0.4146,  0.0405],
          [-0.0190,  0.1979],
          [-0.0013, -0.0036],
          ...,
          [ 0.0040,  0.0327],
          [-0.1699, -0.0014],
          [-0.1699, -0.0014]],

         [[ 0.1674,  0.3511],
          [-0.1323,  0.2496],
          [ 0.0930, -0.0158],
          ...,
          [-0.0235,  0.2316],
          [ 0.3079,  0.1716],
          [ 0.3079,  0.1716]],

         [[-0.1552,  0.0679],
          [ 0.1414,  0.0492],
          [-0.1343,  0.3608],
          ...,
          [-0.2152,  0.0404],
          [-0.0560, -0.1125],
          [-0.0560, -0.1125]],

         [[ 0.0804,  0.1873],
          [-0.2620, -0.0823],
          [ 0.2810,  0.1182],
          ...,
          [-0.2625, -0.0890],
          [ 0.2396, -0.2988],
          [ 0.2396, -0.2988]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 6, 64424509, 2]), dtype=torch.float16)
tensor([[[[ 0.0833,  0.0276],
          [ 0.0782,  0.2046],
          [ 0.2451, -0.0465],
          ...,
          [-0.4324,  0.0991],
          [ 0.1733, -0.1318],
          [ 0.1733, -0.1318]],

         [[ 0.0459, -0.0414],
          [-0.0782,  0.4131],
          [-0.0607,  0.0505],
          ...,
          [-0.1423, -0.4453],
          [-0.1159,  0.4834],
          [-0.1159,  0.4834]],

         [[-0.0363,  0.1521],
          [ 0.2507,  0.1884],
          [-0.0505, -0.2571],
          ...,
          [ 0.2776,  0.2296],
          [ 0.0365,  0.1483],
          [ 0.0365,  0.1483]],

         [[ 0.1107, -0.0743],
          [-0.1489, -0.3271],
          [-0.3196,  0.1155],
          ...,
          [ 0.3564,  0.1906],
          [ 0.0551,  0.0450],
          [ 0.0551,  0.0450]],

         [[-0.3147,  0.2489],
          [-0.1450,  0.2991],
          [ 0.2273, -0.0379],
          ...,
          [-0.3796,  0.3562],
          [-0.2230, -0.1674],
          [-0.2230, -0.1674]],

         [[ 0.1714, -0.0347],
          [-0.2739,  0.3865],
          [ 0.1737, -0.2148],
          ...,
          [ 0.2305,  0.0944],
          [-0.0854,  0.1263],
          [-0.0854,  0.1263]]],


        [[[ 0.1469,  0.0485],
          [ 0.1014,  0.1478],
          [-0.0847,  0.2832],
          ...,
          [-0.4512, -0.1813],
          [-0.1311, -0.3162],
          [-0.1311, -0.3162]],

         [[ 0.1968,  0.1115],
          [ 0.2201, -0.2986],
          [ 0.4658,  0.0906],
          ...,
          [-0.3086, -0.3425],
          [-0.4534,  0.3762],
          [-0.4534,  0.3762]],

         [[ 0.3215,  0.1063],
          [-0.1779,  0.2546],
          [ 0.1829,  0.1995],
          ...,
          [ 0.1777,  0.0974],
          [-0.1091,  0.0729],
          [-0.1091,  0.0729]],

         [[ 0.0114, -0.0512],
          [-0.0130,  0.4446],
          [-0.0300, -0.1259],
          ...,
          [-0.4685, -0.0477],
          [-0.1606, -0.0087],
          [-0.1606, -0.0087]],

         [[-0.1918,  0.1863],
          [ 0.3359,  0.1069],
          [-0.1929,  0.3694],
          ...,
          [-0.0651,  0.4741],
          [-0.1054,  0.3052],
          [-0.1054,  0.3052]],

         [[-0.0740,  0.1665],
          [-0.0901, -0.1541],
          [ 0.2257,  0.1293],
          ...,
          [-0.0415, -0.1021],
          [-0.1189, -0.1434],
          [-0.1189, -0.1434]]]], dtype=torch.float16)

2025-07-26 03:29:34.925779 GPU 7 109385 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 6, 64424512, 2]) != torch.Size([2, 6, 64424509, 2]).
ACTUAL: (shape=torch.Size([2, 6, 64424512, 2]), dtype=torch.float16)
tensor([[[[ 0.2257,  0.1653],
          [-0.2162,  0.0102],
          [ 0.1810, -0.2622],
          ...,
          [ 0.3215, -0.1455],
          [-0.2932, -0.3440],
          [-0.2932, -0.3440]],

         [[ 0.1661,  0.1479],
          [-0.0081,  0.1389],
          [ 0.1976, -0.0092],
          ...,
          [-0.1173,  0.3657],
          [ 0.3987,  0.1788],
          [ 0.3987,  0.1788]],

         [[-0.1431,  0.0276],
          [ 0.1831,  0.2340],
          [-0.0701, -0.0474],
          ...,
          [ 0.0249,  0.1665],
          [-0.2944, -0.0469],
          [-0.2944, -0.0469]],

         [[ 0.1143, -0.0349],
          [-0.0867, -0.2556],
          [-0.2067, -0.0743],
          ...,
          [ 0.0522,  0.0140],
          [ 0.0643, -0.1013],
          [ 0.0643, -0.1013]],

         [[-0.2454,  0.1321],
          [-0.1891,  0.3230],
          [ 0.1326, -0.1045],
          ...,
          [-0.1534, -0.2191],
          [ 0.2485,  0.4155],
          [ 0.2485,  0.4155]],

         [[ 0.3186, -0.1040],
          [-0.1703,  0.2727],
          [ 0.3999, -0.1771],
          ...,
          [-0.1906,  0.4026],
          [ 0.3525, -0.2910],
          [ 0.3525, -0.2910]]],


        [[[ 0.1516, -0.4080],
          [ 0.4041,  0.3391],
          [-0.0714,  0.2756],
          ...,
          [ 0.0331, -0.3064],
          [-0.4619, -0.4211],
          [-0.4619, -0.4211]],

         [[ 0.1813,  0.3862],
          [ 0.0805, -0.2661],
          [ 0.3572,  0.0690],
          ...,
          [-0.4546,  0.2339],
          [-0.0344, -0.1567],
          [-0.0344, -0.1567]],

         [[ 0.3728,  0.0770],
          [-0.0346,  0.2145],
          [ 0.0695,  0.0399],
          ...,
          [-0.0865,  0.0648],
          [-0.2700, -0.0254],
          [-0.2700, -0.0254]],

         [[ 0.1039,  0.0152],
          [-0.0619,  0.1874],
          [ 0.0316,  0.0798],
          ...,
          [-0.1880, -0.0568],
          [ 0.1322,  0.2253],
          [ 0.1322,  0.2253]],

         [[-0.1488,  0.3179],
          [ 0.0684, -0.0016],
          [-0.0754,  0.3997],
          ...,
          [-0.1655,  0.2372],
          [ 0.0108, -0.3242],
          [ 0.0108, -0.3242]],

         [[-0.1671,  0.1532],
          [ 0.0517, -0.0170],
          [ 0.2264, -0.2050],
          ...,
          [ 0.0247, -0.1979],
          [ 0.4644, -0.2283],
          [ 0.4644, -0.2283]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 6, 64424509, 2]), dtype=torch.float16)
tensor([[[[ 0.2257,  0.1653],
          [-0.2162,  0.0102],
          [ 0.1810, -0.2622],
          ...,
          [ 0.3215, -0.1455],
          [ 0.4688,  0.1693],
          [ 0.4688,  0.1693]],

         [[ 0.1661,  0.1479],
          [-0.0081,  0.1389],
          [ 0.1976, -0.0092],
          ...,
          [-0.1173,  0.3657],
          [-0.2615,  0.1054],
          [-0.2615,  0.1054]],

         [[-0.1431,  0.0276],
          [ 0.1831,  0.2340],
          [-0.0701, -0.0474],
          ...,
          [ 0.0249,  0.1665],
          [ 0.1816,  0.1301],
          [ 0.1816,  0.1301]],

         [[ 0.1143, -0.0349],
          [-0.0867, -0.2556],
          [-0.2067, -0.0743],
          ...,
          [ 0.0522,  0.0140],
          [-0.2744,  0.0129],
          [-0.2744,  0.0129]],

         [[-0.2454,  0.1321],
          [-0.1891,  0.3230],
          [ 0.1326, -0.1045],
          ...,
          [-0.1534, -0.2191],
          [ 0.2654, -0.1365],
          [ 0.2654, -0.1365]],

         [[ 0.3186, -0.1040],
          [-0.1703,  0.2727],
          [ 0.3999, -0.1771],
          ...,
          [-0.1906,  0.4026],
          [ 0.4800,  0.4939],
          [ 0.4800,  0.4939]]],


        [[[ 0.1516, -0.4080],
          [ 0.4041,  0.3391],
          [-0.0714,  0.2756],
          ...,
          [ 0.0331, -0.3064],
          [ 0.0710,  0.3167],
          [ 0.0710,  0.3167]],

         [[ 0.1813,  0.3862],
          [ 0.0805, -0.2661],
          [ 0.3572,  0.0690],
          ...,
          [-0.4546,  0.2339],
          [ 0.1768,  0.1835],
          [ 0.1768,  0.1835]],

         [[ 0.3728,  0.0770],
          [-0.0346,  0.2145],
          [ 0.0695,  0.0399],
          ...,
          [-0.0865,  0.0648],
          [-0.1498, -0.1173],
          [-0.1498, -0.1173]],

         [[ 0.1039,  0.0152],
          [-0.0619,  0.1874],
          [ 0.0316,  0.0798],
          ...,
          [-0.1880, -0.0568],
          [ 0.1138, -0.3113],
          [ 0.1138, -0.3113]],

         [[-0.1488,  0.3179],
          [ 0.0684, -0.0016],
          [-0.0754,  0.3997],
          ...,
          [-0.1655,  0.2372],
          [-0.3831, -0.0282],
          [-0.3831, -0.0282]],

         [[-0.1671,  0.1532],
          [ 0.0517, -0.0170],
          [ 0.2264, -0.2050],
          ...,
          [ 0.0247, -0.1979],
          [ 0.0000,  0.0000],
          [ 0.0000,  0.0000]]]], dtype=torch.float16)

2025-07-26 03:29:55.005842 GPU 7 109385 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471805 (unix time) try "date -d @1753471805" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ab49) received by PID 109385 (TID 0x7fe9bb0d3740) from PID 109385 ***]


2025-07-26 03:30:10.290023 GPU 7 109552 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471913 (unix time) try "date -d @1753471913" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1abf0) received by PID 109552 (TID 0x7f3ee9519740) from PID 109552 ***]


2025-07-26 03:31:59.037341 GPU 7 109719 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472020 (unix time) try "date -d @1753472020" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ac97) received by PID 109719 (TID 0x7fbb77af3740) from PID 109719 ***]


2025-07-26 03:32:26.454894 GPU 3 108709 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471962 (unix time) try "date -d @1753471962" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a8a5) received by PID 108709 (TID 0x7f8983a51740) from PID 108709 ***]


2025-07-26 03:32:47.605361 GPU 3 109891 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472069 (unix time) try "date -d @1753472069" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ad43) received by PID 109891 (TID 0x7fe38a426740) from PID 109891 ***]


2025-07-26 03:32:59.305112 GPU 6 109062 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753471993 (unix time) try "date -d @1753471993" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1aa06) received by PID 109062 (TID 0x7fded5caf740) from PID 109062 ***]


2025-07-26 03:33:08.763242 GPU 1 108897 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472001 (unix time) try "date -d @1753472001" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a961) received by PID 108897 (TID 0x7efd7c166740) from PID 108897 ***]


2025-07-26 03:33:18.870913 GPU 6 110049 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472097 (unix time) try "date -d @1753472097" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ade1) received by PID 110049 (TID 0x7f27022c8740) from PID 110049 ***]


2025-07-26 03:33:22.403992 GPU 5 108050 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472017 (unix time) try "date -d @1753472017" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a612) received by PID 108050 (TID 0x7f645b95f740) from PID 108050 ***]


2025-07-26 03:33:26.585806 GPU 1 110208 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472110 (unix time) try "date -d @1753472110" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ae80) received by PID 110208 (TID 0x7f9bf6919740) from PID 110208 ***]


2025-07-26 03:33:36.604179 GPU 2 108219 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472030 (unix time) try "date -d @1753472030" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a6bb) received by PID 108219 (TID 0x7f9425a07740) from PID 108219 ***]


2025-07-26 03:33:43.977559 GPU 5 110367 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472123 (unix time) try "date -d @1753472123" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1af1f) received by PID 110367 (TID 0x7f558f134740) from PID 110367 ***]


2025-07-26 03:33:44.478655 GPU 7 110450 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472137 (unix time) try "date -d @1753472137" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1af72) received by PID 110450 (TID 0x7fcfbb47e740) from PID 110450 ***]


2025-07-26 03:33:55.709525 GPU 2 110683 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472147 (unix time) try "date -d @1753472147" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b05b) received by PID 110683 (TID 0x7fcd40fbb740) from PID 110683 ***]


2025-07-26 03:34:03.823912 GPU 4 107130 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472057 (unix time) try "date -d @1753472057" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a27a) received by PID 107130 (TID 0x7f62b13de740) from PID 107130 ***]


2025-07-26 03:34:23.709618 GPU 4 110843 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472162 (unix time) try "date -d @1753472162" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b0fb) received by PID 110843 (TID 0x7f303b7b9740) from PID 110843 ***]


2025-07-26 03:34:33.618542 GPU 3 111001 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472170 (unix time) try "date -d @1753472170" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b199) received by PID 111001 (TID 0x7fe1728e8740) from PID 111001 ***]


2025-07-26 03:35:02.462786 GPU 6 111162 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753472199 (unix time) try "date -d @1753472199" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b23a) received by PID 111162 (TID 0x7f3c41a97740) from PID 111162 ***]


2025-07-26 03:39:43.156546 GPU 5 111483 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 8, 114085069]) != torch.Size([2, 7, 114085069]).
ACTUAL: (shape=torch.Size([2, 8, 114085069]), dtype=torch.float32)
tensor([[[ 0.1792,  0.0161,  0.3231,  ...,  0.0511, -0.1660,  0.0049],
         [-0.0732, -0.1104, -0.0343,  ...,  0.1250,  0.1171,  0.3664],
         [ 0.2223,  0.0942,  0.0779,  ...,  0.3527, -0.2105,  0.3901],
         ...,
         [ 0.1096, -0.2280, -0.3983,  ..., -0.3356,  0.3580,  0.2885],
         [ 0.1960,  0.1527, -0.0529,  ...,  0.0555, -0.1320,  0.4207],
         [ 0.0240,  0.0895,  0.4120,  ..., -0.0660,  0.3492,  0.4256]],

        [[-0.4268, -0.3398,  0.1336,  ..., -0.2662,  0.0969, -0.2425],
         [ 0.0162,  0.1511, -0.1903,  ..., -0.1760,  0.0063, -0.0987],
         [-0.1377, -0.3121, -0.3321,  ...,  0.1103, -0.2073, -0.0532],
         ...,
         [-0.1508,  0.1964, -0.0612,  ..., -0.1823,  0.0300,  0.4633],
         [ 0.3074,  0.1396, -0.1782,  ...,  0.3327,  0.0048,  0.0657],
         [ 0.2152,  0.1456,  0.2522,  ..., -0.1255,  0.3739, -0.3068]]])
DESIRED: (shape=torch.Size([2, 7, 114085069]), dtype=torch.float32)
tensor([[[ 0.1792,  0.0161,  0.3231,  ...,  0.0511, -0.1660,  0.0049],
         [-0.0732, -0.1104, -0.0343,  ...,  0.1250,  0.1171,  0.3664],
         [ 0.2223,  0.0942,  0.0779,  ...,  0.3527, -0.2105,  0.3901],
         ...,
         [ 0.1757, -0.3732, -0.1158,  ..., -0.2686,  0.0477, -0.2049],
         [ 0.1096, -0.2280, -0.3983,  ..., -0.3356,  0.3580,  0.2885],
         [ 0.1960,  0.1527, -0.0529,  ...,  0.0555, -0.1320,  0.4207]],

        [[-0.4268, -0.3398,  0.1336,  ..., -0.2662,  0.0969, -0.2425],
         [ 0.0162,  0.1511, -0.1903,  ..., -0.1760,  0.0063, -0.0987],
         [-0.1377, -0.3121, -0.3321,  ...,  0.1103, -0.2073, -0.0532],
         ...,
         [-0.3262, -0.0820, -0.1015,  ..., -0.3140,  0.3811, -0.3650],
         [-0.1508,  0.1964, -0.0612,  ..., -0.1823,  0.0300,  0.4633],
         [ 0.3074,  0.1396, -0.1782,  ...,  0.3327,  0.0048,  0.0657]]])

2025-07-26 03:39:55.824967 GPU 7 111644 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 8, 114085069]) != torch.Size([2, 7, 114085069]).
ACTUAL: (shape=torch.Size([2, 8, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.3185, -0.1272, -0.1618,  ..., -0.2453, -0.0658, -0.0260],
         [-0.2284, -0.4440, -0.2064,  ...,  0.2177,  0.2322, -0.1567],
         ...,
         [-0.0815, -0.1324, -0.2214,  ..., -0.4718, -0.2154,  0.0269],
         [ 0.0766, -0.1827, -0.0852,  ..., -0.3196, -0.2686,  0.1592],
         [-0.1688, -0.0104, -0.1444,  ...,  0.2838, -0.3178, -0.1730]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.1882,  0.2364,  0.2060,  ...,  0.4041, -0.2090,  0.0774],
         [ 0.1635, -0.1823, -0.2906,  ...,  0.2350,  0.1659,  0.0103],
         ...,
         [ 0.3070,  0.2253, -0.3133,  ..., -0.2889, -0.2903, -0.2877],
         [-0.2060,  0.0830, -0.1321,  ...,  0.1360, -0.3507, -0.0926],
         [ 0.2247,  0.4257, -0.2541,  ...,  0.0829, -0.2702, -0.0674]]])
DESIRED: (shape=torch.Size([2, 7, 114085069]), dtype=torch.float32)
tensor([[[-0.2753,  0.0998,  0.3567,  ...,  0.3946, -0.1280, -0.3298],
         [-0.3347, -0.1809, -0.1981,  ..., -0.2037, -0.0292, -0.0798],
         [-0.1816, -0.4427, -0.1630,  ...,  0.2710,  0.2519, -0.1087],
         ...,
         [-0.3657,  0.1116, -0.0989,  ...,  0.3429,  0.3301, -0.2414],
         [-0.0721, -0.1692, -0.1753,  ..., -0.4694, -0.2612,  0.0474],
         [ 0.1021, -0.1400, -0.1203,  ..., -0.2852, -0.2132,  0.1614]],

        [[-0.0101,  0.4444, -0.2729,  ...,  0.1068,  0.3027,  0.3980],
         [ 0.1342,  0.1344,  0.1427,  ...,  0.3791, -0.1957,  0.0420],
         [ 0.2384, -0.1340, -0.3197,  ...,  0.2302,  0.2396,  0.0467],
         ...,
         [ 0.3563, -0.0803,  0.1656,  ...,  0.0316,  0.1224,  0.2388],
         [ 0.2462,  0.1431, -0.2952,  ..., -0.2205, -0.3183, -0.1994],
         [-0.2431,  0.1707, -0.1139,  ...,  0.1396, -0.3238, -0.1763]]])

2025-07-26 03:40:06.836514 GPU 2 111803 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 8, 114085069]) != torch.Size([2, 7, 114085069]).
ACTUAL: (shape=torch.Size([2, 8, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.4752,  0.0917,  0.1475,  ...,  0.1904, -0.2912, -0.0225],
         [-0.0389, -0.1390,  0.2532,  ..., -0.0943, -0.1300,  0.2927],
         ...,
         [-0.0054, -0.1334, -0.2871,  ...,  0.1422,  0.0074, -0.2549],
         [ 0.0418, -0.1988, -0.1634,  ...,  0.2851, -0.1851, -0.3863],
         [-0.4986,  0.3410,  0.4783,  ...,  0.3310,  0.1725,  0.2057]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.2852,  0.3603,  0.2647,  ..., -0.0669,  0.2931,  0.2553],
         [-0.2055, -0.2649,  0.0102,  ..., -0.1106,  0.2951,  0.2197],
         ...,
         [-0.0071,  0.1465,  0.1101,  ...,  0.0618,  0.1053,  0.3662],
         [-0.2682,  0.2811, -0.0304,  ..., -0.2807,  0.1789,  0.3131],
         [ 0.3081,  0.1489,  0.0061,  ...,  0.1112, -0.0997, -0.0019]]])
DESIRED: (shape=torch.Size([2, 7, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.4748, -0.0023,  0.2246,  ...,  0.2635, -0.1973,  0.1330],
         [ 0.2872, -0.0769,  0.1398,  ..., -0.4906, -0.2439,  0.1405],
         ...,
         [ 0.0274, -0.1874, -0.2967,  ...,  0.4035,  0.1216, -0.1004],
         [ 0.0145, -0.1575, -0.1967,  ...,  0.1377, -0.1730, -0.4087],
         [-0.4986,  0.3410,  0.4783,  ...,  0.3310,  0.1725,  0.2057]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.3220,  0.2600,  0.2170,  ..., -0.1402,  0.3313,  0.2237],
         [-0.0537, -0.4831, -0.0616,  ...,  0.0397,  0.2011,  0.2721],
         ...,
         [ 0.0892,  0.4003, -0.1232,  ...,  0.2028,  0.3288,  0.4798],
         [-0.2284,  0.1391,  0.1050,  ..., -0.2343,  0.0674,  0.2836],
         [ 0.3081,  0.1489,  0.0061,  ...,  0.1112, -0.0997, -0.0019]]])

2025-07-26 03:40:26.713341 GPU 4 111964 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 8, 114085069]) != torch.Size([2, 7, 114085069]).
ACTUAL: (shape=torch.Size([2, 8, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.3778, -0.2954,  0.0864,  ...,  0.2198, -0.4239, -0.0257],
         [-0.0411, -0.1085,  0.0894,  ...,  0.2346, -0.1499,  0.2962],
         ...,
         [-0.1779,  0.3288, -0.0466,  ..., -0.3783,  0.2861, -0.1777],
         [ 0.1544,  0.4531, -0.2275,  ..., -0.3389,  0.2864, -0.4542],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1703,  0.0065, -0.2558,  ...,  0.4191,  0.2017, -0.1623],
         [-0.3018, -0.1634,  0.1263,  ..., -0.0320,  0.0324, -0.0023],
         ...,
         [-0.4240,  0.0385,  0.1867,  ...,  0.3655,  0.1794,  0.0291],
         [-0.3353, -0.0296,  0.2075,  ...,  0.1005, -0.0239, -0.3736],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])
DESIRED: (shape=torch.Size([2, 7, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.3331, -0.2272,  0.1085,  ...,  0.2565, -0.3879,  0.0448],
         [-0.2435, -0.1388,  0.0365,  ...,  0.1537, -0.0345,  0.3615],
         ...,
         [-0.3936,  0.2610, -0.4135,  ..., -0.2936,  0.2012, -0.0054],
         [ 0.1410,  0.4429, -0.0265,  ..., -0.3846,  0.3203, -0.4402],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1789, -0.0264, -0.1060,  ...,  0.3893,  0.1596, -0.1798],
         [-0.3789, -0.2086,  0.0385,  ..., -0.2959,  0.0106,  0.1616],
         ...,
         [-0.3710,  0.3415,  0.2950,  ...,  0.4221,  0.0879,  0.4086],
         [-0.3831, -0.1304,  0.1579,  ...,  0.1574,  0.0737, -0.4047],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])

2025-07-26 03:42:41.043320 GPU 2 111803 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 11, 114085069]) != torch.Size([2, 10, 114085069]).
ACTUAL: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[-3.2780e-01, -4.6592e-01,  1.4878e-01,  ..., -1.5862e-01,  1.1884e-01,  4.6473e-01],
         [-4.5557e-01,  1.2403e-01,  5.8843e-02,  ...,  5.8621e-02, -3.4340e-01, -1.3501e-01],
         [-4.7421e-01, -1.2208e-01,  3.2273e-01,  ...,  3.5656e-01, -7.7773e-02,  3.3077e-01],
         ...,
         [-2.0196e-02, -1.0501e-01, -2.3896e-01,  ..., -4.9847e-02, -1.5764e-01, -4.3722e-01],
         [-4.7229e-04, -1.7267e-01, -3.7642e-02,  ...,  4.6109e-01, -1.5029e-01, -2.7983e-01],
         [-4.9862e-01,  3.4102e-01,  4.7828e-01,  ...,  3.3096e-01,  1.7250e-01,  2.0571e-01]],

        [[-4.6512e-01,  9.4010e-02,  3.1574e-01,  ..., -2.1879e-02, -2.9190e-01, -4.9949e-01],
         [-2.6740e-01,  4.3951e-01,  3.2653e-01,  ...,  2.3493e-02,  1.6937e-01,  1.8886e-01],
         [-3.6886e-01,  1.3236e-01,  1.5639e-01,  ..., -2.3332e-01,  3.7990e-01,  1.8337e-01],
         ...,
         [-1.7768e-01, -4.1458e-02,  2.7746e-01,  ..., -1.7532e-01, -7.4551e-02,  2.4612e-01],
         [-2.3546e-01,  4.2644e-01, -1.8146e-01,  ..., -2.8059e-01,  2.6938e-01,  3.0411e-01],
         [ 3.0808e-01,  1.4888e-01,  6.0681e-03,  ...,  1.1116e-01, -9.9719e-02, -1.8618e-03]]])
DESIRED: (shape=torch.Size([2, 10, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.4757,  0.2172,  0.0446,  ...,  0.0929, -0.4164, -0.2297],
         [-0.4738, -0.2219,  0.4045,  ...,  0.4341,  0.0218,  0.4956],
         ...,
         [-0.0491, -0.0613, -0.2742,  ..., -0.2062, -0.1448, -0.4610],
         [ 0.0782, -0.2538, -0.1191,  ...,  0.4816, -0.2013, -0.3565],
         [-0.4986,  0.3410,  0.4783,  ...,  0.3310,  0.1725,  0.2057]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.2362,  0.4941,  0.3282,  ...,  0.0307,  0.2422,  0.2975],
         [-0.4079,  0.0260,  0.1058,  ..., -0.3110,  0.4204,  0.1498],
         ...,
         [-0.1354, -0.1920,  0.4211,  ..., -0.1262, -0.1928,  0.2149],
         [-0.3213,  0.4703, -0.2111,  ..., -0.3424,  0.3277,  0.3524],
         [ 0.3081,  0.1489,  0.0061,  ...,  0.1112, -0.0997, -0.0019]]])

2025-07-26 03:42:51.761503 GPU 1 111323 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 11, 114085069]) != torch.Size([2, 10, 114085069]).
ACTUAL: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.2758,  0.0183, -0.2258,  ..., -0.1703, -0.3015, -0.4045],
         [ 0.0383,  0.1575, -0.3843,  ..., -0.3306,  0.1948,  0.0875],
         ...,
         [ 0.1203, -0.2728,  0.1226,  ..., -0.1096,  0.2978,  0.1492],
         [-0.3627, -0.1660,  0.1542,  ..., -0.1736, -0.2232,  0.0009],
         [-0.2162,  0.4746,  0.1491,  ..., -0.4546, -0.1744, -0.3383]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.4139,  0.2597,  0.2684,  ..., -0.0176, -0.4081, -0.2271],
         [-0.4276,  0.3201,  0.0525,  ...,  0.1789, -0.1853,  0.3171],
         ...,
         [-0.0418, -0.0665, -0.1940,  ..., -0.0903, -0.3258,  0.2371],
         [ 0.2823,  0.0077,  0.2941,  ..., -0.3640, -0.2828,  0.3673],
         [ 0.2170,  0.4171,  0.1049,  ...,  0.1054, -0.3253,  0.1478]]])
DESIRED: (shape=torch.Size([2, 10, 114085069]), dtype=torch.float32)
tensor([[[-1.3402e-02,  2.0357e-01,  2.5930e-01,  ...,  4.3507e-01, -1.1694e-01,  2.5361e-01],
         [ 3.0477e-01, -2.2243e-04, -2.7429e-01,  ..., -2.3079e-01, -3.1993e-01, -4.7036e-01],
         [-2.0970e-02,  1.9258e-01, -4.0869e-01,  ..., -3.5282e-01,  3.0914e-01,  2.1142e-01],
         ...,
         [ 3.1362e-01, -2.5944e-01,  1.1026e-01,  ..., -1.0894e-01,  4.9720e-01,  1.7657e-01],
         [-3.9524e-01, -3.0835e-01,  1.5535e-01,  ..., -1.1120e-01, -2.3403e-01,  7.6270e-02],
         [-2.1624e-01,  4.7456e-01,  1.4915e-01,  ..., -4.5458e-01, -1.7443e-01, -3.3835e-01]],

        [[-3.7284e-01,  1.0081e-01,  4.8089e-01,  ..., -4.3703e-01, -3.9235e-01, -2.3305e-01],
         [-4.1799e-01,  2.7557e-01,  2.4711e-01,  ...,  2.4373e-02, -4.0968e-01, -2.2653e-01],
         [-4.2976e-01,  3.3002e-01,  9.2633e-03,  ...,  2.1324e-01, -1.3545e-01,  4.3796e-01],
         ...,
         [-1.6872e-01, -6.0139e-02, -3.9283e-01,  ...,  5.1457e-02, -3.4551e-01,  1.7004e-01],
         [ 2.9678e-01, -8.3298e-02,  3.3620e-01,  ..., -4.6832e-01, -2.7340e-01,  4.1602e-01],
         [ 2.1703e-01,  4.1712e-01,  1.0488e-01,  ...,  1.0538e-01, -3.2530e-01,  1.4782e-01]]])

2025-07-26 03:43:01.063378 GPU 4 111964 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 11, 114085069]) != torch.Size([2, 10, 114085069]).
ACTUAL: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.4306, -0.3492,  0.0366,  ...,  0.1886, -0.3774, -0.1407],
         [ 0.2705, -0.1318,  0.1393,  ...,  0.3080, -0.3374,  0.1434],
         ...,
         [ 0.1222,  0.4287,  0.2549,  ..., -0.4485,  0.3678, -0.4206],
         [ 0.1749,  0.4539, -0.4397,  ..., -0.2289,  0.1911, -0.4180],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1604,  0.0648, -0.4420,  ...,  0.4091,  0.2110, -0.1364],
         [-0.1910, -0.0725,  0.1036,  ...,  0.3476,  0.1007, -0.2045],
         ...,
         [-0.4500, -0.2714,  0.0886,  ...,  0.2370,  0.2103, -0.4481],
         [-0.2000,  0.0868,  0.2353,  ...,  0.0604, -0.0927, -0.2725],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])
DESIRED: (shape=torch.Size([2, 10, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.4374, -0.3863,  0.0571,  ...,  0.1708, -0.4720, -0.1197],
         [ 0.2288, -0.0682,  0.1599,  ...,  0.3423, -0.3038,  0.2092],
         ...,
         [ 0.1097,  0.4192,  0.4426,  ..., -0.4912,  0.3994, -0.4075],
         [ 0.1723,  0.4667, -0.4956,  ..., -0.2779,  0.2412, -0.4728],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1589,  0.0503, -0.4554,  ...,  0.4588,  0.2578, -0.1388],
         [-0.1990, -0.1032,  0.2433,  ...,  0.3198,  0.0614, -0.2209],
         ...,
         [-0.4945, -0.3655,  0.0424,  ...,  0.2900,  0.3013, -0.4771],
         [-0.2716,  0.1048,  0.2735,  ...,  0.0247, -0.1539, -0.3322],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])

2025-07-26 03:44:13.445653 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 11, 114085069]) != torch.Size([2, 10, 114085069]).
ACTUAL: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [-0.1118,  0.2920,  0.2561,  ..., -0.4627, -0.3496,  0.3270],
         [-0.0016,  0.1316, -0.1986,  ..., -0.4651, -0.1596,  0.4258],
         ...,
         [-0.4203, -0.3003, -0.2146,  ..., -0.3268, -0.4257, -0.2172],
         [-0.3810, -0.1337, -0.3496,  ..., -0.2819, -0.1775, -0.3602],
         [-0.0202,  0.4837,  0.2622,  ..., -0.3614,  0.1412,  0.0338]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [ 0.0053,  0.2503,  0.4436,  ...,  0.2665, -0.0750,  0.3673],
         [-0.1510,  0.4605, -0.1668,  ...,  0.0193,  0.0286,  0.3584],
         ...,
         [-0.0949,  0.2260,  0.2468,  ...,  0.2221,  0.1984,  0.2545],
         [-0.0353,  0.2847,  0.0746,  ...,  0.0863,  0.3702,  0.1471],
         [ 0.4483, -0.4204,  0.1298,  ...,  0.2140, -0.4900, -0.3843]]])
DESIRED: (shape=torch.Size([2, 10, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [-0.1713,  0.3574,  0.3212,  ..., -0.4612, -0.4041,  0.4186],
         [ 0.0408,  0.0751, -0.3285,  ..., -0.4661, -0.0985,  0.4276],
         ...,
         [-0.4202, -0.3248, -0.1638,  ..., -0.3402, -0.4789, -0.1706],
         [-0.4211, -0.2023, -0.4175,  ..., -0.2731, -0.2129, -0.4040],
         [-0.0202,  0.4837,  0.2622,  ..., -0.3614,  0.1412,  0.0338]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [ 0.0335,  0.3282,  0.4690,  ...,  0.3441, -0.0745,  0.3676],
         [-0.1972,  0.4936, -0.3258,  ..., -0.0619,  0.0543,  0.3561],
         ...,
         [-0.0963,  0.1918,  0.2914,  ...,  0.2596,  0.1316,  0.2666],
         [-0.0891,  0.3630,  0.0685,  ...,  0.0721,  0.4657,  0.2061],
         [ 0.4483, -0.4204,  0.1298,  ...,  0.2140, -0.4900, -0.3843]]])

2025-07-26 03:44:43.565334 GPU 6 112284 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 12, 114085069]) != torch.Size([2, 11, 114085069]).
ACTUAL: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[-1.1543e-01,  8.3582e-02, -2.2821e-01,  ...,  4.6467e-01, -2.7961e-01,  5.4352e-02],
         [-1.0412e-01,  3.5712e-01, -3.9100e-01,  ...,  2.4571e-02, -3.2206e-01,  1.0604e-01],
         [ 1.0884e-01,  3.9799e-02, -1.1376e-01,  ...,  2.0601e-01, -2.6295e-01,  5.2748e-02],
         ...,
         [-1.0528e-01,  3.6275e-01, -4.0302e-01,  ...,  3.5289e-01,  1.4437e-01, -2.7244e-01],
         [-4.7217e-02,  1.6739e-01, -4.6107e-01,  ...,  2.7450e-01,  3.6191e-01, -2.3669e-01],
         [-2.9127e-01, -1.3711e-01, -4.2879e-01,  ..., -1.5068e-01,  1.5997e-01,  2.5995e-01]],

        [[-4.4456e-01,  3.4552e-01, -8.2902e-02,  ..., -1.2156e-01,  1.2546e-01, -1.1225e-01],
         [-2.8976e-01,  1.6075e-02,  1.5160e-01,  ...,  1.9574e-01, -2.9389e-01,  4.3604e-02],
         [-3.5296e-01,  2.0761e-01, -4.3539e-02,  ...,  3.3184e-01, -4.5971e-01, -1.9926e-01],
         ...,
         [-3.0773e-01,  2.4557e-01, -2.5261e-01,  ...,  2.4510e-01, -3.0447e-02, -1.0669e-01],
         [-4.0527e-02,  3.4364e-01, -4.3795e-04,  ...,  3.2381e-01, -8.1411e-02,  2.4936e-01],
         [ 2.5609e-01,  1.9899e-01,  2.8530e-01,  ...,  1.2080e-01,  6.5816e-02,  4.7328e-01]]])
DESIRED: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[-1.1543e-01,  8.3582e-02, -2.2821e-01,  ...,  4.6467e-01, -2.7961e-01,  5.4352e-02],
         [-1.0412e-01,  3.5712e-01, -3.9100e-01,  ...,  2.4571e-02, -3.2206e-01,  1.0604e-01],
         [ 1.0884e-01,  3.9799e-02, -1.1376e-01,  ...,  2.0601e-01, -2.6295e-01,  5.2748e-02],
         ...,
         [-2.8986e-01,  1.6432e-01, -2.3876e-01,  ...,  2.3346e-01,  1.1722e-01,  9.5623e-02],
         [-1.0528e-01,  3.6275e-01, -4.0302e-01,  ...,  3.5289e-01,  1.4437e-01, -2.7244e-01],
         [-4.7217e-02,  1.6739e-01, -4.6107e-01,  ...,  2.7450e-01,  3.6191e-01, -2.3669e-01]],

        [[-4.4456e-01,  3.4552e-01, -8.2902e-02,  ..., -1.2156e-01,  1.2546e-01, -1.1225e-01],
         [-2.8976e-01,  1.6075e-02,  1.5160e-01,  ...,  1.9574e-01, -2.9389e-01,  4.3604e-02],
         [-3.5296e-01,  2.0761e-01, -4.3539e-02,  ...,  3.3184e-01, -4.5971e-01, -1.9926e-01],
         ...,
         [-2.1373e-01,  1.5666e-01, -3.7911e-01,  ...,  2.2060e-01,  1.0765e-01, -1.9300e-01],
         [-3.0773e-01,  2.4557e-01, -2.5261e-01,  ...,  2.4510e-01, -3.0447e-02, -1.0669e-01],
         [-4.0527e-02,  3.4364e-01, -4.3795e-04,  ...,  3.2381e-01, -8.1411e-02,  2.4936e-01]]])

2025-07-26 03:45:33.080195 GPU 2 111803 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 12, 114085069]) != torch.Size([2, 11, 114085069]).
ACTUAL: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.4511,  0.1033,  0.0620,  ...,  0.0510, -0.3272, -0.1140],
         [-0.4744, -0.0755,  0.2846,  ...,  0.3204, -0.1242,  0.2538],
         ...,
         [ 0.0145, -0.1575, -0.1967,  ...,  0.1377, -0.1730, -0.4087],
         [-0.1141, -0.0555,  0.0800,  ...,  0.4314, -0.0767, -0.1691],
         [-0.4986,  0.3410,  0.4783,  ...,  0.3310,  0.1725,  0.2057]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.2743,  0.4274,  0.3262,  ...,  0.0219,  0.1532,  0.1647],
         [-0.3507,  0.1820,  0.1800,  ..., -0.1971,  0.3610,  0.1990],
         ...,
         [-0.2284,  0.1391,  0.1050,  ..., -0.2343,  0.0674,  0.2836],
         [-0.1115,  0.3631, -0.1387,  ..., -0.1912,  0.1852,  0.2343],
         [ 0.3081,  0.1489,  0.0061,  ...,  0.1112, -0.0997, -0.0019]]])
DESIRED: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.4388,  0.0464,  0.0707,  ...,  0.0300, -0.2826, -0.0561],
         [-0.4746, -0.0389,  0.2546,  ...,  0.2919, -0.1608,  0.1934],
         ...,
         [-0.0172, -0.1138, -0.2836,  ...,  0.0479, -0.0338, -0.3107],
         [ 0.0039, -0.1415, -0.2096,  ...,  0.0804, -0.1683, -0.4174],
         [-0.0660, -0.1051,  0.0302,  ...,  0.4440, -0.1078, -0.2159]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.2934,  0.3941,  0.3251,  ...,  0.0175,  0.1087,  0.0983],
         [-0.3363,  0.2210,  0.1985,  ..., -0.1686,  0.3462,  0.2114],
         ...,
         [-0.0419,  0.0548,  0.1943,  ...,  0.0109,  0.0245,  0.3252],
         [-0.2129,  0.0840,  0.1577,  ..., -0.2163,  0.0240,  0.2722],
         [-0.1639,  0.3899, -0.1568,  ..., -0.2290,  0.2208,  0.2638]]])

2025-07-26 03:45:45.803931 GPU 5 111483 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 12, 114085069]) != torch.Size([2, 11, 114085069]).
ACTUAL: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[ 0.2483,  0.0480,  0.4171,  ...,  0.0716, -0.2124, -0.0595],
         [-0.2037, -0.1607, -0.1981,  ..., -0.0622,  0.0915,  0.3624],
         [ 0.0877, -0.0431,  0.1750,  ...,  0.2763,  0.0879,  0.3039],
         ...,
         [ 0.0728,  0.0751, -0.2290,  ..., -0.1699,  0.0505,  0.4478],
         [ 0.3003,  0.2278,  0.2438,  ...,  0.2864, -0.2394,  0.3909],
         [-0.0258,  0.0646,  0.4424,  ..., -0.1296,  0.4553,  0.4318]],

        [[-0.4667, -0.4283,  0.1822,  ..., -0.2420,  0.0968, -0.2869],
         [-0.2055,  0.1506, -0.1360,  ..., -0.4001,  0.0975,  0.0039],
         [ 0.1303,  0.0618, -0.1790,  ...,  0.0047, -0.0574, -0.2153],
         ...,
         [ 0.2521,  0.2378,  0.0307,  ...,  0.3237, -0.0892,  0.2347],
         [ 0.3512,  0.0293, -0.3262,  ...,  0.2476,  0.1884, -0.2037],
         [ 0.1907,  0.1666,  0.3565,  ..., -0.1928,  0.4073, -0.3253]]])
DESIRED: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[ 0.2483,  0.0480,  0.4171,  ...,  0.0716, -0.2124, -0.0595],
         [-0.2489, -0.1816, -0.2596,  ..., -0.0756,  0.1218,  0.4046],
         [ 0.1885, -0.0009,  0.3061,  ...,  0.3710,  0.0696,  0.2647],
         ...,
         [-0.0044,  0.0265, -0.3393,  ..., -0.3111,  0.1647,  0.4647],
         [ 0.3330,  0.2441,  0.2240,  ...,  0.3280, -0.3089,  0.3868],
         [-0.0258,  0.0646,  0.4424,  ..., -0.1296,  0.4553,  0.4318]],

        [[-0.4667, -0.4283,  0.1822,  ..., -0.2420,  0.0968, -0.2869],
         [-0.1794,  0.2084, -0.1678,  ..., -0.4160,  0.0976,  0.0330],
         [ 0.2018,  0.0059, -0.1719,  ...,  0.1178, -0.0973, -0.2882],
         ...,
         [ 0.2174,  0.2992,  0.1615,  ...,  0.3181, -0.1481,  0.3404],
         [ 0.3672,  0.0156, -0.3945,  ...,  0.2917,  0.1665, -0.1915],
         [ 0.1907,  0.1666,  0.3565,  ..., -0.1928,  0.4073, -0.3253]]])

2025-07-26 03:45:48.289562 GPU 7 111644 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 12, 114085069]) != torch.Size([2, 11, 114085069]).
ACTUAL: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.2838,  0.0049,  0.0036,  ..., -0.1783, -0.1365, -0.0038],
         [-0.3685, -0.2930, -0.2742,  ..., -0.1166,  0.0471, -0.1924],
         ...,
         [ 0.0489, -0.2292, -0.0469,  ..., -0.3572, -0.3290,  0.1567],
         [ 0.0942, -0.0116, -0.2060,  ..., -0.0689, -0.1126,  0.0855],
         [-0.2845, -0.0099, -0.1173,  ...,  0.4390, -0.4081, -0.2868]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.2327,  0.4412,  0.2069,  ...,  0.3819, -0.1237,  0.2001],
         [ 0.0211, -0.0789,  0.0102,  ...,  0.3269, -0.1679, -0.0321],
         ...,
         [-0.1655, -0.0127, -0.1518,  ...,  0.1320, -0.3801, -0.0014],
         [-0.2141,  0.4319, -0.1067,  ...,  0.1341, -0.2496, -0.3401],
         [ 0.4177,  0.4230, -0.3189,  ...,  0.0604, -0.2792,  0.0525]]])
DESIRED: (shape=torch.Size([2, 11, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.2849, -0.0063, -0.0381,  ..., -0.2460, -0.1375,  0.0347],
         [-0.3897, -0.3632, -0.3218,  ..., -0.0621,  0.0949, -0.2629],
         ...,
         [ 0.0156, -0.2851, -0.0009,  ..., -0.4023, -0.4016,  0.1537],
         [ 0.1321, -0.0118, -0.2148,  ..., -0.1197, -0.0831,  0.1227],
         [-0.2845, -0.0099, -0.1173,  ...,  0.4390, -0.4081, -0.2868]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.2614,  0.4409,  0.2636,  ...,  0.4144, -0.1740,  0.1767],
         [-0.0497, -0.2125, -0.0728,  ...,  0.2942, -0.1504, -0.0784],
         ...,
         [-0.1169, -0.1275, -0.1756,  ...,  0.1272, -0.4154,  0.1082],
         [-0.2772,  0.4328, -0.0855,  ...,  0.1415, -0.2466, -0.3793],
         [ 0.4177,  0.4230, -0.3189,  ...,  0.0604, -0.2792,  0.0525]]])

2025-07-26 03:45:48.441125 GPU 1 111323 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 13, 114085069]) != torch.Size([2, 12, 114085069]).
ACTUAL: (shape=torch.Size([2, 13, 114085069]), dtype=torch.float32)
tensor([[[-1.3402e-02,  2.0357e-01,  2.5930e-01,  ...,  4.3507e-01, -1.1694e-01,  2.5361e-01],
         [ 1.9463e-01,  7.0321e-02, -8.9585e-02,  ..., -2.9733e-04, -2.4967e-01, -2.1976e-01],
         [ 1.6696e-01,  8.1346e-02, -3.3115e-01,  ..., -2.8242e-01, -5.3787e-02, -1.8192e-01],
         ...,
         [-9.5340e-02, -2.8766e-01,  1.3627e-01,  ..., -1.1024e-01,  7.5339e-02,  1.1871e-01],
         [-3.3328e-01, -3.7343e-02,  1.5320e-01,  ..., -2.3006e-01, -2.1340e-01, -6.7252e-02],
         [-2.1624e-01,  4.7456e-01,  1.4915e-01,  ..., -4.5458e-01, -1.7443e-01, -3.3835e-01]],

        [[-3.7284e-01,  1.0081e-01,  4.8089e-01,  ..., -4.3703e-01, -3.9235e-01, -2.3305e-01],
         [-4.0236e-01,  2.1508e-01,  3.2804e-01,  ..., -1.3534e-01, -4.0368e-01, -2.2879e-01],
         [-4.2297e-01,  2.9861e-01,  1.4648e-01,  ...,  1.0428e-01, -2.9366e-01,  5.4602e-02],
         ...,
         [ 9.9836e-02, -7.3500e-02,  2.7767e-02,  ..., -2.4841e-01, -3.0391e-01,  3.1195e-01],
         [ 2.6917e-01,  8.9924e-02,  2.5613e-01,  ..., -2.6973e-01, -2.9136e-01,  3.2318e-01],
         [ 2.1703e-01,  4.1712e-01,  1.0488e-01,  ...,  1.0538e-01, -3.2530e-01,  1.4782e-01]]])
DESIRED: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[-1.3402e-02,  2.0357e-01,  2.5930e-01,  ...,  4.3507e-01, -1.1694e-01,  2.5361e-01],
         [ 1.9463e-01,  7.0321e-02, -8.9585e-02,  ..., -2.9733e-04, -2.4967e-01, -2.1976e-01],
         [ 1.6696e-01,  8.1346e-02, -3.3115e-01,  ..., -2.8242e-01, -5.3787e-02, -1.8192e-01],
         ...,
         [ 2.6422e-01, -2.6042e-01,  7.6922e-02,  ..., -1.5215e-01,  3.5381e-01,  7.2932e-02],
         [-9.5340e-02, -2.8766e-01,  1.3627e-01,  ..., -1.1024e-01,  7.5339e-02,  1.1871e-01],
         [-3.3328e-01, -3.7343e-02,  1.5320e-01,  ..., -2.3006e-01, -2.1340e-01, -6.7252e-02]],

        [[-3.7284e-01,  1.0081e-01,  4.8089e-01,  ..., -4.3703e-01, -3.9235e-01, -2.3305e-01],
         [-4.0236e-01,  2.1508e-01,  3.2804e-01,  ..., -1.3534e-01, -4.0368e-01, -2.2879e-01],
         [-4.2297e-01,  2.9861e-01,  1.4648e-01,  ...,  1.0428e-01, -2.9366e-01,  5.4602e-02],
         ...,
         [-1.3805e-01, -6.9579e-02, -3.4333e-01,  ...,  2.4735e-02, -3.1648e-01,  2.1513e-01],
         [ 9.9836e-02, -7.3500e-02,  2.7767e-02,  ..., -2.4841e-01, -3.0391e-01,  3.1195e-01],
         [ 2.6917e-01,  8.9924e-02,  2.5613e-01,  ..., -2.6973e-01, -2.9136e-01,  3.2318e-01]]])

2025-07-26 03:45:52.972951 GPU 4 111964 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 13, 114085069]) != torch.Size([2, 12, 114085069]).
ACTUAL: (shape=torch.Size([2, 13, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.4217, -0.3007,  0.0098,  ...,  0.2120, -0.2537, -0.1683],
         [ 0.3251, -0.2150,  0.1124,  ...,  0.2631, -0.3814,  0.0574],
         ...,
         [ 0.1531,  0.4520, -0.2069,  ..., -0.3435,  0.2899, -0.4527],
         [ 0.1842,  0.4076, -0.2378,  ..., -0.0515,  0.0097, -0.2198],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1624,  0.0838, -0.4245,  ...,  0.3442,  0.1497, -0.1333],
         [-0.1805, -0.0323, -0.0792,  ...,  0.3839,  0.1521, -0.1830],
         ...,
         [-0.3402, -0.0399,  0.2024,  ...,  0.1063, -0.0138, -0.3768],
         [ 0.0588,  0.0220,  0.0970,  ...,  0.1896,  0.1285, -0.0565],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])
DESIRED: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.4139, -0.2579, -0.0138,  ...,  0.2326, -0.1445, -0.1926],
         [ 0.3491, -0.2517,  0.1006,  ...,  0.2433, -0.4008,  0.0195],
         ...,
         [ 0.0129,  0.3888,  0.2779,  ..., -0.4532,  0.3613, -0.3302],
         [ 0.1458,  0.4466, -0.0987,  ..., -0.3682,  0.3081, -0.4452],
         [ 0.1812,  0.4224, -0.3022,  ..., -0.1081,  0.0675, -0.2831]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1642,  0.1005, -0.4091,  ...,  0.2870,  0.0956, -0.1306],
         [-0.1758, -0.0146, -0.1598,  ...,  0.4000,  0.1748, -0.1735],
         ...,
         [-0.4708, -0.2295,  0.0910,  ...,  0.3154,  0.2603, -0.3067],
         [-0.3659, -0.0942,  0.1757,  ...,  0.1369,  0.0387, -0.3935],
         [-0.0238,  0.0427,  0.1411,  ...,  0.1483,  0.0579, -0.1254]]])

2025-07-26 03:47:07.067307 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 13, 114085069]) != torch.Size([2, 12, 114085069]).
ACTUAL: (shape=torch.Size([2, 13, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [-0.0225,  0.1938,  0.1583,  ..., -0.4651, -0.2679,  0.1897],
         [-0.0652,  0.2163, -0.0037,  ..., -0.4636, -0.2513,  0.4231],
         ...,
         [-0.4206, -0.2636, -0.2907,  ..., -0.3067, -0.3459, -0.2873],
         [-0.3208, -0.0308, -0.2476,  ..., -0.2952, -0.1244, -0.2946],
         [-0.0202,  0.4837,  0.2622,  ..., -0.3614,  0.1412,  0.0338]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [-0.0371,  0.1333,  0.4055,  ...,  0.1500, -0.0758,  0.3669],
         [-0.0818,  0.4109,  0.0716,  ...,  0.1411, -0.0101,  0.3619],
         ...,
         [-0.0927,  0.2774,  0.1799,  ...,  0.1659,  0.2986,  0.2364],
         [ 0.0453,  0.1671,  0.0838,  ...,  0.1076,  0.2268,  0.0585],
         [ 0.4483, -0.4204,  0.1298,  ...,  0.2140, -0.4900, -0.3843]]])
DESIRED: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [-0.0631,  0.2384,  0.2027,  ..., -0.4640, -0.3051,  0.2521],
         [-0.0363,  0.1778, -0.0923,  ..., -0.4643, -0.2096,  0.4243],
         ...,
         [-0.4205, -0.2803, -0.2561,  ..., -0.3158, -0.3822, -0.2554],
         [-0.3482, -0.0776, -0.2939,  ..., -0.2892, -0.1486, -0.3244],
         [-0.0202,  0.4837,  0.2622,  ..., -0.3614,  0.1412,  0.0338]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [-0.0179,  0.1865,  0.4229,  ...,  0.2029, -0.0754,  0.3671],
         [-0.1133,  0.4335, -0.0368,  ...,  0.0857,  0.0075,  0.3603],
         ...,
         [-0.0937,  0.2541,  0.2103,  ...,  0.1914,  0.2531,  0.2446],
         [ 0.0086,  0.2205,  0.0796,  ...,  0.0979,  0.2920,  0.0988],
         [ 0.4483, -0.4204,  0.1298,  ...,  0.2140, -0.4900, -0.3843]]])

2025-07-26 03:47:43.770381 GPU 6 112284 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 13, 114085069]) != torch.Size([2, 12, 114085069]).
ACTUAL: (shape=torch.Size([2, 13, 114085069]), dtype=torch.float32)
tensor([[[-1.1543e-01,  8.3582e-02, -2.2821e-01,  ...,  4.6467e-01, -2.7961e-01,  5.4352e-02],
         [-1.0412e-01,  3.5712e-01, -3.9100e-01,  ...,  2.4571e-02, -3.2206e-01,  1.0604e-01],
         [ 7.8958e-02,  9.8156e-02, -1.6112e-01,  ...,  1.5914e-01, -2.7342e-01,  6.2822e-02],
         ...,
         [-8.5366e-02,  3.4934e-01, -4.1285e-01,  ...,  3.6194e-01,  1.8506e-01, -2.9098e-01],
         [-4.7217e-02,  1.6739e-01, -4.6107e-01,  ...,  2.7450e-01,  3.6191e-01, -2.3669e-01],
         [-2.9127e-01, -1.3711e-01, -4.2879e-01,  ..., -1.5068e-01,  1.5997e-01,  2.5995e-01]],

        [[-4.4456e-01,  3.4552e-01, -8.2902e-02,  ..., -1.2156e-01,  1.2546e-01, -1.1225e-01],
         [-2.8976e-01,  1.6075e-02,  1.5160e-01,  ...,  1.9574e-01, -2.9389e-01,  4.3604e-02],
         [-3.3656e-01,  1.6456e-01, -4.4945e-03,  ...,  3.2750e-01, -4.5599e-01, -1.5714e-01],
         ...,
         [-2.8368e-01,  2.6647e-01, -2.3019e-01,  ...,  2.6601e-01, -4.4738e-02, -6.6492e-02],
         [-4.0527e-02,  3.4364e-01, -4.3795e-04,  ...,  3.2381e-01, -8.1411e-02,  2.4936e-01],
         [ 2.5609e-01,  1.9899e-01,  2.8530e-01,  ...,  1.2080e-01,  6.5816e-02,  4.7328e-01]]])
DESIRED: (shape=torch.Size([2, 12, 114085069]), dtype=torch.float32)
tensor([[[-0.1154,  0.0836, -0.2282,  ...,  0.4647, -0.2796,  0.0544],
         [-0.1031,  0.3820, -0.4058,  ..., -0.0154, -0.3259,  0.1107],
         [ 0.1279,  0.0027, -0.0836,  ...,  0.2358, -0.2563,  0.0463],
         ...,
         [-0.1180,  0.3713, -0.3968,  ...,  0.3471,  0.1185, -0.2606],
         [-0.0250,  0.1951, -0.4640,  ...,  0.3132,  0.3803, -0.2818],
         [-0.2913, -0.1371, -0.4288,  ..., -0.1507,  0.1600,  0.2599]],

        [[-0.4446,  0.3455, -0.0829,  ..., -0.1216,  0.1255, -0.1123],
         [-0.2757, -0.0139,  0.1729,  ...,  0.2246, -0.3320,  0.0578],
         [-0.3634,  0.2350, -0.0684,  ...,  0.3346, -0.4621, -0.2261],
         ...,
         [-0.3230,  0.2323, -0.2669,  ...,  0.2318, -0.0214, -0.1323],
         [-0.0675,  0.3568, -0.0264,  ...,  0.3423, -0.0948,  0.2290],
         [ 0.2561,  0.1990,  0.2853,  ...,  0.1208,  0.0658,  0.4733]]])

2025-07-26 03:49:03.063099 GPU 1 111323 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 15, 114085069]) != torch.Size([2, 14, 114085069]).
ACTUAL: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.1457,  0.1017, -0.0075,  ...,  0.1021, -0.2184, -0.1084],
         [ 0.2505,  0.0319, -0.2967,  ..., -0.2511, -0.2151, -0.3567],
         ...,
         [-0.2771, -0.3002,  0.1478,  ..., -0.1108, -0.1122,  0.0930],
         [-0.3057,  0.0831,  0.1522,  ..., -0.2829, -0.2042, -0.1310],
         [-0.2162,  0.4746,  0.1491,  ..., -0.4546, -0.1744, -0.3383]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.3954,  0.1882,  0.3640,  ..., -0.2063, -0.4010, -0.2298],
         [-0.4200,  0.2846,  0.2075,  ...,  0.0559, -0.3640, -0.1158],
         ...,
         [ 0.2192, -0.0794,  0.2147,  ..., -0.3817, -0.2854,  0.3750],
         [ 0.2569,  0.1669,  0.2205,  ..., -0.1815, -0.2994,  0.2819],
         [ 0.2170,  0.4171,  0.1049,  ...,  0.1054, -0.3253,  0.1478]]])
DESIRED: (shape=torch.Size([2, 14, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.1457,  0.1017, -0.0075,  ...,  0.1021, -0.2184, -0.1084],
         [ 0.2505,  0.0319, -0.2967,  ..., -0.2511, -0.2151, -0.3567],
         ...,
         [ 0.1955, -0.2676,  0.1178,  ..., -0.1093,  0.3753,  0.1599],
         [-0.2771, -0.3002,  0.1478,  ..., -0.1108, -0.1122,  0.0930],
         [-0.3057,  0.0831,  0.1522,  ..., -0.2829, -0.2042, -0.1310]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.3954,  0.1882,  0.3640,  ..., -0.2063, -0.4010, -0.2298],
         [-0.4200,  0.2846,  0.2075,  ...,  0.0559, -0.3640, -0.1158],
         ...,
         [-0.0911, -0.0640, -0.2713,  ..., -0.0352, -0.3335,  0.2110],
         [ 0.2192, -0.0794,  0.2147,  ..., -0.3817, -0.2854,  0.3750],
         [ 0.2569,  0.1669,  0.2205,  ..., -0.1815, -0.2994,  0.2819]]])

2025-07-26 03:50:16.681497 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 15, 114085069]) != torch.Size([2, 14, 114085069]).
ACTUAL: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [ 0.0271,  0.1393,  0.1040,  ..., -0.4664, -0.2226,  0.1134],
         [-0.1006,  0.2633,  0.1046,  ..., -0.4628, -0.3022,  0.4216],
         ...,
         [-0.4211, -0.2023, -0.4175,  ..., -0.2731, -0.2129, -0.4040],
         [-0.1538,  0.2550,  0.0356,  ..., -0.3320,  0.0231, -0.1121],
         [-0.0202,  0.4837,  0.2622,  ..., -0.3614,  0.1412,  0.0338]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [-0.0607,  0.0684,  0.3844,  ...,  0.0852, -0.0762,  0.3666],
         [-0.0434,  0.3834,  0.2041,  ...,  0.2088, -0.0316,  0.3638],
         ...,
         [-0.0891,  0.3630,  0.0685,  ...,  0.0721,  0.4657,  0.2061],
         [ 0.2692, -0.1593,  0.1094,  ...,  0.1667, -0.1715, -0.1875],
         [ 0.4483, -0.4204,  0.1298,  ...,  0.2140, -0.4900, -0.3843]]])
DESIRED: (shape=torch.Size([2, 14, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [ 0.1263,  0.0302, -0.0046,  ..., -0.4690, -0.1318, -0.0392],
         [-0.1359,  0.3104,  0.2129,  ..., -0.4620, -0.3532,  0.4201],
         ...,
         [-0.4203, -0.3044, -0.2061,  ..., -0.3290, -0.4346, -0.2095],
         [-0.4209, -0.2227, -0.3753,  ..., -0.2843, -0.2573, -0.3651],
         [-0.2206,  0.1407, -0.0777,  ..., -0.3173, -0.0359, -0.1851]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [-0.1078, -0.0615,  0.3421,  ..., -0.0442, -0.0770,  0.3661],
         [-0.0049,  0.3558,  0.3365,  ...,  0.2764, -0.0530,  0.3657],
         ...,
         [-0.0951,  0.2203,  0.2543,  ...,  0.2284,  0.1873,  0.2565],
         [-0.0903,  0.3345,  0.1056,  ...,  0.1034,  0.4100,  0.2162],
         [ 0.1796, -0.0287,  0.0991,  ...,  0.1430, -0.0122, -0.0891]]])

2025-07-26 03:50:51.170194 GPU 6 112284 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 15, 114085069]) != torch.Size([2, 14, 114085069]).
ACTUAL: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[-0.1154,  0.0836, -0.2282,  ...,  0.4647, -0.2796,  0.0544],
         [-0.1057,  0.3180, -0.3677,  ...,  0.0874, -0.3160,  0.0987],
         [ 0.0021,  0.2482, -0.2829,  ...,  0.0386, -0.3003,  0.0887],
         ...,
         [-0.0342,  0.3149, -0.4381,  ...,  0.3852,  0.2897, -0.3387],
         [-0.0821,  0.1239, -0.4565,  ...,  0.2138,  0.3331, -0.1657],
         [-0.2913, -0.1371, -0.4288,  ..., -0.1507,  0.1600,  0.2599]],

        [[-0.4446,  0.3455, -0.0829,  ..., -0.1216,  0.1255, -0.1123],
         [-0.3119,  0.0631,  0.1181,  ...,  0.1504, -0.2340,  0.0213],
         [-0.2944,  0.0539,  0.0959,  ...,  0.3164, -0.4464, -0.0488],
         ...,
         [-0.2218,  0.3202, -0.1725,  ...,  0.3198, -0.0815,  0.0369],
         [ 0.0018,  0.3230,  0.0404,  ...,  0.2948, -0.0604,  0.2814],
         [ 0.2561,  0.1990,  0.2853,  ...,  0.1208,  0.0658,  0.4733]]])
DESIRED: (shape=torch.Size([2, 14, 114085069]), dtype=torch.float32)
tensor([[[-0.1154,  0.0836, -0.2282,  ...,  0.4647, -0.2796,  0.0544],
         [-0.1050,  0.3361, -0.3785,  ...,  0.0584, -0.3188,  0.1021],
         [ 0.0376,  0.1790, -0.2267,  ...,  0.0942, -0.2879,  0.0768],
         ...,
         [-0.0578,  0.3308, -0.4265,  ...,  0.3745,  0.2414, -0.3167],
         [-0.0660,  0.1440, -0.4586,  ...,  0.2418,  0.3464, -0.1985],
         [-0.2913, -0.1371, -0.4288,  ..., -0.1507,  0.1600,  0.2599]],

        [[-0.4446,  0.3455, -0.0829,  ..., -0.1216,  0.1255, -0.1123],
         [-0.3017,  0.0414,  0.1336,  ...,  0.1713, -0.2616,  0.0316],
         [-0.3139,  0.1050,  0.0496,  ...,  0.3215, -0.4508, -0.0988],
         ...,
         [-0.2504,  0.2954, -0.1991,  ...,  0.2950, -0.0645, -0.0108],
         [-0.0177,  0.3325,  0.0215,  ...,  0.3082, -0.0701,  0.2666],
         [ 0.2561,  0.1990,  0.2853,  ...,  0.1208,  0.0658,  0.4733]]])

2025-07-26 03:52:31.910323 GPU 1 111323 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 15, 114085069]) != torch.Size([2, 14, 114085069]).
ACTUAL: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.1911,  0.0726, -0.0837,  ...,  0.0070, -0.2474, -0.2118],
         [ 0.2117,  0.0549, -0.3127,  ..., -0.2657, -0.1402, -0.2756],
         ...,
         [-0.1927, -0.2944,  0.1425,  ..., -0.1106, -0.0251,  0.1049],
         [-0.3313, -0.0287,  0.1531,  ..., -0.2338, -0.2127, -0.0718],
         [-0.2162,  0.4746,  0.1491,  ..., -0.4546, -0.1744, -0.3383]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.4019,  0.2132,  0.3306,  ..., -0.1404, -0.4035, -0.2289],
         [-0.4214,  0.2911,  0.1792,  ...,  0.0783, -0.3313, -0.0367],
         ...,
         [ 0.1638, -0.0767,  0.1279,  ..., -0.3198, -0.2940,  0.3457],
         [ 0.2683,  0.0954,  0.2536,  ..., -0.2634, -0.2919,  0.3202],
         [ 0.2170,  0.4171,  0.1049,  ...,  0.1054, -0.3253,  0.1478]]])
DESIRED: (shape=torch.Size([2, 14, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.2069,  0.0625, -0.1101,  ..., -0.0259, -0.2575, -0.2476],
         [ 0.1795,  0.0739, -0.3260,  ..., -0.2777, -0.0780, -0.2081],
         ...,
         [-0.1226, -0.2895,  0.1380,  ..., -0.1103,  0.0472,  0.1148],
         [-0.3402, -0.0675,  0.1534,  ..., -0.2169, -0.2157, -0.0513],
         [-0.2162,  0.4746,  0.1491,  ..., -0.4546, -0.1744, -0.3383]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.4041,  0.2218,  0.3190,  ..., -0.1176, -0.4043, -0.2285],
         [-0.4225,  0.2965,  0.1556,  ...,  0.0970, -0.3042,  0.0290],
         ...,
         [ 0.1177, -0.0744,  0.0558,  ..., -0.2684, -0.3011,  0.3214],
         [ 0.2722,  0.0707,  0.2650,  ..., -0.2918, -0.2894,  0.3335],
         [ 0.2170,  0.4171,  0.1049,  ...,  0.1054, -0.3253,  0.1478]]])

2025-07-26 03:52:42.868632 GPU 7 111644 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 16, 114085069]) != torch.Size([2, 15, 114085069]).
ACTUAL: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.2791,  0.0570,  0.1975,  ...,  0.1363, -0.1319, -0.1828],
         [-0.2942, -0.0468, -0.1072,  ..., -0.3078, -0.1205,  0.0548],
         ...,
         [ 0.1656, -0.0333, -0.2081,  ..., -0.1990, -0.0747,  0.1671],
         [-0.0820, -0.0108, -0.1647,  ...,  0.1674, -0.2501, -0.0877],
         [-0.2845, -0.0099, -0.1173,  ...,  0.4390, -0.4081, -0.2868]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.0993,  0.4429, -0.0566,  ...,  0.2308,  0.1105,  0.3088],
         [ 0.2694,  0.3894,  0.3011,  ...,  0.4416, -0.2289,  0.1305],
         ...,
         [-0.3359,  0.3900, -0.0686,  ...,  0.1487, -0.2565, -0.3855],
         [ 0.0799,  0.4277, -0.2054,  ...,  0.0998, -0.2634, -0.1574],
         [ 0.4177,  0.4230, -0.3189,  ...,  0.0604, -0.2792,  0.0525]]])
DESIRED: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.2791,  0.0570,  0.1975,  ...,  0.1363, -0.1319, -0.1828],
         [-0.2942, -0.0468, -0.1072,  ..., -0.3078, -0.1205,  0.0548],
         ...,
         [ 0.0385, -0.2467, -0.0325,  ..., -0.3713, -0.3517,  0.1558],
         [ 0.1656, -0.0333, -0.2081,  ..., -0.1990, -0.0747,  0.1671],
         [-0.0820, -0.0108, -0.1647,  ...,  0.1674, -0.2501, -0.0877]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.0993,  0.4429, -0.0566,  ...,  0.2308,  0.1105,  0.3088],
         [ 0.2694,  0.3894,  0.3011,  ...,  0.4416, -0.2289,  0.1305],
         ...,
         [-0.1503, -0.0486, -0.1593,  ...,  0.1305, -0.3911,  0.0329],
         [-0.3359,  0.3900, -0.0686,  ...,  0.1487, -0.2565, -0.3855],
         [ 0.0799,  0.4277, -0.2054,  ...,  0.0998, -0.2634, -0.1574]]])

2025-07-26 03:52:46.330827 GPU 2 111803 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 16, 114085069]) != torch.Size([2, 15, 114085069]).
ACTUAL: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.4203, -0.0390,  0.0837,  ..., -0.0014, -0.2157,  0.0307],
         [-0.4752,  0.1074,  0.1346,  ...,  0.1782, -0.3068, -0.0484],
         ...,
         [ 0.0061, -0.1794, -0.0444,  ...,  0.4628, -0.1545, -0.2862],
         [-0.3544,  0.1923,  0.3289,  ...,  0.3686,  0.0791,  0.0652],
         [-0.4986,  0.3410,  0.4783,  ...,  0.3310,  0.1725,  0.2057]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.3220,  0.3440,  0.3235,  ...,  0.0110,  0.0419, -0.0013],
         [-0.2791,  0.3770,  0.2726,  ..., -0.0547,  0.2868,  0.2606],
         ...,
         [-0.2426,  0.4301, -0.1839,  ..., -0.2857,  0.2742,  0.3081],
         [ 0.1507,  0.2292, -0.0482,  ..., -0.0022,  0.0071,  0.0867],
         [ 0.3081,  0.1489,  0.0061,  ...,  0.1112, -0.0997, -0.0019]]])
DESIRED: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[-0.3278, -0.4659,  0.1488,  ..., -0.1586,  0.1188,  0.4647],
         [-0.3925, -0.1671,  0.1032,  ..., -0.0486, -0.1153,  0.1609],
         [-0.4756,  0.1897,  0.0671,  ...,  0.1142, -0.3890, -0.1844],
         ...,
         [-0.0093, -0.1214, -0.2257,  ...,  0.0088, -0.1625, -0.4283],
         [ 0.0702, -0.2418, -0.1288,  ...,  0.4386, -0.1977, -0.3630],
         [-0.2463,  0.0808,  0.2169,  ...,  0.3969,  0.0090, -0.0403]],

        [[-0.4651,  0.0940,  0.3157,  ..., -0.0219, -0.2919, -0.4995],
         [-0.3650,  0.2690,  0.3212,  ...,  0.0011, -0.0582, -0.1508],
         [-0.2469,  0.4648,  0.3143,  ...,  0.0093,  0.2533,  0.2883],
         ...,
         [-0.1935,  0.0150,  0.2236,  ..., -0.1938, -0.0302,  0.2578],
         [-0.3097,  0.4289, -0.1716,  ..., -0.3289,  0.2951,  0.3438],
         [ 0.0327,  0.2895, -0.0889,  ..., -0.0873,  0.0873,  0.1531]]])

2025-07-26 03:52:57.121433 GPU 4 111964 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 16, 114085069]) != torch.Size([2, 15, 114085069]).
ACTUAL: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.4102, -0.2379, -0.0248,  ...,  0.2422, -0.0936, -0.2040],
         [ 0.3957, -0.3227,  0.0776,  ...,  0.2051, -0.4383, -0.0539],
         ...,
         [ 0.1598,  0.4572, -0.3079,  ..., -0.3206,  0.2729, -0.4598],
         [ 0.1826,  0.4155, -0.2721,  ..., -0.0817,  0.0405, -0.2536],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1650,  0.1083, -0.4018,  ...,  0.2603,  0.0703, -0.1293],
         [-0.1669,  0.0196, -0.3157,  ...,  0.4310,  0.2186, -0.1552],
         ...,
         [-0.3162,  0.0107,  0.2273,  ...,  0.0777, -0.0629, -0.3612],
         [ 0.0148,  0.0330,  0.1206,  ...,  0.1676,  0.0908, -0.0932],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])
DESIRED: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[ 0.3695, -0.0154, -0.1476,  ...,  0.3493,  0.4740, -0.3304],
         [ 0.4131, -0.2538, -0.0161,  ...,  0.2345, -0.1341, -0.1949],
         [ 0.3778, -0.2954,  0.0864,  ...,  0.2198, -0.4239, -0.0257],
         ...,
         [ 0.1544,  0.4531, -0.2275,  ..., -0.3389,  0.2864, -0.4542],
         [ 0.1815,  0.4210, -0.2961,  ..., -0.1028,  0.0620, -0.2771],
         [ 0.1980,  0.3388,  0.0630,  ...,  0.2126, -0.2605,  0.0753]],

        [[-0.1742,  0.1953, -0.3215,  ..., -0.0375, -0.2110, -0.1151],
         [-0.1643,  0.1021, -0.4076,  ...,  0.2815,  0.0904, -0.1303],
         [-0.1703,  0.0065, -0.2558,  ...,  0.4191,  0.2017, -0.1623],
         ...,
         [-0.3353, -0.0296,  0.2075,  ...,  0.1005, -0.0239, -0.3736],
         [-0.0159,  0.0407,  0.1369,  ...,  0.1523,  0.0646, -0.1188],
         [ 0.4443, -0.0747, -0.1088,  ...,  0.3819,  0.4579,  0.2653]]])

2025-07-26 03:52:59.110694 GPU 5 111483 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 16, 114085069]) != torch.Size([2, 15, 114085069]).
ACTUAL: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[ 0.2483,  0.0480,  0.4171,  ...,  0.0716, -0.2124, -0.0595],
         [-0.0832, -0.1050, -0.0340,  ..., -0.0265,  0.0104,  0.2499],
         [-0.1810, -0.1555, -0.1745,  ...,  0.0238,  0.1366,  0.4083],
         ...,
         [ 0.2785,  0.2047,  0.0650,  ...,  0.2064, -0.2542,  0.4025],
         [ 0.2134,  0.1843,  0.2968,  ...,  0.1755, -0.0542,  0.4018],
         [-0.0258,  0.0646,  0.4424,  ..., -0.1296,  0.4553,  0.4318]],

        [[-0.4667, -0.4283,  0.1822,  ..., -0.2420,  0.0968, -0.2869],
         [-0.2751, -0.0038, -0.0511,  ..., -0.3580,  0.0973, -0.0737],
         [-0.0602,  0.2109, -0.1980,  ..., -0.2970,  0.0489, -0.0207],
         ...,
         [ 0.3445,  0.0739, -0.3180,  ...,  0.3387,  0.0678, -0.0474],
         [ 0.3084,  0.0659, -0.1441,  ...,  0.1302,  0.2468, -0.2361],
         [ 0.1907,  0.1666,  0.3565,  ..., -0.1928,  0.4073, -0.3253]]])
DESIRED: (shape=torch.Size([2, 15, 114085069]), dtype=torch.float32)
tensor([[[ 0.2483,  0.0480,  0.4171,  ...,  0.0716, -0.2124, -0.0595],
         [-0.1069, -0.1160, -0.0662,  ..., -0.0335,  0.0263,  0.2720],
         [-0.1282, -0.1335, -0.1059,  ...,  0.0734,  0.1271,  0.3878],
         ...,
         [ 0.2381,  0.1792,  0.0072,  ...,  0.1325, -0.1943,  0.4114],
         [ 0.2304,  0.1928,  0.2864,  ...,  0.1973, -0.0905,  0.3997],
         [-0.0258,  0.0646,  0.4424,  ..., -0.1296,  0.4553,  0.4318]],

        [[-0.4667, -0.4283,  0.1822,  ..., -0.2420,  0.0968, -0.2869],
         [-0.2615,  0.0265, -0.0678,  ..., -0.3663,  0.0974, -0.0584],
         [-0.0227,  0.1816, -0.1942,  ..., -0.2377,  0.0280, -0.0589],
         ...,
         [ 0.3263,  0.1061, -0.2495,  ...,  0.3357,  0.0370,  0.0080],
         [ 0.3168,  0.0587, -0.1799,  ...,  0.1533,  0.2353, -0.2298],
         [ 0.1907,  0.1666,  0.3565,  ..., -0.1928,  0.4073, -0.3253]]])

2025-07-26 03:53:33.417162 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 17, 114085069]) != torch.Size([2, 16, 114085069]).
ACTUAL: (shape=torch.Size([2, 17, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [ 0.1964, -0.0468, -0.0813,  ..., -0.4709, -0.0677, -0.1469],
         [-0.1538,  0.3382,  0.3021,  ..., -0.4616, -0.3881,  0.3916],
         ...,
         [-0.4093, -0.1821, -0.3975,  ..., -0.2757, -0.2025, -0.3911],
         [-0.1735,  0.2214,  0.0023,  ..., -0.3277,  0.0058, -0.1336],
         [-0.0202,  0.4837,  0.2622,  ..., -0.3614,  0.1412,  0.0338]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [-0.1410, -0.1533,  0.3122,  ..., -0.1355, -0.0776,  0.3658],
         [ 0.0252,  0.3053,  0.4615,  ...,  0.3213, -0.0747,  0.3675],
         ...,
         [-0.0733,  0.3400,  0.0703,  ...,  0.0763,  0.4376,  0.1887],
         [ 0.2428, -0.1209,  0.1063,  ...,  0.1597, -0.1246, -0.1586],
         [ 0.4483, -0.4204,  0.1298,  ...,  0.2140, -0.4900, -0.3843]]])
DESIRED: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[ 0.4240, -0.2970, -0.3304,  ..., -0.4769,  0.1405, -0.4970],
         [ 0.1964, -0.0468, -0.0813,  ..., -0.4709, -0.0677, -0.1469],
         [-0.1538,  0.3382,  0.3021,  ..., -0.4616, -0.3881,  0.3916],
         ...,
         [-0.4206, -0.2708, -0.2758,  ..., -0.3106, -0.3616, -0.2735],
         [-0.4093, -0.1821, -0.3975,  ..., -0.2757, -0.2025, -0.3911],
         [-0.1735,  0.2214,  0.0023,  ..., -0.3277,  0.0058, -0.1336]],

        [[-0.2491, -0.4513,  0.2152,  ..., -0.4325, -0.0795,  0.3646],
         [-0.1410, -0.1533,  0.3122,  ..., -0.1355, -0.0776,  0.3658],
         [ 0.0252,  0.3053,  0.4615,  ...,  0.3213, -0.0747,  0.3675],
         ...,
         [-0.0931,  0.2673,  0.1931,  ...,  0.1769,  0.2790,  0.2399],
         [-0.0733,  0.3400,  0.0703,  ...,  0.0763,  0.4376,  0.1887],
         [ 0.2428, -0.1209,  0.1063,  ...,  0.1597, -0.1246, -0.1586]]])

2025-07-26 03:54:11.172290 GPU 6 112284 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 17, 114085069]) != torch.Size([2, 16, 114085069]).
ACTUAL: (shape=torch.Size([2, 17, 114085069]), dtype=torch.float32)
tensor([[[-0.1154,  0.0836, -0.2282,  ...,  0.4647, -0.2796,  0.0544],
         [-0.1066,  0.2981, -0.3559,  ...,  0.1195, -0.3129,  0.0949],
         [-0.0371,  0.3247, -0.3450,  ..., -0.0229, -0.3140,  0.1019],
         ...,
         [-0.0424,  0.1734, -0.4617,  ...,  0.2828,  0.3659, -0.2464],
         [-0.2338, -0.0655, -0.4364,  ..., -0.0506,  0.2075,  0.1431],
         [-0.2913, -0.1371, -0.4288,  ..., -0.1507,  0.1600,  0.2599]],

        [[-0.4446,  0.3455, -0.0829,  ..., -0.1216,  0.1255, -0.1123],
         [-0.3232,  0.0871,  0.1010,  ...,  0.1273, -0.2034,  0.0100],
         [-0.2729, -0.0026,  0.1471,  ...,  0.3107, -0.4415,  0.0064],
         ...,
         [-0.0463,  0.3465, -0.0060,  ...,  0.3278, -0.0843,  0.2450],
         [ 0.1863,  0.2330,  0.2181,  ...,  0.1686,  0.0312,  0.4206],
         [ 0.2561,  0.1990,  0.2853,  ...,  0.1208,  0.0658,  0.4733]]])
DESIRED: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[-0.1154,  0.0836, -0.2282,  ...,  0.4647, -0.2796,  0.0544],
         [-0.1097,  0.2230, -0.3112,  ...,  0.2403, -0.3013,  0.0807],
         [-0.1008,  0.4376, -0.4389,  ..., -0.1049, -0.3345,  0.1212],
         ...,
         [-0.0994,  0.3588, -0.4059,  ...,  0.3556,  0.1563, -0.2779],
         [ 0.0246,  0.2569, -0.4706,  ...,  0.3996,  0.4213, -0.3828],
         [-0.1669,  0.0181, -0.4452,  ...,  0.0661,  0.2629,  0.0068]],

        [[-0.4446,  0.3455, -0.0829,  ..., -0.1216,  0.1255, -0.1123],
         [-0.3656,  0.1776,  0.0366,  ...,  0.0402, -0.0883, -0.0328],
         [-0.2442, -0.0808,  0.2206,  ...,  0.2891, -0.4172,  0.0894],
         ...,
         [-0.3007,  0.2517, -0.2460,  ...,  0.2512, -0.0347, -0.0949],
         [-0.1278,  0.3862, -0.0845,  ...,  0.3835, -0.1247,  0.1835],
         [ 0.1049,  0.2727,  0.1396,  ...,  0.2243, -0.0092,  0.3591]]])

2025-07-26 03:55:57.036057 GPU 1 111323 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 17, 114085069]) != torch.Size([2, 16, 114085069]).
ACTUAL: (shape=torch.Size([2, 17, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.1656,  0.0889, -0.0408,  ...,  0.0605, -0.2311, -0.1536],
         [ 0.2641,  0.0239, -0.2911,  ..., -0.2460, -0.2413, -0.3851],
         ...,
         [-0.3066, -0.3022,  0.1497,  ..., -0.1109, -0.1426,  0.0888],
         [-0.3169,  0.0342,  0.1526,  ..., -0.2614, -0.2080, -0.1051],
         [-0.2162,  0.4746,  0.1491,  ..., -0.4546, -0.1744, -0.3383]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.3982,  0.1991,  0.3494,  ..., -0.1775, -0.4021, -0.2294],
         [-0.4195,  0.2824,  0.2174,  ...,  0.0480, -0.3754, -0.1435],
         ...,
         [ 0.2386, -0.0804,  0.2451,  ..., -0.4033, -0.2824,  0.3853],
         [ 0.2619,  0.1356,  0.2350,  ..., -0.2173, -0.2961,  0.2987],
         [ 0.2170,  0.4171,  0.1049,  ...,  0.1054, -0.3253,  0.1478]]])
DESIRED: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[-0.0134,  0.2036,  0.2593,  ...,  0.4351, -0.1169,  0.2536],
         [ 0.1775,  0.0813, -0.0609,  ...,  0.0356, -0.2387, -0.1808],
         [ 0.2396,  0.0383, -0.3012,  ..., -0.2552, -0.1941, -0.3340],
         ...,
         [-0.2535, -0.2986,  0.1463,  ..., -0.1107, -0.0878,  0.0963],
         [-0.3236,  0.0048,  0.1529,  ..., -0.2485, -0.2102, -0.0896],
         [-0.2162,  0.4746,  0.1491,  ..., -0.4546, -0.1744, -0.3383]],

        [[-0.3728,  0.1008,  0.4809,  ..., -0.4370, -0.3924, -0.2331],
         [-0.3999,  0.2057,  0.3406,  ..., -0.1602, -0.4027, -0.2291],
         [-0.4203,  0.2865,  0.1995,  ...,  0.0621, -0.3548, -0.0936],
         ...,
         [ 0.2037, -0.0787,  0.1904,  ..., -0.3644, -0.2878,  0.3668],
         [ 0.2649,  0.1169,  0.2437,  ..., -0.2388, -0.2942,  0.3087],
         [ 0.2170,  0.4171,  0.1049,  ...,  0.1054, -0.3253,  0.1478]]])

2025-07-26 03:56:04.120917 GPU 7 111644 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 17, 114085069]) != torch.Size([2, 16, 114085069]).
ACTUAL: (shape=torch.Size([2, 17, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.2807,  0.0399,  0.1339,  ...,  0.0330, -0.1334, -0.1240],
         [-0.3023, -0.0736, -0.1254,  ..., -0.2870, -0.1023,  0.0279],
         ...,
         [ 0.1529, -0.0547, -0.1906,  ..., -0.2162, -0.1024,  0.1659],
         [-0.0241, -0.0111, -0.1783,  ...,  0.0898, -0.2049, -0.0309],
         [-0.2845, -0.0099, -0.1173,  ...,  0.4390, -0.4081, -0.2868]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.1431,  0.4424,  0.0299,  ...,  0.2804,  0.0336,  0.2731],
         [ 0.2423,  0.3384,  0.2694,  ...,  0.4291, -0.2223,  0.1128],
         ...,
         [-0.3173,  0.3462, -0.0777,  ...,  0.1469, -0.2699, -0.3436],
         [-0.0166,  0.4291, -0.1730,  ...,  0.1111, -0.2589, -0.2174],
         [ 0.4177,  0.4230, -0.3189,  ...,  0.0604, -0.2792,  0.0525]]])
DESIRED: (shape=torch.Size([2, 16, 114085069]), dtype=torch.float32)
tensor([[[-0.2737,  0.1169,  0.4204,  ...,  0.4979, -0.1265, -0.3885],
         [-0.2811,  0.0348,  0.1148,  ...,  0.0020, -0.1339, -0.1064],
         [-0.3120, -0.1058, -0.1472,  ..., -0.2620, -0.0804, -0.0044],
         ...,
         [ 0.1377, -0.0803, -0.1695,  ..., -0.2369, -0.1356,  0.1646],
         [-0.0068, -0.0111, -0.1823,  ...,  0.0665, -0.1914, -0.0138],
         [-0.2845, -0.0099, -0.1173,  ...,  0.4390, -0.4081, -0.2868]],

        [[-0.0539,  0.4449, -0.3595,  ...,  0.0571,  0.3796,  0.4337],
         [ 0.1563,  0.4422,  0.0559,  ...,  0.2953,  0.0105,  0.2624],
         [ 0.2099,  0.2772,  0.2314,  ...,  0.4141, -0.2143,  0.0915],
         ...,
         [-0.2951,  0.2935, -0.0885,  ...,  0.1447, -0.2861, -0.2934],
         [-0.0456,  0.4295, -0.1633,  ...,  0.1145, -0.2575, -0.2354],
         [ 0.4177,  0.4230, -0.3189,  ...,  0.0604, -0.2792,  0.0525]]])

2025-07-26 04:09:23.000637 GPU 6 112284 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753474758 (unix time) try "date -d @1753474758" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b69c) received by PID 112284 (TID 0x7fb0023c2740) from PID 112284 ***]


2025-07-26 04:09:55.523504 GPU 5 111483 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753474793 (unix time) try "date -d @1753474793" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b37b) received by PID 111483 (TID 0x7fc1d7cd6740) from PID 111483 ***]


2025-07-26 04:10:04.284538 GPU 7 111644 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753474791 (unix time) try "date -d @1753474791" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b41c) received by PID 111644 (TID 0x7fab554d6740) from PID 111644 ***]


2025-07-26 04:11:32.975551 GPU 1 111323 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753474884 (unix time) try "date -d @1753474884" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b2db) received by PID 111323 (TID 0x7fdfdc1cb740) from PID 111323 ***]


2025-07-26 04:24:42.585487 GPU 2 111803 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 5368710, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475096 (unix time) try "date -d @1753475096" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b4bb) received by PID 111803 (TID 0x7fb8dda19740) from PID 111803 ***]


2025-07-26 04:25:02.052428 GPU 2 113143 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 5368710, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475207 (unix time) try "date -d @1753475207" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b9f7) received by PID 113143 (TID 0x7ffaad543740) from PID 113143 ***]


2025-07-26 04:26:51.883658 GPU 2 113303 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 64424512, 6, 2]) != torch.Size([2, 64424509, 6, 2]).
ACTUAL: (shape=torch.Size([2, 64424512, 6, 2]), dtype=torch.float16)
tensor([[[[-0.2095,  0.2384],
          [ 0.0430,  0.3435],
          [ 0.2620, -0.0070],
          [-0.0674,  0.1476],
          [ 0.0548, -0.2142],
          [ 0.1464, -0.0303]],

         [[-0.0198,  0.2401],
          [-0.0008,  0.1194],
          [-0.2864, -0.3057],
          [-0.0735, -0.4622],
          [-0.4434,  0.4727],
          [ 0.1357, -0.0999]],

         [[ 0.1207, -0.3311],
          [-0.5532, -0.0823],
          [-0.0863, -0.2245],
          [ 0.2444,  0.3167],
          [-0.3279, -0.1101],
          [-0.0475, -0.0098]],

         ...,

         [[ 0.3525, -0.0730],
          [ 0.1722, -0.3440],
          [-0.1804,  0.4041],
          [ 0.3750,  0.3765],
          [ 0.3477,  0.0957],
          [-0.4731, -0.0813]],

         [[ 0.2443,  0.3313],
          [-0.3967, -0.4868],
          [-0.2418,  0.1880],
          [ 0.1553,  0.0892],
          [ 0.3003,  0.4622],
          [-0.1681,  0.1368]],

         [[ 0.2443,  0.3313],
          [-0.3967, -0.4868],
          [-0.2418,  0.1880],
          [ 0.1553,  0.0892],
          [ 0.3003,  0.4622],
          [-0.1681,  0.1368]]],


        [[[ 0.2321,  0.2181],
          [-0.1309,  0.3098],
          [-0.0632,  0.1904],
          [ 0.1947, -0.0260],
          [ 0.1653,  0.0432],
          [ 0.0864, -0.1750]],

         [[-0.1111,  0.1820],
          [-0.4065,  0.1986],
          [-0.2578,  0.0181],
          [-0.0312,  0.1229],
          [-0.2188, -0.2340],
          [ 0.2864,  0.1554]],

         [[ 0.0914, -0.1566],
          [-0.1920, -0.5488],
          [-0.0405,  0.0136],
          [ 0.3064,  0.3711],
          [-0.0549,  0.1685],
          [-0.3179,  0.3030]],

         ...,

         [[ 0.0576, -0.3428],
          [ 0.2101, -0.3486],
          [ 0.2559,  0.1147],
          [-0.5312, -0.2830],
          [ 0.3093, -0.2776],
          [ 0.0756,  0.0572]],

         [[ 0.1296, -0.0255],
          [ 0.0815, -0.3416],
          [ 0.2981, -0.0361],
          [-0.1278, -0.2030],
          [ 0.1316,  0.1575],
          [ 0.0930, -0.0857]],

         [[ 0.1296, -0.0255],
          [ 0.0815, -0.3416],
          [ 0.2981, -0.0361],
          [-0.1278, -0.2030],
          [ 0.1316,  0.1575],
          [ 0.0930, -0.0857]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 64424509, 6, 2]), dtype=torch.float16)
tensor([[[[-0.2095,  0.2383],
          [ 0.0431,  0.3435],
          [ 0.2620, -0.0070],
          [-0.0674,  0.1476],
          [ 0.0548, -0.2142],
          [ 0.1464, -0.0302]],

         [[-0.0198,  0.2401],
          [-0.0008,  0.1194],
          [-0.2864, -0.3057],
          [-0.0734, -0.4622],
          [-0.4434,  0.4727],
          [ 0.1357, -0.0997]],

         [[ 0.1208, -0.3311],
          [-0.5532, -0.0823],
          [-0.0862, -0.2247],
          [ 0.2444,  0.3169],
          [-0.3276, -0.1100],
          [-0.0476, -0.0100]],

         ...,

         [[ 0.2021, -0.3105],
          [ 0.2322,  0.2362],
          [ 0.3640,  0.1865],
          [-0.3091, -0.3066],
          [-0.0961,  0.1923],
          [ 0.0293, -0.2168]],

         [[ 0.3525, -0.0729],
          [ 0.1722, -0.3440],
          [-0.1805,  0.4041],
          [ 0.3750,  0.3762],
          [ 0.3477,  0.0957],
          [-0.4731, -0.0812]],

         [[ 0.3525, -0.0729],
          [ 0.1722, -0.3440],
          [-0.1805,  0.4041],
          [ 0.3750,  0.3762],
          [ 0.3477,  0.0957],
          [-0.4731, -0.0812]]],


        [[[ 0.2321,  0.2181],
          [-0.1309,  0.3098],
          [-0.0632,  0.1906],
          [ 0.1947, -0.0261],
          [ 0.1653,  0.0432],
          [ 0.0863, -0.1750]],

         [[-0.1112,  0.1819],
          [-0.4065,  0.1986],
          [-0.2581,  0.0181],
          [-0.0311,  0.1229],
          [-0.2188, -0.2340],
          [ 0.2861,  0.1554]],

         [[ 0.0916, -0.1566],
          [-0.1921, -0.5488],
          [-0.0405,  0.0134],
          [ 0.3064,  0.3711],
          [-0.0550,  0.1686],
          [-0.3179,  0.3030]],

         ...,

         [[ 0.1195, -0.1643],
          [-0.3906, -0.1169],
          [-0.2939, -0.3809],
          [ 0.3384,  0.1929],
          [-0.4170, -0.1515],
          [ 0.3826,  0.4211]],

         [[ 0.0575, -0.3428],
          [ 0.2101, -0.3486],
          [ 0.2561,  0.1146],
          [-0.5312, -0.2830],
          [ 0.3093, -0.2776],
          [ 0.0755,  0.0570]],

         [[ 0.0575, -0.3428],
          [ 0.2101, -0.3486],
          [ 0.2561,  0.1146],
          [-0.5312, -0.2830],
          [ 0.3093, -0.2776],
          [ 0.0755,  0.0570]]]], dtype=torch.float16)

2025-07-26 04:26:57.997801 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 64424512, 6, 2]) != torch.Size([2, 64424509, 6, 2]).
ACTUAL: (shape=torch.Size([2, 64424512, 6, 2]), dtype=torch.float16)
tensor([[[[ 0.3545, -0.2218],
          [ 0.1439, -0.4885],
          [-0.0654,  0.1390],
          [-0.3005, -0.1571],
          [ 0.0537,  0.2861],
          [-0.4658, -0.0504]],

         [[-0.5454,  0.2534],
          [-0.3628,  0.4075],
          [-0.0558, -0.1515],
          [-0.3418,  0.1858],
          [ 0.3264, -0.3909],
          [ 0.0706,  0.0012]],

         [[ 0.1606, -0.2468],
          [-0.2078,  0.2443],
          [ 0.0402,  0.0508],
          [ 0.3660, -0.4150],
          [-0.0624,  0.1411],
          [ 0.1348,  0.3701]],

         ...,

         [[-0.2595, -0.4197],
          [-0.0032,  0.1387],
          [-0.4260, -0.3342],
          [-0.3367,  0.2415],
          [-0.2520,  0.1893],
          [-0.1290,  0.0373]],

         [[-0.1074,  0.1302],
          [ 0.3738,  0.0975],
          [-0.3916, -0.2573],
          [ 0.4414, -0.0444],
          [-0.3867, -0.3215],
          [-0.0586, -0.0513]],

         [[-0.1074,  0.1302],
          [ 0.3738,  0.0975],
          [-0.3916, -0.2573],
          [ 0.4414, -0.0444],
          [-0.3867, -0.3215],
          [-0.0586, -0.0513]]],


        [[[-0.1702,  0.2542],
          [-0.5488,  0.3542],
          [ 0.4314, -0.6411],
          [-0.2128,  0.1343],
          [ 0.1434,  0.3472],
          [-0.4458,  0.1890]],

         [[ 0.1930,  0.0698],
          [ 0.0784,  0.3308],
          [ 0.1134, -0.1714],
          [-0.4670,  0.2844],
          [-0.1560, -0.2693],
          [ 0.1377, -0.0301]],

         [[-0.4810, -0.2422],
          [ 0.1231, -0.4990],
          [ 0.2485,  0.4788],
          [ 0.1112, -0.0503],
          [ 0.1786,  0.2324],
          [ 0.1602,  0.2688]],

         ...,

         [[ 0.4260,  0.3042],
          [ 0.4468, -0.0338],
          [-0.0847,  0.1034],
          [ 0.0204,  0.2352],
          [ 0.4980, -0.1973],
          [ 0.3652,  0.1046]],

         [[ 0.0771,  0.3533],
          [ 0.4170, -0.1934],
          [-0.1226,  0.0894],
          [-0.5059, -0.4753],
          [ 0.4126,  0.1768],
          [ 0.0850,  0.0190]],

         [[ 0.0771,  0.3533],
          [ 0.4170, -0.1934],
          [-0.1226,  0.0894],
          [-0.5059, -0.4753],
          [ 0.4126,  0.1768],
          [ 0.0850,  0.0190]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 64424509, 6, 2]), dtype=torch.float16)
tensor([[[[ 0.3545, -0.2218],
          [ 0.1439, -0.4885],
          [-0.0655,  0.1392],
          [-0.3003, -0.1572],
          [ 0.0538,  0.2861],
          [-0.4658, -0.0504]],

         [[-0.5454,  0.2537],
          [-0.3630,  0.4075],
          [-0.0558, -0.1515],
          [-0.3418,  0.1859],
          [ 0.3264, -0.3906],
          [ 0.0706,  0.0012]],

         [[ 0.1606, -0.2468],
          [-0.2076,  0.2441],
          [ 0.0402,  0.0508],
          [ 0.3657, -0.4150],
          [-0.0624,  0.1412],
          [ 0.1349,  0.3699]],

         ...,

         [[-0.2595, -0.4197],
          [-0.0032,  0.1387],
          [-0.4260, -0.3342],
          [-0.3367,  0.2413],
          [-0.2520,  0.1893],
          [-0.1290,  0.0373]],

         [[-0.1074,  0.1302],
          [ 0.3740,  0.0974],
          [-0.3916, -0.2576],
          [ 0.4414, -0.0443],
          [-0.3867, -0.3215],
          [-0.0586, -0.0513]],

         [[-0.1074,  0.1302],
          [ 0.3740,  0.0974],
          [-0.3916, -0.2576],
          [ 0.4414, -0.0443],
          [-0.3867, -0.3215],
          [-0.0586, -0.0513]]],


        [[[-0.1702,  0.2542],
          [-0.5488,  0.3545],
          [ 0.4314, -0.6411],
          [-0.2128,  0.1342],
          [ 0.1434,  0.3472],
          [-0.4458,  0.1890]],

         [[ 0.1930,  0.0699],
          [ 0.0785,  0.3308],
          [ 0.1133, -0.1714],
          [-0.4668,  0.2844],
          [-0.1560, -0.2690],
          [ 0.1377, -0.0303]],

         [[-0.4810, -0.2421],
          [ 0.1232, -0.4990],
          [ 0.2485,  0.4785],
          [ 0.1111, -0.0502],
          [ 0.1786,  0.2324],
          [ 0.1602,  0.2688]],

         ...,

         [[ 0.4260,  0.3042],
          [ 0.4468, -0.0338],
          [-0.0847,  0.1033],
          [ 0.0203,  0.2352],
          [ 0.4980, -0.1973],
          [ 0.3652,  0.1046]],

         [[ 0.0771,  0.3533],
          [ 0.4170, -0.1934],
          [-0.1226,  0.0895],
          [-0.5059, -0.4753],
          [ 0.4126,  0.1768],
          [ 0.0850,  0.0190]],

         [[ 0.0771,  0.3533],
          [ 0.4170, -0.1934],
          [-0.1226,  0.0895],
          [-0.5059, -0.4753],
          [ 0.4126,  0.1768],
          [ 0.0850,  0.0190]]]], dtype=torch.float16)

2025-07-26 04:27:17.095128 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 64424512, 6, 2]) != torch.Size([2, 64424509, 6, 2]).
ACTUAL: (shape=torch.Size([2, 64424512, 6, 2]), dtype=torch.float16)
tensor([[[[ 0.3545, -0.2218],
          [ 0.0564, -0.3445],
          [-0.2065,  0.2642],
          [-0.4246,  0.0194],
          [ 0.0130,  0.0269],
          [-0.0126,  0.1188]],

         [[-0.4373,  0.1829],
          [-0.2001,  0.2908],
          [ 0.0177, -0.1224],
          [-0.3057,  0.2026],
          [ 0.0912, -0.3096],
          [ 0.2544,  0.0813]],

         [[ 0.1055, -0.2015],
          [-0.2253,  0.1904],
          [ 0.1240, -0.1144],
          [ 0.3130, -0.4595],
          [-0.0114,  0.0911],
          [ 0.1975,  0.1279]],

         ...,

         [[-0.2595, -0.4197],
          [-0.0439,  0.0698],
          [-0.3623, -0.2365],
          [-0.4514,  0.4346],
          [-0.2083,  0.0672],
          [-0.2495,  0.0026]],

         [[-0.1074,  0.1302],
          [ 0.1682,  0.0790],
          [-0.3167, -0.2705],
          [ 0.4758, -0.3257],
          [-0.2339, -0.0601],
          [-0.0362, -0.2152]],

         [[-0.1074,  0.1302],
          [ 0.1682,  0.0790],
          [-0.3167, -0.2705],
          [ 0.4758, -0.3257],
          [-0.2339, -0.0601],
          [-0.0362, -0.2152]]],


        [[[-0.1702,  0.2542],
          [-0.4495,  0.1879],
          [ 0.3228, -0.4849],
          [ 0.0315,  0.3374],
          [-0.1238,  0.1578],
          [ 0.0791, -0.0330]],

         [[ 0.1158,  0.0225],
          [ 0.0127,  0.2401],
          [ 0.2222,  0.0679],
          [-0.3967,  0.2074],
          [-0.1444, -0.0565],
          [-0.1305, -0.1849]],

         [[-0.3848, -0.1581],
          [ 0.0442, -0.2952],
          [ 0.2407,  0.2493],
          [ 0.2939, -0.0891],
          [ 0.0179,  0.2003],
          [-0.0490,  0.3022]],

         ...,

         [[ 0.4260,  0.3042],
          [ 0.3838, -0.0946],
          [-0.0527, -0.1142],
          [ 0.2957,  0.3633],
          [ 0.1747, -0.2123],
          [ 0.3699,  0.3591]],

         [[ 0.0771,  0.3533],
          [ 0.3438, -0.0967],
          [-0.1085,  0.1875],
          [-0.4431, -0.3506],
          [ 0.1236, -0.0266],
          [ 0.1377, -0.1992]],

         [[ 0.0771,  0.3533],
          [ 0.3438, -0.0967],
          [-0.1085,  0.1875],
          [-0.4431, -0.3506],
          [ 0.1236, -0.0266],
          [ 0.1377, -0.1992]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 64424509, 6, 2]), dtype=torch.float16)
tensor([[[[ 0.0838, -0.1270],
          [ 0.0568, -0.2805],
          [ 0.0096,  0.0336],
          [-0.2502, -0.1849],
          [-0.0067, -0.0138],
          [-0.1039,  0.0141]],

         [[-0.3308,  0.3130],
          [-0.4443,  0.4268],
          [-0.2556, -0.0904],
          [-0.2852,  0.2971],
          [ 0.3428, -0.3416],
          [ 0.1342,  0.1074]],

         [[-0.0829, -0.1533],
          [-0.2949,  0.1962],
          [ 0.1447,  0.1168],
          [ 0.2983, -0.2637],
          [-0.2198,  0.2708],
          [ 0.2327,  0.0675]],

         ...,

         [[ 0.3264,  0.4368],
          [-0.4260, -0.3003],
          [-0.1394, -0.4424],
          [ 0.0259,  0.0316],
          [-0.3660, -0.2788],
          [ 0.1948,  0.1995]],

         [[-0.2002, -0.2920],
          [-0.0252,  0.1230],
          [-0.4124, -0.2358],
          [-0.3574,  0.2295],
          [-0.2277,  0.1912],
          [-0.1893,  0.0199]],

         [[-0.2002, -0.2920],
          [-0.0252,  0.1230],
          [-0.4124, -0.2358],
          [-0.3574,  0.2295],
          [-0.2277,  0.1912],
          [-0.1893,  0.0199]]],


        [[[-0.1366, -0.0171],
          [-0.2496,  0.3552],
          [ 0.3735, -0.3989],
          [-0.1260,  0.0030],
          [-0.0877,  0.1493],
          [-0.0967,  0.1219]],

         [[-0.0628,  0.2429],
          [ 0.1340,  0.2512],
          [-0.0803, -0.0618],
          [-0.4666,  0.3918],
          [ 0.0410, -0.0602],
          [-0.0523, -0.2239]],

         [[-0.3044,  0.1354],
          [ 0.1832, -0.4077],
          [ 0.0317,  0.2830],
          [ 0.0778, -0.0196],
          [-0.0302,  0.2174],
          [ 0.0145,  0.1135]],

         ...,

         [[ 0.3508,  0.2114],
          [-0.4783,  0.2749],
          [-0.1505, -0.2246],
          [ 0.2225, -0.0657],
          [-0.3552,  0.4043],
          [ 0.4182, -0.1603]],

         [[ 0.3887,  0.1181],
          [ 0.4187, -0.0148],
          [-0.0123,  0.1676],
          [ 0.0825,  0.2417],
          [ 0.4341, -0.3176],
          [ 0.3674,  0.2319]],

         [[ 0.3887,  0.1181],
          [ 0.4187, -0.0148],
          [-0.0123,  0.1676],
          [ 0.0825,  0.2417],
          [ 0.4341, -0.3176],
          [ 0.3674,  0.2319]]]], dtype=torch.float16)

2025-07-26 04:27:34.882955 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 64424512, 6, 2]) != torch.Size([2, 64424509, 6, 2]).
ACTUAL: (shape=torch.Size([2, 64424512, 6, 2]), dtype=torch.float16)
tensor([[[[ 3.5449e-01, -2.2180e-01],
          [ 9.8999e-02, -3.9282e-01],
          [-8.8867e-02,  9.7656e-02],
          [-2.4170e-01, -1.3733e-01],
          [ 4.5319e-02,  2.2192e-01],
          [-4.6582e-01, -5.0415e-02]],

         [[-4.3726e-01,  1.8286e-01],
          [-2.5928e-01,  3.0005e-01],
          [-9.3384e-02, -7.5684e-02],
          [-2.4963e-01,  6.4209e-02],
          [ 2.4854e-01, -2.9419e-01],
          [ 3.5675e-02,  4.4495e-02]],

         [[ 1.0553e-01, -2.0154e-01],
          [-1.8176e-01,  2.0068e-01],
          [ 3.0945e-02, -1.9363e-02],
          [ 2.2302e-01, -2.5171e-01],
          [-2.8086e-04,  9.4910e-02],
          [ 1.0626e-01,  2.9028e-01]],

         ...,

         [[-2.5952e-01, -4.1968e-01],
          [-3.6438e-02,  9.1064e-02],
          [-4.0234e-01, -2.3596e-01],
          [-3.3862e-01,  1.8848e-01],
          [-2.4414e-01,  1.5002e-01],
          [-1.2903e-01,  3.7292e-02]],

         [[-1.0736e-01,  1.3025e-01],
          [ 2.8052e-01,  6.6040e-02],
          [-2.6294e-01, -2.4609e-01],
          [ 3.2886e-01, -6.5552e-02],
          [-3.2910e-01, -2.6147e-01],
          [-5.8624e-02, -5.1331e-02]],

         [[-1.0736e-01,  1.3025e-01],
          [ 2.8052e-01,  6.6040e-02],
          [-2.6294e-01, -2.4609e-01],
          [ 3.2886e-01, -6.5552e-02],
          [-3.2910e-01, -2.6147e-01],
          [-5.8624e-02, -5.1331e-02]]],


        [[[-1.7017e-01,  2.5415e-01],
          [-4.6533e-01,  2.6782e-01],
          [ 3.3789e-01, -4.8853e-01],
          [-1.5039e-01,  8.5449e-02],
          [ 8.8989e-02,  2.7759e-01],
          [-4.4580e-01,  1.8896e-01]],

         [[ 1.1584e-01,  2.2537e-02],
          [ 7.3975e-02,  2.4963e-01],
          [ 1.1823e-01, -7.7576e-02],
          [-3.4912e-01,  1.7371e-01],
          [-1.1243e-01, -1.7517e-01],
          [ 1.1182e-01,  2.6199e-02]],

         [[-3.8477e-01, -1.5808e-01],
          [ 1.1273e-01, -3.4180e-01],
          [ 2.2388e-01,  2.9492e-01],
          [ 5.3406e-02,  6.3599e-02],
          [ 1.1731e-01,  1.9397e-01],
          [ 1.2378e-01,  1.9910e-01]],

         ...,

         [[ 4.2603e-01,  3.0420e-01],
          [ 3.9771e-01, -6.2683e-02],
          [-2.0386e-02,  1.1127e-01],
          [ 3.9795e-02,  2.1741e-01],
          [ 4.2163e-01, -1.5674e-01],
          [ 3.6523e-01,  1.0455e-01]],

         [[ 7.7087e-02,  3.5327e-01],
          [ 3.6279e-01, -1.2805e-01],
          [-1.2012e-01,  3.8757e-02],
          [-4.1797e-01, -4.0869e-01],
          [ 3.3325e-01,  1.0461e-01],
          [ 8.5022e-02,  1.8997e-02]],

         [[ 7.7087e-02,  3.5327e-01],
          [ 3.6279e-01, -1.2805e-01],
          [-1.2012e-01,  3.8757e-02],
          [-4.1797e-01, -4.0869e-01],
          [ 3.3325e-01,  1.0461e-01],
          [ 8.5022e-02,  1.8997e-02]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 64424509, 6, 2]), dtype=torch.float16)
tensor([[[[ 3.5449e-01, -2.2180e-01],
          [ 9.8999e-02, -3.9282e-01],
          [-8.8867e-02,  9.7656e-02],
          [-2.4170e-01, -1.3733e-01],
          [ 4.5319e-02,  2.2192e-01],
          [-4.6582e-01, -5.0415e-02]],

         [[-4.3726e-01,  1.8286e-01],
          [-2.5928e-01,  3.0005e-01],
          [-9.3384e-02, -7.5684e-02],
          [-2.4963e-01,  6.4209e-02],
          [ 2.4854e-01, -2.9419e-01],
          [ 3.5675e-02,  4.4495e-02]],

         [[ 1.0553e-01, -2.0154e-01],
          [-1.8176e-01,  2.0068e-01],
          [ 3.0945e-02, -1.9363e-02],
          [ 2.2302e-01, -2.5171e-01],
          [-2.8086e-04,  9.4910e-02],
          [ 1.0626e-01,  2.9028e-01]],

         ...,

         [[-2.5952e-01, -4.1968e-01],
          [-3.6438e-02,  9.1064e-02],
          [-4.0234e-01, -2.3596e-01],
          [-3.3862e-01,  1.8848e-01],
          [-2.4414e-01,  1.5002e-01],
          [-1.2903e-01,  3.7292e-02]],

         [[ 2.5830e-01, -2.6880e-01],
          [ 1.1847e-01,  1.9006e-01],
          [ 4.3213e-01, -1.7810e-01],
          [-1.1163e-01, -2.2327e-01],
          [-2.6782e-01, -3.2593e-01],
          [ 1.5466e-01,  4.9243e-01]],

         [[ 2.5830e-01, -2.6880e-01],
          [ 1.1847e-01,  1.9006e-01],
          [ 4.3213e-01, -1.7810e-01],
          [-1.1163e-01, -2.2327e-01],
          [-2.6782e-01, -3.2593e-01],
          [ 1.5466e-01,  4.9243e-01]]],


        [[[-1.7017e-01,  2.5415e-01],
          [-4.6533e-01,  2.6782e-01],
          [ 3.3789e-01, -4.8853e-01],
          [-1.5039e-01,  8.5449e-02],
          [ 8.8989e-02,  2.7759e-01],
          [-4.4580e-01,  1.8896e-01]],

         [[ 1.1584e-01,  2.2537e-02],
          [ 7.3975e-02,  2.4963e-01],
          [ 1.1823e-01, -7.7576e-02],
          [-3.4912e-01,  1.7371e-01],
          [-1.1243e-01, -1.7517e-01],
          [ 1.1182e-01,  2.6199e-02]],

         [[-3.8477e-01, -1.5808e-01],
          [ 1.1273e-01, -3.4180e-01],
          [ 2.2388e-01,  2.9492e-01],
          [ 5.3406e-02,  6.3599e-02],
          [ 1.1731e-01,  1.9397e-01],
          [ 1.2378e-01,  1.9897e-01]],

         ...,

         [[ 4.2603e-01,  3.0420e-01],
          [ 3.9771e-01, -6.2683e-02],
          [-2.0386e-02,  1.1127e-01],
          [ 3.9795e-02,  2.1741e-01],
          [ 4.2163e-01, -1.5674e-01],
          [ 3.6523e-01,  1.0455e-01]],

         [[ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00]]]], dtype=torch.float16)

2025-07-26 04:27:51.854298 GPU 3 112122 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475280 (unix time) try "date -d @1753475280" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b5fa) received by PID 112122 (TID 0x7f9c9dfec740) from PID 112122 ***]


2025-07-26 04:28:05.925525 GPU 3 113461 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475393 (unix time) try "date -d @1753475393" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bb35) received by PID 113461 (TID 0x7fc25ba55740) from PID 113461 ***]


2025-07-26 04:28:32.764708 GPU 2 113303 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475323 (unix time) try "date -d @1753475323" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ba97) received by PID 113303 (TID 0x7fe53e9a7740) from PID 113303 ***]


2025-07-26 04:28:48.480182 GPU 2 113628 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475430 (unix time) try "date -d @1753475430" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bbdc) received by PID 113628 (TID 0x7fa32fa3c740) from PID 113628 ***]


2025-07-26 04:29:57.764799 GPU 3 113788 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475508 (unix time) try "date -d @1753475508" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bc7c) received by PID 113788 (TID 0x7fd0acb06740) from PID 113788 ***]


2025-07-26 04:30:35.151482 GPU 2 113948 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475529 (unix time) try "date -d @1753475529" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bd1c) received by PID 113948 (TID 0x7f2d385db740) from PID 113948 ***]


2025-07-26 04:31:52.687757 GPU 3 114108 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475621 (unix time) try "date -d @1753475621" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bdbc) received by PID 114108 (TID 0x7fd469a5b740) from PID 114108 ***]


2025-07-26 04:32:13.916931 GPU 2 114268 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475626 (unix time) try "date -d @1753475626" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1be5c) received by PID 114268 (TID 0x7f962199e740) from PID 114268 ***]


2025-07-26 04:33:45.961743 GPU 3 114437 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475731 (unix time) try "date -d @1753475731" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bf05) received by PID 114437 (TID 0x7f97c25ee740) from PID 114437 ***]


2025-07-26 04:33:51.417184 GPU 2 114595 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475738 (unix time) try "date -d @1753475738" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bfa3) received by PID 114595 (TID 0x7f90ca619740) from PID 114595 ***]


2025-07-26 04:34:06.006526 GPU 6 112503 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475657 (unix time) try "date -d @1753475657" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b777) received by PID 112503 (TID 0x7f7ea2719740) from PID 112503 ***]


2025-07-26 04:34:21.641488 GPU 6 114760 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475761 (unix time) try "date -d @1753475761" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c048) received by PID 114760 (TID 0x7f900ad81740) from PID 114760 ***]


2025-07-26 04:34:54.808111 GPU 5 112749 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475709 (unix time) try "date -d @1753475709" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b86d) received by PID 112749 (TID 0x7fb5f074e740) from PID 112749 ***]


2025-07-26 04:35:13.573122 GPU 5 114925 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475810 (unix time) try "date -d @1753475810" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c0ed) received by PID 114925 (TID 0x7f4287383740) from PID 114925 ***]


2025-07-26 04:35:28.535054 GPU 7 112661 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475740 (unix time) try "date -d @1753475740" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b815) received by PID 112661 (TID 0x7f86460d5740) from PID 112661 ***]


2025-07-26 04:35:36.267352 GPU 3 115087 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475832 (unix time) try "date -d @1753475832" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c18f) received by PID 115087 (TID 0x7fef437a4740) from PID 115087 ***]


2025-07-26 04:35:42.746813 GPU 2 115252 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475837 (unix time) try "date -d @1753475837" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c234) received by PID 115252 (TID 0x7f0a0d96d740) from PID 115252 ***]


2025-07-26 04:35:45.684725 GPU 7 115403 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475851 (unix time) try "date -d @1753475851" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c2cb) received by PID 115403 (TID 0x7fae80029740) from PID 115403 ***]


2025-07-26 04:36:06.765980 GPU 6 115570 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475882 (unix time) try "date -d @1753475882" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c372) received by PID 115570 (TID 0x7f4932369740) from PID 115570 ***]


2025-07-26 04:36:34.915870 GPU 1 112979 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753475895 (unix time) try "date -d @1753475895" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b953) received by PID 112979 (TID 0x7fea2b8ac740) from PID 112979 ***]


2025-07-26 04:37:22.268225 GPU 2 116051 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:37:36.087188 GPU 7 116211 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:37:47.909666 GPU 4 111964 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:38:07.271751 GPU 6 116377 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:38:12.988155 GPU 4 116536 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:38:20.733036 GPU 1 116694 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:39:35.216973 GPU 6 117192 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:39:48.930816 GPU 4 117352 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:40:02.992656 GPU 1 117511 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:40:10.465085 GPU 5 115730 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:40:17.007298 GPU 3 115892 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:40:36.052455 GPU 5 117671 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:41:15.250432 GPU 4 118152 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:41:31.575882 GPU 1 118318 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:42:02.454970 GPU 5 118486 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476250 (unix time) try "date -d @1753476250" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ced6) received by PID 118486 (TID 0x7fa021487740) from PID 118486 ***]


2025-07-26 04:42:03.408954 GPU 2 116858 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476154 (unix time) try "date -d @1753476154" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c87a) received by PID 116858 (TID 0x7f01e5cbe740) from PID 116858 ***]


2025-07-26 04:42:28.078950 GPU 7 117017 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476181 (unix time) try "date -d @1753476181" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c919) received by PID 117017 (TID 0x7f680f992740) from PID 117017 ***]


2025-07-26 04:42:39.522063 GPU 2 118648 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476264 (unix time) try "date -d @1753476264" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cf78) received by PID 118648 (TID 0x7f746b604740) from PID 118648 ***]


2025-07-26 04:42:53.132370 GPU 4 118808 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476268 (unix time) try "date -d @1753476268" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d018) received by PID 118808 (TID 0x7efe6d3fb740) from PID 118808 ***]


2025-07-26 04:43:03.400439 GPU 1 118967 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476277 (unix time) try "date -d @1753476277" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d0b7) received by PID 118967 (TID 0x7fae65b0f740) from PID 118967 ***]


2025-07-26 04:43:06.144101 GPU 7 119062 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 41860330 / 2281701400 (1.8%)
Greatest absolute difference: 1.5206817388534546 at index (0, 3583722, 0, 9) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 0, 7) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([2, 11408507, 10, 10]), dtype=torch.float32)
tensor([[[[-0.1947, -0.0059, -0.4735,  ..., -0.5561,  0.1720, -0.0424],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.1718,  0.1284, -0.4012,  ..., -0.3251, -0.2745,  0.4954],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.1672, -0.0968, -0.1730,  ...,  0.1061,  0.8642, -0.5937],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 11408507, 10, 10]), dtype=torch.float32)
tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0460, -0.3968, -0.1432,  ..., -0.4140,  0.4109, -0.2080],
          ...,
          [ 0.3319,  0.1110, -0.1713,  ...,  0.3962, -0.0367, -0.2300],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1817,  0.0142, -0.1981,  ..., -0.1558, -0.3928,  0.6177],
          ...,
          [ 0.6632, -0.2777,  0.1505,  ..., -0.1407,  0.6304,  0.6090],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1802, -0.1371, -0.2728,  ...,  0.2771,  0.8009, -0.7079],
          ...,
          [ 0.3040,  0.3829, -0.2463,  ...,  0.2267, -0.5413, -0.6501],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0440, -0.3985,  0.0914,  ...,  0.3137,  0.4641,  0.1953],
          ...,
          [ 0.2688,  0.2256, -0.1844,  ..., -0.3369, -0.2077,  0.1892],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.8297,  0.2983, -0.3008,  ...,  0.1786, -0.0190,  0.1606],
          ...,
          [ 0.5650,  0.1329, -0.2865,  ...,  0.3334,  0.1914,  0.3711],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2539, -0.1029, -0.7848,  ...,  0.1269,  0.0401, -0.9342],
          ...,
          [ 0.3054,  0.5145,  0.7815,  ...,  0.5862, -0.1362,  0.1167],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.3495, -0.0450,  0.2948,  ..., -0.4009, -0.1968,  0.1152],
          ...,
          [-0.0530, -0.5832, -0.1814,  ..., -0.4312, -0.8817,  0.1228],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.7436,  0.1816,  0.1024,  ..., -0.5149, -0.7706, -0.5410],
          ...,
          [ 0.1703, -0.0838, -0.2346,  ...,  0.5257, -0.0349, -0.1303],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0646,  0.4922,  0.1087,  ...,  0.2139, -0.4681, -0.0951],
          ...,
          [-0.4478,  0.2663,  0.7038,  ...,  0.4483, -0.3017, -0.3871],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1863,  0.6944,  0.5316,  ...,  0.4283,  0.6482,  0.3189],
          ...,
          [ 0.0782,  0.1879,  0.4636,  ...,  0.5969,  0.8339,  0.2431],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0903, -0.2084, -0.4812,  ...,  0.3402, -0.2333, -0.4765],
          ...,
          [ 0.4350, -0.2119, -0.1989,  ..., -0.4901, -0.0174, -0.0579],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2503,  0.5014, -0.2145,  ..., -0.1511, -0.1664, -0.2535],
          ...,
          [-0.0138,  0.1755, -0.0305,  ..., -0.5038, -0.0423,  0.3738],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])

2025-07-26 04:44:16.168079 GPU 5 119310 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476368 (unix time) try "date -d @1753476368" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d20e) received by PID 119310 (TID 0x7f959b11e740) from PID 119310 ***]


2025-07-26 04:44:30.681388 GPU 2 119485 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476379 (unix time) try "date -d @1753476379" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d2bd) received by PID 119485 (TID 0x7fc5df6e5740) from PID 119485 ***]


2025-07-26 04:44:33.039318 GPU 4 119573 test begin: paddle.nn.functional.interpolate(Tensor([2, 1140851, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476367 (unix time) try "date -d @1753476367" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d315) received by PID 119573 (TID 0x7fe9310d3740) from PID 119573 ***]


2025-07-26 04:44:42.095400 GPU 1 119808 test begin: paddle.nn.functional.interpolate(Tensor([2, 1140851, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476369 (unix time) try "date -d @1753476369" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d400) received by PID 119808 (TID 0x7f1a86692740) from PID 119808 ***]


2025-07-26 04:45:22.737848 GPU 6 117992 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 6, 34225524]) != torch.Size([2, 2, 6, 34225521]).
ACTUAL: (shape=torch.Size([2, 2, 6, 34225524]), dtype=torch.float32)
tensor([[[[ 0.1318, -0.3634, -0.2819,  ...,  0.3724,  0.3724,  0.1748],
          [-0.1748, -0.2082, -0.3034,  ...,  0.1721,  0.1721, -0.2674],
          [-0.1255,  0.1268,  0.0684,  ..., -0.2497, -0.2497,  0.3140],
          [-0.3451, -0.1540, -0.1167,  ..., -0.4953, -0.4953, -0.1388],
          [ 0.3750, -0.2024, -0.0560,  ..., -0.2155, -0.2155,  0.1255],
          [-0.0961, -0.0761,  0.0551,  ..., -0.3610, -0.3610,  0.0936]],

         [[-0.4114,  0.2595,  0.3521,  ..., -0.4780, -0.4780,  0.0561],
          [-0.0739, -0.0438, -0.1359,  ..., -0.0397, -0.0397, -0.3840],
          [-0.0779,  0.0319, -0.2049,  ..., -0.0710, -0.0710, -0.1791],
          [-0.1853, -0.2084, -0.4444,  ...,  0.1515,  0.1515, -0.3907],
          [ 0.1698,  0.1246, -0.1708,  ...,  0.0857,  0.0857,  0.0045],
          [-0.2636,  0.1047, -0.0374,  ...,  0.2913,  0.2913, -0.2072]]],


        [[[ 0.1453,  0.3104, -0.3413,  ...,  0.4513,  0.4513,  0.2318],
          [-0.2615, -0.2038,  0.1565,  ...,  0.4255,  0.4255,  0.2374],
          [ 0.0148, -0.1925,  0.0118,  ...,  0.0632,  0.0632, -0.2090],
          [ 0.2304,  0.4684,  0.1530,  ...,  0.2474,  0.2474,  0.0014],
          [ 0.3678,  0.0839,  0.0566,  ..., -0.3939, -0.3939, -0.3037],
          [-0.1426, -0.1696, -0.1298,  ..., -0.2407, -0.2407, -0.2078]],

         [[-0.0201, -0.1254,  0.0930,  ...,  0.1473,  0.1473,  0.0291],
          [-0.3982,  0.0874,  0.0441,  ...,  0.1057,  0.1057, -0.2663],
          [ 0.1659, -0.1247, -0.2169,  ...,  0.1204,  0.1204,  0.1475],
          [-0.3899, -0.2087,  0.0871,  ..., -0.3792, -0.3792,  0.0683],
          [-0.0382,  0.0064,  0.2615,  ..., -0.0711, -0.0711,  0.1841],
          [ 0.2444,  0.1025,  0.1017,  ..., -0.1215, -0.1215,  0.1797]]]])
DESIRED: (shape=torch.Size([2, 2, 6, 34225521]), dtype=torch.float32)
tensor([[[[-0.1081, -0.2445, -0.2154,  ...,  0.2404,  0.2404,  0.2404],
          [-0.1565, -0.2992, -0.4749,  ...,  0.2700,  0.2700,  0.2700],
          [-0.2599,  0.2736, -0.0405,  ..., -0.3449, -0.3449, -0.3449],
          [-0.2053, -0.0783, -0.0866,  ..., -0.2621, -0.2621, -0.2621],
          [ 0.2495, -0.2639, -0.3570,  ..., -0.4255, -0.4255, -0.4255],
          [-0.0959, -0.1379,  0.1633,  ..., -0.2867, -0.2867, -0.2867]],

         [[-0.2188,  0.2625,  0.2503,  ..., -0.2904, -0.2904, -0.2904],
          [ 0.0534, -0.2131,  0.0483,  ..., -0.1020, -0.1020, -0.1020],
          [-0.1537,  0.2563, -0.1766,  ...,  0.1106,  0.1106,  0.1106],
          [ 0.0378, -0.2183, -0.4156,  ...,  0.1478,  0.1478,  0.1478],
          [ 0.0986,  0.1317, -0.1828,  ...,  0.0584,  0.0584,  0.0584],
          [-0.0218,  0.2722,  0.1818,  ...,  0.1792,  0.1792,  0.1792]]],


        [[[-0.0116,  0.3125, -0.1081,  ...,  0.4179,  0.4179,  0.4179],
          [-0.2516, -0.3052,  0.1214,  ...,  0.4626,  0.4626,  0.4626],
          [-0.0258, -0.2844,  0.2303,  ..., -0.0852, -0.0852, -0.0852],
          [ 0.2517,  0.2827,  0.1098,  ...,  0.0733,  0.0733,  0.0733],
          [ 0.2284,  0.3404,  0.0083,  ..., -0.4533, -0.4533, -0.4533],
          [ 0.0670, -0.3207, -0.1470,  ..., -0.3271, -0.3271, -0.3271]],

         [[ 0.0305, -0.3573, -0.1598,  ..., -0.0470, -0.0470, -0.0470],
          [-0.1708,  0.1147,  0.2446,  ...,  0.3762,  0.3762,  0.3762],
          [ 0.0944, -0.1261, -0.1859,  ...,  0.0401,  0.0401,  0.0401],
          [-0.2441,  0.0069,  0.0498,  ..., -0.3871, -0.3871, -0.3871],
          [-0.1061, -0.0477,  0.3017,  ...,  0.0948,  0.0948,  0.0948],
          [ 0.0375,  0.1962,  0.0754,  ...,  0.1172,  0.1172,  0.1172]]]])

2025-07-26 04:45:44.110868 GPU 6 117992 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 6, 34225524]) != torch.Size([2, 2, 6, 34225521]).
ACTUAL: (shape=torch.Size([2, 2, 6, 34225524]), dtype=torch.float32)
tensor([[[[ 0.1318, -0.3634, -0.2819,  ..., -0.3954, -0.3954,  0.1748],
          [-0.1681, -0.2252, -0.3752,  ...,  0.1045,  0.1045, -0.3576],
          [-0.2533,  0.1155,  0.0199,  ..., -0.3106, -0.3106,  0.2885],
          [-0.0799, -0.1789,  0.0451,  ..., -0.3522, -0.3522,  0.0822],
          [ 0.2869, -0.1510, -0.1505,  ..., -0.0328, -0.0328,  0.0582],
          [ 0.0705, -0.2826, -0.1540,  ..., -0.2259, -0.2259, -0.4500]],

         [[-0.4114,  0.2595,  0.3521,  ..., -0.1212, -0.1212,  0.0561],
          [-0.0627, -0.0495, -0.1473,  ..., -0.1190, -0.1190, -0.3785],
          [-0.1821,  0.1312, -0.0532,  ..., -0.3606, -0.3606, -0.1059],
          [ 0.0574, -0.1012, -0.4138,  ...,  0.3228,  0.3228, -0.1332],
          [-0.0456,  0.1192, -0.0791,  ..., -0.3764, -0.3764, -0.1226],
          [ 0.0169,  0.3791,  0.1005,  ..., -0.4917, -0.4917, -0.3549]]],


        [[[ 0.1453,  0.3104, -0.3413,  ..., -0.1585, -0.1585,  0.2318],
          [-0.2368, -0.2510,  0.1730,  ..., -0.3501, -0.3501,  0.1996],
          [ 0.1035, -0.2778,  0.1515,  ...,  0.2436,  0.2436, -0.2035],
          [ 0.2582,  0.2317,  0.0288,  ...,  0.3711,  0.3711, -0.1800],
          [ 0.2665,  0.1102,  0.1091,  ..., -0.2572, -0.2572, -0.2814],
          [ 0.1215, -0.1099, -0.1713,  ...,  0.1526,  0.1526,  0.3555]],

         [[-0.0201, -0.1254,  0.0930,  ..., -0.0422, -0.0422,  0.0291],
          [-0.4263,  0.1397,  0.0302,  ...,  0.1028,  0.1028, -0.3078],
          [ 0.2018, -0.1291, -0.2174,  ..., -0.1663, -0.1663,  0.1344],
          [-0.2387, -0.0345,  0.0969,  ..., -0.3469, -0.3469,  0.0121],
          [ 0.0176, -0.0496,  0.2980,  ..., -0.2459, -0.2459,  0.3339],
          [ 0.1470, -0.0267,  0.0169,  ..., -0.1495, -0.1495, -0.3022]]]])
DESIRED: (shape=torch.Size([2, 2, 6, 34225521]), dtype=torch.float32)
tensor([[[[ 0.1318, -0.3634, -0.2819,  ..., -0.3218, -0.3218, -0.3218],
          [-0.1681, -0.2252, -0.3752,  ...,  0.1968,  0.1968,  0.1968],
          [-0.2533,  0.1155,  0.0199,  ..., -0.3706, -0.3706, -0.3706],
          [-0.0799, -0.1789,  0.0451,  ..., -0.3088, -0.3088, -0.3088],
          [ 0.2869, -0.1510, -0.1505,  ..., -0.1797, -0.1797, -0.1797],
          [ 0.0705, -0.2826, -0.1540,  ...,  0.1751,  0.1751,  0.1751]],

         [[-0.4114,  0.2595,  0.3521,  ..., -0.4143, -0.4143, -0.4143],
          [-0.0627, -0.0495, -0.1473,  ...,  0.0006,  0.0006,  0.0006],
          [-0.1821,  0.1312, -0.0532,  ...,  0.1537,  0.1537,  0.1537],
          [ 0.0574, -0.1012, -0.4138,  ..., -0.1098, -0.1098, -0.1098],
          [-0.0456,  0.1192, -0.0791,  ...,  0.2100,  0.2100,  0.2100],
          [ 0.0169,  0.3791,  0.1005,  ..., -0.0223, -0.0223, -0.0223]]],


        [[[ 0.1453,  0.3104, -0.3413,  ...,  0.1289,  0.1289,  0.1289],
          [-0.2368, -0.2510,  0.1730,  ..., -0.2239, -0.2239, -0.2239],
          [ 0.1035, -0.2778,  0.1515,  ...,  0.1340,  0.1340,  0.1340],
          [ 0.2582,  0.2317,  0.0288,  ..., -0.1866, -0.1866, -0.1866],
          [ 0.2665,  0.1102,  0.1091,  ...,  0.1625,  0.1625,  0.1625],
          [ 0.1215, -0.1099, -0.1713,  ...,  0.3587,  0.3587,  0.3587]],

         [[-0.0201, -0.1254,  0.0930,  ...,  0.1521,  0.1521,  0.1521],
          [-0.4263,  0.1397,  0.0302,  ...,  0.1364,  0.1364,  0.1364],
          [ 0.2018, -0.1291, -0.2174,  ..., -0.3743, -0.3743, -0.3743],
          [-0.2387, -0.0345,  0.0969,  ...,  0.1022,  0.1022,  0.1022],
          [ 0.0176, -0.0496,  0.2980,  ..., -0.0584, -0.0584, -0.0584],
          [ 0.1470, -0.0267,  0.0169,  ...,  0.0000,  0.0000,  0.0000]]]])

2025-07-26 04:45:44.389994 GPU 3 117758 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 6, 102676560]) != torch.Size([2, 2, 6, 102676562]).
ACTUAL: (shape=torch.Size([2, 2, 6, 102676560]), dtype=torch.float32)
tensor([[[[-1.3449e-01, -1.2287e-01, -9.6102e-02,  ...,  2.4443e-02,  2.4443e-02,  2.4443e-02],
          [ 6.1913e-02,  1.3438e-01,  2.1804e-01,  ...,  1.1717e-01,  1.1717e-01,  1.1717e-01],
          [ 2.2711e-01,  2.1406e-01,  1.6790e-01,  ..., -2.7030e-01, -2.7030e-01, -2.7030e-01],
          [ 9.8176e-02,  2.2620e-01,  3.9514e-01,  ...,  3.8049e-01,  3.8049e-01,  3.8049e-01],
          [ 2.5144e-01,  4.2628e-02, -2.1805e-01,  ...,  4.9302e-02,  4.9302e-02,  4.9302e-02],
          [-1.3786e-01,  4.1969e-02,  2.7312e-01,  ...,  1.6697e-01,  1.6697e-01,  1.6697e-01]],

         [[-1.5523e-01, -7.0208e-02,  5.3677e-02,  ..., -6.7564e-03, -6.7564e-03, -6.7564e-03],
          [ 2.0121e-01,  1.2531e-01,  9.6925e-05,  ..., -2.9208e-01, -2.9208e-01, -2.9208e-01],
          [-2.9681e-01, -1.3014e-01,  9.7501e-02,  ..., -4.5067e-01, -4.5067e-01, -4.5067e-01],
          [-2.2906e-01, -1.8128e-01, -1.2025e-01,  ...,  3.0958e-01,  3.0958e-01,  3.0958e-01],
          [-2.0454e-01, -3.2108e-02,  2.0885e-01,  ..., -4.5709e-01, -4.5709e-01, -4.5709e-01],
          [-2.0551e-01, -2.6413e-01, -3.2844e-01,  ..., -3.3329e-01, -3.3329e-01, -3.3329e-01]]],


        [[[ 1.4996e-01,  2.8996e-01,  4.5125e-01,  ..., -2.8353e-01, -2.8353e-01, -2.8353e-01],
          [ 4.9511e-01,  2.2624e-01, -1.6880e-01,  ...,  7.1652e-02,  7.1652e-02,  7.1652e-02],
          [-3.3287e-01, -3.0652e-01, -2.4134e-01,  ..., -9.4918e-02, -9.4918e-02, -9.4918e-02],
          [-2.7948e-01, -1.4111e-02,  3.4477e-01,  ...,  1.9408e-01,  1.9408e-01,  1.9408e-01],
          [ 4.9214e-01,  4.5989e-01,  3.9357e-01,  ..., -6.6285e-02, -6.6285e-02, -6.6285e-02],
          [ 3.3477e-01,  2.2656e-01,  6.6218e-02,  ...,  1.1502e-01,  1.1502e-01,  1.1502e-01]],

         [[ 3.1860e-01,  2.5611e-01,  1.7691e-01,  ..., -7.6444e-02, -7.6444e-02, -7.6444e-02],
          [ 2.7760e-02,  8.6858e-02,  1.7332e-01,  ...,  1.5568e-01,  1.5568e-01,  1.5568e-01],
          [-2.7105e-01, -2.4287e-01, -1.9261e-01,  ..., -2.1191e-02, -2.1191e-02, -2.1191e-02],
          [-6.6817e-02, -1.5224e-01, -2.7024e-01,  ..., -1.2184e-01, -1.2184e-01, -1.2184e-01],
          [ 4.0392e-01,  4.9811e-02, -4.2465e-01,  ...,  2.6431e-01,  2.6431e-01,  2.6431e-01],
          [-3.2302e-01, -2.0934e-01, -6.2838e-02,  ...,  8.3934e-02,  8.3934e-02,  8.3934e-02]]]])
DESIRED: (shape=torch.Size([2, 2, 6, 102676562]), dtype=torch.float32)
tensor([[[[-1.3449e-01, -1.2287e-01, -9.6102e-02,  ...,  2.4443e-02,  2.4443e-02,  2.4443e-02],
          [ 6.1913e-02,  1.3438e-01,  2.1804e-01,  ...,  1.1717e-01,  1.1717e-01,  1.1717e-01],
          [ 2.2711e-01,  2.1406e-01,  1.6790e-01,  ..., -2.7030e-01, -2.7030e-01, -2.7030e-01],
          [ 9.8176e-02,  2.2620e-01,  3.9514e-01,  ...,  3.8049e-01,  3.8049e-01,  3.8049e-01],
          [ 2.5144e-01,  4.2628e-02, -2.1805e-01,  ...,  4.9302e-02,  4.9302e-02,  4.9302e-02],
          [-1.3786e-01,  4.1969e-02,  2.7312e-01,  ...,  1.6697e-01,  1.6697e-01,  1.6697e-01]],

         [[-1.5523e-01, -7.0208e-02,  5.3677e-02,  ..., -6.7564e-03, -6.7564e-03, -6.7564e-03],
          [ 2.0121e-01,  1.2531e-01,  9.6925e-05,  ..., -2.9208e-01, -2.9208e-01, -2.9208e-01],
          [-2.9681e-01, -1.3014e-01,  9.7501e-02,  ..., -4.5067e-01, -4.5067e-01, -4.5067e-01],
          [-2.2906e-01, -1.8128e-01, -1.2025e-01,  ...,  3.0958e-01,  3.0958e-01,  3.0958e-01],
          [-2.0454e-01, -3.2108e-02,  2.0885e-01,  ..., -4.5709e-01, -4.5709e-01, -4.5709e-01],
          [-2.0551e-01, -2.6413e-01, -3.2844e-01,  ..., -3.3329e-01, -3.3329e-01, -3.3329e-01]]],


        [[[ 1.4996e-01,  2.8996e-01,  4.5125e-01,  ..., -2.8353e-01, -2.8353e-01, -2.8353e-01],
          [ 4.9511e-01,  2.2624e-01, -1.6880e-01,  ...,  7.1652e-02,  7.1652e-02,  7.1652e-02],
          [-3.3287e-01, -3.0652e-01, -2.4134e-01,  ..., -9.4918e-02, -9.4918e-02, -9.4918e-02],
          [-2.7948e-01, -1.4111e-02,  3.4477e-01,  ...,  1.9408e-01,  1.9408e-01,  1.9408e-01],
          [ 4.9214e-01,  4.5989e-01,  3.9357e-01,  ..., -6.6285e-02, -6.6285e-02, -6.6285e-02],
          [ 3.3477e-01,  2.2656e-01,  6.6218e-02,  ...,  1.1502e-01,  1.1502e-01,  1.1502e-01]],

         [[ 3.1860e-01,  2.5611e-01,  1.7691e-01,  ..., -7.6444e-02, -7.6444e-02, -7.6444e-02],
          [ 2.7760e-02,  8.6858e-02,  1.7332e-01,  ...,  1.5568e-01,  1.5568e-01,  1.5568e-01],
          [-2.7105e-01, -2.4287e-01, -1.9261e-01,  ..., -2.1191e-02, -2.1191e-02, -2.1191e-02],
          [-6.6817e-02, -1.5224e-01, -2.7024e-01,  ..., -1.2184e-01, -1.2184e-01, -1.2184e-01],
          [ 4.0392e-01,  4.9811e-02, -4.2465e-01,  ...,  2.6431e-01,  2.6431e-01,  2.6431e-01],
          [-3.2302e-01, -2.0934e-01, -6.2838e-02,  ...,  8.3934e-02,  8.3934e-02,  8.3934e-02]]]])

2025-07-26 04:45:55.243237 GPU 7 119062 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 6, 102676560]) != torch.Size([2, 2, 6, 102676562]).
ACTUAL: (shape=torch.Size([2, 2, 6, 102676560]), dtype=torch.float32)
tensor([[[[-0.4427, -0.3488, -0.2188,  ...,  0.2237,  0.2237,  0.2237],
          [-0.0427, -0.2313, -0.3767,  ...,  0.4438,  0.4438,  0.4438],
          [-0.0105, -0.1016, -0.1869,  ..., -0.3600, -0.3600, -0.3600],
          [-0.1222,  0.2222,  0.4184,  ..., -0.3231, -0.3231, -0.3231],
          [-0.3156, -0.3730, -0.3677,  ...,  0.4643,  0.4643,  0.4643],
          [-0.4179,  0.1088,  0.4784,  ...,  0.3040,  0.3040,  0.3040]],

         [[-0.1630, -0.1309, -0.1653,  ...,  0.1493,  0.1493,  0.1493],
          [-0.1358, -0.1753, -0.0744,  ..., -0.0717, -0.0717, -0.0717],
          [-0.0298, -0.0170,  0.0436,  ..., -0.1469, -0.1469, -0.1469],
          [ 0.3104, -0.0694, -0.3614,  ...,  0.2125,  0.2125,  0.2125],
          [ 0.3052,  0.2489,  0.1981,  ...,  0.0925,  0.0925,  0.0925],
          [ 0.1662,  0.3429,  0.4040,  ..., -0.1217, -0.1217, -0.1217]]],


        [[[-0.4269, -0.0328,  0.3037,  ...,  0.2769,  0.2769,  0.2769],
          [ 0.3240,  0.0356, -0.1720,  ...,  0.0146,  0.0146,  0.0146],
          [-0.0492,  0.2203,  0.4148,  ..., -0.2026, -0.2026, -0.2026],
          [-0.3721, -0.3066, -0.2949,  ...,  0.3173,  0.3173,  0.3173],
          [ 0.0640, -0.2499, -0.3609,  ...,  0.5217,  0.5217,  0.5217],
          [ 0.3237,  0.2941,  0.1002,  ...,  0.2377,  0.2377,  0.2377]],

         [[-0.3135,  0.1447,  0.3293,  ...,  0.4683,  0.4683,  0.4683],
          [ 0.3439,  0.2328,  0.0156,  ...,  0.2864,  0.2864,  0.2864],
          [ 0.2040, -0.1158, -0.2237,  ..., -0.2296, -0.2296, -0.2296],
          [-0.3197, -0.0650,  0.0669,  ...,  0.3360,  0.3360,  0.3360],
          [-0.0943,  0.1754,  0.3102,  ..., -0.0714, -0.0714, -0.0714],
          [-0.0830, -0.2006, -0.1599,  ..., -0.4150, -0.4150, -0.4150]]]])
DESIRED: (shape=torch.Size([2, 2, 6, 102676562]), dtype=torch.float32)
tensor([[[[-0.4427, -0.3488, -0.2188,  ...,  0.2237,  0.2237,  0.2237],
          [-0.0427, -0.2313, -0.3767,  ...,  0.4438,  0.4438,  0.4438],
          [-0.0105, -0.1016, -0.1869,  ..., -0.3600, -0.3600, -0.3600],
          [-0.1222,  0.2222,  0.4184,  ..., -0.3231, -0.3231, -0.3231],
          [-0.3156, -0.3730, -0.3677,  ...,  0.4643,  0.4643,  0.4643],
          [-0.4179,  0.1088,  0.4784,  ...,  0.3040,  0.3040,  0.3040]],

         [[-0.1630, -0.1309, -0.1653,  ...,  0.1493,  0.1493,  0.1493],
          [-0.1358, -0.1753, -0.0744,  ..., -0.0717, -0.0717, -0.0717],
          [-0.0298, -0.0170,  0.0436,  ..., -0.1469, -0.1469, -0.1469],
          [ 0.3104, -0.0694, -0.3614,  ...,  0.2125,  0.2125,  0.2125],
          [ 0.3052,  0.2489,  0.1981,  ...,  0.0925,  0.0925,  0.0925],
          [ 0.1662,  0.3429,  0.4040,  ..., -0.1217, -0.1217, -0.1217]]],


        [[[-0.4269, -0.0328,  0.3037,  ...,  0.2769,  0.2769,  0.2769],
          [ 0.3240,  0.0356, -0.1720,  ...,  0.0146,  0.0146,  0.0146],
          [-0.0492,  0.2203,  0.4148,  ..., -0.2026, -0.2026, -0.2026],
          [-0.3721, -0.3066, -0.2949,  ...,  0.3173,  0.3173,  0.3173],
          [ 0.0640, -0.2499, -0.3609,  ...,  0.5217,  0.5217,  0.5217],
          [ 0.3237,  0.2941,  0.1002,  ...,  0.2377,  0.2377,  0.2377]],

         [[-0.3135,  0.1447,  0.3293,  ...,  0.4683,  0.4683,  0.4683],
          [ 0.3439,  0.2328,  0.0156,  ...,  0.2864,  0.2864,  0.2864],
          [ 0.2040, -0.1158, -0.2237,  ..., -0.2296, -0.2296, -0.2296],
          [-0.3197, -0.0650,  0.0669,  ...,  0.3360,  0.3360,  0.3360],
          [-0.0943,  0.1754,  0.3102,  ..., -0.0714, -0.0714, -0.0714],
          [-0.0830, -0.2006, -0.1599,  ..., -0.4150, -0.4150, -0.4150]]]])

2025-07-26 04:46:01.984870 GPU 6 117992 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:14.064470 GPU 6 120010 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:14.458098 GPU 4 120093 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:15.967375 GPU 3 117758 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:16.078273 GPU 1 120186 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:16.325148 GPU 5 120250 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:25.426127 GPU 3 120642 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 18, 34225524]) != torch.Size([2, 2, 18, 34225521]).
ACTUAL: (shape=torch.Size([2, 2, 18, 34225524]), dtype=torch.float32)
tensor([[[[-0.0513, -0.1724, -0.2866,  ...,  0.1439, -0.4190, -0.4190],
          [ 0.1326,  0.1234, -0.2174,  ...,  0.1041, -0.0880, -0.0880],
          [ 0.3492,  0.4807, -0.0913,  ...,  0.0408,  0.3369,  0.3369],
          ...,
          [-0.0549,  0.0564, -0.0545,  ..., -0.1658,  0.0098,  0.0098],
          [ 0.2301,  0.0513, -0.1404,  ..., -0.3408,  0.0493,  0.0493],
          [ 0.4460,  0.0476, -0.1972,  ..., -0.4413,  0.0951,  0.0951]],

         [[-0.2395, -0.0968,  0.5487,  ..., -0.0111,  0.0825,  0.0825],
          [-0.0777,  0.0325,  0.2492,  ..., -0.1120,  0.0445,  0.0445],
          [ 0.1360,  0.2272, -0.1322,  ..., -0.2369,  0.0202,  0.0202],
          ...,
          [ 0.2495, -0.3666, -0.2540,  ...,  0.0921, -0.1032, -0.1032],
          [-0.1026, -0.0156, -0.3233,  ..., -0.0663,  0.1378,  0.1378],
          [-0.3472,  0.2482, -0.3454,  ..., -0.1937,  0.3326,  0.3326]]],


        [[[ 0.3820, -0.0842,  0.1999,  ...,  0.0667,  0.4445,  0.4445],
          [ 0.1311, -0.2129, -0.0123,  ..., -0.1814,  0.1834,  0.1834],
          [-0.1900, -0.3484, -0.2613,  ..., -0.4893, -0.1485, -0.1485],
          ...,
          [-0.2031, -0.0941,  0.2022,  ...,  0.4539, -0.2288, -0.2288],
          [-0.1114,  0.0450,  0.1352,  ..., -0.1080, -0.3747, -0.3747],
          [-0.0248,  0.1457,  0.0750,  ..., -0.5378, -0.4796, -0.4796]],

         [[-0.3503,  0.1198, -0.1163,  ..., -0.2852, -0.3954, -0.3954],
          [-0.2935,  0.0725, -0.1624,  ..., -0.0749, -0.2119, -0.2119],
          [-0.2151,  0.0052, -0.2345,  ...,  0.2029,  0.0737,  0.0737],
          ...,
          [ 0.2662, -0.1204, -0.0371,  ...,  0.3820,  0.3625,  0.3625],
          [ 0.0906,  0.0548,  0.2844,  ..., -0.0085, -0.0200, -0.0200],
          [-0.0504,  0.1759,  0.5210,  ..., -0.3066, -0.3102, -0.3102]]]])
DESIRED: (shape=torch.Size([2, 2, 18, 34225521]), dtype=torch.float32)
tensor([[[[-0.0513, -0.1724, -0.2866,  ...,  0.1439,  0.1439,  0.1439],
          [ 0.1326,  0.1234, -0.2174,  ...,  0.1041,  0.1041,  0.1041],
          [ 0.3492,  0.4807, -0.0913,  ...,  0.0408,  0.0408,  0.0408],
          ...,
          [-0.0549,  0.0564, -0.0545,  ..., -0.1658, -0.1658, -0.1658],
          [ 0.2301,  0.0513, -0.1404,  ..., -0.3408, -0.3408, -0.3408],
          [ 0.4460,  0.0476, -0.1972,  ..., -0.4413, -0.4413, -0.4413]],

         [[-0.2395, -0.0968,  0.5487,  ..., -0.0111, -0.0111, -0.0111],
          [-0.0777,  0.0325,  0.2492,  ..., -0.1120, -0.1120, -0.1120],
          [ 0.1360,  0.2272, -0.1322,  ..., -0.2369, -0.2369, -0.2369],
          ...,
          [ 0.2495, -0.3666, -0.2540,  ...,  0.0921,  0.0921,  0.0921],
          [-0.1026, -0.0156, -0.3233,  ..., -0.0663, -0.0663, -0.0663],
          [-0.3472,  0.2482, -0.3454,  ..., -0.1937, -0.1937, -0.1937]]],


        [[[ 0.3820, -0.0842,  0.1999,  ...,  0.0667,  0.0667,  0.0667],
          [ 0.1311, -0.2129, -0.0123,  ..., -0.1814, -0.1814, -0.1814],
          [-0.1900, -0.3484, -0.2613,  ..., -0.4893, -0.4893, -0.4893],
          ...,
          [-0.2031, -0.0941,  0.2022,  ...,  0.4539,  0.4539,  0.4539],
          [-0.1114,  0.0450,  0.1352,  ..., -0.1080, -0.1080, -0.1080],
          [-0.0248,  0.1457,  0.0750,  ..., -0.5378, -0.5378, -0.5378]],

         [[-0.3503,  0.1198, -0.1163,  ..., -0.2852, -0.2852, -0.2852],
          [-0.2935,  0.0725, -0.1624,  ..., -0.0749, -0.0749, -0.0749],
          [-0.2151,  0.0052, -0.2345,  ...,  0.2029,  0.2029,  0.2029],
          ...,
          [ 0.2662, -0.1204, -0.0371,  ...,  0.3820,  0.3820,  0.3820],
          [ 0.0906,  0.0548,  0.2844,  ..., -0.0085, -0.0085, -0.0085],
          [-0.0504,  0.1759,  0.5210,  ..., -0.3066, -0.3066, -0.3066]]]])

2025-07-26 04:46:25.794143 GPU 2 120725 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 18, 34225524]) != torch.Size([2, 2, 18, 34225521]).
ACTUAL: (shape=torch.Size([2, 2, 18, 34225524]), dtype=torch.float32)
tensor([[[[-4.8489e-02, -2.7258e-01, -2.3775e-01,  ..., -3.0379e-02, -3.0379e-02,  2.4438e-01],
          [-4.2600e-02, -3.3158e-01,  1.6659e-01,  ...,  2.8941e-01,  2.8941e-01,  3.7640e-01],
          [ 4.6982e-02, -2.8221e-01,  4.7020e-01,  ...,  4.9188e-01,  4.9188e-01,  4.5092e-01],
          ...,
          [-4.2352e-01, -1.4802e-02, -3.2384e-01,  ..., -4.3429e-01, -4.3429e-01, -4.3771e-02],
          [-4.3316e-01, -3.3706e-03, -3.7287e-01,  ..., -9.6843e-02, -9.6843e-02,  4.2849e-02],
          [-3.5373e-01,  9.7615e-02, -2.6895e-01,  ...,  4.6538e-01,  4.6538e-01,  1.4523e-01]],

         [[-1.8211e-01,  3.7782e-01,  2.7993e-01,  ...,  2.1744e-01,  2.1744e-01, -2.9077e-01],
          [-1.3206e-01,  1.1629e-01,  1.7478e-01,  ...,  2.2876e-01,  2.2876e-01, -1.7605e-06],
          [-1.4904e-01, -1.6048e-01,  8.5370e-02,  ...,  2.6818e-01,  2.6818e-01,  1.4416e-01],
          ...,
          [ 3.4661e-01, -4.0240e-01,  4.6825e-01,  ...,  4.2860e-02,  4.2860e-02, -2.6391e-01],
          [ 3.6101e-01, -4.4269e-01,  4.4833e-01,  ...,  1.1562e-01,  1.1562e-01, -3.4257e-01],
          [ 3.2932e-01, -2.7171e-01,  3.6743e-01,  ...,  1.9060e-01,  1.9060e-01, -3.3003e-01]]],


        [[[-4.1106e-01, -1.1293e-01, -2.8884e-01,  ...,  4.6036e-02,  4.6036e-02, -3.4093e-01],
          [-2.7489e-01, -1.9541e-01, -1.2428e-01,  ..., -1.2227e-01, -1.2227e-01, -2.4032e-01],
          [-1.0886e-01, -2.4932e-01,  3.0214e-02,  ..., -2.0284e-01, -2.0284e-01, -1.4120e-01],
          ...,
          [ 4.2460e-01, -1.8681e-01,  3.4440e-02,  ...,  1.9694e-01,  1.9694e-01, -1.7556e-01],
          [ 2.0026e-01, -2.2652e-02,  6.0771e-02,  ..., -2.5703e-04, -2.5703e-04, -1.5954e-01],
          [-7.0013e-02,  2.2318e-01,  5.7060e-02,  ..., -1.8370e-01, -1.8370e-01, -1.7935e-01]],

         [[-4.0036e-01, -4.7158e-01,  3.1759e-01,  ..., -2.3097e-01, -2.3097e-01,  4.9667e-02],
          [-2.2486e-01, -3.5457e-01,  1.5875e-01,  ..., -3.1753e-02, -3.1753e-02, -2.3158e-01],
          [ 4.8291e-02, -2.1172e-01, -5.9598e-02,  ...,  3.6466e-02,  3.6466e-02, -3.2981e-01],
          ...,
          [ 1.1162e-01, -3.7376e-03, -2.3558e-01,  ...,  3.4028e-01,  3.4028e-01, -9.4319e-02],
          [ 2.7607e-01, -7.5925e-02, -1.6549e-01,  ...,  1.3606e-01,  1.3606e-01,  1.2338e-01],
          [ 3.1236e-01, -1.5995e-02, -6.8396e-02,  ..., -2.5548e-01, -2.5548e-01,  3.2182e-01]]]])
DESIRED: (shape=torch.Size([2, 2, 18, 34225521]), dtype=torch.float32)
tensor([[[[-4.8489e-02, -2.7258e-01, -2.3775e-01,  ...,  2.4438e-01,  2.4438e-01,  2.4438e-01],
          [-4.2600e-02, -3.3158e-01,  1.6659e-01,  ...,  3.7640e-01,  3.7640e-01,  3.7640e-01],
          [ 4.6982e-02, -2.8221e-01,  4.7020e-01,  ...,  4.5092e-01,  4.5092e-01,  4.5092e-01],
          ...,
          [-4.2352e-01, -1.4802e-02, -3.2384e-01,  ..., -4.3771e-02, -4.3771e-02, -4.3771e-02],
          [-4.3316e-01, -3.3707e-03, -3.7287e-01,  ...,  4.2849e-02,  4.2849e-02,  4.2849e-02],
          [-3.5373e-01,  9.7615e-02, -2.6895e-01,  ...,  1.4523e-01,  1.4523e-01,  1.4523e-01]],

         [[-1.8211e-01,  3.7782e-01,  2.7993e-01,  ..., -2.9077e-01, -2.9077e-01, -2.9077e-01],
          [-1.3206e-01,  1.1629e-01,  1.7478e-01,  ..., -1.7605e-06, -1.7605e-06, -1.7605e-06],
          [-1.4904e-01, -1.6048e-01,  8.5369e-02,  ...,  1.4416e-01,  1.4416e-01,  1.4416e-01],
          ...,
          [ 3.4661e-01, -4.0240e-01,  4.6825e-01,  ..., -2.6391e-01, -2.6391e-01, -2.6391e-01],
          [ 3.6101e-01, -4.4269e-01,  4.4833e-01,  ..., -3.4257e-01, -3.4257e-01, -3.4257e-01],
          [ 3.2932e-01, -2.7171e-01,  3.6743e-01,  ..., -3.3003e-01, -3.3003e-01, -3.3003e-01]]],


        [[[-4.1106e-01, -1.1293e-01, -2.8884e-01,  ..., -3.4093e-01, -3.4093e-01, -3.4093e-01],
          [-2.7489e-01, -1.9541e-01, -1.2429e-01,  ..., -2.4032e-01, -2.4032e-01, -2.4032e-01],
          [-1.0886e-01, -2.4932e-01,  3.0214e-02,  ..., -1.4120e-01, -1.4120e-01, -1.4120e-01],
          ...,
          [ 4.2460e-01, -1.8681e-01,  3.4440e-02,  ..., -1.7556e-01, -1.7556e-01, -1.7556e-01],
          [ 2.0026e-01, -2.2652e-02,  6.0771e-02,  ..., -1.5954e-01, -1.5954e-01, -1.5954e-01],
          [-7.0013e-02,  2.2318e-01,  5.7060e-02,  ..., -1.7935e-01, -1.7935e-01, -1.7935e-01]],

         [[-4.0036e-01, -4.7158e-01,  3.1759e-01,  ...,  4.9667e-02,  4.9667e-02,  4.9667e-02],
          [-2.2486e-01, -3.5457e-01,  1.5875e-01,  ..., -2.3158e-01, -2.3158e-01, -2.3158e-01],
          [ 4.8291e-02, -2.1172e-01, -5.9599e-02,  ..., -3.2981e-01, -3.2981e-01, -3.2981e-01],
          ...,
          [ 1.1162e-01, -3.7375e-03, -2.3558e-01,  ..., -9.4319e-02, -9.4319e-02, -9.4319e-02],
          [ 2.7607e-01, -7.5925e-02, -1.6549e-01,  ...,  1.2338e-01,  1.2338e-01,  1.2338e-01],
          [ 3.1236e-01, -1.5994e-02, -6.8396e-02,  ...,  3.2182e-01,  3.2182e-01,  3.2182e-01]]]])

2025-07-26 04:46:30.618697 GPU 7 119062 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:46:41.050587 GPU 7 120958 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:47:31.287064 GPU 6 121121 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:47:35.966889 GPU 1 121281 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:47:38.611021 GPU 5 121370 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:47:47.809784 GPU 4 121601 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:48:04.403816 GPU 7 121763 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476574 (unix time) try "date -d @1753476574" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dba3) received by PID 121763 (TID 0x7f33e5f38740) from PID 121763 ***]


2025-07-26 04:48:12.649644 GPU 2 120725 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 4 / 2281701400 (0.0%)
Greatest absolute difference: 0.5960376262664795 at index (0, 1, 9, 0) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 3, 28521268) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([2, 2, 10, 57042535]), dtype=torch.float32)
tensor([[[[-0.3340,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0137,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0335,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.1087,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.1191,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.1575,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.0570,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.3884,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.4600,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.0698,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2810,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.5960,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0196,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.3221,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1516,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.2208,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2551,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.4804,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.3416,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.3987,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2485,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.4924,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 10, 57042535]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])

2025-07-26 04:48:52.369231 GPU 1 121938 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476619 (unix time) try "date -d @1753476619" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dc52) received by PID 121938 (TID 0x7f6d5df32740) from PID 121938 ***]


2025-07-26 04:48:54.701671 GPU 6 122027 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476616 (unix time) try "date -d @1753476616" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dcab) received by PID 122027 (TID 0x7f1139fbe740) from PID 122027 ***]


2025-07-26 04:49:11.774841 GPU 5 122258 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476645 (unix time) try "date -d @1753476645" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dd92) received by PID 122258 (TID 0x7f3a45085740) from PID 122258 ***]


2025-07-26 04:49:20.678198 GPU 4 122417 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476645 (unix time) try "date -d @1753476645" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1de31) received by PID 122417 (TID 0x7f9c11d84740) from PID 122417 ***]


2025-07-26 04:49:34.055150 GPU 3 120642 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 88 / 2281701400 (0.0%)
Greatest absolute difference: 1.0970780849456787 at index (1, 0, 9, 8775775) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 0, 8775775) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([2, 2, 10, 57042535]), dtype=torch.float32)
tensor([[[[ 0.0491,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2964,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1992,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.2792,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.8070,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.1465,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.2677,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2611,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2773,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.1693,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0107,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2166,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[-0.0756,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1138,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1999,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0378,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.3137,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.6644,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.3879,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0846,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1680,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.7473,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 10, 57042535]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])

2025-07-26 04:49:39.046804 GPU 7 122577 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476667 (unix time) try "date -d @1753476667" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ded1) received by PID 122577 (TID 0x7f63ce280740) from PID 122577 ***]


2025-07-26 04:49:50.169593 GPU 2 120725 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 11 / 2281701400 (0.0%)
Greatest absolute difference: 0.7196066379547119 at index (1, 1, 4, 0) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([2, 2, 10, 57042535]), dtype=torch.float32)
tensor([[[[-0.6076,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1882,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.2913,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.1559,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2639,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0505,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.3364,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.1901,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0196,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.0100,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.4522,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.1003,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[-0.2628,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.2107,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0113,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.3928,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.4826,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [-0.0526,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[-0.1826,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.1191,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.3465,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [-0.1187,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 10, 57042535]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])

2025-07-26 04:50:22.319892 GPU 6 122739 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476713 (unix time) try "date -d @1753476713" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1df73) received by PID 122739 (TID 0x7fa25129c740) from PID 122739 ***]


2025-07-26 04:50:25.314470 GPU 1 122827 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476716 (unix time) try "date -d @1753476716" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dfcb) received by PID 122827 (TID 0x7ff9deaad740) from PID 122827 ***]


2025-07-26 04:50:50.342761 GPU 5 123059 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 4, 268435457],"float16"), size=list[10,11,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476745 (unix time) try "date -d @1753476745" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e0b3) received by PID 123059 (TID 0x7f594704b740) from PID 123059 ***]


2025-07-26 04:50:51.496951 GPU 4 123147 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 34225524, 6]) != torch.Size([2, 2, 34225521, 6]).
ACTUAL: (shape=torch.Size([2, 2, 34225524, 6]), dtype=torch.float32)
tensor([[[[ 0.2385,  0.0430,  0.2758,  0.3401,  0.0342, -0.2013],
          [ 0.2265,  0.2302,  0.2002, -0.0479,  0.0143,  0.0395],
          [-0.0433, -0.2310,  0.1173,  0.1714,  0.0217, -0.0424],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.3142,  0.0599, -0.3296,  0.0642, -0.1336,  0.0647],
          [ 0.1451, -0.1466,  0.0681,  0.0115, -0.0047,  0.0463],
          [ 0.0500, -0.1029, -0.0862,  0.2245, -0.0048, -0.2613],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[-0.4525,  0.1649,  0.2489,  0.2078,  0.1279,  0.1266],
          [-0.1668,  0.0968,  0.1650, -0.2009, -0.1640, -0.1491],
          [-0.1170,  0.2050,  0.0728, -0.1304, -0.0163,  0.0880],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.4661, -0.0317,  0.2644, -0.3745, -0.2389,  0.0605],
          [ 0.2589, -0.1143,  0.2755,  0.1015,  0.2040,  0.1636],
          [-0.0012,  0.0739, -0.0702, -0.1001, -0.0915,  0.0422],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 34225521, 6]), dtype=torch.float32)
tensor([[[[ 0.2100, -0.0383,  0.2569,  0.1622,  0.3486, -0.1942],
          [ 0.2667,  0.3457,  0.0815, -0.1489, -0.3127,  0.0027],
          [-0.0333, -0.1825,  0.0601, -0.0145, -0.0746, -0.0876],
          ...,
          [ 0.0132, -0.4897, -0.2658,  0.3399, -0.2489,  0.2905],
          [ 0.0132, -0.4897, -0.2658,  0.3399, -0.2489,  0.2905],
          [ 0.0132, -0.4897, -0.2658,  0.3399, -0.2489,  0.2905]],

         [[-0.0812,  0.1685, -0.2866,  0.0751, -0.0125, -0.0095],
          [ 0.0421, -0.4697,  0.0130, -0.1986,  0.0181, -0.1974],
          [ 0.0273, -0.3516,  0.0226,  0.3202, -0.0021, -0.2581],
          ...,
          [-0.2259,  0.0906,  0.0618, -0.4216,  0.0333, -0.1599],
          [-0.2259,  0.0906,  0.0618, -0.4216,  0.0333, -0.1599],
          [-0.2259,  0.0906,  0.0618, -0.4216,  0.0333, -0.1599]]],


        [[[-0.0119,  0.2404,  0.1466,  0.0016,  0.1655,  0.0705],
          [-0.2446, -0.2045, -0.1637, -0.1797, -0.2530, -0.1218],
          [ 0.1126,  0.3080, -0.0942,  0.0251, -0.3372,  0.1160],
          ...,
          [ 0.4597,  0.1637, -0.1843,  0.1979,  0.4942, -0.3625],
          [ 0.4597,  0.1637, -0.1843,  0.1979,  0.4942, -0.3625],
          [ 0.4597,  0.1637, -0.1843,  0.1979,  0.4942, -0.3625]],

         [[-0.1485,  0.0671,  0.1460, -0.1411, -0.2843,  0.0783],
          [ 0.1216, -0.3314,  0.3144,  0.1233,  0.4373,  0.3082],
          [-0.0181,  0.2489, -0.1804, -0.1969,  0.0047, -0.1076],
          ...,
          [ 0.1165,  0.2915, -0.1947,  0.3728, -0.1191, -0.3396],
          [ 0.1165,  0.2915, -0.1947,  0.3728, -0.1191, -0.3396],
          [ 0.1165,  0.2915, -0.1947,  0.3728, -0.1191, -0.3396]]]])

2025-07-26 04:51:04.395615 GPU 3 120642 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 34225524, 6]) != torch.Size([2, 2, 34225521, 6]).
ACTUAL: (shape=torch.Size([2, 2, 34225524, 6]), dtype=torch.float32)
tensor([[[[-0.2510, -0.0096, -0.2561, -0.0589,  0.0368,  0.0076],
          [-0.3048,  0.0744,  0.3015,  0.2146,  0.3214,  0.2259],
          [-0.1147, -0.0303,  0.0189, -0.0514, -0.1260,  0.1975],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.1782, -0.0967,  0.4018, -0.2971, -0.0464,  0.2729],
          [-0.3155, -0.2054,  0.1638, -0.2246,  0.0444,  0.3684],
          [-0.0892,  0.2243,  0.1321,  0.0219, -0.3423, -0.4446],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.4204, -0.0662,  0.0487, -0.1223,  0.3435,  0.2811],
          [-0.0616, -0.1867, -0.1623,  0.0697, -0.1134, -0.1159],
          [-0.1923, -0.2388, -0.0425,  0.1946,  0.3056,  0.0174],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

         [[-0.3048,  0.0207, -0.0701,  0.2265, -0.0123,  0.2332],
          [ 0.2022, -0.2401,  0.1267, -0.0383,  0.1684, -0.0996],
          [ 0.2386,  0.2935,  0.0451,  0.0124, -0.2129,  0.2052],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 34225521, 6]), dtype=torch.float32)
tensor([[[[-0.2510, -0.0096, -0.2561, -0.0589,  0.0368,  0.0076],
          [-0.3048,  0.0744,  0.3015,  0.2146,  0.3214,  0.2259],
          [-0.1147, -0.0303,  0.0189, -0.0514, -0.1260,  0.1975],
          ...,
          [-0.2499, -0.0197,  0.0802, -0.4041, -0.2622,  0.2853],
          [-0.2499, -0.0197,  0.0802, -0.4041, -0.2622,  0.2853],
          [-0.2499, -0.0197,  0.0802, -0.4041, -0.2622,  0.2853]],

         [[-0.1782, -0.0967,  0.4018, -0.2971, -0.0464,  0.2729],
          [-0.3155, -0.2054,  0.1638, -0.2246,  0.0444,  0.3684],
          [-0.0892,  0.2243,  0.1321,  0.0219, -0.3423, -0.4446],
          ...,
          [ 0.0878, -0.2404, -0.3649, -0.0860, -0.0014, -0.3703],
          [ 0.0878, -0.2404, -0.3649, -0.0860, -0.0014, -0.3703],
          [ 0.0878, -0.2404, -0.3649, -0.0860, -0.0014, -0.3703]]],


        [[[ 0.4204, -0.0662,  0.0487, -0.1223,  0.3435,  0.2811],
          [-0.0616, -0.1867, -0.1623,  0.0697, -0.1134, -0.1159],
          [-0.1923, -0.2388, -0.0425,  0.1946,  0.3056,  0.0174],
          ...,
          [-0.1746, -0.4292,  0.0678, -0.4783, -0.2180,  0.4931],
          [-0.1746, -0.4292,  0.0678, -0.4783, -0.2180,  0.4931],
          [-0.1746, -0.4292,  0.0678, -0.4783, -0.2180,  0.4931]],

         [[-0.3048,  0.0207, -0.0701,  0.2265, -0.0123,  0.2332],
          [ 0.2022, -0.2401,  0.1267, -0.0383,  0.1684, -0.0996],
          [ 0.2386,  0.2935,  0.0451,  0.0124, -0.2129,  0.2052],
          ...,
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])

2025-07-26 04:51:12.561729 GPU 7 123377 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 34225524, 18]) != torch.Size([2, 2, 34225521, 18]).
ACTUAL: (shape=torch.Size([2, 2, 34225524, 18]), dtype=torch.float32)
tensor([[[[-3.6219e-01, -2.3577e-01, -6.0061e-02,  ..., -2.2350e-01, -3.2019e-01, -3.8777e-01],
          [ 4.0639e-01,  1.2329e-01, -2.5527e-01,  ..., -3.5165e-03,  1.2546e-01,  2.2279e-01],
          [ 2.2973e-01,  3.3991e-01,  4.7514e-01,  ...,  1.1908e-01,  6.2973e-02,  3.5851e-02],
          ...,
          [-3.3203e-01, -2.5474e-01, -1.5259e-01,  ...,  5.0504e-01,  3.4339e-01,  1.8787e-01],
          [ 5.2131e-01,  3.5966e-01,  1.3448e-01,  ..., -3.1594e-01, -2.3612e-01, -1.6722e-01],
          [ 5.2131e-01,  3.5966e-01,  1.3448e-01,  ..., -3.1594e-01, -2.3612e-01, -1.6722e-01]],

         [[ 1.1253e-01,  2.3532e-01,  3.6734e-01,  ..., -1.9181e-01, -2.0778e-01, -2.2175e-01],
          [ 4.5042e-01,  2.3483e-01, -6.8600e-02,  ...,  3.6413e-01,  8.1158e-02, -1.3483e-01],
          [-5.2608e-01, -4.4007e-01, -2.8029e-01,  ...,  2.3345e-01, -6.5168e-02, -2.9034e-01],
          ...,
          [-4.0383e-01, -1.9506e-01,  1.1139e-01,  ...,  3.4260e-01,  1.4059e-01, -1.6304e-02],
          [-4.6525e-01, -1.6099e-01,  2.7085e-01,  ..., -4.6503e-01, -2.1496e-01, -1.9986e-02],
          [-4.6525e-01, -1.6099e-01,  2.7085e-01,  ..., -4.6503e-01, -2.1496e-01, -1.9986e-02]]],


        [[[ 2.4774e-01,  1.1598e-01, -6.6316e-02,  ..., -3.8383e-01, -2.3938e-01, -1.0561e-01],
          [ 3.0652e-01,  1.8850e-01,  9.5490e-03,  ..., -4.0680e-02,  2.8347e-01,  5.1358e-01],
          [-9.8779e-02,  1.8625e-04,  1.1197e-01,  ..., -2.9260e-01,  8.2279e-02,  3.7626e-01],
          ...,
          [ 2.6569e-01,  6.3992e-02, -2.3701e-01,  ...,  1.3007e-02,  2.6908e-01,  4.7087e-01],
          [-2.0881e-01, -2.4883e-01, -3.0512e-01,  ..., -1.0727e-01,  1.5701e-01,  3.4163e-01],
          [-2.0881e-01, -2.4883e-01, -3.0512e-01,  ..., -1.0727e-01,  1.5701e-01,  3.4163e-01]],

         [[-5.7660e-02, -1.0055e-01, -1.4077e-01,  ...,  3.0172e-02,  3.8358e-02,  2.3272e-02],
          [ 3.1349e-01,  2.1483e-01,  6.3770e-02,  ...,  2.5563e-01,  2.0514e-01,  1.5689e-01],
          [-5.4505e-01, -3.1874e-01,  2.0878e-02,  ...,  2.9662e-01,  2.1748e-01,  1.5552e-01],
          ...,
          [ 4.5831e-01,  3.9635e-01,  2.9864e-01,  ...,  3.5443e-01,  3.9869e-01,  4.0620e-01],
          [-3.6954e-01, -7.2920e-02,  3.1390e-01,  ..., -2.5975e-01,  9.3868e-02,  3.6504e-01],
          [-3.6954e-01, -7.2920e-02,  3.1390e-01,  ..., -2.5975e-01,  9.3868e-02,  3.6504e-01]]]])
DESIRED: (shape=torch.Size([2, 2, 34225521, 18]), dtype=torch.float32)
tensor([[[[-3.6219e-01, -2.3577e-01, -6.0061e-02,  ..., -2.2350e-01, -3.2019e-01, -3.8777e-01],
          [ 4.0639e-01,  1.2329e-01, -2.5527e-01,  ..., -3.5165e-03,  1.2546e-01,  2.2279e-01],
          [ 2.2973e-01,  3.3991e-01,  4.7514e-01,  ...,  1.1908e-01,  6.2973e-02,  3.5851e-02],
          ...,
          [-3.3203e-01, -2.5474e-01, -1.5259e-01,  ...,  5.0504e-01,  3.4339e-01,  1.8787e-01],
          [-3.3203e-01, -2.5474e-01, -1.5259e-01,  ...,  5.0504e-01,  3.4339e-01,  1.8787e-01],
          [-3.3203e-01, -2.5474e-01, -1.5259e-01,  ...,  5.0504e-01,  3.4339e-01,  1.8787e-01]],

         [[ 1.1253e-01,  2.3532e-01,  3.6734e-01,  ..., -1.9181e-01, -2.0778e-01, -2.2175e-01],
          [ 4.5042e-01,  2.3483e-01, -6.8600e-02,  ...,  3.6413e-01,  8.1158e-02, -1.3483e-01],
          [-5.2608e-01, -4.4007e-01, -2.8029e-01,  ...,  2.3345e-01, -6.5168e-02, -2.9034e-01],
          ...,
          [-4.0383e-01, -1.9506e-01,  1.1139e-01,  ...,  3.4260e-01,  1.4059e-01, -1.6304e-02],
          [-4.0383e-01, -1.9506e-01,  1.1139e-01,  ...,  3.4260e-01,  1.4059e-01, -1.6304e-02],
          [-4.0383e-01, -1.9506e-01,  1.1139e-01,  ...,  3.4260e-01,  1.4059e-01, -1.6304e-02]]],


        [[[ 2.4774e-01,  1.1598e-01, -6.6316e-02,  ..., -3.8383e-01, -2.3938e-01, -1.0561e-01],
          [ 3.0652e-01,  1.8850e-01,  9.5490e-03,  ..., -4.0680e-02,  2.8347e-01,  5.1358e-01],
          [-9.8779e-02,  1.8625e-04,  1.1197e-01,  ..., -2.9260e-01,  8.2279e-02,  3.7626e-01],
          ...,
          [ 2.6569e-01,  6.3992e-02, -2.3701e-01,  ...,  1.3007e-02,  2.6908e-01,  4.7087e-01],
          [ 2.6569e-01,  6.3992e-02, -2.3701e-01,  ...,  1.3007e-02,  2.6908e-01,  4.7087e-01],
          [ 2.6569e-01,  6.3992e-02, -2.3701e-01,  ...,  1.3007e-02,  2.6908e-01,  4.7087e-01]],

         [[-5.7660e-02, -1.0055e-01, -1.4077e-01,  ...,  3.0172e-02,  3.8358e-02,  2.3272e-02],
          [ 3.1349e-01,  2.1483e-01,  6.3770e-02,  ...,  2.5563e-01,  2.0514e-01,  1.5689e-01],
          [-5.4505e-01, -3.1874e-01,  2.0878e-02,  ...,  2.9662e-01,  2.1748e-01,  1.5552e-01],
          ...,
          [ 4.5831e-01,  3.9635e-01,  2.9864e-01,  ...,  3.5443e-01,  3.9869e-01,  4.0620e-01],
          [ 4.5831e-01,  3.9635e-01,  2.9864e-01,  ...,  3.5443e-01,  3.9869e-01,  4.0620e-01],
          [ 4.5831e-01,  3.9635e-01,  2.9864e-01,  ...,  3.5443e-01,  3.9869e-01,  4.0620e-01]]]])

2025-07-26 04:51:28.921738 GPU 3 120642 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 34225524, 18]) != torch.Size([2, 2, 34225521, 18]).
ACTUAL: (shape=torch.Size([2, 2, 34225524, 18]), dtype=torch.float32)
tensor([[[[-2.5104e-01,  1.5006e-01,  4.0699e-01,  ..., -1.2775e-01, -8.7535e-02,  7.5541e-03],
          [-3.2200e-01, -8.5040e-03,  2.4468e-01,  ...,  5.5684e-01,  4.3698e-01,  2.5355e-01],
          [-1.2857e-01,  9.7129e-02,  2.3112e-01,  ..., -4.9361e-01, -1.8860e-01,  2.2783e-01],
          ...,
          [-3.8991e-01, -1.9667e-01,  7.5046e-02,  ..., -4.7660e-01, -2.8679e-01,  1.3265e-01],
          [-3.8991e-01, -1.9667e-01,  7.5046e-02,  ..., -4.7660e-01, -2.8679e-01,  1.3265e-01],
          [-4.5923e-01, -5.6853e-01, -4.5835e-01,  ...,  2.0923e-01,  2.2974e-01,  8.8996e-02]],

         [[-1.7823e-01, -2.2205e-01, -2.2514e-01,  ...,  1.0876e-01,  2.1435e-01,  2.7294e-01],
          [-3.6866e-01, -3.0733e-01, -2.5486e-01,  ..., -5.8426e-01, -1.7736e-01,  4.6831e-01],
          [-4.1705e-02, -1.3340e-02,  8.4686e-02,  ...,  1.9950e-01, -6.4457e-02, -5.4379e-01],
          ...,
          [-1.2546e-01,  1.3945e-01,  3.3719e-01,  ..., -1.8738e-01, -1.8485e-01, -1.4416e-01],
          [-1.2546e-01,  1.3945e-01,  3.3719e-01,  ..., -1.8738e-01, -1.8485e-01, -1.4416e-01],
          [ 4.8856e-01, -4.3206e-02, -3.6782e-01,  ...,  2.3664e-01,  3.1629e-01,  2.9260e-01]]],


        [[[ 4.2036e-01,  2.6562e-01,  7.1820e-02,  ..., -2.3257e-01, -7.3822e-02,  2.8110e-01],
          [-4.7771e-02, -1.7878e-01, -2.7356e-01,  ..., -1.4883e-04, -3.7543e-02, -1.4480e-01],
          [-2.1771e-01, -2.2520e-01, -2.3608e-01,  ...,  3.5808e-01,  1.9648e-01,  4.5232e-02],
          ...,
          [ 3.6322e-01, -5.4787e-02, -3.4878e-01,  ..., -3.3301e-01, -1.5755e-01,  2.4963e-02],
          [ 3.6322e-01, -5.4787e-02, -3.4878e-01,  ..., -3.3301e-01, -1.5755e-01,  2.4963e-02],
          [-1.7231e-01, -1.0732e-03,  6.9392e-02,  ...,  3.9520e-01,  8.5656e-02, -4.5488e-01]],

         [[-3.0480e-01, -3.6161e-01, -3.1065e-01,  ..., -4.9130e-02,  8.4866e-02,  2.3320e-01],
          [ 2.1553e-01,  2.3703e-02, -2.0217e-01,  ...,  2.2144e-01,  2.2043e-02, -1.7461e-01],
          [ 2.3840e-01,  4.3428e-01,  5.6470e-01,  ..., -4.0661e-01, -7.6736e-02,  3.0202e-01],
          ...,
          [-1.9080e-01, -2.9474e-01, -2.5724e-01,  ...,  4.6596e-02,  4.2896e-02, -3.1985e-02],
          [-1.9080e-01, -2.9474e-01, -2.5724e-01,  ...,  4.6596e-02,  4.2896e-02, -3.1985e-02],
          [-4.0098e-01, -4.3550e-01, -3.8989e-01,  ..., -4.1931e-01, -3.5640e-01, -2.4596e-01]]]])
DESIRED: (shape=torch.Size([2, 2, 34225521, 18]), dtype=torch.float32)
tensor([[[[-2.5104e-01,  1.5006e-01,  4.0699e-01,  ..., -1.2775e-01, -8.7535e-02,  7.5541e-03],
          [-3.2200e-01, -8.5040e-03,  2.4468e-01,  ...,  5.5684e-01,  4.3698e-01,  2.5355e-01],
          [-1.2857e-01,  9.7129e-02,  2.3112e-01,  ..., -4.9361e-01, -1.8860e-01,  2.2783e-01],
          ...,
          [-4.5923e-01, -5.6853e-01, -4.5835e-01,  ...,  2.0923e-01,  2.2974e-01,  8.8996e-02],
          [-4.5923e-01, -5.6853e-01, -4.5835e-01,  ...,  2.0923e-01,  2.2974e-01,  8.8996e-02],
          [-4.5923e-01, -5.6853e-01, -4.5835e-01,  ...,  2.0923e-01,  2.2974e-01,  8.8996e-02]],

         [[-1.7823e-01, -2.2205e-01, -2.2514e-01,  ...,  1.0876e-01,  2.1435e-01,  2.7294e-01],
          [-3.6866e-01, -3.0733e-01, -2.5486e-01,  ..., -5.8426e-01, -1.7736e-01,  4.6831e-01],
          [-4.1705e-02, -1.3340e-02,  8.4686e-02,  ...,  1.9950e-01, -6.4457e-02, -5.4379e-01],
          ...,
          [ 4.8856e-01, -4.3206e-02, -3.6782e-01,  ...,  2.3664e-01,  3.1629e-01,  2.9260e-01],
          [ 4.8856e-01, -4.3206e-02, -3.6782e-01,  ...,  2.3664e-01,  3.1629e-01,  2.9260e-01],
          [ 4.8856e-01, -4.3206e-02, -3.6782e-01,  ...,  2.3664e-01,  3.1629e-01,  2.9260e-01]]],


        [[[ 4.2036e-01,  2.6562e-01,  7.1820e-02,  ..., -2.3257e-01, -7.3822e-02,  2.8110e-01],
          [-4.7770e-02, -1.7878e-01, -2.7356e-01,  ..., -1.4883e-04, -3.7543e-02, -1.4480e-01],
          [-2.1771e-01, -2.2520e-01, -2.3608e-01,  ...,  3.5808e-01,  1.9648e-01,  4.5232e-02],
          ...,
          [-1.7231e-01, -1.0732e-03,  6.9392e-02,  ...,  3.9520e-01,  8.5656e-02, -4.5488e-01],
          [-1.7231e-01, -1.0732e-03,  6.9392e-02,  ...,  3.9520e-01,  8.5656e-02, -4.5488e-01],
          [-1.7231e-01, -1.0732e-03,  6.9392e-02,  ...,  3.9520e-01,  8.5656e-02, -4.5488e-01]],

         [[-3.0480e-01, -3.6161e-01, -3.1065e-01,  ..., -4.9130e-02,  8.4866e-02,  2.3320e-01],
          [ 2.1553e-01,  2.3703e-02, -2.0217e-01,  ...,  2.2144e-01,  2.2043e-02, -1.7461e-01],
          [ 2.3840e-01,  4.3428e-01,  5.6470e-01,  ..., -4.0661e-01, -7.6736e-02,  3.0202e-01],
          ...,
          [-4.0098e-01, -4.3550e-01, -3.8989e-01,  ..., -4.1931e-01, -3.5640e-01, -2.4596e-01],
          [-4.0098e-01, -4.3550e-01, -3.8989e-01,  ..., -4.1931e-01, -3.5640e-01, -2.4596e-01],
          [-4.0098e-01, -4.3550e-01, -3.8989e-01,  ..., -4.1931e-01, -3.5640e-01, -2.4596e-01]]]])

2025-07-26 04:51:58.650386 GPU 3 120642 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:51:59.088425 GPU 6 123540 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:52:02.404977 GPU 1 123699 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:52:07.984959 GPU 3 123858 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:52:19.640351 GPU 4 123147 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:52:29.802344 GPU 5 124018 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:52:32.262775 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 102676560, 6]) != torch.Size([2, 2, 102676562, 6]).
ACTUAL: (shape=torch.Size([2, 2, 102676560, 6]), dtype=torch.float32)
tensor([[[[ 9.6666e-03,  3.5472e-01, -1.6176e-01,  1.2223e-01, -1.2996e-01, -1.7573e-01],
          [-9.4848e-02,  3.3420e-01, -1.5002e-01, -6.4277e-02, -5.9238e-04, -2.4317e-01],
          [-2.5271e-01,  2.9797e-01, -1.1419e-01, -3.3030e-01,  2.0062e-01, -3.0554e-01],
          ...,
          [ 1.7394e-02,  5.4683e-02, -2.3177e-01, -1.1645e-01,  1.7008e-01,  2.5281e-01],
          [ 1.7394e-02,  5.4683e-02, -2.3177e-01, -1.1645e-01,  1.7008e-01,  2.5281e-01],
          [ 1.7394e-02,  5.4683e-02, -2.3177e-01, -1.1645e-01,  1.7008e-01,  2.5281e-01]],

         [[-9.1622e-02, -5.0585e-01, -6.1079e-01, -3.0727e-01,  4.3209e-01,  1.9752e-01],
          [-2.3041e-01, -2.7310e-01, -1.4461e-01, -1.8532e-01,  2.3623e-01,  2.9688e-01],
          [-4.1800e-01,  5.8581e-02,  4.6905e-01, -1.3966e-02, -2.4852e-02,  4.2397e-01],
          ...,
          [ 4.1825e-01, -4.7554e-01,  1.9789e-02, -1.2119e-01, -3.4258e-01, -2.1121e-02],
          [ 4.1825e-01, -4.7554e-01,  1.9789e-02, -1.2119e-01, -3.4258e-01, -2.1121e-02],
          [ 4.1825e-01, -4.7554e-01,  1.9789e-02, -1.2119e-01, -3.4258e-01, -2.1121e-02]]],


        [[[-1.8880e-01,  1.8743e-01, -3.1531e-01, -4.5294e-01,  3.1478e-01, -3.6570e-02],
          [-4.5138e-02, -3.4611e-02, -1.3220e-01, -2.4587e-01,  1.5298e-01,  6.9768e-02],
          [ 1.5649e-01, -3.1417e-01,  1.1934e-01,  4.3772e-02, -5.4358e-02,  2.2832e-01],
          ...,
          [-9.7288e-02, -2.5325e-01, -2.7926e-01, -1.0554e-01, -1.6627e-01, -2.0754e-01],
          [-9.7288e-02, -2.5325e-01, -2.7926e-01, -1.0554e-01, -1.6627e-01, -2.0754e-01],
          [-9.7288e-02, -2.5325e-01, -2.7926e-01, -1.0554e-01, -1.6627e-01, -2.0754e-01]],

         [[-1.2609e-01, -5.2063e-01,  2.2218e-01,  6.4070e-02, -2.8613e-01, -2.9172e-01],
          [ 7.2132e-03, -1.9985e-01,  1.2240e-01,  1.2266e-01, -1.6565e-01, -1.7796e-02],
          [ 1.7862e-01,  2.3585e-01,  7.5831e-03,  2.0597e-01,  8.2882e-04,  3.3882e-01],
          ...,
          [-1.6603e-01, -1.7184e-01,  5.1419e-02, -8.3106e-02,  1.0153e-01, -7.4828e-02],
          [-1.6603e-01, -1.7184e-01,  5.1419e-02, -8.3106e-02,  1.0153e-01, -7.4828e-02],
          [-1.6603e-01, -1.7184e-01,  5.1419e-02, -8.3106e-02,  1.0153e-01, -7.4828e-02]]]])
DESIRED: (shape=torch.Size([2, 2, 102676562, 6]), dtype=torch.float32)
tensor([[[[ 9.6666e-03,  3.5472e-01, -1.6176e-01,  1.2223e-01, -1.2996e-01, -1.7573e-01],
          [-9.4848e-02,  3.3420e-01, -1.5002e-01, -6.4277e-02, -5.9238e-04, -2.4317e-01],
          [-2.5271e-01,  2.9797e-01, -1.1419e-01, -3.3030e-01,  2.0062e-01, -3.0554e-01],
          ...,
          [ 1.7394e-02,  5.4683e-02, -2.3177e-01, -1.1645e-01,  1.7008e-01,  2.5281e-01],
          [ 1.7394e-02,  5.4683e-02, -2.3177e-01, -1.1645e-01,  1.7008e-01,  2.5281e-01],
          [ 1.7394e-02,  5.4683e-02, -2.3177e-01, -1.1645e-01,  1.7008e-01,  2.5281e-01]],

         [[-9.1622e-02, -5.0585e-01, -6.1079e-01, -3.0727e-01,  4.3209e-01,  1.9752e-01],
          [-2.3041e-01, -2.7310e-01, -1.4461e-01, -1.8532e-01,  2.3623e-01,  2.9688e-01],
          [-4.1800e-01,  5.8581e-02,  4.6905e-01, -1.3966e-02, -2.4852e-02,  4.2397e-01],
          ...,
          [ 4.1825e-01, -4.7554e-01,  1.9789e-02, -1.2119e-01, -3.4258e-01, -2.1121e-02],
          [ 4.1825e-01, -4.7554e-01,  1.9789e-02, -1.2119e-01, -3.4258e-01, -2.1121e-02],
          [ 4.1825e-01, -4.7554e-01,  1.9789e-02, -1.2119e-01, -3.4258e-01, -2.1121e-02]]],


        [[[-1.8880e-01,  1.8743e-01, -3.1531e-01, -4.5294e-01,  3.1478e-01, -3.6570e-02],
          [-4.5138e-02, -3.4611e-02, -1.3220e-01, -2.4587e-01,  1.5298e-01,  6.9768e-02],
          [ 1.5649e-01, -3.1417e-01,  1.1934e-01,  4.3772e-02, -5.4358e-02,  2.2832e-01],
          ...,
          [-9.7288e-02, -2.5325e-01, -2.7926e-01, -1.0554e-01, -1.6627e-01, -2.0754e-01],
          [-9.7288e-02, -2.5325e-01, -2.7926e-01, -1.0554e-01, -1.6627e-01, -2.0754e-01],
          [-9.7288e-02, -2.5325e-01, -2.7926e-01, -1.0554e-01, -1.6627e-01, -2.0754e-01]],

         [[-1.2609e-01, -5.2063e-01,  2.2218e-01,  6.4070e-02, -2.8613e-01, -2.9172e-01],
          [ 7.2132e-03, -1.9985e-01,  1.2240e-01,  1.2266e-01, -1.6565e-01, -1.7796e-02],
          [ 1.7862e-01,  2.3585e-01,  7.5831e-03,  2.0597e-01,  8.2882e-04,  3.3882e-01],
          ...,
          [-1.6603e-01, -1.7184e-01,  5.1419e-02, -8.3106e-02,  1.0153e-01, -7.4828e-02],
          [-1.6603e-01, -1.7184e-01,  5.1419e-02, -8.3106e-02,  1.0153e-01, -7.4828e-02],
          [-1.6603e-01, -1.7184e-01,  5.1419e-02, -8.3106e-02,  1.0153e-01, -7.4828e-02]]]])

2025-07-26 04:52:48.176880 GPU 2 120725 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 2, 102676560, 6]) != torch.Size([2, 2, 102676562, 6]).
ACTUAL: (shape=torch.Size([2, 2, 102676560, 6]), dtype=torch.float32)
tensor([[[[-0.0485, -0.3515, -0.2076, -0.2883,  0.1546,  0.1937],
          [ 0.1210, -0.2109,  0.1888, -0.0341,  0.0631, -0.1141],
          [ 0.2323, -0.1476,  0.4295,  0.2041, -0.0788, -0.2921],
          ...,
          [ 0.4598,  0.2318, -0.0162, -0.0095, -0.5191,  0.1452],
          [ 0.4598,  0.2318, -0.0162, -0.0095, -0.5191,  0.1452],
          [ 0.4598,  0.2318, -0.0162, -0.0095, -0.5191,  0.1452]],

         [[-0.1821,  0.3728,  0.3584, -0.2382, -0.0131, -0.4543],
          [-0.3083, -0.0854, -0.1513,  0.1165, -0.0712, -0.1629],
          [-0.3288, -0.2774, -0.4822,  0.3292, -0.1106,  0.1953],
          ...,
          [-0.4479,  0.4504,  0.2773, -0.3712, -0.4265, -0.3300],
          [-0.4479,  0.4504,  0.2773, -0.3712, -0.4265, -0.3300],
          [-0.4479,  0.4504,  0.2773, -0.3712, -0.4265, -0.3300]]],


        [[[-0.4111, -0.0484, -0.2169,  0.5011,  0.2128,  0.3278],
          [-0.0157, -0.2594, -0.0131,  0.2243,  0.0438,  0.2411],
          [ 0.1510, -0.4243,  0.1208, -0.0527, -0.1685,  0.0127],
          ...,
          [-0.4519, -0.1864, -0.2483,  0.0530,  0.2482, -0.1794],
          [-0.4519, -0.1864, -0.2483,  0.0530,  0.2482, -0.1794],
          [-0.4519, -0.1864, -0.2483,  0.0530,  0.2482, -0.1794]],

         [[-0.4004, -0.4637,  0.1314, -0.1697,  0.3633, -0.1537],
          [ 0.0273, -0.2226, -0.1243, -0.2534,  0.1678, -0.1716],
          [ 0.3098, -0.0473, -0.3559, -0.2727, -0.1236, -0.2346],
          ...,
          [-0.3551,  0.2518, -0.1476, -0.2395, -0.0300,  0.3218],
          [-0.3551,  0.2518, -0.1476, -0.2395, -0.0300,  0.3218],
          [-0.3551,  0.2518, -0.1476, -0.2395, -0.0300,  0.3218]]]])
DESIRED: (shape=torch.Size([2, 2, 102676562, 6]), dtype=torch.float32)
tensor([[[[-0.0485, -0.3515, -0.2076, -0.2883,  0.1546,  0.1937],
          [ 0.1210, -0.2109,  0.1888, -0.0341,  0.0631, -0.1141],
          [ 0.2323, -0.1476,  0.4295,  0.2041, -0.0788, -0.2921],
          ...,
          [ 0.4598,  0.2318, -0.0162, -0.0095, -0.5191,  0.1452],
          [ 0.4598,  0.2318, -0.0162, -0.0095, -0.5191,  0.1452],
          [ 0.4598,  0.2318, -0.0162, -0.0095, -0.5191,  0.1452]],

         [[-0.1821,  0.3728,  0.3584, -0.2382, -0.0131, -0.4543],
          [-0.3083, -0.0854, -0.1513,  0.1165, -0.0712, -0.1629],
          [-0.3288, -0.2774, -0.4822,  0.3292, -0.1106,  0.1953],
          ...,
          [-0.4479,  0.4504,  0.2773, -0.3712, -0.4265, -0.3300],
          [-0.4479,  0.4504,  0.2773, -0.3712, -0.4265, -0.3300],
          [-0.4479,  0.4504,  0.2773, -0.3712, -0.4265, -0.3300]]],


        [[[-0.4111, -0.0484, -0.2169,  0.5011,  0.2128,  0.3278],
          [-0.0157, -0.2594, -0.0131,  0.2243,  0.0438,  0.2411],
          [ 0.1510, -0.4243,  0.1208, -0.0527, -0.1685,  0.0127],
          ...,
          [-0.4519, -0.1864, -0.2483,  0.0530,  0.2482, -0.1794],
          [-0.4519, -0.1864, -0.2483,  0.0530,  0.2482, -0.1794],
          [-0.4519, -0.1864, -0.2483,  0.0530,  0.2482, -0.1794]],

         [[-0.4004, -0.4637,  0.1314, -0.1697,  0.3633, -0.1537],
          [ 0.0273, -0.2226, -0.1243, -0.2534,  0.1678, -0.1716],
          [ 0.3098, -0.0473, -0.3559, -0.2727, -0.1236, -0.2346],
          ...,
          [-0.3551,  0.2518, -0.1476, -0.2395, -0.0300,  0.3218],
          [-0.3551,  0.2518, -0.1476, -0.2395, -0.0300,  0.3218],
          [-0.3551,  0.2518, -0.1476, -0.2395, -0.0300,  0.3218]]]])

2025-07-26 04:53:06.170181 GPU 7 123377 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:53:14.767418 GPU 6 124339 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:53:16.429475 GPU 7 124427 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:53:20.558069 GPU 2 120725 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:53:23.027045 GPU 1 124656 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:53:31.608644 GPU 2 124815 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 04:53:42.757805 GPU 3 124975 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476906 (unix time) try "date -d @1753476906" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e82f) received by PID 124975 (TID 0x7f20c67d1740) from PID 124975 ***]


2025-07-26 04:53:50.997456 GPU 5 125135 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476926 (unix time) try "date -d @1753476926" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e8cf) received by PID 125135 (TID 0x7febac723740) from PID 125135 ***]


2025-07-26 04:54:33.394754 GPU 6 125296 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476950 (unix time) try "date -d @1753476950" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e970) received by PID 125296 (TID 0x7f800eec4740) from PID 125296 ***]


2025-07-26 04:54:47.949134 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 1 / 2281701400 (0.0%)
Greatest absolute difference: 0.639074981212616 at index (0, 0, 0, 9) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 0, 9) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([2, 2, 57042535, 10]), dtype=torch.float32)
tensor([[[[-0.4844,  0.0814, -0.1980,  ...,  0.0727, -0.0531, -0.6391],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 57042535, 10]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])

2025-07-26 04:54:57.507130 GPU 1 125714 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753476979 (unix time) try "date -d @1753476979" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1eb12) received by PID 125714 (TID 0x7f79b6328740) from PID 125714 ***]


2025-07-26 04:55:32.345453 GPU 5 126103 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477023 (unix time) try "date -d @1753477023" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ec97) received by PID 126103 (TID 0x7f8dba8eb740) from PID 126103 ***]


2025-07-26 04:55:55.257928 GPU 6 126263 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477035 (unix time) try "date -d @1753477035" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ed37) received by PID 126263 (TID 0x7fd1dda43740) from PID 126263 ***]


2025-07-26 04:56:24.052043 GPU 1 126427 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[accuracy error] backward paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 4 / 2281701400 (0.0%)
Greatest absolute difference: 0.8928765058517456 at index (0, 0, 0, 3) (up to 0.5 allowed)
Greatest relative difference: inf at index (0, 0, 0, 3) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([2, 2, 57042535, 10]), dtype=torch.float32)
tensor([[[[-0.1976, -0.1142, -0.0510,  ...,  0.2666,  0.6441,  0.6640],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          ...,
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])
DESIRED: (shape=torch.Size([2, 2, 57042535, 10]), dtype=torch.float32)
tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])

2025-07-26 04:56:50.654851 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 171127616, 4]) != torch.Size([2, 171127603, 4]).
ACTUAL: (shape=torch.Size([2, 171127616, 4]), dtype=torch.float32)
tensor([[[ 0.0109,  0.0825,  0.1489, -0.2993],
         [ 0.2147, -0.3945, -0.1955, -0.3667],
         [-0.0334,  0.1098, -0.1412, -0.3197],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.2934, -0.0090, -0.2167, -0.0931],
         [-0.0381, -0.3259,  0.1409, -0.1753],
         [-0.1201, -0.0949,  0.0329,  0.0763],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 171127603, 4]), dtype=torch.float32)
tensor([[[ 0.0109,  0.0825,  0.1489, -0.2993],
         [ 0.2147, -0.3945, -0.1955, -0.3667],
         [-0.0334,  0.1098, -0.1412, -0.3197],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.2934, -0.0090, -0.2167, -0.0931],
         [-0.0381, -0.3259,  0.1409, -0.1753],
         [-0.1201, -0.0949,  0.0329,  0.0763],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])

2025-07-26 04:57:00.617006 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 171127616, 4]) != torch.Size([2, 171127603, 4]).
ACTUAL: (shape=torch.Size([2, 171127616, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [ 0.0808, -0.0219, -0.1089, -0.3783],
         [-0.0373,  0.3441,  0.0097, -0.4466],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.0217,  0.2063, -0.0607, -0.2335],
         [-0.0351, -0.0502, -0.3531,  0.3329],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 171127603, 4]), dtype=torch.float32)
tensor([[[ 0.0099, -0.0218, -0.1472, -0.3319],
         [ 0.1820,  0.1437, -0.0855, -0.3252],
         [ 0.2152,  0.2422, -0.0965, -0.4404],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1601,  0.1004,  0.0978, -0.1173],
         [ 0.0937,  0.1619, -0.0827, -0.3830],
         [-0.1073, -0.0059, -0.4214,  0.3176],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 04:57:09.508989 GPU 5 126612 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 171127616, 4]) != torch.Size([2, 171127603, 4]).
ACTUAL: (shape=torch.Size([2, 171127616, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.2465, -0.0303, -0.0435, -0.2544],
         [ 0.2427, -0.1109,  0.2531,  0.0181],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.2649, -0.1070,  0.2324,  0.1880],
         [ 0.0142, -0.1567, -0.3000,  0.2294],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])
DESIRED: (shape=torch.Size([2, 171127603, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.2465, -0.0303, -0.0435, -0.2544],
         [ 0.2427, -0.1109,  0.2531,  0.0181],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.2649, -0.1070,  0.2324,  0.1880],
         [ 0.0142, -0.1567, -0.3000,  0.2294],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])

2025-07-26 04:57:12.136662 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 171127616, 4]) != torch.Size([2, 171127603, 4]).
ACTUAL: (shape=torch.Size([2, 171127616, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [ 0.1741,  0.0294,  0.0906,  0.2590],
         [-0.1934,  0.1686,  0.0304,  0.2156],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [-0.4317,  0.1929, -0.1353, -0.1673],
         [-0.2825,  0.0559, -0.1678, -0.1026],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])
DESIRED: (shape=torch.Size([2, 171127603, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [ 0.1741,  0.0294,  0.0906,  0.2590],
         [-0.1934,  0.1686,  0.0304,  0.2156],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [-0.4317,  0.1929, -0.1353, -0.1673],
         [-0.2825,  0.0559, -0.1678, -0.1026],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])

2025-07-26 04:57:18.986788 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 199648864, 4]) != torch.Size([2, 199648871, 4]).
ACTUAL: (shape=torch.Size([2, 199648864, 4]), dtype=torch.float32)
tensor([[[ 0.0047,  0.0592,  0.2201, -0.3357],
         [ 0.1544, -0.1776, -0.2150, -0.2698],
         [ 0.2514, -0.1369, -0.0751, -0.3634],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.3584,  0.0505, -0.1797, -0.1402],
         [ 0.0009, -0.3319, -0.0608, -0.0518],
         [-0.2791, -0.3103, -0.3671,  0.2583],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 199648871, 4]), dtype=torch.float32)
tensor([[[ 0.0047,  0.0592,  0.2201, -0.3357],
         [ 0.1544, -0.1776, -0.2150, -0.2698],
         [ 0.2514, -0.1369, -0.0751, -0.3634],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.3584,  0.0505, -0.1797, -0.1402],
         [ 0.0009, -0.3319, -0.0608, -0.0518],
         [-0.2791, -0.3103, -0.3671,  0.2583],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])

2025-07-26 04:57:19.616107 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 199648864, 4]) != torch.Size([2, 199648871, 4]).
ACTUAL: (shape=torch.Size([2, 199648864, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.0341,  0.0128,  0.3186, -0.1376],
         [-0.4179, -0.1838, -0.0237,  0.3485],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3412,  0.1190, -0.2001,  0.1761],
         [ 0.0936, -0.2244, -0.2138,  0.0536],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 199648871, 4]), dtype=torch.float32)
tensor([[[ 0.1170,  0.1366, -0.1408,  0.0923],
         [-0.1147, -0.0847,  0.3769, -0.1013],
         [-0.4245, -0.1661, -0.1195,  0.3508],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[ 0.0482, -0.2282, -0.2931,  0.1650],
         [ 0.2916,  0.1704, -0.1867,  0.2880],
         [ 0.0638, -0.3148, -0.2294, -0.0480],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 04:57:20.755508 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 199648864, 4]) != torch.Size([2, 199648871, 4]).
ACTUAL: (shape=torch.Size([2, 199648864, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.3194,  0.1426,  0.2192, -0.3903],
         [ 0.0341,  0.2890,  0.3142, -0.1519],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.0610, -0.1103, -0.0486,  0.1293],
         [-0.1096,  0.0506,  0.3975, -0.0348],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])
DESIRED: (shape=torch.Size([2, 199648871, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.3194,  0.1426,  0.2192, -0.3903],
         [ 0.0341,  0.2890,  0.3142, -0.1519],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.0610, -0.1103, -0.0486,  0.1293],
         [-0.1096,  0.0506,  0.3975, -0.0348],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])

2025-07-26 04:57:27.699314 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 199648864, 4]) != torch.Size([2, 199648871, 4]).
ACTUAL: (shape=torch.Size([2, 199648864, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [ 0.0085, -0.1402, -0.1255, -0.4162],
         [-0.2223,  0.4029,  0.0872, -0.4345],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.1041,  0.2381, -0.0449, -0.1267],
         [ 0.0453, -0.0579, -0.2558,  0.2437],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 199648871, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [ 0.0085, -0.1402, -0.1255, -0.4162],
         [-0.2223,  0.4029,  0.0872, -0.4345],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.1041,  0.2381, -0.0449, -0.1267],
         [ 0.0453, -0.0579, -0.2558,  0.2437],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 04:57:37.166617 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 228170144, 4]) != torch.Size([2, 228170138, 4]).
ACTUAL: (shape=torch.Size([2, 228170144, 4]), dtype=torch.float32)
tensor([[[ 0.1628,  0.1994, -0.4494,  0.1890],
         [ 0.0500, -0.1092,  0.0040,  0.1989],
         [-0.1716,  0.3791,  0.0902,  0.2395],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.3238,  0.3885, -0.1205,  0.4189],
         [-0.4151,  0.1802,  0.0988, -0.1407],
         [-0.3409,  0.0747, -0.2832, -0.2681],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])
DESIRED: (shape=torch.Size([2, 228170138, 4]), dtype=torch.float32)
tensor([[[ 0.1628,  0.1994, -0.4494,  0.1890],
         [ 0.0500, -0.1092,  0.0040,  0.1989],
         [-0.1716,  0.3791,  0.0902,  0.2395],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.3238,  0.3885, -0.1205,  0.4189],
         [-0.4151,  0.1802,  0.0988, -0.1407],
         [-0.3409,  0.0747, -0.2832, -0.2681],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])

2025-07-26 04:57:41.890294 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 228170144, 4]) != torch.Size([2, 228170138, 4]).
ACTUAL: (shape=torch.Size([2, 228170144, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0880,  0.0610, -0.2364, -0.1632],
         [ 0.2502, -0.2805, -0.1313, -0.3677],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [ 0.0438, -0.3384, -0.2827,  0.0841],
         [-0.1681, -0.3311, -0.1371,  0.0524],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 228170138, 4]), dtype=torch.float32)
tensor([[[ 5.8084e-05,  4.1733e-02,  2.7358e-01, -3.6302e-01],
         [ 1.0911e-01, -1.4946e-02, -2.2963e-01, -1.9709e-01],
         [ 2.5900e-01, -2.5200e-01, -1.1526e-01, -3.6793e-01],
         ...,
         [ 1.7082e-02,  1.0447e-01,  4.6039e-01,  2.0623e-01],
         [ 1.7082e-02,  1.0447e-01,  4.6039e-01,  2.0623e-01],
         [ 1.7082e-02,  1.0447e-01,  4.6039e-01,  2.0623e-01]],

        [[-4.0722e-01,  9.5220e-02, -1.5193e-01, -1.7548e-01],
         [ 3.0116e-02, -3.3634e-01, -2.1208e-01,  4.0825e-02],
         [-2.0062e-01, -3.3235e-01, -2.0658e-01,  1.0934e-01],
         ...,
         [-4.0331e-01, -2.4818e-01,  1.2908e-01, -2.5180e-02],
         [-4.0331e-01, -2.4818e-01,  1.2908e-01, -2.5180e-02],
         [-4.0331e-01, -2.4818e-01,  1.2908e-01, -2.5180e-02]]])

2025-07-26 04:57:45.783974 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 228170144, 4]) != torch.Size([2, 228170138, 4]).
ACTUAL: (shape=torch.Size([2, 228170144, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.1580,  0.0940,  0.2700, -0.1678],
         [-0.3949, -0.2102,  0.1837,  0.1862],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3824,  0.0763, -0.2113,  0.0829],
         [ 0.1417, -0.0242, -0.1932,  0.2290],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 228170138, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.1580,  0.0940,  0.2700, -0.1678],
         [-0.3949, -0.2102,  0.1837,  0.1862],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3824,  0.0763, -0.2113,  0.0829],
         [ 0.1417, -0.0242, -0.1932,  0.2290],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 04:57:54.281349 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 228170144, 4]) != torch.Size([2, 228170138, 4]).
ACTUAL: (shape=torch.Size([2, 228170144, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0458, -0.2289, -0.1380, -0.4446],
         [-0.0538,  0.2949,  0.0152, -0.3890],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.1660,  0.2619, -0.0331, -0.0466],
         [ 0.0655,  0.0337, -0.1837, -0.0175],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 228170138, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0458, -0.2289, -0.1380, -0.4446],
         [-0.0538,  0.2949,  0.0152, -0.3890],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.1660,  0.2619, -0.0331, -0.0466],
         [ 0.0655,  0.0337, -0.1837, -0.0175],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 04:58:06.052891 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 256691392, 4]) != torch.Size([2, 256691405, 4]).
ACTUAL: (shape=torch.Size([2, 256691392, 4]), dtype=torch.float32)
tensor([[[ 0.1845,  0.2381, -0.4766,  0.1943],
         [-0.0387, -0.2081, -0.0579,  0.1560],
         [ 0.0993,  0.2728,  0.1454,  0.2885],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.3808,  0.4063, -0.1618,  0.4606],
         [-0.4033,  0.1712,  0.2660, -0.1218],
         [-0.4019,  0.1484, -0.3496, -0.2290],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])
DESIRED: (shape=torch.Size([2, 256691405, 4]), dtype=torch.float32)
tensor([[[ 0.1845,  0.2381, -0.4766,  0.1943],
         [-0.0387, -0.2081, -0.0579,  0.1560],
         [ 0.0993,  0.2728,  0.1454,  0.2885],
         ...,
         [ 0.2457,  0.2855, -0.1315, -0.4504],
         [ 0.2457,  0.2855, -0.1315, -0.4504],
         [ 0.2457,  0.2855, -0.1315, -0.4504]],

        [[ 0.3808,  0.4063, -0.1618,  0.4606],
         [-0.4033,  0.1712,  0.2660, -0.1218],
         [-0.4019,  0.1484, -0.3496, -0.2290],
         ...,
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])

2025-07-26 04:58:06.783018 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 256691392, 4]) != torch.Size([2, 256691405, 4]).
ACTUAL: (shape=torch.Size([2, 256691392, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0645,  0.1453, -0.2440, -0.1255],
         [ 0.2305, -0.3438, -0.1670, -0.3671],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [ 0.0589, -0.3407, -0.3611,  0.1321],
         [-0.0959, -0.3282,  0.0173, -0.0741],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 256691405, 4]), dtype=torch.float32)
tensor([[[-0.0036,  0.0282,  0.3151, -0.3843],
         [ 0.0739,  0.1116, -0.2410, -0.1406],
         [ 0.2344, -0.3312, -0.1599, -0.3672],
         ...,
         [-0.2787,  0.1132,  0.0893,  0.0766],
         [-0.2787,  0.1132,  0.0893,  0.0766],
         [-0.2787,  0.1132,  0.0893,  0.0766]],

        [[-0.4452,  0.1300, -0.1304, -0.2029],
         [ 0.0528, -0.3398, -0.3297,  0.1129],
         [-0.1103, -0.3288, -0.0136, -0.0488],
         ...,
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])

2025-07-26 04:58:13.106817 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 256691392, 4]) != torch.Size([2, 256691405, 4]).
ACTUAL: (shape=torch.Size([2, 256691392, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2545,  0.1571,  0.2322, -0.1912],
         [-0.3769, -0.2307,  0.3451,  0.0600],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.4145,  0.0430, -0.2199,  0.0103],
         [ 0.1791,  0.1314, -0.1773,  0.3653],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 256691405, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2545,  0.1571,  0.2322, -0.1912],
         [-0.3769, -0.2307,  0.3451,  0.0600],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.4145,  0.0430, -0.2199,  0.0103],
         [ 0.1791,  0.1314, -0.1773,  0.3653],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 04:58:24.663363 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 256691392, 4]) != torch.Size([2, 256691405, 4]).
ACTUAL: (shape=torch.Size([2, 256691392, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0880, -0.2979, -0.1477, -0.4667],
         [ 0.0772,  0.2109, -0.0408, -0.3536],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2140,  0.2804, -0.0239,  0.0157],
         [ 0.0812,  0.1049, -0.1276, -0.2205],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 256691405, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0880, -0.2979, -0.1477, -0.4667],
         [ 0.0772,  0.2109, -0.0408, -0.3536],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2140,  0.2804, -0.0239,  0.0157],
         [ 0.0812,  0.1049, -0.1276, -0.2205],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 04:58:42.789983 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 313733952, 4]) != torch.Size([2, 313733940, 4]).
ACTUAL: (shape=torch.Size([2, 313733952, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2943,  0.1953,  0.1425, -0.1576],
         [-0.2048, -0.1437,  0.4123, -0.0794],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3722, -0.0261, -0.2384, -0.0108],
         [ 0.2616,  0.2015, -0.1786,  0.3558],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 313733940, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2943,  0.1953,  0.1425, -0.1576],
         [-0.2048, -0.1437,  0.4123, -0.0794],
         ...,
         [-0.4704, -0.2617,  0.3095,  0.1044],
         [-0.4704, -0.2617,  0.3095,  0.1044],
         [-0.4704, -0.2617,  0.3095,  0.1044]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3722, -0.0261, -0.2384, -0.0108],
         [ 0.2616,  0.2015, -0.1786,  0.3558],
         ...,
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])

2025-07-26 04:58:53.934899 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 313733952, 4]) != torch.Size([2, 313733940, 4]).
ACTUAL: (shape=torch.Size([2, 313733952, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.1038, -0.3079, -0.1544, -0.4636],
         [ 0.1268,  0.0534, -0.0983, -0.3542],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2399,  0.2686, -0.0009,  0.0406],
         [ 0.0308,  0.1861, -0.0707, -0.3015],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 313733940, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0948, -0.2853, -0.1538, -0.4532],
         [ 0.1130,  0.0308, -0.1014, -0.3614],
         ...,
         [-0.3062, -0.3005,  0.3601, -0.0760],
         [-0.3062, -0.3005,  0.3601, -0.0760],
         [-0.3062, -0.3005,  0.3601, -0.0760]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2336,  0.2553,  0.0069,  0.0281],
         [ 0.0150,  0.1922, -0.0677, -0.2811],
         ...,
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])

2025-07-26 04:59:06.022725 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 313733952, 4]) != torch.Size([2, 313733940, 4]).
ACTUAL: (shape=torch.Size([2, 313733952, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.4134,  0.2538,  0.1657, -0.2590],
         [-0.1767,  0.0386,  0.2836, -0.4599],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2383, -0.0329, -0.0868,  0.0474],
         [ 0.1095, -0.1711, -0.0147,  0.1717],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])
DESIRED: (shape=torch.Size([2, 313733940, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.4134,  0.2538,  0.1657, -0.2590],
         [-0.1767,  0.0386,  0.2836, -0.4599],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2383, -0.0329, -0.0868,  0.0474],
         [ 0.1095, -0.1711, -0.0147,  0.1717],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])

2025-07-26 04:59:15.518927 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 313733952, 4]) != torch.Size([2, 313733940, 4]).
ACTUAL: (shape=torch.Size([2, 313733952, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.3068,  0.1994,  0.1623, -0.1751],
         [-0.2364, -0.1644,  0.4246, -0.0717],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3949, -0.0120, -0.2345, -0.0231],
         [ 0.2511,  0.2124, -0.1758,  0.3795],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 313733940, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.3068,  0.1994,  0.1623, -0.1751],
         [-0.2364, -0.1644,  0.4246, -0.0717],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3949, -0.0120, -0.2345, -0.0231],
         [ 0.2511,  0.2124, -0.1758,  0.3795],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 04:59:26.201481 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 342255232, 4]) != torch.Size([2, 342255207, 4]).
ACTUAL: (shape=torch.Size([2, 342255232, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0724, -0.2289, -0.1524, -0.4272],
         [ 0.0555, -0.0633, -0.1147, -0.3915],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2179,  0.2222,  0.0264, -0.0031],
         [-0.0505,  0.2174, -0.0551, -0.1961],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 342255207, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0724, -0.2289, -0.1524, -0.4272],
         [ 0.0555, -0.0633, -0.1147, -0.3915],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2179,  0.2222,  0.0264, -0.0031],
         [-0.0505,  0.2174, -0.0551, -0.1961],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 04:59:40.475503 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 342255232, 4]) != torch.Size([2, 342255207, 4]).
ACTUAL: (shape=torch.Size([2, 342255232, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.3609,  0.2511,  0.1801, -0.2134],
         [-0.2322,  0.0790,  0.2585, -0.4328],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2296, -0.0242, -0.0874,  0.0180],
         [ 0.0432, -0.1474, -0.0279,  0.1552],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])
DESIRED: (shape=torch.Size([2, 342255207, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.3031,  0.2481,  0.1959, -0.1633],
         [-0.2627,  0.1013,  0.2448, -0.4179],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2201, -0.0146, -0.0881, -0.0143],
         [ 0.0067, -0.1344, -0.0351,  0.1462],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])

2025-07-26 04:59:49.733179 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 342255232, 4]) != torch.Size([2, 342255207, 4]).
ACTUAL: (shape=torch.Size([2, 342255232, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2861,  0.1926,  0.1292, -0.1459],
         [-0.1312, -0.0955,  0.3834, -0.0973],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3571, -0.0355, -0.2409, -0.0026],
         [ 0.2861,  0.1761, -0.1853,  0.3004],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 342255207, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2861,  0.1926,  0.1292, -0.1459],
         [-0.1312, -0.0955,  0.3834, -0.0973],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.3571, -0.0355, -0.2409, -0.0026],
         [ 0.2861,  0.1761, -0.1853,  0.3004],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 04:59:50.906185 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 342255232, 4]) != torch.Size([2, 342255207, 4]).
ACTUAL: (shape=torch.Size([2, 342255232, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0370,  0.1802, -0.1503, -0.1463],
         [ 0.1584, -0.1921, -0.2137, -0.2762],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.0201, -0.2592, -0.3721,  0.1046],
         [-0.0017, -0.3315, -0.0474, -0.0600],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 342255207, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0370,  0.1802, -0.1503, -0.1463],
         [ 0.1584, -0.1921, -0.2137, -0.2762],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.0201, -0.2592, -0.3721,  0.1046],
         [-0.0017, -0.3315, -0.0474, -0.0600],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])

2025-07-26 04:59:59.027197 GPU 5 126612 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 370776448, 4]) != torch.Size([2, 370776474, 4]).
ACTUAL: (shape=torch.Size([2, 370776448, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.1208,  0.2894, -0.0422, -0.0144],
         [ 0.2989,  0.1118, -0.0195, -0.1378],
         ...,
         [-0.3147, -0.2087,  0.1152, -0.1382],
         [-0.3147, -0.2087,  0.1152, -0.1382],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0680,  0.1468, -0.0491, -0.0377],
         [-0.2032,  0.0212,  0.0952,  0.0773],
         ...,
         [-0.1720,  0.1413,  0.4757,  0.3676],
         [-0.1720,  0.1413,  0.4757,  0.3676],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])
DESIRED: (shape=torch.Size([2, 370776474, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.1208,  0.2894, -0.0422, -0.0144],
         [ 0.2989,  0.1118, -0.0195, -0.1378],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0680,  0.1468, -0.0491, -0.0377],
         [-0.2032,  0.0212,  0.0952,  0.0773],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])

2025-07-26 04:59:59.662484 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 370776448, 4]) != torch.Size([2, 370776474, 4]).
ACTUAL: (shape=torch.Size([2, 370776448, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [-0.0378, -0.1589, -0.1976,  0.1394],
         [ 0.1196, -0.0315,  0.0525,  0.2326],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [-0.2046,  0.2231,  0.2625,  0.0320],
         [-0.4244,  0.1873, -0.0324, -0.1556],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])
DESIRED: (shape=torch.Size([2, 370776474, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [-0.0019, -0.0947, -0.2427,  0.1483],
         [ 0.0705, -0.0863,  0.0183,  0.2088],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [-0.1100,  0.2528,  0.1939,  0.1013],
         [-0.4179,  0.1823,  0.0602, -0.1451],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])

2025-07-26 05:00:02.721177 GPU 1 126427 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 370776448, 4]) != torch.Size([2, 370776474, 4]).
ACTUAL: (shape=torch.Size([2, 370776448, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [ 0.0563, -0.4792,  0.0990,  0.1216],
         [ 0.2854, -0.2567,  0.2237,  0.3447],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [-0.0381, -0.3010,  0.1025,  0.3011],
         [ 0.2017, -0.1199,  0.2539,  0.1442],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])
DESIRED: (shape=torch.Size([2, 370776474, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [ 0.0563, -0.4792,  0.0990,  0.1216],
         [ 0.2854, -0.2567,  0.2237,  0.3447],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [-0.0381, -0.3010,  0.1025,  0.3011],
         [ 0.2017, -0.1199,  0.2539,  0.1442],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])

2025-07-26 05:00:05.975520 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 370776448, 4]) != torch.Size([2, 370776474, 4]).
ACTUAL: (shape=torch.Size([2, 370776448, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0762, -0.2384, -0.1526, -0.4316],
         [ 0.0418, -0.0856, -0.1178, -0.3987],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2205,  0.2278,  0.0231,  0.0022],
         [-0.0661,  0.2234, -0.0522, -0.1760],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 370776474, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0762, -0.2384, -0.1526, -0.4316],
         [ 0.0418, -0.0856, -0.1178, -0.3987],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2205,  0.2278,  0.0231,  0.0022],
         [-0.0661,  0.2234, -0.0522, -0.1760],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 05:00:15.953436 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 399297728, 4]) != torch.Size([2, 399297742, 4]).
ACTUAL: (shape=torch.Size([2, 399297728, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.1793,  0.2417,  0.2299, -0.0559],
         [-0.3717,  0.1808,  0.1956, -0.3647],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.1998,  0.0059, -0.0895, -0.0837],
         [-0.1236, -0.0880, -0.0611,  0.1138],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])
DESIRED: (shape=torch.Size([2, 399297742, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.1793,  0.2417,  0.2299, -0.0559],
         [-0.3717,  0.1808,  0.1956, -0.3647],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.1998,  0.0059, -0.0895, -0.0837],
         [-0.1236, -0.0880, -0.0611,  0.1138],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])

2025-07-26 05:00:25.162150 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 399297728, 4]) != torch.Size([2, 399297742, 4]).
ACTUAL: (shape=torch.Size([2, 399297728, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2535,  0.1818,  0.0773, -0.1001],
         [ 0.0341,  0.0128,  0.3186, -0.1376],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.2977, -0.0726, -0.2510,  0.0297],
         [ 0.3412,  0.1190, -0.2001,  0.1761],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 399297742, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2145,  0.1689,  0.0150, -0.0451],
         [ 0.1332,  0.0777,  0.2797, -0.1617],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.2264, -0.1171, -0.2630,  0.0683],
         [ 0.3742,  0.0848, -0.2090,  0.1015],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 05:00:30.677322 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 399297728, 4]) != torch.Size([2, 399297742, 4]).
ACTUAL: (shape=torch.Size([2, 399297728, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0308,  0.1569, -0.0791, -0.1827],
         [ 0.1182, -0.0475, -0.2267, -0.2116],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.0851, -0.1996, -0.3351,  0.0575],
         [ 0.0243, -0.3354, -0.1818,  0.0223],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 399297742, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0308,  0.1569, -0.0791, -0.1827],
         [ 0.1182, -0.0475, -0.2267, -0.2116],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.0851, -0.1996, -0.3351,  0.0575],
         [ 0.0243, -0.3354, -0.1818,  0.0223],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])

2025-07-26 05:00:36.634058 GPU 5 126612 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 399297728, 4]) != torch.Size([2, 399297742, 4]).
ACTUAL: (shape=torch.Size([2, 399297728, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.1678,  0.3015, -0.0309, -0.0006],
         [ 0.2977,  0.1086, -0.0201, -0.1405],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0729,  0.1637, -0.0655, -0.0512],
         [-0.2046,  0.0183,  0.0983,  0.0798],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])
DESIRED: (shape=torch.Size([2, 399297742, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.1678,  0.3015, -0.0309, -0.0006],
         [ 0.2977,  0.1086, -0.0201, -0.1405],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0729,  0.1637, -0.0655, -0.0512],
         [-0.2046,  0.0183,  0.0983,  0.0798],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])

2025-07-26 05:00:38.270279 GPU 1 126427 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 427819008, 4]) != torch.Size([2, 427819009, 4]).
ACTUAL: (shape=torch.Size([2, 427819008, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [-0.0551, -0.4646,  0.0160,  0.0505],
         [ 0.1931, -0.4190,  0.1868,  0.2328],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [ 0.0289, -0.1359,  0.0577,  0.2397],
         [-0.0035, -0.3427,  0.1759,  0.2889],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])
DESIRED: (shape=torch.Size([2, 427819009, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [-0.0551, -0.4646,  0.0160,  0.0505],
         [ 0.1931, -0.4190,  0.1868,  0.2328],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [ 0.0289, -0.1359,  0.0577,  0.2397],
         [-0.0035, -0.3427,  0.1759,  0.2889],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])

2025-07-26 05:00:42.198723 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 427819008, 4]) != torch.Size([2, 427819009, 4]).
ACTUAL: (shape=torch.Size([2, 427819008, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [-0.0058, -0.1019, -0.2377,  0.1473],
         [ 0.0322, -0.1290, -0.0084,  0.1903],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [-0.1205,  0.2495,  0.2015,  0.0936],
         [-0.4128,  0.1784,  0.1322, -0.1370],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])
DESIRED: (shape=torch.Size([2, 427819009, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [ 0.0461, -0.0092, -0.3028,  0.1601],
         [-0.0387, -0.2081, -0.0579,  0.1560],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [ 0.0162,  0.2922,  0.1024,  0.1937],
         [-0.4033,  0.1712,  0.2660, -0.1218],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])

2025-07-26 05:00:42.378132 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 427819008, 4]) != torch.Size([2, 427819009, 4]).
ACTUAL: (shape=torch.Size([2, 427819008, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0559, -0.1874, -0.1514, -0.4081],
         [-0.0205, -0.1875, -0.1322, -0.4313],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2063,  0.1978,  0.0407, -0.0259],
         [-0.1371,  0.2507, -0.0386, -0.0840],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 427819009, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0559, -0.1874, -0.1514, -0.4081],
         [-0.0205, -0.1875, -0.1322, -0.4313],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.2063,  0.1978,  0.0407, -0.0259],
         [-0.1371,  0.2507, -0.0386, -0.0840],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 05:00:54.626732 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 427819008, 4]) != torch.Size([2, 427819009, 4]).
ACTUAL: (shape=torch.Size([2, 427819008, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.2453,  0.2451,  0.2118, -0.1132],
         [-0.3543,  0.1680,  0.2034, -0.3732],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2106, -0.0050, -0.0888, -0.0467],
         [-0.1027, -0.0954, -0.0569,  0.1190],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])
DESIRED: (shape=torch.Size([2, 427819009, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.2453,  0.2451,  0.2118, -0.1132],
         [-0.3543,  0.1680,  0.2034, -0.3732],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2106, -0.0050, -0.0888, -0.0467],
         [-0.1027, -0.0954, -0.0569,  0.1190],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])

2025-07-26 05:01:03.733990 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 456340288, 4]) != torch.Size([2, 456340276, 4]).
ACTUAL: (shape=torch.Size([2, 456340288, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.1780,  0.1568, -0.0435,  0.0064],
         [ 0.2882,  0.1792,  0.2190, -0.1995],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.1595, -0.1588, -0.2743,  0.1046],
         [ 0.4258,  0.0313, -0.2230, -0.0150],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 456340276, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.1780,  0.1568, -0.0435,  0.0064],
         [ 0.2882,  0.1792,  0.2190, -0.1995],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.1595, -0.1588, -0.2743,  0.1046],
         [ 0.4258,  0.0313, -0.2230, -0.0150],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 05:01:10.705327 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 456340288, 4]) != torch.Size([2, 456340276, 4]).
ACTUAL: (shape=torch.Size([2, 456340288, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0262,  0.1395, -0.0257, -0.2101],
         [ 0.0880,  0.0610, -0.2364, -0.1632],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.1339, -0.1550, -0.3073,  0.0222],
         [ 0.0438, -0.3384, -0.2827,  0.0841],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 456340276, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0164,  0.1028,  0.0866, -0.2674],
         [ 0.0563,  0.1748, -0.2467, -0.1123],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.2364, -0.0611, -0.2490, -0.0519],
         [ 0.0642, -0.3415, -0.3886,  0.1489],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])

2025-07-26 05:01:16.209711 GPU 5 126612 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 456340288, 4]) != torch.Size([2, 456340276, 4]).
ACTUAL: (shape=torch.Size([2, 456340288, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.0984,  0.2837, -0.0475, -0.0210],
         [ 0.3361,  0.2128, -0.0025, -0.0550],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0657,  0.1387, -0.0413, -0.0313],
         [-0.1593,  0.1123, -0.0023, -0.0013],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])
DESIRED: (shape=torch.Size([2, 456340276, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.0984,  0.2837, -0.0475, -0.0210],
         [ 0.3361,  0.2128, -0.0025, -0.0550],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0657,  0.1387, -0.0413, -0.0313],
         [-0.1593,  0.1123, -0.0023, -0.0013],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])

2025-07-26 05:01:17.734295 GPU 1 126427 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 456340288, 4]) != torch.Size([2, 456340276, 4]).
ACTUAL: (shape=torch.Size([2, 456340288, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [-0.0033, -0.4714,  0.0545,  0.0835],
         [ 0.2138, -0.3826,  0.1950,  0.2579],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [-0.0022, -0.2126,  0.0785,  0.2682],
         [ 0.0425, -0.2927,  0.1934,  0.2564],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])
DESIRED: (shape=torch.Size([2, 456340276, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [-0.0033, -0.4714,  0.0545,  0.0835],
         [ 0.2138, -0.3826,  0.1950,  0.2579],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [-0.0022, -0.2126,  0.0785,  0.2682],
         [ 0.0425, -0.2927,  0.1934,  0.2564],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])

2025-07-26 05:01:22.461246 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 484861568, 4]) != torch.Size([2, 484861544, 4]).
ACTUAL: (shape=torch.Size([2, 484861568, 4]), dtype=torch.float32)
tensor([[[ 7.5688e-02,  1.4392e-01, -1.4307e-01, -2.5559e-01],
         [ 2.0419e-04, -4.6123e-02, -1.4782e-01, -3.4308e-01],
         [-1.1593e-01, -3.3850e-01, -1.5513e-01, -4.7769e-01],
         ...,
         [ 4.4726e-01,  8.5799e-02, -2.6078e-01,  3.6056e-01],
         [ 4.4726e-01,  8.5799e-02, -2.6078e-01,  3.6056e-01],
         [ 4.4726e-01,  8.5799e-02, -2.6078e-01,  3.6056e-01]],

        [[-1.1388e-01,  3.0815e-03,  1.5496e-01, -2.0878e-01],
         [-1.6689e-01,  1.1476e-01,  8.9402e-02, -1.0390e-01],
         [-2.4844e-01,  2.8658e-01, -1.1451e-02,  5.7453e-02],
         ...,
         [-2.5067e-01,  6.2916e-02, -2.9163e-01, -4.6581e-01],
         [-2.5067e-01,  6.2916e-02, -2.9163e-01, -4.6581e-01],
         [-2.5067e-01,  6.2916e-02, -2.9163e-01, -4.6581e-01]]])
DESIRED: (shape=torch.Size([2, 484861544, 4]), dtype=torch.float32)
tensor([[[ 7.5688e-02,  1.4392e-01, -1.4307e-01, -2.5559e-01],
         [ 2.0417e-04, -4.6123e-02, -1.4782e-01, -3.4308e-01],
         [-1.1593e-01, -3.3850e-01, -1.5513e-01, -4.7769e-01],
         ...,
         [ 4.4726e-01,  8.5799e-02, -2.6078e-01,  3.6056e-01],
         [ 4.4726e-01,  8.5799e-02, -2.6078e-01,  3.6056e-01],
         [ 4.4726e-01,  8.5799e-02, -2.6078e-01,  3.6056e-01]],

        [[-1.1388e-01,  3.0815e-03,  1.5496e-01, -2.0878e-01],
         [-1.6689e-01,  1.1476e-01,  8.9402e-02, -1.0390e-01],
         [-2.4844e-01,  2.8658e-01, -1.1451e-02,  5.7453e-02],
         ...,
         [-2.5067e-01,  6.2916e-02, -2.9163e-01, -4.6581e-01],
         [-2.5067e-01,  6.2916e-02, -2.9163e-01, -4.6581e-01],
         [-2.5067e-01,  6.2916e-02, -2.9163e-01, -4.6581e-01]]])

2025-07-26 05:01:29.229574 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 484861568, 4]) != torch.Size([2, 484861544, 4]).
ACTUAL: (shape=torch.Size([2, 484861568, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [ 0.0186, -0.0582, -0.2683,  0.1534],
         [-0.0345, -0.2035, -0.0550,  0.1580],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [-0.0561,  0.2696,  0.1549,  0.1407],
         [-0.4039,  0.1716,  0.2581, -0.1227],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])
DESIRED: (shape=torch.Size([2, 484861544, 4]), dtype=torch.float32)
tensor([[[ 0.2018,  0.2690, -0.4983,  0.1986],
         [ 0.0827,  0.0563, -0.3488,  0.1692],
         [-0.1005, -0.2709, -0.1189,  0.1240],
         ...,
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074],
         [-0.3345,  0.0059, -0.4698, -0.3074]],

        [[ 0.4263,  0.4206, -0.1949,  0.4940],
         [ 0.1127,  0.3224,  0.0325,  0.2644],
         [-0.3697,  0.1715,  0.3822, -0.0889],
         ...,
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899],
         [ 0.0915, -0.1271,  0.2699,  0.1899]]])

2025-07-26 05:01:34.857893 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 484861568, 4]) != torch.Size([2, 484861544, 4]).
ACTUAL: (shape=torch.Size([2, 484861568, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.1909,  0.2423,  0.2267, -0.0660],
         [-0.4117,  0.2099,  0.1775, -0.3452],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2017,  0.0040, -0.0894, -0.0772],
         [-0.1714, -0.0709, -0.0706,  0.1019],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])
DESIRED: (shape=torch.Size([2, 484861544, 4]), dtype=torch.float32)
tensor([[[ 0.2168,  0.2212,  0.3387,  0.2877],
         [-0.1909,  0.2423,  0.2267, -0.0660],
         [-0.4117,  0.2099,  0.1775, -0.3452],
         ...,
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502],
         [ 0.4078, -0.0890, -0.2494,  0.1502]],

        [[-0.1347,  0.0716, -0.0943, -0.3056],
         [-0.2017,  0.0040, -0.0894, -0.0772],
         [-0.1714, -0.0709, -0.0706,  0.1019],
         ...,
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529],
         [ 0.0299,  0.3718,  0.0178,  0.4529]]])

2025-07-26 05:01:46.625803 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 484861568, 4]) != torch.Size([2, 484861544, 4]).
ACTUAL: (shape=torch.Size([2, 484861568, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2191,  0.1704,  0.0223, -0.0516],
         [ 0.2091,  0.1274,  0.2500, -0.1802],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.2348, -0.1118, -0.2616,  0.0638],
         [ 0.3994,  0.0586, -0.2159,  0.0445],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])
DESIRED: (shape=torch.Size([2, 484861544, 4]), dtype=torch.float32)
tensor([[[ 0.0585,  0.1173, -0.2343,  0.1748],
         [ 0.2191,  0.1704,  0.0223, -0.0516],
         [ 0.2091,  0.1274,  0.2500, -0.1802],
         ...,
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639],
         [-0.2603,  0.1386, -0.4628,  0.2639]],

        [[-0.0588, -0.2950, -0.3112,  0.2230],
         [ 0.2348, -0.1118, -0.2616,  0.0638],
         [ 0.3994,  0.0586, -0.2159,  0.0445],
         ...,
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506],
         [-0.4297, -0.3211,  0.1528,  0.1506]]])

2025-07-26 05:01:52.632483 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 513382784, 4]) != torch.Size([2, 513382811, 4]).
ACTUAL: (shape=torch.Size([2, 513382784, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0109,  0.0825,  0.1489, -0.2993],
         [ 0.0399,  0.1911, -0.1836, -0.1293],
         ...,
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062],
         [ 0.0171,  0.1045,  0.4604,  0.2062]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.2934, -0.0090, -0.2167, -0.0931],
         [ 0.0103, -0.2870, -0.3893,  0.1266],
         ...,
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252],
         [-0.4033, -0.2482,  0.1291, -0.0252]]])
DESIRED: (shape=torch.Size([2, 513382811, 4]), dtype=torch.float32)
tensor([[[-0.0065,  0.0173,  0.3484, -0.4013],
         [ 0.0109,  0.0825,  0.1489, -0.2993],
         [ 0.0399,  0.1911, -0.1836, -0.1293],
         ...,
         [-0.2787,  0.1132,  0.0893,  0.0766],
         [-0.2787,  0.1132,  0.0893,  0.0766],
         [-0.2787,  0.1132,  0.0893,  0.0766]],

        [[-0.4755,  0.1578, -0.1131, -0.2249],
         [-0.2934, -0.0090, -0.2167, -0.0931],
         [ 0.0103, -0.2870, -0.3893,  0.1266],
         ...,
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])

2025-07-26 05:01:59.633598 GPU 1 126427 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 513382784, 4]) != torch.Size([2, 513382811, 4]).
ACTUAL: (shape=torch.Size([2, 513382784, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [-0.0321, -0.4676,  0.0331,  0.0651],
         [ 0.1793, -0.4432,  0.1812,  0.2160],
         ...,
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013],
         [-0.2794, -0.3471, -0.0854,  0.0013]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [ 0.0151, -0.1700,  0.0670,  0.2523],
         [-0.0342, -0.3759,  0.1642,  0.3105],
         ...,
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623],
         [-0.2535, -0.0492, -0.4090, -0.4623]]])
DESIRED: (shape=torch.Size([2, 513382811, 4]), dtype=torch.float32)
tensor([[[-0.2619, -0.4376, -0.1382, -0.0816],
         [-0.1240, -0.4556, -0.0354,  0.0064],
         [ 0.1058, -0.4857,  0.1359,  0.1532],
         ...,
         [ 0.1266, -0.2618, -0.0328, -0.1998],
         [ 0.1266, -0.2618, -0.0328, -0.1998],
         [ 0.1266, -0.2618, -0.0328, -0.1998]],

        [[ 0.1533,  0.1707, -0.0255,  0.1256],
         [ 0.0704, -0.0337,  0.0300,  0.2016],
         [-0.0679, -0.3744,  0.1224,  0.3284],
         ...,
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])

2025-07-26 05:01:59.681771 GPU 5 126612 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 513382784, 4]) != torch.Size([2, 513382811, 4]).
ACTUAL: (shape=torch.Size([2, 513382784, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.0444,  0.2698, -0.0604, -0.0369],
         [ 0.3659,  0.2938,  0.0112,  0.0115],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0601,  0.1192, -0.0225, -0.0158],
         [-0.1241,  0.1854, -0.0805, -0.0643],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])
DESIRED: (shape=torch.Size([2, 513382811, 4]), dtype=torch.float32)
tensor([[[-0.3874,  0.1587, -0.1637, -0.1638],
         [ 0.0444,  0.2698, -0.0604, -0.0369],
         [ 0.3659,  0.2938,  0.0112,  0.0115],
         ...,
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904],
         [ 0.4622,  0.2425,  0.0289, -0.4904]],

        [[-0.0153, -0.0368,  0.1283,  0.1078],
         [-0.0601,  0.1192, -0.0225, -0.0158],
         [-0.1241,  0.1854, -0.0805, -0.0643],
         ...,
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246],
         [-0.1817, -0.4204, -0.1434, -0.2246]]])

2025-07-26 05:02:06.044076 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 513382784, 4]) != torch.Size([2, 513382811, 4]).
ACTUAL: (shape=torch.Size([2, 513382784, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0340, -0.1322, -0.1500, -0.3827],
         [-0.0880, -0.2979, -0.1477, -0.4667],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.1909,  0.1654,  0.0597, -0.0564],
         [-0.2140,  0.2804, -0.0239,  0.0157],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])
DESIRED: (shape=torch.Size([2, 513382811, 4]), dtype=torch.float32)
tensor([[[ 0.0757,  0.1439, -0.1431, -0.2556],
         [-0.0340, -0.1322, -0.1500, -0.3827],
         [-0.0880, -0.2979, -0.1477, -0.4667],
         ...,
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606],
         [ 0.4473,  0.0858, -0.2608,  0.3606]],

        [[-0.1139,  0.0031,  0.1550, -0.2088],
         [-0.1909,  0.1654,  0.0597, -0.0564],
         [-0.2140,  0.2804, -0.0239,  0.0157],
         ...,
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658],
         [-0.2507,  0.0629, -0.2916, -0.4658]]])

2025-07-26 05:02:13.050523 GPU 3 125943 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477355 (unix time) try "date -d @1753477355" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ebf7) received by PID 125943 (TID 0x7f09e9ec6740) from PID 125943 ***]


2025-07-26 05:02:18.427424 GPU 6 126770 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477359 (unix time) try "date -d @1753477359" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ef32) received by PID 126770 (TID 0x7ff9ce738740) from PID 126770 ***]


2025-07-26 05:02:31.391135 GPU 2 125625 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477364 (unix time) try "date -d @1753477364" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1eab9) received by PID 125625 (TID 0x7f3aef519740) from PID 125625 ***]


2025-07-26 05:02:40.683952 GPU 3 126955 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477440 (unix time) try "date -d @1753477440" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1efeb) received by PID 126955 (TID 0x7fda4f531740) from PID 126955 ***]


2025-07-26 05:02:41.739165 GPU 4 124106 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477382 (unix time) try "date -d @1753477382" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e4ca) received by PID 124106 (TID 0x7f655c20b740) from PID 124106 ***]


2025-07-26 05:02:43.941624 GPU 6 127113 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477464 (unix time) try "date -d @1753477464" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f089) received by PID 127113 (TID 0x7f74c85d6740) from PID 127113 ***]


2025-07-26 05:02:45.566904 GPU 1 126427 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477376 (unix time) try "date -d @1753477376" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1eddb) received by PID 126427 (TID 0x7f66f7398740) from PID 126427 ***]


2025-07-26 05:02:48.400689 GPU 5 126612 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477381 (unix time) try "date -d @1753477381" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ee94) received by PID 126612 (TID 0x7fd8254b6740) from PID 126612 ***]


2025-07-26 05:02:50.772301 GPU 2 127271 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 2852127, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477457 (unix time) try "date -d @1753477457" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f127) received by PID 127271 (TID 0x7fab162f4740) from PID 127271 ***]


2025-07-26 05:02:53.436137 GPU 7 125465 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 2852127, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477395 (unix time) try "date -d @1753477395" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ea19) received by PID 125465 (TID 0x7f296a125740) from PID 125465 ***]


2025-07-26 05:03:03.078882 GPU 1 127429 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 2852127, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477464 (unix time) try "date -d @1753477464" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f1c5) received by PID 127429 (TID 0x7ff71a9f4740) from PID 127429 ***]


2025-07-26 05:03:07.007779 GPU 5 127587 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 214748368, 4]) != torch.Size([2, 214748365, 4]).
ACTUAL: (shape=torch.Size([2, 214748368, 4]), dtype=torch.float16)
tensor([[[-0.1768,  0.2620, -0.3579,  0.1770],
         [ 0.0477,  0.0871, -0.0862,  0.2344],
         [ 0.0171, -0.3469,  0.1262, -0.0759],
         ...,
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175]],

        [[-0.1134,  0.3364,  0.1005, -0.1764],
         [ 0.0637, -0.1113, -0.0511, -0.2898],
         [ 0.2397,  0.3074, -0.2379,  0.3914],
         ...,
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 214748365, 4]), dtype=torch.float16)
tensor([[[-0.1768,  0.2620, -0.3579,  0.1770],
         [ 0.0477,  0.0871, -0.0862,  0.2344],
         [ 0.0171, -0.3469,  0.1262, -0.0759],
         ...,
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175]],

        [[-0.1134,  0.3364,  0.1005, -0.1764],
         [ 0.0637, -0.1113, -0.0511, -0.2898],
         [ 0.2397,  0.3074, -0.2379,  0.3914],
         ...,
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691]]], dtype=torch.float16)

2025-07-26 05:03:08.170788 GPU 4 127675 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 214748368, 4]) != torch.Size([2, 214748365, 4]).
ACTUAL: (shape=torch.Size([2, 214748368, 4]), dtype=torch.float16)
tensor([[[ 0.4402,  0.3821,  0.2925,  0.3083],
         [ 0.1069,  0.1637, -0.2058,  0.0280],
         [-0.3340, -0.4343,  0.1437, -0.1511],
         ...,
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564]],

        [[-0.1921, -0.1187,  0.1069, -0.0362],
         [-0.0057,  0.1118,  0.3608, -0.0688],
         [ 0.2434, -0.4561,  0.1041,  0.1197],
         ...,
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 214748365, 4]), dtype=torch.float16)
tensor([[[ 0.3484,  0.1837,  0.0123,  0.3032],
         [-0.1567,  0.3745,  0.0037, -0.3589],
         [-0.1421, -0.0256, -0.0282, -0.1471],
         ...,
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564]],

        [[ 0.2258,  0.3169,  0.2666,  0.1687],
         [-0.2162,  0.2837,  0.1730, -0.0177],
         [ 0.2681,  0.0467,  0.3923,  0.3506],
         ...,
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620]]], dtype=torch.float16)

2025-07-26 05:03:20.655753 GPU 7 127903 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 214748368, 4]) != torch.Size([2, 214748365, 4]).
ACTUAL: (shape=torch.Size([2, 214748368, 4]), dtype=torch.float16)
tensor([[[ 0.1259,  0.3838, -0.2512, -0.2859],
         [-0.0197, -0.4729, -0.0274, -0.3955],
         [ 0.1342, -0.1277,  0.4836, -0.4521],
         ...,
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391]],

        [[ 0.2769, -0.4541,  0.1718, -0.4060],
         [ 0.2524,  0.0378,  0.0486,  0.3010],
         [-0.3284, -0.0856, -0.3848, -0.1908],
         ...,
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 214748365, 4]), dtype=torch.float16)
tensor([[[ 0.1259,  0.3838, -0.2512, -0.2859],
         [-0.0197, -0.4729, -0.0274, -0.3955],
         [ 0.1342, -0.1277,  0.4836, -0.4521],
         ...,
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391]],

        [[ 0.2769, -0.4541,  0.1718, -0.4060],
         [ 0.2524,  0.0378,  0.0486,  0.3010],
         [-0.3284, -0.0856, -0.3848, -0.1908],
         ...,
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143]]], dtype=torch.float16)

2025-07-26 05:04:05.585537 GPU 3 128066 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 214748368, 4]) != torch.Size([2, 214748365, 4]).
ACTUAL: (shape=torch.Size([2, 214748368, 4]), dtype=torch.float16)
tensor([[[ 0.2468,  0.1749,  0.2336, -0.1166],
         [ 0.2920,  0.3193,  0.2979, -0.1936],
         [ 0.0568,  0.4836, -0.1460,  0.2008],
         ...,
         [-0.2634, -0.2365,  0.0903,  0.3752],
         [-0.2634, -0.2365,  0.0903,  0.3752],
         [-0.2634, -0.2365,  0.0903,  0.3752]],

        [[ 0.0748, -0.2617,  0.2170, -0.3181],
         [-0.3140,  0.0094,  0.0117, -0.0475],
         [ 0.1548,  0.1262, -0.2169, -0.0455],
         ...,
         [-0.3518,  0.2241, -0.0811,  0.2318],
         [-0.3518,  0.2241, -0.0811,  0.2318],
         [-0.3518,  0.2241, -0.0811,  0.2318]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 214748365, 4]), dtype=torch.float16)
tensor([[[ 0.2468,  0.1749,  0.2336, -0.1166],
         [ 0.2920,  0.3193,  0.2979, -0.1936],
         [ 0.0568,  0.4836, -0.1460,  0.2008],
         ...,
         [-0.2634, -0.2365,  0.0903,  0.3752],
         [-0.2634, -0.2365,  0.0903,  0.3752],
         [-0.2634, -0.2365,  0.0903,  0.3752]],

        [[ 0.0748, -0.2617,  0.2170, -0.3181],
         [-0.3140,  0.0094,  0.0117, -0.0475],
         [ 0.1548,  0.1262, -0.2169, -0.0455],
         ...,
         [-0.3518,  0.2241, -0.0811,  0.2318],
         [-0.3518,  0.2241, -0.0811,  0.2318],
         [-0.3518,  0.2241, -0.0811,  0.2318]]], dtype=torch.float16)

2025-07-26 05:04:22.840393 GPU 2 128241 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 322122560, 4]) != torch.Size([2, 322122547, 4]).
ACTUAL: (shape=torch.Size([2, 322122560, 4]), dtype=torch.float16)
tensor([[[-0.2761,  0.1791, -0.1875, -0.1581],
         [-0.0505, -0.2131, -0.2373,  0.2120],
         [-0.2886, -0.2083, -0.0432,  0.1503],
         ...,
         [-0.4771, -0.4177,  0.4246,  0.3655],
         [-0.4771, -0.4177,  0.4246,  0.3655],
         [-0.4771, -0.4177,  0.4246,  0.3655]],

        [[-0.4326, -0.2808, -0.2472,  0.2102],
         [-0.1567, -0.3799, -0.4746, -0.4690],
         [ 0.2489,  0.0892, -0.2534, -0.1683],
         ...,
         [ 0.4700, -0.2322,  0.1265, -0.2333],
         [ 0.4700, -0.2322,  0.1265, -0.2333],
         [ 0.4700, -0.2322,  0.1265, -0.2333]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 322122547, 4]), dtype=torch.float16)
tensor([[[-0.2761,  0.1791, -0.1875, -0.1581],
         [-0.0505, -0.2131, -0.2373,  0.2120],
         [-0.2886, -0.2083, -0.0432,  0.1503],
         ...,
         [-0.4771, -0.4177,  0.4246,  0.3655],
         [-0.4771, -0.4177,  0.4246,  0.3655],
         [-0.4771, -0.4177,  0.4246,  0.3655]],

        [[-0.4326, -0.2808, -0.2472,  0.2102],
         [-0.1567, -0.3799, -0.4746, -0.4690],
         [ 0.2489,  0.0892, -0.2534, -0.1683],
         ...,
         [ 0.4700, -0.2322,  0.1265, -0.2333],
         [ 0.4700, -0.2322,  0.1265, -0.2333],
         [ 0.4700, -0.2322,  0.1265, -0.2333]]], dtype=torch.float16)

2025-07-26 05:04:29.889602 GPU 1 128400 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 322122560, 4]) != torch.Size([2, 322122547, 4]).
ACTUAL: (shape=torch.Size([2, 322122560, 4]), dtype=torch.float16)
tensor([[[ 0.0954,  0.0349,  0.1838,  0.2502],
         [ 0.2191,  0.0906, -0.2742,  0.2983],
         [ 0.3083, -0.1471, -0.1433,  0.0438],
         ...,
         [ 0.3940,  0.1593, -0.0679,  0.1892],
         [ 0.3940,  0.1593, -0.0679,  0.1892],
         [ 0.3940,  0.1593, -0.0679,  0.1892]],

        [[ 0.2947, -0.2008, -0.4219, -0.4263],
         [-0.2042,  0.2864, -0.1862, -0.3613],
         [ 0.0185,  0.1898,  0.0325, -0.0398],
         ...,
         [ 0.4407, -0.0330, -0.0572,  0.1516],
         [ 0.4407, -0.0330, -0.0572,  0.1516],
         [ 0.4407, -0.0330, -0.0572,  0.1516]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 322122547, 4]), dtype=torch.float16)
tensor([[[ 0.1043,  0.0265,  0.0803,  0.1951],
         [ 0.2676,  0.1310, -0.3477,  0.4053],
         [ 0.2374, -0.2969, -0.0114,  0.0034],
         ...,
         [ 0.3940,  0.1593, -0.0679,  0.1892],
         [ 0.3940,  0.1593, -0.0679,  0.1892],
         [ 0.3940,  0.1593, -0.0679,  0.1892]],

        [[ 0.0314,  0.0083, -0.2795, -0.3538],
         [-0.0587,  0.2162, -0.2820, -0.4377],
         [ 0.0027,  0.3057,  0.2524, -0.0326],
         ...,
         [ 0.4407, -0.0330, -0.0572,  0.1516],
         [ 0.4407, -0.0330, -0.0572,  0.1516],
         [ 0.4407, -0.0330, -0.0572,  0.1516]]], dtype=torch.float16)

2025-07-26 05:04:29.931893 GPU 6 128464 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 322122560, 4]) != torch.Size([2, 322122547, 4]).
ACTUAL: (shape=torch.Size([2, 322122560, 4]), dtype=torch.float16)
tensor([[[-7.9346e-02,  2.4792e-01, -2.5659e-01, -1.7624e-02],
         [-5.8990e-02, -4.0967e-01,  2.2937e-01, -3.2593e-02],
         [ 2.8735e-01, -1.3257e-01,  2.9736e-01, -1.8628e-01],
         ...,
         [ 4.7266e-01, -2.0068e-01, -1.1635e-03, -2.2607e-01],
         [ 4.7266e-01, -2.0068e-01, -1.1635e-03, -2.2607e-01],
         [ 4.7266e-01, -2.0068e-01, -1.1635e-03, -2.2607e-01]],

        [[ 2.4976e-01,  1.5906e-01,  1.6565e-01, -1.0522e-01],
         [-2.7728e-04, -1.5369e-01,  4.9469e-02,  2.9004e-01],
         [-3.2495e-01, -1.3269e-01, -8.1543e-02,  3.2373e-01],
         ...,
         [ 4.5703e-01, -6.9763e-02, -3.2080e-01, -1.6431e-01],
         [ 4.5703e-01, -6.9763e-02, -3.2080e-01, -1.6431e-01],
         [ 4.5703e-01, -6.9763e-02, -3.2080e-01, -1.6431e-01]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 322122547, 4]), dtype=torch.float16)
tensor([[[-7.9346e-02,  2.4792e-01, -2.5659e-01, -1.7624e-02],
         [-5.8990e-02, -4.0967e-01,  2.2937e-01, -3.2593e-02],
         [ 2.8735e-01, -1.3257e-01,  2.9736e-01, -1.8628e-01],
         ...,
         [ 4.7266e-01, -2.0068e-01, -1.1635e-03, -2.2607e-01],
         [ 4.7266e-01, -2.0068e-01, -1.1635e-03, -2.2607e-01],
         [ 4.7266e-01, -2.0068e-01, -1.1635e-03, -2.2607e-01]],

        [[ 2.4976e-01,  1.5906e-01,  1.6565e-01, -1.0522e-01],
         [-2.7728e-04, -1.5369e-01,  4.9469e-02,  2.9004e-01],
         [-3.2495e-01, -1.3269e-01, -8.1543e-02,  3.2373e-01],
         ...,
         [ 4.5703e-01, -6.9763e-02, -3.2080e-01, -1.6431e-01],
         [ 4.5703e-01, -6.9763e-02, -3.2080e-01, -1.6431e-01],
         [ 4.5703e-01, -6.9763e-02, -3.2080e-01, -1.6431e-01]]], dtype=torch.float16)

2025-07-26 05:04:49.619498 GPU 5 127587 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 322122560, 4]) != torch.Size([2, 322122547, 4]).
ACTUAL: (shape=torch.Size([2, 322122560, 4]), dtype=torch.float16)
tensor([[[-0.4363, -0.2803, -0.0768, -0.2147],
         [-0.2952, -0.1447, -0.1373,  0.1744],
         [ 0.0213,  0.1176, -0.1318,  0.2499],
         ...,
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175]],

        [[-0.3254,  0.3298, -0.4753,  0.0591],
         [-0.0509, -0.2180,  0.0119, -0.0589],
         [ 0.0526, -0.0594, -0.0209, -0.2622],
         ...,
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 322122547, 4]), dtype=torch.float16)
tensor([[[-0.4363, -0.2803, -0.0768, -0.2147],
         [-0.2952, -0.1447, -0.1373,  0.1744],
         [ 0.0213,  0.1176, -0.1318,  0.2499],
         ...,
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175]],

        [[-0.3254,  0.3298, -0.4753,  0.0591],
         [-0.0509, -0.2180,  0.0119, -0.0589],
         [ 0.0526, -0.0594, -0.0209, -0.2622],
         ...,
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691]]], dtype=torch.float16)

2025-07-26 05:05:03.482306 GPU 7 127903 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 429496736, 4]) != torch.Size([2, 429496730, 4]).
ACTUAL: (shape=torch.Size([2, 429496736, 4]), dtype=torch.float16)
tensor([[[ 0.0588,  0.3345, -0.2744, -0.1980],
         [-0.4248, -0.1858, -0.2603,  0.1031],
         [ 0.0876, -0.4719, -0.0427, -0.3894],
         ...,
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391]],

        [[ 0.2957, -0.4575,  0.1317, -0.4116],
         [ 0.3767, -0.2014, -0.0906, -0.2440],
         [ 0.2426, -0.0188,  0.0591,  0.3508],
         ...,
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 429496730, 4]), dtype=torch.float16)
tensor([[[ 0.0588,  0.3345, -0.2744, -0.1980],
         [-0.4248, -0.1858, -0.2603,  0.1031],
         [ 0.0876, -0.4719, -0.0427, -0.3894],
         ...,
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391]],

        [[ 0.2957, -0.4575,  0.1317, -0.4116],
         [ 0.3767, -0.2014, -0.0906, -0.2440],
         [ 0.2426, -0.0188,  0.0591,  0.3508],
         ...,
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143]]], dtype=torch.float16)

2025-07-26 05:05:04.977823 GPU 4 127675 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 429496736, 4]) != torch.Size([2, 429496730, 4]).
ACTUAL: (shape=torch.Size([2, 429496736, 4]), dtype=torch.float16)
tensor([[[ 0.4402,  0.3821,  0.2925,  0.3083],
         [ 0.3052,  0.0595, -0.1322,  0.3398],
         [ 0.1069,  0.1637, -0.2058,  0.0280],
         ...,
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564]],

        [[-0.1921, -0.1187,  0.1069, -0.0362],
         [ 0.3105,  0.3477,  0.3577,  0.1387],
         [-0.0057,  0.1118,  0.3608, -0.0688],
         ...,
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 429496730, 4]), dtype=torch.float16)
tensor([[[ 0.4248,  0.3491,  0.2458,  0.3076],
         [ 0.2988,  0.0305, -0.1577,  0.3589],
         [ 0.0669,  0.2333, -0.1858, -0.0787],
         ...,
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564],
         [ 0.4097,  0.3545,  0.0815,  0.1564]],

        [[-0.1224, -0.0461,  0.1335, -0.0020],
         [ 0.2832,  0.2905,  0.3767,  0.0895],
         [-0.0438,  0.1387,  0.3333, -0.0470],
         ...,
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620],
         [ 0.0477, -0.4128, -0.1298, -0.1620]]], dtype=torch.float16)

2025-07-26 05:05:16.684900 GPU 5 127587 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 429496736, 4]) != torch.Size([2, 429496730, 4]).
ACTUAL: (shape=torch.Size([2, 429496736, 4]), dtype=torch.float16)
tensor([[[-0.4363, -0.2803, -0.0768, -0.2147],
         [-0.1671,  0.2224, -0.3337,  0.2576],
         [-0.1354, -0.2213,  0.0354,  0.1479],
         ...,
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175]],

        [[-0.3254,  0.3298, -0.4753,  0.0591],
         [-0.0458,  0.1299,  0.1873, -0.1814],
         [ 0.0209, -0.3816, -0.1351, -0.1669],
         ...,
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 429496730, 4]), dtype=torch.float16)
tensor([[[-0.4363, -0.2803, -0.0768, -0.2147],
         [-0.1671,  0.2224, -0.3337,  0.2576],
         [-0.1354, -0.2213,  0.0354,  0.1479],
         ...,
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175],
         [-0.2161, -0.2947, -0.2167, -0.4175]],

        [[-0.3254,  0.3298, -0.4753,  0.0591],
         [-0.0458,  0.1299,  0.1873, -0.1814],
         [ 0.0209, -0.3816, -0.1351, -0.1669],
         ...,
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691],
         [-0.2817, -0.1678,  0.2498, -0.3691]]], dtype=torch.float16)

2025-07-26 05:05:37.327683 GPU 7 127903 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([2, 429496736, 4]) != torch.Size([2, 429496730, 4]).
ACTUAL: (shape=torch.Size([2, 429496736, 4]), dtype=torch.float16)
tensor([[[ 0.1259,  0.3838, -0.2512, -0.2859],
         [-0.4199, -0.1276, -0.3188,  0.2080],
         [-0.0197, -0.4729, -0.0274, -0.3955],
         ...,
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391]],

        [[ 0.2769, -0.4541,  0.1718, -0.4060],
         [ 0.3936, -0.2947, -0.1100, -0.3132],
         [ 0.2524,  0.0378,  0.0486,  0.3010],
         ...,
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 429496730, 4]), dtype=torch.float16)
tensor([[[ 0.1259,  0.3838, -0.2512, -0.2859],
         [-0.4199, -0.1276, -0.3188,  0.2080],
         [-0.0197, -0.4729, -0.0274, -0.3955],
         ...,
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391],
         [ 0.4819, -0.3699,  0.3538, -0.0391]],

        [[ 0.2769, -0.4541,  0.1718, -0.4060],
         [ 0.3936, -0.2947, -0.1100, -0.3132],
         [ 0.2524,  0.0378,  0.0486,  0.3010],
         ...,
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143],
         [ 0.4070,  0.3462, -0.4158, -0.4143]]], dtype=torch.float16)

2025-07-26 05:05:45.113985 GPU 4 127675 test begin: paddle.nn.functional.interpolate(Tensor([2, 5368710, 10, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477557 (unix time) try "date -d @1753477557" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f2bb) received by PID 127675 (TID 0x7ffaacdfc740) from PID 127675 ***]


2025-07-26 05:05:48.932813 GPU 5 127587 test begin: paddle.nn.functional.interpolate(Tensor([2, 5368710, 10, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477562 (unix time) try "date -d @1753477562" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f263) received by PID 127587 (TID 0x7fa9fa24e740) from PID 127587 ***]


2025-07-26 05:06:07.587825 GPU 7 127903 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477605 (unix time) try "date -d @1753477605" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f39f) received by PID 127903 (TID 0x7f180565f740) from PID 127903 ***]


2025-07-26 05:06:15.444559 GPU 2 128241 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477615 (unix time) try "date -d @1753477615" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f4f1) received by PID 128241 (TID 0x7fa2bcd72740) from PID 128241 ***]


2025-07-26 05:06:51.034388 GPU 7 129094 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477749 (unix time) try "date -d @1753477749" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f846) received by PID 129094 (TID 0x7fdb1035c740) from PID 129094 ***]


2025-07-26 05:06:59.916675 GPU 2 129252 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477738 (unix time) try "date -d @1753477738" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f8e4) received by PID 129252 (TID 0x7f898face740) from PID 129252 ***]


2025-07-26 05:09:03.846554 GPU 2 129432 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477874 (unix time) try "date -d @1753477874" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f998) received by PID 129432 (TID 0x7fc2444c0740) from PID 129432 ***]


2025-07-26 05:09:14.146119 GPU 7 129590 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753477875 (unix time) try "date -d @1753477875" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fa36) received by PID 129590 (TID 0x7f2df9cc6740) from PID 129590 ***]


2025-07-26 05:14:41.525100 GPU 1 128400 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478110 (unix time) try "date -d @1753478110" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f590) received by PID 128400 (TID 0x7f0b91347740) from PID 128400 ***]


2025-07-26 05:14:52.253956 GPU 6 128464 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478121 (unix time) try "date -d @1753478121" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f5d0) received by PID 128464 (TID 0x7f630d3d7740) from PID 128464 ***]


2025-07-26 05:15:14.973750 GPU 1 130086 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478237 (unix time) try "date -d @1753478237" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fc26) received by PID 130086 (TID 0x7fa051f9f740) from PID 130086 ***]


2025-07-26 05:15:25.785073 GPU 6 130244 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478265 (unix time) try "date -d @1753478265" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fcc4) received by PID 130244 (TID 0x7f9cf468b740) from PID 130244 ***]


2025-07-26 05:16:39.929890 GPU 4 128753 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 05:17:02.708527 GPU 4 130419 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-07-26 05:17:22.654998 GPU 1 130585 test begin: paddle.nn.functional.interpolate(Tensor([2147484, 5, 20, 20],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478362 (unix time) try "date -d @1753478362" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fe19) received by PID 130585 (TID 0x7fe5f76c7740) from PID 130585 ***]


2025-07-26 05:17:34.439943 GPU 5 128912 test begin: paddle.nn.functional.interpolate(Tensor([4, 128, 1, 8388609],"float16"), list[16,32,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478265 (unix time) try "date -d @1753478265" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f790) received by PID 128912 (TID 0x7f57c5425740) from PID 128912 ***]


2025-07-26 05:18:58.865518 GPU 4 131069 test begin: paddle.nn.functional.interpolate(Tensor([4, 150, 64, 111849],"float16"), list[512,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478444 (unix time) try "date -d @1753478444" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fffd) received by PID 131069 (TID 0x7fba1f9f7740) from PID 131069 ***]


2025-07-26 05:19:27.654105 GPU 1 131237 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 128, 441506],"float16"), list[1024,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478458 (unix time) try "date -d @1753478458" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x200a5) received by PID 131237 (TID 0x7f3e85c62740) from PID 131237 ***]


2025-07-26 05:19:50.363473 GPU 6 130814 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 16, 3532046],"float16"), list[512,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478404 (unix time) try "date -d @1753478404" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fefe) received by PID 130814 (TID 0x7ff136be0740) from PID 130814 ***]


2025-07-26 05:20:49.720053 GPU 4 131579 test begin: paddle.nn.functional.interpolate(Tensor([4, 25565282, 6, 7],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478547 (unix time) try "date -d @1753478547" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x201fb) received by PID 131579 (TID 0x7fde98b11740) from PID 131579 ***]


2025-07-26 05:21:04.236782 GPU 1 131752 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 1, 4194305],"float16"), list[64,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478577 (unix time) try "date -d @1753478577" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x202a8) received by PID 131752 (TID 0x7fd39b696740) from PID 131752 ***]


2025-07-26 05:21:39.111181 GPU 7 129854 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 32, 131073],"float16"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478511 (unix time) try "date -d @1753478511" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fb3e) received by PID 129854 (TID 0x7f4845dd5740) from PID 129854 ***]


2025-07-26 05:21:59.313815 GPU 5 130750 test begin: paddle.nn.functional.interpolate(Tensor([4, 2684355, 20, 20],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478545 (unix time) try "date -d @1753478545" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1febe) received by PID 130750 (TID 0x7f6accf01740) from PID 130750 ***]


2025-07-26 05:22:07.266566 GPU 2 129766 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 10737419, 20],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478538 (unix time) try "date -d @1753478538" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fae6) received by PID 129766 (TID 0x7f21d198b740) from PID 129766 ***]


2025-07-26 05:22:23.105296 GPU 2 132086 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 20, 10737419],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478646 (unix time) try "date -d @1753478646" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x203f6) received by PID 132086 (TID 0x7fd2baac3740) from PID 132086 ***]


2025-07-26 05:22:23.682645 GPU 6 131411 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 30678338, 7],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478555 (unix time) try "date -d @1753478555" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20153) received by PID 131411 (TID 0x7f2289136740) from PID 131411 ***]


2025-07-26 05:22:32.432795 GPU 4 132332 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 6, 35791395],"float16"), size=list[100,50,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478642 (unix time) try "date -d @1753478642" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x204ec) received by PID 132332 (TID 0x7f18a79b8740) from PID 132332 ***]


2025-07-26 05:23:02.183654 GPU 1 132727 test begin: paddle.nn.functional.interpolate(Tensor([46422, 3, 64, 256],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478665 (unix time) try "date -d @1753478665" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20677) received by PID 132727 (TID 0x7f550108f740) from PID 132727 ***]


2025-07-26 05:23:55.794441 GPU 7 131919 test begin: paddle.nn.functional.interpolate(Tensor([512, 273, 64, 256],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478715 (unix time) try "date -d @1753478715" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2034f) received by PID 131919 (TID 0x7fade136b740) from PID 131919 ***]


2025-07-26 05:24:06.894777 GPU 4 132907 test begin: paddle.nn.functional.interpolate(Tensor([512, 3, 5803, 256],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478729 (unix time) try "date -d @1753478729" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2072b) received by PID 132907 (TID 0x7f3963ad0740) from PID 132907 ***]


2025-07-26 05:24:07.726508 GPU 6 132560 test begin: paddle.nn.functional.interpolate(Tensor([512, 3, 64, 23211],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753478660 (unix time) try "date -d @1753478660" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x205d0) received by PID 132560 (TID 0x7fabaa03e740) from PID 132560 ***]


2025-07-26 05:28:22.044554 GPU 1 133406 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 8, 4]) != torch.Size([57042535, 7, 4]).
ACTUAL: (shape=torch.Size([57042535, 8, 4]), dtype=torch.float32)
tensor([[[-6.1990e-02,  4.2188e-01,  1.4612e-01,  4.7048e-01],
         [ 8.6802e-03,  4.8074e-02, -5.3060e-02,  2.8652e-01],
         [-3.2320e-01, -1.3950e-01,  5.7358e-02,  2.0737e-01],
         ...,
         [ 8.6171e-02,  3.8508e-01, -3.2344e-02,  3.0212e-01],
         [-3.4988e-01,  2.7396e-01, -1.2858e-01,  4.2448e-01],
         [ 9.0053e-02, -7.0947e-02, -1.7913e-01,  7.9206e-02]],

        [[-1.6554e-01, -4.0250e-01,  3.9873e-01, -7.4751e-02],
         [ 1.0796e-01, -3.2275e-01,  5.1240e-02, -3.3310e-01],
         [ 3.7825e-02, -4.1473e-01,  4.4747e-03,  6.2314e-02],
         ...,
         [ 1.1063e-01, -2.0531e-01,  1.0917e-01, -3.1085e-01],
         [ 1.3151e-01,  1.2072e-01,  1.5391e-01, -3.6238e-01],
         [-2.4058e-01, -1.5862e-01, -1.5413e-01, -3.2279e-01]],

        [[-2.6824e-01, -3.1684e-01, -5.4616e-03, -4.0461e-01],
         [ 1.7135e-01, -2.4731e-01, -1.3188e-01,  2.4173e-02],
         [-7.5722e-02,  1.9739e-01,  3.3876e-01,  2.7099e-01],
         ...,
         [-4.3251e-02, -1.6012e-01,  1.4100e-01, -5.5836e-03],
         [ 9.8441e-02, -1.7440e-01,  3.5556e-02,  1.9843e-01],
         [ 4.3096e-01,  1.4290e-01,  2.2725e-01, -1.9080e-01]],

        ...,

        [[ 1.6331e-01,  3.1618e-01, -1.8013e-01, -1.0449e-01],
         [ 3.5904e-02,  1.7044e-01,  1.1940e-02, -1.5281e-01],
         [-2.4943e-01, -3.0101e-01,  2.3094e-01, -2.7832e-01],
         ...,
         [ 2.7791e-01,  8.3204e-02, -2.1119e-02,  1.8682e-01],
         [ 1.5589e-01, -2.9412e-01,  8.0477e-02,  1.3094e-02],
         [-2.6351e-01, -3.3522e-01,  1.8754e-01,  2.9058e-01]],

        [[-4.3606e-01,  3.3447e-01,  1.3725e-01, -3.5816e-01],
         [-2.1441e-01,  2.0523e-01, -4.1006e-01, -1.8605e-01],
         [-1.2408e-01,  1.8528e-02,  1.6661e-01, -6.8850e-02],
         ...,
         [-4.4178e-03,  2.1574e-01,  4.4673e-01, -3.6538e-02],
         [ 1.7588e-01,  2.6938e-01, -2.5981e-02,  1.3424e-02],
         [ 3.6528e-01,  1.4525e-01,  2.5026e-01,  3.3169e-01]],

        [[-2.3302e-01, -2.6454e-01,  2.8597e-01, -1.1087e-01],
         [ 5.4945e-02,  1.0730e-04, -2.5999e-01, -8.9200e-02],
         [-1.6729e-01, -8.5223e-02,  1.6674e-01,  1.2742e-01],
         ...,
         [-2.6657e-01, -3.2370e-02, -1.8246e-01, -2.9039e-01],
         [ 1.8638e-01,  4.1783e-01,  2.5087e-01, -3.1928e-01],
         [ 2.3512e-01, -3.1871e-01, -2.9919e-01, -1.2521e-02]]])
DESIRED: (shape=torch.Size([57042535, 7, 4]), dtype=torch.float32)
tensor([[[-6.1990e-02,  4.2188e-01,  1.4612e-01,  4.7048e-01],
         [ 8.6802e-03,  4.8074e-02, -5.3060e-02,  2.8652e-01],
         [-3.2320e-01, -1.3950e-01,  5.7358e-02,  2.0737e-01],
         ...,
         [ 4.3886e-01,  1.7790e-01, -2.6592e-02, -1.8552e-01],
         [ 8.6171e-02,  3.8508e-01, -3.2344e-02,  3.0212e-01],
         [-3.4988e-01,  2.7396e-01, -1.2858e-01,  4.2448e-01]],

        [[-1.6554e-01, -4.0250e-01,  3.9873e-01, -7.4751e-02],
         [ 1.0796e-01, -3.2275e-01,  5.1240e-02, -3.3310e-01],
         [ 3.7825e-02, -4.1473e-01,  4.4747e-03,  6.2314e-02],
         ...,
         [ 4.3389e-01, -1.6166e-01, -1.8195e-02,  8.4287e-02],
         [ 1.1063e-01, -2.0531e-01,  1.0917e-01, -3.1085e-01],
         [ 1.3151e-01,  1.2072e-01,  1.5391e-01, -3.6238e-01]],

        [[-2.6824e-01, -3.1684e-01, -5.4616e-03, -4.0461e-01],
         [ 1.7135e-01, -2.4731e-01, -1.3188e-01,  2.4173e-02],
         [-7.5722e-02,  1.9739e-01,  3.3876e-01,  2.7099e-01],
         ...,
         [-5.1468e-02, -1.4397e-01, -1.3564e-01, -1.5269e-01],
         [-4.3251e-02, -1.6012e-01,  1.4100e-01, -5.5836e-03],
         [ 9.8441e-02, -1.7440e-01,  3.5556e-02,  1.9843e-01]],

        ...,

        [[ 1.6331e-01,  3.1618e-01, -1.8013e-01, -1.0449e-01],
         [ 3.5904e-02,  1.7044e-01,  1.1940e-02, -1.5281e-01],
         [-2.4943e-01, -3.0101e-01,  2.3094e-01, -2.7832e-01],
         ...,
         [-2.4414e-01,  1.1500e-01, -1.5148e-01,  8.0128e-02],
         [ 2.7791e-01,  8.3204e-02, -2.1119e-02,  1.8682e-01],
         [ 1.5589e-01, -2.9412e-01,  8.0477e-02,  1.3094e-02]],

        [[-4.3606e-01,  3.3447e-01,  1.3725e-01, -3.5816e-01],
         [-2.1441e-01,  2.0523e-01, -4.1006e-01, -1.8605e-01],
         [-1.2408e-01,  1.8528e-02,  1.6661e-01, -6.8850e-02],
         ...,
         [ 9.8757e-02, -8.1988e-02, -2.9131e-01,  1.1941e-01],
         [-4.4178e-03,  2.1574e-01,  4.4673e-01, -3.6538e-02],
         [ 1.7588e-01,  2.6938e-01, -2.5981e-02,  1.3424e-02]],

        [[-2.3302e-01, -2.6454e-01,  2.8597e-01, -1.1087e-01],
         [ 5.4945e-02,  1.0730e-04, -2.5999e-01, -8.9200e-02],
         [-1.6729e-01, -8.5223e-02,  1.6674e-01,  1.2742e-01],
         ...,
         [ 1.6984e-01,  2.0562e-01,  3.7333e-01,  1.9252e-01],
         [-2.6657e-01, -3.2370e-02, -1.8246e-01, -2.9039e-01],
         [ 1.8638e-01,  4.1783e-01,  2.5087e-01, -3.1928e-01]]])

2025-07-26 05:28:26.900572 GPU 5 132244 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 8, 4]) != torch.Size([57042535, 7, 4]).
ACTUAL: (shape=torch.Size([57042535, 8, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.2057,  0.2329, -0.1620,  0.1150],
         [-0.0079,  0.0796,  0.2731, -0.2589],
         ...,
         [ 0.3796,  0.1633,  0.1388,  0.1035],
         [ 0.2510,  0.1105,  0.2587, -0.0169],
         [-0.1442, -0.3112,  0.4188,  0.0454]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [ 0.0133,  0.4645,  0.3155, -0.0287],
         [ 0.3431,  0.1855, -0.2264, -0.0594],
         ...,
         [-0.2865, -0.1163, -0.1425,  0.0712],
         [-0.0877,  0.2272,  0.0436,  0.0989],
         [ 0.2269, -0.1615,  0.2161, -0.0824]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.3209, -0.1932, -0.0564,  0.0223],
         [-0.0645, -0.1383, -0.2110, -0.3465],
         ...,
         [-0.3951,  0.1172,  0.4054,  0.0838],
         [-0.1411,  0.0560,  0.0533, -0.3015],
         [ 0.0041,  0.0427,  0.0592,  0.2702]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.1627,  0.2520, -0.4050, -0.2114],
         [ 0.1304,  0.2377,  0.0023, -0.0896],
         ...,
         [-0.4058, -0.0547,  0.0715, -0.0306],
         [-0.0863,  0.2022, -0.0291, -0.2201],
         [-0.1842, -0.2584,  0.1413, -0.1722]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.1725, -0.1330, -0.4301,  0.0591],
         [ 0.1340, -0.2130, -0.2374, -0.0702],
         ...,
         [-0.3440, -0.2462,  0.2181, -0.0711],
         [-0.1483, -0.1155, -0.1264, -0.0264],
         [ 0.1526, -0.3322,  0.4098,  0.2816]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [ 0.0069, -0.1862,  0.2300,  0.1819],
         [-0.0103, -0.0160,  0.0210, -0.0927],
         ...,
         [ 0.0357,  0.0116,  0.1494, -0.4310],
         [-0.1296, -0.1876, -0.2535, -0.4131],
         [-0.0846, -0.0169, -0.1260, -0.3425]]])
DESIRED: (shape=torch.Size([57042535, 7, 4]), dtype=torch.float32)
tensor([[[ 0.4404,  0.2876,  0.3414, -0.2582],
         [ 0.1100,  0.1503, -0.1260,  0.0456],
         [ 0.0823,  0.1652,  0.3278, -0.2483],
         ...,
         [-0.0686, -0.2895,  0.1646,  0.1576],
         [ 0.3263,  0.1492,  0.1566,  0.1397],
         [ 0.2988,  0.1184,  0.2620, -0.1012]],

        [[-0.3703,  0.4063,  0.0968,  0.3097],
         [ 0.0715,  0.4612,  0.2572, -0.0214],
         [ 0.3383,  0.1208, -0.2744, -0.0780],
         ...,
         [-0.1159, -0.0044,  0.2090,  0.0136],
         [-0.2111, -0.0715, -0.1301,  0.0636],
         [-0.1511,  0.2458,  0.0716,  0.1171]],

        [[ 0.0750,  0.0485, -0.4304, -0.3824],
         [-0.3492, -0.1320, -0.0711, -0.0624],
         [ 0.0421, -0.2163, -0.2276, -0.3116],
         ...,
         [ 0.3107,  0.2497,  0.2893,  0.0511],
         [-0.3809,  0.0501,  0.3907,  0.0335],
         [-0.0990,  0.1413, -0.0126, -0.3223]],

        ...,

        [[-0.2113,  0.2632,  0.0628, -0.2393],
         [ 0.1305,  0.2088, -0.3597, -0.2275],
         [ 0.1707,  0.2990,  0.0361, -0.0350],
         ...,
         [-0.2077,  0.1187, -0.2121,  0.3729],
         [-0.3827,  0.0071,  0.0705, -0.0967],
         [-0.0410,  0.1738, -0.0528, -0.1683]],

        [[-0.2629, -0.2562,  0.1820,  0.4202],
         [-0.1699, -0.1565, -0.4211,  0.0312],
         [ 0.2067, -0.1978, -0.2027, -0.0607],
         ...,
         [-0.0732, -0.4571,  0.1923, -0.3029],
         [-0.3611, -0.1942,  0.1104, -0.1382],
         [-0.0737, -0.1609, -0.0511,  0.0855]],

        [[-0.2994,  0.3414,  0.2024,  0.1332],
         [-0.0317, -0.1551,  0.1851,  0.1278],
         [ 0.0433, -0.0200,  0.0361, -0.0802],
         ...,
         [-0.0652, -0.0779, -0.0675, -0.1882],
         [-0.0020, -0.0406,  0.0682, -0.4186],
         [-0.1144, -0.1591, -0.2326, -0.4271]]])

2025-07-26 05:29:24.995310 GPU 7 133566 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 8, 4]) != torch.Size([57042535, 7, 4]).
ACTUAL: (shape=torch.Size([57042535, 8, 4]), dtype=torch.float32)
tensor([[[-3.8114e-01, -2.3059e-01,  3.9696e-01,  1.3346e-01],
         [-1.1063e-01, -1.9041e-02,  9.1920e-02,  3.2854e-01],
         [ 4.4626e-01,  1.1666e-01,  2.8891e-02,  8.0549e-02],
         ...,
         [-3.1795e-01,  8.1191e-02,  3.5048e-01,  1.8269e-01],
         [ 1.0144e-01,  2.1024e-01,  4.4803e-01, -2.5747e-01],
         [ 3.8941e-01,  4.5885e-01,  4.2324e-02,  4.9860e-01]],

        [[-5.5418e-02,  3.1780e-01, -3.8291e-01,  6.2668e-04],
         [-1.6478e-01, -1.6167e-01, -2.3296e-02, -2.3147e-01],
         [ 1.5577e-02,  1.7903e-01, -1.2613e-01, -2.9298e-01],
         ...,
         [-2.8852e-01, -3.2302e-02, -1.4965e-01, -2.5239e-01],
         [-2.2724e-02,  8.0663e-02,  2.8455e-01,  2.0016e-02],
         [ 2.7228e-02, -1.7969e-01, -4.8935e-01,  4.3102e-01]],

        [[ 2.9238e-01,  3.4243e-01,  1.2186e-01, -4.4803e-01],
         [ 3.0024e-04, -1.7254e-01, -2.5492e-01, -2.0944e-01],
         [ 1.8196e-02,  3.5860e-01, -2.0258e-01, -2.1803e-02],
         ...,
         [ 1.7303e-01,  2.4592e-02, -9.8472e-03,  2.4109e-01],
         [ 1.0663e-01, -2.3450e-01, -3.3885e-01,  1.8499e-01],
         [-3.7258e-01,  5.9253e-02,  2.4917e-01,  1.3119e-02]],

        ...,

        [[ 3.8758e-01, -4.8142e-01,  3.8929e-02,  4.7398e-01],
         [ 4.7718e-02,  9.3132e-02,  3.1694e-02, -2.6811e-01],
         [-4.6367e-01,  3.1559e-01,  1.6483e-01, -1.8788e-01],
         ...,
         [ 8.7378e-02,  8.1336e-02, -4.0850e-01, -3.7082e-01],
         [ 3.0667e-02,  3.0259e-01,  1.4080e-01, -2.3272e-01],
         [-1.9600e-01,  3.3292e-01, -4.4737e-01, -1.1863e-01]],

        [[-2.3768e-01, -1.3051e-01, -4.5867e-01, -3.0494e-01],
         [-2.3643e-01, -4.0766e-01,  6.7551e-02,  4.5064e-01],
         [ 1.0280e-01, -4.0775e-01,  4.2382e-01,  2.3345e-01],
         ...,
         [-3.5687e-01, -3.7773e-01,  6.5512e-02,  3.1634e-01],
         [ 2.2739e-01,  1.1541e-01,  2.5795e-02,  1.0742e-01],
         [ 2.2382e-01,  7.4381e-02, -4.4241e-02, -1.8295e-01]],

        [[-3.8453e-02,  2.6156e-01,  2.1690e-01, -2.4821e-01],
         [ 4.2155e-01, -3.4202e-01,  2.2187e-01, -3.7876e-01],
         [ 3.1008e-01, -7.2092e-02, -3.6660e-01, -6.6393e-02],
         ...,
         [-1.6667e-01, -8.8434e-02, -3.1248e-01,  2.3243e-01],
         [ 3.4909e-01, -4.0726e-01, -2.3879e-01, -3.3284e-01],
         [-3.3152e-01, -1.6975e-01,  4.3329e-01,  9.3995e-02]]])
DESIRED: (shape=torch.Size([57042535, 7, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [ 0.0422,  0.0400,  0.1046,  0.2050],
         [ 0.4820,  0.0708, -0.0500,  0.2034],
         ...,
         [-0.2433,  0.2245,  0.2694,  0.4452],
         [-0.0542,  0.1142,  0.4512, -0.2304],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.0854, -0.0173,  0.0105, -0.1816],
         [-0.0476,  0.0735, -0.2878, -0.4637],
         ...,
         [-0.3159, -0.2191, -0.1757, -0.2750],
         [-0.0915,  0.1215,  0.1647, -0.0526],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [ 0.1283, -0.0021, -0.1550, -0.2874],
         [-0.2884,  0.3308, -0.4130,  0.3139],
         ...,
         [ 0.4528, -0.1912, -0.0624,  0.1097],
         [ 0.0147, -0.0705, -0.2191,  0.2544],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [-0.1099,  0.1365, -0.0623, -0.1936],
         [-0.4532,  0.3741,  0.4997, -0.3141],
         ...,
         [ 0.0595, -0.1336, -0.4121, -0.3485],
         [ 0.0588,  0.3222, -0.0225, -0.2831],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2560, -0.3756,  0.1649,  0.4623],
         [ 0.4062, -0.4880,  0.4476,  0.0415],
         ...,
         [-0.3894, -0.3202,  0.0243,  0.2513],
         [ 0.0651, -0.0555,  0.0542,  0.1961],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.3650, -0.2961,  0.0753, -0.3929],
         [ 0.3678,  0.0157, -0.4416,  0.2033],
         ...,
         [-0.2775,  0.1433, -0.3533,  0.4289],
         [ 0.2387, -0.4043, -0.2446, -0.2419],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])

2025-07-26 05:29:32.301046 GPU 4 133732 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 8, 4]) != torch.Size([57042535, 7, 4]).
ACTUAL: (shape=torch.Size([57042535, 8, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.0823, -0.0823, -0.1368, -0.2907],
         [ 0.0085,  0.1232,  0.2307,  0.0475],
         ...,
         [ 0.3566,  0.1574,  0.0824, -0.0916],
         [ 0.2187,  0.1326,  0.1679,  0.3933],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.1675, -0.3016, -0.2985,  0.2609],
         [-0.3469, -0.0041, -0.1732, -0.2179],
         ...,
         [-0.0887,  0.3476,  0.2164, -0.2350],
         [ 0.2614, -0.0730,  0.4642,  0.0887],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.1935, -0.0444,  0.1717,  0.0773],
         [ 0.2769, -0.2004, -0.3060,  0.1252],
         ...,
         [-0.0424,  0.0220, -0.0337,  0.2676],
         [ 0.3585, -0.1460,  0.1744,  0.3337],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.2032,  0.1371, -0.0101, -0.0250],
         [ 0.0243,  0.0129,  0.1806,  0.1739],
         ...,
         [ 0.0463, -0.1309, -0.1398, -0.2208],
         [-0.1939, -0.2301, -0.1365, -0.0676],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.3811, -0.4046,  0.3474,  0.0217],
         [ 0.0925,  0.1280,  0.1566, -0.0894],
         ...,
         [-0.0052,  0.1288, -0.0143, -0.2146],
         [-0.0040, -0.0044,  0.3376,  0.1277],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.0954,  0.2972, -0.1276,  0.3470],
         [ 0.2102,  0.1305, -0.0831, -0.0383],
         ...,
         [-0.1396, -0.0439,  0.1729,  0.2302],
         [-0.3374, -0.1859, -0.0325, -0.2580],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])
DESIRED: (shape=torch.Size([57042535, 7, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.0410, -0.1208, -0.0363, -0.2636],
         [ 0.0563,  0.3736,  0.2550,  0.2335],
         ...,
         [ 0.4338,  0.0661,  0.4144, -0.2766],
         [ 0.2292,  0.1766,  0.0095,  0.3218],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.0342, -0.2601, -0.3503,  0.1118],
         [-0.3995,  0.1153,  0.0502, -0.2041],
         ...,
         [-0.3724,  0.3310,  0.0519, -0.0567],
         [ 0.2699,  0.0599,  0.4557, -0.0797],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.1002,  0.0065,  0.0955, -0.0077],
         [ 0.3965, -0.4447, -0.4739,  0.3737],
         ...,
         [-0.2402, -0.1846,  0.0448,  0.3223],
         [ 0.3174, -0.0130,  0.0805,  0.2920],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.0547,  0.0413,  0.0755,  0.0648],
         [-0.1763,  0.1592,  0.1097,  0.0986],
         ...,
         [-0.0351, -0.0830, -0.2426, -0.4881],
         [-0.0892, -0.2195, -0.0963, -0.0066],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.3159, -0.3338,  0.3402,  0.1320],
         [ 0.2847,  0.3504,  0.0314, -0.4485],
         ...,
         [-0.1793,  0.3136, -0.0427, -0.4180],
         [ 0.0653, -0.0384,  0.2434,  0.1064],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.1113,  0.1729, -0.0955,  0.3224],
         [ 0.2566,  0.3163, -0.1299, -0.2656],
         ...,
         [-0.1323,  0.2942,  0.4788,  0.2238],
         [-0.2809, -0.2785, -0.0933, -0.1090],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])

2025-07-26 05:31:06.037849 GPU 6 133241 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 11, 4]) != torch.Size([57042535, 10, 4]).
ACTUAL: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.2834, -0.0303, -0.4358,  0.3317],
         [-0.4106,  0.1565,  0.2055,  0.1920],
         ...,
         [-0.0869,  0.2771,  0.1355, -0.0094],
         [-0.1333, -0.3498, -0.1776, -0.4244],
         [ 0.1168, -0.3929,  0.2746, -0.3370]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.1234,  0.0029, -0.1512,  0.3104],
         [ 0.3598, -0.0741, -0.4152,  0.1693],
         ...,
         [-0.0140, -0.0510,  0.1788, -0.1636],
         [ 0.1656, -0.3371,  0.4180, -0.2027],
         [ 0.3350,  0.4178,  0.4897, -0.4462]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.2648,  0.1546,  0.1403, -0.1458],
         [ 0.3544, -0.1673, -0.0964,  0.0423],
         ...,
         [-0.3402,  0.0263,  0.4166, -0.2065],
         [ 0.1828,  0.1432,  0.3277, -0.0843],
         [ 0.3886, -0.1577,  0.0784, -0.0632]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [ 0.0086,  0.1652,  0.2870,  0.0356],
         [ 0.1197, -0.3358, -0.1684,  0.1800],
         ...,
         [-0.1742,  0.4620,  0.2170,  0.1392],
         [ 0.3807,  0.2805, -0.1040, -0.0668],
         [-0.2747, -0.1583,  0.4301,  0.4670]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [ 0.1019, -0.3025, -0.3057, -0.0060],
         [-0.1087, -0.3137, -0.1235,  0.2578],
         ...,
         [-0.2428, -0.2092,  0.3128,  0.0729],
         [-0.0787, -0.3536,  0.2306,  0.3521],
         [ 0.0215, -0.4151, -0.4184,  0.3034]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2149, -0.0927,  0.2962, -0.3556],
         [-0.0176,  0.2412,  0.4466,  0.0468],
         ...,
         [-0.0521, -0.0454, -0.0339,  0.0453],
         [-0.4720,  0.2312, -0.1555,  0.3435],
         [-0.4843,  0.0304,  0.2015, -0.4288]]])
DESIRED: (shape=torch.Size([57042535, 10, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.2532, -0.0370, -0.4831,  0.4163],
         [-0.4569,  0.2134,  0.4081,  0.1261],
         ...,
         [-0.0616,  0.4595,  0.2487,  0.1168],
         [-0.1728, -0.3430, -0.2490, -0.4382],
         [ 0.1168, -0.3929,  0.2746, -0.3370]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.1415, -0.0108, -0.2403,  0.4044],
         [ 0.4240, -0.0927, -0.4667,  0.1001],
         ...,
         [-0.0589,  0.0682,  0.1118, -0.1634],
         [ 0.1389, -0.4563,  0.4066, -0.1643],
         [ 0.3350,  0.4178,  0.4897, -0.4462]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.3126,  0.1132,  0.1480, -0.2001],
         [ 0.3667, -0.2499, -0.1683,  0.1136],
         ...,
         [-0.4845, -0.0221,  0.4311, -0.2414],
         [ 0.1503,  0.1907,  0.3671, -0.0876],
         [ 0.3886, -0.1577,  0.0784, -0.0632]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [-0.0566,  0.1921,  0.3716, -0.0197],
         [ 0.1716, -0.4910, -0.3272,  0.2388],
         ...,
         [-0.3678,  0.4949,  0.3363,  0.2246],
         [ 0.4842,  0.3498, -0.1884, -0.1511],
         [-0.2747, -0.1583,  0.4301,  0.4670]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [ 0.1482, -0.4194, -0.3632, -0.0521],
         [-0.1843, -0.2826, -0.0530,  0.3489],
         ...,
         [-0.2864, -0.1696,  0.3068, -0.0115],
         [-0.0946, -0.3439,  0.3331,  0.3598],
         [ 0.0215, -0.4151, -0.4184,  0.3034]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2158, -0.1772,  0.3249, -0.4110],
         [ 0.0407,  0.3642,  0.4824,  0.1815],
         ...,
         [ 0.0708, -0.1361,  0.0185, -0.0782],
         [-0.4701,  0.2630, -0.2119,  0.4655],
         [-0.4843,  0.0304,  0.2015, -0.4288]]])

2025-07-26 05:31:37.780901 GPU 7 133566 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 11, 4]) != torch.Size([57042535, 10, 4]).
ACTUAL: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3204, -0.1099,  0.1043,  0.4605],
         [ 0.2690,  0.1278,  0.1234,  0.0216],
         ...,
         [-0.2193,  0.0123,  0.4546, -0.2018],
         [ 0.3236,  0.3602,  0.3708, -0.1495],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.2510, -0.2931, -0.0970, -0.2708],
         [ 0.0325,  0.1972,  0.0607, -0.1077],
         ...,
         [-0.1645,  0.1648,  0.0376, -0.1297],
         [ 0.0614, -0.0112,  0.2746,  0.1740],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [-0.1283, -0.3324, -0.3417, -0.1366],
         [ 0.3184,  0.2511, -0.0067, -0.4033],
         ...,
         [-0.0829,  0.1035, -0.0921,  0.3280],
         [ 0.1198, -0.3600, -0.3626,  0.0780],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.2696, -0.0116,  0.1463, -0.2910],
         [-0.3439,  0.2008, -0.2019, -0.0829],
         ...,
         [ 0.0887,  0.3430, -0.1958, -0.3365],
         [-0.0412,  0.2867,  0.2120, -0.1571],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2128, -0.4213, -0.0983,  0.3679],
         [-0.2851, -0.3280,  0.3095,  0.4795],
         ...,
         [-0.1069, -0.2369,  0.0843,  0.2901],
         [ 0.4037,  0.2944, -0.0179, -0.0421],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.4483, -0.3427,  0.3990, -0.3497],
         [ 0.2810, -0.2280, -0.1423, -0.4139],
         ...,
         [ 0.1216, -0.4012, -0.2507, -0.1454],
         [ 0.3458, -0.3673, -0.1103, -0.3545],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])
DESIRED: (shape=torch.Size([57042535, 10, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3143, -0.0978,  0.0751,  0.4932],
         [ 0.3986,  0.1779,  0.1341, -0.0832],
         ...,
         [-0.4174, -0.1099,  0.4587, -0.1674],
         [ 0.3090,  0.3383,  0.4438, -0.2935],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.2706, -0.3542, -0.0684, -0.2979],
         [ 0.0998,  0.3197,  0.0894, -0.0654],
         ...,
         [-0.2521,  0.2168, -0.1150, -0.2222],
         [ 0.0690,  0.0262,  0.4444,  0.1169],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [-0.1704, -0.3999, -0.3881, -0.1054],
         [ 0.4270,  0.3957,  0.0780, -0.4695],
         ...,
         [-0.2000,  0.3123,  0.0603,  0.4163],
         [ 0.2293, -0.4532, -0.4985,  0.0925],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.2579,  0.0354,  0.1570, -0.3675],
         [-0.4776,  0.2376, -0.2817, -0.0196],
         ...,
         [ 0.1245,  0.3679, -0.4036, -0.4005],
         [-0.0069,  0.2765,  0.3586, -0.1656],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2103, -0.4504, -0.0623,  0.4351],
         [-0.3018, -0.3008,  0.3921,  0.4894],
         ...,
         [-0.3135, -0.4544,  0.1204,  0.4030],
         [ 0.4437,  0.3433, -0.0121, -0.0108],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.4969, -0.4032,  0.4173, -0.3599],
         [ 0.2330, -0.1891, -0.2666, -0.4259],
         ...,
         [-0.0189, -0.3975, -0.2580, -0.0295],
         [ 0.4963, -0.4112, -0.2311, -0.4542],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])

2025-07-26 05:31:45.296620 GPU 4 133732 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 11, 4]) != torch.Size([57042535, 10, 4]).
ACTUAL: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.1111, -0.0549, -0.2228, -0.2499],
         [-0.0168, -0.1747,  0.1045, -0.2257],
         ...,
         [ 0.2440,  0.2381, -0.2124,  0.2217],
         [ 0.2180,  0.0855,  0.3329,  0.4655],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.3496, -0.3602, -0.2396,  0.4516],
         [-0.1524, -0.2020, -0.4228, -0.0970],
         ...,
         [ 0.2817,  0.2458,  0.4438, -0.3155],
         [ 0.2095, -0.2405,  0.3989,  0.2325],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.2502, -0.1356,  0.2317,  0.1376],
         [ 0.0304,  0.0777, -0.0112, -0.1267],
         ...,
         [ 0.2598,  0.1733, -0.0508,  0.2337],
         [ 0.3269, -0.2646,  0.2232,  0.4001],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.4017,  0.2195, -0.1367, -0.0826],
         [ 0.1532, -0.0928,  0.1953,  0.1905],
         ...,
         [ 0.0572, -0.2046, -0.0401,  0.0787],
         [-0.2736, -0.2565, -0.1685, -0.1009],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.4561, -0.4383,  0.2892, -0.0882],
         [-0.2246, -0.2347,  0.3303,  0.2865],
         ...,
         [ 0.1623, -0.0859,  0.1115,  0.0765],
         [-0.1066,  0.0587,  0.4180,  0.1589],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.1101,  0.4412, -0.1060,  0.3095],
         [ 0.1336, -0.0012, -0.0507,  0.2879],
         ...,
         [-0.2020, -0.4081, -0.1783,  0.0996],
         [-0.3902, -0.0287,  0.0660, -0.3637],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])
DESIRED: (shape=torch.Size([57042535, 10, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.1374, -0.0310, -0.2709, -0.3268],
         [-0.0553, -0.2106,  0.1984, -0.2004],
         ...,
         [ 0.2538,  0.2792, -0.3602,  0.1549],
         [ 0.2047,  0.0740,  0.3792,  0.4887],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.3452, -0.3570, -0.2294,  0.4597],
         [-0.2768, -0.1632, -0.4711, -0.2362],
         ...,
         [ 0.2896,  0.3698,  0.4358, -0.4727],
         [ 0.2502, -0.2501,  0.4756,  0.3133],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.3178, -0.1123,  0.2733,  0.1907],
         [ 0.1174,  0.1252, -0.0823, -0.2061],
         ...,
         [ 0.2214,  0.2974, -0.1384,  0.1947],
         [ 0.4134, -0.3234,  0.2995,  0.3893],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.4012,  0.2647, -0.1242, -0.1448],
         [ 0.2918, -0.1821,  0.2752,  0.2743],
         ...,
         [ 0.1549, -0.1947, -0.0027,  0.1356],
         [-0.3334, -0.2442, -0.1900, -0.1489],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.4681, -0.4990,  0.3569, -0.1253],
         [-0.1638, -0.1686,  0.3236,  0.3894],
         ...,
         [ 0.2270, -0.1176,  0.0235,  0.0567],
         [-0.0964,  0.0408,  0.4632,  0.1561],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.0742,  0.4629, -0.1703,  0.3798],
         [ 0.1484, -0.1172, -0.0208,  0.2649],
         ...,
         [-0.1493, -0.4945, -0.2350,  0.2387],
         [-0.4126, -0.0625,  0.0484, -0.4567],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])

2025-07-26 05:33:29.031206 GPU 6 133241 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 11, 4]) != torch.Size([57042535, 10, 4]).
ACTUAL: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.2753, -0.0321, -0.4484,  0.3542],
         [-0.4162,  0.1633,  0.2298,  0.1841],
         ...,
         [-0.0839,  0.2990,  0.1491,  0.0058],
         [-0.1438, -0.3480, -0.1967, -0.4280],
         [ 0.1168, -0.3929,  0.2746, -0.3370]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.1282, -0.0007, -0.1750,  0.3354],
         [ 0.3675, -0.0763, -0.4214,  0.1610],
         ...,
         [-0.0194, -0.0367,  0.1708, -0.1636],
         [ 0.1585, -0.3689,  0.4149, -0.1925],
         [ 0.3350,  0.4178,  0.4897, -0.4462]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.2776,  0.1436,  0.1424, -0.1603],
         [ 0.3559, -0.1773, -0.1051,  0.0509],
         ...,
         [-0.3575,  0.0205,  0.4183, -0.2107],
         [ 0.1741,  0.1559,  0.3382, -0.0852],
         [ 0.3886, -0.1577,  0.0784, -0.0632]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [-0.0088,  0.1723,  0.3095,  0.0209],
         [ 0.1259, -0.3544, -0.1875,  0.1871],
         ...,
         [-0.1974,  0.4659,  0.2313,  0.1495],
         [ 0.4083,  0.2990, -0.1265, -0.0893],
         [-0.2747, -0.1583,  0.4301,  0.4670]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [ 0.1142, -0.3337, -0.3210, -0.0183],
         [-0.1178, -0.3099, -0.1150,  0.2687],
         ...,
         [-0.2480, -0.2045,  0.3121,  0.0628],
         [-0.0829, -0.3511,  0.2580,  0.3541],
         [ 0.0215, -0.4151, -0.4184,  0.3034]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2151, -0.1152,  0.3039, -0.3704],
         [-0.0106,  0.2559,  0.4509,  0.0630],
         ...,
         [-0.0374, -0.0563, -0.0276,  0.0305],
         [-0.4715,  0.2397, -0.1706,  0.3761],
         [-0.4843,  0.0304,  0.2015, -0.4288]]])
DESIRED: (shape=torch.Size([57042535, 10, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.2532, -0.0370, -0.4831,  0.4163],
         [-0.4569,  0.2134,  0.4081,  0.1261],
         ...,
         [-0.0616,  0.4595,  0.2487,  0.1168],
         [-0.1728, -0.3430, -0.2490, -0.4382],
         [ 0.1168, -0.3929,  0.2746, -0.3370]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.1415, -0.0108, -0.2403,  0.4044],
         [ 0.4240, -0.0927, -0.4667,  0.1001],
         ...,
         [-0.0589,  0.0682,  0.1118, -0.1634],
         [ 0.1389, -0.4563,  0.4066, -0.1643],
         [ 0.3350,  0.4178,  0.4897, -0.4462]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.3126,  0.1132,  0.1480, -0.2001],
         [ 0.3667, -0.2499, -0.1683,  0.1136],
         ...,
         [-0.4845, -0.0221,  0.4311, -0.2414],
         [ 0.1503,  0.1907,  0.3671, -0.0876],
         [ 0.3886, -0.1577,  0.0784, -0.0632]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [-0.0566,  0.1921,  0.3716, -0.0197],
         [ 0.1716, -0.4910, -0.3272,  0.2388],
         ...,
         [-0.3678,  0.4949,  0.3363,  0.2246],
         [ 0.4842,  0.3498, -0.1884, -0.1511],
         [-0.2747, -0.1583,  0.4301,  0.4670]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [ 0.1482, -0.4194, -0.3632, -0.0521],
         [-0.1843, -0.2826, -0.0530,  0.3489],
         ...,
         [-0.2864, -0.1696,  0.3068, -0.0115],
         [-0.0946, -0.3439,  0.3331,  0.3598],
         [ 0.0215, -0.4151, -0.4184,  0.3034]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2158, -0.1772,  0.3249, -0.4110],
         [ 0.0407,  0.3642,  0.4824,  0.1815],
         ...,
         [ 0.0708, -0.1361,  0.0185, -0.0782],
         [-0.4701,  0.2630, -0.2119,  0.4655],
         [-0.4843,  0.0304,  0.2015, -0.4288]]])

2025-07-26 05:33:41.476684 GPU 1 133406 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 12, 4]) != torch.Size([57042535, 11, 4]).
ACTUAL: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0704,  0.0928,  0.1174,  0.4779],
         [-0.0550,  0.0963, -0.1414,  0.1786],
         ...,
         [-0.3167,  0.2593,  0.0762,  0.4117],
         [-0.2668,  0.1943, -0.4064,  0.3423],
         [ 0.1614, -0.1240, -0.1337,  0.0266]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0716, -0.3503,  0.1722, -0.3435],
         [ 0.0755, -0.3190,  0.0344, -0.2676],
         ...,
         [ 0.0720, -0.0385,  0.0624, -0.2999],
         [ 0.1017,  0.2456,  0.1836, -0.4314],
         [-0.3090, -0.2395, -0.2217, -0.3011]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.0724, -0.3939, -0.2713, -0.1459],
         [ 0.2632, -0.1487,  0.0046,  0.0612],
         ...,
         [ 0.1655, -0.0825,  0.0227,  0.1037],
         [ 0.1072, -0.2019,  0.1069,  0.2090],
         [ 0.4957,  0.2119,  0.2513, -0.2708]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.2098,  0.3275, -0.0952, -0.2145],
         [-0.0711,  0.0807,  0.0526, -0.0941],
         ...,
         [ 0.2219, -0.2833,  0.1703,  0.1262],
         [-0.0487, -0.3197, -0.0045, -0.0531],
         [-0.3065, -0.3383,  0.2259,  0.3593]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3092,  0.3393, -0.3158, -0.1255],
         [-0.1899,  0.1296, -0.3617, -0.2714],
         ...,
         [ 0.1122,  0.1655,  0.1170, -0.1141],
         [ 0.3119,  0.3674, -0.1309,  0.2684],
         [ 0.3760,  0.1008,  0.3265,  0.3444]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0461, -0.0062, -0.1277, -0.3267],
         [ 0.0695, -0.0538, -0.2415,  0.0907],
         ...,
         [ 0.0254,  0.4211,  0.1657, -0.2926],
         [ 0.4073,  0.2032,  0.2032, -0.2660],
         [ 0.2007, -0.4231, -0.3997,  0.0382]]])
DESIRED: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0704,  0.0928,  0.1174,  0.4779],
         [-0.0550,  0.0963, -0.1414,  0.1786],
         ...,
         [-0.0260,  0.3334,  0.1404,  0.3301],
         [-0.3167,  0.2593,  0.0762,  0.4117],
         [-0.2668,  0.1943, -0.4064,  0.3423]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0716, -0.3503,  0.1722, -0.3435],
         [ 0.0755, -0.3190,  0.0344, -0.2676],
         ...,
         [ 0.0581, -0.2559,  0.0326, -0.2656],
         [ 0.0720, -0.0385,  0.0624, -0.2999],
         [ 0.1017,  0.2456,  0.1836, -0.4314]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.0724, -0.3939, -0.2713, -0.1459],
         [ 0.2632, -0.1487,  0.0046,  0.0612],
         ...,
         [ 0.0711, -0.0729,  0.0930, -0.0323],
         [ 0.1655, -0.0825,  0.0227,  0.1037],
         [ 0.1072, -0.2019,  0.1069,  0.2090]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.2098,  0.3275, -0.0952, -0.2145],
         [-0.0711,  0.0807,  0.0526, -0.0941],
         ...,
         [ 0.3032, -0.0318,  0.1026,  0.2420],
         [ 0.2219, -0.2833,  0.1703,  0.1262],
         [-0.0487, -0.3197, -0.0045, -0.0531]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3092,  0.3393, -0.3158, -0.1255],
         [-0.1899,  0.1296, -0.3617, -0.2714],
         ...,
         [-0.0080,  0.1298,  0.4321, -0.1474],
         [ 0.1122,  0.1655,  0.1170, -0.1141],
         [ 0.3119,  0.3674, -0.1309,  0.2684]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0461, -0.0062, -0.1277, -0.3267],
         [ 0.0695, -0.0538, -0.2415,  0.0907],
         ...,
         [-0.2766,  0.1210, -0.1232, -0.2733],
         [ 0.0254,  0.4211,  0.1657, -0.2926],
         [ 0.4073,  0.2032,  0.2032, -0.2660]]])

2025-07-26 05:33:44.952671 GPU 5 132244 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 12, 4]) != torch.Size([57042535, 11, 4]).
ACTUAL: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.4054,  0.3770, -0.1245,  0.1562],
         [-0.1134, -0.0424, -0.0418, -0.1162],
         ...,
         [ 0.2510,  0.1105,  0.2587, -0.0169],
         [ 0.1816, -0.0593,  0.3372, -0.1767],
         [-0.3397, -0.4623,  0.4677,  0.1786]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [-0.1539,  0.4589,  0.3682,  0.0239],
         [ 0.2072,  0.4534,  0.1211, -0.0043],
         ...,
         [-0.0877,  0.2272,  0.0436,  0.0989],
         [-0.0888,  0.0959,  0.1824,  0.0588],
         [ 0.4163, -0.3160,  0.2363, -0.1671]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.1995, -0.2462, -0.1039,  0.0824],
         [-0.4155,  0.0107, -0.1054, -0.2602],
         ...,
         [-0.1411,  0.0560,  0.0533, -0.3015],
         [ 0.0171,  0.2396, -0.0905, -0.0938],
         [-0.0037, -0.0755,  0.1491,  0.4885]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.1436,  0.3242, -0.3892, -0.1907],
         [ 0.0553,  0.1079, -0.2540, -0.2651],
         ...,
         [-0.0863,  0.2022, -0.0291, -0.2201],
         [-0.0292, -0.0658, -0.0060, -0.0837],
         [-0.2772, -0.3740,  0.2297, -0.2252]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.1939, -0.1185, -0.3282,  0.1730],
         [-0.1638, -0.2113, -0.4000, -0.0338],
         ...,
         [-0.1483, -0.1155, -0.1264, -0.0264],
         [ 0.1512, -0.3127,  0.2794,  0.3590],
         [ 0.1534, -0.3439,  0.4880,  0.2351]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [ 0.0110, -0.1360,  0.2975,  0.2601],
         [-0.1218, -0.0826,  0.0804,  0.0017],
         ...,
         [-0.1296, -0.1876, -0.2535, -0.4131],
         [-0.0758, -0.0486, -0.1502, -0.4129],
         [-0.0898,  0.0021, -0.1114, -0.3003]]])
DESIRED: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.4095,  0.3665, -0.0697,  0.1074],
         [-0.0496,  0.0126, -0.0659, -0.0700],
         ...,
         [ 0.2374,  0.1257,  0.1862,  0.2000],
         [ 0.2191,  0.1052,  0.2565,  0.0394],
         [ 0.2468, -0.0089,  0.3209, -0.2211]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [-0.1794,  0.4527,  0.3363,  0.0575],
         [ 0.1684,  0.4556,  0.1600, -0.0092],
         ...,
         [-0.0855,  0.0032, -0.1094,  0.0511],
         [-0.0455,  0.2147,  0.0250,  0.0867],
         [-0.1519,  0.1474,  0.1756,  0.0870]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.1672, -0.2115, -0.1423,  0.0277],
         [-0.3965, -0.0300, -0.0956, -0.2037],
         ...,
         [-0.3572, -0.0616,  0.3661, -0.0504],
         [-0.1692, -0.0008,  0.0972, -0.2876],
         [ 0.0197,  0.2790, -0.1205, -0.1666]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.1019,  0.3170, -0.3361, -0.1964],
         [ 0.0768,  0.1367, -0.2842, -0.2544],
         ...,
         [-0.3443,  0.1101,  0.0689, -0.2068],
         [-0.1164,  0.2212, -0.0133, -0.2546],
         [ 0.0018, -0.0272, -0.0354, -0.0661]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.2020, -0.1347, -0.2681,  0.2021],
         [-0.1656, -0.1956, -0.4060, -0.0152],
         ...,
         [-0.3897, -0.1074, -0.0690, -0.2500],
         [-0.1981, -0.0852, -0.1767, -0.1009],
         [ 0.1509, -0.3088,  0.2533,  0.3745]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [-0.0255, -0.0798,  0.2863,  0.2452],
         [-0.0961, -0.1033,  0.1103,  0.0378],
         ...,
         [-0.0648, -0.1275, -0.0670, -0.3980],
         [-0.1397, -0.2065, -0.2675, -0.4037],
         [-0.0741, -0.0549, -0.1551, -0.4270]]])

2025-07-26 05:34:02.643839 GPU 7 133566 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 12, 4]) != torch.Size([57042535, 11, 4]).
ACTUAL: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3265, -0.1220,  0.1336,  0.4278],
         [ 0.1394,  0.0776,  0.1126,  0.1264],
         ...,
         [-0.1533,  0.0531,  0.4532, -0.2132],
         [ 0.3236,  0.3602,  0.3708, -0.1495],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.2315, -0.2320, -0.1256, -0.2436],
         [-0.0349,  0.0746,  0.0320, -0.1499],
         ...,
         [-0.1353,  0.1475,  0.0884, -0.0989],
         [ 0.0614, -0.0112,  0.2746,  0.1740],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [-0.0862, -0.2649, -0.2954, -0.1677],
         [ 0.2098,  0.1064, -0.0915, -0.3371],
         ...,
         [-0.0439,  0.0339, -0.1429,  0.2986],
         [ 0.1198, -0.3600, -0.3626,  0.0780],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.2814, -0.0586,  0.1356, -0.2145],
         [-0.2102,  0.1640, -0.1221, -0.1461],
         ...,
         [ 0.0767,  0.3347, -0.1265, -0.3151],
         [-0.0412,  0.2867,  0.2120, -0.1571],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2153, -0.3922, -0.1344,  0.3006],
         [-0.2685, -0.3552,  0.2269,  0.4697],
         ...,
         [-0.0381, -0.1643,  0.0723,  0.2525],
         [ 0.4037,  0.2944, -0.0179, -0.0421],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.3996, -0.2823,  0.3808, -0.3396],
         [ 0.3290, -0.2670, -0.0179, -0.4019],
         ...,
         [ 0.1684, -0.4025, -0.2482, -0.1840],
         [ 0.3458, -0.3673, -0.1103, -0.3545],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])
DESIRED: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3210, -0.1111,  0.1072,  0.4573],
         [ 0.2561,  0.1227,  0.1223,  0.0321],
         ...,
         [-0.2722, -0.0203,  0.4557, -0.1926],
         [ 0.3170,  0.3504,  0.4036, -0.2143],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.2491, -0.2870, -0.0998, -0.2681],
         [ 0.0257,  0.1849,  0.0578, -0.1119],
         ...,
         [-0.1878,  0.1787, -0.0031, -0.1544],
         [ 0.0648,  0.0056,  0.3510,  0.1483],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [-0.1241, -0.3256, -0.3371, -0.1397],
         [ 0.3075,  0.2366, -0.0152, -0.3966],
         ...,
         [-0.1141,  0.1592, -0.0515,  0.3515],
         [ 0.1691, -0.4020, -0.4237,  0.0845],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.2708, -0.0163,  0.1452, -0.2834],
         [-0.3305,  0.1971, -0.1939, -0.0892],
         ...,
         [ 0.0982,  0.3496, -0.2512, -0.3536],
         [-0.0258,  0.2821,  0.2780, -0.1609],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2130, -0.4184, -0.1019,  0.3611],
         [-0.2835, -0.3307,  0.3012,  0.4785],
         ...,
         [-0.1620, -0.2949,  0.0939,  0.3202],
         [ 0.4217,  0.3164, -0.0153, -0.0280],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.4434, -0.3367,  0.3972, -0.3487],
         [ 0.2858, -0.2319, -0.1298, -0.4127],
         ...,
         [ 0.0841, -0.4002, -0.2527, -0.1145],
         [ 0.4135, -0.3870, -0.1647, -0.3993],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])

2025-07-26 05:34:09.511702 GPU 4 133732 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 12, 4]) != torch.Size([57042535, 11, 4]).
ACTUAL: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.0896, -0.0745, -0.1834, -0.1870],
         [ 0.0148, -0.1453,  0.0277, -0.2464],
         ...,
         [ 0.2359,  0.2045, -0.0914,  0.2763],
         [ 0.2288,  0.0950,  0.2951,  0.4465],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.3532, -0.3628, -0.2480,  0.4450],
         [-0.0506, -0.2337, -0.3832,  0.0169],
         ...,
         [ 0.2753,  0.1444,  0.4503, -0.1869],
         [ 0.1762, -0.2327,  0.3362,  0.1663],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.1949, -0.1547,  0.1976,  0.0941],
         [-0.0408,  0.0389,  0.0470, -0.0618],
         ...,
         [ 0.2912,  0.0717,  0.0208,  0.2655],
         [ 0.2562, -0.2165,  0.1608,  0.4090],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.4022,  0.1825, -0.1469, -0.0318],
         [ 0.0398, -0.0196,  0.1300,  0.1219],
         ...,
         [-0.0227, -0.2127, -0.0708,  0.0321],
         [-0.2247, -0.2665, -0.1509, -0.0616],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.4462, -0.3886,  0.2338, -0.0578],
         [-0.2744, -0.2887,  0.3357,  0.2022],
         ...,
         [ 0.1094, -0.0600,  0.1834,  0.0928],
         [-0.1150,  0.0734,  0.3810,  0.1611],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.1394,  0.4234, -0.0534,  0.2519],
         [ 0.1215,  0.0938, -0.0751,  0.3067],
         ...,
         [-0.2450, -0.3374, -0.1319, -0.0142],
         [-0.3719, -0.0011,  0.0804, -0.2877],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])
DESIRED: (shape=torch.Size([57042535, 11, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.1111, -0.0549, -0.2228, -0.2499],
         [-0.0168, -0.1747,  0.1045, -0.2257],
         ...,
         [ 0.2440,  0.2381, -0.2124,  0.2217],
         [ 0.2180,  0.0855,  0.3329,  0.4655],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.3496, -0.3602, -0.2396,  0.4516],
         [-0.1524, -0.2020, -0.4228, -0.0970],
         ...,
         [ 0.2817,  0.2458,  0.4438, -0.3155],
         [ 0.2095, -0.2405,  0.3989,  0.2325],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.2502, -0.1356,  0.2317,  0.1376],
         [ 0.0304,  0.0777, -0.0112, -0.1267],
         ...,
         [ 0.2598,  0.1733, -0.0508,  0.2337],
         [ 0.3269, -0.2646,  0.2232,  0.4001],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.4017,  0.2195, -0.1367, -0.0826],
         [ 0.1532, -0.0928,  0.1953,  0.1905],
         ...,
         [ 0.0572, -0.2046, -0.0401,  0.0787],
         [-0.2736, -0.2565, -0.1685, -0.1009],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.4561, -0.4383,  0.2892, -0.0882],
         [-0.2246, -0.2347,  0.3303,  0.2865],
         ...,
         [ 0.1623, -0.0859,  0.1115,  0.0765],
         [-0.1066,  0.0587,  0.4180,  0.1589],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.1101,  0.4412, -0.1060,  0.3095],
         [ 0.1336, -0.0012, -0.0507,  0.2879],
         ...,
         [-0.2020, -0.4081, -0.1783,  0.0996],
         [-0.3902, -0.0287,  0.0660, -0.3637],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])

2025-07-26 05:34:12.855738 GPU 2 133073 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 13, 4]) != torch.Size([57042535, 12, 4]).
ACTUAL: (shape=torch.Size([57042535, 13, 4]), dtype=torch.float32)
tensor([[[ 1.6326e-01, -4.4508e-01,  4.8267e-01, -4.5835e-01],
         [-7.5437e-02, -7.8489e-02,  2.5755e-01,  8.2394e-02],
         [-5.9294e-02,  1.4003e-01, -1.1807e-01,  1.1603e-01],
         ...,
         [-2.0120e-01, -3.6510e-02, -4.9762e-02,  3.8324e-02],
         [-4.0126e-02,  8.4964e-02, -1.6802e-01, -2.8413e-02],
         [-6.0730e-02, -2.5143e-02, -4.0994e-04, -2.6592e-01]],

        [[ 3.9119e-01,  1.8266e-01,  3.2916e-01, -4.8163e-01],
         [ 1.1509e-01, -1.9475e-01,  2.2982e-01,  1.4911e-01],
         [-3.4762e-02, -3.7689e-01, -1.0575e-01,  2.4818e-01],
         ...,
         [ 2.6073e-01,  2.3718e-02,  3.5088e-01,  2.1429e-02],
         [ 2.4825e-01, -1.1986e-01,  2.8760e-01,  2.9479e-01],
         [-9.5309e-02, -2.8143e-01,  7.3123e-02,  4.5244e-01]],

        [[ 6.2583e-02,  4.9107e-01,  4.0281e-01, -2.9639e-01],
         [ 6.7938e-02,  2.2308e-02,  1.1145e-01, -1.4691e-01],
         [ 2.1089e-01, -1.6917e-01,  8.6964e-02,  9.1728e-02],
         ...,
         [-1.4237e-01, -1.0221e-01, -3.4844e-01,  1.4390e-01],
         [ 6.2535e-02, -3.6509e-01, -2.2064e-01,  4.0282e-02],
         [ 1.1464e-02, -1.5886e-01,  4.5994e-02,  1.5285e-01]],

        ...,

        [[-3.6934e-01,  3.8988e-01,  1.3074e-01,  2.1386e-01],
         [ 1.3392e-01,  4.1963e-01,  4.5470e-02, -1.5038e-01],
         [ 3.7118e-01,  1.1590e-01, -1.2904e-01, -3.1137e-01],
         ...,
         [-6.4803e-02,  1.9704e-01,  2.4034e-01,  1.0146e-01],
         [ 1.9443e-01,  3.8945e-01,  1.0786e-01,  3.2501e-01],
         [ 4.6138e-01,  2.0128e-01, -1.2700e-01,  2.7103e-01]],

        [[-3.2110e-01,  2.5314e-01, -1.9003e-01,  3.5313e-01],
         [-3.9802e-01,  1.5837e-02, -8.1848e-02,  2.5963e-01],
         [-2.7090e-01, -1.3049e-01, -1.4406e-01, -7.4543e-02],
         ...,
         [-3.2708e-02, -1.5050e-03, -2.2834e-01, -1.3325e-01],
         [ 9.2937e-02,  9.5574e-02, -8.9730e-02, -2.0302e-01],
         [ 2.4134e-01,  2.7990e-01,  1.2492e-01, -2.2090e-01]],

        [[-3.1707e-01, -3.3021e-01, -4.2028e-01, -3.2517e-01],
         [ 9.1694e-03, -3.6998e-01, -3.4019e-01, -2.5994e-01],
         [ 2.2309e-01, -1.6390e-01, -1.2995e-01, -1.1014e-01],
         ...,
         [-4.6604e-02,  2.6364e-01,  1.0192e-01,  6.8104e-02],
         [-1.4429e-01, -7.0152e-03, -3.5871e-02, -6.8875e-02],
         [-2.1938e-01, -3.4548e-01, -7.8588e-02, -3.9344e-01]]])
DESIRED: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[ 0.1633, -0.4451,  0.4827, -0.4584],
         [-0.0754, -0.0785,  0.2575,  0.0824],
         [-0.0593,  0.1400, -0.1181,  0.1160],
         ...,
         [-0.3955, -0.2652,  0.1691,  0.0109],
         [-0.2012, -0.0365, -0.0498,  0.0383],
         [-0.0401,  0.0850, -0.1680, -0.0284]],

        [[ 0.3912,  0.1827,  0.3292, -0.4816],
         [ 0.1151, -0.1948,  0.2298,  0.1491],
         [-0.0348, -0.3769, -0.1057,  0.2482],
         ...,
         [ 0.1145,  0.0446,  0.2141, -0.2874],
         [ 0.2607,  0.0237,  0.3509,  0.0214],
         [ 0.2483, -0.1199,  0.2876,  0.2948]],

        [[ 0.0626,  0.4911,  0.4028, -0.2964],
         [ 0.0679,  0.0223,  0.1115, -0.1469],
         [ 0.2109, -0.1692,  0.0870,  0.0917],
         ...,
         [-0.4489,  0.2643, -0.3491,  0.3878],
         [-0.1424, -0.1022, -0.3484,  0.1439],
         [ 0.0625, -0.3651, -0.2206,  0.0403]],

        ...,

        [[-0.3693,  0.3899,  0.1307,  0.2139],
         [ 0.1339,  0.4196,  0.0455, -0.1504],
         [ 0.3712,  0.1159, -0.1290, -0.3114],
         ...,
         [-0.1379, -0.2421,  0.2839, -0.2523],
         [-0.0648,  0.1970,  0.2403,  0.1015],
         [ 0.1944,  0.3894,  0.1079,  0.3250]],

        [[-0.3211,  0.2531, -0.1900,  0.3531],
         [-0.3980,  0.0158, -0.0818,  0.2596],
         [-0.2709, -0.1305, -0.1441, -0.0745],
         ...,
         [-0.0980,  0.0026, -0.2986, -0.0568],
         [-0.0327, -0.0015, -0.2283, -0.1332],
         [ 0.0929,  0.0956, -0.0897, -0.2030]],

        [[-0.3171, -0.3302, -0.4203, -0.3252],
         [ 0.0092, -0.3700, -0.3402, -0.2599],
         [ 0.2231, -0.1639, -0.1299, -0.1101],
         ...,
         [ 0.0088,  0.3583,  0.1289, -0.0449],
         [-0.0466,  0.2636,  0.1019,  0.0681],
         [-0.1443, -0.0070, -0.0359, -0.0689]]])

2025-07-26 05:34:39.986351 GPU 3 128066 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 13, 4]) != torch.Size([57042535, 12, 4]).
ACTUAL: (shape=torch.Size([57042535, 13, 4]), dtype=torch.float32)
tensor([[[-1.6753e-01, -3.5715e-01,  1.1132e-01, -2.3202e-01],
         [-2.5200e-01,  1.4012e-01, -6.6201e-02,  2.0635e-01],
         [ 2.2583e-02,  3.2609e-01,  1.1945e-02, -5.9342e-02],
         ...,
         [-1.7953e-01, -2.3189e-01, -3.7266e-01, -1.5877e-01],
         [ 8.4146e-02, -2.5470e-01, -2.2221e-02, -1.1052e-01],
         [ 2.9406e-01, -2.9734e-01,  3.7663e-01,  2.2536e-02]],

        [[ 3.1347e-01, -4.0706e-01,  5.6496e-02,  3.6504e-01],
         [-8.4155e-02, -2.9028e-01,  1.5316e-02,  8.1934e-02],
         [-3.2638e-01, -1.5852e-01, -2.5588e-01, -1.0076e-01],
         ...,
         [ 1.1512e-01, -1.8988e-01,  2.4952e-01,  1.7321e-01],
         [ 4.0930e-01, -1.6509e-01,  3.4440e-01,  1.4617e-01],
         [ 4.4777e-01, -1.8367e-01,  2.4835e-01,  4.5767e-02]],

        [[-3.5568e-01,  1.9639e-01, -8.9280e-02,  4.1835e-01],
         [ 1.9017e-01, -2.7499e-01, -1.0929e-01, -3.2637e-02],
         [ 2.2339e-01, -3.6893e-01,  9.8410e-02, -4.7544e-02],
         ...,
         [ 6.8384e-02, -2.5401e-01, -1.8412e-01, -1.1386e-01],
         [-6.2339e-02, -1.8208e-01, -3.7623e-01,  1.8257e-01],
         [-1.6579e-01, -1.3092e-01, -3.7865e-01,  4.9057e-01]],

        ...,

        [[ 3.7664e-01,  3.0825e-01, -3.3213e-01,  3.3278e-01],
         [ 3.0997e-01, -1.3450e-01, -8.1675e-02,  3.9677e-01],
         [-6.0552e-03, -4.4937e-02, -1.4289e-01,  1.7148e-01],
         ...,
         [ 2.4062e-01, -1.2496e-01,  2.9756e-02, -4.8266e-01],
         [ 2.5131e-01, -3.4658e-01, -4.7727e-04, -2.7586e-01],
         [ 2.0845e-01, -2.8976e-01,  1.6937e-01, -2.1008e-02]],

        [[-2.2912e-01, -4.1109e-01, -4.8481e-01,  4.3647e-01],
         [ 3.5705e-02, -1.2973e-01, -4.5274e-01, -2.3230e-01],
         [-1.4391e-01, -1.2398e-01,  1.3429e-02, -3.1981e-03],
         ...,
         [ 3.5059e-01,  2.4181e-02, -2.7425e-02,  3.6916e-01],
         [ 3.0427e-01,  2.4294e-01, -1.0690e-01,  2.2243e-01],
         [ 2.8658e-01,  3.6744e-01,  7.0162e-02,  1.0414e-01]],

        [[ 1.3781e-01, -4.2708e-01,  2.1654e-01, -2.5355e-02],
         [-3.2192e-01, -1.4972e-03,  1.1870e-01, -3.8727e-01],
         [-3.7712e-01,  2.3862e-01,  6.8759e-02, -5.4032e-02],
         ...,
         [ 1.2640e-02, -2.4626e-01, -1.5911e-01,  1.6978e-01],
         [-2.7216e-01, -1.5101e-01, -1.8564e-02,  5.5563e-02],
         [-4.3273e-01, -4.1812e-02,  1.1942e-01,  2.0238e-02]]])
DESIRED: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[-0.1675, -0.3572,  0.1113, -0.2320],
         [-0.2393,  0.0655, -0.0396,  0.1406],
         [-0.0417,  0.3182, -0.0162,  0.0258],
         ...,
         [-0.2238, -0.1644, -0.3253, -0.0272],
         [-0.2109, -0.2370, -0.3759, -0.1341],
         [ 0.0392, -0.2456, -0.1077, -0.1390]],

        [[ 0.3135, -0.4071,  0.0565,  0.3650],
         [-0.0245, -0.3078,  0.0215,  0.1244],
         [-0.3000, -0.1793, -0.2004, -0.0798],
         ...,
         [-0.3300, -0.2308, -0.1224, -0.0286],
         [ 0.0172, -0.2051,  0.1831,  0.1511],
         [ 0.4011, -0.1611,  0.3650,  0.1677]],

        [[-0.3557,  0.1964, -0.0893,  0.4184],
         [ 0.1083, -0.2043, -0.1063,  0.0350],
         [ 0.2514, -0.3791,  0.0526, -0.0733],
         ...,
         [ 0.1605, -0.2790,  0.2212, -0.0705],
         [ 0.0842, -0.2645, -0.1129, -0.1260],
         [-0.0402, -0.1930, -0.3757,  0.1166]],

        ...,

        [[ 0.3766,  0.3082, -0.3321,  0.3328],
         [ 0.3200, -0.0681, -0.1192,  0.3872],
         [ 0.0574, -0.0926, -0.1137,  0.2239],
         ...,
         [ 0.1330,  0.4631,  0.3860, -0.3012],
         [ 0.2228, -0.0236,  0.0957, -0.4783],
         [ 0.2605, -0.3588, -0.0369, -0.3305]],

        [[-0.2291, -0.4111, -0.4848,  0.4365],
         [-0.0040, -0.1719, -0.4576, -0.1320],
         [-0.0884, -0.1071, -0.0844, -0.0953],
         ...,
         [ 0.3955, -0.2514,  0.4685,  0.4010],
         [ 0.3623, -0.0178,  0.0593,  0.3862],
         [ 0.3081,  0.2163, -0.1448,  0.2478]],

        [[ 0.1378, -0.4271,  0.2165, -0.0254],
         [-0.2530, -0.0653,  0.1334, -0.3330],
         [-0.3948,  0.2145,  0.0732, -0.1487],
         ...,
         [ 0.2048, -0.2648, -0.2130,  0.3827],
         [ 0.0678, -0.2469, -0.1675,  0.2013],
         [-0.2377, -0.1744, -0.0481,  0.0631]]])

2025-07-26 05:35:50.928035 GPU 6 133241 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 13, 4]) != torch.Size([57042535, 12, 4]).
ACTUAL: (shape=torch.Size([57042535, 13, 4]), dtype=torch.float32)
tensor([[[-4.7432e-01,  1.2368e-02, -1.3595e-01, -2.0418e-01],
         [-3.0849e-01, -2.4672e-02, -3.9634e-01,  2.6116e-01],
         [-3.5506e-01,  8.8172e-02, -3.7522e-02,  2.7118e-01],
         ...,
         [-1.1721e-01,  5.8250e-02, -1.8863e-04, -1.6070e-01],
         [-1.0040e-01, -3.5545e-01, -1.1813e-01, -4.1287e-01],
         [ 1.1681e-01, -3.9290e-01,  2.7457e-01, -3.3703e-01]],

        [[ 9.2633e-03,  8.9874e-02,  4.1317e-01, -2.8497e-01],
         [ 1.0841e-01,  1.4363e-02, -7.6935e-02,  2.3204e-01],
         [ 2.8273e-01, -5.1734e-02, -3.5349e-01,  2.5226e-01],
         ...,
         [ 3.9974e-02, -1.9403e-01,  2.5924e-01, -1.6384e-01],
         [ 1.8789e-01, -2.3775e-01,  4.2740e-01, -2.3475e-01],
         [ 3.3498e-01,  4.1775e-01,  4.8971e-01, -4.4615e-01]],

        [[-3.7533e-02,  4.1694e-01,  9.1470e-02,  1.9794e-01],
         [ 2.2506e-01,  1.8916e-01,  1.3387e-01, -1.0060e-01],
         [ 3.3963e-01, -6.8320e-02, -1.0163e-02, -4.3256e-02],
         ...,
         [-1.6709e-01,  8.4323e-02,  3.9909e-01, -1.6453e-01],
         [ 2.0988e-01,  1.0361e-01,  2.9489e-01, -8.1517e-02],
         [ 3.8857e-01, -1.5772e-01,  7.8394e-02, -6.3185e-02]],

        ...,

        [[ 4.2156e-01, -5.2655e-03, -2.4876e-01,  3.8569e-01],
         [ 6.2963e-02,  1.4273e-01,  2.1650e-01,  8.1664e-02],
         [ 5.7502e-02, -1.4948e-01,  2.2179e-02,  1.0954e-01],
         ...,
         [ 5.8192e-02,  4.2236e-01,  7.3955e-02,  3.6763e-02],
         [ 2.9446e-01,  2.2275e-01, -3.3739e-02,  3.4091e-03],
         [-2.7467e-01, -1.5833e-01,  4.3010e-01,  4.6695e-01]],

        [[-1.9185e-01,  4.3816e-01,  5.8852e-02,  2.8580e-01],
         [ 6.3209e-02, -2.0502e-01, -2.5772e-01,  3.2363e-02],
         [-1.8033e-02, -3.5099e-01, -2.0811e-01,  1.4840e-01],
         ...,
         [-1.9049e-01, -2.5676e-01,  3.1996e-01,  1.7416e-01],
         [-6.5538e-02, -3.6173e-01,  1.4523e-01,  3.4569e-01],
         [ 2.1510e-02, -4.1508e-01, -4.1840e-01,  3.0342e-01]],

        [[-2.0891e-01,  4.4250e-01,  1.1439e-01, -4.9078e-03],
         [-2.1410e-01, -2.2277e-02,  2.7227e-01, -3.0948e-01],
         [-8.7579e-02,  9.3505e-02,  4.0365e-01, -1.1475e-01],
         ...,
         [-1.9965e-01,  6.3442e-02, -9.6702e-02,  1.9363e-01],
         [-4.7364e-01,  2.0483e-01, -1.0855e-01,  2.4192e-01],
         [-4.8427e-01,  3.0447e-02,  2.0151e-01, -4.2883e-01]]])
DESIRED: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[-4.7432e-01,  1.2368e-02, -1.3595e-01, -2.0418e-01],
         [-2.9342e-01, -2.8040e-02, -4.2002e-01,  3.0346e-01],
         [-3.8283e-01,  1.2232e-01,  8.4011e-02,  2.3161e-01],
         ...,
         [-1.0205e-01,  1.6767e-01,  6.7677e-02, -8.5032e-02],
         [-1.2014e-01, -3.5204e-01, -1.5383e-01, -4.1977e-01],
         [ 1.1681e-01, -3.9290e-01,  2.7457e-01, -3.3703e-01]],

        [[ 9.2633e-03,  8.9874e-02,  4.1317e-01, -2.8497e-01],
         [ 1.1743e-01,  7.4979e-03, -1.2149e-01,  2.7904e-01],
         [ 3.2126e-01, -6.2896e-02, -3.8437e-01,  2.1077e-01],
         ...,
         [ 1.3005e-02, -1.2251e-01,  2.1904e-01, -1.6372e-01],
         [ 1.7452e-01, -2.9734e-01,  4.2173e-01, -2.1554e-01],
         [ 3.3498e-01,  4.1775e-01,  4.8971e-01, -4.4615e-01]],

        [[-3.7533e-02,  4.1694e-01,  9.1470e-02,  1.9794e-01],
         [ 2.4893e-01,  1.6845e-01,  1.3773e-01, -1.2774e-01],
         [ 3.4700e-01, -1.1783e-01, -5.3301e-02, -4.7630e-04],
         ...,
         [-2.5366e-01,  5.5306e-02,  4.0782e-01, -1.8550e-01],
         [ 1.9363e-01,  1.2737e-01,  3.1457e-01, -8.3184e-02],
         [ 3.8857e-01, -1.5772e-01,  7.8394e-02, -6.3185e-02]],

        ...,

        [[ 4.2156e-01, -5.2655e-03, -2.4876e-01,  3.8569e-01],
         [ 3.0363e-02,  1.5618e-01,  2.5879e-01,  5.4026e-02],
         [ 8.8612e-02, -2.4263e-01, -7.3113e-02,  1.4478e-01],
         ...,
         [-5.7982e-02,  4.4216e-01,  1.4549e-01,  8.8000e-02],
         [ 3.4619e-01,  2.5739e-01, -7.5906e-02, -3.8732e-02],
         [-2.7467e-01, -1.5833e-01,  4.3010e-01,  4.6695e-01]],

        [[-1.9185e-01,  4.3816e-01,  5.8852e-02,  2.8580e-01],
         [ 8.6396e-02, -2.6349e-01, -2.8650e-01,  9.3237e-03],
         [-6.3377e-02, -3.3233e-01, -1.6581e-01,  2.0308e-01],
         ...,
         [-2.1665e-01, -2.3298e-01,  3.1637e-01,  1.2353e-01],
         [-7.3451e-02, -3.5688e-01,  1.9647e-01,  3.4953e-01],
         [ 2.1510e-02, -4.1508e-01, -4.1840e-01,  3.0342e-01]],

        [[-2.0891e-01,  4.4250e-01,  1.1439e-01, -4.9078e-03],
         [-2.1457e-01, -6.4530e-02,  2.8663e-01, -3.3717e-01],
         [-5.2602e-02,  1.6733e-01,  4.2513e-01, -3.3948e-02],
         ...,
         [-1.2589e-01,  9.0301e-03, -6.5285e-02,  1.1949e-01],
         [-4.7268e-01,  2.2068e-01, -1.3674e-01,  3.0290e-01],
         [-4.8427e-01,  3.0447e-02,  2.0151e-01, -4.2883e-01]]])

2025-07-26 05:36:19.158615 GPU 1 133406 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 13, 4]) != torch.Size([57042535, 12, 4]).
ACTUAL: (shape=torch.Size([57042535, 13, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0704,  0.0928,  0.1174,  0.4779],
         [-0.0296,  0.0770, -0.1061,  0.2218],
         ...,
         [-0.3300,  0.2652, -0.0057,  0.4168],
         [-0.2668,  0.1943, -0.4064,  0.3423],
         [ 0.1614, -0.1240, -0.1337,  0.0266]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0716, -0.3503,  0.1722, -0.3435],
         [ 0.0885, -0.3205,  0.0411, -0.2938],
         ...,
         [ 0.0958,  0.0252,  0.0990, -0.3249],
         [ 0.1017,  0.2456,  0.1836, -0.4314],
         [-0.3090, -0.2395, -0.2217, -0.3011]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.0724, -0.3939, -0.2713, -0.1459],
         [ 0.2265, -0.1882, -0.0500,  0.0464],
         ...,
         [ 0.1387, -0.1192,  0.0278,  0.1416],
         [ 0.1072, -0.2019,  0.1069,  0.2090],
         [ 0.4957,  0.2119,  0.2513, -0.2708]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.2098,  0.3275, -0.0952, -0.2145],
         [-0.0283,  0.1166,  0.0363, -0.1176],
         ...,
         [ 0.1955, -0.2877,  0.1344,  0.0810],
         [-0.0487, -0.3197, -0.0045, -0.0531],
         [-0.3065, -0.3383,  0.2259,  0.3593]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3092,  0.3393, -0.3158, -0.1255],
         [-0.1997,  0.1599, -0.3810, -0.2373],
         ...,
         [ 0.1377,  0.2071,  0.0598, -0.0631],
         [ 0.3119,  0.3674, -0.1309,  0.2684],
         [ 0.3760,  0.1008,  0.3265,  0.3444]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0461, -0.0062, -0.1277, -0.3267],
         [ 0.0637, -0.0322, -0.2489,  0.0187],
         ...,
         [ 0.0898,  0.4198,  0.1998, -0.3033],
         [ 0.4073,  0.2032,  0.2032, -0.2660],
         [ 0.2007, -0.4231, -0.3997,  0.0382]]])
DESIRED: (shape=torch.Size([57042535, 12, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0849,  0.0570,  0.1143,  0.4787],
         [-0.0713,  0.1086, -0.1639,  0.1511],
         ...,
         [-0.3082,  0.2555,  0.1284,  0.4084],
         [-0.3058,  0.2232, -0.4312,  0.3710],
         [ 0.1614, -0.1240, -0.1337,  0.0266]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0975, -0.3446,  0.1475, -0.3728],
         [ 0.0672, -0.3181,  0.0301, -0.2509],
         ...,
         [ 0.0569, -0.0790,  0.0391, -0.2840],
         [ 0.1390,  0.2897,  0.2204, -0.4432],
         [-0.3090, -0.2395, -0.2217, -0.3011]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.0510, -0.4023, -0.3003, -0.1177],
         [ 0.2866, -0.1236,  0.0394,  0.0706],
         ...,
         [ 0.1826, -0.0591,  0.0194,  0.0796],
         [ 0.0718, -0.2396,  0.0938,  0.2527],
         [ 0.4957,  0.2119,  0.2513, -0.2708]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.2149,  0.3287, -0.0859, -0.2265],
         [-0.0983,  0.0578,  0.0629, -0.0792],
         ...,
         [ 0.2386, -0.2806,  0.1932,  0.1550],
         [-0.0253, -0.3180, -0.0254, -0.0906],
         [-0.3065, -0.3383,  0.2259,  0.3593]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.2954,  0.3399, -0.3653, -0.1001],
         [-0.1837,  0.1104, -0.3494, -0.2931],
         ...,
         [ 0.0960,  0.1391,  0.1534, -0.1466],
         [ 0.3061,  0.3917, -0.1724,  0.2615],
         [ 0.3760,  0.1008,  0.3265,  0.3444]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0257,  0.0220, -0.1729, -0.3502],
         [ 0.0733, -0.0675, -0.2368,  0.1365],
         ...,
         [-0.0156,  0.4219,  0.1440, -0.2858],
         [ 0.4261,  0.2601,  0.2581, -0.2936],
         [ 0.2007, -0.4231, -0.3997,  0.0382]]])

2025-07-26 05:37:23.579585 GPU 3 128066 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 15, 4]) != torch.Size([57042535, 14, 4]).
ACTUAL: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[-0.1675, -0.3572,  0.1113, -0.2320],
         [-0.2224, -0.0339, -0.0041,  0.0529],
         [-0.1845,  0.3007, -0.0788,  0.2149],
         ...,
         [-0.1411, -0.2256, -0.3687, -0.1889],
         [ 0.0991, -0.2577,  0.0063, -0.1010],
         [ 0.2941, -0.2973,  0.3766,  0.0225]],

        [[ 0.3135, -0.4071,  0.0565,  0.3650],
         [ 0.0550, -0.3312,  0.0297,  0.1810],
         [-0.2415, -0.2253, -0.0772, -0.0333],
         ...,
         [ 0.2348, -0.1712,  0.3307,  0.2003],
         [ 0.4120, -0.1664,  0.3375,  0.1390],
         [ 0.4478, -0.1837,  0.2483,  0.0458]],

        [[-0.3557,  0.1964, -0.0893,  0.4184],
         [-0.0009, -0.1100, -0.1023,  0.1252],
         [ 0.3135, -0.4017, -0.0491, -0.1307],
         ...,
         [ 0.0491, -0.2411, -0.2712, -0.0990],
         [-0.0697, -0.1784, -0.3764,  0.2046],
         [-0.1658, -0.1309, -0.3786,  0.4906]],

        ...,

        [[ 0.3766,  0.3082, -0.3321,  0.3328],
         [ 0.3333,  0.0205, -0.1693,  0.3744],
         [ 0.1983, -0.1985, -0.0487,  0.3403],
         ...,
         [ 0.2624, -0.2489, -0.0508, -0.4880],
         [ 0.2482, -0.3425,  0.0117, -0.2577],
         [ 0.2085, -0.2898,  0.1694, -0.0210]],

        [[-0.2291, -0.4111, -0.4848,  0.4365],
         [-0.0570, -0.2282, -0.4640,  0.0018],
         [ 0.0350, -0.0697, -0.3018, -0.2999],
         ...,
         [ 0.3363,  0.0755, -0.1334,  0.3484],
         [ 0.3030,  0.2518, -0.0943,  0.2140],
         [ 0.2866,  0.3674,  0.0702,  0.1041]],

        [[ 0.1378, -0.4271,  0.2165, -0.0254],
         [-0.1610, -0.1505,  0.1529, -0.2606],
         [-0.4342,  0.1610,  0.0830, -0.3591],
         ...,
         [-0.0548, -0.2455, -0.1489,  0.1313],
         [-0.2836, -0.1432, -0.0087,  0.0530],
         [-0.4327, -0.0418,  0.1194,  0.0202]]])
DESIRED: (shape=torch.Size([57042535, 14, 4]), dtype=torch.float32)
tensor([[[-0.1675, -0.3572,  0.1113, -0.2320],
         [-0.2224, -0.0339, -0.0041,  0.0529],
         [-0.1845,  0.3007, -0.0788,  0.2149],
         ...,
         [-0.3226, -0.2554, -0.3873, -0.0464],
         [-0.1411, -0.2256, -0.3687, -0.1889],
         [ 0.0991, -0.2577,  0.0063, -0.1010]],

        [[ 0.3135, -0.4071,  0.0565,  0.3650],
         [ 0.0550, -0.3312,  0.0297,  0.1810],
         [-0.2415, -0.2253, -0.0772, -0.0333],
         ...,
         [-0.3311, -0.2594, -0.0532,  0.0724],
         [ 0.2348, -0.1712,  0.3307,  0.2003],
         [ 0.4120, -0.1664,  0.3375,  0.1390]],

        [[-0.3557,  0.1964, -0.0893,  0.4184],
         [-0.0009, -0.1100, -0.1023,  0.1252],
         [ 0.3135, -0.4017, -0.0491, -0.1307],
         ...,
         [ 0.1402, -0.3020,  0.1405, -0.1693],
         [ 0.0491, -0.2411, -0.2712, -0.0990],
         [-0.0697, -0.1784, -0.3764,  0.2046]],

        ...,

        [[ 0.3766,  0.3082, -0.3321,  0.3328],
         [ 0.3333,  0.0205, -0.1693,  0.3744],
         [ 0.1983, -0.1985, -0.0487,  0.3403],
         ...,
         [ 0.1596,  0.3369,  0.3301, -0.4628],
         [ 0.2624, -0.2489, -0.0508, -0.4880],
         [ 0.2482, -0.3425,  0.0117, -0.2577]],

        [[-0.2291, -0.4111, -0.4848,  0.4365],
         [-0.0570, -0.2282, -0.4640,  0.0018],
         [ 0.0350, -0.0697, -0.3018, -0.2999],
         ...,
         [ 0.4038, -0.1672,  0.3676,  0.4466],
         [ 0.3363,  0.0755, -0.1334,  0.3484],
         [ 0.3030,  0.2518, -0.0943,  0.2140]],

        [[ 0.1378, -0.4271,  0.2165, -0.0254],
         [-0.1610, -0.1505,  0.1529, -0.2606],
         [-0.4342,  0.1610,  0.0830, -0.3591],
         ...,
         [ 0.2640, -0.2491, -0.1972,  0.3132],
         [-0.0548, -0.2455, -0.1489,  0.1313],
         [-0.2836, -0.1432, -0.0087,  0.0530]]])

2025-07-26 05:38:29.728127 GPU 6 133241 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 15, 4]) != torch.Size([57042535, 14, 4]).
ACTUAL: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.3269, -0.0206, -0.3674,  0.2095],
         [-0.3211,  0.0464, -0.1861,  0.3195],
         ...,
         [-0.1728, -0.3430, -0.2490, -0.4382],
         [ 0.0203, -0.3763,  0.1000, -0.3707],
         [ 0.1168, -0.3929,  0.2746, -0.3370]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.0974,  0.0228, -0.0225,  0.1746],
         [ 0.2356, -0.0381, -0.3158,  0.3030],
         ...,
         [ 0.1389, -0.4563,  0.4066, -0.1643],
         [ 0.2696,  0.1264,  0.4620, -0.3522],
         [ 0.3350,  0.4178,  0.4897, -0.4462]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.1959,  0.2145,  0.1292, -0.0674],
         [ 0.3306, -0.0078,  0.0426, -0.0955],
         ...,
         [ 0.1503,  0.1907,  0.3671, -0.0876],
         [ 0.3092, -0.0416,  0.1746, -0.0713],
         [ 0.3886, -0.1577,  0.0784, -0.0632]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [ 0.1028,  0.1263,  0.1648,  0.1154],
         [ 0.0195, -0.0356,  0.1386,  0.0665],
         ...,
         [ 0.4842,  0.3498, -0.1884, -0.1511],
         [-0.0217,  0.0110,  0.2239,  0.2609],
         [-0.2747, -0.1583,  0.4301,  0.4670]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [ 0.0349, -0.1336, -0.2225,  0.0605],
         [ 0.0374, -0.3738, -0.2598,  0.0816],
         ...,
         [-0.0946, -0.3439,  0.3331,  0.3598],
         [-0.0172, -0.3914, -0.1679,  0.3222],
         [ 0.0215, -0.4151, -0.4184,  0.3034]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2135,  0.0294,  0.2547, -0.2756],
         [-0.1303,  0.0033,  0.3774, -0.2135],
         ...,
         [-0.4701,  0.2630, -0.2119,  0.4655],
         [-0.4795,  0.1079,  0.0637, -0.1307],
         [-0.4843,  0.0304,  0.2015, -0.4288]]])
DESIRED: (shape=torch.Size([57042535, 14, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.3638, -0.0123, -0.3095,  0.1060],
         [-0.2872,  0.0047, -0.3346,  0.3679],
         ...,
         [-0.0802,  0.3257,  0.1657,  0.0243],
         [-0.1543, -0.2092, -0.1661, -0.3457],
         [-0.0280, -0.3679,  0.0128, -0.3876]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.0754,  0.0395,  0.0864,  0.0597],
         [ 0.1886, -0.0245, -0.2780,  0.3537],
         ...,
         [-0.0259, -0.0192,  0.1610, -0.1635],
         [ 0.1059, -0.3688,  0.3575, -0.1641],
         [ 0.2369, -0.0192,  0.4482, -0.3052]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.1375,  0.2651,  0.1197, -0.0011],
         [ 0.3216,  0.0527,  0.0953, -0.1478],
         ...,
         [-0.3787,  0.0134,  0.4204, -0.2158],
         [ 0.0445,  0.1553,  0.3777, -0.1133],
         [ 0.2694,  0.0165,  0.2227, -0.0754]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [ 0.1825,  0.0934,  0.0614,  0.1830],
         [-0.0185,  0.0782,  0.2551,  0.0234],
         ...,
         [-0.2258,  0.4708,  0.2488,  0.1620],
         [ 0.3422,  0.3740, -0.1009, -0.0885],
         [ 0.1047,  0.0957,  0.1209,  0.1579]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [-0.0218,  0.0094, -0.1522,  0.1168],
         [ 0.0928, -0.3966, -0.3115,  0.0147],
         ...,
         [-0.2544, -0.1986,  0.3112,  0.0504],
         [-0.1265, -0.3149,  0.3287,  0.2979],
         [-0.0365, -0.3795, -0.0426,  0.3316]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2124,  0.1326,  0.2196, -0.2080],
         [-0.1731, -0.0870,  0.3512, -0.3123],
         ...,
         [-0.0193, -0.0696, -0.0199,  0.0124],
         [-0.3800,  0.1964, -0.1735,  0.3749],
         [-0.4772,  0.1467, -0.0052,  0.0183]]])

2025-07-26 05:38:59.949228 GPU 1 133406 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 15, 4]) != torch.Size([57042535, 14, 4]).
ACTUAL: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0477,  0.1493,  0.1223,  0.4766],
         [ 0.0360,  0.0274, -0.0152,  0.3328],
         ...,
         [-0.3641,  0.2803, -0.2164,  0.4300],
         [-0.2057,  0.1488, -0.3674,  0.2972],
         [ 0.1614, -0.1240, -0.1337,  0.0266]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0310, -0.3593,  0.2110, -0.2974],
         [ 0.1219, -0.3243,  0.0585, -0.3612],
         ...,
         [ 0.1570,  0.1890,  0.1931, -0.3891],
         [ 0.0430,  0.1763,  0.1257, -0.4128],
         [-0.3090, -0.2395, -0.2217, -0.3011]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.1060, -0.3807, -0.2257, -0.1903],
         [ 0.1320, -0.2896, -0.1904,  0.0083],
         ...,
         [ 0.0697, -0.2138,  0.0411,  0.2390],
         [ 0.1627, -0.1428,  0.1275,  0.1405],
         [ 0.4957,  0.2119,  0.2513, -0.2708]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.2019,  0.3256, -0.1097, -0.1956],
         [ 0.0817,  0.2089, -0.0055, -0.1780],
         ...,
         [ 0.1276, -0.2987,  0.0420, -0.0354],
         [-0.0856, -0.3224,  0.0285,  0.0058],
         [-0.3065, -0.3383,  0.2259,  0.3593]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3310,  0.3385, -0.2382, -0.1654],
         [-0.2249,  0.2376, -0.4308, -0.1495],
         ...,
         [ 0.2032,  0.3139, -0.0873,  0.0681],
         [ 0.3210,  0.3293, -0.0655,  0.2792],
         [ 0.3760,  0.1008,  0.3265,  0.3444]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0781, -0.0505, -0.0568, -0.2897],
         [ 0.0487,  0.0232, -0.2679, -0.1663],
         ...,
         [ 0.2554,  0.4164,  0.2874, -0.3307],
         [ 0.3778,  0.1137,  0.1171, -0.2225],
         [ 0.2007, -0.4231, -0.3997,  0.0382]]])
DESIRED: (shape=torch.Size([57042535, 14, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0582,  0.1232,  0.1201,  0.4772],
         [ 0.0057,  0.0503, -0.0571,  0.2815],
         ...,
         [-0.3483,  0.2733, -0.1191,  0.4239],
         [-0.2339,  0.1698, -0.3854,  0.3180],
         [ 0.1614, -0.1240, -0.1337,  0.0266]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0497, -0.3551,  0.1931, -0.3187],
         [ 0.1065, -0.3226,  0.0505, -0.3301],
         ...,
         [ 0.1288,  0.1134,  0.1497, -0.3595],
         [ 0.0701,  0.2083,  0.1524, -0.4214],
         [-0.3090, -0.2395, -0.2217, -0.3011]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.0905, -0.3868, -0.2467, -0.1698],
         [ 0.1756, -0.2428, -0.1256,  0.0259],
         ...,
         [ 0.1015, -0.1702,  0.0350,  0.1941],
         [ 0.1371, -0.1701,  0.1180,  0.1721],
         [ 0.4957,  0.2119,  0.2513, -0.2708]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.2055,  0.3265, -0.1030, -0.2043],
         [ 0.0310,  0.1663,  0.0138, -0.1501],
         ...,
         [ 0.1589, -0.2936,  0.0846,  0.0183],
         [-0.0686, -0.3211,  0.0133, -0.0214],
         [-0.3065, -0.3383,  0.2259,  0.3593]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3210,  0.3389, -0.2740, -0.1469],
         [-0.2133,  0.2017, -0.4078, -0.1900],
         ...,
         [ 0.1729,  0.2646, -0.0194,  0.0075],
         [ 0.3168,  0.3469, -0.0957,  0.2742],
         [ 0.3760,  0.1008,  0.3265,  0.3444]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0634, -0.0300, -0.0896, -0.3067],
         [ 0.0556, -0.0024, -0.2591, -0.0809],
         ...,
         [ 0.1789,  0.4180,  0.2469, -0.3180],
         [ 0.3914,  0.1550,  0.1569, -0.2426],
         [ 0.2007, -0.4231, -0.3997,  0.0382]]])

2025-07-26 05:40:06.632837 GPU 5 132244 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 15, 4]) != torch.Size([57042535, 14, 4]).
ACTUAL: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.4148,  0.3529,  0.0008,  0.0447],
         [ 0.1784,  0.2093, -0.1517,  0.0951],
         ...,
         [ 0.3329,  0.1241,  0.2644, -0.1615],
         [ 0.1630, -0.0737,  0.3419, -0.1640],
         [-0.3397, -0.4623,  0.4677,  0.1786]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [-0.2121,  0.4447,  0.2952,  0.1007],
         [ 0.0299,  0.4636,  0.2988, -0.0266],
         ...,
         [-0.1964,  0.2592,  0.0915,  0.1301],
         [-0.0707,  0.0812,  0.1843,  0.0507],
         [ 0.4163, -0.3160,  0.2363, -0.1671]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.1257, -0.1669, -0.1917, -0.0426],
         [-0.3290, -0.1757, -0.0606, -0.0019],
         ...,
         [-0.0689,  0.2022, -0.0597, -0.3372],
         [ 0.0164,  0.2284, -0.0820, -0.0730],
         [-0.0037, -0.0755,  0.1491,  0.4885]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.0482,  0.3078, -0.2677, -0.2038],
         [ 0.1535,  0.2397, -0.3920, -0.2160],
         ...,
         [-0.0086,  0.1534, -0.0697, -0.1313],
         [-0.0380, -0.0768,  0.0024, -0.0888],
         [-0.2772, -0.3740,  0.2297, -0.2252]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.2125, -0.1555, -0.1910,  0.2395],
         [-0.1717, -0.1397, -0.4275,  0.0511],
         ...,
         [-0.0204, -0.1933,  0.0028,  0.1653],
         [ 0.1513, -0.3139,  0.2868,  0.3546],
         [ 0.1534, -0.3439,  0.4880,  0.2351]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [-0.0725, -0.0076,  0.2719,  0.2260],
         [-0.0042, -0.1773,  0.2172,  0.1665],
         ...,
         [-0.1036, -0.1388, -0.2176, -0.4372],
         [-0.0763, -0.0467, -0.1488, -0.4089],
         [-0.0898,  0.0021, -0.1114, -0.3003]]])
DESIRED: (shape=torch.Size([57042535, 14, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.4124,  0.3592, -0.0318,  0.0737],
         [ 0.1026,  0.1439, -0.1232,  0.0403],
         ...,
         [ 0.2951,  0.1178,  0.2618, -0.0948],
         [ 0.2016, -0.0438,  0.3322, -0.1903],
         [-0.3397, -0.4623,  0.4677,  0.1786]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [-0.1970,  0.4484,  0.3142,  0.0808],
         [ 0.0760,  0.4609,  0.2527, -0.0208],
         ...,
         [-0.1463,  0.2444,  0.0694,  0.1157],
         [-0.1082,  0.1117,  0.1803,  0.0675],
         [ 0.4163, -0.3160,  0.2363, -0.1671]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.1449, -0.1875, -0.1689, -0.0101],
         [-0.3514, -0.1273, -0.0723, -0.0690],
         ...,
         [-0.1022,  0.1348, -0.0075, -0.3207],
         [ 0.0179,  0.2517, -0.0997, -0.1162],
         [-0.0037, -0.0755,  0.1491,  0.4885]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.0730,  0.3120, -0.2992, -0.2004],
         [ 0.1280,  0.2054, -0.3562, -0.2288],
         ...,
         [-0.0445,  0.1760, -0.0509, -0.1723],
         [-0.0196, -0.0539, -0.0150, -0.0783],
         [-0.2772, -0.3740,  0.2297, -0.2252]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.2076, -0.1459, -0.2266,  0.2222],
         [-0.1697, -0.1583, -0.4204,  0.0291],
         ...,
         [-0.0795, -0.1574, -0.0568,  0.0769],
         [ 0.1511, -0.3115,  0.2713,  0.3638],
         [ 0.1534, -0.3439,  0.4880,  0.2351]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [-0.0508, -0.0409,  0.2785,  0.2349],
         [-0.0347, -0.1527,  0.1817,  0.1237],
         ...,
         [-0.1156, -0.1613, -0.2342, -0.4260],
         [-0.0753, -0.0505, -0.1517, -0.4173],
         [-0.0898,  0.0021, -0.1114, -0.3003]]])

2025-07-26 05:40:17.703866 GPU 7 133566 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 16, 4]) != torch.Size([57042535, 15, 4]).
ACTUAL: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3519, -0.1725,  0.2561,  0.2909],
         [-0.2698, -0.0806,  0.0787,  0.4572],
         ...,
         [ 0.2636,  0.3103,  0.4447, -0.2856],
         [ 0.3542,  0.4061,  0.2180,  0.1521],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.1496,  0.0238, -0.2453, -0.1300],
         [-0.2475, -0.3121, -0.0585, -0.2834],
         ...,
         [ 0.0489,  0.0381,  0.4094,  0.0957],
         [ 0.0455, -0.0896, -0.0809,  0.2936],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [ 0.0899,  0.0177, -0.1012, -0.2981],
         [-0.1330, -0.3501, -0.3590, -0.1282],
         ...,
         [ 0.2024, -0.4054, -0.4636,  0.1127],
         [-0.1093, -0.1650, -0.0779,  0.0478],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.3308, -0.2553,  0.0906,  0.1058],
         [ 0.2119,  0.0480,  0.1296, -0.3458],
         ...,
         [ 0.0013,  0.2822,  0.3109, -0.1803],
         [-0.1133,  0.3082, -0.0948, -0.1392],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2257, -0.2705, -0.2852,  0.0188],
         [-0.2160, -0.4411, -0.0339,  0.4385],
         ...,
         [ 0.3964,  0.2935, -0.0038,  0.0151],
         [ 0.3200,  0.1921, -0.0302, -0.1076],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.1958, -0.0293,  0.3046, -0.2971],
         [ 0.4805, -0.3898,  0.3745, -0.3640],
         ...,
         [ 0.4641, -0.4103, -0.2328, -0.4276],
         [ 0.0306, -0.2754,  0.1426, -0.1458],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])
DESIRED: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3519, -0.1725,  0.2561,  0.2909],
         [-0.2698, -0.0806,  0.0787,  0.4572],
         ...,
         [-0.1904,  0.0301,  0.4540, -0.2068],
         [ 0.2636,  0.3103,  0.4447, -0.2856],
         [ 0.3542,  0.4061,  0.2180,  0.1521]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.1496,  0.0238, -0.2453, -0.1300],
         [-0.2475, -0.3121, -0.0585, -0.2834],
         ...,
         [-0.1517,  0.1572,  0.0598, -0.1162],
         [ 0.0489,  0.0381,  0.4094,  0.0957],
         [ 0.0455, -0.0896, -0.0809,  0.2936]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [ 0.0899,  0.0177, -0.1012, -0.2981],
         [-0.1330, -0.3501, -0.3590, -0.1282],
         ...,
         [-0.0658,  0.0731, -0.1143,  0.3151],
         [ 0.2024, -0.4054, -0.4636,  0.1127],
         [-0.1093, -0.1650, -0.0779,  0.0478]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.3308, -0.2553,  0.0906,  0.1058],
         [ 0.2119,  0.0480,  0.1296, -0.3458],
         ...,
         [ 0.0834,  0.3393, -0.1654, -0.3271],
         [ 0.0013,  0.2822,  0.3109, -0.1803],
         [-0.1133,  0.3082, -0.0948, -0.1392]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2257, -0.2705, -0.2852,  0.0188],
         [-0.2160, -0.4411, -0.0339,  0.4385],
         ...,
         [-0.0768, -0.2051,  0.0790,  0.2737],
         [ 0.3964,  0.2935, -0.0038,  0.0151],
         [ 0.3200,  0.1921, -0.0302, -0.1076]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.1958, -0.0293,  0.3046, -0.2971],
         [ 0.4805, -0.3898,  0.3745, -0.3640],
         ...,
         [ 0.1421, -0.4018, -0.2496, -0.1622],
         [ 0.4641, -0.4103, -0.2328, -0.4276],
         [ 0.0306, -0.2754,  0.1426, -0.1458]]])

2025-07-26 05:40:20.319597 GPU 3 128066 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 16, 4]) != torch.Size([57042535, 15, 4]).
ACTUAL: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[-0.1675, -0.3572,  0.1113, -0.2320],
         [-0.2362,  0.0469, -0.0329,  0.1242],
         [-0.1381,  0.3064, -0.0584,  0.1534],
         ...,
         [-0.0470, -0.2280, -0.2715, -0.1937],
         [ 0.1966, -0.2775,  0.1915, -0.0392],
         [ 0.2941, -0.2973,  0.3766,  0.0225]],

        [[ 0.3135, -0.4071,  0.0565,  0.3650],
         [-0.0096, -0.3122,  0.0230,  0.1350],
         [-0.2605, -0.2103, -0.1172, -0.0484],
         ...,
         [ 0.3853, -0.1535,  0.4044,  0.2089],
         [ 0.4299, -0.1750,  0.2929,  0.0924],
         [ 0.4478, -0.1837,  0.2483,  0.0458]],

        [[-0.3557,  0.1964, -0.0893,  0.4184],
         [ 0.0878, -0.1866, -0.1055,  0.0519],
         [ 0.2933, -0.3944, -0.0161, -0.1120],
         ...,
         [ 0.0023, -0.2141, -0.3747, -0.0099],
         [-0.1178, -0.1547, -0.3775,  0.3476],
         [-0.1658, -0.1309, -0.3786,  0.4906]],

        ...,

        [[ 0.3766,  0.3082, -0.3321,  0.3328],
         [ 0.3225, -0.0515, -0.1286,  0.3848],
         [ 0.1525, -0.1641, -0.0698,  0.3025],
         ...,
         [ 0.2781, -0.3821, -0.1066, -0.4351],
         [ 0.2283, -0.3161,  0.0905, -0.1393],
         [ 0.2085, -0.2898,  0.1694, -0.0210]],

        [[-0.2291, -0.4111, -0.4848,  0.4365],
         [-0.0139, -0.1825, -0.4588, -0.1069],
         [-0.0051, -0.0818, -0.2312, -0.2334],
         ...,
         [ 0.3153,  0.1651, -0.2176,  0.2964],
         [ 0.2948,  0.3096, -0.0120,  0.1591],
         [ 0.2866,  0.3674,  0.0702,  0.1041]],

        [[ 0.1378, -0.4271,  0.2165, -0.0254],
         [-0.2357, -0.0813,  0.1370, -0.3194],
         [-0.4214,  0.1784,  0.0798, -0.2907],
         ...,
         [-0.1718, -0.2193, -0.1048,  0.0776],
         [-0.3582, -0.0925,  0.0554,  0.0366],
         [-0.4327, -0.0418,  0.1194,  0.0202]]])
DESIRED: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[-0.1675, -0.3572,  0.1113, -0.2320],
         [-0.2156, -0.0743,  0.0104,  0.0173],
         [-0.2425,  0.2936, -0.1042,  0.2918],
         ...,
         [-0.2829, -0.2489, -0.3832, -0.0776],
         [-0.1128, -0.2209, -0.3658, -0.2112],
         [ 0.1235, -0.2627,  0.0526, -0.0856]],

        [[ 0.3135, -0.4071,  0.0565,  0.3650],
         [ 0.0873, -0.3406,  0.0331,  0.2040],
         [-0.2177, -0.2440, -0.0271, -0.0143],
         ...,
         [-0.2073, -0.2401,  0.0308,  0.1004],
         [ 0.3233, -0.1574,  0.3907,  0.2202],
         [ 0.4165, -0.1686,  0.3264,  0.1273]],

        [[-0.3557,  0.1964, -0.0893,  0.4184],
         [-0.0452, -0.0717, -0.1007,  0.1619],
         [ 0.3388, -0.4109, -0.0905, -0.1540],
         ...,
         [ 0.1203, -0.2887,  0.0505, -0.1539],
         [ 0.0349, -0.2316, -0.3356, -0.0880],
         [-0.0817, -0.1725, -0.3767,  0.2403]],

        ...,

        [[ 0.3766,  0.3082, -0.3321,  0.3328],
         [ 0.3387,  0.0564, -0.1897,  0.3692],
         [ 0.2556, -0.2415, -0.0224,  0.3876],
         ...,
         [ 0.1821,  0.2087,  0.2468, -0.4683],
         [ 0.2784, -0.3404, -0.1103, -0.4919],
         [ 0.2433, -0.3359,  0.0314, -0.2281]],

        [[-0.2291, -0.4111, -0.4848,  0.4365],
         [-0.0785, -0.2511, -0.4666,  0.0561],
         [ 0.0851, -0.0545, -0.3901, -0.3830],
         ...,
         [ 0.3891, -0.1141,  0.2580,  0.4251],
         [ 0.3258,  0.1135, -0.2117,  0.3330],
         [ 0.3010,  0.2663, -0.0737,  0.2003]],

        [[ 0.1378, -0.4271,  0.2165, -0.0254],
         [-0.1237, -0.1850,  0.1609, -0.2312],
         [-0.4502,  0.1392,  0.0870, -0.4446],
         ...,
         [ 0.1943, -0.2483, -0.1866,  0.2734],
         [-0.1046, -0.2449, -0.1414,  0.1029],
         [-0.3023, -0.1305,  0.0073,  0.0489]]])

2025-07-26 05:40:23.343680 GPU 4 133732 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 16, 4]) != torch.Size([57042535, 15, 4]).
ACTUAL: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.0323, -0.1267, -0.0783, -0.0192],
         [ 0.0988, -0.0669, -0.1771, -0.3015],
         ...,
         [ 0.2145,  0.1150,  0.2313,  0.4219],
         [ 0.2578,  0.1202,  0.1942,  0.3960],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.3628, -0.3698, -0.2702,  0.4274],
         [ 0.2208, -0.3182, -0.2778,  0.3206],
         ...,
         [ 0.2581, -0.1261,  0.4677,  0.1561],
         [ 0.0873, -0.2117,  0.1689, -0.0101],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.0474, -0.2056,  0.1067, -0.0218],
         [-0.2308, -0.0648,  0.2022,  0.1113],
         ...,
         [ 0.3750, -0.1992,  0.2119,  0.3504],
         [ 0.0675, -0.0882, -0.0057,  0.4326],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.4033,  0.0838, -0.1742,  0.1038],
         [-0.2626,  0.1754, -0.0443, -0.0610],
         ...,
         [-0.2357, -0.2343, -0.1525, -0.0920],
         [-0.0943, -0.2932, -0.1039,  0.0431],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.4200, -0.2562,  0.0862,  0.0232],
         [-0.4072, -0.4329,  0.3502, -0.0224],
         ...,
         [-0.0317,  0.0091,  0.3752,  0.1362],
         [-0.1374,  0.1125,  0.2824,  0.1672],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.2175,  0.3760,  0.0869,  0.0985],
         [ 0.0891,  0.3469, -0.1404,  0.3568],
         ...,
         [-0.3599, -0.1489, -0.0083, -0.3176],
         [-0.3232,  0.0726,  0.1187, -0.0850],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])
DESIRED: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[-0.1252, -0.2702,  0.2106,  0.4422],
         [ 0.0436, -0.1164, -0.0990, -0.0522],
         [ 0.0823, -0.0823, -0.1368, -0.2907],
         ...,
         [ 0.2187,  0.1326,  0.1679,  0.3933],
         [ 0.2521,  0.1153,  0.2140,  0.4059],
         [ 0.3374,  0.1896, -0.0832,  0.2569]],

        [[ 0.3892, -0.3890, -0.3313,  0.3788],
         [ 0.3609, -0.3684, -0.2658,  0.4308],
         [ 0.1675, -0.3016, -0.2985,  0.2609],
         ...,
         [ 0.2614, -0.0730,  0.4642,  0.0887],
         [ 0.1048, -0.2158,  0.2017,  0.0246],
         [-0.1569, -0.1541, -0.2913, -0.4951]],

        [[ 0.3581, -0.3455, -0.1432, -0.3404],
         [-0.0764, -0.1956,  0.1246,  0.0010],
         [-0.1935, -0.0444,  0.1717,  0.0773],
         ...,
         [ 0.3585, -0.1460,  0.1744,  0.3337],
         [ 0.1046, -0.1134,  0.0270,  0.4280],
         [-0.4513,  0.2646, -0.4634,  0.4976]],

        ...,

        [[-0.4063, -0.1875, -0.2493,  0.4767],
         [-0.4031,  0.1032, -0.1689,  0.0772],
         [-0.2032,  0.1371, -0.0101, -0.0250],
         ...,
         [-0.1939, -0.2301, -0.1365, -0.0676],
         [-0.1199, -0.2879, -0.1131,  0.0225],
         [ 0.2642, -0.3666,  0.0252,  0.3311]],

        [[-0.3479,  0.1081, -0.3198,  0.2461],
         [-0.4252, -0.2822,  0.1152,  0.0073],
         [-0.3811, -0.4046,  0.3474,  0.0217],
         ...,
         [-0.0040, -0.0044,  0.3376,  0.1277],
         [-0.1330,  0.1048,  0.3018,  0.1660],
         [-0.1988,  0.2200,  0.0114,  0.1840]],

        [[ 0.4323,  0.2457,  0.4727, -0.3236],
         [ 0.2021,  0.3853,  0.0593,  0.1286],
         [ 0.0954,  0.2972, -0.1276,  0.3470],
         ...,
         [-0.3374, -0.1859, -0.0325, -0.2580],
         [-0.3327,  0.0581,  0.1112, -0.1248],
         [-0.1890,  0.2752,  0.2242,  0.4724]]])

2025-07-26 05:40:36.288943 GPU 2 133073 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 16, 4]) != torch.Size([57042535, 15, 4]).
ACTUAL: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[ 1.6326e-01, -4.4508e-01,  4.8267e-01, -4.5835e-01],
         [-5.5779e-02, -1.0868e-01,  2.7608e-01,  3.7862e-02],
         [-1.3444e-01,  1.2714e-01,  1.7139e-02,  2.4924e-01],
         ...,
         [-1.1052e-01,  5.8276e-02, -1.5890e-01,  6.9434e-02],
         [-4.1823e-02,  7.5896e-02, -1.5422e-01, -4.7972e-02],
         [-6.0730e-02, -2.5143e-02, -4.0994e-04, -2.6592e-01]],

        [[ 3.9119e-01,  1.8266e-01,  3.2916e-01, -4.8163e-01],
         [ 1.3783e-01, -1.6367e-01,  2.3800e-01,  9.7165e-02],
         [-3.2820e-02, -3.8621e-01,  4.3457e-02,  3.7201e-01],
         ...,
         [ 3.5006e-01, -6.8836e-03,  3.7739e-01,  1.2156e-01],
         [ 2.1996e-01, -1.3316e-01,  2.6994e-01,  3.0778e-01],
         [-9.5309e-02, -2.8143e-01,  7.3123e-02,  4.5244e-01]],

        [[ 6.2583e-02,  4.9107e-01,  4.0281e-01, -2.9639e-01],
         [ 6.7497e-02,  6.0912e-02,  1.3545e-01, -1.5922e-01],
         [ 1.3701e-01, -1.9906e-01,  1.8545e-02,  7.6261e-03],
         ...,
         [-2.0073e-02, -2.9839e-01, -3.5548e-01,  5.7843e-02],
         [ 5.8329e-02, -3.4811e-01, -1.9868e-01,  4.9553e-02],
         [ 1.1464e-02, -1.5886e-01,  4.5994e-02,  1.5285e-01]],

        ...,

        [[-3.6934e-01,  3.8988e-01,  1.3074e-01,  2.1386e-01],
         [ 9.2475e-02,  4.1718e-01,  5.2492e-02, -1.2038e-01],
         [ 3.8656e-01,  2.8435e-01, -6.0827e-02, -3.2816e-01],
         ...,
         [-2.6345e-03,  3.5101e-01,  2.3605e-01,  2.3440e-01],
         [ 2.1641e-01,  3.7395e-01,  8.8518e-02,  3.2056e-01],
         [ 4.6138e-01,  2.0128e-01, -1.2700e-01,  2.7103e-01]],

        [[-3.2110e-01,  2.5314e-01, -1.9003e-01,  3.5313e-01],
         [-3.9169e-01,  3.5380e-02, -9.0757e-02,  2.6733e-01],
         [-3.5940e-01, -1.1958e-01, -8.1061e-02,  7.5556e-02],
         ...,
         [-7.8850e-03, -1.7703e-03, -2.1517e-01, -1.6504e-01],
         [ 1.0516e-01,  1.1075e-01, -7.2053e-02, -2.0449e-01],
         [ 2.4134e-01,  2.7990e-01,  1.2492e-01, -2.2090e-01]],

        [[-3.1707e-01, -3.3021e-01, -4.2028e-01, -3.2517e-01],
         [-1.7698e-02, -3.6670e-01, -3.4679e-01, -2.6531e-01],
         [ 2.0136e-01, -2.8366e-01, -2.1845e-01, -1.7091e-01],
         ...,
         [-7.7152e-02,  2.1541e-01,  4.1193e-02,  8.6480e-02],
         [-1.5048e-01, -3.4889e-02, -3.9389e-02, -9.5604e-02],
         [-2.1938e-01, -3.4548e-01, -7.8588e-02, -3.9344e-01]]])
DESIRED: (shape=torch.Size([57042535, 15, 4]), dtype=torch.float32)
tensor([[[ 1.6326e-01, -4.4508e-01,  4.8267e-01, -4.5835e-01],
         [-7.1425e-02, -8.4650e-02,  2.6133e-01,  7.3306e-02],
         [-1.0556e-01,  1.3209e-01, -3.4814e-02,  1.9806e-01],
         ...,
         [-1.4536e-01,  2.1856e-02, -1.1697e-01,  5.7480e-02],
         [-4.0472e-02,  8.3113e-02, -1.6520e-01, -3.2404e-02],
         [-6.0730e-02, -2.5143e-02, -4.0994e-04, -2.6592e-01]],

        [[ 3.9119e-01,  1.8266e-01,  3.2916e-01, -4.8163e-01],
         [ 1.1973e-01, -1.8841e-01,  2.3149e-01,  1.3851e-01],
         [-3.3566e-02, -3.8263e-01, -1.3872e-02,  3.2443e-01],
         ...,
         [ 3.1573e-01,  4.8748e-03,  3.6720e-01,  8.3087e-02],
         [ 2.4248e-01, -1.2257e-01,  2.8400e-01,  2.9744e-01],
         [-9.5309e-02, -2.8143e-01,  7.3123e-02,  4.5244e-01]],

        [[ 6.2583e-02,  4.9107e-01,  4.0281e-01, -2.9639e-01],
         [ 6.7848e-02,  3.0186e-02,  1.1635e-01, -1.4942e-01],
         [ 1.6539e-01, -1.8757e-01,  4.4834e-02,  3.9941e-02],
         ...,
         [-6.7065e-02, -2.2301e-01, -3.5278e-01,  9.0911e-02],
         [ 6.1677e-02, -3.6163e-01, -2.1616e-01,  4.2174e-02],
         [ 1.1464e-02, -1.5886e-01,  4.5994e-02,  1.5285e-01]],

        ...,

        [[-3.6934e-01,  3.8988e-01,  1.3074e-01,  2.1386e-01],
         [ 1.2546e-01,  4.1913e-01,  4.6903e-02, -1.4425e-01],
         [ 3.8065e-01,  2.1963e-01, -8.7036e-02, -3.2171e-01],
         ...,
         [-2.6522e-02,  2.9185e-01,  2.3770e-01,  1.8332e-01],
         [ 1.9892e-01,  3.8628e-01,  1.0391e-01,  3.2410e-01],
         [ 4.6138e-01,  2.0128e-01, -1.2700e-01,  2.7103e-01]],

        [[-3.2110e-01,  2.5314e-01, -1.9003e-01,  3.5313e-01],
         [-3.9673e-01,  1.9825e-02, -8.3666e-02,  2.6120e-01],
         [-3.2540e-01, -1.2377e-01, -1.0527e-01,  1.7882e-02],
         ...,
         [-1.7423e-02, -1.6684e-03, -2.2023e-01, -1.5283e-01],
         [ 9.5431e-02,  9.8672e-02, -8.6122e-02, -2.0332e-01],
         [ 2.4134e-01,  2.7990e-01,  1.2492e-01, -2.2090e-01]],

        [[-3.1707e-01, -3.3021e-01, -4.2028e-01, -3.2517e-01],
         [ 3.6864e-03, -3.6931e-01, -3.4154e-01, -2.6103e-01],
         [ 2.0971e-01, -2.3765e-01, -1.8444e-01, -1.4756e-01],
         ...,
         [-6.5414e-02,  2.3395e-01,  6.4528e-02,  7.9419e-02],
         [-1.4556e-01, -1.2703e-02, -3.6589e-02, -7.4330e-02],
         [-2.1938e-01, -3.4548e-01, -7.8588e-02, -3.9344e-01]]])

2025-07-26 05:41:19.597110 GPU 6 133241 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 17, 4]) != torch.Size([57042535, 16, 4]).
ACTUAL: (shape=torch.Size([57042535, 17, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.3898, -0.0065, -0.2687,  0.0331],
         [-0.2597, -0.0356, -0.4729,  0.3980],
         ...,
         [-0.1643, -0.3444, -0.2336, -0.4352],
         [ 0.0061, -0.3738,  0.0744, -0.3757],
         [ 0.1168, -0.3929,  0.2746, -0.3370]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.0598,  0.0514,  0.1633, -0.0214],
         [ 0.1376, -0.0078, -0.2211,  0.3841],
         ...,
         [ 0.1446, -0.4305,  0.4091, -0.1726],
         [ 0.2600,  0.0836,  0.4579, -0.3384],
         [ 0.3350,  0.4178,  0.4897, -0.4462]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.0963,  0.3008,  0.1131,  0.0457],
         [ 0.3023,  0.1222,  0.1463, -0.1884],
         ...,
         [ 0.1573,  0.1805,  0.3586, -0.0869],
         [ 0.2975, -0.0245,  0.1888, -0.0725],
         [ 0.3886, -0.1577,  0.0784, -0.0632]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [ 0.2387,  0.0702, -0.0116,  0.2307],
         [-0.0425,  0.1863,  0.3533, -0.0078],
         ...,
         [ 0.4618,  0.3348, -0.1702, -0.1329],
         [ 0.0155,  0.0359,  0.1936,  0.2306],
         [-0.2747, -0.1583,  0.4301,  0.4670]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [-0.0618,  0.1103, -0.1025,  0.1566],
         [ 0.1382, -0.3942, -0.3508, -0.0422],
         ...,
         [-0.0911, -0.3460,  0.3110,  0.3581],
         [-0.0229, -0.3879, -0.1311,  0.3250],
         [ 0.0215, -0.4151, -0.4184,  0.3034]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2116,  0.2056,  0.1949, -0.1602],
         [-0.2156, -0.1590,  0.3187, -0.3991],
         ...,
         [-0.4705,  0.2561, -0.1997,  0.4392],
         [-0.4789,  0.1193,  0.0434, -0.0869],
         [-0.4843,  0.0304,  0.2015, -0.4288]]])
DESIRED: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[-0.4743,  0.0124, -0.1360, -0.2042],
         [-0.3898, -0.0065, -0.2687,  0.0331],
         [-0.2597, -0.0356, -0.4729,  0.3980],
         ...,
         [-0.1107,  0.1055,  0.0291, -0.1281],
         [-0.1643, -0.3444, -0.2336, -0.4352],
         [ 0.0061, -0.3738,  0.0744, -0.3757]],

        [[ 0.0093,  0.0899,  0.4132, -0.2850],
         [ 0.0598,  0.0514,  0.1633, -0.0214],
         [ 0.1376, -0.0078, -0.2211,  0.3841],
         ...,
         [ 0.0283, -0.1632,  0.2419, -0.1638],
         [ 0.1446, -0.4305,  0.4091, -0.1726],
         [ 0.2600,  0.0836,  0.4579, -0.3384]],

        [[-0.0375,  0.4169,  0.0915,  0.1979],
         [ 0.0963,  0.3008,  0.1131,  0.0457],
         [ 0.3023,  0.1222,  0.1463, -0.1884],
         ...,
         [-0.2044,  0.0718,  0.4029, -0.1736],
         [ 0.1573,  0.1805,  0.3586, -0.0869],
         [ 0.2975, -0.0245,  0.1888, -0.0725]],

        ...,

        [[ 0.4216, -0.0053, -0.2488,  0.3857],
         [ 0.2387,  0.0702, -0.0116,  0.2307],
         [-0.0425,  0.1863,  0.3533, -0.0078],
         ...,
         [ 0.0081,  0.4309,  0.1048,  0.0589],
         [ 0.4618,  0.3348, -0.1702, -0.1329],
         [ 0.0155,  0.0359,  0.1936,  0.2306]],

        [[-0.1918,  0.4382,  0.0589,  0.2858],
         [-0.0618,  0.1103, -0.1025,  0.1566],
         [ 0.1382, -0.3942, -0.3508, -0.0422],
         ...,
         [-0.2018, -0.2465,  0.3184,  0.1523],
         [-0.0911, -0.3460,  0.3110,  0.3581],
         [-0.0229, -0.3879, -0.1311,  0.3250]],

        [[-0.2089,  0.4425,  0.1144, -0.0049],
         [-0.2116,  0.2056,  0.1949, -0.1602],
         [-0.2156, -0.1590,  0.3187, -0.3991],
         ...,
         [-0.1678,  0.0400, -0.0831,  0.1616],
         [-0.4705,  0.2561, -0.1997,  0.4392],
         [-0.4789,  0.1193,  0.0434, -0.0869]]])

2025-07-26 05:41:51.959028 GPU 1 133406 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 17, 4]) != torch.Size([57042535, 16, 4]).
ACTUAL: (shape=torch.Size([57042535, 17, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [ 0.0361,  0.1780,  0.1248,  0.4760],
         [ 0.0694,  0.0021,  0.0311,  0.3894],
         ...,
         [-0.2752,  0.2005, -0.4117,  0.3485],
         [ 0.0607, -0.0491, -0.1978,  0.1009],
         [ 0.1614, -0.1240, -0.1337,  0.0266]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [ 0.0102, -0.3638,  0.2308, -0.2739],
         [ 0.1389, -0.3263,  0.0673, -0.3955],
         ...,
         [ 0.1097,  0.2551,  0.1915, -0.4339],
         [-0.2124, -0.1253, -0.1263, -0.3317],
         [-0.3090, -0.2395, -0.2217, -0.3011]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.1231, -0.3740, -0.2025, -0.2129],
         [ 0.0838, -0.3413, -0.2620, -0.0111],
         ...,
         [ 0.0995, -0.2101,  0.1041,  0.2184],
         [ 0.4043,  0.1145,  0.2173, -0.1579],
         [ 0.4957,  0.2119,  0.2513, -0.2708]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.1978,  0.3246, -0.1172, -0.1860],
         [ 0.1378,  0.2560, -0.0268, -0.2087],
         ...,
         [-0.0437, -0.3194, -0.0090, -0.0612],
         [-0.2458, -0.3339,  0.1717,  0.2623],
         [-0.3065, -0.3383,  0.2259,  0.3593]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3421,  0.3381, -0.1986, -0.1857],
         [-0.2378,  0.2773, -0.4561, -0.1047],
         ...,
         [ 0.3106,  0.3726, -0.1398,  0.2669],
         [ 0.3609,  0.1635,  0.2189,  0.3265],
         [ 0.3760,  0.1008,  0.3265,  0.3444]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.0945, -0.0731, -0.0207, -0.2708],
         [ 0.0410,  0.0515, -0.2776, -0.2606],
         ...,
         [ 0.4113,  0.2155,  0.2151, -0.2719],
         [ 0.2493, -0.2757, -0.2578, -0.0334],
         [ 0.2007, -0.4231, -0.3997,  0.0382]]])
DESIRED: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[-0.0885,  0.4877,  0.1519,  0.4690],
         [-0.0075,  0.2864,  0.1343,  0.4735],
         [ 0.1172, -0.0233,  0.1073,  0.4805],
         ...,
         [-0.3206,  0.2610,  0.0521,  0.4132],
         [-0.3928,  0.2879, -0.4866,  0.4352],
         [-0.0569,  0.0383, -0.2727,  0.1875]],

        [[-0.2130, -0.4129,  0.4440, -0.0210],
         [-0.0679, -0.3810,  0.3054, -0.1854],
         [ 0.1553, -0.3319,  0.0922, -0.4384],
         ...,
         [ 0.0790, -0.0198,  0.0732, -0.3073],
         [ 0.2224,  0.3883,  0.3028, -0.4697],
         [-0.0997,  0.0078, -0.0151, -0.3675]],

        [[-0.3074, -0.3014,  0.0477, -0.4563],
         [-0.1876, -0.3486, -0.1149, -0.2981],
         [-0.0032, -0.4211, -0.3651, -0.0546],
         ...,
         [ 0.1577, -0.0933,  0.0242,  0.1148],
         [-0.0071, -0.3237,  0.0644,  0.3502],
         [ 0.2976,  0.0009,  0.1777, -0.0262]],

        ...,

        [[ 0.1540,  0.3139, -0.1971, -0.0825],
         [ 0.1825,  0.3208, -0.1451, -0.1498],
         [ 0.2263,  0.3315, -0.0652, -0.2533],
         ...,
         [ 0.2141, -0.2846,  0.1598,  0.1129],
         [ 0.0271, -0.3142, -0.0722, -0.1744],
         [-0.1751, -0.3288,  0.1085,  0.1491]],

        [[-0.4614,  0.3335,  0.2279, -0.4047],
         [-0.3838,  0.3365, -0.0493, -0.2623],
         [-0.2645,  0.3411, -0.4758, -0.0433],
         ...,
         [ 0.1197,  0.1778,  0.1002, -0.0991],
         [ 0.2930,  0.4458, -0.2654,  0.2460],
         [ 0.3433,  0.2367,  0.0933,  0.3056]],

        [[-0.2704, -0.3162,  0.3687, -0.0677],
         [-0.1561, -0.1582,  0.1156, -0.1997],
         [ 0.0199,  0.0850, -0.2738, -0.4028],
         ...,
         [ 0.0443,  0.4207,  0.1757, -0.2957],
         [ 0.4681,  0.3874,  0.3806, -0.3554],
         [ 0.3060, -0.1038, -0.0923, -0.1169]]])

2025-07-26 05:43:02.787662 GPU 5 132244 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 17, 4]) != torch.Size([57042535, 16, 4]).
ACTUAL: (shape=torch.Size([57042535, 17, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.4188,  0.3428,  0.0536, -0.0023],
         [ 0.3014,  0.3154, -0.1981,  0.1843],
         ...,
         [ 0.3944,  0.1343,  0.2687, -0.2700],
         [ 0.1001, -0.1222,  0.3576, -0.1212],
         [-0.3397, -0.4623,  0.4677,  0.1786]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [-0.2366,  0.4388,  0.2644,  0.1332],
         [-0.0448,  0.4679,  0.3738, -0.0361],
         ...,
         [-0.2779,  0.2832,  0.1275,  0.1535],
         [-0.0099,  0.0315,  0.1908,  0.0235],
         [ 0.4163, -0.3160,  0.2363, -0.1671]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.0946, -0.1335, -0.2287, -0.0953],
         [-0.2925, -0.2543, -0.0417,  0.1071],
         ...,
         [-0.0147,  0.3119, -0.1444, -0.3641],
         [ 0.0139,  0.1904, -0.0531, -0.0028],
         [-0.0037, -0.0755,  0.1491,  0.4885]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.0079,  0.3009, -0.2164, -0.2093],
         [ 0.1949,  0.2953, -0.4503, -0.1953],
         ...,
         [ 0.0496,  0.1168, -0.1001, -0.0648],
         [-0.0679, -0.1139,  0.0308, -0.1058],
         [-0.2772, -0.3740,  0.2297, -0.2252]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.2203, -0.1711, -0.1331,  0.2675],
         [-0.1751, -0.1095, -0.4392,  0.0870],
         ...,
         [ 0.0755, -0.2517,  0.0997,  0.3091],
         [ 0.1515, -0.3176,  0.3120,  0.3397],
         [ 0.1534, -0.3439,  0.4880,  0.2351]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [-0.1077,  0.0466,  0.2611,  0.2116],
         [ 0.0455, -0.2172,  0.2749,  0.2360],
         ...,
         [-0.0840, -0.1023, -0.1906, -0.4552],
         [-0.0780, -0.0406, -0.1442, -0.3953],
         [-0.0898,  0.0021, -0.1114, -0.3003]]])
DESIRED: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[ 0.4466,  0.2718,  0.4236, -0.3313],
         [ 0.4169,  0.3475,  0.0289,  0.0197],
         [ 0.2440,  0.2659, -0.1764,  0.1427],
         ...,
         [ 0.3657,  0.1296,  0.2667, -0.2194],
         [ 0.1295, -0.0996,  0.3503, -0.1411],
         [-0.3397, -0.4623,  0.4677,  0.1786]],

        [[-0.4085,  0.3971,  0.0488,  0.3601],
         [-0.2252,  0.4416,  0.2788,  0.1180],
         [-0.0099,  0.4659,  0.3388, -0.0317],
         ...,
         [-0.2399,  0.2720,  0.1107,  0.1426],
         [-0.0383,  0.0547,  0.1878,  0.0362],
         [ 0.4163, -0.3160,  0.2363, -0.1671]],

        [[ 0.1234,  0.1005, -0.4880, -0.4644],
         [-0.1091, -0.1491, -0.2114, -0.0707],
         [-0.3095, -0.2176, -0.0506,  0.0562],
         ...,
         [-0.0399,  0.2607, -0.1049, -0.3515],
         [ 0.0150,  0.2081, -0.0666, -0.0356],
         [-0.0037, -0.0755,  0.1491,  0.4885]],

        ...,

        [[-0.2739,  0.2525,  0.1426, -0.2479],
         [ 0.0267,  0.3041, -0.2403, -0.2067],
         [ 0.1756,  0.2693, -0.4231, -0.2050],
         ...,
         [ 0.0224,  0.1339, -0.0859, -0.0958],
         [-0.0540, -0.0966,  0.0176, -0.0979],
         [-0.2772, -0.3740,  0.2297, -0.2252]],

        [[-0.2751, -0.2805,  0.2721,  0.4638],
         [-0.2166, -0.1638, -0.1601,  0.2544],
         [-0.1735, -0.1236, -0.4337,  0.0702],
         ...,
         [ 0.0307, -0.2245,  0.0545,  0.2420],
         [ 0.1514, -0.3159,  0.3002,  0.3467],
         [ 0.1534, -0.3439,  0.4880,  0.2351]],

        [[-0.3542,  0.4257,  0.1857,  0.1108],
         [-0.0912,  0.0213,  0.2662,  0.2183],
         [ 0.0223, -0.1986,  0.2480,  0.2035],
         ...,
         [-0.0932, -0.1194, -0.2032, -0.4468],
         [-0.0772, -0.0435, -0.1463, -0.4017],
         [-0.0898,  0.0021, -0.1114, -0.3003]]])

2025-07-26 05:43:15.057424 GPU 7 133566 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
[accuracy error] paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
Not equal to tolerance rtol=1.5, atol=0.5
The values for attribute 'shape' do not match: torch.Size([57042535, 17, 4]) != torch.Size([57042535, 16, 4]).
ACTUAL: (shape=torch.Size([57042535, 17, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3436, -0.1559,  0.2159,  0.3358],
         [-0.2252, -0.0633,  0.0824,  0.4212],
         ...,
         [ 0.2182,  0.2823,  0.4456, -0.2777],
         [ 0.3442,  0.3910,  0.2681,  0.0530],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.1765, -0.0602, -0.2060, -0.1673],
         [-0.2243, -0.2700, -0.0486, -0.2688],
         ...,
         [ 0.0289,  0.0500,  0.3744,  0.0745],
         [ 0.0507, -0.0639,  0.0359,  0.2543],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [ 0.0321, -0.0751, -0.1650, -0.2553],
         [-0.0957, -0.3004, -0.3298, -0.1509],
         ...,
         [ 0.1756, -0.3575, -0.4287,  0.1329],
         [-0.0340, -0.2290, -0.1714,  0.0577],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.3146, -0.1907,  0.1054,  0.0006],
         [ 0.1659,  0.0606,  0.1022, -0.3240],
         ...,
         [ 0.0096,  0.2879,  0.2633, -0.1950],
         [-0.0896,  0.3012,  0.0060, -0.1450],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2223, -0.3105, -0.2357,  0.1114],
         [-0.2217, -0.4317, -0.0055,  0.4419],
         ...,
         [ 0.3491,  0.2436,  0.0045,  0.0409],
         [ 0.3475,  0.2257, -0.0261, -0.0861],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.2627, -0.1124,  0.3296, -0.3110],
         [ 0.4640, -0.3764,  0.3318, -0.3682],
         ...,
         [ 0.4319, -0.4095, -0.2345, -0.4011],
         [ 0.1341, -0.3056,  0.0596, -0.2143],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])
DESIRED: (shape=torch.Size([57042535, 16, 4]), dtype=torch.float32)
tensor([[[-0.3811, -0.2306,  0.3970,  0.1335],
         [-0.3411, -0.1509,  0.2038,  0.3493],
         [-0.1717, -0.0427,  0.0869,  0.3779],
         ...,
         [ 0.1637,  0.2487,  0.4468, -0.2683],
         [ 0.3412,  0.3865,  0.2832,  0.0233],
         [ 0.3894,  0.4589,  0.0423,  0.4986]],

        [[-0.0554,  0.3178, -0.3829,  0.0006],
         [-0.1845, -0.0854, -0.1942, -0.1785],
         [-0.1965, -0.2194, -0.0368, -0.2514],
         ...,
         [ 0.0048,  0.0643,  0.3325,  0.0491],
         [ 0.0523, -0.0561,  0.0709,  0.2425],
         [ 0.0272, -0.1797, -0.4893,  0.4310]],

        [[ 0.2924,  0.3424,  0.1219, -0.4480],
         [ 0.0147, -0.1029, -0.1841, -0.2425],
         [-0.0509, -0.2407, -0.2949, -0.1782],
         ...,
         [ 0.1434, -0.3001, -0.3867,  0.1572],
         [-0.0115, -0.2482, -0.1994,  0.0607],
         [-0.3726,  0.0593,  0.2492,  0.0131]],

        ...,

        [[ 0.3876, -0.4814,  0.0389,  0.4740],
         [ 0.3097, -0.1714,  0.1098, -0.0309],
         [ 0.1108,  0.0758,  0.0693, -0.2979],
         ...,
         [ 0.0194,  0.2948,  0.2061, -0.2126],
         [-0.0825,  0.2990,  0.0362, -0.1468],
         [-0.1960,  0.3329, -0.4474, -0.1186]],

        [[-0.2377, -0.1305, -0.4587, -0.3049],
         [-0.2212, -0.3224, -0.2208,  0.1391],
         [-0.2286, -0.4205,  0.0286,  0.4460],
         ...,
         [ 0.2923,  0.1838,  0.0144,  0.0720],
         [ 0.3558,  0.2358, -0.0249, -0.0797],
         [ 0.2238,  0.0744, -0.0442, -0.1830]],

        [[-0.0385,  0.2616,  0.2169, -0.2482],
         [ 0.2828, -0.1373,  0.3371, -0.3152],
         [ 0.4442, -0.3604,  0.2805, -0.3731],
         ...,
         [ 0.3932, -0.4084, -0.2365, -0.3692],
         [ 0.1652, -0.3146,  0.0347, -0.2349],
         [-0.3315, -0.1697,  0.4333,  0.0940]]])

2025-07-26 05:54:33.452817 GPU 4 133732 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753480496 (unix time) try "date -d @1753480496" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20a64) received by PID 133732 (TID 0x7f0a59fff740) from PID 133732 ***]


2025-07-26 05:55:01.725468 GPU 4 133934 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753480597 (unix time) try "date -d @1753480597" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20b2e) received by PID 133934 (TID 0x7fcbbaed2740) from PID 133934 ***]


2025-07-26 05:55:02.790372 GPU 3 128066 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753480517 (unix time) try "date -d @1753480517" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f442) received by PID 128066 (TID 0x7fd0cb0c9740) from PID 128066 ***]


2025-07-26 05:55:23.041893 GPU 3 134092 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >::~vector()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753480610 (unix time) try "date -d @1753480610" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20bcc) received by PID 134092 (TID 0x7f68cbd9c740) from PID 134092 ***]


2025-07-26 05:58:23.385160 GPU 3 134426 test begin: paddle.nn.functional.layer_norm(Tensor([19066, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[accuracy error] paddle.nn.functional.layer_norm(Tensor([19066, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 207232 / 4295188480 (0.0%)
Greatest absolute difference: 1.388401985168457 at index (19065, 37, 103) (up to 0.01 allowed)
Greatest relative difference: inf at index (19065, 4, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([19066, 220, 1024]), dtype=torch.float32)
tensor([[[ 2.1409e-01, -9.2510e-04,  3.6642e-01,  ...,  6.6594e-02,  3.9839e-02,  4.5165e-03],
         [ 2.3198e-01, -2.3067e-01,  2.0174e-01,  ...,  1.1855e-01, -5.4461e-01,  8.6021e-03],
         [ 2.7667e-01,  1.8167e-01,  5.2838e-01,  ...,  1.5166e-03, -4.1042e-03, -2.3889e-03],
         ...,
         [ 1.3180e-01,  1.3914e-01,  1.9592e-01,  ..., -2.7621e-03, -2.6237e-01, -1.6925e-03],
         [ 1.2865e-01, -1.5264e-01,  2.6918e-01,  ...,  7.4734e-02, -5.5247e-01,  9.0396e-03],
         [ 2.5106e-01, -6.7323e-01,  3.9590e-01,  ...,  4.2506e-04, -3.0806e-01, -1.9748e-03]],

        [[ 1.6880e-01, -3.8619e-01,  1.9170e-01,  ...,  7.9683e-03, -7.0734e-01,  4.0493e-03],
         [-9.6448e-02, -3.7002e-01,  3.2825e-01,  ...,  1.2136e-01, -4.2140e-02,  1.4249e-03],
         [-5.4368e-02, -7.0210e-01,  5.3285e-01,  ...,  1.7733e-02, -7.6988e-01, -2.0158e-03],
         ...,
         [ 7.0680e-02, -7.2113e-01,  5.4355e-01,  ...,  1.0843e-01, -8.4019e-01, -2.7441e-03],
         [ 4.9199e-02, -3.4448e-01,  2.4705e-01,  ...,  9.3872e-02, -7.2579e-01, -1.6706e-03],
         [ 2.6228e-02, -3.8774e-01, -1.9974e-02,  ...,  1.0734e-01, -4.9070e-01,  3.3254e-03]],

        [[ 1.7947e-01,  1.1627e-02,  1.9424e-02,  ...,  9.2605e-02, -1.3040e-02, -1.5051e-03],
         [ 1.8295e-01, -3.9394e-01,  1.4079e-02,  ...,  3.0839e-03, -1.0083e-02,  6.4852e-03],
         [ 2.3443e-01,  7.4613e-02,  1.8432e-01,  ...,  2.1951e-02, -1.9791e-01,  6.3739e-03],
         ...,
         [ 2.1863e-01,  6.8049e-02,  3.8808e-01,  ...,  1.3779e-01, -6.2850e-01,  9.8253e-03],
         [ 3.4373e-01, -2.7103e-01,  2.7647e-01,  ...,  1.2359e-01, -3.6334e-01,  1.2321e-02],
         [-1.8596e-02, -1.0802e-01,  2.6456e-01,  ...,  4.6127e-02, -1.5939e-01, -2.4202e-03]],

        ...,

        [[ 2.4752e-02, -2.0229e-02,  2.3112e-01,  ...,  7.5095e-02, -8.5938e-02,  7.6813e-03],
         [ 2.3340e-01,  1.2505e-01,  9.3307e-02,  ..., -3.1012e-02, -1.4056e-01,  3.6169e-03],
         [ 1.4643e-01, -4.6946e-02,  5.3330e-01,  ...,  4.2166e-02, -6.9905e-01,  5.8071e-03],
         ...,
         [ 3.6932e-02,  1.8843e-01, -6.4439e-02,  ...,  1.4128e-01, -2.6871e-02,  1.1140e-02],
         [ 3.0408e-01, -4.9282e-01,  4.9450e-01,  ..., -2.2868e-03, -3.6246e-01,  1.0563e-02],
         [-1.0267e-01, -2.6701e-01,  5.9628e-03,  ..., -3.3058e-02, -2.5467e-02, -1.5995e-03]],

        [[-4.4777e-02, -3.9717e-01, -9.5988e-02,  ..., -1.1166e-02,  1.0799e-01, -3.0577e-03],
         [ 1.6329e-01, -3.1042e-01, -6.6365e-02,  ...,  1.1228e-01, -3.2305e-01,  7.6916e-03],
         [ 2.3281e-01, -5.8818e-01,  9.7066e-02,  ...,  6.5867e-02, -1.7233e-01,  1.2791e-03],
         ...,
         [-1.7345e-02, -3.4277e-01,  2.3249e-02,  ..., -1.5281e-03, -8.6774e-02,  1.0286e-02],
         [ 5.2259e-02, -3.1350e-01,  3.1246e-01,  ...,  6.3817e-02, -7.8191e-01,  2.1560e-03],
         [ 2.0258e-01,  2.0679e-01,  3.8227e-01,  ...,  6.1298e-02, -6.3565e-01,  5.1058e-03]],

        [[ 1.1142e-01, -6.9618e-02,  2.7123e-01,  ...,  1.4599e-01, -8.5827e-03, -1.0740e-03],
         [ 3.5895e-02,  4.3971e-02,  1.6023e-01,  ...,  1.2121e-01, -8.0354e-01,  2.3021e-03],
         [ 3.1677e-01, -3.8012e-01,  1.6245e-01,  ...,  7.0935e-02, -3.7109e-01,  1.1562e-02],
         ...,
         [ 5.3329e-02, -3.7948e-01, -1.3592e-01,  ...,  6.9576e-02, -5.2261e-01, -1.6473e-03],
         [ 2.9670e-01, -5.7615e-01,  5.3945e-01,  ...,  8.8753e-03,  2.2759e-01,  1.6925e-03],
         [ 1.9043e-01, -2.6237e-02,  2.0369e-01,  ...,  1.0697e-02, -2.5699e-01, -2.4381e-03]]])
DESIRED: (shape=torch.Size([19066, 220, 1024]), dtype=torch.float32)
tensor([[[ 2.1409e-01, -9.2512e-04,  3.6642e-01,  ...,  6.6594e-02,  3.9839e-02,  4.5165e-03],
         [ 2.3198e-01, -2.3067e-01,  2.0174e-01,  ...,  1.1855e-01, -5.4461e-01,  8.6021e-03],
         [ 2.7667e-01,  1.8167e-01,  5.2838e-01,  ...,  1.5166e-03, -4.1042e-03, -2.3889e-03],
         ...,
         [ 1.3180e-01,  1.3914e-01,  1.9592e-01,  ..., -2.7621e-03, -2.6237e-01, -1.6925e-03],
         [ 1.2865e-01, -1.5264e-01,  2.6918e-01,  ...,  7.4734e-02, -5.5247e-01,  9.0396e-03],
         [ 2.5106e-01, -6.7323e-01,  3.9590e-01,  ...,  4.2506e-04, -3.0806e-01, -1.9748e-03]],

        [[ 1.6880e-01, -3.8619e-01,  1.9170e-01,  ...,  7.9683e-03, -7.0734e-01,  4.0493e-03],
         [-9.6448e-02, -3.7002e-01,  3.2825e-01,  ...,  1.2136e-01, -4.2140e-02,  1.4249e-03],
         [-5.4368e-02, -7.0210e-01,  5.3285e-01,  ...,  1.7733e-02, -7.6988e-01, -2.0158e-03],
         ...,
         [ 7.0680e-02, -7.2113e-01,  5.4355e-01,  ...,  1.0843e-01, -8.4019e-01, -2.7441e-03],
         [ 4.9199e-02, -3.4448e-01,  2.4705e-01,  ...,  9.3872e-02, -7.2579e-01, -1.6706e-03],
         [ 2.6228e-02, -3.8774e-01, -1.9974e-02,  ...,  1.0734e-01, -4.9070e-01,  3.3254e-03]],

        [[ 1.7947e-01,  1.1627e-02,  1.9424e-02,  ...,  9.2605e-02, -1.3040e-02, -1.5051e-03],
         [ 1.8295e-01, -3.9394e-01,  1.4079e-02,  ...,  3.0839e-03, -1.0083e-02,  6.4852e-03],
         [ 2.3443e-01,  7.4613e-02,  1.8432e-01,  ...,  2.1951e-02, -1.9791e-01,  6.3739e-03],
         ...,
         [ 2.1863e-01,  6.8049e-02,  3.8808e-01,  ...,  1.3779e-01, -6.2850e-01,  9.8253e-03],
         [ 3.4373e-01, -2.7103e-01,  2.7647e-01,  ...,  1.2359e-01, -3.6334e-01,  1.2321e-02],
         [-1.8596e-02, -1.0802e-01,  2.6456e-01,  ...,  4.6127e-02, -1.5939e-01, -2.4202e-03]],

        ...,

        [[ 2.4752e-02, -2.0229e-02,  2.3112e-01,  ...,  7.5095e-02, -8.5938e-02,  7.6813e-03],
         [ 2.3340e-01,  1.2505e-01,  9.3307e-02,  ..., -3.1012e-02, -1.4056e-01,  3.6169e-03],
         [ 1.4643e-01, -4.6946e-02,  5.3330e-01,  ...,  4.2166e-02, -6.9905e-01,  5.8071e-03],
         ...,
         [ 3.6932e-02,  1.8843e-01, -6.4439e-02,  ...,  1.4128e-01, -2.6871e-02,  1.1140e-02],
         [ 3.0408e-01, -4.9282e-01,  4.9450e-01,  ..., -2.2868e-03, -3.6246e-01,  1.0563e-02],
         [-1.0267e-01, -2.6701e-01,  5.9628e-03,  ..., -3.3058e-02, -2.5467e-02, -1.5995e-03]],

        [[-4.4777e-02, -3.9717e-01, -9.5988e-02,  ..., -1.1166e-02,  1.0799e-01, -3.0577e-03],
         [ 1.6329e-01, -3.1042e-01, -6.6365e-02,  ...,  1.1228e-01, -3.2305e-01,  7.6916e-03],
         [ 2.3281e-01, -5.8818e-01,  9.7066e-02,  ...,  6.5867e-02, -1.7233e-01,  1.2791e-03],
         ...,
         [-1.7345e-02, -3.4277e-01,  2.3249e-02,  ..., -1.5281e-03, -8.6774e-02,  1.0286e-02],
         [ 5.2259e-02, -3.1350e-01,  3.1246e-01,  ...,  6.3817e-02, -7.8191e-01,  2.1560e-03],
         [ 2.0258e-01,  2.0679e-01,  3.8227e-01,  ...,  6.1298e-02, -6.3565e-01,  5.1058e-03]],

        [[ 1.1142e-01, -6.9618e-02,  2.7123e-01,  ...,  1.4599e-01, -8.5827e-03, -1.0740e-03],
         [ 3.5895e-02,  4.3971e-02,  1.6023e-01,  ...,  1.2121e-01, -8.0354e-01,  2.3021e-03],
         [ 3.1677e-01, -3.8012e-01,  1.6245e-01,  ...,  7.0935e-02, -3.7109e-01,  1.1562e-02],
         ...,
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])

2025-07-26 05:58:24.952912 GPU 2 134746 test begin: paddle.nn.functional.layer_norm(Tensor([20069, 209, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[accuracy error] paddle.nn.functional.layer_norm(Tensor([20069, 209, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 112974 / 4295087104 (0.0%)
Greatest absolute difference: 1.387761116027832 at index (20068, 141, 307) (up to 0.01 allowed)
Greatest relative difference: inf at index (20068, 92, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([20069, 209, 1024]), dtype=torch.float32)
tensor([[[-0.0393,  0.7725,  0.1010,  ...,  0.6780,  0.0224,  0.2091],
         [-0.2288,  0.8341, -0.6283,  ...,  0.3420, -0.3932, -0.0797],
         [-0.4297,  0.2121,  0.2468,  ...,  0.7215, -0.1539,  0.1075],
         ...,
         [-0.1697,  0.3890,  0.1006,  ..., -0.1765,  0.1799, -0.0250],
         [-0.5142, -0.0667, -0.4714,  ...,  0.8350, -0.5963,  0.3695],
         [-0.0122,  0.2301, -0.9033,  ..., -0.2359, -0.5289, -0.0880]],

        [[-0.2291,  0.2895, -0.1053,  ...,  0.2855, -0.7421, -0.0433],
         [-0.1240, -0.2001, -0.4819,  ..., -0.1469, -0.6213,  0.2371],
         [-0.5774,  0.6089, -0.3752,  ...,  0.1599, -0.2210,  0.0124],
         ...,
         [ 0.0210,  0.7227,  0.0499,  ...,  0.5355, -0.5102, -0.0782],
         [ 0.0466,  0.3264, -1.0163,  ..., -0.0065, -0.4423,  0.0587],
         [-0.2687,  0.1940, -0.1167,  ...,  0.5269, -0.7834,  0.3886]],

        [[-0.6500,  0.3628,  0.1823,  ...,  0.0913, -0.0014,  0.3488],
         [-0.3277, -0.2020, -0.9014,  ...,  0.1305, -0.3076,  0.1967],
         [-0.2434,  0.6025, -0.9600,  ...,  0.6682,  0.1000,  0.2722],
         ...,
         [-0.2135,  0.3341, -0.8280,  ...,  0.8033, -0.4924, -0.0218],
         [ 0.0482,  0.1222, -0.6910,  ..., -0.0780, -0.8153,  0.2074],
         [-0.5772, -0.1533, -0.1133,  ...,  0.4926,  0.1200, -0.0043]],

        ...,

        [[-0.0332,  0.0113, -0.2673,  ...,  0.5110, -0.2408,  0.0898],
         [ 0.0113, -0.0740, -0.4687,  ...,  0.0674, -0.7992,  0.1737],
         [ 0.1473,  0.6438,  0.0257,  ..., -0.1987, -0.4656,  0.1577],
         ...,
         [-0.5952,  0.3742, -0.1195,  ..., -0.1171, -0.1735,  0.3491],
         [-0.5160,  0.2421, -0.3265,  ...,  0.7449,  0.1418,  0.1226],
         [-0.0118,  0.4337, -0.9473,  ..., -0.1601, -0.0177,  0.1998]],

        [[-0.1513, -0.2274,  0.2587,  ...,  0.1775, -0.0166,  0.2910],
         [-0.1626, -0.1830, -0.2504,  ...,  0.3358,  0.0556,  0.2168],
         [-0.5711, -0.1975, -0.7219,  ...,  0.5818, -0.8281,  0.3701],
         ...,
         [-0.3623, -0.0332, -0.2855,  ...,  0.5815, -0.6295,  0.2569],
         [-0.5279,  0.4476, -0.8876,  ...,  0.5410, -0.3114,  0.2919],
         [ 0.0198,  0.5026, -0.9280,  ...,  0.6137, -0.2809,  0.2535]],

        [[-0.5762,  0.3666, -0.9367,  ...,  0.5168, -0.5831,  0.1595],
         [ 0.0901,  0.9411,  0.1594,  ...,  0.1796, -0.3210,  0.3235],
         [-0.5451, -0.1494, -0.8328,  ..., -0.0839, -0.3537,  0.0503],
         ...,
         [ 0.0397,  0.2393, -0.9275,  ...,  0.0082, -0.1830,  0.0220],
         [-0.1629,  0.4980, -0.0446,  ...,  0.6119, -0.6753, -0.0282],
         [-0.4821,  0.3007, -0.5921,  ...,  0.7775, -0.0727, -0.0780]]])
DESIRED: (shape=torch.Size([20069, 209, 1024]), dtype=torch.float32)
tensor([[[-0.0393,  0.7725,  0.1010,  ...,  0.6780,  0.0224,  0.2091],
         [-0.2288,  0.8341, -0.6283,  ...,  0.3420, -0.3932, -0.0797],
         [-0.4297,  0.2121,  0.2468,  ...,  0.7215, -0.1539,  0.1075],
         ...,
         [-0.1697,  0.3890,  0.1006,  ..., -0.1765,  0.1799, -0.0250],
         [-0.5142, -0.0667, -0.4714,  ...,  0.8350, -0.5963,  0.3695],
         [-0.0122,  0.2301, -0.9033,  ..., -0.2359, -0.5289, -0.0880]],

        [[-0.2291,  0.2895, -0.1053,  ...,  0.2855, -0.7421, -0.0433],
         [-0.1240, -0.2001, -0.4819,  ..., -0.1469, -0.6213,  0.2371],
         [-0.5774,  0.6089, -0.3752,  ...,  0.1599, -0.2210,  0.0124],
         ...,
         [ 0.0210,  0.7227,  0.0499,  ...,  0.5355, -0.5102, -0.0782],
         [ 0.0466,  0.3264, -1.0163,  ..., -0.0065, -0.4423,  0.0587],
         [-0.2687,  0.1940, -0.1167,  ...,  0.5269, -0.7834,  0.3886]],

        [[-0.6500,  0.3628,  0.1823,  ...,  0.0913, -0.0014,  0.3488],
         [-0.3277, -0.2020, -0.9014,  ...,  0.1305, -0.3076,  0.1967],
         [-0.2434,  0.6025, -0.9600,  ...,  0.6682,  0.1000,  0.2722],
         ...,
         [-0.2135,  0.3341, -0.8280,  ...,  0.8033, -0.4924, -0.0218],
         [ 0.0482,  0.1222, -0.6910,  ..., -0.0780, -0.8153,  0.2074],
         [-0.5772, -0.1533, -0.1133,  ...,  0.4926,  0.1200, -0.0043]],

        ...,

        [[-0.0332,  0.0113, -0.2673,  ...,  0.5110, -0.2408,  0.0898],
         [ 0.0113, -0.0740, -0.4687,  ...,  0.0674, -0.7992,  0.1737],
         [ 0.1473,  0.6438,  0.0257,  ..., -0.1987, -0.4656,  0.1577],
         ...,
         [-0.5952,  0.3742, -0.1195,  ..., -0.1171, -0.1735,  0.3491],
         [-0.5160,  0.2421, -0.3265,  ...,  0.7449,  0.1418,  0.1226],
         [-0.0118,  0.4337, -0.9473,  ..., -0.1601, -0.0177,  0.1998]],

        [[-0.1513, -0.2274,  0.2587,  ...,  0.1775, -0.0166,  0.2910],
         [-0.1626, -0.1830, -0.2504,  ...,  0.3358,  0.0556,  0.2168],
         [-0.5711, -0.1975, -0.7219,  ...,  0.5818, -0.8281,  0.3701],
         ...,
         [-0.3623, -0.0332, -0.2855,  ...,  0.5815, -0.6295,  0.2569],
         [-0.5279,  0.4476, -0.8876,  ...,  0.5410, -0.3114,  0.2919],
         [ 0.0198,  0.5026, -0.9280,  ...,  0.6137, -0.2809,  0.2535]],

        [[-0.5762,  0.3666, -0.9367,  ...,  0.5168, -0.5831,  0.1595],
         [ 0.0901,  0.9411,  0.1594,  ...,  0.1796, -0.3210,  0.3235],
         [-0.5451, -0.1494, -0.8328,  ..., -0.0839, -0.3537,  0.0503],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])

2025-07-26 05:58:25.053028 GPU 7 134810 test begin: paddle.nn.functional.layer_norm(Tensor([20361, 206, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[accuracy error] paddle.nn.functional.layer_norm(Tensor([20361, 206, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 58722 / 4295030784 (0.0%)
Greatest absolute difference: 1.3749668598175049 at index (20360, 196, 214) (up to 0.01 allowed)
Greatest relative difference: inf at index (20360, 144, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([20361, 206, 1024]), dtype=torch.float32)
tensor([[[ 0.0884,  0.1061,  0.0430,  ..., -0.0595,  0.0485,  0.2952],
         [ 0.0811,  0.1610,  0.2226,  ..., -0.0286, -0.8692, -0.1040],
         [ 0.0437, -0.0204, -0.5492,  ..., -0.0401, -0.8023, -0.0369],
         ...,
         [-0.0442,  0.0122, -0.8388,  ..., -0.3118, -0.3441, -1.2928],
         [ 0.0105,  0.0199, -0.0202,  ..., -0.4002, -0.6907, -0.8488],
         [-0.0399,  0.1414,  0.1185,  ...,  0.0037, -0.0683, -0.6776]],

        [[ 0.0488, -0.0506, -0.8035,  ...,  0.0648, -0.2091, -0.5185],
         [ 0.1856,  0.1997, -0.1150,  ..., -0.1165, -0.4604, -1.1785],
         [ 0.0730, -0.0160, -0.8400,  ..., -0.3325,  0.1443, -0.7391],
         ...,
         [ 0.0426,  0.2103, -0.3816,  ..., -0.6041, -0.3978, -0.5403],
         [ 0.0496,  0.0610,  0.0322,  ..., -0.0115, -0.8357, -0.4249],
         [ 0.0096,  0.0849, -0.4515,  ..., -0.0262, -0.1256,  0.2356]],

        [[ 0.0247,  0.0648, -0.3491,  ..., -0.0379, -0.1424, -0.9093],
         [ 0.0242,  0.0711, -0.7224,  ..., -0.2896, -0.3348, -0.1711],
         [ 0.1080,  0.1521, -0.3856,  ...,  0.1432, -0.7101, -0.2149],
         ...,
         [ 0.0366,  0.1914,  0.0709,  ..., -0.0106,  0.1798,  0.3260],
         [ 0.0427,  0.0318, -0.3390,  ...,  0.1479, -0.3083,  0.2322],
         [-0.0246,  0.0276,  0.0756,  ..., -0.3655, -0.7402, -0.2862]],

        ...,

        [[ 0.1336, -0.0101, -0.5720,  ..., -0.0039, -0.7387,  0.1178],
         [-0.0144,  0.2078,  0.1028,  ..., -0.0720, -0.5034, -0.6613],
         [ 0.0022,  0.0378,  0.0220,  ..., -0.2541, -0.5071, -1.1877],
         ...,
         [ 0.1086,  0.0829, -0.5451,  ...,  0.0221, -0.1651, -1.2699],
         [ 0.1336,  0.1483, -0.1378,  ..., -0.6047, -0.7569, -0.4357],
         [ 0.1629, -0.0130, -0.8144,  ..., -0.2093, -0.8709, -0.5644]],

        [[ 0.1547,  0.1208, -0.6677,  ..., -0.2383, -0.8666, -0.3570],
         [ 0.1186, -0.0292, -0.5089,  ..., -0.1091,  0.1618, -1.1718],
         [ 0.1333,  0.0906, -0.3049,  ..., -0.4358, -0.1388, -0.9224],
         ...,
         [ 0.1607,  0.0629, -0.7808,  ...,  0.0886, -0.7459,  0.0981],
         [-0.0116,  0.0053, -0.0165,  ...,  0.1147, -0.0764, -1.2861],
         [ 0.0783,  0.0173,  0.0018,  ..., -0.2900, -0.7307, -0.5779]],

        [[ 0.1505,  0.0816, -0.6868,  ..., -0.4593, -0.4029, -0.4239],
         [-0.0412,  0.0030,  0.1544,  ..., -0.0241, -0.8858, -1.1182],
         [-0.0239,  0.0926, -0.2461,  ...,  0.0128, -0.8842, -0.0418],
         ...,
         [ 0.0405, -0.0504,  0.1135,  ..., -0.5603, -0.4243, -0.1170],
         [-0.0304, -0.0066, -0.3036,  ..., -0.2348, -0.3596,  0.0597],
         [ 0.1920,  0.1312, -0.3554,  ...,  0.0310,  0.0848,  0.2310]]])
DESIRED: (shape=torch.Size([20361, 206, 1024]), dtype=torch.float32)
tensor([[[ 0.0884,  0.1061,  0.0430,  ..., -0.0595,  0.0485,  0.2952],
         [ 0.0811,  0.1610,  0.2226,  ..., -0.0286, -0.8692, -0.1040],
         [ 0.0437, -0.0204, -0.5492,  ..., -0.0401, -0.8023, -0.0369],
         ...,
         [-0.0442,  0.0122, -0.8388,  ..., -0.3118, -0.3441, -1.2928],
         [ 0.0105,  0.0199, -0.0202,  ..., -0.4002, -0.6907, -0.8488],
         [-0.0399,  0.1414,  0.1185,  ...,  0.0037, -0.0683, -0.6776]],

        [[ 0.0488, -0.0506, -0.8035,  ...,  0.0648, -0.2091, -0.5185],
         [ 0.1856,  0.1997, -0.1150,  ..., -0.1165, -0.4604, -1.1785],
         [ 0.0730, -0.0160, -0.8400,  ..., -0.3325,  0.1443, -0.7391],
         ...,
         [ 0.0426,  0.2103, -0.3816,  ..., -0.6041, -0.3978, -0.5403],
         [ 0.0496,  0.0610,  0.0322,  ..., -0.0115, -0.8357, -0.4249],
         [ 0.0096,  0.0849, -0.4515,  ..., -0.0262, -0.1256,  0.2356]],

        [[ 0.0247,  0.0648, -0.3491,  ..., -0.0379, -0.1424, -0.9093],
         [ 0.0242,  0.0711, -0.7224,  ..., -0.2896, -0.3348, -0.1711],
         [ 0.1080,  0.1521, -0.3856,  ...,  0.1432, -0.7101, -0.2149],
         ...,
         [ 0.0366,  0.1914,  0.0709,  ..., -0.0106,  0.1798,  0.3260],
         [ 0.0427,  0.0318, -0.3390,  ...,  0.1479, -0.3083,  0.2322],
         [-0.0246,  0.0276,  0.0756,  ..., -0.3655, -0.7402, -0.2862]],

        ...,

        [[ 0.1336, -0.0101, -0.5720,  ..., -0.0039, -0.7387,  0.1178],
         [-0.0144,  0.2078,  0.1028,  ..., -0.0720, -0.5034, -0.6613],
         [ 0.0022,  0.0378,  0.0220,  ..., -0.2541, -0.5071, -1.1877],
         ...,
         [ 0.1086,  0.0829, -0.5451,  ...,  0.0221, -0.1651, -1.2699],
         [ 0.1336,  0.1483, -0.1378,  ..., -0.6047, -0.7569, -0.4357],
         [ 0.1629, -0.0130, -0.8144,  ..., -0.2093, -0.8709, -0.5644]],

        [[ 0.1547,  0.1208, -0.6677,  ..., -0.2383, -0.8666, -0.3570],
         [ 0.1186, -0.0292, -0.5089,  ..., -0.1091,  0.1618, -1.1718],
         [ 0.1333,  0.0906, -0.3049,  ..., -0.4358, -0.1388, -0.9224],
         ...,
         [ 0.1607,  0.0629, -0.7808,  ...,  0.0886, -0.7459,  0.0981],
         [-0.0116,  0.0053, -0.0165,  ...,  0.1147, -0.0764, -1.2861],
         [ 0.0783,  0.0173,  0.0018,  ..., -0.2900, -0.7307, -0.5779]],

        [[ 0.1505,  0.0816, -0.6868,  ..., -0.4593, -0.4029, -0.4239],
         [-0.0412,  0.0030,  0.1544,  ..., -0.0241, -0.8858, -1.1182],
         [-0.0239,  0.0926, -0.2461,  ...,  0.0128, -0.8842, -0.0418],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])

2025-07-26 05:58:26.104948 GPU 1 133406 test begin: paddle.nn.functional.layer_norm(Tensor([22551, 186, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[accuracy error] paddle.nn.functional.layer_norm(Tensor([22551, 186, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 176076 / 4295153664 (0.0%)
Greatest absolute difference: 1.39495849609375 at index (22550, 72, 866) (up to 0.01 allowed)
Greatest relative difference: inf at index (22550, 4, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([22551, 186, 1024]), dtype=torch.float32)
tensor([[[-5.9662e-02,  1.2921e+00,  2.2754e-01,  ...,  7.7586e-01,  8.8266e-01, -3.1521e-02],
         [ 6.0594e-02,  4.1805e-01, -8.1531e-02,  ...,  5.3491e-01, -1.2472e-01, -4.3767e-01],
         [ 4.4721e-02, -1.8722e-01,  9.5727e-02,  ...,  9.0889e-01,  1.5765e-02, -3.6752e-01],
         ...,
         [-8.8328e-02, -2.4927e-01,  6.4159e-02,  ...,  5.2474e-01,  2.6813e-01, -2.6903e-02],
         [-1.1254e-01,  2.5265e-01,  5.4105e-02,  ...,  6.9172e-01,  7.0633e-01, -3.0402e-01],
         [-8.3238e-02, -2.2831e-01,  1.7592e-01,  ..., -1.3484e-01,  7.2795e-01,  2.7337e-02]],

        [[ 2.8282e-02,  1.1873e+00,  3.8509e-01,  ...,  8.7306e-01, -8.8736e-02, -3.2255e-01],
         [-1.7866e-02, -1.1698e-01, -5.4276e-02,  ...,  1.8829e-01,  4.4115e-01, -2.2069e-01],
         [ 4.4100e-03,  8.1957e-01,  1.1815e-01,  ...,  2.6869e-01, -9.8010e-02,  1.4734e-01],
         ...,
         [-2.3706e-01,  7.0619e-01,  2.9083e-02,  ...,  6.2481e-01,  7.0881e-01, -4.2764e-01],
         [-3.4846e-02,  7.3051e-01,  9.0244e-02,  ...,  3.9699e-01,  1.0117e+00, -2.6694e-01],
         [ 2.5694e-03,  3.5902e-01,  4.0830e-01,  ...,  1.7585e-01, -2.0479e-01, -2.9214e-01]],

        [[ 6.2233e-02, -3.4840e-02,  3.9128e-02,  ..., -1.8571e-01,  9.5256e-02,  3.8206e-02],
         [-9.4715e-02,  3.1941e-01,  6.7447e-02,  ...,  6.4553e-01, -1.4377e-01, -5.3439e-01],
         [-1.9145e-01,  9.6047e-01,  1.9726e-01,  ..., -1.1251e-01,  6.1569e-01, -6.2482e-01],
         ...,
         [-1.0630e-01, -2.4199e-01,  1.2852e-01,  ..., -1.9160e-01, -1.1712e-01, -3.8878e-01],
         [-9.6819e-02,  4.9952e-01,  1.0748e-01,  ..., -7.1502e-03, -1.5272e-01, -1.2094e-01],
         [-2.0534e-01,  8.2025e-02, -6.6462e-02,  ...,  7.1844e-01,  9.9331e-01, -5.7789e-01]],

        ...,

        [[-2.3254e-01,  5.6095e-01,  8.7766e-02,  ...,  3.4179e-01, -5.6313e-02, -4.6195e-01],
         [-1.4447e-01,  4.9524e-01,  3.3821e-01,  ...,  8.2762e-02,  3.8555e-01, -1.8845e-01],
         [-1.5224e-02,  1.2689e+00, -3.3569e-02,  ...,  5.7692e-02,  6.2613e-01, -5.3373e-01],
         ...,
         [ 2.4216e-02,  8.9731e-01,  2.0646e-01,  ...,  8.3763e-01, -1.0634e-03,  1.5532e-01],
         [-6.3039e-02,  1.3066e+00,  3.2627e-01,  ...,  9.2590e-01, -8.7104e-02,  1.2535e-01],
         [ 3.4412e-03,  1.2053e+00,  2.9046e-01,  ...,  7.3020e-01,  5.0532e-01,  6.4673e-02]],

        [[-1.0603e-01,  1.1357e+00,  2.9676e-01,  ...,  6.3042e-01,  1.5644e-01,  6.0202e-02],
         [-2.3421e-01,  6.6630e-02,  1.6756e-01,  ..., -2.2832e-01,  3.3201e-02, -2.9429e-01],
         [-4.5672e-02,  4.9336e-01,  1.4497e-01,  ...,  4.4363e-01, -4.7736e-02,  4.8896e-02],
         ...,
         [-2.3216e-02,  4.0846e-02, -6.1113e-02,  ...,  6.0985e-01,  2.6156e-01,  1.6556e-01],
         [-2.4001e-01,  1.2845e+00,  1.2775e-02,  ..., -1.6570e-01,  4.9275e-01, -4.8080e-01],
         [-8.6142e-02,  3.7796e-01,  3.5223e-01,  ..., -1.3577e-02, -9.3009e-02,  5.5099e-02]],

        [[-2.7299e-02,  1.1303e+00,  8.8136e-02,  ...,  3.6549e-01,  7.3173e-02, -3.9749e-02],
         [ 1.2419e-02,  9.4394e-01,  2.4904e-01,  ...,  1.2273e-01,  1.3508e-01, -2.2752e-01],
         [-2.2820e-01, -2.0172e-01, -6.5188e-02,  ...,  5.3289e-01,  2.7888e-01, -5.8117e-03],
         ...,
         [ 1.4318e-03, -3.8373e-01,  3.7716e-01,  ...,  5.2151e-01,  4.2964e-01, -1.0774e-01],
         [-3.7342e-03,  1.3365e+00, -9.9649e-02,  ...,  1.3695e-01,  3.8992e-02,  1.0681e-01],
         [-1.1437e-01, -4.4666e-02,  3.1201e-01,  ..., -1.4435e-01,  4.2163e-01, -6.2091e-01]]])
DESIRED: (shape=torch.Size([22551, 186, 1024]), dtype=torch.float32)
tensor([[[-5.9662e-02,  1.2921e+00,  2.2754e-01,  ...,  7.7586e-01,  8.8266e-01, -3.1521e-02],
         [ 6.0594e-02,  4.1805e-01, -8.1531e-02,  ...,  5.3491e-01, -1.2472e-01, -4.3767e-01],
         [ 4.4721e-02, -1.8722e-01,  9.5727e-02,  ...,  9.0889e-01,  1.5765e-02, -3.6752e-01],
         ...,
         [-8.8328e-02, -2.4927e-01,  6.4159e-02,  ...,  5.2474e-01,  2.6813e-01, -2.6903e-02],
         [-1.1254e-01,  2.5265e-01,  5.4105e-02,  ...,  6.9172e-01,  7.0633e-01, -3.0402e-01],
         [-8.3238e-02, -2.2831e-01,  1.7592e-01,  ..., -1.3484e-01,  7.2795e-01,  2.7337e-02]],

        [[ 2.8282e-02,  1.1873e+00,  3.8509e-01,  ...,  8.7306e-01, -8.8736e-02, -3.2255e-01],
         [-1.7866e-02, -1.1698e-01, -5.4276e-02,  ...,  1.8829e-01,  4.4115e-01, -2.2069e-01],
         [ 4.4100e-03,  8.1957e-01,  1.1815e-01,  ...,  2.6869e-01, -9.8010e-02,  1.4734e-01],
         ...,
         [-2.3706e-01,  7.0619e-01,  2.9083e-02,  ...,  6.2481e-01,  7.0881e-01, -4.2764e-01],
         [-3.4846e-02,  7.3051e-01,  9.0244e-02,  ...,  3.9699e-01,  1.0117e+00, -2.6694e-01],
         [ 2.5694e-03,  3.5902e-01,  4.0830e-01,  ...,  1.7585e-01, -2.0479e-01, -2.9214e-01]],

        [[ 6.2233e-02, -3.4840e-02,  3.9128e-02,  ..., -1.8571e-01,  9.5256e-02,  3.8206e-02],
         [-9.4715e-02,  3.1941e-01,  6.7447e-02,  ...,  6.4553e-01, -1.4377e-01, -5.3439e-01],
         [-1.9145e-01,  9.6047e-01,  1.9726e-01,  ..., -1.1251e-01,  6.1569e-01, -6.2482e-01],
         ...,
         [-1.0630e-01, -2.4199e-01,  1.2852e-01,  ..., -1.9160e-01, -1.1712e-01, -3.8878e-01],
         [-9.6819e-02,  4.9952e-01,  1.0748e-01,  ..., -7.1502e-03, -1.5272e-01, -1.2094e-01],
         [-2.0534e-01,  8.2025e-02, -6.6462e-02,  ...,  7.1844e-01,  9.9331e-01, -5.7789e-01]],

        ...,

        [[-2.3254e-01,  5.6095e-01,  8.7766e-02,  ...,  3.4179e-01, -5.6313e-02, -4.6195e-01],
         [-1.4447e-01,  4.9524e-01,  3.3821e-01,  ...,  8.2762e-02,  3.8555e-01, -1.8845e-01],
         [-1.5224e-02,  1.2689e+00, -3.3569e-02,  ...,  5.7692e-02,  6.2613e-01, -5.3373e-01],
         ...,
         [ 2.4216e-02,  8.9731e-01,  2.0646e-01,  ...,  8.3763e-01, -1.0634e-03,  1.5532e-01],
         [-6.3039e-02,  1.3066e+00,  3.2627e-01,  ...,  9.2590e-01, -8.7104e-02,  1.2535e-01],
         [ 3.4412e-03,  1.2053e+00,  2.9046e-01,  ...,  7.3020e-01,  5.0532e-01,  6.4673e-02]],

        [[-1.0603e-01,  1.1357e+00,  2.9676e-01,  ...,  6.3042e-01,  1.5644e-01,  6.0202e-02],
         [-2.3421e-01,  6.6630e-02,  1.6756e-01,  ..., -2.2832e-01,  3.3201e-02, -2.9429e-01],
         [-4.5672e-02,  4.9336e-01,  1.4497e-01,  ...,  4.4363e-01, -4.7736e-02,  4.8896e-02],
         ...,
         [-2.3216e-02,  4.0846e-02, -6.1113e-02,  ...,  6.0985e-01,  2.6156e-01,  1.6556e-01],
         [-2.4001e-01,  1.2845e+00,  1.2775e-02,  ..., -1.6570e-01,  4.9275e-01, -4.8080e-01],
         [-8.6142e-02,  3.7796e-01,  3.5223e-01,  ..., -1.3577e-02, -9.3009e-02,  5.5099e-02]],

        [[-2.7299e-02,  1.1303e+00,  8.8136e-02,  ...,  3.6549e-01,  7.3173e-02, -3.9749e-02],
         [ 1.2419e-02,  9.4394e-01,  2.4904e-01,  ...,  1.2273e-01,  1.3508e-01, -2.2752e-01],
         [-2.2820e-01, -2.0172e-01, -6.5188e-02,  ...,  5.3289e-01,  2.7888e-01, -5.8117e-03],
         ...,
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])

2025-07-26 05:59:06.851716 GPU 4 134261 test begin: paddle.nn.functional.layer_norm(Tensor([25421, 165, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[accuracy error] paddle.nn.functional.layer_norm(Tensor([25421, 165, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 154790 / 4295132160 (0.0%)
Greatest absolute difference: 1.3835428953170776 at index (25420, 90, 534) (up to 0.01 allowed)
Greatest relative difference: inf at index (25420, 4, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([25421, 165, 1024]), dtype=torch.float32)
tensor([[[ 0.3343,  0.8408,  0.0566,  ...,  0.1455,  0.1019,  1.0585],
         [-0.8016,  0.5897, -0.3191,  ..., -0.4287, -0.1216,  0.2587],
         [ 0.3378, -0.1956, -0.2985,  ...,  0.2612, -0.0282,  0.6240],
         ...,
         [ 0.0695,  1.0090, -0.4665,  ...,  0.2823, -0.3856,  0.1404],
         [-0.3013,  0.2102, -0.5923,  ...,  0.0451, -0.6517,  0.7574],
         [ 0.0774,  0.6703, -0.3111,  ..., -0.2110, -0.9482,  0.1984]],

        [[ 0.2170,  0.5574, -0.5812,  ..., -0.5974, -0.1868,  0.8409],
         [ 0.3508,  0.5889, -0.1540,  ...,  0.0694,  0.0322, -0.2703],
         [-0.7565,  0.7697, -0.5700,  ...,  0.2023, -0.3563,  0.6546],
         ...,
         [-1.1473,  0.0811, -0.5301,  ..., -0.2534, -0.5663,  0.9025],
         [-0.5224,  0.5932, -0.4623,  ...,  0.1948, -0.0827, -0.0742],
         [ 0.2023,  0.3786,  0.1600,  ..., -0.8865, -0.0186,  1.1784]],

        [[-0.3651,  0.9624, -0.0219,  ..., -1.0104, -0.7745,  0.3502],
         [-0.7487, -0.1453, -0.8402,  ..., -0.9971, -0.9018, -0.1411],
         [-0.4850,  0.6150,  0.0967,  ..., -0.9480, -0.4761,  0.4575],
         ...,
         [-0.2594,  0.1653, -0.5153,  ..., -0.8213, -0.2926,  0.5059],
         [-0.4404,  0.1816, -0.4320,  ...,  0.2141,  0.1584, -0.1190],
         [ 0.0848,  0.7693, -0.0462,  ..., -0.5013, -0.2734,  1.0108]],

        ...,

        [[-1.2851, -0.1918, -0.7588,  ...,  0.0974, -0.1350, -0.1537],
         [ 0.1638,  0.2871, -0.6059,  ..., -0.0591, -0.7310,  0.0434],
         [-1.0943,  0.6743,  0.1199,  ..., -0.3519, -0.8747,  0.5896],
         ...,
         [-0.5154,  0.2957, -0.2893,  ..., -0.1794, -0.4400, -0.1101],
         [-0.5884, -0.2579, -0.1448,  ..., -0.8770, -0.4937,  0.2989],
         [-0.2523,  0.5939, -0.2967,  ..., -0.3276,  0.2254, -0.0270]],

        [[-0.3157, -0.1776, -0.1068,  ..., -0.4313,  0.0127, -0.2479],
         [-0.4985, -0.0835,  0.1300,  ..., -0.8694, -0.3347,  0.9258],
         [-0.5048,  1.0286, -0.2509,  ..., -0.3829,  0.0414,  0.0110],
         ...,
         [ 0.0973,  0.5923, -0.4294,  ..., -0.0966, -0.0295,  0.0528],
         [-1.0392,  0.0987,  0.1069,  ..., -0.0038, -0.4323,  0.0133],
         [-0.3145,  0.0189,  0.0955,  ..., -0.2676, -0.0308, -0.2506]],

        [[-1.2159,  0.2490, -0.3293,  ...,  0.1016, -0.6313,  0.4323],
         [-1.1054,  0.5700, -0.0263,  ..., -0.8288, -0.1988,  0.2262],
         [-1.2992,  0.0252, -0.0988,  ..., -0.7936, -0.5612,  0.8677],
         ...,
         [-0.0106, -0.1508, -0.0329,  ..., -0.9384, -0.4705, -0.0083],
         [-0.3729, -0.2324, -0.7069,  ..., -0.4945, -0.5811, -0.2185],
         [-0.8248, -0.0749, -0.0998,  ...,  0.2642,  0.1797,  0.3579]]])
DESIRED: (shape=torch.Size([25421, 165, 1024]), dtype=torch.float32)
tensor([[[ 0.3343,  0.8408,  0.0566,  ...,  0.1455,  0.1019,  1.0585],
         [-0.8016,  0.5897, -0.3191,  ..., -0.4287, -0.1216,  0.2587],
         [ 0.3378, -0.1956, -0.2985,  ...,  0.2612, -0.0282,  0.6240],
         ...,
         [ 0.0695,  1.0090, -0.4665,  ...,  0.2823, -0.3856,  0.1404],
         [-0.3013,  0.2102, -0.5923,  ...,  0.0451, -0.6517,  0.7574],
         [ 0.0774,  0.6703, -0.3111,  ..., -0.2110, -0.9482,  0.1984]],

        [[ 0.2170,  0.5574, -0.5812,  ..., -0.5974, -0.1868,  0.8409],
         [ 0.3508,  0.5889, -0.1540,  ...,  0.0694,  0.0322, -0.2703],
         [-0.7565,  0.7697, -0.5700,  ...,  0.2023, -0.3563,  0.6546],
         ...,
         [-1.1473,  0.0811, -0.5301,  ..., -0.2534, -0.5663,  0.9025],
         [-0.5224,  0.5932, -0.4623,  ...,  0.1948, -0.0827, -0.0742],
         [ 0.2023,  0.3786,  0.1600,  ..., -0.8865, -0.0186,  1.1784]],

        [[-0.3651,  0.9624, -0.0219,  ..., -1.0104, -0.7745,  0.3502],
         [-0.7487, -0.1453, -0.8402,  ..., -0.9971, -0.9018, -0.1411],
         [-0.4850,  0.6150,  0.0967,  ..., -0.9480, -0.4761,  0.4575],
         ...,
         [-0.2594,  0.1653, -0.5153,  ..., -0.8213, -0.2926,  0.5059],
         [-0.4404,  0.1816, -0.4320,  ...,  0.2141,  0.1584, -0.1190],
         [ 0.0848,  0.7693, -0.0462,  ..., -0.5013, -0.2734,  1.0108]],

        ...,

        [[-1.2851, -0.1918, -0.7588,  ...,  0.0974, -0.1350, -0.1537],
         [ 0.1638,  0.2871, -0.6059,  ..., -0.0591, -0.7310,  0.0434],
         [-1.0943,  0.6743,  0.1199,  ..., -0.3519, -0.8747,  0.5896],
         ...,
         [-0.5154,  0.2957, -0.2893,  ..., -0.1794, -0.4400, -0.1101],
         [-0.5884, -0.2579, -0.1448,  ..., -0.8770, -0.4937,  0.2989],
         [-0.2523,  0.5939, -0.2967,  ..., -0.3276,  0.2254, -0.0270]],

        [[-0.3157, -0.1776, -0.1068,  ..., -0.4313,  0.0127, -0.2479],
         [-0.4985, -0.0835,  0.1300,  ..., -0.8694, -0.3347,  0.9258],
         [-0.5048,  1.0286, -0.2509,  ..., -0.3829,  0.0414,  0.0110],
         ...,
         [ 0.0973,  0.5923, -0.4294,  ..., -0.0966, -0.0295,  0.0528],
         [-1.0392,  0.0987,  0.1069,  ..., -0.0038, -0.4323,  0.0133],
         [-0.3145,  0.0189,  0.0955,  ..., -0.2676, -0.0308, -0.2506]],

        [[-1.2159,  0.2490, -0.3293,  ...,  0.1016, -0.6313,  0.4323],
         [-1.1054,  0.5700, -0.0263,  ..., -0.8288, -0.1988,  0.2262],
         [-1.2992,  0.0252, -0.0988,  ..., -0.7936, -0.5612,  0.8677],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])

2025-07-26 05:59:41.317633 GPU 6 134584 test begin: paddle.nn.functional.layer_norm(Tensor([7, 599187, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[accuracy error] paddle.nn.functional.layer_norm(Tensor([7, 599187, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4774 / 4294972416 (0.0%)
Greatest absolute difference: 1.3729337453842163 at index (6, 599186, 567) (up to 0.01 allowed)
Greatest relative difference: inf at index (6, 599182, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([7, 599187, 1024]), dtype=torch.float32)
tensor([[[ 0.0944,  0.2044, -0.0393,  ...,  0.7143,  0.2848,  0.2958],
         [ 0.1299, -0.3225, -0.1052,  ...,  0.0812, -0.7232, -0.7621],
         [ 0.0185, -0.1503, -0.1197,  ...,  0.3069, -0.7044, -0.9063],
         ...,
         [-0.5093, -0.0716, -0.2040,  ...,  0.4902, -1.2492, -0.0343],
         [-0.9239, -1.0625, -0.1498,  ...,  0.6498, -1.2656, -0.2397],
         [-0.8975, -0.9319, -0.3210,  ...,  0.3290, -0.6333, -0.6974]],

        [[-0.6611, -1.0038, -0.2482,  ..., -0.2403, -0.8267, -0.4103],
         [-0.7238, -0.8247, -0.5641,  ...,  0.4007, -1.2695, -0.9662],
         [-0.8951, -0.2756, -0.3511,  ...,  0.8549, -0.3749, -0.9972],
         ...,
         [ 0.1207, -0.5870, -0.4760,  ...,  0.7621, -0.7811, -0.7913],
         [-0.9403,  0.2333, -0.2319,  ...,  0.2462, -1.2532, -0.1515],
         [-0.0123, -0.9251,  0.0070,  ...,  0.5589, -1.1901,  0.3721]],

        [[-0.0711,  0.3097, -0.2603,  ...,  0.1789, -0.7548, -1.1086],
         [-0.4760, -0.6257, -0.0890,  ...,  0.7149, -0.1067, -1.0402],
         [ 0.0381, -0.9716,  0.0535,  ...,  0.7481, -1.2066,  0.1981],
         ...,
         [-0.1389, -0.0385, -0.5629,  ...,  0.5593, -0.6863, -1.1579],
         [-0.8357, -1.1245, -0.4831,  ..., -0.1892, -0.9252, -0.4061],
         [ 0.0807, -0.4663, -0.4798,  ..., -0.0529,  0.0574, -0.3899]],

        ...,

        [[-0.0572, -0.3326,  0.0365,  ..., -0.1674,  0.3002, -0.7351],
         [-0.0656, -0.1424, -0.2541,  ...,  0.5962,  0.0653, -0.1977],
         [ 0.0160,  0.1282,  0.0813,  ...,  0.8700, -1.2711, -0.4677],
         ...,
         [-0.9097, -0.3149, -0.5844,  ...,  0.8420, -1.1847, -0.9284],
         [-0.6761, -0.9083,  0.1085,  ...,  0.1446, -0.1861, -0.9937],
         [-0.1480, -0.2067, -0.0422,  ...,  0.7388, -1.0872,  0.2044]],

        [[-0.0396, -0.8360, -0.4746,  ...,  0.4165,  0.0536, -1.2347],
         [-0.3443, -1.0743, -0.1450,  ...,  0.0390, -0.9386, -1.0569],
         [ 0.1385, -0.7904, -0.0642,  ..., -0.1249, -1.1416, -0.2409],
         ...,
         [-0.0186, -0.1903,  0.1176,  ...,  0.3688, -0.3286, -0.9875],
         [-0.5782, -0.7144, -0.6296,  ...,  0.0074, -0.7946, -1.1536],
         [ 0.1591, -0.5763,  0.1482,  ...,  0.4657, -1.1051, -1.1050]],

        [[-0.6747, -0.3833, -0.2250,  ...,  0.2895, -0.6881,  0.2088],
         [-0.3797, -0.8479,  0.0370,  ...,  0.4683, -0.3536, -1.0708],
         [ 0.0162, -0.6676,  0.1178,  ..., -0.1911, -0.3828,  0.1630],
         ...,
         [ 0.0226, -1.1004, -0.2297,  ..., -0.1561, -0.9931,  0.1525],
         [-0.7219, -0.0641, -0.2068,  ...,  0.0902, -0.9307, -0.8642],
         [-0.0994, -0.0596, -0.3444,  ...,  0.5938, -1.0161, -1.1405]]])
DESIRED: (shape=torch.Size([7, 599187, 1024]), dtype=torch.float32)
tensor([[[ 0.0944,  0.2044, -0.0393,  ...,  0.7143,  0.2848,  0.2958],
         [ 0.1299, -0.3225, -0.1052,  ...,  0.0812, -0.7232, -0.7621],
         [ 0.0185, -0.1503, -0.1197,  ...,  0.3069, -0.7044, -0.9063],
         ...,
         [-0.5093, -0.0716, -0.2040,  ...,  0.4902, -1.2492, -0.0343],
         [-0.9239, -1.0625, -0.1498,  ...,  0.6498, -1.2656, -0.2397],
         [-0.8975, -0.9319, -0.3210,  ...,  0.3290, -0.6333, -0.6974]],

        [[-0.6611, -1.0038, -0.2482,  ..., -0.2403, -0.8267, -0.4103],
         [-0.7238, -0.8247, -0.5641,  ...,  0.4007, -1.2695, -0.9662],
         [-0.8951, -0.2756, -0.3511,  ...,  0.8549, -0.3749, -0.9972],
         ...,
         [ 0.1207, -0.5870, -0.4760,  ...,  0.7621, -0.7811, -0.7913],
         [-0.9403,  0.2333, -0.2319,  ...,  0.2462, -1.2532, -0.1515],
         [-0.0123, -0.9251,  0.0070,  ...,  0.5589, -1.1901,  0.3721]],

        [[-0.0711,  0.3097, -0.2603,  ...,  0.1789, -0.7548, -1.1086],
         [-0.4760, -0.6257, -0.0890,  ...,  0.7149, -0.1067, -1.0402],
         [ 0.0381, -0.9716,  0.0535,  ...,  0.7481, -1.2066,  0.1981],
         ...,
         [-0.1389, -0.0385, -0.5629,  ...,  0.5593, -0.6863, -1.1579],
         [-0.8357, -1.1245, -0.4831,  ..., -0.1892, -0.9252, -0.4061],
         [ 0.0807, -0.4663, -0.4798,  ..., -0.0529,  0.0574, -0.3899]],

        ...,

        [[-0.0572, -0.3326,  0.0365,  ..., -0.1674,  0.3002, -0.7351],
         [-0.0656, -0.1424, -0.2541,  ...,  0.5962,  0.0653, -0.1977],
         [ 0.0160,  0.1282,  0.0813,  ...,  0.8700, -1.2711, -0.4677],
         ...,
         [-0.9097, -0.3149, -0.5844,  ...,  0.8420, -1.1847, -0.9284],
         [-0.6761, -0.9083,  0.1085,  ...,  0.1446, -0.1861, -0.9937],
         [-0.1480, -0.2067, -0.0422,  ...,  0.7388, -1.0872,  0.2044]],

        [[-0.0396, -0.8360, -0.4746,  ...,  0.4165,  0.0536, -1.2347],
         [-0.3443, -1.0743, -0.1450,  ...,  0.0390, -0.9386, -1.0569],
         [ 0.1385, -0.7904, -0.0642,  ..., -0.1249, -1.1416, -0.2409],
         ...,
         [-0.0186, -0.1903,  0.1176,  ...,  0.3688, -0.3286, -0.9875],
         [-0.5782, -0.7144, -0.6296,  ...,  0.0074, -0.7946, -1.1536],
         [ 0.1591, -0.5763,  0.1482,  ...,  0.4657, -1.1051, -1.1050]],

        [[-0.6747, -0.3833, -0.2250,  ...,  0.2895, -0.6881,  0.2088],
         [-0.3797, -0.8479,  0.0370,  ...,  0.4683, -0.3536, -1.0708],
         [ 0.0162, -0.6676,  0.1178,  ..., -0.1911, -0.3828,  0.1630],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])

2025-07-26 06:07:47.693430 GPU 6 136070 test begin: paddle.nn.functional.log_softmax(Tensor([2, 2, 1073741825],"float16"), 0, )
[cuda error] backward paddle.nn.functional.log_softmax(Tensor([2, 2, 1073741825],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:08:36.829552 GPU 1 137077 test begin: paddle.nn.functional.log_softmax(Tensor([2, 2147483649, 1],"float16"), 0, )
[cuda error] backward paddle.nn.functional.log_softmax(Tensor([2, 2147483649, 1],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:14:07.615578 GPU 2 138908 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 0, )
[cuda error] backward paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:14:23.892888 GPU 1 139067 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 1, )
[accuracy error] backward paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 4294967298 (0.0%)
Greatest absolute difference: 0.38134765625 at index (1, 1, 715827882) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 2, 715827881) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 715827883]), dtype=torch.float16)
tensor([[[ 0.2778,  0.2939, -0.0815,  ...,  0.1364, -0.2776, -0.1722],
         [ 0.1926, -0.0364,  0.1029,  ..., -0.0604,  0.3235,  0.0410],
         [-0.4705, -0.2576, -0.0215,  ..., -0.0761, -0.0461,  0.1312]],

        [[ 0.1644, -0.0173, -0.3599,  ...,  0.0956,  0.4700, -0.0793],
         [-0.2373, -0.2057,  0.0468,  ..., -0.1542, -0.3350,  0.2212],
         [ 0.0728,  0.2229,  0.3130,  ...,  0.0586, -0.1351, -0.1418]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3, 715827883]), dtype=torch.float16)
tensor([[[ 0.2296,  0.4272, -0.0815,  ...,  0.1364, -0.2776, -0.1722],
         [ 0.1926, -0.0364,  0.1029,  ..., -0.0604,  0.3235,  0.0410],
         [-0.4705, -0.2576, -0.0215,  ..., -0.0761, -0.0461,  0.1312]],

        [[ 0.1644, -0.0173, -0.3599,  ...,  0.0956,  0.2766, -0.2664],
         [-0.2373, -0.2057,  0.0468,  ..., -0.1542, -0.5093, -0.1603],
         [ 0.0728,  0.2229,  0.3130,  ...,  0.0586,  0.0000,  0.0000]]], dtype=torch.float16)

2025-07-26 06:15:43.234291 GPU 7 139415 test begin: paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 0, )
[cuda error] backward paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:16:25.901889 GPU 2 139582 test begin: paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 1, )
[accuracy error] backward paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 4294967304 (0.0%)
Greatest absolute difference: 0.491455078125 at index (1, 536870912, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 536870911, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 536870913, 4]), dtype=torch.float16)
tensor([[[ 0.3042,  0.2930, -0.4739,  0.2915],
         [ 0.0598,  0.4976,  0.0586, -0.2878],
         [ 0.2639, -0.0638, -0.1489,  0.2263],
         ...,
         [-0.3540, -0.4521,  0.3037,  0.4553],
         [-0.0965, -0.4683, -0.0767, -0.1165],
         [ 0.1960, -0.3862,  0.0285, -0.2556]],

        [[ 0.2137,  0.1055,  0.3965, -0.4824],
         [ 0.3931,  0.3994,  0.0264, -0.4319],
         [-0.4680,  0.2100,  0.1996,  0.2234],
         ...,
         [-0.3923, -0.0152,  0.0391, -0.2056],
         [ 0.4866,  0.1420,  0.4636,  0.0570],
         [-0.4048, -0.4915,  0.1873, -0.3203]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 536870913, 4]), dtype=torch.float16)
tensor([[[ 0.3042,  0.2930, -0.4739,  0.2915],
         [ 0.0598,  0.4976,  0.0586, -0.2878],
         [ 0.2639, -0.0638, -0.1489,  0.2263],
         ...,
         [-0.3540, -0.4521,  0.3037,  0.4553],
         [-0.0965, -0.4683, -0.0767, -0.1165],
         [ 0.1960, -0.3862,  0.0285, -0.2556]],

        [[ 0.2137,  0.1055,  0.3965, -0.4824],
         [ 0.3931,  0.3994,  0.0264, -0.4319],
         [-0.4680,  0.2100,  0.1996,  0.2234],
         ...,
         [-0.3923, -0.0152,  0.0391, -0.2056],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float16)

2025-07-26 06:18:28.538219 GPU 1 139067 test begin: paddle.nn.functional.log_softmax(Tensor([357913942, 3, 4],"float16"), 0, )
[accuracy error] backward paddle.nn.functional.log_softmax(Tensor([357913942, 3, 4],"float16"), 0, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 4294967304 (0.0%)
Greatest absolute difference: 0.498291015625 at index (357913941, 2, 3) (up to 0.01 allowed)
Greatest relative difference: inf at index (357913941, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.2720,  0.1011,  0.1381,  0.3298],
         [-0.4304,  0.2739,  0.2734,  0.3699],
         [-0.3176, -0.3240, -0.2881,  0.1104]],

        [[-0.4006, -0.0544,  0.1727, -0.0077],
         [-0.0547,  0.2222, -0.2473,  0.2769],
         [ 0.1331,  0.1036, -0.2729, -0.0740]],

        [[-0.2009, -0.1482,  0.1742, -0.1287],
         [ 0.2017, -0.1183, -0.3184, -0.2327],
         [-0.4739,  0.2957, -0.2563,  0.0031]],

        ...,

        [[-0.3040,  0.4072, -0.3167, -0.1414],
         [ 0.4690, -0.2179, -0.3787, -0.2759],
         [ 0.2002,  0.0053, -0.0607, -0.2390]],

        [[-0.4614,  0.1300,  0.0467, -0.2732],
         [ 0.0324,  0.2703,  0.0450, -0.1921],
         [ 0.0226, -0.0074, -0.1238,  0.3286]],

        [[ 0.0743, -0.3533,  0.0138,  0.2008],
         [-0.4395,  0.1807,  0.2686,  0.0763],
         [-0.2101, -0.1960, -0.2318, -0.4983]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.2720,  0.1011,  0.1381,  0.3298],
         [-0.4304,  0.2739,  0.2734,  0.3699],
         [-0.3176, -0.3240, -0.2881,  0.1104]],

        [[-0.4006, -0.0544,  0.1727, -0.0077],
         [-0.0547,  0.2222, -0.2473,  0.2769],
         [ 0.1331,  0.1036, -0.2729, -0.0740]],

        [[-0.2009, -0.1482,  0.1742, -0.1287],
         [ 0.2017, -0.1183, -0.3184, -0.2327],
         [-0.4739,  0.2957, -0.2563,  0.0031]],

        ...,

        [[-0.3040,  0.4072, -0.3167, -0.1414],
         [ 0.4690, -0.2179, -0.3787, -0.2759],
         [ 0.2002,  0.0053, -0.0607, -0.2390]],

        [[-0.4614,  0.1300,  0.0467, -0.2732],
         [ 0.0324,  0.2703,  0.0450, -0.1921],
         [ 0.0226, -0.0074, -0.1238,  0.3286]],

        [[ 0.0743, -0.3533,  0.0138,  0.2008],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float16)

2025-07-26 06:19:30.860858 GPU 4 139933 test begin: paddle.nn.functional.log_softmax(Tensor([357913942, 3, 4],"float16"), 1, )
[accuracy error] backward paddle.nn.functional.log_softmax(Tensor([357913942, 3, 4],"float16"), 1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 18 / 4294967304 (0.0%)
Greatest absolute difference: 0.51123046875 at index (357913941, 1, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (357913941, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.1398, -0.2117,  0.2094, -0.1571],
         [-0.1942,  0.0352, -0.1804, -0.0665],
         [ 0.0547,  0.1765, -0.0290,  0.2236]],

        [[-0.1823,  0.1785,  0.1962,  0.4197],
         [ 0.1752,  0.1572,  0.2053, -0.2944],
         [ 0.0071, -0.3357, -0.4016, -0.1251]],

        [[-0.0113,  0.0361,  0.0381, -0.4597],
         [-0.0140,  0.3086,  0.1344,  0.1962],
         [ 0.0253, -0.3447, -0.1725,  0.2639]],

        ...,

        [[ 0.2932, -0.0986,  0.2213, -0.2759],
         [-0.4827,  0.2192,  0.1381,  0.3259],
         [ 0.1898, -0.1207, -0.3591, -0.0499]],

        [[-0.0152, -0.2639, -0.0724,  0.2700],
         [-0.3604,  0.1322,  0.3516, -0.1422],
         [ 0.3755,  0.1317, -0.2791, -0.1278]],

        [[ 0.2360, -0.1088,  0.0276, -0.0278],
         [-0.5112,  0.3821,  0.0764,  0.0402],
         [ 0.2754, -0.2732, -0.1041, -0.0125]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 8.3923e-03, -2.0374e-01,  1.9983e-01,  1.3525e-01],
         [-4.2603e-01,  4.5715e-02, -1.9580e-01,  1.3989e-01],
         [ 5.4657e-02,  1.7651e-01, -2.8961e-02,  2.2363e-01]],

        [[-1.8225e-01,  1.7847e-01,  1.9617e-01,  4.1968e-01],
         [ 1.7517e-01,  1.5723e-01,  2.0532e-01, -2.9443e-01],
         [ 7.0763e-03, -3.3569e-01, -4.0161e-01, -1.2512e-01]],

        [[-1.1292e-02,  3.6102e-02,  3.8086e-02, -4.5972e-01],
         [-1.4000e-02,  3.0859e-01,  1.3440e-01,  1.9617e-01],
         [ 2.5253e-02, -3.4473e-01, -1.7249e-01,  2.6392e-01]],

        ...,

        [[ 2.9321e-01, -9.8633e-02,  2.2131e-01, -2.7588e-01],
         [-4.8267e-01,  2.1924e-01,  1.3806e-01,  3.2593e-01],
         [ 1.8982e-01, -1.2067e-01, -3.5913e-01, -4.9896e-02]],

        [[-1.5152e-02, -2.6392e-01, -7.2449e-02,  2.7002e-01],
         [-3.6035e-01,  1.3220e-01,  3.5156e-01, -1.4221e-01],
         [ 3.7549e-01,  1.3171e-01, -2.7905e-01, -1.2781e-01]],

        [[ 4.1748e-01,  7.0251e-02, -2.8467e-04, -2.2864e-01],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]], dtype=torch.float16)

2025-07-26 06:25:07.831555 GPU 1 139067 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 2, 1073741825],"float16"), axis=0, )
[cuda error] backward paddle.nn.functional.log_softmax(x=Tensor([2, 2, 1073741825],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:26:12.363121 GPU 1 141420 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 2147483649, 1],"float16"), axis=0, )
[cuda error] backward paddle.nn.functional.log_softmax(x=Tensor([2, 2147483649, 1],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:28:45.451525 GPU 6 141250 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=0, )
[cuda error] backward paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:29:01.894568 GPU 3 141022 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=1, )
[accuracy error] backward paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 7 / 4294967298 (0.0%)
Greatest absolute difference: 0.53515625 at index (1, 2, 715827882) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 2, 715827881) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 715827883]), dtype=torch.float16)
tensor([[[ 2.0203e-01, -5.7770e-02,  2.2485e-01,  ...,  1.3306e-01,  3.8892e-01, -1.8298e-01],
         [-1.0944e-01,  1.2695e-01, -2.5659e-01,  ..., -3.0884e-01, -1.5320e-01,  4.5264e-01],
         [-9.2651e-02, -6.9153e-02,  3.1708e-02,  ...,  1.7566e-01, -2.3584e-01, -2.6978e-01]],

        [[ 1.9165e-01,  1.8152e-01,  9.8633e-02,  ...,  1.2030e-01, -5.1367e-01,  2.1716e-01],
         [-3.5889e-01,  1.8750e-01, -9.8389e-02,  ..., -1.0187e-01,  3.6255e-01,  3.1812e-01],
         [ 1.6724e-01, -3.6914e-01, -2.3043e-04,  ..., -1.8417e-02,  1.5125e-01, -5.3516e-01]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3, 715827883]), dtype=torch.float16)
tensor([[[ 1.0712e-01, -4.3945e-01,  2.2485e-01,  ...,  1.3306e-01,  3.8892e-01, -1.8298e-01],
         [-1.0944e-01,  1.2695e-01, -2.5659e-01,  ..., -3.0884e-01, -1.5320e-01,  4.5264e-01],
         [-9.2651e-02, -6.9153e-02,  3.1708e-02,  ...,  1.7566e-01, -2.3584e-01, -2.6978e-01]],

        [[ 1.9165e-01,  1.8152e-01,  9.8633e-02,  ...,  1.2030e-01, -4.9658e-01,  1.7908e-01],
         [-3.5889e-01,  1.8750e-01, -9.8389e-02,  ..., -1.0187e-01,  3.7329e-01,  2.9492e-01],
         [ 1.6724e-01, -3.6914e-01, -2.3043e-04,  ..., -1.8417e-02,  0.0000e+00,  0.0000e+00]]], dtype=torch.float16)

2025-07-26 06:29:10.855801 GPU 5 142247 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=0, )
[cuda error] backward paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /host_home/ningzhengsheng/src/Paddle/paddle/fluid/pybind/eager_functions.cc:1391)


2025-07-26 06:30:54.202441 GPU 2 141736 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=1, )
[accuracy error] backward paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 4294967304 (0.0%)
Greatest absolute difference: 0.38330078125 at index (1, 536870912, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 536870911, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 536870913, 4]), dtype=torch.float16)
tensor([[[-0.3853, -0.0465,  0.2026, -0.4031],
         [ 0.1605,  0.1697,  0.4895, -0.1760],
         [-0.2354, -0.1173,  0.0992, -0.4065],
         ...,
         [ 0.1537, -0.0871, -0.0587, -0.2810],
         [-0.4570,  0.4004, -0.0369,  0.0778],
         [-0.0739,  0.2632,  0.1383,  0.3237]],

        [[ 0.2507, -0.1700,  0.0463,  0.3105],
         [-0.4292,  0.2690,  0.1302,  0.0018],
         [ 0.2122, -0.3992,  0.2981, -0.1376],
         ...,
         [ 0.3616, -0.4807, -0.4983,  0.1986],
         [-0.3403,  0.0953,  0.2979,  0.0842],
         [ 0.3833,  0.0501,  0.1074, -0.2214]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 536870913, 4]), dtype=torch.float16)
tensor([[[-0.3853, -0.0464,  0.2026, -0.4031],
         [ 0.1605,  0.1697,  0.4895, -0.1760],
         [-0.2354, -0.1173,  0.0992, -0.4065],
         ...,
         [ 0.1537, -0.0871, -0.0587, -0.2810],
         [-0.4570,  0.4004, -0.0369,  0.0778],
         [-0.0739,  0.2632,  0.1383,  0.3237]],

        [[ 0.2507, -0.1700,  0.0463,  0.3105],
         [-0.4292,  0.2690,  0.1302,  0.0018],
         [ 0.2122, -0.3992,  0.2981, -0.1376],
         ...,
         [ 0.3616, -0.4807, -0.4983,  0.1986],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float16)

2025-07-26 06:30:56.052588 GPU 4 142423 test begin: paddle.nn.functional.log_softmax(x=Tensor([357913942, 3, 4],"float16"), axis=0, )
[accuracy error] backward paddle.nn.functional.log_softmax(x=Tensor([357913942, 3, 4],"float16"), axis=0, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 7 / 4294967304 (0.0%)
Greatest absolute difference: 0.485595703125 at index (357913941, 2, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (357913941, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.4194, -0.4316, -0.2194,  0.2371],
         [-0.2072,  0.0867,  0.1345,  0.0789],
         [-0.4490,  0.1807,  0.1313, -0.2927]],

        [[ 0.2482, -0.0131, -0.0914,  0.1726],
         [ 0.0131, -0.1083,  0.3699,  0.2629],
         [-0.3430, -0.0124,  0.3179, -0.2605]],

        [[-0.2622, -0.3704, -0.0437,  0.2563],
         [ 0.2546,  0.3215,  0.1854,  0.0638],
         [ 0.4463, -0.1798,  0.4136,  0.1846]],

        ...,

        [[ 0.2021, -0.1398, -0.1105,  0.3372],
         [-0.0591,  0.0377, -0.3774,  0.4778],
         [ 0.3623, -0.0730, -0.3303,  0.3074]],

        [[ 0.3547, -0.3584, -0.4097,  0.2402],
         [ 0.4094,  0.0554,  0.4514, -0.4441],
         [-0.1780,  0.2927, -0.2380, -0.3650]],

        [[ 0.3530,  0.1058, -0.4268, -0.4175],
         [-0.0025, -0.3525, -0.3877, -0.1288],
         [ 0.4856, -0.1009, -0.4241, -0.3679]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.4194, -0.4316, -0.2194,  0.2371],
         [-0.2072,  0.0867,  0.1345,  0.0789],
         [-0.4490,  0.1807,  0.1313, -0.2927]],

        [[ 0.2482, -0.0131, -0.0914,  0.1726],
         [ 0.0131, -0.1083,  0.3699,  0.2629],
         [-0.3430, -0.0124,  0.3179, -0.2605]],

        [[-0.2622, -0.3704, -0.0437,  0.2563],
         [ 0.2546,  0.3215,  0.1854,  0.0638],
         [ 0.4463, -0.1798,  0.4136,  0.1846]],

        ...,

        [[ 0.2021, -0.1398, -0.1105,  0.3372],
         [-0.0591,  0.0377, -0.3774,  0.4778],
         [ 0.3623, -0.0730, -0.3303,  0.3074]],

        [[ 0.3547, -0.3584, -0.4097,  0.2402],
         [ 0.4094,  0.0554,  0.4514, -0.4441],
         [-0.1780,  0.2927, -0.2380, -0.3650]],

        [[ 0.3530,  0.1058, -0.4268, -0.4175],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float16)

2025-07-26 06:31:10.335016 GPU 6 142589 test begin: paddle.nn.functional.log_softmax(x=Tensor([357913942, 3, 4],"float16"), axis=1, )
[accuracy error] backward paddle.nn.functional.log_softmax(x=Tensor([357913942, 3, 4],"float16"), axis=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 19 / 4294967304 (0.0%)
Greatest absolute difference: 0.44384765625 at index (357913941, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (357913941, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.2991, -0.1443, -0.0502,  0.1760],
         [-0.0034, -0.0299, -0.1857, -0.2510],
         [-0.2957,  0.1743,  0.2358,  0.0750]],

        [[-0.3560,  0.0921, -0.2157, -0.2194],
         [ 0.5581, -0.0938, -0.0254,  0.3306],
         [-0.2020,  0.0017,  0.2412, -0.1111]],

        [[-0.1304, -0.1937,  0.3706, -0.1383],
         [-0.0259, -0.0356, -0.0050,  0.1841],
         [ 0.1564,  0.2294, -0.3655, -0.0457]],

        ...,

        [[-0.1057, -0.1812, -0.0659, -0.2620],
         [ 0.3748,  0.1252,  0.1594,  0.1907],
         [-0.2690,  0.0560, -0.0936,  0.0712]],

        [[ 0.2097,  0.1499,  0.1802, -0.4714],
         [ 0.1825,  0.0038, -0.2769,  0.3970],
         [-0.3921, -0.1537,  0.0968,  0.0745]],

        [[-0.0683, -0.1427,  0.1344,  0.0497],
         [ 0.0849, -0.1896,  0.2294, -0.1653],
         [-0.0167,  0.3323, -0.3638,  0.1155]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([357913942, 3, 4]), dtype=torch.float16)
tensor([[[ 0.3501, -0.1327, -0.0403,  0.1448],
         [ 0.0707, -0.0184, -0.1720, -0.2834],
         [-0.2957,  0.1743,  0.2358,  0.0750]],

        [[-0.3560,  0.0921, -0.2157, -0.2194],
         [ 0.5581, -0.0938, -0.0254,  0.3306],
         [-0.2020,  0.0017,  0.2412, -0.1111]],

        [[-0.1304, -0.1937,  0.3706, -0.1383],
         [-0.0259, -0.0356, -0.0050,  0.1841],
         [ 0.1564,  0.2294, -0.3655, -0.0457]],

        ...,

        [[-0.1057, -0.1812, -0.0659, -0.2620],
         [ 0.3748,  0.1252,  0.1594,  0.1907],
         [-0.2690,  0.0560, -0.0936,  0.0712]],

        [[ 0.2097,  0.1499,  0.1802, -0.4714],
         [ 0.1825,  0.0038, -0.2769,  0.3970],
         [-0.3921, -0.1537,  0.0968,  0.0745]],

        [[-0.5122,  0.1302,  0.2271,  0.1077],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float16)

2025-07-26 10:00:59.724433 GPU 6 7808 test begin: paddle.nn.functional.temporal_shift(x=Tensor([2, 95070891, 4, 3],"float16"), seg_num=2, )
[accuracy error] paddle.nn.functional.temporal_shift(x=Tensor([2, 95070891, 4, 3],"float16"), seg_num=2, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 24 / 2281701384 (0.0%)
Greatest absolute difference: 0.927734375 at index (0, 47535444, 0, 2) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 47535444, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 95070891, 4, 3]), dtype=torch.float16)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[-3.8599e-01, -3.5913e-01,  2.7161e-02],
          [-8.2336e-02,  6.6032e-03,  2.4612e-02],
          [ 4.0747e-01,  4.6118e-01, -2.8027e-01],
          [-3.6230e-01, -1.8176e-01,  2.0996e-01]],

         [[-2.9517e-01,  5.7800e-02,  3.5767e-02],
          [-8.8135e-02, -1.8665e-01, -7.6050e-02],
          [-3.8013e-01,  2.4170e-01,  3.3008e-01],
          [ 2.7563e-01,  6.9397e-02,  2.3723e-04]],

         [[-1.8042e-01, -1.4514e-01, -1.5283e-01],
          [-4.3994e-01, -1.9250e-01,  1.8665e-01],
          [ 4.2310e-01,  2.0886e-01,  1.2152e-01],
          [-1.9397e-01,  2.0508e-01, -2.9272e-01]]],


        [[[ 3.7085e-01,  3.1445e-01,  3.9819e-01],
          [-4.4580e-01,  1.5186e-01,  9.1248e-02],
          [ 8.8196e-02,  2.7466e-01,  2.2437e-01],
          [ 1.9031e-01,  5.1239e-02,  4.0016e-03]],

         [[-1.0208e-02, -3.3228e-01, -4.7192e-01],
          [ 8.2153e-02,  4.6899e-01,  4.4238e-01],
          [-4.2236e-01, -3.4546e-01, -2.8882e-01],
          [-4.7656e-01, -3.3936e-01, -6.3416e-02]],

         [[-4.3677e-01,  1.2524e-01, -1.0626e-01],
          [-3.9160e-01,  3.0542e-01,  2.1228e-01],
          [-1.9238e-01,  4.7681e-01,  2.0850e-01],
          [ 1.5125e-01,  1.0017e-02,  3.6401e-01]],

         ...,

         [[ 4.8413e-01, -4.2822e-01,  1.9885e-01],
          [-2.3361e-02, -6.4880e-02,  7.0129e-02],
          [ 3.8428e-01,  1.8176e-01,  4.4995e-01],
          [-5.9204e-02,  2.0984e-01, -1.2341e-01]],

         [[ 3.5718e-01,  3.6041e-02, -1.7346e-01],
          [ 3.1543e-01,  7.1350e-02,  3.7646e-01],
          [ 1.3176e-02,  1.1523e-01,  5.9021e-02],
          [-2.4524e-01,  1.6235e-01,  3.2959e-01]],

         [[-3.3887e-01,  4.1870e-01, -2.9419e-01],
          [ 1.9409e-01,  3.2568e-01, -2.1350e-01],
          [ 3.7427e-01, -4.7668e-02,  2.9517e-01],
          [ 2.6831e-01,  3.6523e-01,  2.8125e-01]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 95070891, 4, 3]), dtype=torch.float16)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[-3.8599e-01, -3.5913e-01,  2.7161e-02],
          [-8.2336e-02,  6.6032e-03,  2.4612e-02],
          [ 4.0747e-01,  4.6118e-01, -2.8027e-01],
          [-3.6230e-01, -1.8176e-01,  2.0996e-01]],

         [[-2.9517e-01,  5.7800e-02,  3.5767e-02],
          [-8.8135e-02, -1.8665e-01, -7.6050e-02],
          [-3.8013e-01,  2.4170e-01,  3.3008e-01],
          [ 2.7563e-01,  6.9397e-02,  2.3723e-04]],

         [[-1.8042e-01, -1.4514e-01, -1.5283e-01],
          [-4.3994e-01, -1.9250e-01,  1.8665e-01],
          [ 4.2310e-01,  2.0886e-01,  1.2152e-01],
          [-1.9397e-01,  2.0508e-01, -2.9272e-01]]],


        [[[ 3.7085e-01,  3.1445e-01,  3.9819e-01],
          [-4.4580e-01,  1.5186e-01,  9.1248e-02],
          [ 8.8196e-02,  2.7466e-01,  2.2437e-01],
          [ 1.9031e-01,  5.1239e-02,  4.0016e-03]],

         [[-1.0208e-02, -3.3228e-01, -4.7192e-01],
          [ 8.2153e-02,  4.6899e-01,  4.4238e-01],
          [-4.2236e-01, -3.4546e-01, -2.8882e-01],
          [-4.7656e-01, -3.3936e-01, -6.3416e-02]],

         [[-4.3677e-01,  1.2524e-01, -1.0626e-01],
          [-3.9160e-01,  3.0542e-01,  2.1228e-01],
          [-1.9238e-01,  4.7681e-01,  2.0850e-01],
          [ 1.5125e-01,  1.0017e-02,  3.6401e-01]],

         ...,

         [[ 4.8413e-01, -4.2822e-01,  1.9885e-01],
          [-2.3361e-02, -6.4880e-02,  7.0129e-02],
          [ 3.8428e-01,  1.8176e-01,  4.4995e-01],
          [-5.9204e-02,  2.0984e-01, -1.2341e-01]],

         [[ 3.5718e-01,  3.6041e-02, -1.7346e-01],
          [ 3.1543e-01,  7.1350e-02,  3.7646e-01],
          [ 1.3176e-02,  1.1523e-01,  5.9021e-02],
          [-2.4524e-01,  1.6235e-01,  3.2959e-01]],

         [[-3.3887e-01,  4.1870e-01, -2.9419e-01],
          [ 1.9409e-01,  3.2568e-01, -2.1350e-01],
          [ 3.7427e-01, -4.7668e-02,  2.9517e-01],
          [ 2.6831e-01,  3.6523e-01,  2.8125e-01]]]], dtype=torch.float16)

2025-07-26 10:04:16.183669 GPU 2 7975 test begin: paddle.nn.functional.upsample(x=Tensor([1, 1073741825, 2, 2, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.nn.functional.upsample(x=Tensor([1, 1073741825, 2, 2, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 11745 / 20592 (57.0%)
Greatest absolute difference: 3332.0 at index (0, 65, 0, 0, 0) (up to 0.5 allowed)
Greatest relative difference: 920.0 at index (0, 58, 0, 0, 0) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([1, 88, 6, 39, 1]), dtype=torch.float16)
tensor([[[[[   86.0000],
           [   85.8750],
           [   85.7500],
           ...,
           [   82.2500],
           [   82.0625],
           [   82.0000]],

          [[   81.3750],
           [   81.1250],
           [   80.8125],
           ...,
           [   71.9375],
           [   71.6250],
           [   71.3750]],

          [[   76.8125],
           [   76.3750],
           [   75.9375],
           ...,
           [   61.6562],
           [   61.1875],
           [   60.8125]],

          [[   72.1875],
           [   71.5625],
           [   71.0625],
           ...,
           [   51.3750],
           [   50.7500],
           [   50.1875]],

          [[   67.5625],
           [   66.8750],
           [   66.1250],
           ...,
           [   41.0938],
           [   40.3438],
           [   39.5938]],

          [[   63.0000],
           [   62.0938],
           [   61.2188],
           ...,
           [   30.7969],
           [   29.8906],
           [   29.0000]]],


         [[[   45.0000],
           [   45.7188],
           [   46.4062],
           ...,
           [   70.5625],
           [   71.3125],
           [   72.0000]],

          [[   50.7812],
           [   51.3438],
           [   51.8750],
           ...,
           [   70.4375],
           [   71.0625],
           [   71.5625]],

          [[   56.5938],
           [   56.9688],
           [   57.3750],
           ...,
           [   70.4375],
           [   70.8125],
           [   71.1875]],

          [[   62.4062],
           [   62.6250],
           [   62.8438],
           ...,
           [   70.3125],
           [   70.5625],
           [   70.8125]],

          [[   68.1875],
           [   68.2500],
           [   68.3125],
           ...,
           [   70.2500],
           [   70.3125],
           [   70.4375]],

          [[   74.0000],
           [   73.8750],
           [   73.8125],
           ...,
           [   70.1875],
           [   70.0625],
           [   70.0000]]],


         [[[   73.0000],
           [   71.3125],
           [   69.6875],
           ...,
           [   13.3203],
           [   11.6562],
           [   10.0000]],

          [[   77.5625],
           [   75.8750],
           [   74.1875],
           ...,
           [   16.5938],
           [   14.8906],
           [   13.1953]],

          [[   82.1875],
           [   80.4375],
           [   78.7500],
           ...,
           [   19.8750],
           [   18.1250],
           [   16.4062]],

          [[   86.8125],
           [   85.0000],
           [   83.2500],
           ...,
           [   23.1406],
           [   21.3594],
           [   19.5938]],

          [[   91.3750],
           [   89.5625],
           [   87.7500],
           ...,
           [   26.4219],
           [   24.5938],
           [   22.7969]],

          [[   96.0000],
           [   94.1250],
           [   92.3125],
           ...,
           [   29.6875],
           [   27.8438],
           [   26.0000]]],


         ...,


         [[[ -199.0000],
           [ -202.5000],
           [ -205.5000],
           ...,
           [ -316.5000],
           [ -319.7500],
           [ -323.0000]],

          [[ -136.7500],
           [ -141.7500],
           [ -146.1250],
           ...,
           [ -300.0000],
           [ -304.7500],
           [ -309.2500]],

          [[  -75.5625],
           [  -80.3750],
           [  -86.9375],
           ...,
           [ -283.7500],
           [ -289.5000],
           [ -295.2500]],

          [[  -12.4375],
           [  -19.8750],
           [  -26.7188],
           ...,
           [ -267.7500],
           [ -274.5000],
           [ -281.7500]],

          [[   48.3750],
           [   42.0000],
           [   31.1875],
           ...,
           [ -250.6250],
           [ -259.5000],
           [ -267.7500]],

          [[  111.0000],
           [  102.0625],
           [   91.8125],
           ...,
           [ -234.2500],
           [ -244.6250],
           [ -254.0000]]],


         [[[ -508.0000],
           [ -486.5000],
           [ -465.0000],
           ...,
           [  254.5000],
           [  273.5000],
           [  296.0000]],

          [[ -804.0000],
           [ -786.0000],
           [ -767.5000],
           ...,
           [ -157.7500],
           [ -144.0000],
           [ -124.6250]],

          [[-1100.0000],
           [-1085.0000],
           [-1070.0000],
           ...,
           [ -573.5000],
           [ -561.0000],
           [ -546.5000]],

          [[-1396.0000],
           [-1385.0000],
           [-1374.0000],
           ...,
           [ -987.0000],
           [ -977.5000],
           [ -966.5000]],

          [[-1692.0000],
           [-1684.0000],
           [-1676.0000],
           ...,
           [-1402.0000],
           [-1394.0000],
           [-1386.0000]],

          [[-1988.0000],
           [-1983.0000],
           [-1978.0000],
           ...,
           [-1818.0000],
           [-1813.0000],
           [-1808.0000]]],


         [[[    5.0000],
           [    7.6836],
           [   10.3672],
           ...,
           [  101.6250],
           [  104.3125],
           [  107.0000]],

          [[   28.7969],
           [   30.8125],
           [   32.8438],
           ...,
           [  101.6875],
           [  103.7500],
           [  105.7500]],

          [[   52.5938],
           [   53.9688],
           [   55.3125],
           ...,
           [  101.8750],
           [  103.2500],
           [  104.5625]],

          [[   76.4375],
           [   77.1250],
           [   77.8125],
           ...,
           [  102.0000],
           [  102.6250],
           [  103.4375]],

          [[  100.1875],
           [  100.2500],
           [  100.2500],
           ...,
           [  102.1250],
           [  102.1250],
           [  102.1875]],

          [[  124.0000],
           [  123.3750],
           [  122.7500],
           ...,
           [  102.2500],
           [  101.5625],
           [  101.0000]]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 88, 6, 39, 1]), dtype=torch.float16)
tensor([[[[[ 86.0000],
           [ 85.8750],
           [ 85.8125],
           ...,
           [ 82.1875],
           [ 82.1250],
           [ 82.0000]],

          [[ 81.3750],
           [ 81.1250],
           [ 80.8750],
           ...,
           [ 71.9375],
           [ 71.6875],
           [ 71.3750]],

          [[ 76.8125],
           [ 76.3750],
           [ 75.9375],
           ...,
           [ 61.6562],
           [ 61.2188],
           [ 60.8125]],

          [[ 72.1875],
           [ 71.6250],
           [ 71.0625],
           ...,
           [ 51.3438],
           [ 50.7812],
           [ 50.1875]],

          [[ 67.6250],
           [ 66.8750],
           [ 66.1250],
           ...,
           [ 41.0625],
           [ 40.3438],
           [ 39.5938]],

          [[ 63.0000],
           [ 62.0938],
           [ 61.2188],
           ...,
           [ 30.7969],
           [ 29.8906],
           [ 29.0000]]],


         [[[ 45.0000],
           [ 45.7188],
           [ 46.4062],
           ...,
           [ 70.5625],
           [ 71.3125],
           [ 72.0000]],

          [[ 50.8125],
           [ 51.3438],
           [ 51.9062],
           ...,
           [ 70.5000],
           [ 71.0625],
           [ 71.6250]],

          [[ 56.5938],
           [ 56.9688],
           [ 57.3750],
           ...,
           [ 70.4375],
           [ 70.8125],
           [ 71.1875]],

          [[ 62.4062],
           [ 62.6250],
           [ 62.8438],
           ...,
           [ 70.3750],
           [ 70.5625],
           [ 70.8125]],

          [[ 68.1875],
           [ 68.2500],
           [ 68.3125],
           ...,
           [ 70.3125],
           [ 70.3125],
           [ 70.3750]],

          [[ 74.0000],
           [ 73.8750],
           [ 73.8125],
           ...,
           [ 70.1875],
           [ 70.1250],
           [ 70.0000]]],


         [[[ 73.0000],
           [ 71.3125],
           [ 69.6875],
           ...,
           [ 13.3125],
           [ 11.6562],
           [ 10.0000]],

          [[ 77.6250],
           [ 75.8750],
           [ 74.1875],
           ...,
           [ 16.5938],
           [ 14.8984],
           [ 13.2031]],

          [[ 82.1875],
           [ 80.4375],
           [ 78.7500],
           ...,
           [ 19.8594],
           [ 18.1250],
           [ 16.4062]],

          [[ 86.8125],
           [ 85.0625],
           [ 83.2500],
           ...,
           [ 23.1406],
           [ 21.3750],
           [ 19.5938]],

          [[ 91.3750],
           [ 89.6250],
           [ 87.8125],
           ...,
           [ 26.4062],
           [ 24.6094],
           [ 22.7969]],

          [[ 96.0000],
           [ 94.1875],
           [ 92.3125],
           ...,
           [ 29.6875],
           [ 27.8438],
           [ 26.0000]]],


         ...,


         [[[ 29.0000],
           [ 28.5781],
           [ 28.1562],
           ...,
           [ 13.8438],
           [ 13.4219],
           [ 13.0000]],

          [[ 40.5938],
           [ 39.9062],
           [ 39.2500],
           ...,
           [ 16.1562],
           [ 15.4766],
           [ 14.7969]],

          [[ 52.1875],
           [ 51.2500],
           [ 50.3125],
           ...,
           [ 18.4688],
           [ 17.5312],
           [ 16.5938]],

          [[ 63.8125],
           [ 62.5938],
           [ 61.4062],
           ...,
           [ 20.7969],
           [ 19.5938],
           [ 18.4062]],

          [[ 75.3750],
           [ 73.9375],
           [ 72.5000],
           ...,
           [ 23.1094],
           [ 21.6562],
           [ 20.2031]],

          [[ 87.0000],
           [ 85.3125],
           [ 83.5625],
           ...,
           [ 25.4219],
           [ 23.7031],
           [ 22.0000]]],


         [[[ 44.0000],
           [ 44.9375],
           [ 45.9062],
           ...,
           [ 78.1250],
           [ 79.0625],
           [ 80.0000]],

          [[ 55.1875],
           [ 56.0312],
           [ 56.8438],
           ...,
           [ 84.7500],
           [ 85.5625],
           [ 86.3750]],

          [[ 66.3750],
           [ 67.1250],
           [ 67.8125],
           ...,
           [ 91.4375],
           [ 92.1250],
           [ 92.8125]],

          [[ 77.6250],
           [ 78.1875],
           [ 78.7500],
           ...,
           [ 98.0625],
           [ 98.6250],
           [ 99.1875]],

          [[ 88.8125],
           [ 89.2500],
           [ 89.6875],
           ...,
           [104.6875],
           [105.1875],
           [105.6250]],

          [[100.0000],
           [100.3125],
           [100.6250],
           ...,
           [111.3750],
           [111.6875],
           [112.0000]]],


         [[[  5.0000],
           [  7.6836],
           [ 10.3672],
           ...,
           [101.6250],
           [104.3125],
           [107.0000]],

          [[ 28.7969],
           [ 30.8281],
           [ 32.8438],
           ...,
           [101.7500],
           [103.7500],
           [105.8125]],

          [[ 52.5938],
           [ 53.9688],
           [ 55.3438],
           ...,
           [101.8750],
           [103.2500],
           [104.6250]],

          [[ 76.3750],
           [ 77.1250],
           [ 77.8125],
           ...,
           [102.0000],
           [102.6875],
           [103.3750]],

          [[100.1875],
           [100.2500],
           [100.3125],
           ...,
           [102.1250],
           [102.1250],
           [102.1875]],

          [[124.0000],
           [123.3750],
           [122.8125],
           ...,
           [102.1875],
           [101.6250],
           [101.0000]]]]], dtype=torch.float16)

2025-07-26 10:04:22.091482 GPU 5 7322 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 1073741825, 2, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.nn.functional.upsample(x=Tensor([1, 2, 1073741825, 2, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 3530 / 22800 (15.5%)
Greatest absolute difference: 3456.0 at index (0, 75, 7, 24, 0) (up to 0.5 allowed)
Greatest relative difference: 114.3125 at index (0, 75, 9, 0, 0) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([1, 76, 12, 25, 1]), dtype=torch.float16)
tensor([[[[[   72.0000],
           [   71.2500],
           [   70.3750],
           ...,
           [   54.5625],
           [   53.8125],
           [   53.0000]],

          [[   53.0000],
           [   54.5625],
           [   56.0625],
           ...,
           [   86.9375],
           [   88.4375],
           [   90.0000]],

          [[  103.0000],
           [  102.0625],
           [  101.0625],
           ...,
           [   81.9375],
           [   80.9375],
           [   80.0000]],

          ...,

          [[  115.0000],
           [  152.8750],
           [  192.7500],
           ...,
           [  963.0000],
           [ 1001.0000],
           [ 1040.0000]],

          [[  106.0000],
           [  104.3750],
           [  102.6250],
           ...,
           [   69.3750],
           [   67.6250],
           [   66.0000]],

          [[   18.0000],
           [   21.3750],
           [   24.7500],
           ...,
           [   92.2500],
           [   95.6250],
           [   99.0000]]],


         [[[   71.8125],
           [   71.0625],
           [   70.1875],
           ...,
           [   54.4375],
           [   53.6875],
           [   52.8750]],

          [[   53.2500],
           [   54.7500],
           [   56.2188],
           ...,
           [   86.2500],
           [   87.6875],
           [   89.2500]],

          [[  102.0625],
           [  101.1250],
           [  100.1875],
           ...,
           [   81.3125],
           [   80.3125],
           [   79.3750]],

          ...,

          [[   92.3125],
           [  129.7500],
           [  169.1250],
           ...,
           [  929.5000],
           [  967.5000],
           [ 1006.0000]],

          [[  105.1250],
           [  103.5000],
           [  101.8125],
           ...,
           [   69.8125],
           [   68.1250],
           [   66.5625]],

          [[   19.2500],
           [   22.5156],
           [   25.7812],
           ...,
           [   91.1875],
           [   94.4375],
           [   97.7500]]],


         [[[   71.5625],
           [   70.8125],
           [   70.0000],
           ...,
           [   54.2812],
           [   53.5312],
           [   52.7188]],

          [[   53.4375],
           [   54.9062],
           [   56.3438],
           ...,
           [   85.5000],
           [   86.9375],
           [   88.4375]],

          [[  101.0625],
           [  100.1875],
           [   99.1875],
           ...,
           [   80.6250],
           [   79.6250],
           [   78.7500]],

          ...,

          [[   69.6250],
           [  106.5000],
           [  145.3750],
           ...,
           [  896.0000],
           [  933.0000],
           [  971.0000]],

          [[  104.1250],
           [  102.6250],
           [  101.0000],
           ...,
           [   70.1875],
           [   68.5625],
           [   67.0625]],

          [[   20.4844],
           [   23.6406],
           [   26.7969],
           ...,
           [   90.0625],
           [   93.2500],
           [   96.3750]]],


         ...,


         [[[   57.4062],
           [   56.8125],
           [   56.1875],
           ...,
           [   44.4375],
           [   43.8750],
           [   43.2812]],

          [[   69.5625],
           [   68.0000],
           [   66.4375],
           ...,
           [   35.6875],
           [   34.1250],
           [   32.5938]],

          [[   33.9062],
           [   33.9375],
           [   33.9062],
           ...,
           [   34.2500],
           [   34.2500],
           [   34.2812]],

          ...,

          [[-1540.0000],
           [-1538.0000],
           [-1534.0000],
           ...,
           [-1475.0000],
           [-1468.0000],
           [-1467.0000]],

          [[   38.8438],
           [   41.6250],
           [   44.3438],
           ...,
           [   99.3750],
           [  102.2500],
           [  104.8750]],

          [[  108.5000],
           [  104.1875],
           [   99.8125],
           ...,
           [   13.2812],
           [    8.9141],
           [    4.6055]]],


         [[[   57.1875],
           [   56.6250],
           [   56.0000],
           ...,
           [   44.2812],
           [   43.7500],
           [   43.1250]],

          [[   69.7500],
           [   68.2500],
           [   66.6250],
           ...,
           [   34.9688],
           [   33.3438],
           [   31.7812]],

          [[   32.9375],
           [   33.0000],
           [   32.9688],
           ...,
           [   33.5938],
           [   33.5625],
           [   33.6250]],

          ...,

          [[-1563.0000],
           [-1562.0000],
           [-1557.0000],
           ...,
           [-1509.0000],
           [-1503.0000],
           [-1502.0000]],

          [[   37.9062],
           [   40.7188],
           [   43.5312],
           ...,
           [   99.8125],
           [  102.6875],
           [  105.5000]],

          [[  109.8125],
           [  105.4375],
           [  100.8750],
           ...,
           [   12.1719],
           [    7.6992],
           [    3.2793]]],


         [[[   57.0000],
           [   56.4375],
           [   55.8125],
           ...,
           [   44.1562],
           [   43.5938],
           [   43.0000]],

          [[   70.0000],
           [   68.3750],
           [   66.7500],
           ...,
           [   34.2500],
           [   32.6250],
           [   31.0000]],

          [[   32.0000],
           [   32.0625],
           [   32.0625],
           ...,
           [   32.9375],
           [   32.9375],
           [   33.0000]],

          ...,

          [[-1586.0000],
           [-1585.0000],
           [-1581.0000],
           ...,
           [-1542.0000],
           [-1536.0000],
           [-1536.0000]],

          [[   37.0000],
           [   39.8750],
           [   42.7500],
           ...,
           [  100.1875],
           [  103.1875],
           [  106.0000]],

          [[  111.0000],
           [  106.5000],
           [  101.8750],
           ...,
           [   11.1016],
           [    6.5234],
           [    2.0000]]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 76, 12, 25, 1]), dtype=torch.float16)
tensor([[[[[ 72.0000],
           [ 71.1875],
           [ 70.4375],
           ...,
           [ 54.5938],
           [ 53.7812],
           [ 53.0000]],

          [[ 53.0000],
           [ 54.5312],
           [ 56.0938],
           ...,
           [ 86.9375],
           [ 88.4375],
           [ 90.0000]],

          [[103.0000],
           [102.0625],
           [101.0625],
           ...,
           [ 81.9375],
           [ 80.9375],
           [ 80.0000]],

          ...,

          [[ 83.0000],
           [ 82.8750],
           [ 82.7500],
           ...,
           [ 80.2500],
           [ 80.1250],
           [ 80.0000]],

          [[106.0000],
           [104.3125],
           [102.6875],
           ...,
           [ 69.3125],
           [ 67.6875],
           [ 66.0000]],

          [[ 18.0000],
           [ 21.3750],
           [ 24.7500],
           ...,
           [ 92.2500],
           [ 95.6250],
           [ 99.0000]]],


         [[[ 71.8125],
           [ 71.0000],
           [ 70.2500],
           ...,
           [ 54.4375],
           [ 53.6562],
           [ 52.8750]],

          [[ 53.2188],
           [ 54.7188],
           [ 56.2188],
           ...,
           [ 86.1875],
           [ 87.6875],
           [ 89.1875]],

          [[102.0625],
           [101.1250],
           [100.1875],
           ...,
           [ 81.2500],
           [ 80.3125],
           [ 79.3750]],

          ...,

          [[ 82.0625],
           [ 82.0000],
           [ 81.8750],
           ...,
           [ 80.0000],
           [ 79.8750],
           [ 79.8125]],

          [[105.0625],
           [103.5000],
           [101.8750],
           ...,
           [ 69.7500],
           [ 68.1250],
           [ 66.5625]],

          [[ 19.2344],
           [ 22.5156],
           [ 25.7812],
           ...,
           [ 91.1875],
           [ 94.4375],
           [ 97.6875]]],


         [[[ 71.6250],
           [ 70.8125],
           [ 70.0000],
           ...,
           [ 54.3125],
           [ 53.5312],
           [ 52.7188]],

          [[ 53.4688],
           [ 54.9062],
           [ 56.3750],
           ...,
           [ 85.5000],
           [ 87.0000],
           [ 88.4375]],

          [[101.1250],
           [100.1875],
           [ 99.2500],
           ...,
           [ 80.6250],
           [ 79.6875],
           [ 78.7500]],

          ...,

          [[ 81.1875],
           [ 81.1250],
           [ 81.0000],
           ...,
           [ 79.6875],
           [ 79.6250],
           [ 79.5625]],

          [[104.1875],
           [102.6250],
           [101.0625],
           ...,
           [ 70.1875],
           [ 68.6250],
           [ 67.0625]],

          [[ 20.4844],
           [ 23.6406],
           [ 26.8125],
           ...,
           [ 90.0625],
           [ 93.2500],
           [ 96.4375]]],


         ...,


         [[[ 57.4062],
           [ 56.8125],
           [ 56.2188],
           ...,
           [ 44.4375],
           [ 43.8438],
           [ 43.2812]],

          [[ 69.5625],
           [ 68.0000],
           [ 66.4375],
           ...,
           [ 35.6562],
           [ 34.1250],
           [ 32.5625]],

          [[ 33.9062],
           [ 33.9062],
           [ 33.9375],
           ...,
           [ 34.2188],
           [ 34.2500],
           [ 34.2500]],

          ...,

          [[ 15.8438],
           [ 17.8594],
           [ 19.8906],
           ...,
           [ 60.3750],
           [ 62.4062],
           [ 64.4375]],

          [[ 38.8438],
           [ 41.5938],
           [ 44.3438],
           ...,
           [ 99.4375],
           [102.1875],
           [104.9375]],

          [[108.5000],
           [104.1875],
           [ 99.8750],
           ...,
           [ 13.2500],
           [  8.9141],
           [  4.5859]]],


         [[[ 57.1875],
           [ 56.6250],
           [ 56.0312],
           ...,
           [ 44.3125],
           [ 43.7188],
           [ 43.1250]],

          [[ 69.7500],
           [ 68.1875],
           [ 66.6250],
           ...,
           [ 34.9375],
           [ 33.3750],
           [ 31.7812]],

          [[ 32.9375],
           [ 32.9688],
           [ 33.0000],
           ...,
           [ 33.5625],
           [ 33.5938],
           [ 33.6250]],

          ...,

          [[ 14.9219],
           [ 16.9688],
           [ 19.0312],
           ...,
           [ 60.0938],
           [ 62.1562],
           [ 64.1875]],

          [[ 37.9062],
           [ 40.7500],
           [ 43.5625],
           ...,
           [ 99.8125],
           [102.6250],
           [105.4375]],

          [[109.7500],
           [105.3125],
           [100.8750],
           ...,
           [ 12.1641],
           [  7.7305],
           [  3.2930]]],


         [[[ 57.0000],
           [ 56.4062],
           [ 55.8438],
           ...,
           [ 44.1562],
           [ 43.5938],
           [ 43.0000]],

          [[ 70.0000],
           [ 68.3750],
           [ 66.7500],
           ...,
           [ 34.2500],
           [ 32.6250],
           [ 31.0000]],

          [[ 32.0000],
           [ 32.0312],
           [ 32.0938],
           ...,
           [ 32.9062],
           [ 32.9688],
           [ 33.0000]],

          ...,

          [[ 14.0000],
           [ 16.0781],
           [ 18.1719],
           ...,
           [ 59.8438],
           [ 61.9062],
           [ 64.0000]],

          [[ 37.0000],
           [ 39.8750],
           [ 42.7500],
           ...,
           [100.2500],
           [103.1250],
           [106.0000]],

          [[111.0000],
           [106.4375],
           [101.9375],
           ...,
           [ 11.0859],
           [  6.5430],
           [  2.0000]]]]], dtype=torch.float16)

2025-07-26 10:04:23.490622 GPU 1 7640 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 2, 1073741825, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.nn.functional.upsample(x=Tensor([1, 2, 2, 1073741825, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
Not equal to tolerance rtol=1.5, atol=0.5
Tensor-likes are not close!

Mismatched elements: 314408 / 533832 (58.9%)
Greatest absolute difference: 3540.0 at index (0, 0, 51, 94, 0) (up to 0.5 allowed)
Greatest relative difference: 1452.0 at index (0, 86, 0, 104, 0) (up to 1.5 allowed)
ACTUAL: (shape=torch.Size([1, 87, 52, 118, 1]), dtype=torch.float16)
tensor([[[[[   97.0000],
           [   98.0000],
           [   40.0000],
           ...,
           [-1009.0000],
           [  295.0000],
           [   68.0000]],

          [[   97.1875],
           [   98.5000],
           [   41.3125],
           ...,
           [ -997.5000],
           [  277.5000],
           [   67.1250]],

          [[   97.3750],
           [   98.9375],
           [   42.6250],
           ...,
           [ -986.0000],
           [  260.0000],
           [   66.2500]],

          ...,

          [[  106.6250],
           [  121.0625],
           [  104.3750],
           ...,
           [ -445.0000],
           [ -561.0000],
           [   24.7500]],

          [[  106.8125],
           [  121.5625],
           [  105.7500],
           ...,
           [ -433.5000],
           [ -578.5000],
           [   23.8750]],

          [[  107.0000],
           [  122.0000],
           [  107.0000],
           ...,
           [ -422.0000],
           [ -596.0000],
           [   23.0000]]],


         [[[   96.5000],
           [   97.1250],
           [   40.2812],
           ...,
           [ -994.0000],
           [  287.2500],
           [   68.4375]],

          [[   96.7500],
           [   97.6250],
           [   41.5938],
           ...,
           [ -982.5000],
           [  270.0000],
           [   67.5625]],

          [[   96.9375],
           [   98.0625],
           [   42.8750],
           ...,
           [ -971.0000],
           [  252.6250],
           [   66.6875]],

          ...,

          [[  106.6875],
           [  121.0000],
           [  103.6875],
           ...,
           [ -427.2500],
           [ -559.0000],
           [   25.7656]],

          [[  106.8750],
           [  121.5000],
           [  105.0625],
           ...,
           [ -415.7500],
           [ -576.0000],
           [   24.8906]],

          [[  107.0625],
           [  121.9375],
           [  106.3125],
           ...,
           [ -404.0000],
           [ -593.5000],
           [   24.0312]]],


         [[[   96.0625],
           [   96.2500],
           [   40.5625],
           ...,
           [ -979.0000],
           [  279.5000],
           [   68.8125]],

          [[   96.2500],
           [   96.7500],
           [   41.8438],
           ...,
           [ -967.5000],
           [  262.5000],
           [   68.0000]],

          [[   96.5000],
           [   97.2500],
           [   43.1250],
           ...,
           [ -956.0000],
           [  245.3750],
           [   67.1250]],

          ...,

          [[  106.6875],
           [  120.8750],
           [  103.0625],
           ...,
           [ -409.5000],
           [ -557.0000],
           [   26.7656]],

          [[  106.9375],
           [  121.4375],
           [  104.3750],
           ...,
           [ -397.7500],
           [ -574.0000],
           [   25.9219]],

          [[  107.1250],
           [  121.8750],
           [  105.6250],
           ...,
           [ -386.2500],
           [ -591.0000],
           [   25.0625]]],


         ...,


         [[[   57.9375],
           [   24.7656],
           [   64.3750],
           ...,
           [  235.1250],
           [ -352.5000],
           [  103.1250]],

          [[   59.0000],
           [   26.5938],
           [   64.1250],
           ...,
           [  251.8750],
           [ -353.0000],
           [  103.3125]],

          [[   60.0938],
           [   28.4219],
           [   63.8750],
           ...,
           [  268.5000],
           [ -354.0000],
           [  103.4375]],

          ...,

          [[  110.6875],
           [  114.3750],
           [   49.9688],
           ...,
           [ 1048.0000],
           [ -386.7500],
           [  109.6250]],

          [[  111.8125],
           [  116.2500],
           [   49.6875],
           ...,
           [ 1064.0000],
           [ -387.2500],
           [  109.8125]],

          [[  112.8750],
           [  118.1250],
           [   49.3750],
           ...,
           [ 1081.0000],
           [ -388.0000],
           [  109.9375]]],


         [[[   57.4688],
           [   23.8750],
           [   64.7500],
           ...,
           [  250.1250],
           [ -360.2500],
           [  103.5625]],

          [[   58.5312],
           [   25.7188],
           [   64.4375],
           ...,
           [  266.7500],
           [ -360.7500],
           [  103.7500]],

          [[   59.6562],
           [   27.5781],
           [   64.1250],
           ...,
           [  283.5000],
           [ -361.5000],
           [  103.8125]],

          ...,

          [[  110.7500],
           [  114.3750],
           [   49.3125],
           ...,
           [ 1065.0000],
           [ -384.5000],
           [  110.6875]],

          [[  111.8750],
           [  116.1875],
           [   49.0312],
           ...,
           [ 1082.0000],
           [ -385.0000],
           [  110.8125]],

          [[  112.9375],
           [  118.0625],
           [   48.6875],
           ...,
           [ 1099.0000],
           [ -385.5000],
           [  110.9375]]],


         [[[   57.0000],
           [   23.0000],
           [   65.0000],
           ...,
           [  265.0000],
           [ -368.0000],
           [  104.0000]],

          [[   58.0938],
           [   24.8594],
           [   64.6875],
           ...,
           [  281.7500],
           [ -368.2500],
           [  104.1875]],

          [[   59.1875],
           [   26.7344],
           [   64.3750],
           ...,
           [  298.5000],
           [ -368.7500],
           [  104.3125]],

          ...,

          [[  110.8125],
           [  114.2500],
           [   48.6562],
           ...,
           [ 1083.0000],
           [ -382.5000],
           [  111.6875]],

          [[  111.9375],
           [  116.1250],
           [   48.3438],
           ...,
           [ 1100.0000],
           [ -382.7500],
           [  111.8750]],

          [[  113.0000],
           [  118.0000],
           [   48.0000],
           ...,
           [ 1117.0000],
           [ -383.0000],
           [  112.0000]]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 87, 52, 118, 1]), dtype=torch.float16)
tensor([[[[[ 97.0000],
           [ 98.0000],
           [ 40.0000],
           ...,
           [ 18.0000],
           [115.0000],
           [ 68.0000]],

          [[ 97.1875],
           [ 98.5000],
           [ 41.3125],
           ...,
           [ 17.7812],
           [112.8125],
           [ 67.1250]],

          [[ 97.3750],
           [ 98.9375],
           [ 42.6250],
           ...,
           [ 17.5625],
           [110.6250],
           [ 66.2500]],

          ...,

          [[106.6250],
           [121.0625],
           [104.3750],
           ...,
           [  7.4297],
           [  8.3516],
           [ 24.7656]],

          [[106.8125],
           [121.5000],
           [105.6875],
           ...,
           [  7.2148],
           [  6.1758],
           [ 23.8750]],

          [[107.0000],
           [122.0000],
           [107.0000],
           ...,
           [  7.0000],
           [  4.0000],
           [ 23.0000]]],


         [[[ 96.5625],
           [ 97.1250],
           [ 40.2812],
           ...,
           [ 18.1562],
           [114.2500],
           [ 68.3750]],

          [[ 96.7500],
           [ 97.6250],
           [ 41.5938],
           ...,
           [ 17.9531],
           [112.1250],
           [ 67.5000]],

          [[ 96.9375],
           [ 98.1250],
           [ 42.8750],
           ...,
           [ 17.7656],
           [109.9375],
           [ 66.6250]],

          ...,

          [[106.6875],
           [121.0000],
           [103.7500],
           ...,
           [  8.6562],
           [  8.2891],
           [ 25.7656]],

          [[106.8750],
           [121.4375],
           [105.0000],
           ...,
           [  8.4609],
           [  6.1289],
           [ 24.8906]],

          [[107.0625],
           [121.9375],
           [106.3125],
           ...,
           [  8.2656],
           [  3.9648],
           [ 24.0156]]],


         [[[ 96.0625],
           [ 96.2500],
           [ 40.5938],
           ...,
           [ 18.2969],
           [113.5625],
           [ 68.8125]],

          [[ 96.3125],
           [ 96.7500],
           [ 41.8438],
           ...,
           [ 18.1250],
           [111.3750],
           [ 67.9375]],

          [[ 96.5000],
           [ 97.2500],
           [ 43.1250],
           ...,
           [ 17.9531],
           [109.2500],
           [ 67.0625]],

          ...,

          [[106.6875],
           [120.8750],
           [103.0625],
           ...,
           [  9.8750],
           [  8.2266],
           [ 26.7656]],

          [[106.9375],
           [121.3750],
           [104.3750],
           ...,
           [  9.7031],
           [  6.0781],
           [ 25.9062]],

          [[107.1250],
           [121.9375],
           [105.6250],
           ...,
           [  9.5312],
           [  3.9297],
           [ 25.0469]]],


         ...,


         [[[ 57.9375],
           [ 24.7500],
           [ 64.4375],
           ...,
           [ 30.7031],
           [ 53.4688],
           [101.1875]],

          [[ 59.0000],
           [ 26.5781],
           [ 64.1250],
           ...,
           [ 32.3125],
           [ 52.4375],
           [101.3750]],

          [[ 60.0938],
           [ 28.4062],
           [ 63.8438],
           ...,
           [ 33.9375],
           [ 51.4062],
           [101.5000]],

          ...,

          [[110.6875],
           [114.4375],
           [ 49.9688],
           ...,
           [110.2500],
           [  3.1250],
           [108.6250]],

          [[111.8125],
           [116.2500],
           [ 49.6562],
           ...,
           [111.8125],
           [  2.0977],
           [108.8125]],

          [[112.8750],
           [118.0625],
           [ 49.3750],
           ...,
           [113.4375],
           [  1.0693],
           [108.9375]]],


         [[[ 57.4688],
           [ 23.8750],
           [ 64.6875],
           ...,
           [ 30.8438],
           [ 52.7188],
           [101.6250]],

          [[ 58.5625],
           [ 25.7188],
           [ 64.3750],
           ...,
           [ 32.5000],
           [ 51.7188],
           [101.7500]],

          [[ 59.6250],
           [ 27.5625],
           [ 64.0625],
           ...,
           [ 34.1250],
           [ 50.7188],
           [101.9375]],

          ...,

          [[110.7500],
           [114.3750],
           [ 49.3125],
           ...,
           [111.4375],
           [  3.0625],
           [109.6250]],

          [[111.8125],
           [116.1875],
           [ 49.0000],
           ...,
           [113.0625],
           [  2.0488],
           [109.8125]],

          [[112.9375],
           [118.0625],
           [ 48.6875],
           ...,
           [114.7500],
           [  1.0352],
           [110.0000]]],


         [[[ 57.0000],
           [ 23.0000],
           [ 65.0000],
           ...,
           [ 31.0000],
           [ 52.0000],
           [102.0000]],

          [[ 58.0938],
           [ 24.8594],
           [ 64.6875],
           ...,
           [ 32.6562],
           [ 51.0000],
           [102.1875]],

          [[ 59.1875],
           [ 26.7188],
           [ 64.3125],
           ...,
           [ 34.3438],
           [ 50.0000],
           [102.3750]],

          ...,

          [[110.8125],
           [114.2500],
           [ 48.6562],
           ...,
           [112.6875],
           [  3.0000],
           [110.6250]],

          [[111.8750],
           [116.1250],
           [ 48.3438],
           ...,
           [114.3125],
           [  2.0000],
           [110.8125]],

          [[113.0000],
           [118.0000],
           [ 48.0000],
           ...,
           [116.0000],
           [  1.0000],
           [111.0000]]]]], dtype=torch.float16)

2025-07-26 10:04:32.356508 GPU 7 7161 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 2147483649, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bicubic", align_corners=False, align_mode=0, data_format="NHWC", )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /host_home/ningzhengsheng/src/Paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release()
1   phi::DenseTensor::~DenseTensor()
2   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753495529 (unix time) try "date -d @1753495529" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bf9) received by PID 7161 (TID 0x7f4f77335740) from PID 7161 ***]


2025-07-26 13:46:59.259573 GPU 1 18595 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([1014090, 5, 5, 5],"float32"), offset=Tensor([1014090, 90, 5, 5],"float32"), mask=Tensor([1014090, 45, 5, 5],"float32"), weight=Tensor([5, 5, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=5, groups=1, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([1014090, 5, 5, 5],"float32"), offset=Tensor([1014090, 90, 5, 5],"float32"), mask=Tensor([1014090, 45, 5, 5],"float32"), weight=Tensor([5, 5, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=5, groups=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 5 / 2281702500 (0.0%)
Greatest absolute difference: 0.027013687416911125 at index (448642, 58, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (189740, 20, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1014090, 90, 5, 5]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  4.8658e-03,  4.7588e-03, -4.9261e-05],
          [ 5.5794e-05,  3.5899e-06,  9.0910e-03, -1.3478e-03, -3.3371e-03],
          [ 0.0000e+00, -6.4551e-03, -1.3064e-02, -1.4380e-02, -7.3662e-03],
          [ 1.2794e-04,  3.1503e-04, -1.9014e-03,  1.4721e-02,  6.0602e-03],
          [-5.6147e-03, -5.5020e-03, -3.1787e-03,  1.1379e-02, -1.6013e-03]],

         [[ 0.0000e+00,  0.0000e+00, -1.8015e-02, -5.5430e-04,  1.5897e-06],
          [ 1.3100e-04,  6.6789e-06, -1.9658e-02,  1.6789e-03,  3.2792e-03],
          [ 0.0000e+00,  3.1787e-04,  7.0778e-03,  2.3490e-02,  3.0416e-02],
          [-8.2850e-04, -2.1675e-04, -8.2854e-04, -1.2619e-03, -1.1660e-02],
          [-9.7063e-03,  2.1884e-03,  4.1133e-03, -6.9551e-03,  1.8188e-04]],

         [[-4.1381e-03, -5.8289e-04,  1.2238e-02,  0.0000e+00,  1.7827e-04],
          [ 2.4670e-02, -3.0495e-03,  3.5974e-02,  9.6017e-03, -4.0729e-03],
          [ 1.8156e-03, -3.2396e-03,  1.5421e-02, -1.6244e-02, -6.3938e-03],
          [ 3.6001e-03, -6.9170e-03,  1.1133e-02,  7.3138e-04,  2.5794e-03],
          [ 3.9836e-03, -7.3478e-03, -2.5669e-03,  2.8502e-03,  1.5848e-04]],

         ...,

         [[-7.5649e-04,  3.7865e-02,  8.8910e-03,  2.2065e-03,  7.4080e-04],
          [ 4.5058e-04,  5.5127e-03,  5.9845e-04,  2.8562e-02, -2.6789e-02],
          [-4.9090e-04, -7.3323e-03, -1.6451e-03,  5.3842e-03,  3.2646e-03],
          [-6.3439e-04,  1.4323e-03, -4.0095e-02, -1.6226e-02,  6.5238e-03],
          [ 4.4740e-06, -1.2815e-03,  0.0000e+00, -3.3047e-04,  3.7273e-04]],

         [[-2.5215e-02, -1.7371e-03, -5.2992e-05,  1.4717e-03, -1.2013e-03],
          [ 1.0889e-02, -5.8447e-04, -1.3792e-02, -1.1813e-03,  5.1324e-03],
          [-8.9615e-03, -9.7299e-04,  1.1494e-03, -1.3163e-03,  0.0000e+00],
          [ 7.3953e-04,  2.1068e-03, -4.8522e-04, -2.3927e-03,  0.0000e+00],
          [ 0.0000e+00,  3.7959e-03,  2.6027e-04, -1.6459e-02,  0.0000e+00]],

         [[ 2.7372e-02,  6.3297e-03, -3.2483e-05,  3.0926e-03,  4.9088e-04],
          [-4.0157e-03,  3.0638e-03,  1.2887e-03, -5.3679e-03, -7.0350e-03],
          [-1.5310e-02,  6.5571e-03, -4.9673e-05,  1.7783e-03,  0.0000e+00],
          [ 2.8013e-03, -1.8545e-03,  3.2184e-03,  2.6371e-03,  0.0000e+00],
          [ 0.0000e+00,  1.7923e-03,  1.7504e-04, -5.1412e-03,  0.0000e+00]]],


        [[[ 0.0000e+00,  2.8679e-04,  0.0000e+00,  0.0000e+00, -3.0783e-04],
          [ 5.8920e-04, -4.2482e-03, -1.1249e-02,  5.9747e-05, -6.6352e-04],
          [ 0.0000e+00, -3.4945e-02, -5.1967e-03,  3.0698e-03, -1.9360e-03],
          [ 0.0000e+00,  6.0152e-03, -9.8380e-03,  5.6698e-03,  7.3005e-04],
          [-3.6717e-04,  4.9462e-03,  7.4799e-03, -1.3005e-03, -3.8283e-03]],

         [[ 0.0000e+00, -7.9964e-05,  0.0000e+00,  0.0000e+00, -8.2606e-03],
          [ 2.1149e-03, -9.6683e-03,  1.7339e-03, -1.4701e-03, -7.1319e-03],
          [ 0.0000e+00,  3.6207e-05, -1.7651e-03, -2.8452e-02, -3.9437e-03],
          [ 0.0000e+00, -3.6065e-02, -1.3329e-02,  1.2842e-02,  2.0877e-04],
          [ 2.8212e-03, -9.3598e-03, -1.0875e-03, -1.8319e-04, -2.2861e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1003e-03,  0.0000e+00],
          [ 5.7518e-03,  9.5581e-03,  1.0178e-03,  1.8620e-02,  3.4324e-03],
          [ 6.9390e-03, -2.5732e-02, -1.0241e-02,  1.1040e-02,  5.9381e-03],
          [-4.0264e-03,  3.4342e-02, -5.2956e-03,  3.1213e-02,  3.8408e-03],
          [ 5.5463e-03, -3.9980e-03, -1.0799e-04, -6.7229e-04, -1.1825e-02]],

         ...,

         [[ 1.1124e-03,  3.2343e-04,  9.3711e-04, -3.8243e-03, -9.7269e-03],
          [ 3.3082e-04,  9.9170e-03, -1.2232e-02,  2.3030e-03,  9.5987e-03],
          [ 2.4139e-05, -9.6522e-04,  6.4446e-02,  1.4888e-02, -1.2178e-03],
          [-1.0201e-02,  3.9039e-03, -6.7823e-03,  2.2746e-02,  1.1176e-02],
          [-4.9554e-03,  0.0000e+00, -1.1797e-04,  0.0000e+00, -1.2732e-03]],

         [[ 1.0122e-02, -4.0419e-03, -4.5781e-04, -3.6484e-03,  0.0000e+00],
          [ 5.1928e-04, -2.6662e-02, -9.1895e-03,  3.4599e-03,  0.0000e+00],
          [ 1.7493e-04, -4.7580e-04, -4.4344e-05,  6.3062e-04, -1.9363e-06],
          [-1.5905e-04,  2.4849e-03,  3.4788e-03, -3.1646e-03,  0.0000e+00],
          [-8.9984e-03, -6.4189e-03, -2.4861e-03,  0.0000e+00, -2.3116e-04]],

         [[-9.2022e-03, -2.8796e-03,  9.7596e-04,  2.5974e-03,  0.0000e+00],
          [ 7.2643e-04,  3.2826e-03, -1.2028e-02, -6.6186e-03,  0.0000e+00],
          [-8.0255e-04,  6.8648e-04, -8.8143e-05,  2.6578e-04, -2.1476e-05],
          [ 7.2063e-04, -3.5305e-03, -4.6586e-03, -2.3551e-03,  0.0000e+00],
          [ 5.0968e-03, -5.3685e-04,  5.0500e-03,  0.0000e+00, -6.1209e-03]]],


        [[[ 0.0000e+00, -6.7623e-03,  7.5652e-03,  3.1890e-02,  0.0000e+00],
          [ 0.0000e+00,  2.6852e-02,  1.6005e-04, -4.5417e-02, -7.5493e-04],
          [ 0.0000e+00, -3.0681e-03,  1.2589e-03,  1.6748e-02, -3.8512e-04],
          [ 0.0000e+00,  1.2503e-02,  2.2198e-03,  1.5902e-05,  1.7822e-02],
          [-2.4016e-03, -2.7986e-02, -1.2092e-04, -1.2807e-04,  1.2050e-04]],

         [[ 0.0000e+00,  2.8148e-03,  8.9748e-04,  7.2712e-03,  0.0000e+00],
          [ 0.0000e+00, -2.5677e-02, -3.5278e-04,  6.8421e-02,  2.0522e-03],
          [ 0.0000e+00, -2.4869e-03, -3.6615e-03,  9.0288e-03, -3.4962e-04],
          [ 0.0000e+00, -7.5988e-04,  2.5402e-03,  9.4167e-05,  5.8168e-03],
          [-1.5769e-03,  2.6436e-02,  1.7483e-04, -3.7508e-04, -8.0949e-04]],

         [[-1.8048e-03,  8.2446e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-4.1893e-03,  2.8824e-04, -2.1146e-04,  1.8035e-03,  1.6655e-02],
          [-5.9704e-04, -2.0143e-05,  4.3891e-02,  1.9517e-02, -7.4670e-03],
          [-2.5777e-02, -1.5280e-03,  9.9655e-03,  7.6619e-03, -1.5242e-04],
          [ 4.4448e-02,  1.2399e-02, -1.1815e-02,  9.1234e-03,  4.1369e-03]],

         ...,

         [[ 6.1798e-03, -8.7701e-03, -2.1760e-02, -7.1954e-03, -1.7621e-02],
          [-1.3357e-03, -1.0427e-03,  1.6920e-02,  6.4508e-02,  8.9961e-03],
          [-8.1135e-03, -4.3751e-04, -5.1641e-05, -5.7362e-03, -1.7311e-02],
          [-3.4422e-02, -7.1696e-03,  1.4996e-02, -9.5860e-03, -1.7927e-02],
          [ 5.7094e-03, -3.2803e-05,  2.3380e-04,  0.0000e+00,  0.0000e+00]],

         [[ 1.1314e-02, -1.4716e-04,  7.3007e-04,  8.5791e-03,  7.5490e-04],
          [-1.6096e-02, -1.4412e-02, -1.4289e-02,  6.9213e-03,  0.0000e+00],
          [ 3.7865e-03,  4.6950e-03, -5.5093e-03, -4.5942e-04,  0.0000e+00],
          [ 7.7441e-03,  2.5604e-02,  2.4547e-04,  1.3384e-03,  1.5032e-03],
          [ 1.0836e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 7.1073e-03, -9.1846e-04,  3.8728e-03, -1.0320e-02, -5.1577e-03],
          [ 1.5093e-03, -1.0319e-02, -1.2425e-02,  4.6928e-03,  0.0000e+00],
          [ 2.6555e-03, -1.9720e-03,  1.7478e-03, -2.2703e-02,  0.0000e+00],
          [ 1.2782e-03, -2.5626e-02, -2.1157e-04,  4.9269e-02,  4.4768e-03],
          [ 2.1192e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 7.4153e-04,  0.0000e+00,  5.3247e-05,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -8.8886e-04, -3.6546e-04, -1.6424e-04, -3.3745e-03],
          [-1.2484e-03,  2.4957e-03,  3.0723e-04, -3.7343e-04, -3.8520e-02],
          [ 0.0000e+00,  2.5548e-02, -1.3493e-02,  1.7080e-03, -1.4353e-02],
          [ 0.0000e+00, -3.5767e-03,  3.8925e-02,  3.3277e-03, -3.1171e-02]],

         [[ 5.7875e-04,  0.0000e+00,  1.4269e-06,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -7.9402e-04,  3.6649e-05,  1.1026e-03, -1.1904e-02],
          [ 3.9913e-04,  1.5548e-03, -2.6948e-04,  7.0364e-03,  1.7804e-02],
          [ 0.0000e+00, -9.8824e-03,  2.0191e-02, -1.0960e-02,  1.0776e-03],
          [ 0.0000e+00, -2.1693e-03,  4.9756e-04,  3.9746e-04,  1.1288e-02]],

         [[ 0.0000e+00,  0.0000e+00, -9.4185e-05, -8.7652e-05,  0.0000e+00],
          [ 3.0930e-02,  2.1860e-03, -3.9788e-04,  5.0653e-03, -1.8537e-03],
          [-4.8660e-03, -4.1270e-03,  1.7523e-03, -1.6657e-03, -7.0888e-03],
          [ 8.3691e-03,  2.6137e-03, -2.2383e-03,  3.7348e-02, -1.8957e-03],
          [ 1.1311e-02, -6.5135e-03,  2.2372e-02, -1.0169e-02,  2.4038e-03]],

         ...,

         [[ 1.5123e-02, -1.4731e-03, -1.0096e-02,  2.7359e-02,  1.0660e-03],
          [ 2.5319e-03,  8.5594e-03,  5.8241e-04, -1.8687e-04,  1.6162e-03],
          [ 1.6658e-02,  2.2503e-02,  1.7261e-03, -3.7620e-03,  1.9868e-03],
          [-9.4480e-04, -3.6143e-03,  4.0012e-04,  3.2977e-04, -3.2327e-03],
          [-1.0290e-03,  1.1243e-04, -8.3676e-03,  0.0000e+00,  0.0000e+00]],

         [[-2.9136e-04,  2.8265e-03,  3.9042e-03,  2.7870e-03, -3.4923e-03],
          [ 2.4606e-02, -2.9631e-03, -4.9945e-03,  3.3796e-06,  0.0000e+00],
          [-5.6640e-03, -1.1489e-02, -1.0415e-03,  1.7782e-04,  0.0000e+00],
          [-6.4939e-04,  2.6027e-03,  2.4354e-03, -2.1392e-03,  2.1133e-05],
          [ 2.3408e-03,  0.0000e+00,  3.4538e-03, -2.5635e-04,  0.0000e+00]],

         [[-2.4313e-04,  6.0897e-04,  7.2214e-03, -5.8930e-03,  2.3570e-04],
          [-5.1795e-02,  1.8210e-02,  1.0051e-03, -9.7565e-05,  0.0000e+00],
          [-1.4037e-03, -9.8607e-03, -1.6852e-03,  9.5803e-04,  0.0000e+00],
          [ 2.5384e-04,  1.2551e-03,  1.0366e-02, -2.5357e-03,  1.3761e-03],
          [-1.2426e-03,  0.0000e+00, -8.7512e-04, -4.4708e-05,  0.0000e+00]]],


        [[[-1.6718e-03,  0.0000e+00,  0.0000e+00,  9.0853e-03, -2.0271e-03],
          [ 0.0000e+00,  1.1766e-02, -5.1471e-04,  2.8698e-03,  2.2925e-04],
          [-6.9194e-03, -1.7730e-03, -1.4674e-02,  1.1754e-04, -6.0232e-04],
          [-1.0370e-03,  2.0479e-02, -4.0819e-03,  8.2137e-03,  8.9856e-03],
          [ 0.0000e+00,  3.5010e-03, -1.0170e-02, -4.0019e-03,  3.4001e-03]],

         [[-1.7228e-04,  0.0000e+00,  0.0000e+00,  1.1764e-02,  1.8768e-04],
          [ 0.0000e+00, -1.9957e-03, -6.3835e-03, -1.1239e-02,  5.4552e-03],
          [-1.2204e-02, -1.7194e-03,  4.5986e-03, -3.3256e-03, -1.9029e-04],
          [-3.9842e-03,  1.5304e-03,  3.8174e-04, -5.5278e-03, -8.0725e-03],
          [ 0.0000e+00,  6.4544e-03, -1.6260e-02,  3.9054e-04,  1.0217e-03]],

         [[ 6.9236e-03,  0.0000e+00, -2.2745e-03,  0.0000e+00,  0.0000e+00],
          [ 2.1050e-04,  5.7336e-04,  2.4363e-02,  3.7138e-04, -7.9319e-04],
          [-5.7533e-04, -4.8043e-03,  7.8824e-03,  4.3888e-03,  9.9513e-03],
          [-5.0795e-04, -1.6532e-02,  2.1121e-02, -1.9135e-02, -1.1567e-03],
          [-2.9849e-04, -3.2343e-03,  1.4392e-02, -2.3498e-02, -1.4851e-02]],

         ...,

         [[-2.6966e-03, -4.1705e-03, -1.6388e-03,  9.8280e-03,  9.6080e-04],
          [ 3.1930e-02, -3.0772e-02, -6.9929e-03, -2.2569e-02,  9.3354e-03],
          [-2.6170e-03,  1.7631e-02,  6.7512e-03, -8.0828e-02,  1.8253e-02],
          [ 3.0209e-04,  1.2413e-02, -5.4322e-02,  2.2806e-02, -3.2674e-02],
          [-1.3625e-04,  0.0000e+00, -1.6395e-03,  1.4241e-02, -3.1429e-03]],

         [[ 3.1266e-03,  1.4618e-03, -1.9106e-03,  4.1904e-04,  1.5186e-03],
          [ 4.3942e-04,  2.3971e-03, -3.3098e-03,  2.8310e-04,  0.0000e+00],
          [ 1.6076e-02, -2.0033e-04,  3.1605e-02,  5.2170e-03,  0.0000e+00],
          [ 7.3581e-03,  8.1427e-04,  5.3397e-04, -4.9693e-03,  3.4906e-03],
          [ 1.5512e-03,  0.0000e+00, -2.1079e-02,  0.0000e+00,  0.0000e+00]],

         [[ 1.4810e-02, -1.2681e-04,  4.6831e-03, -7.1397e-03, -7.4662e-04],
          [-2.4832e-03,  7.5927e-03,  1.3620e-02, -6.9006e-04,  0.0000e+00],
          [-5.1994e-03,  9.7067e-04, -2.1429e-02, -6.4481e-03,  0.0000e+00],
          [-9.6817e-04, -1.7334e-03,  1.5430e-03, -4.4638e-03, -8.7494e-03],
          [ 1.9818e-07,  0.0000e+00, -1.8694e-02,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00, -4.7906e-03,  0.0000e+00,  4.4935e-03, -2.1988e-03],
          [ 7.7863e-04,  9.0410e-05,  5.2891e-02, -6.1434e-03, -1.8323e-03],
          [ 0.0000e+00,  4.1481e-02, -5.0385e-03,  4.9054e-04, -1.2300e-02],
          [ 0.0000e+00,  1.6494e-02,  7.7261e-04, -1.0307e-03, -1.5648e-02],
          [ 1.8692e-04, -5.7323e-03, -2.0788e-03,  3.9637e-03, -6.9458e-03]],

         [[ 0.0000e+00,  6.3366e-04,  0.0000e+00, -2.5451e-03, -1.1733e-03],
          [-4.3794e-03,  2.4843e-04,  1.1069e-01, -1.4231e-02, -1.4287e-03],
          [ 0.0000e+00, -3.7946e-02,  2.5442e-03, -6.4543e-04,  1.1944e-02],
          [ 0.0000e+00,  1.7361e-02, -8.7302e-03, -1.8998e-03,  1.4141e-03],
          [-6.5529e-03, -2.4488e-03, -1.0222e-02,  5.3780e-03,  4.0736e-03]],

         [[ 0.0000e+00, -3.9963e-03, -4.1395e-05,  0.0000e+00,  0.0000e+00],
          [ 4.8567e-02,  8.3273e-03,  4.9294e-04, -5.3040e-03, -1.3665e-03],
          [ 7.8611e-03, -9.2504e-03, -3.3742e-04, -3.3844e-02,  2.0660e-03],
          [ 1.0578e-03, -2.0898e-02, -8.7057e-02,  6.4455e-03, -1.9557e-02],
          [-3.3015e-02,  1.2325e-02, -1.0316e-02, -7.9609e-03,  1.0933e-02]],

         ...,

         [[ 2.1453e-04,  2.1443e-02, -6.7372e-03,  1.3396e-02,  3.3435e-03],
          [ 6.6821e-03,  1.5821e-03, -3.0166e-03,  6.2966e-03,  4.2668e-04],
          [-2.9969e-05, -6.2441e-03, -9.3856e-03, -9.7157e-03,  2.4362e-03],
          [-1.2412e-02,  2.1571e-02, -1.1373e-03, -1.6712e-02, -4.2755e-03],
          [ 0.0000e+00,  5.8628e-03, -4.9015e-03, -2.0431e-03, -6.5420e-05]],

         [[-2.1442e-03,  1.4564e-02,  2.4497e-04,  2.0508e-02,  0.0000e+00],
          [-9.2912e-03, -1.6257e-03, -3.5949e-03, -3.0997e-02,  0.0000e+00],
          [ 3.0139e-04,  5.6057e-03, -1.6494e-02, -7.1188e-04,  0.0000e+00],
          [ 3.6120e-03,  4.3352e-03,  1.3272e-02,  1.0161e-03,  0.0000e+00],
          [ 8.3165e-03,  5.5936e-04,  0.0000e+00,  1.3409e-04,  0.0000e+00]],

         [[-9.7121e-04, -1.3159e-02, -4.9037e-04,  2.3144e-02,  0.0000e+00],
          [ 1.6478e-03, -7.9872e-04,  6.1030e-03,  1.6779e-02,  0.0000e+00],
          [ 3.2452e-04,  2.7947e-02,  1.3547e-02, -3.3658e-03,  0.0000e+00],
          [-4.9069e-03, -4.0425e-03, -5.0237e-03,  4.9727e-03,  0.0000e+00],
          [-2.1899e-03,  1.1752e-04,  0.0000e+00,  8.8728e-05,  0.0000e+00]]]])
DESIRED: (shape=torch.Size([1014090, 90, 5, 5]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  4.8658e-03,  4.7588e-03, -4.9261e-05],
          [ 5.5794e-05,  3.5899e-06,  9.0910e-03, -1.3478e-03, -3.3371e-03],
          [ 0.0000e+00, -6.4551e-03, -1.3064e-02, -1.4380e-02, -7.3662e-03],
          [ 1.2794e-04,  3.1503e-04, -1.9014e-03,  1.4721e-02,  6.0602e-03],
          [-5.6147e-03, -5.5020e-03, -3.1787e-03,  1.1379e-02, -1.6013e-03]],

         [[ 0.0000e+00,  0.0000e+00, -1.8015e-02, -5.5430e-04,  1.5897e-06],
          [ 1.3100e-04,  6.6789e-06, -1.9658e-02,  1.6789e-03,  3.2792e-03],
          [ 0.0000e+00,  3.1787e-04,  7.0778e-03,  2.3490e-02,  3.0416e-02],
          [-8.2850e-04, -2.1675e-04, -8.2854e-04, -1.2619e-03, -1.1660e-02],
          [-9.7063e-03,  2.1884e-03,  4.1133e-03, -6.9551e-03,  1.8188e-04]],

         [[-4.1381e-03, -5.8289e-04,  1.2238e-02,  0.0000e+00,  1.7827e-04],
          [ 2.4670e-02, -3.0495e-03,  3.5974e-02,  9.6017e-03, -4.0729e-03],
          [ 1.8156e-03, -3.2396e-03,  1.5421e-02, -1.6244e-02, -6.3938e-03],
          [ 3.6001e-03, -6.9170e-03,  1.1133e-02,  7.3138e-04,  2.5794e-03],
          [ 3.9836e-03, -7.3478e-03, -2.5669e-03,  2.8502e-03,  1.5848e-04]],

         ...,

         [[-7.5649e-04,  3.7865e-02,  8.8910e-03,  2.2065e-03,  7.4080e-04],
          [ 4.5058e-04,  5.5127e-03,  5.9845e-04,  2.8562e-02, -2.6789e-02],
          [-4.9090e-04, -7.3323e-03, -1.6451e-03,  5.3842e-03,  3.2646e-03],
          [-6.3439e-04,  1.4323e-03, -4.0095e-02, -1.6226e-02,  6.5238e-03],
          [ 4.4740e-06, -1.2815e-03,  0.0000e+00, -3.3047e-04,  3.7273e-04]],

         [[-2.5215e-02, -1.7371e-03, -5.2992e-05,  1.4717e-03, -1.2013e-03],
          [ 1.0889e-02, -5.8447e-04, -1.3792e-02, -1.1813e-03,  5.1324e-03],
          [-8.9615e-03, -9.7299e-04,  1.1494e-03, -1.3163e-03,  0.0000e+00],
          [ 7.3953e-04,  2.1068e-03, -4.8522e-04, -2.3927e-03,  0.0000e+00],
          [ 0.0000e+00,  3.7959e-03,  2.6027e-04, -1.6459e-02,  0.0000e+00]],

         [[ 2.7372e-02,  6.3297e-03, -3.2483e-05,  3.0926e-03,  4.9088e-04],
          [-4.0157e-03,  3.0638e-03,  1.2887e-03, -5.3679e-03, -7.0350e-03],
          [-1.5310e-02,  6.5571e-03, -4.9673e-05,  1.7783e-03,  0.0000e+00],
          [ 2.8013e-03, -1.8545e-03,  3.2184e-03,  2.6371e-03,  0.0000e+00],
          [ 0.0000e+00,  1.7923e-03,  1.7504e-04, -5.1412e-03,  0.0000e+00]]],


        [[[ 0.0000e+00,  2.8679e-04,  0.0000e+00,  0.0000e+00, -3.0783e-04],
          [ 5.8920e-04, -4.2482e-03, -1.1249e-02,  5.9747e-05, -6.6352e-04],
          [ 0.0000e+00, -3.4945e-02, -5.1967e-03,  3.0698e-03, -1.9360e-03],
          [ 0.0000e+00,  6.0152e-03, -9.8380e-03,  5.6698e-03,  7.3005e-04],
          [-3.6717e-04,  4.9462e-03,  7.4799e-03, -1.3005e-03, -3.8283e-03]],

         [[ 0.0000e+00, -7.9964e-05,  0.0000e+00,  0.0000e+00, -8.2606e-03],
          [ 2.1149e-03, -9.6683e-03,  1.7339e-03, -1.4701e-03, -7.1319e-03],
          [ 0.0000e+00,  3.6207e-05, -1.7651e-03, -2.8452e-02, -3.9437e-03],
          [ 0.0000e+00, -3.6065e-02, -1.3329e-02,  1.2842e-02,  2.0877e-04],
          [ 2.8212e-03, -9.3598e-03, -1.0875e-03, -1.8319e-04, -2.2861e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1003e-03,  0.0000e+00],
          [ 5.7518e-03,  9.5581e-03,  1.0178e-03,  1.8620e-02,  3.4324e-03],
          [ 6.9390e-03, -2.5732e-02, -1.0241e-02,  1.1040e-02,  5.9381e-03],
          [-4.0264e-03,  3.4342e-02, -5.2956e-03,  3.1213e-02,  3.8408e-03],
          [ 5.5463e-03, -3.9980e-03, -1.0799e-04, -6.7229e-04, -1.1825e-02]],

         ...,

         [[ 1.1124e-03,  3.2343e-04,  9.3711e-04, -3.8243e-03, -9.7269e-03],
          [ 3.3082e-04,  9.9170e-03, -1.2232e-02,  2.3030e-03,  9.5987e-03],
          [ 2.4139e-05, -9.6522e-04,  6.4446e-02,  1.4888e-02, -1.2178e-03],
          [-1.0201e-02,  3.9039e-03, -6.7823e-03,  2.2746e-02,  1.1176e-02],
          [-4.9554e-03,  0.0000e+00, -1.1797e-04,  0.0000e+00, -1.2732e-03]],

         [[ 1.0122e-02, -4.0419e-03, -4.5781e-04, -3.6484e-03,  0.0000e+00],
          [ 5.1928e-04, -2.6662e-02, -9.1895e-03,  3.4599e-03,  0.0000e+00],
          [ 1.7493e-04, -4.7580e-04, -4.4344e-05,  6.3062e-04, -1.9363e-06],
          [-1.5905e-04,  2.4849e-03,  3.4788e-03, -3.1646e-03,  0.0000e+00],
          [-8.9984e-03, -6.4189e-03, -2.4861e-03,  0.0000e+00, -2.3116e-04]],

         [[-9.2022e-03, -2.8796e-03,  9.7596e-04,  2.5974e-03,  0.0000e+00],
          [ 7.2643e-04,  3.2826e-03, -1.2028e-02, -6.6186e-03,  0.0000e+00],
          [-8.0255e-04,  6.8648e-04, -8.8143e-05,  2.6578e-04, -2.1476e-05],
          [ 7.2063e-04, -3.5305e-03, -4.6586e-03, -2.3551e-03,  0.0000e+00],
          [ 5.0968e-03, -5.3685e-04,  5.0500e-03,  0.0000e+00, -6.1209e-03]]],


        [[[ 0.0000e+00, -6.7623e-03,  7.5652e-03,  3.1890e-02,  0.0000e+00],
          [ 0.0000e+00,  2.6852e-02,  1.6005e-04, -4.5417e-02, -7.5493e-04],
          [ 0.0000e+00, -3.0681e-03,  1.2589e-03,  1.6748e-02, -3.8512e-04],
          [ 0.0000e+00,  1.2503e-02,  2.2198e-03,  1.5902e-05,  1.7822e-02],
          [-2.4016e-03, -2.7986e-02, -1.2092e-04, -1.2807e-04,  1.2050e-04]],

         [[ 0.0000e+00,  2.8148e-03,  8.9748e-04,  7.2712e-03,  0.0000e+00],
          [ 0.0000e+00, -2.5677e-02, -3.5278e-04,  6.8421e-02,  2.0522e-03],
          [ 0.0000e+00, -2.4869e-03, -3.6615e-03,  9.0288e-03, -3.4962e-04],
          [ 0.0000e+00, -7.5988e-04,  2.5402e-03,  9.4167e-05,  5.8168e-03],
          [-1.5769e-03,  2.6436e-02,  1.7483e-04, -3.7508e-04, -8.0949e-04]],

         [[-1.8048e-03,  8.2446e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-4.1893e-03,  2.8824e-04, -2.1146e-04,  1.8035e-03,  1.6655e-02],
          [-5.9704e-04, -2.0143e-05,  4.3891e-02,  1.9517e-02, -7.4670e-03],
          [-2.5777e-02, -1.5280e-03,  9.9655e-03,  7.6619e-03, -1.5242e-04],
          [ 4.4448e-02,  1.2399e-02, -1.1815e-02,  9.1234e-03,  4.1369e-03]],

         ...,

         [[ 6.1798e-03, -8.7701e-03, -2.1760e-02, -7.1954e-03, -1.7621e-02],
          [-1.3357e-03, -1.0427e-03,  1.6920e-02,  6.4508e-02,  8.9961e-03],
          [-8.1135e-03, -4.3751e-04, -5.1641e-05, -5.7362e-03, -1.7311e-02],
          [-3.4422e-02, -7.1696e-03,  1.4996e-02, -9.5860e-03, -1.7927e-02],
          [ 5.7094e-03, -3.2803e-05,  2.3380e-04,  0.0000e+00,  0.0000e+00]],

         [[ 1.1314e-02, -1.4716e-04,  7.3007e-04,  8.5791e-03,  7.5490e-04],
          [-1.6096e-02, -1.4412e-02, -1.4289e-02,  6.9213e-03,  0.0000e+00],
          [ 3.7865e-03,  4.6950e-03, -5.5093e-03, -4.5942e-04,  0.0000e+00],
          [ 7.7441e-03,  2.5604e-02,  2.4547e-04,  1.3384e-03,  1.5032e-03],
          [ 1.0836e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 7.1073e-03, -9.1846e-04,  3.8728e-03, -1.0320e-02, -5.1577e-03],
          [ 1.5093e-03, -1.0319e-02, -1.2425e-02,  4.6928e-03,  0.0000e+00],
          [ 2.6555e-03, -1.9720e-03,  1.7478e-03, -2.2703e-02,  0.0000e+00],
          [ 1.2782e-03, -2.5626e-02, -2.1157e-04,  4.9269e-02,  4.4768e-03],
          [ 2.1192e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 7.4153e-04,  0.0000e+00,  5.3247e-05,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -8.8886e-04, -3.6546e-04, -1.6424e-04, -3.3745e-03],
          [-1.2484e-03,  2.4957e-03,  3.0723e-04, -3.7343e-04, -3.8520e-02],
          [ 0.0000e+00,  2.5548e-02, -1.3493e-02,  1.7080e-03, -1.4353e-02],
          [ 0.0000e+00, -3.5767e-03,  3.8925e-02,  3.3277e-03, -3.1171e-02]],

         [[ 5.7875e-04,  0.0000e+00,  1.4269e-06,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -7.9402e-04,  3.6649e-05,  1.1026e-03, -1.1904e-02],
          [ 3.9913e-04,  1.5548e-03, -2.6948e-04,  7.0364e-03,  1.7804e-02],
          [ 0.0000e+00, -9.8824e-03,  2.0191e-02, -1.0960e-02,  1.0776e-03],
          [ 0.0000e+00, -2.1693e-03,  4.9756e-04,  3.9746e-04,  1.1288e-02]],

         [[ 0.0000e+00,  0.0000e+00, -9.4185e-05, -8.7652e-05,  0.0000e+00],
          [ 3.0930e-02,  2.1860e-03, -3.9788e-04,  5.0653e-03, -1.8537e-03],
          [-4.8660e-03, -4.1270e-03,  1.7523e-03, -1.6657e-03, -7.0888e-03],
          [ 8.3691e-03,  2.6137e-03, -2.2383e-03,  3.7348e-02, -1.8957e-03],
          [ 1.1311e-02, -6.5135e-03,  2.2372e-02, -1.0169e-02,  2.4038e-03]],

         ...,

         [[ 1.5123e-02, -1.4731e-03, -1.0096e-02,  2.7359e-02,  1.0660e-03],
          [ 2.5319e-03,  8.5594e-03,  5.8241e-04, -1.8687e-04,  1.6162e-03],
          [ 1.6658e-02,  2.2503e-02,  1.7261e-03, -3.7620e-03,  1.9868e-03],
          [-9.4480e-04, -3.6143e-03,  4.0012e-04,  3.2977e-04, -3.2327e-03],
          [-1.0290e-03,  1.1243e-04, -8.3676e-03,  0.0000e+00,  0.0000e+00]],

         [[-2.9136e-04,  2.8265e-03,  3.9042e-03,  2.7870e-03, -3.4923e-03],
          [ 2.4606e-02, -2.9631e-03, -4.9945e-03,  3.3796e-06,  0.0000e+00],
          [-5.6640e-03, -1.1489e-02, -1.0415e-03,  1.7782e-04,  0.0000e+00],
          [-6.4939e-04,  2.6027e-03,  2.4354e-03, -2.1392e-03,  2.1133e-05],
          [ 2.3408e-03,  0.0000e+00,  3.4538e-03, -2.5635e-04,  0.0000e+00]],

         [[-2.4313e-04,  6.0897e-04,  7.2214e-03, -5.8930e-03,  2.3570e-04],
          [-5.1795e-02,  1.8210e-02,  1.0051e-03, -9.7565e-05,  0.0000e+00],
          [-1.4037e-03, -9.8607e-03, -1.6852e-03,  9.5803e-04,  0.0000e+00],
          [ 2.5384e-04,  1.2551e-03,  1.0366e-02, -2.5357e-03,  1.3761e-03],
          [-1.2426e-03,  0.0000e+00, -8.7512e-04, -4.4708e-05,  0.0000e+00]]],


        [[[-1.6718e-03,  0.0000e+00,  0.0000e+00,  9.0853e-03, -2.0271e-03],
          [ 0.0000e+00,  1.1766e-02, -5.1471e-04,  2.8698e-03,  2.2925e-04],
          [-6.9194e-03, -1.7730e-03, -1.4674e-02,  1.1754e-04, -6.0232e-04],
          [-1.0370e-03,  2.0479e-02, -4.0819e-03,  8.2137e-03,  8.9856e-03],
          [ 0.0000e+00,  3.5010e-03, -1.0170e-02, -4.0019e-03,  3.4001e-03]],

         [[-1.7228e-04,  0.0000e+00,  0.0000e+00,  1.1764e-02,  1.8768e-04],
          [ 0.0000e+00, -1.9957e-03, -6.3835e-03, -1.1239e-02,  5.4552e-03],
          [-1.2204e-02, -1.7194e-03,  4.5986e-03, -3.3256e-03, -1.9029e-04],
          [-3.9842e-03,  1.5304e-03,  3.8174e-04, -5.5278e-03, -8.0725e-03],
          [ 0.0000e+00,  6.4544e-03, -1.6260e-02,  3.9054e-04,  1.0217e-03]],

         [[ 6.9236e-03,  0.0000e+00, -2.2745e-03,  0.0000e+00,  0.0000e+00],
          [ 2.1050e-04,  5.7336e-04,  2.4363e-02,  3.7138e-04, -7.9319e-04],
          [-5.7533e-04, -4.8043e-03,  7.8824e-03,  4.3888e-03,  9.9513e-03],
          [-5.0795e-04, -1.6532e-02,  2.1121e-02, -1.9135e-02, -1.1567e-03],
          [-2.9849e-04, -3.2343e-03,  1.4392e-02, -2.3498e-02, -1.4851e-02]],

         ...,

         [[-2.6966e-03, -4.1705e-03, -1.6388e-03,  9.8280e-03,  9.6080e-04],
          [ 3.1930e-02, -3.0772e-02, -6.9929e-03, -2.2569e-02,  9.3354e-03],
          [-2.6170e-03,  1.7631e-02,  6.7512e-03, -8.0828e-02,  1.8253e-02],
          [ 3.0209e-04,  1.2413e-02, -5.4322e-02,  2.2806e-02, -3.2674e-02],
          [-1.3625e-04,  0.0000e+00, -1.6395e-03,  1.4241e-02, -3.1429e-03]],

         [[ 3.1266e-03,  1.4618e-03, -1.9106e-03,  4.1904e-04,  1.5186e-03],
          [ 4.3942e-04,  2.3971e-03, -3.3098e-03,  2.8310e-04,  0.0000e+00],
          [ 1.6076e-02, -2.0033e-04,  3.1605e-02,  5.2170e-03,  0.0000e+00],
          [ 7.3581e-03,  8.1427e-04,  5.3397e-04, -4.9693e-03,  3.4906e-03],
          [ 1.5512e-03,  0.0000e+00, -2.1079e-02,  0.0000e+00,  0.0000e+00]],

         [[ 1.4810e-02, -1.2681e-04,  4.6831e-03, -7.1397e-03, -7.4662e-04],
          [-2.4832e-03,  7.5927e-03,  1.3620e-02, -6.9006e-04,  0.0000e+00],
          [-5.1994e-03,  9.7067e-04, -2.1429e-02, -6.4481e-03,  0.0000e+00],
          [-9.6817e-04, -1.7334e-03,  1.5430e-03, -4.4638e-03, -8.7494e-03],
          [ 1.9818e-07,  0.0000e+00, -1.8694e-02,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00, -4.7906e-03,  0.0000e+00,  4.4935e-03, -2.1988e-03],
          [ 7.7863e-04,  9.0410e-05,  5.2891e-02, -6.1434e-03, -1.8323e-03],
          [ 0.0000e+00,  4.1481e-02, -5.0385e-03,  4.9054e-04, -1.2300e-02],
          [ 0.0000e+00,  1.6494e-02,  7.7261e-04, -1.0307e-03, -1.5648e-02],
          [ 1.8692e-04, -5.7323e-03, -2.0788e-03,  3.9637e-03, -6.9458e-03]],

         [[ 0.0000e+00,  6.3366e-04,  0.0000e+00, -2.5451e-03, -1.1733e-03],
          [-4.3794e-03,  2.4843e-04,  1.1069e-01, -1.4231e-02, -1.4287e-03],
          [ 0.0000e+00, -3.7946e-02,  2.5442e-03, -6.4543e-04,  1.1944e-02],
          [ 0.0000e+00,  1.7361e-02, -8.7302e-03, -1.8998e-03,  1.4141e-03],
          [-6.5529e-03, -2.4488e-03, -1.0222e-02,  5.3780e-03,  4.0736e-03]],

         [[ 0.0000e+00, -3.9963e-03, -4.1395e-05,  0.0000e+00,  0.0000e+00],
          [ 4.8567e-02,  8.3273e-03,  4.9294e-04, -5.3040e-03, -1.3665e-03],
          [ 7.8611e-03, -9.2504e-03, -3.3742e-04, -3.3844e-02,  2.0660e-03],
          [ 1.0578e-03, -2.0898e-02, -8.7057e-02,  6.4455e-03, -1.9557e-02],
          [-3.3015e-02,  1.2325e-02, -1.0316e-02, -7.9609e-03,  1.0933e-02]],

         ...,

         [[ 2.1453e-04,  2.1443e-02, -6.7372e-03,  1.3396e-02,  3.3435e-03],
          [ 6.6821e-03,  1.5821e-03, -3.0166e-03,  6.2966e-03,  4.2668e-04],
          [-2.9969e-05, -6.2441e-03, -9.3856e-03, -9.7157e-03,  2.4362e-03],
          [-1.2412e-02,  2.1571e-02, -1.1373e-03, -1.6712e-02, -4.2755e-03],
          [ 0.0000e+00,  5.8628e-03, -4.9015e-03, -2.0431e-03, -6.5420e-05]],

         [[-2.1442e-03,  1.4564e-02,  2.4497e-04,  2.0508e-02,  0.0000e+00],
          [-9.2912e-03, -1.6257e-03, -3.5949e-03, -3.0997e-02,  0.0000e+00],
          [ 3.0139e-04,  5.6057e-03, -1.6494e-02, -7.1188e-04,  0.0000e+00],
          [ 3.6120e-03,  4.3352e-03,  1.3272e-02,  1.0161e-03,  0.0000e+00],
          [ 8.3165e-03,  5.5936e-04,  0.0000e+00,  1.3409e-04,  0.0000e+00]],

         [[-9.7121e-04, -1.3159e-02, -4.9037e-04,  2.3144e-02,  0.0000e+00],
          [ 1.6478e-03, -7.9872e-04,  6.1030e-03,  1.6779e-02,  0.0000e+00],
          [ 3.2452e-04,  2.7947e-02,  1.3547e-02, -3.3658e-03,  0.0000e+00],
          [-4.9069e-03, -4.0425e-03, -5.0237e-03,  4.9727e-03,  0.0000e+00],
          [-2.1899e-03,  1.1752e-04,  0.0000e+00,  8.8728e-05,  0.0000e+00]]]])

2025-07-26 13:47:54.033582 GPU 4 19121 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([14084577, 3, 5, 5],"float32"), offset=Tensor([14084577, 18, 3, 3],"float32"), mask=Tensor([14084577, 9, 3, 3],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([14084577, 3, 5, 5],"float32"), offset=Tensor([14084577, 18, 3, 3],"float32"), mask=Tensor([14084577, 9, 3, 3],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 2281701474 (0.0%)
Greatest absolute difference: 0.05758749321103096 at index (12874039, 7, 1, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (1169984, 1, 2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([14084577, 18, 3, 3]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  3.5636e-03,  0.0000e+00],
          [-4.2469e-03,  2.8648e-02, -1.8555e-02],
          [ 0.0000e+00, -2.5764e-02,  4.0395e-02]],

         [[ 0.0000e+00,  2.0120e-02,  0.0000e+00],
          [ 1.0512e-03,  1.0079e-02,  8.3692e-03],
          [ 0.0000e+00, -1.2932e-02,  1.5139e-02]],

         [[ 0.0000e+00,  0.0000e+00, -3.6221e-02],
          [-3.3227e-02,  2.4957e-03, -6.0005e-03],
          [ 1.4999e-03,  4.3298e-02,  4.4087e-02]],

         ...,

         [[-2.1514e-02, -4.9183e-03, -1.0517e-02],
          [ 9.0691e-02,  8.6717e-03,  3.1378e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.5120e-02, -7.3486e-02,  0.0000e+00],
          [-1.9378e-02, -1.6364e-02, -4.0646e-04],
          [ 0.0000e+00,  0.0000e+00,  1.7972e-03]],

         [[-6.6045e-02, -5.1405e-02,  0.0000e+00],
          [ 1.0755e-02, -2.9901e-02,  2.5162e-03],
          [ 0.0000e+00,  0.0000e+00,  5.4790e-04]]],


        [[[-6.7872e-04,  0.0000e+00, -1.0822e-02],
          [ 0.0000e+00, -1.4820e-02, -2.0555e-03],
          [ 0.0000e+00, -4.0587e-02,  4.2704e-02]],

         [[-3.7137e-03,  0.0000e+00, -2.6247e-03],
          [ 0.0000e+00,  1.4560e-02,  1.4338e-02],
          [ 0.0000e+00, -2.9076e-02, -6.4984e-02]],

         [[ 8.7487e-04,  0.0000e+00,  0.0000e+00],
          [ 4.4274e-02,  3.8597e-03,  9.4926e-04],
          [-1.1089e-02,  6.9555e-03,  2.6949e-02]],

         ...,

         [[-1.3751e-03, -1.6185e-03, -9.2528e-03],
          [ 1.1350e-03,  2.5864e-02, -2.6293e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.4263e-02,  2.5453e-02,  0.0000e+00],
          [-3.9433e-03,  4.6210e-02,  7.0559e-03],
          [-5.5033e-03, -1.1994e-02,  0.0000e+00]],

         [[ 1.0251e-01, -1.4138e-02,  0.0000e+00],
          [ 7.4490e-03, -5.1349e-02, -7.7369e-03],
          [ 7.7076e-03, -2.0436e-02,  0.0000e+00]]],


        [[[ 2.2014e-03,  0.0000e+00, -2.9235e-02],
          [ 0.0000e+00,  3.7764e-02,  2.4420e-02],
          [ 1.5914e-03,  1.9148e-02,  2.9029e-02]],

         [[ 3.9414e-03,  0.0000e+00,  4.6680e-03],
          [ 0.0000e+00, -2.7098e-02, -1.0742e-02],
          [-1.3925e-04, -3.9365e-02,  5.0693e-02]],

         [[-1.2140e-03,  0.0000e+00,  0.0000e+00],
          [ 6.0778e-02, -2.9433e-03,  1.6279e-02],
          [-5.5127e-03,  2.0480e-02, -4.3550e-03]],

         ...,

         [[ 1.2059e-01, -5.2001e-02,  7.3441e-03],
          [-3.4218e-02,  8.5013e-04, -2.7846e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 5.8138e-03,  1.2100e-02,  4.9300e-03],
          [-4.6284e-02, -9.1211e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.3254e-03, -2.7384e-03, -4.4150e-03],
          [ 3.9435e-02, -1.0654e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00, -1.0039e-02,  0.0000e+00],
          [ 0.0000e+00, -2.9562e-02,  3.8277e-02],
          [ 0.0000e+00, -2.0684e-03,  2.5829e-02]],

         [[ 0.0000e+00,  2.2780e-03,  0.0000e+00],
          [ 0.0000e+00,  3.4177e-02, -1.7203e-02],
          [ 0.0000e+00,  1.6492e-03,  1.1305e-02]],

         [[ 0.0000e+00,  0.0000e+00, -3.0242e-02],
          [ 3.1040e-02, -4.3182e-03,  5.8881e-03],
          [-1.0193e-02, -1.5340e-02,  5.0345e-02]],

         ...,

         [[-5.6884e-04,  8.2138e-03, -2.0981e-02],
          [-2.5196e-04, -2.9228e-02,  3.0522e-02],
          [-8.0955e-04, -4.9666e-03,  0.0000e+00]],

         [[ 1.9778e-02, -4.4698e-02,  0.0000e+00],
          [ 1.0716e-02,  5.4906e-02,  0.0000e+00],
          [ 0.0000e+00,  6.6425e-03,  0.0000e+00]],

         [[-2.5995e-02,  2.1285e-03,  0.0000e+00],
          [-7.0401e-03, -1.9186e-02,  0.0000e+00],
          [ 0.0000e+00, -4.7737e-03,  0.0000e+00]]],


        [[[ 8.9014e-04,  0.0000e+00,  2.3266e-02],
          [ 0.0000e+00,  3.3664e-02, -2.6370e-04],
          [ 0.0000e+00, -1.6519e-02,  9.6217e-02]],

         [[ 2.9172e-03,  0.0000e+00, -2.6536e-03],
          [ 0.0000e+00, -3.4883e-03, -5.5848e-04],
          [ 0.0000e+00, -7.2334e-03,  2.7296e-02]],

         [[ 0.0000e+00,  5.5033e-03,  0.0000e+00],
          [-1.2028e-02,  1.4426e-02,  4.9014e-02],
          [-7.8411e-03,  3.1950e-03, -3.1886e-03]],

         ...,

         [[-4.2695e-02, -1.5045e-02, -3.0852e-02],
          [ 3.5913e-03,  1.4372e-02,  6.0966e-02],
          [ 3.9569e-04,  0.0000e+00,  1.0329e-04]],

         [[ 7.2663e-03, -3.9015e-03, -8.8867e-03],
          [-6.7022e-02,  5.7522e-03,  4.8462e-03],
          [ 0.0000e+00,  0.0000e+00,  6.0240e-04]],

         [[ 2.8164e-03, -2.0080e-03, -4.8653e-02],
          [ 3.0972e-02, -2.1287e-02, -6.4769e-03],
          [ 0.0000e+00,  0.0000e+00,  1.4385e-04]]],


        [[[ 0.0000e+00,  9.0402e-04,  0.0000e+00],
          [-1.2975e-03,  1.6439e-02, -9.3381e-03],
          [ 0.0000e+00,  1.6029e-01, -9.9876e-03]],

         [[ 0.0000e+00,  4.4258e-03,  0.0000e+00],
          [-1.3814e-02,  3.7649e-03, -1.4575e-02],
          [ 0.0000e+00,  2.0695e-02,  1.2477e-02]],

         [[ 1.6532e-02, -6.4765e-03,  3.6871e-03],
          [ 1.5587e-03,  2.2740e-02, -4.8883e-03],
          [-2.4921e-02, -4.9407e-02,  1.2454e-02]],

         ...,

         [[ 6.6657e-03,  3.0042e-02,  3.6821e-02],
          [-3.7583e-02,  3.7801e-02,  3.0793e-02],
          [ 4.4159e-04,  0.0000e+00,  0.0000e+00]],

         [[ 4.8827e-02,  1.1251e-02, -6.2639e-03],
          [ 1.0675e-02,  9.9095e-04,  0.0000e+00],
          [-2.9029e-02, -6.5158e-02,  4.8066e-04]],

         [[ 2.0602e-03, -1.2229e-02, -8.5234e-03],
          [-4.4956e-03,  5.5311e-03,  0.0000e+00],
          [ 1.4713e-04, -2.2385e-05,  6.5137e-03]]]])
DESIRED: (shape=torch.Size([14084577, 18, 3, 3]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  3.5636e-03,  0.0000e+00],
          [-4.2469e-03,  2.8648e-02, -1.8555e-02],
          [ 0.0000e+00, -2.5764e-02,  4.0395e-02]],

         [[ 0.0000e+00,  2.0120e-02,  0.0000e+00],
          [ 1.0512e-03,  1.0079e-02,  8.3692e-03],
          [ 0.0000e+00, -1.2932e-02,  1.5139e-02]],

         [[ 0.0000e+00,  0.0000e+00, -3.6221e-02],
          [-3.3227e-02,  2.4957e-03, -6.0005e-03],
          [ 1.4999e-03,  4.3298e-02,  4.4087e-02]],

         ...,

         [[-2.1514e-02, -4.9183e-03, -1.0517e-02],
          [ 9.0691e-02,  8.6717e-03,  3.1378e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.5120e-02, -7.3486e-02,  0.0000e+00],
          [-1.9378e-02, -1.6364e-02, -4.0646e-04],
          [ 0.0000e+00,  0.0000e+00,  1.7972e-03]],

         [[-6.6045e-02, -5.1405e-02,  0.0000e+00],
          [ 1.0755e-02, -2.9901e-02,  2.5162e-03],
          [ 0.0000e+00,  0.0000e+00,  5.4790e-04]]],


        [[[-6.7872e-04,  0.0000e+00, -1.0822e-02],
          [ 0.0000e+00, -1.4820e-02, -2.0555e-03],
          [ 0.0000e+00, -4.0587e-02,  4.2704e-02]],

         [[-3.7137e-03,  0.0000e+00, -2.6247e-03],
          [ 0.0000e+00,  1.4560e-02,  1.4338e-02],
          [ 0.0000e+00, -2.9076e-02, -6.4984e-02]],

         [[ 8.7487e-04,  0.0000e+00,  0.0000e+00],
          [ 4.4274e-02,  3.8597e-03,  9.4926e-04],
          [-1.1089e-02,  6.9555e-03,  2.6949e-02]],

         ...,

         [[-1.3751e-03, -1.6185e-03, -9.2528e-03],
          [ 1.1350e-03,  2.5864e-02, -2.6293e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.4263e-02,  2.5453e-02,  0.0000e+00],
          [-3.9433e-03,  4.6210e-02,  7.0559e-03],
          [-5.5033e-03, -1.1994e-02,  0.0000e+00]],

         [[ 1.0251e-01, -1.4138e-02,  0.0000e+00],
          [ 7.4490e-03, -5.1349e-02, -7.7369e-03],
          [ 7.7076e-03, -2.0436e-02,  0.0000e+00]]],


        [[[ 2.2014e-03,  0.0000e+00, -2.9235e-02],
          [ 0.0000e+00,  3.7764e-02,  2.4420e-02],
          [ 1.5914e-03,  1.9148e-02,  2.9029e-02]],

         [[ 3.9414e-03,  0.0000e+00,  4.6680e-03],
          [ 0.0000e+00, -2.7098e-02, -1.0742e-02],
          [-1.3925e-04, -3.9365e-02,  5.0693e-02]],

         [[-1.2140e-03,  0.0000e+00,  0.0000e+00],
          [ 6.0778e-02, -2.9433e-03,  1.6279e-02],
          [-5.5127e-03,  2.0480e-02, -4.3550e-03]],

         ...,

         [[ 1.2059e-01, -5.2001e-02,  7.3441e-03],
          [-3.4218e-02,  8.5013e-04, -2.7846e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 5.8138e-03,  1.2100e-02,  4.9300e-03],
          [-4.6284e-02, -9.1211e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.3254e-03, -2.7384e-03, -4.4150e-03],
          [ 3.9435e-02, -1.0654e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00, -1.0039e-02,  0.0000e+00],
          [ 0.0000e+00, -2.9562e-02,  3.8277e-02],
          [ 0.0000e+00, -2.0684e-03,  2.5829e-02]],

         [[ 0.0000e+00,  2.2780e-03,  0.0000e+00],
          [ 0.0000e+00,  3.4177e-02, -1.7203e-02],
          [ 0.0000e+00,  1.6492e-03,  1.1305e-02]],

         [[ 0.0000e+00,  0.0000e+00, -3.0242e-02],
          [ 3.1040e-02, -4.3182e-03,  5.8881e-03],
          [-1.0193e-02, -1.5340e-02,  5.0345e-02]],

         ...,

         [[-5.6884e-04,  8.2138e-03, -2.0981e-02],
          [-2.5196e-04, -2.9228e-02,  3.0522e-02],
          [-8.0955e-04, -4.9666e-03,  0.0000e+00]],

         [[ 1.9778e-02, -4.4698e-02,  0.0000e+00],
          [ 1.0716e-02,  5.4906e-02,  0.0000e+00],
          [ 0.0000e+00,  6.6425e-03,  0.0000e+00]],

         [[-2.5995e-02,  2.1285e-03,  0.0000e+00],
          [-7.0401e-03, -1.9186e-02,  0.0000e+00],
          [ 0.0000e+00, -4.7737e-03,  0.0000e+00]]],


        [[[ 8.9014e-04,  0.0000e+00,  2.3266e-02],
          [ 0.0000e+00,  3.3664e-02, -2.6370e-04],
          [ 0.0000e+00, -1.6519e-02,  9.6217e-02]],

         [[ 2.9172e-03,  0.0000e+00, -2.6536e-03],
          [ 0.0000e+00, -3.4883e-03, -5.5848e-04],
          [ 0.0000e+00, -7.2334e-03,  2.7296e-02]],

         [[ 0.0000e+00,  5.5033e-03,  0.0000e+00],
          [-1.2028e-02,  1.4426e-02,  4.9014e-02],
          [-7.8411e-03,  3.1950e-03, -3.1886e-03]],

         ...,

         [[-4.2695e-02, -1.5045e-02, -3.0852e-02],
          [ 3.5913e-03,  1.4372e-02,  6.0966e-02],
          [ 3.9569e-04,  0.0000e+00,  1.0329e-04]],

         [[ 7.2663e-03, -3.9015e-03, -8.8867e-03],
          [-6.7022e-02,  5.7522e-03,  4.8462e-03],
          [ 0.0000e+00,  0.0000e+00,  6.0240e-04]],

         [[ 2.8164e-03, -2.0080e-03, -4.8653e-02],
          [ 3.0972e-02, -2.1287e-02, -6.4769e-03],
          [ 0.0000e+00,  0.0000e+00,  1.4385e-04]]],


        [[[ 0.0000e+00,  9.0402e-04,  0.0000e+00],
          [-1.2975e-03,  1.6439e-02, -9.3381e-03],
          [ 0.0000e+00,  1.6029e-01, -9.9876e-03]],

         [[ 0.0000e+00,  4.4258e-03,  0.0000e+00],
          [-1.3814e-02,  3.7649e-03, -1.4575e-02],
          [ 0.0000e+00,  2.0695e-02,  1.2477e-02]],

         [[ 1.6532e-02, -6.4765e-03,  3.6871e-03],
          [ 1.5587e-03,  2.2740e-02, -4.8883e-03],
          [-2.4921e-02, -4.9407e-02,  1.2454e-02]],

         ...,

         [[ 6.6657e-03,  3.0042e-02,  3.6821e-02],
          [-3.7583e-02,  3.7801e-02,  3.0793e-02],
          [ 4.4159e-04,  0.0000e+00,  0.0000e+00]],

         [[ 4.8827e-02,  1.1251e-02, -6.2639e-03],
          [ 1.0675e-02,  9.9095e-04,  0.0000e+00],
          [-2.9029e-02, -6.5158e-02,  4.8066e-04]],

         [[ 2.0602e-03, -1.2229e-02, -8.5234e-03],
          [-4.4956e-03,  5.5311e-03,  0.0000e+00],
          [ 1.4713e-04, -2.2385e-05,  6.5137e-03]]]])

2025-07-26 13:48:57.678268 GPU 6 14613 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([2586964, 3, 5, 5],"float32"), offset=Tensor([2586964, 18, 7, 7],"float32"), mask=Tensor([2586964, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([2586964, 3, 5, 5],"float32"), offset=Tensor([2586964, 18, 7, 7],"float32"), mask=Tensor([2586964, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 2281702248 (0.0%)
Greatest absolute difference: 0.12616747617721558 at index (131429, 8, 0, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (131429, 8, 0, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2586964, 18, 7, 7]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  3.7477e-04,  ..., -1.4767e-02,  3.6817e-03,  2.1210e-02],
          [ 0.0000e+00,  0.0000e+00, -4.0238e-03,  ...,  2.2728e-02,  1.0194e-01, -1.5105e-03],
          ...,
          [ 0.0000e+00, -1.5836e-02, -3.0909e-02,  ..., -3.7740e-03,  3.5005e-02, -5.9038e-03],
          [ 0.0000e+00, -1.5703e-02,  9.7374e-03,  ..., -1.5659e-03, -2.5295e-02, -4.0359e-03],
          [ 0.0000e+00,  0.0000e+00, -3.9852e-03,  ...,  1.4914e-02,  2.2321e-03, -9.9806e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.7495e-05,  ..., -2.4471e-02,  1.7443e-04, -8.3984e-03],
          [ 0.0000e+00,  0.0000e+00, -7.4370e-03,  ...,  3.1995e-02, -4.9427e-02,  2.2810e-03],
          ...,
          [ 0.0000e+00, -2.7607e-02, -2.3483e-02,  ...,  3.0443e-02,  2.7252e-02,  7.5339e-03],
          [ 0.0000e+00, -4.6493e-02, -1.7889e-02,  ...,  2.6383e-02,  1.8941e-02, -9.3077e-03],
          [ 0.0000e+00,  0.0000e+00,  4.0641e-03,  ..., -2.3758e-02,  8.1521e-03, -1.2475e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.1866e-04,  ...,  3.7901e-02,  2.4852e-03,  0.0000e+00],
          [-3.8408e-02, -1.2225e-01, -2.1541e-02,  ..., -2.2492e-02,  1.7274e-02,  1.9202e-03],
          ...,
          [-3.1585e-03, -5.4631e-02, -1.0525e-02,  ...,  1.0915e-02, -3.8750e-02,  0.0000e+00],
          [ 0.0000e+00, -3.1533e-03,  8.8549e-04,  ..., -1.1803e-02, -1.9831e-02,  9.3064e-03],
          [-4.3531e-04, -3.0624e-03, -5.4055e-03,  ...,  1.1308e-03,  3.8462e-05,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  4.4577e-03, -1.2857e-02,  ...,  6.3659e-03,  5.2055e-05, -1.3171e-02],
          [ 3.2537e-03, -2.0552e-02, -8.9852e-02,  ...,  7.2825e-02,  3.2091e-03,  0.0000e+00],
          [ 0.0000e+00, -2.5106e-03,  1.4743e-02,  ..., -4.1848e-02, -4.8150e-02,  0.0000e+00],
          ...,
          [-1.8606e-03,  1.7459e-02,  1.6647e-03,  ...,  1.0702e-02, -9.9582e-04,  6.3151e-03],
          [ 0.0000e+00,  0.0000e+00, -1.3830e-02,  ...,  0.0000e+00, -1.1170e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.6422e-02, -3.1156e-02,  4.0048e-03,  ...,  1.4524e-02, -7.2413e-03,  0.0000e+00],
          [ 4.9232e-02,  1.1750e-02,  1.7227e-02,  ...,  1.9019e-02,  0.0000e+00,  0.0000e+00],
          [ 8.0841e-02, -1.5276e-02,  1.1882e-02,  ...,  3.6855e-03, -3.8084e-02,  0.0000e+00],
          ...,
          [-9.9662e-02, -6.0313e-03, -6.7793e-05,  ..., -5.8791e-03, -8.9603e-05,  0.0000e+00],
          [-5.0877e-03,  0.0000e+00,  0.0000e+00,  ..., -5.3621e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.7658e-03,  8.9237e-02, -2.9443e-03,  ...,  8.0985e-03,  2.0483e-02,  0.0000e+00],
          [ 2.7468e-02,  1.7808e-02,  1.0607e-02,  ...,  3.1219e-02,  0.0000e+00,  0.0000e+00],
          [-7.4617e-02, -9.9613e-03, -1.9228e-02,  ..., -8.5681e-03,  2.1983e-02,  0.0000e+00],
          ...,
          [-5.2770e-02,  2.5221e-02, -1.1025e-03,  ..., -1.1923e-02, -1.9585e-02,  0.0000e+00],
          [ 1.8221e-04,  0.0000e+00,  0.0000e+00,  ...,  1.1838e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.4930e-02,  0.0000e+00,  ..., -6.1735e-03,  0.0000e+00,  8.9426e-04],
          [ 0.0000e+00,  7.4799e-03, -3.9793e-02,  ...,  6.2272e-02, -1.8489e-01,  3.6660e-02],
          ...,
          [ 0.0000e+00, -1.7051e-03,  4.4716e-03,  ..., -5.4003e-02, -4.3593e-02,  3.6362e-02],
          [ 0.0000e+00,  2.2605e-03, -5.3650e-02,  ..., -1.8759e-02,  2.1417e-02, -3.0083e-02],
          [ 0.0000e+00,  0.0000e+00, -4.1333e-03,  ..., -3.4219e-03, -1.9373e-02,  7.6294e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -5.0987e-03,  0.0000e+00,  ...,  3.2892e-03,  0.0000e+00, -8.1710e-06],
          [ 0.0000e+00,  2.2816e-02, -1.1095e-02,  ...,  2.2317e-02, -1.1073e-01, -3.5041e-02],
          ...,
          [ 0.0000e+00, -2.1322e-02, -2.0875e-03,  ...,  1.9818e-02,  1.0053e-02,  3.6261e-03],
          [ 0.0000e+00, -2.9740e-02,  3.6154e-02,  ..., -8.3239e-03, -3.2650e-03, -1.3326e-02],
          [ 0.0000e+00,  0.0000e+00, -1.3005e-02,  ..., -4.7855e-03,  1.6877e-02,  3.2722e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.9985e-03, -4.9425e-03,  5.3700e-04,  ..., -1.4000e-02, -9.7302e-03,  0.0000e+00],
          [ 0.0000e+00, -1.6134e-02, -1.7872e-01,  ..., -9.7696e-03,  1.5077e-02,  0.0000e+00],
          ...,
          [-6.5963e-03, -3.1617e-02, -1.0044e-02,  ..., -6.1577e-03,  4.9603e-03,  0.0000e+00],
          [ 0.0000e+00, -3.7409e-02,  2.2481e-04,  ...,  9.0106e-03, -4.9316e-02, -1.6403e-03],
          [ 0.0000e+00,  1.1550e-01, -3.6088e-02,  ..., -1.1112e-02, -3.2165e-02,  0.0000e+00]],

         ...,

         [[-8.4609e-02, -2.0117e-04, -4.3768e-03,  ..., -1.0209e-01, -6.1756e-02,  0.0000e+00],
          [-2.2426e-02,  6.1805e-02,  5.9464e-03,  ..., -4.5278e-02, -3.3354e-03,  1.0794e-02],
          [ 0.0000e+00,  2.1004e-03, -4.8362e-04,  ..., -3.4147e-03, -4.9004e-02, -8.4868e-03],
          ...,
          [ 0.0000e+00, -1.5420e-02, -6.6251e-02,  ...,  4.2995e-03, -9.0820e-03,  0.0000e+00],
          [ 1.4069e-04, -8.8922e-03,  2.2486e-03,  ...,  0.0000e+00,  9.5663e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-6.2107e-03, -2.4615e-02, -1.6905e-02,  ..., -3.2792e-03,  1.2695e-02,  0.0000e+00],
          [ 7.9300e-02,  3.8340e-02,  9.3848e-03,  ..., -1.0222e-05,  2.5615e-05,  0.0000e+00],
          [-3.0512e-02,  7.0595e-02,  3.7196e-02,  ...,  6.9454e-03, -2.1781e-03,  0.0000e+00],
          ...,
          [-7.5774e-06, -9.0762e-03, -1.1002e-02,  ..., -2.2690e-02,  1.8306e-04,  0.0000e+00],
          [ 6.6162e-03, -2.1281e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.5474e-02,  1.6358e-02, -5.5549e-03,  ..., -2.6544e-02, -1.7552e-02,  0.0000e+00],
          [-4.8037e-02, -5.7950e-03, -1.8551e-02,  ..., -7.3240e-03, -5.3358e-03,  0.0000e+00],
          [ 1.2807e-03,  2.6906e-02, -2.8917e-02,  ..., -5.5066e-02, -1.9413e-02,  0.0000e+00],
          ...,
          [-3.1830e-03, -1.4259e-02,  3.0720e-03,  ..., -1.4467e-02,  2.3955e-04,  0.0000e+00],
          [ 2.2631e-03,  1.3630e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.6215e-03, -1.0472e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.4330e-03,  ...,  7.4330e-03,  1.0993e-02, -8.7129e-02],
          ...,
          [ 0.0000e+00, -9.0026e-03,  2.4412e-03,  ..., -1.7962e-02,  1.7293e-02,  1.5931e-03],
          [ 0.0000e+00,  0.0000e+00, -1.3230e-02,  ..., -6.1307e-02,  1.0870e-02, -2.5420e-02],
          [ 0.0000e+00,  0.0000e+00,  2.1070e-03,  ...,  8.8273e-02,  5.8868e-02, -1.4112e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.4521e-03,  1.0516e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -4.7458e-03,  ...,  2.2140e-02, -3.5084e-02, -4.8880e-03],
          ...,
          [ 0.0000e+00, -1.5635e-02,  1.3005e-02,  ..., -1.4718e-02,  6.8237e-02,  3.7760e-03],
          [ 0.0000e+00,  0.0000e+00, -2.9509e-02,  ...,  3.2951e-02,  2.5486e-03,  1.1077e-02],
          [ 0.0000e+00,  0.0000e+00, -6.3294e-03,  ..., -1.2925e-02,  2.5630e-02, -8.6666e-04]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.2369e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.1929e-02, -2.0148e-03,  ...,  4.6578e-04, -1.2143e-04, -2.1079e-03],
          ...,
          [-7.1601e-03, -2.0788e-02, -3.7098e-03,  ..., -1.0818e-02,  7.4447e-03,  0.0000e+00],
          [ 8.0969e-03, -9.0674e-03,  2.8273e-03,  ...,  8.5001e-03,  1.9746e-03,  3.1539e-03],
          [ 0.0000e+00, -1.3980e-02, -2.9246e-03,  ...,  3.7897e-03, -1.0334e-02,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -3.8704e-03, -4.0509e-02,  ..., -1.0162e-02, -9.8235e-05,  0.0000e+00],
          [ 0.0000e+00, -1.6586e-02,  4.1327e-02,  ...,  1.2802e-02, -3.9306e-03,  0.0000e+00],
          [ 0.0000e+00, -1.0677e-02, -2.6895e-02,  ...,  2.5251e-03, -1.0262e-02, -1.3573e-02],
          ...,
          [-9.9474e-03, -7.9526e-03,  9.9921e-03,  ..., -1.9283e-03,  1.5881e-03, -2.4996e-03],
          [ 0.0000e+00,  2.6964e-02,  0.0000e+00,  ..., -1.0836e-03,  1.4038e-03,  2.4038e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-2.0401e-02, -4.7873e-04,  1.3635e-04,  ..., -1.4682e-02, -1.1921e-03,  0.0000e+00],
          [-1.3377e-02, -4.8789e-03,  5.5601e-02,  ...,  2.8706e-02,  0.0000e+00,  0.0000e+00],
          [ 5.8726e-03, -2.4174e-02,  6.5463e-03,  ..., -1.2925e-02, -1.5164e-02,  0.0000e+00],
          ...,
          [ 2.9206e-02, -1.1601e-02, -4.6145e-02,  ...,  2.8759e-02,  0.0000e+00,  0.0000e+00],
          [-4.6395e-02, -3.1073e-02,  0.0000e+00,  ...,  1.8170e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 9.1527e-03,  1.8568e-03, -3.3472e-03,  ..., -2.8304e-02,  2.0333e-03,  0.0000e+00],
          [-2.8587e-02, -1.8454e-03,  1.3625e-01,  ...,  1.3631e-02,  0.0000e+00,  0.0000e+00],
          [ 2.6712e-02, -1.9040e-02,  3.1103e-03,  ...,  3.5766e-04, -7.3104e-03,  0.0000e+00],
          ...,
          [ 3.1657e-02, -2.1647e-03,  7.7425e-03,  ...,  4.0862e-02,  0.0000e+00,  0.0000e+00],
          [-8.1216e-03, -1.0096e-03,  0.0000e+00,  ...,  5.9612e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -2.5127e-05,  2.0241e-02,  ...,  0.0000e+00, -1.7650e-03,  0.0000e+00],
          [ 0.0000e+00, -2.7902e-04,  2.5519e-02,  ..., -2.6117e-03,  7.0390e-03, -4.4892e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2404e-02,  ..., -6.5288e-02, -2.2329e-03,  1.0484e-03],
          [ 0.0000e+00, -4.0531e-03,  6.3655e-05,  ..., -1.2984e-02, -1.1100e-02,  1.0939e-01],
          [ 0.0000e+00,  0.0000e+00, -8.0356e-03,  ..., -1.1831e-02,  1.5809e-02,  1.1999e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -3.2960e-03,  2.6543e-03,  ...,  0.0000e+00,  6.1698e-03,  0.0000e+00],
          [ 0.0000e+00, -1.0539e-04,  1.5006e-02,  ..., -3.7343e-03, -2.7750e-03,  3.5457e-03],
          ...,
          [ 0.0000e+00,  0.0000e+00,  1.7806e-03,  ...,  6.6651e-02,  1.8099e-04,  2.8230e-03],
          [ 0.0000e+00,  1.6101e-03,  1.0047e-04,  ..., -3.2475e-02,  1.4378e-02, -7.2385e-02],
          [ 0.0000e+00,  0.0000e+00, -1.0177e-02,  ...,  7.9826e-04,  2.9431e-03,  1.2601e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.9246e-02, -1.2165e-01,  ...,  8.1076e-04, -3.0793e-04,  0.0000e+00],
          [ 0.0000e+00, -2.4016e-02,  8.5764e-04,  ...,  3.1468e-02, -3.2895e-02, -5.6438e-03],
          ...,
          [-1.1845e-04,  1.5732e-02,  1.5368e-02,  ..., -3.1826e-03, -8.9669e-03,  0.0000e+00],
          [ 9.3183e-03, -2.9955e-02, -1.0617e-02,  ...,  8.6321e-03, -4.4170e-03,  2.2404e-02],
          [ 2.9078e-02,  2.1716e-02,  1.8905e-02,  ..., -7.8022e-04, -2.0893e-05,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -6.0303e-03, -2.8968e-02,  ...,  3.4225e-03, -1.1542e-02,  2.5778e-02],
          [ 0.0000e+00,  6.1848e-04,  2.2603e-02,  ..., -6.6239e-03, -1.9764e-03,  0.0000e+00],
          [ 0.0000e+00, -4.8423e-03, -2.6581e-03,  ..., -1.7503e-02,  1.1605e-01, -2.4046e-04],
          ...,
          [-4.1894e-03, -1.8143e-02,  2.1181e-02,  ...,  4.8473e-05, -2.5504e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.9236e-03,  ...,  0.0000e+00,  4.0432e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.4289e-02,  7.3569e-04,  4.5173e-02,  ..., -8.1295e-03,  0.0000e+00,  0.0000e+00],
          [-7.7211e-02, -4.8809e-04,  1.1736e-02,  ...,  3.7611e-02,  0.0000e+00,  0.0000e+00],
          [-2.7306e-03,  1.3421e-02, -8.0465e-02,  ..., -2.2150e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 2.1210e-02, -2.6490e-02,  1.1427e-02,  ...,  4.8394e-03,  0.0000e+00,  0.0000e+00],
          [-1.0156e-02,  3.0119e-02,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.8265e-03, -3.3069e-04,  6.0542e-04,  ..., -3.4135e-03,  0.0000e+00,  0.0000e+00],
          [-1.1420e-02, -6.3695e-05, -7.5346e-04,  ...,  2.1846e-02,  0.0000e+00,  0.0000e+00],
          [ 4.2466e-03,  1.1805e-02, -8.2473e-03,  ...,  1.1375e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 3.1836e-02, -4.5932e-02, -7.3398e-03,  ..., -5.4431e-02,  0.0000e+00,  0.0000e+00],
          [ 5.7150e-03, -3.7042e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -5.9403e-03,  ...,  0.0000e+00, -2.4085e-03,  5.7238e-03],
          [ 0.0000e+00,  1.0028e-05,  2.0448e-02,  ..., -1.4763e-02,  3.6645e-02,  2.6949e-03],
          ...,
          [ 0.0000e+00,  6.7280e-03, -1.4060e-02,  ..., -7.0479e-04,  2.2371e-02,  8.4421e-02],
          [ 0.0000e+00, -1.8624e-02, -3.1967e-03,  ..., -2.5870e-02,  9.3602e-03, -2.3904e-02],
          [ 0.0000e+00,  0.0000e+00,  5.4856e-03,  ..., -1.1150e-02,  9.0915e-04, -9.2491e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.3202e-03,  ...,  0.0000e+00, -1.6785e-04,  5.5315e-04],
          [ 0.0000e+00,  9.2749e-04, -1.2767e-02,  ..., -5.8556e-03, -7.7542e-02, -3.1515e-03],
          ...,
          [ 0.0000e+00,  4.5625e-02, -2.4180e-02,  ...,  1.0936e-03, -5.5921e-02,  7.8524e-02],
          [ 0.0000e+00,  1.3876e-02, -2.0034e-02,  ...,  3.3246e-02, -7.3384e-03, -3.2142e-03],
          [ 0.0000e+00,  0.0000e+00, -3.4031e-03,  ...,  4.1785e-03, -3.9644e-04, -9.6741e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.6846e-03,  0.0000e+00,  ..., -3.9494e-02,  1.4295e-02, -8.7329e-04],
          [-9.2377e-05,  3.0410e-03, -1.4401e-03,  ...,  1.3232e-02, -3.9967e-03, -8.2961e-03],
          ...,
          [ 0.0000e+00, -8.3514e-03, -7.4878e-03,  ..., -1.9997e-02,  3.0674e-03,  1.7394e-03],
          [ 0.0000e+00, -4.1140e-03, -1.5732e-02,  ...,  4.1994e-02,  5.1754e-03, -4.6354e-04],
          [-1.4383e-03,  3.3931e-02, -8.3296e-03,  ..., -1.8466e-04, -9.8652e-03,  1.7408e-04]],

         ...,

         [[ 5.6623e-02,  3.0139e-02,  2.3866e-03,  ...,  8.3747e-03, -1.6619e-02, -8.5007e-04],
          [ 0.0000e+00, -1.2620e-02, -6.5312e-03,  ..., -2.0040e-02, -5.4153e-04, -3.4961e-04],
          [-3.6724e-03, -1.6551e-03,  4.0833e-02,  ..., -4.1201e-02,  6.2010e-03,  0.0000e+00],
          ...,
          [ 0.0000e+00,  1.3773e-03, -6.0097e-03,  ...,  5.2845e-03,  3.5030e-03,  3.7832e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -5.3821e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.5454e-02,  9.3117e-03, -3.6799e-02,  ..., -5.1075e-06, -3.8158e-04,  0.0000e+00],
          [ 5.1438e-02,  5.8007e-02, -5.2211e-03,  ...,  5.9737e-03, -3.1277e-04,  0.0000e+00],
          [-5.0160e-02, -4.3870e-02, -1.3642e-02,  ..., -5.6392e-02,  7.7080e-03,  0.0000e+00],
          ...,
          [ 1.3059e-02, -3.7577e-02, -1.1870e-02,  ..., -6.0825e-03, -7.6904e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -1.0314e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 5.9417e-03, -3.1662e-03, -6.7557e-02,  ...,  9.5015e-07, -2.5761e-04,  0.0000e+00],
          [ 3.5722e-02, -2.3701e-03,  1.3558e-02,  ..., -1.1154e-03,  5.6904e-04,  0.0000e+00],
          [-4.6680e-03,  3.4928e-02,  1.1048e-02,  ..., -5.8465e-02, -2.5062e-02,  0.0000e+00],
          ...,
          [-1.5582e-02, -2.1827e-03, -1.0030e-01,  ..., -3.5994e-03, -1.6353e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -1.5290e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  3.8025e-04, -2.2682e-03,  ..., -2.6453e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.9798e-02,  ...,  1.0067e-02, -6.8130e-03, -1.7465e-04],
          ...,
          [ 0.0000e+00,  0.0000e+00, -9.9627e-03,  ...,  3.1473e-02,  2.2164e-02,  9.0800e-03],
          [ 0.0000e+00,  0.0000e+00, -2.5729e-02,  ...,  3.3294e-02,  1.4384e-03,  4.1804e-03],
          [ 0.0000e+00,  0.0000e+00, -5.0061e-02,  ..., -1.0285e-02,  3.8671e-03, -4.3939e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.0391e-03,  2.3061e-03,  ..., -6.5739e-05,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.7850e-02,  ...,  2.0246e-03,  3.4841e-02, -3.5283e-04],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.0730e-02,  ..., -4.3060e-03,  1.3268e-02, -1.3678e-02],
          [ 0.0000e+00,  0.0000e+00, -4.2467e-02,  ..., -6.0794e-02,  4.3708e-03, -5.5054e-03],
          [ 0.0000e+00,  0.0000e+00, -2.1205e-02,  ..., -1.5386e-03, -7.5460e-03,  2.0564e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  6.5075e-03,  ...,  3.5771e-02, -2.9427e-03,  0.0000e+00],
          [ 1.6223e-03,  4.3728e-03,  3.8093e-03,  ...,  1.3584e-05, -1.7470e-02,  3.3543e-02],
          ...,
          [-9.4788e-03, -1.9396e-02, -2.0349e-02,  ...,  9.7484e-03,  9.1521e-03,  3.6859e-03],
          [ 0.0000e+00,  1.1765e-01,  4.0306e-03,  ..., -2.0251e-03,  3.7622e-02, -9.4596e-03],
          [ 0.0000e+00,  8.9917e-03,  1.1097e-01,  ..., -3.6008e-03,  3.1695e-05,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  1.4689e-03, -6.1996e-03,  ..., -3.1124e-02, -2.7237e-02,  0.0000e+00],
          [ 0.0000e+00, -4.7613e-02,  1.4140e-02,  ...,  2.9212e-02,  1.0522e-03,  9.0411e-04],
          [ 0.0000e+00, -1.4803e-04,  8.7920e-03,  ..., -8.9217e-05,  3.7015e-03, -5.6174e-03],
          ...,
          [ 0.0000e+00,  2.1163e-02,  3.2531e-02,  ...,  1.2515e-03, -1.8240e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.6101e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.1235e-02, -1.6916e-02, -1.0613e-01,  ..., -6.0801e-03,  0.0000e+00,  0.0000e+00],
          [-3.3665e-03, -6.6503e-03, -1.6958e-03,  ...,  1.1206e-02,  0.0000e+00,  0.0000e+00],
          [ 9.2032e-03, -2.5255e-03,  2.3908e-02,  ...,  4.8907e-03, -2.1981e-04,  0.0000e+00],
          ...,
          [-3.7284e-02, -1.3181e-02,  6.3802e-02,  ...,  1.3257e-02,  0.0000e+00,  0.0000e+00],
          [-7.0842e-03, -2.9429e-04, -4.0328e-02,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0010e-02, -1.9438e-02, -2.8443e-03,  ...,  9.3426e-03,  0.0000e+00,  0.0000e+00],
          [ 3.0144e-02,  4.7019e-03, -1.0271e-03,  ..., -1.5519e-02,  0.0000e+00,  0.0000e+00],
          [-2.3748e-02,  3.0951e-03, -2.1265e-02,  ..., -3.1671e-03, -1.2285e-03,  0.0000e+00],
          ...,
          [ 1.4123e-02, -1.6017e-02,  1.4634e-02,  ...,  6.1301e-03,  0.0000e+00,  0.0000e+00],
          [ 1.3481e-03, -6.8071e-03, -1.4418e-02,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])
DESIRED: (shape=torch.Size([2586964, 18, 7, 7]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  3.7477e-04,  ..., -1.4767e-02,  3.6817e-03,  2.1210e-02],
          [ 0.0000e+00,  0.0000e+00, -4.0238e-03,  ...,  2.2728e-02,  1.0194e-01, -1.5105e-03],
          ...,
          [ 0.0000e+00, -1.5836e-02, -3.0909e-02,  ..., -3.7740e-03,  3.5005e-02, -5.9038e-03],
          [ 0.0000e+00, -1.5703e-02,  9.7374e-03,  ..., -1.5659e-03, -2.5295e-02, -4.0359e-03],
          [ 0.0000e+00,  0.0000e+00, -3.9852e-03,  ...,  1.4914e-02,  2.2321e-03, -9.9806e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.7495e-05,  ..., -2.4471e-02,  1.7443e-04, -8.3984e-03],
          [ 0.0000e+00,  0.0000e+00, -7.4370e-03,  ...,  3.1995e-02, -4.9427e-02,  2.2810e-03],
          ...,
          [ 0.0000e+00, -2.7607e-02, -2.3483e-02,  ...,  3.0443e-02,  2.7252e-02,  7.5339e-03],
          [ 0.0000e+00, -4.6493e-02, -1.7889e-02,  ...,  2.6383e-02,  1.8941e-02, -9.3077e-03],
          [ 0.0000e+00,  0.0000e+00,  4.0641e-03,  ..., -2.3758e-02,  8.1521e-03, -1.2475e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.1866e-04,  ...,  3.7901e-02,  2.4852e-03,  0.0000e+00],
          [-3.8408e-02, -1.2225e-01, -2.1541e-02,  ..., -2.2492e-02,  1.7274e-02,  1.9202e-03],
          ...,
          [-3.1585e-03, -5.4631e-02, -1.0525e-02,  ...,  1.0915e-02, -3.8750e-02,  0.0000e+00],
          [ 0.0000e+00, -3.1533e-03,  8.8549e-04,  ..., -1.1803e-02, -1.9831e-02,  9.3064e-03],
          [-4.3531e-04, -3.0624e-03, -5.4055e-03,  ...,  1.1308e-03,  3.8462e-05,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  4.4577e-03, -1.2857e-02,  ...,  6.3659e-03,  5.2054e-05, -1.3171e-02],
          [ 3.2537e-03, -2.0552e-02, -8.9852e-02,  ...,  7.2825e-02,  3.2091e-03,  0.0000e+00],
          [ 0.0000e+00, -2.5106e-03,  1.4743e-02,  ..., -4.1848e-02, -4.8150e-02,  0.0000e+00],
          ...,
          [-1.8606e-03,  1.7459e-02,  1.6647e-03,  ...,  1.0702e-02, -9.9582e-04,  6.3151e-03],
          [ 0.0000e+00,  0.0000e+00, -1.3830e-02,  ...,  0.0000e+00, -1.1170e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.6422e-02, -3.1156e-02,  4.0048e-03,  ...,  1.4524e-02, -7.2413e-03,  0.0000e+00],
          [ 4.9232e-02,  1.1750e-02,  1.7227e-02,  ...,  1.9019e-02,  0.0000e+00,  0.0000e+00],
          [ 8.0841e-02, -1.5276e-02,  1.1882e-02,  ...,  3.6855e-03, -3.8084e-02,  0.0000e+00],
          ...,
          [-9.9662e-02, -6.0313e-03, -6.7793e-05,  ..., -5.8791e-03, -8.9603e-05,  0.0000e+00],
          [-5.0877e-03,  0.0000e+00,  0.0000e+00,  ..., -5.3621e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.7658e-03,  8.9237e-02, -2.9443e-03,  ...,  8.0985e-03,  2.0483e-02,  0.0000e+00],
          [ 2.7468e-02,  1.7808e-02,  1.0607e-02,  ...,  3.1219e-02,  0.0000e+00,  0.0000e+00],
          [-7.4617e-02, -9.9613e-03, -1.9228e-02,  ..., -8.5681e-03,  2.1983e-02,  0.0000e+00],
          ...,
          [-5.2770e-02,  2.5221e-02, -1.1025e-03,  ..., -1.1923e-02, -1.9585e-02,  0.0000e+00],
          [ 1.8221e-04,  0.0000e+00,  0.0000e+00,  ...,  1.1838e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.4930e-02,  0.0000e+00,  ..., -6.1735e-03,  0.0000e+00,  8.9426e-04],
          [ 0.0000e+00,  7.4799e-03, -3.9793e-02,  ...,  6.2272e-02, -1.8489e-01,  3.6660e-02],
          ...,
          [ 0.0000e+00, -1.7051e-03,  4.4716e-03,  ..., -5.4003e-02, -4.3593e-02,  3.6362e-02],
          [ 0.0000e+00,  2.2605e-03, -5.3650e-02,  ..., -1.8759e-02,  2.1417e-02, -3.0083e-02],
          [ 0.0000e+00,  0.0000e+00, -4.1333e-03,  ..., -3.4219e-03, -1.9373e-02,  7.6294e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -5.0987e-03,  0.0000e+00,  ...,  3.2892e-03,  0.0000e+00, -8.1710e-06],
          [ 0.0000e+00,  2.2816e-02, -1.1095e-02,  ...,  2.2317e-02, -1.1073e-01, -3.5041e-02],
          ...,
          [ 0.0000e+00, -2.1322e-02, -2.0875e-03,  ...,  1.9818e-02,  1.0053e-02,  3.6261e-03],
          [ 0.0000e+00, -2.9740e-02,  3.6154e-02,  ..., -8.3239e-03, -3.2650e-03, -1.3326e-02],
          [ 0.0000e+00,  0.0000e+00, -1.3005e-02,  ..., -4.7855e-03,  1.6877e-02,  3.2722e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.9985e-03, -4.9425e-03,  5.3700e-04,  ..., -1.4000e-02, -9.7302e-03,  0.0000e+00],
          [ 0.0000e+00, -1.6134e-02, -1.7872e-01,  ..., -9.7696e-03,  1.5077e-02,  0.0000e+00],
          ...,
          [-6.5963e-03, -3.1617e-02, -1.0044e-02,  ..., -6.1577e-03,  4.9603e-03,  0.0000e+00],
          [ 0.0000e+00, -3.7409e-02,  2.2481e-04,  ...,  9.0106e-03, -4.9316e-02, -1.6403e-03],
          [ 0.0000e+00,  1.1550e-01, -3.6088e-02,  ..., -1.1112e-02, -3.2165e-02,  0.0000e+00]],

         ...,

         [[-8.4610e-02, -2.0117e-04, -4.3768e-03,  ..., -1.0209e-01, -6.1756e-02,  0.0000e+00],
          [-2.2426e-02,  6.1805e-02,  5.9464e-03,  ..., -4.5278e-02, -3.3354e-03,  1.0794e-02],
          [ 0.0000e+00,  2.1004e-03, -4.8362e-04,  ..., -3.4147e-03, -4.9004e-02, -8.4868e-03],
          ...,
          [ 0.0000e+00, -1.5420e-02, -6.6251e-02,  ...,  4.2995e-03, -9.0820e-03,  0.0000e+00],
          [ 1.4069e-04, -8.8922e-03,  2.2486e-03,  ...,  0.0000e+00,  9.5663e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-6.2106e-03, -2.4615e-02, -1.6905e-02,  ..., -3.2792e-03,  1.2695e-02,  0.0000e+00],
          [ 7.9300e-02,  3.8340e-02,  9.3848e-03,  ..., -1.0222e-05,  2.5615e-05,  0.0000e+00],
          [-3.0512e-02,  7.0595e-02,  3.7196e-02,  ...,  6.9454e-03, -2.1781e-03,  0.0000e+00],
          ...,
          [-7.5770e-06, -9.0762e-03, -1.1002e-02,  ..., -2.2690e-02,  1.8306e-04,  0.0000e+00],
          [ 6.6162e-03, -2.1281e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.5474e-02,  1.6358e-02, -5.5549e-03,  ..., -2.6544e-02, -1.7552e-02,  0.0000e+00],
          [-4.8037e-02, -5.7950e-03, -1.8551e-02,  ..., -7.3240e-03, -5.3358e-03,  0.0000e+00],
          [ 1.2807e-03,  2.6906e-02, -2.8917e-02,  ..., -5.5066e-02, -1.9413e-02,  0.0000e+00],
          ...,
          [-3.1830e-03, -1.4259e-02,  3.0720e-03,  ..., -1.4467e-02,  2.3955e-04,  0.0000e+00],
          [ 2.2631e-03,  1.3630e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.6215e-03, -1.0472e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.4330e-03,  ...,  7.4330e-03,  1.0993e-02, -8.7129e-02],
          ...,
          [ 0.0000e+00, -9.0026e-03,  2.4412e-03,  ..., -1.7962e-02,  1.7293e-02,  1.5931e-03],
          [ 0.0000e+00,  0.0000e+00, -1.3230e-02,  ..., -6.1307e-02,  1.0870e-02, -2.5420e-02],
          [ 0.0000e+00,  0.0000e+00,  2.1070e-03,  ...,  8.8273e-02,  5.8868e-02, -1.4112e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.4521e-03,  1.0516e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -4.7458e-03,  ...,  2.2140e-02, -3.5084e-02, -4.8880e-03],
          ...,
          [ 0.0000e+00, -1.5635e-02,  1.3005e-02,  ..., -1.4718e-02,  6.8237e-02,  3.7760e-03],
          [ 0.0000e+00,  0.0000e+00, -2.9509e-02,  ...,  3.2951e-02,  2.5486e-03,  1.1077e-02],
          [ 0.0000e+00,  0.0000e+00, -6.3294e-03,  ..., -1.2925e-02,  2.5630e-02, -8.6666e-04]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.2369e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.1929e-02, -2.0148e-03,  ...,  4.6578e-04, -1.2143e-04, -2.1079e-03],
          ...,
          [-7.1601e-03, -2.0788e-02, -3.7098e-03,  ..., -1.0818e-02,  7.4447e-03,  0.0000e+00],
          [ 8.0969e-03, -9.0674e-03,  2.8273e-03,  ...,  8.5001e-03,  1.9746e-03,  3.1539e-03],
          [ 0.0000e+00, -1.3980e-02, -2.9246e-03,  ...,  3.7897e-03, -1.0334e-02,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -3.8704e-03, -4.0509e-02,  ..., -1.0162e-02, -9.8235e-05,  0.0000e+00],
          [ 0.0000e+00, -1.6586e-02,  4.1327e-02,  ...,  1.2802e-02, -3.9306e-03,  0.0000e+00],
          [ 0.0000e+00, -1.0677e-02, -2.6895e-02,  ...,  2.5251e-03, -1.0262e-02, -1.3573e-02],
          ...,
          [-9.9474e-03, -7.9526e-03,  9.9921e-03,  ..., -1.9283e-03,  1.5881e-03, -2.4996e-03],
          [ 0.0000e+00,  2.6964e-02,  0.0000e+00,  ..., -1.0836e-03,  1.4038e-03,  2.4038e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-2.0401e-02, -4.7873e-04,  1.3635e-04,  ..., -1.4682e-02, -1.1921e-03,  0.0000e+00],
          [-1.3377e-02, -4.8789e-03,  5.5601e-02,  ...,  2.8706e-02,  0.0000e+00,  0.0000e+00],
          [ 5.8726e-03, -2.4174e-02,  6.5463e-03,  ..., -1.2925e-02, -1.5164e-02,  0.0000e+00],
          ...,
          [ 2.9206e-02, -1.1601e-02, -4.6145e-02,  ...,  2.8759e-02,  0.0000e+00,  0.0000e+00],
          [-4.6395e-02, -3.1073e-02,  0.0000e+00,  ...,  1.8170e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 9.1527e-03,  1.8568e-03, -3.3472e-03,  ..., -2.8304e-02,  2.0333e-03,  0.0000e+00],
          [-2.8587e-02, -1.8454e-03,  1.3625e-01,  ...,  1.3631e-02,  0.0000e+00,  0.0000e+00],
          [ 2.6712e-02, -1.9040e-02,  3.1103e-03,  ...,  3.5766e-04, -7.3104e-03,  0.0000e+00],
          ...,
          [ 3.1657e-02, -2.1647e-03,  7.7425e-03,  ...,  4.0862e-02,  0.0000e+00,  0.0000e+00],
          [-8.1216e-03, -1.0096e-03,  0.0000e+00,  ...,  5.9612e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -2.5127e-05,  2.0241e-02,  ...,  0.0000e+00, -1.7650e-03,  0.0000e+00],
          [ 0.0000e+00, -2.7902e-04,  2.5519e-02,  ..., -2.6117e-03,  7.0390e-03, -4.4892e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2404e-02,  ..., -6.5288e-02, -2.2329e-03,  1.0484e-03],
          [ 0.0000e+00, -4.0531e-03,  6.3655e-05,  ..., -1.2984e-02, -1.1100e-02,  1.0939e-01],
          [ 0.0000e+00,  0.0000e+00, -8.0356e-03,  ..., -1.1831e-02,  1.5809e-02,  1.1999e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -3.2960e-03,  2.6543e-03,  ...,  0.0000e+00,  6.1698e-03,  0.0000e+00],
          [ 0.0000e+00, -1.0539e-04,  1.5006e-02,  ..., -3.7343e-03, -2.7750e-03,  3.5457e-03],
          ...,
          [ 0.0000e+00,  0.0000e+00,  1.7806e-03,  ...,  6.6651e-02,  1.8099e-04,  2.8230e-03],
          [ 0.0000e+00,  1.6101e-03,  1.0047e-04,  ..., -3.2475e-02,  1.4378e-02, -7.2385e-02],
          [ 0.0000e+00,  0.0000e+00, -1.0177e-02,  ...,  7.9826e-04,  2.9431e-03,  1.2601e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.9246e-02, -1.2165e-01,  ...,  8.1076e-04, -3.0793e-04,  0.0000e+00],
          [ 0.0000e+00, -2.4016e-02,  8.5764e-04,  ...,  3.1468e-02, -3.2895e-02, -5.6438e-03],
          ...,
          [-1.1845e-04,  1.5732e-02,  1.5368e-02,  ..., -3.1826e-03, -8.9669e-03,  0.0000e+00],
          [ 9.3183e-03, -2.9955e-02, -1.0617e-02,  ...,  8.6321e-03, -4.4170e-03,  2.2404e-02],
          [ 2.9078e-02,  2.1716e-02,  1.8905e-02,  ..., -7.8022e-04, -2.0893e-05,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -6.0303e-03, -2.8968e-02,  ...,  3.4225e-03, -1.1542e-02,  2.5778e-02],
          [ 0.0000e+00,  6.1848e-04,  2.2603e-02,  ..., -6.6239e-03, -1.9764e-03,  0.0000e+00],
          [ 0.0000e+00, -4.8423e-03, -2.6581e-03,  ..., -1.7503e-02,  1.1605e-01, -2.4046e-04],
          ...,
          [-4.1894e-03, -1.8143e-02,  2.1181e-02,  ...,  4.8473e-05, -2.5504e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.9236e-03,  ...,  0.0000e+00,  4.0432e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.4289e-02,  7.3569e-04,  4.5173e-02,  ..., -8.1295e-03,  0.0000e+00,  0.0000e+00],
          [-7.7211e-02, -4.8809e-04,  1.1736e-02,  ...,  3.7611e-02,  0.0000e+00,  0.0000e+00],
          [-2.7306e-03,  1.3421e-02, -8.0465e-02,  ..., -2.2150e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 2.1210e-02, -2.6490e-02,  1.1427e-02,  ...,  4.8394e-03,  0.0000e+00,  0.0000e+00],
          [-1.0156e-02,  3.0119e-02,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.8265e-03, -3.3069e-04,  6.0542e-04,  ..., -3.4135e-03,  0.0000e+00,  0.0000e+00],
          [-1.1420e-02, -6.3695e-05, -7.5346e-04,  ...,  2.1846e-02,  0.0000e+00,  0.0000e+00],
          [ 4.2466e-03,  1.1805e-02, -8.2473e-03,  ...,  1.1375e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 3.1836e-02, -4.5932e-02, -7.3398e-03,  ..., -5.4431e-02,  0.0000e+00,  0.0000e+00],
          [ 5.7150e-03, -3.7042e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -5.9403e-03,  ...,  0.0000e+00, -2.4085e-03,  5.7238e-03],
          [ 0.0000e+00,  1.0028e-05,  2.0448e-02,  ..., -1.4763e-02,  3.6645e-02,  2.6949e-03],
          ...,
          [ 0.0000e+00,  6.7280e-03, -1.4060e-02,  ..., -7.0479e-04,  2.2371e-02,  8.4421e-02],
          [ 0.0000e+00, -1.8624e-02, -3.1967e-03,  ..., -2.5870e-02,  9.3602e-03, -2.3904e-02],
          [ 0.0000e+00,  0.0000e+00,  5.4856e-03,  ..., -1.1150e-02,  9.0915e-04, -9.2491e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.3202e-03,  ...,  0.0000e+00, -1.6785e-04,  5.5315e-04],
          [ 0.0000e+00,  9.2749e-04, -1.2767e-02,  ..., -5.8556e-03, -7.7542e-02, -3.1515e-03],
          ...,
          [ 0.0000e+00,  4.5625e-02, -2.4180e-02,  ...,  1.0936e-03, -5.5921e-02,  7.8524e-02],
          [ 0.0000e+00,  1.3876e-02, -2.0034e-02,  ...,  3.3246e-02, -7.3384e-03, -3.2142e-03],
          [ 0.0000e+00,  0.0000e+00, -3.4031e-03,  ...,  4.1785e-03, -3.9644e-04, -9.6741e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.6846e-03,  0.0000e+00,  ..., -3.9494e-02,  1.4295e-02, -8.7329e-04],
          [-9.2377e-05,  3.0410e-03, -1.4401e-03,  ...,  1.3232e-02, -3.9967e-03, -8.2961e-03],
          ...,
          [ 0.0000e+00, -8.3514e-03, -7.4878e-03,  ..., -1.9997e-02,  3.0674e-03,  1.7394e-03],
          [ 0.0000e+00, -4.1140e-03, -1.5732e-02,  ...,  4.1994e-02,  5.1754e-03, -4.6354e-04],
          [-1.4383e-03,  3.3931e-02, -8.3296e-03,  ..., -1.8466e-04, -9.8652e-03,  1.7408e-04]],

         ...,

         [[ 5.6623e-02,  3.0139e-02,  2.3866e-03,  ...,  8.3747e-03, -1.6619e-02, -8.5007e-04],
          [ 0.0000e+00, -1.2620e-02, -6.5312e-03,  ..., -2.0040e-02, -5.4153e-04, -3.4961e-04],
          [-3.6724e-03, -1.6551e-03,  4.0833e-02,  ..., -4.1201e-02,  6.2010e-03,  0.0000e+00],
          ...,
          [ 0.0000e+00,  1.3773e-03, -6.0097e-03,  ...,  5.2845e-03,  3.5030e-03,  3.7832e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -5.3821e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.5454e-02,  9.3117e-03, -3.6799e-02,  ..., -5.1075e-06, -3.8158e-04,  0.0000e+00],
          [ 5.1438e-02,  5.8007e-02, -5.2211e-03,  ...,  5.9737e-03, -3.1277e-04,  0.0000e+00],
          [-5.0160e-02, -4.3870e-02, -1.3642e-02,  ..., -5.6392e-02,  7.7080e-03,  0.0000e+00],
          ...,
          [ 1.3059e-02, -3.7577e-02, -1.1870e-02,  ..., -6.0825e-03, -7.6904e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -1.0314e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 5.9417e-03, -3.1662e-03, -6.7557e-02,  ...,  9.5015e-07, -2.5761e-04,  0.0000e+00],
          [ 3.5722e-02, -2.3701e-03,  1.3558e-02,  ..., -1.1154e-03,  5.6904e-04,  0.0000e+00],
          [-4.6680e-03,  3.4928e-02,  1.1048e-02,  ..., -5.8465e-02, -2.5062e-02,  0.0000e+00],
          ...,
          [-1.5582e-02, -2.1827e-03, -1.0030e-01,  ..., -3.5994e-03, -1.6353e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -1.5290e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  3.8025e-04, -2.2682e-03,  ..., -2.6453e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.9798e-02,  ...,  1.0067e-02, -6.8130e-03, -1.7465e-04],
          ...,
          [ 0.0000e+00,  0.0000e+00, -9.9627e-03,  ...,  3.1473e-02,  2.2164e-02,  9.0800e-03],
          [ 0.0000e+00,  0.0000e+00, -2.5729e-02,  ...,  3.3294e-02,  1.4384e-03,  4.1804e-03],
          [ 0.0000e+00,  0.0000e+00, -5.0061e-02,  ..., -1.0285e-02,  3.8671e-03, -4.3939e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.0391e-03,  2.3061e-03,  ..., -6.5739e-05,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.7850e-02,  ...,  2.0246e-03,  3.4841e-02, -3.5283e-04],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.0730e-02,  ..., -4.3060e-03,  1.3268e-02, -1.3678e-02],
          [ 0.0000e+00,  0.0000e+00, -4.2467e-02,  ..., -6.0794e-02,  4.3708e-03, -5.5054e-03],
          [ 0.0000e+00,  0.0000e+00, -2.1205e-02,  ..., -1.5386e-03, -7.5460e-03,  2.0564e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  6.5075e-03,  ...,  3.5771e-02, -2.9427e-03,  0.0000e+00],
          [ 1.6223e-03,  4.3728e-03,  3.8093e-03,  ...,  1.3584e-05, -1.7470e-02,  3.3543e-02],
          ...,
          [-9.4788e-03, -1.9396e-02, -2.0349e-02,  ...,  9.7484e-03,  9.1521e-03,  3.6859e-03],
          [ 0.0000e+00,  1.1765e-01,  4.0306e-03,  ..., -2.0251e-03,  3.7622e-02, -9.4596e-03],
          [ 0.0000e+00,  8.9917e-03,  1.1097e-01,  ..., -3.6008e-03,  3.1695e-05,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  1.4689e-03, -6.1996e-03,  ..., -3.1124e-02, -2.7237e-02,  0.0000e+00],
          [ 0.0000e+00, -4.7613e-02,  1.4140e-02,  ...,  2.9212e-02,  1.0522e-03,  9.0411e-04],
          [ 0.0000e+00, -1.4803e-04,  8.7920e-03,  ..., -8.9217e-05,  3.7015e-03, -5.6174e-03],
          ...,
          [ 0.0000e+00,  2.1163e-02,  3.2531e-02,  ...,  1.2515e-03, -1.8240e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.6101e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.1235e-02, -1.6916e-02, -1.0613e-01,  ..., -6.0801e-03,  0.0000e+00,  0.0000e+00],
          [-3.3665e-03, -6.6503e-03, -1.6958e-03,  ...,  1.1206e-02,  0.0000e+00,  0.0000e+00],
          [ 9.2032e-03, -2.5255e-03,  2.3908e-02,  ...,  4.8907e-03, -2.1981e-04,  0.0000e+00],
          ...,
          [-3.7284e-02, -1.3181e-02,  6.3802e-02,  ...,  1.3257e-02,  0.0000e+00,  0.0000e+00],
          [-7.0842e-03, -2.9429e-04, -4.0328e-02,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0010e-02, -1.9438e-02, -2.8443e-03,  ...,  9.3426e-03,  0.0000e+00,  0.0000e+00],
          [ 3.0144e-02,  4.7019e-03, -1.0271e-03,  ..., -1.5519e-02,  0.0000e+00,  0.0000e+00],
          [-2.3748e-02,  3.0951e-03, -2.1265e-02,  ..., -3.1671e-03, -1.2285e-03,  0.0000e+00],
          ...,
          [ 1.4123e-02, -1.6017e-02,  1.4634e-02,  ...,  6.1301e-03,  0.0000e+00,  0.0000e+00],
          [ 1.3481e-03, -6.8071e-03, -1.4418e-02,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])

2025-07-26 13:49:21.738594 GPU 5 14851 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([2586964, 3, 5, 5],"float32"), offset=Tensor([2586964, 18, 7, 7],"float32"), mask=Tensor([2586964, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([2586964, 3, 5, 5],"float32"), offset=Tensor([2586964, 18, 7, 7],"float32"), mask=Tensor([2586964, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 7 / 2281702248 (0.0%)
Greatest absolute difference: 0.04583489149808884 at index (1626972, 8, 0, 4) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (561053, 10, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2586964, 18, 7, 7]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.7380e-02, -3.3691e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.4937e-03,  ..., -1.2662e-02, -1.1833e-02,  5.2989e-03],
          ...,
          [ 0.0000e+00,  1.5395e-03, -4.7288e-03,  ...,  8.8376e-02,  8.7236e-02, -1.5174e-02],
          [ 0.0000e+00,  6.7696e-03, -8.4227e-02,  ..., -1.2566e-02, -2.7982e-02,  4.3723e-02],
          [ 0.0000e+00,  4.5512e-03, -2.4790e-02,  ...,  2.1981e-03,  5.1714e-02, -2.6883e-04]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.4449e-02,  3.5368e-04,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.2193e-03,  ...,  1.3806e-02, -3.9649e-02, -5.9321e-03],
          ...,
          [ 0.0000e+00,  1.2716e-02, -2.5278e-02,  ..., -2.0731e-02, -6.3051e-02,  2.6703e-02],
          [ 0.0000e+00, -3.3562e-03, -4.2181e-02,  ...,  3.7513e-03,  2.3835e-02, -2.3390e-02],
          [ 0.0000e+00,  2.7255e-02,  2.7625e-02,  ...,  2.6820e-03, -2.4391e-02, -1.7169e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -2.5456e-03, -2.3385e-02],
          [-4.5663e-04, -2.1566e-02, -2.0220e-02,  ...,  9.2375e-04,  2.9871e-03,  0.0000e+00],
          ...,
          [-3.6983e-02, -5.1884e-02, -1.9778e-02,  ...,  3.1028e-02, -2.1630e-02, -8.9944e-03],
          [ 0.0000e+00,  3.5904e-02, -1.1741e-03,  ...,  1.7360e-03, -2.8454e-02,  0.0000e+00],
          [ 0.0000e+00, -1.8390e-03, -1.5876e-03,  ...,  4.7438e-04,  4.3879e-03, -1.1785e-02]],

         ...,

         [[ 4.4688e-02, -2.5044e-03,  1.3931e-02,  ..., -9.4672e-03, -6.6076e-04, -1.4340e-03],
          [-1.1663e-02,  3.1510e-02,  5.0038e-02,  ..., -5.2123e-02, -4.5495e-03,  0.0000e+00],
          [ 0.0000e+00,  1.7630e-02, -1.9381e-01,  ..., -1.1511e-01,  2.6467e-02,  0.0000e+00],
          ...,
          [ 0.0000e+00, -2.6970e-03,  1.0085e-04,  ..., -1.1057e-02, -4.2338e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -3.4766e-04,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.5218e-02, -4.3779e-03,  3.4158e-03,  ..., -1.8825e-02,  0.0000e+00,  0.0000e+00],
          [-1.0531e-02,  1.6731e-03,  1.3807e-03,  ...,  3.6666e-04,  3.7667e-03,  0.0000e+00],
          [-9.7894e-03,  1.1009e-02, -9.5039e-04,  ...,  1.9879e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [-2.7695e-02, -1.6041e-03,  8.5853e-03,  ...,  1.2051e-02,  8.2736e-04,  0.0000e+00],
          [-1.7403e-02,  6.1850e-03,  7.6512e-02,  ...,  5.7643e-03, -2.3889e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.7883e-02, -1.0127e-02,  5.3059e-03,  ..., -3.7218e-02,  0.0000e+00,  0.0000e+00],
          [-3.4213e-02,  2.2532e-03,  1.4410e-02,  ..., -4.6979e-03, -1.4275e-02,  0.0000e+00],
          [ 1.1412e-02,  1.2590e-03, -1.7026e-03,  ...,  1.9571e-04,  0.0000e+00,  0.0000e+00],
          ...,
          [-1.2212e-02,  6.8317e-04,  1.6335e-04,  ..., -1.8115e-03,  6.3982e-03,  0.0000e+00],
          [ 5.6247e-03, -1.1418e-02, -9.8943e-03,  ..., -7.4118e-04, -2.9290e-04,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  2.1900e-03,  0.0000e+00,  ...,  1.3747e-02, -2.2671e-02,  1.7054e-02],
          [ 0.0000e+00,  1.5487e-02, -1.0188e-02,  ...,  4.3064e-02,  3.4824e-03,  1.6488e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00,  1.1175e-02,  ..., -1.2254e-03, -3.4529e-02,  2.1168e-03],
          [ 0.0000e+00,  0.0000e+00,  4.3269e-02,  ...,  1.4752e-02, -1.3678e-02,  5.5639e-03],
          [ 0.0000e+00,  0.0000e+00,  1.1474e-03,  ..., -5.0376e-04, -1.3357e-02,  4.0031e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.0375e-03,  0.0000e+00,  ...,  1.2023e-03,  8.8445e-03, -1.5451e-03],
          [ 0.0000e+00,  3.6860e-02,  2.5071e-02,  ..., -2.1115e-02,  1.1053e-03,  2.4190e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -3.6971e-03,  ...,  4.9816e-03,  5.0312e-02,  1.5416e-02],
          [ 0.0000e+00,  0.0000e+00, -2.9240e-02,  ...,  1.7942e-02, -2.4488e-03,  9.7840e-04],
          [ 0.0000e+00,  0.0000e+00,  1.5760e-03,  ...,  9.2556e-04,  1.4220e-02,  1.8946e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.3490e-02,  ...,  0.0000e+00,  0.0000e+00,  8.0449e-03],
          [ 4.1831e-02, -1.9755e-03, -2.3978e-02,  ...,  7.0533e-04, -4.6826e-02,  1.3898e-04],
          ...,
          [ 0.0000e+00,  1.9273e-02,  5.2956e-02,  ...,  1.4780e-02,  2.2564e-02,  0.0000e+00],
          [ 3.3672e-02, -8.2759e-02,  2.2730e-02,  ..., -3.1820e-03, -1.2880e-02,  1.8662e-02],
          [-4.1389e-04,  4.8195e-03, -6.0542e-05,  ...,  4.6010e-03, -2.4855e-02,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  1.5387e-02, -1.9297e-02,  ...,  3.1389e-02, -9.6236e-03,  4.9641e-03],
          [ 0.0000e+00, -9.7958e-03,  1.2922e-02,  ...,  1.0947e-02,  1.2450e-02,  0.0000e+00],
          [-7.1056e-04, -8.4550e-03, -1.0436e-02,  ..., -5.1282e-02,  5.9356e-03,  0.0000e+00],
          ...,
          [ 0.0000e+00, -5.8554e-02,  2.6602e-02,  ..., -6.0103e-04, -3.3696e-05,  1.2407e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.5571e-04,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 4.0189e-02, -1.3823e-02,  1.1588e-02,  ..., -1.8625e-02,  0.0000e+00,  0.0000e+00],
          [ 1.3866e-02,  2.8468e-02,  3.1948e-02,  ..., -6.1649e-03,  0.0000e+00,  0.0000e+00],
          [ 1.7056e-04, -8.2466e-02,  9.4927e-02,  ..., -5.1217e-03,  2.6834e-03,  0.0000e+00],
          ...,
          [-9.5112e-03, -2.8311e-03, -1.4693e-02,  ...,  2.5362e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -3.4704e-03,  ..., -2.4498e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.5189e-02, -1.1183e-02, -1.2023e-04,  ...,  1.4888e-03,  0.0000e+00,  0.0000e+00],
          [-4.2653e-02,  1.1153e-02,  9.9819e-03,  ...,  7.7003e-02,  0.0000e+00,  0.0000e+00],
          [ 5.7944e-03,  5.3116e-03,  2.4566e-02,  ..., -2.4888e-02, -1.1056e-02,  0.0000e+00],
          ...,
          [ 6.6918e-03,  1.5830e-02,  1.5884e-03,  ..., -1.4057e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -6.5640e-04,  ...,  5.2739e-04,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.0428e-02, -9.6033e-02,  ...,  0.0000e+00,  7.1765e-04, -6.8315e-03],
          [ 0.0000e+00, -3.0315e-05, -9.6622e-02,  ...,  2.7532e-02,  1.1508e-02,  2.0737e-03],
          ...,
          [ 0.0000e+00, -3.9802e-02, -3.0758e-03,  ..., -1.0650e-01,  6.1615e-03,  1.9874e-02],
          [ 0.0000e+00, -1.1711e-05, -1.5836e-02,  ...,  6.4462e-02,  2.6407e-03,  5.8935e-05],
          [ 0.0000e+00,  2.8154e-04, -3.3906e-02,  ..., -6.8256e-03, -3.3286e-03,  2.1450e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.0410e-02, -3.6690e-02,  ...,  0.0000e+00,  1.3501e-03, -6.7726e-03],
          [ 0.0000e+00,  3.2795e-03, -9.0930e-02,  ...,  1.5901e-02, -3.3122e-03,  2.0372e-03],
          ...,
          [ 0.0000e+00,  8.8879e-02, -2.7557e-03,  ...,  2.2221e-01,  2.1250e-02,  1.0730e-02],
          [ 0.0000e+00,  7.4747e-05, -5.9988e-03,  ..., -8.4431e-03,  3.1525e-02, -2.1401e-04],
          [ 0.0000e+00,  1.3082e-03, -3.7663e-03,  ...,  7.7021e-03, -7.1673e-03,  2.1397e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.7716e-02,  2.9031e-03,  0.0000e+00],
          [ 0.0000e+00,  7.9754e-03,  4.6232e-03,  ...,  6.2304e-03,  1.8480e-02, -8.5425e-03],
          ...,
          [ 0.0000e+00,  5.1395e-02,  7.9904e-02,  ...,  4.7096e-03,  5.9802e-03, -2.6765e-02],
          [-1.5054e-02, -4.6855e-03, -2.3245e-03,  ...,  6.5756e-02, -4.2203e-02,  0.0000e+00],
          [ 4.7208e-03, -1.6103e-02, -1.3466e-01,  ...,  4.0702e-02,  6.9888e-02,  0.0000e+00]],

         ...,

         [[-1.8208e-02, -1.2578e-03, -5.4236e-03,  ...,  7.1589e-03, -2.6632e-02,  0.0000e+00],
          [ 1.1257e-02, -8.5775e-03, -1.8676e-03,  ..., -1.9076e-02, -1.4594e-02,  0.0000e+00],
          [ 0.0000e+00,  6.0909e-03, -1.5120e-03,  ...,  1.3778e-02, -1.0491e-04,  0.0000e+00],
          ...,
          [ 0.0000e+00, -8.4115e-02,  1.1437e-02,  ...,  6.7214e-02, -3.8898e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  2.1214e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.9936e-02, -7.7724e-04,  2.9218e-02,  ...,  6.6391e-03, -2.4315e-03,  0.0000e+00],
          [-1.7752e-03,  5.2519e-04,  3.6454e-03,  ...,  3.7487e-04,  0.0000e+00,  0.0000e+00],
          [ 4.4596e-02,  4.4613e-03, -1.6077e-02,  ...,  4.5093e-02,  9.6099e-04,  0.0000e+00],
          ...,
          [ 7.6621e-03, -2.3522e-02,  1.6981e-02,  ..., -8.0097e-03,  5.7412e-03,  0.0000e+00],
          [ 1.6065e-02,  1.3355e-02, -9.6061e-03,  ...,  3.3288e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.8354e-03, -4.4090e-03, -2.9953e-02,  ...,  2.5714e-02,  7.5378e-03,  0.0000e+00],
          [ 2.8559e-03, -4.1638e-03, -1.1034e-03,  ...,  1.1740e-03,  0.0000e+00,  0.0000e+00],
          [ 2.5080e-02,  5.4032e-02, -7.0489e-02,  ..., -2.7114e-02, -1.6711e-02,  0.0000e+00],
          ...,
          [-1.1071e-03,  3.0726e-02,  9.7226e-03,  ...,  1.9971e-03,  8.4962e-03,  0.0000e+00],
          [ 8.9584e-03, -2.6554e-02, -7.9139e-04,  ...,  1.7872e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -3.7954e-03,  0.0000e+00,  ..., -3.5034e-04,  0.0000e+00,  2.9392e-03],
          [ 0.0000e+00,  0.0000e+00,  1.1264e-03,  ..., -2.1502e-02, -1.9869e-02, -3.4818e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2923e-03,  ..., -2.1484e-02,  2.9688e-02,  5.7290e-03],
          [ 0.0000e+00,  0.0000e+00, -6.7047e-02,  ..., -3.4649e-02,  1.8736e-02, -2.2834e-02],
          [ 0.0000e+00, -2.0992e-03, -1.7948e-03,  ..., -3.1981e-02,  3.0836e-03, -3.6936e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -2.3209e-03,  0.0000e+00,  ..., -2.4592e-03,  0.0000e+00, -9.9052e-03],
          [ 0.0000e+00,  0.0000e+00, -3.4145e-03,  ..., -1.2112e-01, -3.0210e-02,  5.7774e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -3.8347e-03,  ...,  2.2340e-02, -8.0357e-02,  3.8203e-03],
          [ 0.0000e+00,  0.0000e+00,  3.4961e-02,  ...,  4.9092e-02,  2.0260e-02,  2.6082e-02],
          [ 0.0000e+00,  2.3741e-03, -2.8057e-03,  ...,  5.1466e-02,  9.4951e-03, -5.0099e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 1.9455e-03, -1.3200e-02,  0.0000e+00,  ...,  0.0000e+00, -9.0498e-03,  0.0000e+00],
          [-6.7043e-03, -2.4006e-02,  1.4615e-02,  ...,  1.0365e-02,  5.9943e-03,  0.0000e+00],
          ...,
          [-5.7269e-04,  1.6238e-03,  3.0937e-02,  ..., -4.4052e-04,  2.0541e-02, -1.2862e-03],
          [ 0.0000e+00,  4.8697e-02,  1.5248e-02,  ..., -4.8908e-02, -1.6716e-02, -5.9278e-03],
          [ 9.8215e-03, -6.7409e-03, -1.3387e-02,  ...,  1.4987e-02,  1.3847e-03,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -2.5817e-03,  5.9417e-03,  ..., -2.9407e-02, -4.2647e-03,  0.0000e+00],
          [ 3.9934e-02, -3.1947e-02,  5.2801e-02,  ..., -7.3818e-03,  5.4983e-04, -1.0331e-03],
          [ 0.0000e+00, -7.0843e-02, -6.1178e-03,  ...,  1.1076e-01, -1.6447e-02, -1.8855e-02],
          ...,
          [ 0.0000e+00, -5.6173e-04,  9.4273e-03,  ..., -1.5997e-02, -3.3077e-04,  0.0000e+00],
          [ 0.0000e+00,  7.0958e-06, -8.6661e-03,  ..., -6.2000e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 3.6174e-02, -1.0410e-02,  3.0188e-02,  ..., -3.5591e-04,  0.0000e+00,  0.0000e+00],
          [ 4.4265e-02,  2.0607e-02,  3.6324e-02,  ...,  1.7853e-02,  0.0000e+00,  0.0000e+00],
          [-3.6145e-03, -1.5501e-02,  4.7639e-02,  ...,  2.1409e-03, -3.3670e-03,  0.0000e+00],
          ...,
          [ 8.7650e-03,  7.5827e-03, -2.0355e-02,  ...,  2.9681e-04,  2.1069e-04,  0.0000e+00],
          [ 0.0000e+00, -5.1950e-03,  5.2916e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.8075e-02, -5.5464e-02,  1.9924e-02,  ...,  3.4300e-04,  0.0000e+00,  0.0000e+00],
          [ 2.6375e-02, -4.3755e-03, -1.6809e-03,  ..., -1.4375e-02,  0.0000e+00,  0.0000e+00],
          [-3.5127e-03,  9.9487e-02,  1.5300e-02,  ..., -3.6692e-03,  1.4986e-02,  0.0000e+00],
          ...,
          [-1.4275e-03, -3.6509e-02,  1.5153e-02,  ...,  2.5653e-03,  4.6353e-04,  0.0000e+00],
          [ 0.0000e+00,  7.4609e-03,  5.3497e-04,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.9883e-04,  ...,  2.5082e-02, -4.7939e-03,  0.0000e+00],
          [ 0.0000e+00,  2.8194e-03, -7.4200e-03,  ...,  1.1603e-02, -1.3595e-02,  2.7932e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2296e-03,  ..., -7.3874e-03,  5.9480e-02, -6.3186e-02],
          [ 0.0000e+00,  0.0000e+00, -9.8008e-03,  ...,  1.6221e-02,  1.1467e-02, -4.4449e-04],
          [ 0.0000e+00, -3.5760e-03,  5.7166e-02,  ..., -6.8639e-02,  1.7857e-02, -2.6384e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.1922e-04,  ..., -2.4677e-03, -3.3187e-03,  0.0000e+00],
          [ 0.0000e+00,  4.4153e-03,  1.1596e-02,  ..., -2.0422e-02,  3.1373e-02, -2.8483e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.0094e-03,  ..., -4.4344e-02,  2.5766e-03, -2.7209e-02],
          [ 0.0000e+00,  0.0000e+00, -1.1222e-02,  ...,  4.4152e-02,  1.0607e-03,  2.3635e-04],
          [ 0.0000e+00,  7.5973e-03, -1.3307e-01,  ...,  1.3067e-01,  1.1802e-02,  1.1822e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.7847e-03,  ...,  0.0000e+00, -2.1307e-02,  0.0000e+00],
          [ 0.0000e+00,  4.9039e-03,  5.2914e-02,  ...,  4.4070e-02,  7.3211e-03,  1.3240e-03],
          ...,
          [ 5.4882e-03, -2.7865e-02, -3.7792e-02,  ..., -7.2699e-03, -8.2209e-02,  0.0000e+00],
          [ 0.0000e+00, -1.9989e-02,  5.2883e-02,  ...,  1.9585e-02,  6.4683e-02, -1.9087e-02],
          [ 0.0000e+00,  1.1995e-02, -1.9632e-02,  ..., -8.6109e-03, -1.6470e-02,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  1.7201e-02,  1.2727e-03,  ..., -1.3850e-02,  1.0590e-02,  0.0000e+00],
          [-3.9009e-03,  1.9968e-03, -2.1347e-02,  ..., -1.0248e-02, -1.3943e-02,  0.0000e+00],
          [-5.7883e-02, -4.3076e-03,  4.7764e-02,  ...,  8.6071e-03, -6.3265e-03, -1.9118e-02],
          ...,
          [ 0.0000e+00,  7.8958e-03,  7.5938e-03,  ...,  5.6933e-04,  2.3318e-02,  0.0000e+00],
          [ 2.2600e-02,  0.0000e+00,  6.1061e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 3.0008e-03, -1.2040e-01,  2.7400e-03,  ..., -8.8229e-02,  4.2008e-04,  0.0000e+00],
          [-5.4219e-04, -3.0095e-02, -4.5303e-02,  ..., -8.9466e-02,  0.0000e+00,  0.0000e+00],
          [-9.5391e-03,  4.4695e-02,  2.4786e-02,  ..., -4.3788e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 4.3256e-02,  1.4081e-02,  1.9429e-03,  ..., -3.1338e-02,  3.5860e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 2.6117e-03,  3.9955e-02, -2.9893e-03,  ..., -4.6350e-03, -2.2382e-03,  0.0000e+00],
          [ 6.8560e-03, -1.5227e-02, -6.0061e-04,  ..., -1.7922e-02,  0.0000e+00,  0.0000e+00],
          [-6.0150e-03,  5.4787e-02, -1.0301e-02,  ..., -5.8659e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 4.2573e-02, -9.7863e-03,  4.0624e-03,  ..., -5.9732e-02,  4.2799e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.5399e-03,  ...,  0.0000e+00,  0.0000e+00, -5.3401e-02],
          [ 0.0000e+00, -3.4809e-03, -1.1282e-02,  ...,  4.9698e-02,  2.1581e-02,  2.8130e-03],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2843e-04,  ...,  1.3075e-02, -2.1142e-03, -1.3622e-02],
          [ 0.0000e+00,  0.0000e+00, -1.4704e-02,  ..., -1.9832e-03,  2.9175e-02, -4.9580e-03],
          [ 0.0000e+00, -1.5474e-05, -2.3097e-02,  ...,  1.5836e-02,  6.1955e-03,  7.0138e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  2.5262e-05,  ...,  0.0000e+00,  0.0000e+00, -1.7599e-02],
          [ 0.0000e+00, -1.4315e-02, -1.1198e-02,  ...,  1.6020e-02, -4.7189e-02,  3.7005e-03],
          ...,
          [ 0.0000e+00,  0.0000e+00,  5.7970e-04,  ...,  1.2068e-02, -1.5331e-02,  2.3611e-02],
          [ 0.0000e+00,  0.0000e+00,  1.9221e-02,  ...,  4.3185e-04, -1.1039e-02,  8.6909e-04],
          [ 0.0000e+00,  2.9697e-04, -1.3253e-02,  ..., -2.0589e-02,  2.4579e-03,  1.2176e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -4.2080e-04, -1.7828e-04,  ...,  8.0613e-03,  4.6000e-03, -3.0371e-02],
          [ 0.0000e+00, -4.0363e-02,  7.2284e-03,  ...,  7.7715e-03, -3.4726e-03,  0.0000e+00],
          ...,
          [ 0.0000e+00, -1.0105e-02, -2.2591e-03,  ..., -8.7662e-02, -1.0157e-02,  2.7117e-03],
          [ 0.0000e+00,  2.0412e-02,  5.2827e-02,  ...,  5.6694e-02, -6.3536e-03,  0.0000e+00],
          [-4.7207e-03,  8.8549e-03, -1.0575e-02,  ...,  3.9816e-03,  1.3547e-02, -3.4476e-03]],

         ...,

         [[ 0.0000e+00, -6.9671e-03,  1.5880e-02,  ..., -8.3269e-04, -3.3884e-02, -6.6163e-02],
          [ 2.0038e-03, -6.7449e-03, -5.0270e-02,  ...,  8.3538e-02, -4.4408e-02,  0.0000e+00],
          [ 1.8337e-03,  7.2256e-03,  3.8802e-03,  ...,  5.5201e-02,  2.4030e-02, -4.4526e-02],
          ...,
          [ 0.0000e+00, -5.4558e-02, -6.6308e-03,  ..., -1.8912e-03, -2.5922e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.1821e-02,  ...,  0.0000e+00, -3.6099e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.4401e-03, -6.9273e-03, -8.1704e-03,  ...,  7.5779e-03,  0.0000e+00,  0.0000e+00],
          [ 4.6291e-02, -4.6209e-02, -1.6405e-02,  ...,  5.0507e-02,  0.0000e+00,  0.0000e+00],
          [ 3.5231e-04,  7.1418e-03,  2.1433e-02,  ...,  5.7808e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [-7.1320e-03,  1.4815e-02, -3.6674e-02,  ...,  8.4679e-03,  1.3678e-02,  0.0000e+00],
          [-1.0554e-02,  0.0000e+00,  0.0000e+00,  ...,  7.7900e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.9640e-03,  1.3565e-02,  1.2915e-03,  ...,  6.8261e-03,  0.0000e+00,  0.0000e+00],
          [-4.6545e-02, -2.7313e-02,  1.4284e-04,  ...,  3.7349e-02,  0.0000e+00,  0.0000e+00],
          [ 3.8436e-03, -4.0661e-02, -6.5474e-02,  ..., -1.7603e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 8.0866e-03, -1.4499e-02,  8.6906e-03,  ...,  8.9140e-03,  2.6186e-02,  0.0000e+00],
          [-4.4916e-03,  0.0000e+00,  0.0000e+00,  ...,  2.8914e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])
DESIRED: (shape=torch.Size([2586964, 18, 7, 7]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.7380e-02, -3.3691e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.4937e-03,  ..., -1.2662e-02, -1.1833e-02,  5.2989e-03],
          ...,
          [ 0.0000e+00,  1.5395e-03, -4.7288e-03,  ...,  8.8376e-02,  8.7236e-02, -1.5174e-02],
          [ 0.0000e+00,  6.7696e-03, -8.4227e-02,  ..., -1.2566e-02, -2.7982e-02,  4.3723e-02],
          [ 0.0000e+00,  4.5512e-03, -2.4790e-02,  ...,  2.1981e-03,  5.1714e-02, -2.6883e-04]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.4449e-02,  3.5368e-04,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.2193e-03,  ...,  1.3806e-02, -3.9649e-02, -5.9321e-03],
          ...,
          [ 0.0000e+00,  1.2716e-02, -2.5278e-02,  ..., -2.0731e-02, -6.3051e-02,  2.6703e-02],
          [ 0.0000e+00, -3.3562e-03, -4.2181e-02,  ...,  3.7513e-03,  2.3835e-02, -2.3390e-02],
          [ 0.0000e+00,  2.7255e-02,  2.7625e-02,  ...,  2.6820e-03, -2.4391e-02, -1.7169e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -2.5456e-03, -2.3385e-02],
          [-4.5664e-04, -2.1566e-02, -2.0220e-02,  ...,  9.2375e-04,  2.9871e-03,  0.0000e+00],
          ...,
          [-3.6983e-02, -5.1884e-02, -1.9778e-02,  ...,  3.1028e-02, -2.1630e-02, -8.9944e-03],
          [ 0.0000e+00,  3.5904e-02, -1.1741e-03,  ...,  1.7360e-03, -2.8454e-02,  0.0000e+00],
          [ 0.0000e+00, -1.8390e-03, -1.5876e-03,  ...,  4.7438e-04,  4.3879e-03, -1.1785e-02]],

         ...,

         [[ 4.4688e-02, -2.5044e-03,  1.3931e-02,  ..., -9.4672e-03, -6.6076e-04, -1.4340e-03],
          [-1.1663e-02,  3.1510e-02,  5.0038e-02,  ..., -5.2123e-02, -4.5495e-03,  0.0000e+00],
          [ 0.0000e+00,  1.7630e-02, -1.9381e-01,  ..., -1.1511e-01,  2.6467e-02,  0.0000e+00],
          ...,
          [ 0.0000e+00, -2.6970e-03,  1.0085e-04,  ..., -1.1057e-02, -4.2338e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -3.4766e-04,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.5218e-02, -4.3779e-03,  3.4158e-03,  ..., -1.8825e-02,  0.0000e+00,  0.0000e+00],
          [-1.0531e-02,  1.6731e-03,  1.3807e-03,  ...,  3.6666e-04,  3.7667e-03,  0.0000e+00],
          [-9.7894e-03,  1.1009e-02, -9.5039e-04,  ...,  1.9879e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [-2.7695e-02, -1.6041e-03,  8.5853e-03,  ...,  1.2051e-02,  8.2736e-04,  0.0000e+00],
          [-1.7403e-02,  6.1850e-03,  7.6512e-02,  ...,  5.7643e-03, -2.3889e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.7883e-02, -1.0127e-02,  5.3059e-03,  ..., -3.7218e-02,  0.0000e+00,  0.0000e+00],
          [-3.4213e-02,  2.2532e-03,  1.4410e-02,  ..., -4.6979e-03, -1.4275e-02,  0.0000e+00],
          [ 1.1412e-02,  1.2590e-03, -1.7026e-03,  ...,  1.9571e-04,  0.0000e+00,  0.0000e+00],
          ...,
          [-1.2212e-02,  6.8317e-04,  1.6335e-04,  ..., -1.8115e-03,  6.3982e-03,  0.0000e+00],
          [ 5.6247e-03, -1.1418e-02, -9.8943e-03,  ..., -7.4118e-04, -2.9290e-04,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  2.1900e-03,  0.0000e+00,  ...,  1.3747e-02, -2.2671e-02,  1.7054e-02],
          [ 0.0000e+00,  1.5487e-02, -1.0188e-02,  ...,  4.3064e-02,  3.4824e-03,  1.6488e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00,  1.1175e-02,  ..., -1.2254e-03, -3.4529e-02,  2.1168e-03],
          [ 0.0000e+00,  0.0000e+00,  4.3269e-02,  ...,  1.4752e-02, -1.3678e-02,  5.5639e-03],
          [ 0.0000e+00,  0.0000e+00,  1.1474e-03,  ..., -5.0376e-04, -1.3357e-02,  4.0031e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.0375e-03,  0.0000e+00,  ...,  1.2023e-03,  8.8445e-03, -1.5451e-03],
          [ 0.0000e+00,  3.6860e-02,  2.5071e-02,  ..., -2.1115e-02,  1.1053e-03,  2.4190e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -3.6971e-03,  ...,  4.9816e-03,  5.0312e-02,  1.5416e-02],
          [ 0.0000e+00,  0.0000e+00, -2.9240e-02,  ...,  1.7942e-02, -2.4488e-03,  9.7840e-04],
          [ 0.0000e+00,  0.0000e+00,  1.5760e-03,  ...,  9.2556e-04,  1.4220e-02,  1.8946e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.3490e-02,  ...,  0.0000e+00,  0.0000e+00,  8.0449e-03],
          [ 4.1831e-02, -1.9755e-03, -2.3978e-02,  ...,  7.0533e-04, -4.6826e-02,  1.3898e-04],
          ...,
          [ 0.0000e+00,  1.9273e-02,  5.2956e-02,  ...,  1.4780e-02,  2.2564e-02,  0.0000e+00],
          [ 3.3672e-02, -8.2759e-02,  2.2730e-02,  ..., -3.1820e-03, -1.2880e-02,  1.8662e-02],
          [-4.1389e-04,  4.8195e-03, -6.0542e-05,  ...,  4.6010e-03, -2.4855e-02,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  1.5387e-02, -1.9297e-02,  ...,  3.1389e-02, -9.6236e-03,  4.9641e-03],
          [ 0.0000e+00, -9.7958e-03,  1.2922e-02,  ...,  1.0947e-02,  1.2450e-02,  0.0000e+00],
          [-7.1057e-04, -8.4550e-03, -1.0436e-02,  ..., -5.1282e-02,  5.9356e-03,  0.0000e+00],
          ...,
          [ 0.0000e+00, -5.8554e-02,  2.6602e-02,  ..., -6.0103e-04, -3.3696e-05,  1.2407e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.5571e-04,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 4.0189e-02, -1.3823e-02,  1.1588e-02,  ..., -1.8625e-02,  0.0000e+00,  0.0000e+00],
          [ 1.3866e-02,  2.8468e-02,  3.1948e-02,  ..., -6.1649e-03,  0.0000e+00,  0.0000e+00],
          [ 1.7056e-04, -8.2466e-02,  9.4927e-02,  ..., -5.1217e-03,  2.6834e-03,  0.0000e+00],
          ...,
          [-9.5112e-03, -2.8311e-03, -1.4693e-02,  ...,  2.5362e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -3.4704e-03,  ..., -2.4498e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-4.5189e-02, -1.1183e-02, -1.2023e-04,  ...,  1.4888e-03,  0.0000e+00,  0.0000e+00],
          [-4.2653e-02,  1.1153e-02,  9.9819e-03,  ...,  7.7003e-02,  0.0000e+00,  0.0000e+00],
          [ 5.7944e-03,  5.3116e-03,  2.4566e-02,  ..., -2.4888e-02, -1.1056e-02,  0.0000e+00],
          ...,
          [ 6.6918e-03,  1.5830e-02,  1.5884e-03,  ..., -1.4057e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -6.5640e-04,  ...,  5.2739e-04,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.0428e-02, -9.6033e-02,  ...,  0.0000e+00,  7.1765e-04, -6.8315e-03],
          [ 0.0000e+00, -3.0315e-05, -9.6622e-02,  ...,  2.7532e-02,  1.1508e-02,  2.0737e-03],
          ...,
          [ 0.0000e+00, -3.9802e-02, -3.0758e-03,  ..., -1.0650e-01,  6.1614e-03,  1.9874e-02],
          [ 0.0000e+00, -1.1711e-05, -1.5836e-02,  ...,  6.4462e-02,  2.6407e-03,  5.8935e-05],
          [ 0.0000e+00,  2.8154e-04, -3.3906e-02,  ..., -6.8256e-03, -3.3286e-03,  2.1450e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.0410e-02, -3.6690e-02,  ...,  0.0000e+00,  1.3501e-03, -6.7726e-03],
          [ 0.0000e+00,  3.2795e-03, -9.0930e-02,  ...,  1.5901e-02, -3.3122e-03,  2.0372e-03],
          ...,
          [ 0.0000e+00,  8.8879e-02, -2.7557e-03,  ...,  2.2221e-01,  2.1250e-02,  1.0730e-02],
          [ 0.0000e+00,  7.4747e-05, -5.9988e-03,  ..., -8.4431e-03,  3.1525e-02, -2.1401e-04],
          [ 0.0000e+00,  1.3082e-03, -3.7664e-03,  ...,  7.7021e-03, -7.1673e-03,  2.1397e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.7716e-02,  2.9031e-03,  0.0000e+00],
          [ 0.0000e+00,  7.9754e-03,  4.6232e-03,  ...,  6.2304e-03,  1.8480e-02, -8.5425e-03],
          ...,
          [ 0.0000e+00,  5.1395e-02,  7.9904e-02,  ...,  4.7096e-03,  5.9802e-03, -2.6765e-02],
          [-1.5054e-02, -4.6855e-03, -2.3245e-03,  ...,  6.5756e-02, -4.2203e-02,  0.0000e+00],
          [ 4.7208e-03, -1.6103e-02, -1.3466e-01,  ...,  4.0702e-02,  6.9888e-02,  0.0000e+00]],

         ...,

         [[-1.8208e-02, -1.2578e-03, -5.4236e-03,  ...,  7.1589e-03, -2.6632e-02,  0.0000e+00],
          [ 1.1257e-02, -8.5775e-03, -1.8676e-03,  ..., -1.9076e-02, -1.4594e-02,  0.0000e+00],
          [ 0.0000e+00,  6.0909e-03, -1.5120e-03,  ...,  1.3778e-02, -1.0491e-04,  0.0000e+00],
          ...,
          [ 0.0000e+00, -8.4115e-02,  1.1437e-02,  ...,  6.7214e-02, -3.8898e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  2.1214e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.9936e-02, -7.7724e-04,  2.9218e-02,  ...,  6.6390e-03, -2.4315e-03,  0.0000e+00],
          [-1.7752e-03,  5.2519e-04,  3.6454e-03,  ...,  3.7487e-04,  0.0000e+00,  0.0000e+00],
          [ 4.4596e-02,  4.4613e-03, -1.6077e-02,  ...,  4.5093e-02,  9.6099e-04,  0.0000e+00],
          ...,
          [ 7.6621e-03, -2.3522e-02,  1.6981e-02,  ..., -8.0097e-03,  5.7412e-03,  0.0000e+00],
          [ 1.6065e-02,  1.3355e-02, -9.6061e-03,  ...,  3.3288e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.8354e-03, -4.4090e-03, -2.9953e-02,  ...,  2.5714e-02,  7.5378e-03,  0.0000e+00],
          [ 2.8559e-03, -4.1638e-03, -1.1034e-03,  ...,  1.1740e-03,  0.0000e+00,  0.0000e+00],
          [ 2.5080e-02,  5.4032e-02, -7.0489e-02,  ..., -2.7114e-02, -1.6711e-02,  0.0000e+00],
          ...,
          [-1.1071e-03,  3.0726e-02,  9.7226e-03,  ...,  1.9971e-03,  8.4962e-03,  0.0000e+00],
          [ 8.9584e-03, -2.6554e-02, -7.9139e-04,  ...,  1.7872e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -3.7954e-03,  0.0000e+00,  ..., -3.5034e-04,  0.0000e+00,  2.9392e-03],
          [ 0.0000e+00,  0.0000e+00,  1.1264e-03,  ..., -2.1502e-02, -1.9869e-02, -3.4818e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2923e-03,  ..., -2.1484e-02,  2.9688e-02,  5.7290e-03],
          [ 0.0000e+00,  0.0000e+00, -6.7047e-02,  ..., -3.4649e-02,  1.8736e-02, -2.2834e-02],
          [ 0.0000e+00, -2.0992e-03, -1.7948e-03,  ..., -3.1981e-02,  3.0836e-03, -3.6936e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -2.3209e-03,  0.0000e+00,  ..., -2.4592e-03,  0.0000e+00, -9.9052e-03],
          [ 0.0000e+00,  0.0000e+00, -3.4145e-03,  ..., -1.2112e-01, -3.0210e-02,  5.7774e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -3.8347e-03,  ...,  2.2340e-02, -8.0357e-02,  3.8203e-03],
          [ 0.0000e+00,  0.0000e+00,  3.4961e-02,  ...,  4.9092e-02,  2.0260e-02,  2.6082e-02],
          [ 0.0000e+00,  2.3741e-03, -2.8057e-03,  ...,  5.1466e-02,  9.4951e-03, -5.0099e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 1.9455e-03, -1.3200e-02,  0.0000e+00,  ...,  0.0000e+00, -9.0498e-03,  0.0000e+00],
          [-6.7042e-03, -2.4006e-02,  1.4615e-02,  ...,  1.0365e-02,  5.9943e-03,  0.0000e+00],
          ...,
          [-5.7269e-04,  1.6238e-03,  3.0937e-02,  ..., -4.4052e-04,  2.0541e-02, -1.2862e-03],
          [ 0.0000e+00,  4.8697e-02,  1.5248e-02,  ..., -4.8908e-02, -1.6716e-02, -5.9278e-03],
          [ 9.8215e-03, -6.7409e-03, -1.3387e-02,  ...,  1.4987e-02,  1.3847e-03,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -2.5817e-03,  5.9417e-03,  ..., -2.9407e-02, -4.2647e-03,  0.0000e+00],
          [ 3.9934e-02, -3.1947e-02,  5.2801e-02,  ..., -7.3818e-03,  5.4983e-04, -1.0331e-03],
          [ 0.0000e+00, -7.0843e-02, -6.1178e-03,  ...,  1.1076e-01, -1.6447e-02, -1.8855e-02],
          ...,
          [ 0.0000e+00, -5.6173e-04,  9.4273e-03,  ..., -1.5997e-02, -3.3077e-04,  0.0000e+00],
          [ 0.0000e+00,  7.0958e-06, -8.6661e-03,  ..., -6.2000e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 3.6174e-02, -1.0410e-02,  3.0188e-02,  ..., -3.5591e-04,  0.0000e+00,  0.0000e+00],
          [ 4.4265e-02,  2.0607e-02,  3.6324e-02,  ...,  1.7853e-02,  0.0000e+00,  0.0000e+00],
          [-3.6145e-03, -1.5501e-02,  4.7639e-02,  ...,  2.1409e-03, -3.3670e-03,  0.0000e+00],
          ...,
          [ 8.7650e-03,  7.5827e-03, -2.0355e-02,  ...,  2.9681e-04,  2.1069e-04,  0.0000e+00],
          [ 0.0000e+00, -5.1950e-03,  5.2916e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.8075e-02, -5.5464e-02,  1.9924e-02,  ...,  3.4300e-04,  0.0000e+00,  0.0000e+00],
          [ 2.6375e-02, -4.3755e-03, -1.6809e-03,  ..., -1.4375e-02,  0.0000e+00,  0.0000e+00],
          [-3.5127e-03,  9.9487e-02,  1.5299e-02,  ..., -3.6692e-03,  1.4986e-02,  0.0000e+00],
          ...,
          [-1.4275e-03, -3.6509e-02,  1.5153e-02,  ...,  2.5653e-03,  4.6353e-04,  0.0000e+00],
          [ 0.0000e+00,  7.4609e-03,  5.3497e-04,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.9883e-04,  ...,  2.5082e-02, -4.7939e-03,  0.0000e+00],
          [ 0.0000e+00,  2.8194e-03, -7.4200e-03,  ...,  1.1603e-02, -1.3595e-02,  2.7932e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2296e-03,  ..., -7.3874e-03,  5.9480e-02, -6.3186e-02],
          [ 0.0000e+00,  0.0000e+00, -9.8008e-03,  ...,  1.6221e-02,  1.1467e-02, -4.4449e-04],
          [ 0.0000e+00, -3.5760e-03,  5.7166e-02,  ..., -6.8639e-02,  1.7857e-02, -2.6384e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.1922e-04,  ..., -2.4677e-03, -3.3187e-03,  0.0000e+00],
          [ 0.0000e+00,  4.4153e-03,  1.1596e-02,  ..., -2.0422e-02,  3.1373e-02, -2.8483e-02],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.0094e-03,  ..., -4.4344e-02,  2.5766e-03, -2.7209e-02],
          [ 0.0000e+00,  0.0000e+00, -1.1222e-02,  ...,  4.4152e-02,  1.0607e-03,  2.3635e-04],
          [ 0.0000e+00,  7.5973e-03, -1.3307e-01,  ...,  1.3067e-01,  1.1802e-02,  1.1822e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.7847e-03,  ...,  0.0000e+00, -2.1307e-02,  0.0000e+00],
          [ 0.0000e+00,  4.9039e-03,  5.2914e-02,  ...,  4.4070e-02,  7.3211e-03,  1.3240e-03],
          ...,
          [ 5.4882e-03, -2.7865e-02, -3.7792e-02,  ..., -7.2699e-03, -8.2209e-02,  0.0000e+00],
          [ 0.0000e+00, -1.9989e-02,  5.2883e-02,  ...,  1.9585e-02,  6.4683e-02, -1.9087e-02],
          [ 0.0000e+00,  1.1995e-02, -1.9632e-02,  ..., -8.6109e-03, -1.6470e-02,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  1.7201e-02,  1.2727e-03,  ..., -1.3850e-02,  1.0590e-02,  0.0000e+00],
          [-3.9009e-03,  1.9968e-03, -2.1347e-02,  ..., -1.0248e-02, -1.3943e-02,  0.0000e+00],
          [-5.7883e-02, -4.3076e-03,  4.7764e-02,  ...,  8.6071e-03, -6.3265e-03, -1.9118e-02],
          ...,
          [ 0.0000e+00,  7.8958e-03,  7.5938e-03,  ...,  5.6933e-04,  2.3318e-02,  0.0000e+00],
          [ 2.2600e-02,  0.0000e+00,  6.1061e-03,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 3.0008e-03, -1.2040e-01,  2.7400e-03,  ..., -8.8229e-02,  4.2008e-04,  0.0000e+00],
          [-5.4219e-04, -3.0095e-02, -4.5303e-02,  ..., -8.9466e-02,  0.0000e+00,  0.0000e+00],
          [-9.5391e-03,  4.4695e-02,  2.4786e-02,  ..., -4.3788e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 4.3256e-02,  1.4081e-02,  1.9429e-03,  ..., -3.1338e-02,  3.5860e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 2.6117e-03,  3.9955e-02, -2.9893e-03,  ..., -4.6350e-03, -2.2382e-03,  0.0000e+00],
          [ 6.8560e-03, -1.5227e-02, -6.0061e-04,  ..., -1.7922e-02,  0.0000e+00,  0.0000e+00],
          [-6.0150e-03,  5.4787e-02, -1.0301e-02,  ..., -5.8659e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 4.2573e-02, -9.7863e-03,  4.0624e-03,  ..., -5.9732e-02,  4.2799e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.5399e-03,  ...,  0.0000e+00,  0.0000e+00, -5.3401e-02],
          [ 0.0000e+00, -3.4809e-03, -1.1282e-02,  ...,  4.9698e-02,  2.1581e-02,  2.8130e-03],
          ...,
          [ 0.0000e+00,  0.0000e+00, -1.2843e-04,  ...,  1.3075e-02, -2.1142e-03, -1.3622e-02],
          [ 0.0000e+00,  0.0000e+00, -1.4704e-02,  ..., -1.9832e-03,  2.9175e-02, -4.9580e-03],
          [ 0.0000e+00, -1.5474e-05, -2.3097e-02,  ...,  1.5836e-02,  6.1955e-03,  7.0138e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  2.5262e-05,  ...,  0.0000e+00,  0.0000e+00, -1.7599e-02],
          [ 0.0000e+00, -1.4315e-02, -1.1198e-02,  ...,  1.6020e-02, -4.7189e-02,  3.7005e-03],
          ...,
          [ 0.0000e+00,  0.0000e+00,  5.7970e-04,  ...,  1.2068e-02, -1.5331e-02,  2.3611e-02],
          [ 0.0000e+00,  0.0000e+00,  1.9221e-02,  ...,  4.3185e-04, -1.1039e-02,  8.6909e-04],
          [ 0.0000e+00,  2.9697e-04, -1.3253e-02,  ..., -2.0589e-02,  2.4579e-03,  1.2176e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -4.2080e-04, -1.7828e-04,  ...,  8.0613e-03,  4.6000e-03, -3.0371e-02],
          [ 0.0000e+00, -4.0363e-02,  7.2284e-03,  ...,  7.7715e-03, -3.4726e-03,  0.0000e+00],
          ...,
          [ 0.0000e+00, -1.0105e-02, -2.2591e-03,  ..., -8.7662e-02, -1.0157e-02,  2.7117e-03],
          [ 0.0000e+00,  2.0412e-02,  5.2827e-02,  ...,  5.6694e-02, -6.3536e-03,  0.0000e+00],
          [-4.7207e-03,  8.8549e-03, -1.0575e-02,  ...,  3.9816e-03,  1.3547e-02, -3.4476e-03]],

         ...,

         [[ 0.0000e+00, -6.9671e-03,  1.5880e-02,  ..., -8.3269e-04, -3.3884e-02, -6.6163e-02],
          [ 2.0038e-03, -6.7449e-03, -5.0270e-02,  ...,  8.3537e-02, -4.4408e-02,  0.0000e+00],
          [ 1.8337e-03,  7.2256e-03,  3.8802e-03,  ...,  5.5201e-02,  2.4030e-02, -4.4526e-02],
          ...,
          [ 0.0000e+00, -5.4558e-02, -6.6308e-03,  ..., -1.8912e-03, -2.5922e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  1.1821e-02,  ...,  0.0000e+00, -3.6099e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.4401e-03, -6.9273e-03, -8.1704e-03,  ...,  7.5779e-03,  0.0000e+00,  0.0000e+00],
          [ 4.6291e-02, -4.6209e-02, -1.6405e-02,  ...,  5.0507e-02,  0.0000e+00,  0.0000e+00],
          [ 3.5231e-04,  7.1418e-03,  2.1433e-02,  ...,  5.7808e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [-7.1320e-03,  1.4815e-02, -3.6674e-02,  ...,  8.4679e-03,  1.3678e-02,  0.0000e+00],
          [-1.0554e-02,  0.0000e+00,  0.0000e+00,  ...,  7.7900e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.9640e-03,  1.3565e-02,  1.2915e-03,  ...,  6.8261e-03,  0.0000e+00,  0.0000e+00],
          [-4.6545e-02, -2.7313e-02,  1.4284e-04,  ...,  3.7349e-02,  0.0000e+00,  0.0000e+00],
          [ 3.8436e-03, -4.0661e-02, -6.5474e-02,  ..., -1.7603e-02,  0.0000e+00,  0.0000e+00],
          ...,
          [ 8.0866e-03, -1.4499e-02,  8.6906e-03,  ...,  8.9140e-03,  2.6186e-02,  0.0000e+00],
          [-4.4916e-03,  0.0000e+00,  0.0000e+00,  ...,  2.8914e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])

2025-07-26 13:50:06.485370 GPU 3 11113 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([3621749, 3, 5, 5],"float32"), offset=Tensor([3621749, 18, 5, 7],"float32"), mask=Tensor([3621749, 9, 5, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([3621749, 3, 5, 5],"float32"), offset=Tensor([3621749, 18, 5, 7],"float32"), mask=Tensor([3621749, 9, 5, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 2281701870 (0.0%)
Greatest absolute difference: 0.0443221814930439 at index (1471427, 4, 0, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (594636, 3, 3, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3621749, 18, 5, 7]), dtype=torch.float32)
tensor([[[[ 0.0000e+00, -7.7752e-03,  0.0000e+00,  ...,  0.0000e+00, -3.7253e-02,  0.0000e+00],
          [ 0.0000e+00, -1.3076e-05, -9.5625e-02,  ...,  9.1568e-03,  3.3915e-03, -2.1371e-02],
          [ 0.0000e+00,  0.0000e+00,  3.3441e-04,  ..., -1.3269e-04,  4.3367e-03,  1.3147e-02],
          [ 0.0000e+00,  0.0000e+00, -1.7825e-02,  ..., -1.0582e-02,  3.7508e-02, -1.3759e-02],
          [ 0.0000e+00,  0.0000e+00, -2.4727e-03,  ..., -5.5703e-02, -5.8007e-04, -5.0889e-02]],

         [[ 0.0000e+00, -6.7382e-03,  0.0000e+00,  ...,  0.0000e+00, -1.3968e-03,  0.0000e+00],
          [ 0.0000e+00, -1.0739e-04,  3.3913e-02,  ...,  2.2857e-03, -1.5848e-02, -2.7684e-02],
          [ 0.0000e+00,  0.0000e+00, -2.9381e-04,  ...,  3.6814e-04, -2.2237e-02,  8.7475e-03],
          [ 0.0000e+00,  0.0000e+00,  1.7044e-02,  ..., -2.8820e-02, -1.5544e-02,  1.8958e-03],
          [ 0.0000e+00,  0.0000e+00,  7.7248e-03,  ...,  6.8267e-02,  3.2321e-02,  2.3932e-02]],

         [[ 8.3803e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.5968e-03,  6.3702e-02,  ...,  2.0678e-02,  8.4197e-04, -3.1595e-03],
          [-2.8271e-03, -4.8699e-02,  1.0774e-02,  ...,  1.3748e-02,  5.1490e-04,  0.0000e+00],
          [-1.7609e-03, -4.1500e-02,  5.2861e-03,  ...,  4.3790e-03,  6.7990e-04,  0.0000e+00],
          [-1.4655e-03,  2.0806e-02,  1.2434e-02,  ...,  1.4372e-02, -7.6750e-03, -1.6253e-02]],

         ...,

         [[ 0.0000e+00,  1.6600e-02, -5.8116e-03,  ...,  9.0431e-04, -1.4927e-02,  6.5742e-03],
          [-3.5267e-06, -1.5614e-04,  1.1106e-02,  ...,  3.2895e-02, -2.7154e-02,  1.1256e-02],
          [ 0.0000e+00,  2.5941e-02, -1.9438e-02,  ...,  2.7998e-02,  9.0799e-03, -8.1860e-03],
          [ 0.0000e+00, -3.2237e-02, -8.2379e-03,  ...,  8.7697e-04,  3.1581e-04,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -7.4960e-03,  5.0303e-03]],

         [[ 1.9641e-03,  5.8298e-03,  4.3684e-03,  ...,  3.8712e-03,  0.0000e+00,  0.0000e+00],
          [-1.5120e-03, -1.3703e-02,  7.0152e-03,  ..., -3.3235e-03,  0.0000e+00,  0.0000e+00],
          [-4.1581e-03, -1.0558e-02, -1.1218e-02,  ...,  3.7038e-02, -7.2613e-03,  0.0000e+00],
          [-2.6961e-02,  8.3645e-03, -1.8508e-02,  ...,  9.0873e-04,  7.1205e-05,  0.0000e+00],
          [ 0.0000e+00, -4.1118e-03,  0.0000e+00,  ...,  0.0000e+00, -2.2490e-02,  0.0000e+00]],

         [[ 1.6046e-04, -5.3245e-03,  1.7604e-02,  ..., -2.0863e-02,  0.0000e+00,  0.0000e+00],
          [ 1.3699e-03,  3.4623e-02, -2.5663e-02,  ..., -1.3366e-03,  0.0000e+00,  0.0000e+00],
          [ 9.5135e-03, -6.4468e-03, -7.2882e-03,  ...,  3.9852e-03,  3.4101e-03,  0.0000e+00],
          [ 2.2679e-03, -5.1964e-03,  1.6727e-02,  ...,  3.7874e-03,  1.7673e-03,  0.0000e+00],
          [ 0.0000e+00, -3.8736e-03,  0.0000e+00,  ...,  0.0000e+00, -2.5836e-02,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -3.6579e-02],
          [ 0.0000e+00,  0.0000e+00, -3.9061e-03,  ..., -1.0281e-02,  2.9783e-02, -3.0070e-02],
          [ 0.0000e+00,  0.0000e+00,  3.9699e-02,  ..., -5.8861e-02,  1.1054e-02,  8.1618e-03],
          [ 0.0000e+00,  0.0000e+00,  1.4620e-02,  ...,  7.6680e-03, -3.9158e-02, -5.5354e-05],
          [ 0.0000e+00, -1.5039e-02, -6.2082e-02,  ...,  2.3737e-02, -4.3823e-02, -9.0999e-05]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -2.0801e-02],
          [ 0.0000e+00,  0.0000e+00, -2.3812e-03,  ..., -2.0020e-02,  1.9285e-02, -2.3140e-02],
          [ 0.0000e+00,  0.0000e+00,  4.4614e-02,  ...,  2.2819e-02, -1.1088e-02,  7.4893e-03],
          [ 0.0000e+00,  0.0000e+00, -2.3713e-02,  ..., -8.6517e-03,  7.4708e-02,  3.3642e-04],
          [ 0.0000e+00, -2.9391e-02,  5.8774e-02,  ...,  3.1025e-02,  7.9430e-02,  1.3503e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.9916e-03,  5.5955e-03,  0.0000e+00],
          [ 0.0000e+00,  3.6544e-03, -2.5737e-04,  ...,  1.4828e-02, -4.0416e-02,  0.0000e+00],
          [ 0.0000e+00,  2.6882e-04,  3.7998e-02,  ..., -5.1860e-02, -1.8820e-02,  8.3276e-03],
          [ 1.3647e-03,  3.1550e-02, -1.0922e-01,  ...,  3.5119e-03, -1.7582e-02,  0.0000e+00],
          [ 0.0000e+00,  2.4142e-02,  3.2809e-03,  ...,  2.7019e-02, -1.7314e-02, -8.3791e-04]],

         ...,

         [[ 0.0000e+00, -1.7248e-03, -3.3349e-02,  ...,  1.9957e-03,  3.8501e-02, -1.6240e-02],
          [ 1.4700e-03, -1.1686e-02,  7.5245e-03,  ...,  9.2927e-03, -3.2268e-02,  1.9788e-02],
          [ 0.0000e+00, -6.5706e-03,  5.2827e-03,  ..., -6.5413e-03, -1.9729e-02,  0.0000e+00],
          [-3.5120e-02,  1.9402e-02, -4.4863e-03,  ..., -6.0736e-03,  3.4331e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 8.6979e-04, -2.5147e-02,  1.1753e-02,  ...,  2.2490e-02,  0.0000e+00,  0.0000e+00],
          [-6.0238e-03, -2.8264e-02,  1.1672e-02,  ..., -4.2486e-03,  0.0000e+00,  0.0000e+00],
          [-9.2880e-03, -3.3672e-02, -5.8316e-02,  ..., -2.0353e-02,  0.0000e+00,  0.0000e+00],
          [-1.9084e-04,  1.3346e-02,  3.5882e-02,  ...,  2.3288e-02,  9.5073e-05,  0.0000e+00],
          [-3.9722e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -1.8273e-02,  0.0000e+00]],

         [[-9.0840e-04, -2.8988e-02, -1.2462e-02,  ..., -3.0189e-04,  0.0000e+00,  0.0000e+00],
          [-1.2668e-03, -2.1335e-02,  6.6248e-03,  ...,  7.3344e-03,  0.0000e+00,  0.0000e+00],
          [-2.3789e-02, -7.0364e-02, -3.2090e-02,  ..., -1.4640e-02,  0.0000e+00,  0.0000e+00],
          [ 7.9065e-04, -1.0901e-02, -1.3619e-02,  ...,  3.8961e-03,  3.6260e-04,  0.0000e+00],
          [ 1.1464e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -2.9776e-03,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.2798e-02, -2.3101e-03,  ...,  9.8780e-04,  3.2374e-03,  1.0325e-02],
          [ 0.0000e+00, -1.1069e-04, -4.3314e-03,  ..., -2.0231e-02,  1.0047e-02, -1.9213e-02],
          [ 0.0000e+00,  2.9289e-04,  1.3017e-01,  ...,  3.2677e-03,  1.1487e-02, -2.4879e-03],
          [ 0.0000e+00,  2.8711e-04, -5.0210e-02,  ..., -1.1513e-01, -9.1243e-03, -2.9442e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  3.7955e-02,  2.3153e-02,  ..., -4.2335e-03, -9.9258e-04, -8.2060e-03],
          [ 0.0000e+00, -3.6325e-04, -1.8411e-02,  ...,  2.0306e-02, -3.1983e-02, -5.8763e-02],
          [ 0.0000e+00, -8.0679e-03,  1.0965e-02,  ..., -1.3739e-03, -1.9606e-02, -2.8415e-03],
          [ 0.0000e+00, -6.8619e-03, -1.1981e-02,  ..., -8.7405e-02, -1.5894e-02, -3.0049e-04]],

         [[-1.5188e-03, -8.9511e-03,  1.1240e-03,  ..., -5.1968e-02,  0.0000e+00,  0.0000e+00],
          [ 1.9472e-03,  1.3781e-03, -1.3938e-03,  ..., -1.8400e-03, -4.1342e-03, -2.1689e-02],
          [-3.1381e-03,  1.4380e-02,  2.1090e-03,  ..., -4.9376e-02, -3.2596e-02,  0.0000e+00],
          [ 5.8719e-03,  6.2775e-02,  6.7716e-03,  ..., -3.4024e-03,  5.5661e-02,  2.9031e-03],
          [ 0.0000e+00,  1.0280e-03, -5.9301e-03,  ...,  1.0221e-02, -1.8614e-02,  0.0000e+00]],

         ...,

         [[ 2.2471e-04, -7.9048e-03,  9.2413e-03,  ..., -2.8121e-02, -8.0093e-03,  0.0000e+00],
          [-2.4792e-02,  1.7481e-02, -7.0489e-02,  ..., -2.3480e-02, -1.7373e-03,  0.0000e+00],
          [ 0.0000e+00, -2.5250e-02, -6.7875e-02,  ..., -2.5878e-02,  5.0817e-04,  5.7301e-02],
          [ 0.0000e+00,  1.9698e-02, -1.4216e-02,  ..., -8.0566e-02, -7.4687e-03, -1.2421e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  4.0558e-04, -2.7313e-04]],

         [[ 4.4441e-03,  3.7787e-02, -1.8144e-03,  ...,  8.0637e-03,  0.0000e+00,  0.0000e+00],
          [ 6.4142e-03,  1.5443e-03,  2.8262e-04,  ..., -1.0776e-02,  0.0000e+00,  0.0000e+00],
          [-1.1383e-01,  2.9987e-03,  1.9963e-02,  ...,  3.8608e-02,  0.0000e+00,  0.0000e+00],
          [-2.5755e-04,  1.3024e-02, -1.5113e-04,  ..., -2.8248e-03, -2.3083e-03,  0.0000e+00],
          [ 0.0000e+00,  8.0031e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-6.3606e-03,  1.7356e-02,  4.7617e-02,  ..., -4.8314e-02,  0.0000e+00,  0.0000e+00],
          [-9.3365e-03, -2.2950e-02, -2.1544e-03,  ..., -5.5797e-04,  0.0000e+00,  0.0000e+00],
          [ 3.0326e-03, -3.0620e-02, -2.3671e-03,  ..., -6.6907e-03,  0.0000e+00,  0.0000e+00],
          [-2.1654e-04, -3.0195e-04, -6.2788e-04,  ..., -2.5431e-02, -4.0300e-03,  0.0000e+00],
          [ 0.0000e+00,  5.0057e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  4.2370e-03,  ...,  0.0000e+00,  2.4388e-04,  0.0000e+00],
          [ 0.0000e+00, -3.2586e-02, -1.2433e-01,  ...,  1.2091e-03, -4.1138e-02,  2.7263e-02],
          [ 0.0000e+00,  0.0000e+00,  1.0062e-03,  ..., -4.5881e-03,  1.5213e-02,  3.2924e-02],
          [ 0.0000e+00,  0.0000e+00,  5.4384e-02,  ...,  5.1758e-02, -1.3605e-03, -7.6316e-03],
          [ 0.0000e+00,  0.0000e+00, -2.5774e-03,  ...,  1.3204e-02, -8.2981e-04,  7.1922e-02]],

         [[ 0.0000e+00,  0.0000e+00, -1.0719e-02,  ...,  0.0000e+00,  4.4599e-05,  0.0000e+00],
          [ 0.0000e+00,  2.3485e-02, -3.0421e-02,  ...,  2.3380e-03, -3.1210e-02, -3.6857e-02],
          [ 0.0000e+00,  0.0000e+00,  4.1770e-04,  ...,  2.8879e-02, -4.9213e-06, -1.1647e-02],
          [ 0.0000e+00,  0.0000e+00,  5.0558e-03,  ..., -5.5371e-02, -1.1919e-02,  2.8817e-04],
          [ 0.0000e+00,  0.0000e+00,  1.3166e-03,  ...,  1.1962e-02,  2.1165e-04, -1.1826e-02]],

         [[-5.9710e-03,  0.0000e+00, -3.2953e-02,  ...,  1.6295e-02,  0.0000e+00,  0.0000e+00],
          [-7.0230e-03, -2.5038e-02, -4.1316e-02,  ..., -2.6962e-02, -1.4165e-02,  0.0000e+00],
          [-3.0914e-03,  4.4099e-04, -3.9988e-02,  ...,  8.1396e-03,  1.7599e-03, -1.3803e-02],
          [ 0.0000e+00,  9.2343e-03,  4.7752e-03,  ..., -5.5084e-04,  5.1714e-04,  4.8672e-04],
          [-1.2672e-02, -3.5556e-03, -2.0189e-02,  ..., -3.9519e-04, -3.1722e-02, -1.7825e-02]],

         ...,

         [[ 0.0000e+00, -4.1329e-02, -2.1516e-03,  ...,  3.1789e-03,  2.0983e-02, -3.9212e-02],
          [-2.4279e-02,  6.5555e-04, -1.3514e-02,  ..., -2.6942e-02, -3.1346e-04,  0.0000e+00],
          [ 5.0587e-05, -9.6032e-03, -1.1915e-01,  ..., -1.4640e-02, -2.8392e-02,  0.0000e+00],
          [-6.8010e-03,  7.0995e-04,  2.1338e-02,  ..., -2.2319e-02, -1.3112e-01,  2.1855e-02],
          [ 0.0000e+00,  0.0000e+00, -1.0378e-02,  ...,  0.0000e+00,  1.0283e-03,  0.0000e+00]],

         [[ 3.2184e-02,  9.4436e-03, -2.6554e-02,  ..., -4.6858e-02,  0.0000e+00,  0.0000e+00],
          [ 1.1702e-02,  8.0316e-03,  9.8064e-03,  ..., -2.5983e-03,  0.0000e+00,  0.0000e+00],
          [-8.4716e-02, -1.3115e-03, -1.2433e-02,  ..., -7.5628e-03,  6.4042e-03,  0.0000e+00],
          [ 6.5126e-02, -7.7410e-03, -4.4353e-02,  ..., -7.0795e-02, -1.0745e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.7588e-03, -3.7907e-03, -5.4446e-02,  ...,  5.9246e-03,  0.0000e+00,  0.0000e+00],
          [ 1.1689e-03,  9.3848e-04,  1.4938e-02,  ...,  2.0690e-02,  0.0000e+00,  0.0000e+00],
          [-1.4347e-02, -1.5644e-03, -2.7685e-02,  ...,  1.4908e-03, -6.6309e-03,  0.0000e+00],
          [ 5.9903e-02,  1.2907e-02, -4.8073e-02,  ..., -1.8986e-01,  3.4123e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  9.3743e-05, -1.1307e-03,  ...,  0.0000e+00,  0.0000e+00,  1.5303e-02],
          [ 0.0000e+00, -5.8007e-04, -2.3781e-02,  ...,  2.9007e-04, -3.1686e-03, -1.1559e-02],
          [ 0.0000e+00,  0.0000e+00, -9.3341e-04,  ...,  2.6745e-02, -7.7909e-03,  2.0394e-02],
          [ 0.0000e+00, -1.7871e-02,  3.5946e-03,  ..., -5.7679e-02, -2.3485e-02,  2.3363e-02],
          [ 0.0000e+00,  0.0000e+00,  2.1192e-02,  ..., -4.7866e-03, -7.5165e-02, -1.5420e-02]],

         [[ 0.0000e+00,  1.5556e-03, -2.9133e-05,  ...,  0.0000e+00,  0.0000e+00,  1.0809e-02],
          [ 0.0000e+00,  5.8515e-04,  7.4950e-02,  ..., -3.3512e-02, -2.8793e-02,  1.2043e-02],
          [ 0.0000e+00,  0.0000e+00,  3.3926e-03,  ...,  5.5606e-02, -1.2363e-02, -1.6372e-02],
          [ 0.0000e+00,  3.7488e-02, -2.2357e-03,  ..., -5.7501e-04, -2.6717e-03,  3.6345e-02],
          [ 0.0000e+00,  0.0000e+00,  2.2183e-02,  ...,  3.7968e-03, -1.7153e-02, -1.2413e-02]],

         [[ 0.0000e+00,  3.9279e-02,  0.0000e+00,  ..., -4.4233e-03, -3.5699e-02,  0.0000e+00],
          [ 1.3455e-03, -1.2934e-03,  3.2299e-02,  ..., -6.3583e-03,  1.0342e-02,  0.0000e+00],
          [ 5.1631e-02, -5.9627e-03, -1.7549e-02,  ..., -1.8059e-02,  2.9075e-03,  2.2745e-04],
          [-6.6969e-03, -5.7475e-02,  2.4945e-02,  ..., -5.2964e-03, -4.5090e-02,  0.0000e+00],
          [-2.2504e-02, -1.3680e-03,  2.1127e-02,  ..., -5.5149e-03, -4.5754e-02, -9.3170e-03]],

         ...,

         [[-1.0858e-03, -1.5693e-02,  2.8624e-02,  ..., -4.9238e-02,  1.7842e-02,  0.0000e+00],
          [ 4.0582e-02, -1.6726e-03,  1.2374e-02,  ...,  5.1085e-02,  1.7969e-02,  0.0000e+00],
          [ 0.0000e+00, -3.7481e-02, -2.9563e-03,  ...,  1.2118e-02, -8.6304e-03, -7.6727e-03],
          [ 0.0000e+00,  5.5902e-02, -4.2087e-02,  ..., -2.8174e-03,  4.6970e-02,  0.0000e+00],
          [ 0.0000e+00, -3.7278e-02,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 6.0353e-03, -4.1276e-02, -8.5912e-02,  ..., -5.9987e-02,  0.0000e+00,  0.0000e+00],
          [-9.6454e-03, -1.3096e-02, -2.9897e-02,  ...,  4.1344e-02,  0.0000e+00,  0.0000e+00],
          [ 1.3149e-02,  1.0999e-02, -1.1825e-01,  ...,  4.6297e-02, -2.3761e-03,  0.0000e+00],
          [ 6.0210e-02,  5.2027e-03,  1.6300e-03,  ...,  1.2898e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.7826e-02,  ...,  0.0000e+00, -8.1036e-04,  0.0000e+00]],

         [[ 1.9301e-02,  1.0127e-02, -7.6114e-02,  ...,  5.0419e-02,  0.0000e+00,  0.0000e+00],
          [ 8.3144e-03, -5.6549e-03,  1.3172e-02,  ...,  4.0255e-03,  0.0000e+00,  0.0000e+00],
          [-3.5233e-02, -4.9252e-03,  2.8089e-02,  ...,  3.2674e-02, -1.2599e-02,  0.0000e+00],
          [ 7.5574e-02,  1.5272e-02, -1.1187e-02,  ...,  2.5362e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.0542e-03,  ...,  0.0000e+00, -2.1499e-03,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -1.9003e-02],
          [ 0.0000e+00,  1.9780e-05, -5.4811e-04,  ...,  2.7013e-03,  4.8889e-03, -2.6172e-02],
          [ 0.0000e+00,  0.0000e+00,  4.4609e-02,  ..., -1.7500e-03, -9.9747e-03,  5.2012e-02],
          [ 0.0000e+00,  0.0000e+00, -4.2511e-03,  ..., -5.7957e-02,  4.4235e-04,  6.8315e-02],
          [ 0.0000e+00,  0.0000e+00,  2.7084e-03,  ..., -6.8873e-02, -1.1552e-02, -1.3027e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  1.3643e-03],
          [ 0.0000e+00,  5.1185e-02,  8.0972e-03,  ...,  1.4333e-02, -1.6021e-02, -2.8792e-02],
          [ 0.0000e+00,  0.0000e+00,  6.8866e-02,  ...,  1.1566e-02,  3.0766e-02, -5.7583e-02],
          [ 0.0000e+00,  0.0000e+00,  8.0935e-05,  ...,  1.0949e-01, -1.0958e-03,  9.4471e-03],
          [ 0.0000e+00,  0.0000e+00, -2.7233e-03,  ...,  5.8417e-02,  3.9556e-02, -7.5078e-04]],

         [[ 0.0000e+00, -9.4551e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-6.7695e-06,  5.0031e-05, -1.4963e-03,  ..., -2.9398e-02, -1.2968e-02,  5.0780e-02],
          [ 0.0000e+00, -3.7119e-02,  9.5644e-03,  ...,  5.6950e-03, -1.0416e-03,  1.9314e-03],
          [ 0.0000e+00, -9.1576e-03, -8.1270e-03,  ..., -2.9345e-03,  1.7027e-03,  0.0000e+00],
          [ 0.0000e+00, -5.2707e-02, -8.3641e-03,  ...,  3.7348e-02,  4.7674e-03,  0.0000e+00]],

         ...,

         [[-8.6810e-03,  3.8547e-02,  1.7843e-02,  ...,  6.8015e-03,  2.8110e-02, -1.2507e-02],
          [ 0.0000e+00, -1.5026e-02, -1.6236e-02,  ..., -1.2586e-02, -1.4291e-02,  0.0000e+00],
          [ 4.6051e-03,  1.6528e-02, -2.8085e-02,  ...,  1.0348e-01, -8.1958e-04,  0.0000e+00],
          [ 0.0000e+00, -1.7424e-02,  1.4610e-02,  ..., -6.6002e-03,  1.7194e-02, -1.8165e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0523e-02, -1.4342e-02,  5.3942e-03,  ..., -3.7965e-02,  2.4445e-04,  0.0000e+00],
          [ 6.7315e-02, -3.3688e-02,  2.3095e-02,  ..., -5.8303e-03,  0.0000e+00,  0.0000e+00],
          [-2.9548e-02,  1.4992e-02,  1.7414e-02,  ..., -2.3668e-03,  0.0000e+00,  0.0000e+00],
          [-1.4127e-02, -7.8554e-03, -1.0674e-02,  ...,  4.2935e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  4.4644e-03,  ..., -1.7751e-02,  2.0651e-02,  0.0000e+00]],

         [[ 2.6238e-03, -1.3979e-02,  9.6808e-03,  ...,  4.5743e-02,  9.6199e-03,  0.0000e+00],
          [ 1.7057e-02,  5.7038e-02,  2.4855e-02,  ..., -1.4373e-02,  0.0000e+00,  0.0000e+00],
          [ 2.1369e-03,  2.9435e-02, -2.0629e-02,  ...,  3.7789e-02,  0.0000e+00,  0.0000e+00],
          [-6.0929e-03,  4.5470e-03,  3.9318e-03,  ..., -4.6399e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.5606e-03,  ..., -5.1142e-03,  1.3044e-02,  0.0000e+00]]]])
DESIRED: (shape=torch.Size([3621749, 18, 5, 7]), dtype=torch.float32)
tensor([[[[ 0.0000e+00, -7.7752e-03,  0.0000e+00,  ...,  0.0000e+00, -3.7253e-02,  0.0000e+00],
          [ 0.0000e+00, -1.3076e-05, -9.5625e-02,  ...,  9.1568e-03,  3.3915e-03, -2.1371e-02],
          [ 0.0000e+00,  0.0000e+00,  3.3441e-04,  ..., -1.3269e-04,  4.3367e-03,  1.3147e-02],
          [ 0.0000e+00,  0.0000e+00, -1.7825e-02,  ..., -1.0582e-02,  3.7508e-02, -1.3759e-02],
          [ 0.0000e+00,  0.0000e+00, -2.4727e-03,  ..., -5.5703e-02, -5.8007e-04, -5.0889e-02]],

         [[ 0.0000e+00, -6.7382e-03,  0.0000e+00,  ...,  0.0000e+00, -1.3968e-03,  0.0000e+00],
          [ 0.0000e+00, -1.0739e-04,  3.3913e-02,  ...,  2.2857e-03, -1.5848e-02, -2.7684e-02],
          [ 0.0000e+00,  0.0000e+00, -2.9381e-04,  ...,  3.6814e-04, -2.2237e-02,  8.7475e-03],
          [ 0.0000e+00,  0.0000e+00,  1.7044e-02,  ..., -2.8821e-02, -1.5544e-02,  1.8958e-03],
          [ 0.0000e+00,  0.0000e+00,  7.7248e-03,  ...,  6.8267e-02,  3.2321e-02,  2.3932e-02]],

         [[ 8.3803e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.5968e-03,  6.3702e-02,  ...,  2.0678e-02,  8.4197e-04, -3.1595e-03],
          [-2.8271e-03, -4.8699e-02,  1.0774e-02,  ...,  1.3748e-02,  5.1490e-04,  0.0000e+00],
          [-1.7609e-03, -4.1500e-02,  5.2861e-03,  ...,  4.3790e-03,  6.7990e-04,  0.0000e+00],
          [-1.4655e-03,  2.0806e-02,  1.2434e-02,  ...,  1.4372e-02, -7.6750e-03, -1.6253e-02]],

         ...,

         [[ 0.0000e+00,  1.6600e-02, -5.8116e-03,  ...,  9.0431e-04, -1.4927e-02,  6.5742e-03],
          [-3.5267e-06, -1.5614e-04,  1.1106e-02,  ...,  3.2895e-02, -2.7154e-02,  1.1256e-02],
          [ 0.0000e+00,  2.5941e-02, -1.9438e-02,  ...,  2.7998e-02,  9.0799e-03, -8.1860e-03],
          [ 0.0000e+00, -3.2237e-02, -8.2379e-03,  ...,  8.7697e-04,  3.1581e-04,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -7.4960e-03,  5.0303e-03]],

         [[ 1.9641e-03,  5.8298e-03,  4.3684e-03,  ...,  3.8712e-03,  0.0000e+00,  0.0000e+00],
          [-1.5120e-03, -1.3703e-02,  7.0152e-03,  ..., -3.3235e-03,  0.0000e+00,  0.0000e+00],
          [-4.1581e-03, -1.0558e-02, -1.1218e-02,  ...,  3.7038e-02, -7.2613e-03,  0.0000e+00],
          [-2.6961e-02,  8.3645e-03, -1.8508e-02,  ...,  9.0873e-04,  7.1205e-05,  0.0000e+00],
          [ 0.0000e+00, -4.1118e-03,  0.0000e+00,  ...,  0.0000e+00, -2.2490e-02,  0.0000e+00]],

         [[ 1.6046e-04, -5.3245e-03,  1.7603e-02,  ..., -2.0863e-02,  0.0000e+00,  0.0000e+00],
          [ 1.3699e-03,  3.4623e-02, -2.5663e-02,  ..., -1.3366e-03,  0.0000e+00,  0.0000e+00],
          [ 9.5135e-03, -6.4468e-03, -7.2882e-03,  ...,  3.9852e-03,  3.4101e-03,  0.0000e+00],
          [ 2.2679e-03, -5.1964e-03,  1.6727e-02,  ...,  3.7874e-03,  1.7673e-03,  0.0000e+00],
          [ 0.0000e+00, -3.8736e-03,  0.0000e+00,  ...,  0.0000e+00, -2.5836e-02,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -3.6579e-02],
          [ 0.0000e+00,  0.0000e+00, -3.9061e-03,  ..., -1.0281e-02,  2.9783e-02, -3.0070e-02],
          [ 0.0000e+00,  0.0000e+00,  3.9699e-02,  ..., -5.8861e-02,  1.1054e-02,  8.1618e-03],
          [ 0.0000e+00,  0.0000e+00,  1.4620e-02,  ...,  7.6680e-03, -3.9158e-02, -5.5354e-05],
          [ 0.0000e+00, -1.5039e-02, -6.2082e-02,  ...,  2.3737e-02, -4.3823e-02, -9.0999e-05]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -2.0801e-02],
          [ 0.0000e+00,  0.0000e+00, -2.3812e-03,  ..., -2.0020e-02,  1.9285e-02, -2.3140e-02],
          [ 0.0000e+00,  0.0000e+00,  4.4614e-02,  ...,  2.2819e-02, -1.1088e-02,  7.4893e-03],
          [ 0.0000e+00,  0.0000e+00, -2.3713e-02,  ..., -8.6517e-03,  7.4708e-02,  3.3642e-04],
          [ 0.0000e+00, -2.9391e-02,  5.8774e-02,  ...,  3.1025e-02,  7.9430e-02,  1.3503e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.9916e-03,  5.5955e-03,  0.0000e+00],
          [ 0.0000e+00,  3.6544e-03, -2.5737e-04,  ...,  1.4828e-02, -4.0416e-02,  0.0000e+00],
          [ 0.0000e+00,  2.6882e-04,  3.7998e-02,  ..., -5.1860e-02, -1.8820e-02,  8.3276e-03],
          [ 1.3647e-03,  3.1550e-02, -1.0922e-01,  ...,  3.5119e-03, -1.7582e-02,  0.0000e+00],
          [ 0.0000e+00,  2.4142e-02,  3.2809e-03,  ...,  2.7019e-02, -1.7314e-02, -8.3791e-04]],

         ...,

         [[ 0.0000e+00, -1.7248e-03, -3.3349e-02,  ...,  1.9957e-03,  3.8501e-02, -1.6240e-02],
          [ 1.4700e-03, -1.1686e-02,  7.5245e-03,  ...,  9.2927e-03, -3.2268e-02,  1.9788e-02],
          [ 0.0000e+00, -6.5706e-03,  5.2827e-03,  ..., -6.5413e-03, -1.9729e-02,  0.0000e+00],
          [-3.5120e-02,  1.9402e-02, -4.4863e-03,  ..., -6.0736e-03,  3.4331e-03,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 8.6979e-04, -2.5147e-02,  1.1753e-02,  ...,  2.2490e-02,  0.0000e+00,  0.0000e+00],
          [-6.0238e-03, -2.8264e-02,  1.1672e-02,  ..., -4.2486e-03,  0.0000e+00,  0.0000e+00],
          [-9.2880e-03, -3.3672e-02, -5.8316e-02,  ..., -2.0353e-02,  0.0000e+00,  0.0000e+00],
          [-1.9084e-04,  1.3346e-02,  3.5882e-02,  ...,  2.3288e-02,  9.5073e-05,  0.0000e+00],
          [-3.9722e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -1.8273e-02,  0.0000e+00]],

         [[-9.0840e-04, -2.8988e-02, -1.2462e-02,  ..., -3.0189e-04,  0.0000e+00,  0.0000e+00],
          [-1.2668e-03, -2.1335e-02,  6.6248e-03,  ...,  7.3344e-03,  0.0000e+00,  0.0000e+00],
          [-2.3789e-02, -7.0364e-02, -3.2090e-02,  ..., -1.4640e-02,  0.0000e+00,  0.0000e+00],
          [ 7.9065e-04, -1.0901e-02, -1.3619e-02,  ...,  3.8961e-03,  3.6260e-04,  0.0000e+00],
          [ 1.1464e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00, -2.9776e-03,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  1.2798e-02, -2.3101e-03,  ...,  9.8780e-04,  3.2374e-03,  1.0325e-02],
          [ 0.0000e+00, -1.1069e-04, -4.3314e-03,  ..., -2.0231e-02,  1.0047e-02, -1.9213e-02],
          [ 0.0000e+00,  2.9289e-04,  1.3017e-01,  ...,  3.2677e-03,  1.1487e-02, -2.4879e-03],
          [ 0.0000e+00,  2.8711e-04, -5.0210e-02,  ..., -1.1513e-01, -9.1243e-03, -2.9442e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  3.7955e-02,  2.3153e-02,  ..., -4.2335e-03, -9.9258e-04, -8.2060e-03],
          [ 0.0000e+00, -3.6325e-04, -1.8411e-02,  ...,  2.0306e-02, -3.1983e-02, -5.8763e-02],
          [ 0.0000e+00, -8.0679e-03,  1.0965e-02,  ..., -1.3739e-03, -1.9606e-02, -2.8415e-03],
          [ 0.0000e+00, -6.8619e-03, -1.1981e-02,  ..., -8.7405e-02, -1.5894e-02, -3.0049e-04]],

         [[-1.5188e-03, -8.9512e-03,  1.1240e-03,  ..., -5.1968e-02,  0.0000e+00,  0.0000e+00],
          [ 1.9472e-03,  1.3781e-03, -1.3938e-03,  ..., -1.8400e-03, -4.1342e-03, -2.1689e-02],
          [-3.1381e-03,  1.4380e-02,  2.1090e-03,  ..., -4.9376e-02, -3.2596e-02,  0.0000e+00],
          [ 5.8719e-03,  6.2775e-02,  6.7716e-03,  ..., -3.4024e-03,  5.5661e-02,  2.9031e-03],
          [ 0.0000e+00,  1.0280e-03, -5.9301e-03,  ...,  1.0221e-02, -1.8614e-02,  0.0000e+00]],

         ...,

         [[ 2.2471e-04, -7.9048e-03,  9.2413e-03,  ..., -2.8121e-02, -8.0093e-03,  0.0000e+00],
          [-2.4792e-02,  1.7481e-02, -7.0489e-02,  ..., -2.3480e-02, -1.7373e-03,  0.0000e+00],
          [ 0.0000e+00, -2.5250e-02, -6.7875e-02,  ..., -2.5878e-02,  5.0817e-04,  5.7301e-02],
          [ 0.0000e+00,  1.9698e-02, -1.4216e-02,  ..., -8.0566e-02, -7.4687e-03, -1.2421e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  4.0558e-04, -2.7313e-04]],

         [[ 4.4441e-03,  3.7787e-02, -1.8144e-03,  ...,  8.0637e-03,  0.0000e+00,  0.0000e+00],
          [ 6.4142e-03,  1.5443e-03,  2.8262e-04,  ..., -1.0776e-02,  0.0000e+00,  0.0000e+00],
          [-1.1383e-01,  2.9987e-03,  1.9963e-02,  ...,  3.8608e-02,  0.0000e+00,  0.0000e+00],
          [-2.5755e-04,  1.3024e-02, -1.5113e-04,  ..., -2.8248e-03, -2.3083e-03,  0.0000e+00],
          [ 0.0000e+00,  8.0031e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-6.3606e-03,  1.7356e-02,  4.7617e-02,  ..., -4.8314e-02,  0.0000e+00,  0.0000e+00],
          [-9.3365e-03, -2.2950e-02, -2.1544e-03,  ..., -5.5797e-04,  0.0000e+00,  0.0000e+00],
          [ 3.0326e-03, -3.0620e-02, -2.3671e-03,  ..., -6.6907e-03,  0.0000e+00,  0.0000e+00],
          [-2.1654e-04, -3.0195e-04, -6.2788e-04,  ..., -2.5431e-02, -4.0300e-03,  0.0000e+00],
          [ 0.0000e+00,  5.0057e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  4.2370e-03,  ...,  0.0000e+00,  2.4388e-04,  0.0000e+00],
          [ 0.0000e+00, -3.2586e-02, -1.2433e-01,  ...,  1.2091e-03, -4.1138e-02,  2.7263e-02],
          [ 0.0000e+00,  0.0000e+00,  1.0062e-03,  ..., -4.5881e-03,  1.5213e-02,  3.2924e-02],
          [ 0.0000e+00,  0.0000e+00,  5.4384e-02,  ...,  5.1758e-02, -1.3605e-03, -7.6316e-03],
          [ 0.0000e+00,  0.0000e+00, -2.5774e-03,  ...,  1.3204e-02, -8.2981e-04,  7.1922e-02]],

         [[ 0.0000e+00,  0.0000e+00, -1.0719e-02,  ...,  0.0000e+00,  4.4599e-05,  0.0000e+00],
          [ 0.0000e+00,  2.3485e-02, -3.0421e-02,  ...,  2.3380e-03, -3.1210e-02, -3.6857e-02],
          [ 0.0000e+00,  0.0000e+00,  4.1770e-04,  ...,  2.8879e-02, -4.9212e-06, -1.1647e-02],
          [ 0.0000e+00,  0.0000e+00,  5.0558e-03,  ..., -5.5371e-02, -1.1919e-02,  2.8817e-04],
          [ 0.0000e+00,  0.0000e+00,  1.3166e-03,  ...,  1.1962e-02,  2.1165e-04, -1.1826e-02]],

         [[-5.9710e-03,  0.0000e+00, -3.2953e-02,  ...,  1.6295e-02,  0.0000e+00,  0.0000e+00],
          [-7.0230e-03, -2.5038e-02, -4.1316e-02,  ..., -2.6962e-02, -1.4165e-02,  0.0000e+00],
          [-3.0914e-03,  4.4099e-04, -3.9988e-02,  ...,  8.1396e-03,  1.7599e-03, -1.3803e-02],
          [ 0.0000e+00,  9.2343e-03,  4.7752e-03,  ..., -5.5084e-04,  5.1713e-04,  4.8672e-04],
          [-1.2672e-02, -3.5556e-03, -2.0189e-02,  ..., -3.9519e-04, -3.1722e-02, -1.7825e-02]],

         ...,

         [[ 0.0000e+00, -4.1329e-02, -2.1516e-03,  ...,  3.1789e-03,  2.0983e-02, -3.9212e-02],
          [-2.4279e-02,  6.5555e-04, -1.3514e-02,  ..., -2.6942e-02, -3.1346e-04,  0.0000e+00],
          [ 5.0587e-05, -9.6032e-03, -1.1915e-01,  ..., -1.4640e-02, -2.8392e-02,  0.0000e+00],
          [-6.8010e-03,  7.0995e-04,  2.1338e-02,  ..., -2.2319e-02, -1.3112e-01,  2.1855e-02],
          [ 0.0000e+00,  0.0000e+00, -1.0378e-02,  ...,  0.0000e+00,  1.0283e-03,  0.0000e+00]],

         [[ 3.2184e-02,  9.4436e-03, -2.6554e-02,  ..., -4.6858e-02,  0.0000e+00,  0.0000e+00],
          [ 1.1702e-02,  8.0316e-03,  9.8064e-03,  ..., -2.5983e-03,  0.0000e+00,  0.0000e+00],
          [-8.4716e-02, -1.3115e-03, -1.2433e-02,  ..., -7.5628e-03,  6.4042e-03,  0.0000e+00],
          [ 6.5126e-02, -7.7410e-03, -4.4353e-02,  ..., -7.0795e-02, -1.0745e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.7588e-03, -3.7907e-03, -5.4446e-02,  ...,  5.9246e-03,  0.0000e+00,  0.0000e+00],
          [ 1.1689e-03,  9.3848e-04,  1.4938e-02,  ...,  2.0690e-02,  0.0000e+00,  0.0000e+00],
          [-1.4347e-02, -1.5644e-03, -2.7685e-02,  ...,  1.4908e-03, -6.6309e-03,  0.0000e+00],
          [ 5.9903e-02,  1.2907e-02, -4.8073e-02,  ..., -1.8986e-01,  3.4123e-02,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  9.3743e-05, -1.1307e-03,  ...,  0.0000e+00,  0.0000e+00,  1.5303e-02],
          [ 0.0000e+00, -5.8007e-04, -2.3781e-02,  ...,  2.9007e-04, -3.1685e-03, -1.1559e-02],
          [ 0.0000e+00,  0.0000e+00, -9.3341e-04,  ...,  2.6745e-02, -7.7909e-03,  2.0394e-02],
          [ 0.0000e+00, -1.7871e-02,  3.5946e-03,  ..., -5.7679e-02, -2.3485e-02,  2.3363e-02],
          [ 0.0000e+00,  0.0000e+00,  2.1192e-02,  ..., -4.7866e-03, -7.5165e-02, -1.5420e-02]],

         [[ 0.0000e+00,  1.5556e-03, -2.9133e-05,  ...,  0.0000e+00,  0.0000e+00,  1.0809e-02],
          [ 0.0000e+00,  5.8515e-04,  7.4951e-02,  ..., -3.3512e-02, -2.8793e-02,  1.2043e-02],
          [ 0.0000e+00,  0.0000e+00,  3.3926e-03,  ...,  5.5606e-02, -1.2363e-02, -1.6372e-02],
          [ 0.0000e+00,  3.7488e-02, -2.2357e-03,  ..., -5.7501e-04, -2.6717e-03,  3.6345e-02],
          [ 0.0000e+00,  0.0000e+00,  2.2183e-02,  ...,  3.7968e-03, -1.7153e-02, -1.2413e-02]],

         [[ 0.0000e+00,  3.9279e-02,  0.0000e+00,  ..., -4.4233e-03, -3.5699e-02,  0.0000e+00],
          [ 1.3455e-03, -1.2934e-03,  3.2299e-02,  ..., -6.3583e-03,  1.0342e-02,  0.0000e+00],
          [ 5.1631e-02, -5.9627e-03, -1.7549e-02,  ..., -1.8059e-02,  2.9075e-03,  2.2745e-04],
          [-6.6969e-03, -5.7475e-02,  2.4945e-02,  ..., -5.2964e-03, -4.5090e-02,  0.0000e+00],
          [-2.2504e-02, -1.3680e-03,  2.1127e-02,  ..., -5.5150e-03, -4.5754e-02, -9.3170e-03]],

         ...,

         [[-1.0858e-03, -1.5693e-02,  2.8624e-02,  ..., -4.9238e-02,  1.7842e-02,  0.0000e+00],
          [ 4.0582e-02, -1.6726e-03,  1.2374e-02,  ...,  5.1085e-02,  1.7969e-02,  0.0000e+00],
          [ 0.0000e+00, -3.7481e-02, -2.9563e-03,  ...,  1.2118e-02, -8.6304e-03, -7.6727e-03],
          [ 0.0000e+00,  5.5902e-02, -4.2087e-02,  ..., -2.8174e-03,  4.6970e-02,  0.0000e+00],
          [ 0.0000e+00, -3.7278e-02,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 6.0353e-03, -4.1276e-02, -8.5912e-02,  ..., -5.9987e-02,  0.0000e+00,  0.0000e+00],
          [-9.6454e-03, -1.3096e-02, -2.9897e-02,  ...,  4.1344e-02,  0.0000e+00,  0.0000e+00],
          [ 1.3149e-02,  1.0999e-02, -1.1825e-01,  ...,  4.6297e-02, -2.3761e-03,  0.0000e+00],
          [ 6.0210e-02,  5.2027e-03,  1.6300e-03,  ...,  1.2898e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.7826e-02,  ...,  0.0000e+00, -8.1036e-04,  0.0000e+00]],

         [[ 1.9301e-02,  1.0127e-02, -7.6114e-02,  ...,  5.0419e-02,  0.0000e+00,  0.0000e+00],
          [ 8.3144e-03, -5.6549e-03,  1.3172e-02,  ...,  4.0255e-03,  0.0000e+00,  0.0000e+00],
          [-3.5233e-02, -4.9252e-03,  2.8089e-02,  ...,  3.2674e-02, -1.2599e-02,  0.0000e+00],
          [ 7.5574e-02,  1.5272e-02, -1.1187e-02,  ...,  2.5362e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -2.0542e-03,  ...,  0.0000e+00, -2.1499e-03,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00, -1.9003e-02],
          [ 0.0000e+00,  1.9780e-05, -5.4811e-04,  ...,  2.7013e-03,  4.8889e-03, -2.6172e-02],
          [ 0.0000e+00,  0.0000e+00,  4.4609e-02,  ..., -1.7500e-03, -9.9747e-03,  5.2012e-02],
          [ 0.0000e+00,  0.0000e+00, -4.2511e-03,  ..., -5.7957e-02,  4.4235e-04,  6.8315e-02],
          [ 0.0000e+00,  0.0000e+00,  2.7084e-03,  ..., -6.8873e-02, -1.1552e-02, -1.3027e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  1.3643e-03],
          [ 0.0000e+00,  5.1185e-02,  8.0972e-03,  ...,  1.4333e-02, -1.6021e-02, -2.8792e-02],
          [ 0.0000e+00,  0.0000e+00,  6.8866e-02,  ...,  1.1566e-02,  3.0766e-02, -5.7583e-02],
          [ 0.0000e+00,  0.0000e+00,  8.0935e-05,  ...,  1.0949e-01, -1.0958e-03,  9.4471e-03],
          [ 0.0000e+00,  0.0000e+00, -2.7233e-03,  ...,  5.8417e-02,  3.9556e-02, -7.5078e-04]],

         [[ 0.0000e+00, -9.4551e-03,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-6.7695e-06,  5.0031e-05, -1.4963e-03,  ..., -2.9398e-02, -1.2968e-02,  5.0780e-02],
          [ 0.0000e+00, -3.7119e-02,  9.5644e-03,  ...,  5.6950e-03, -1.0416e-03,  1.9314e-03],
          [ 0.0000e+00, -9.1576e-03, -8.1269e-03,  ..., -2.9345e-03,  1.7027e-03,  0.0000e+00],
          [ 0.0000e+00, -5.2707e-02, -8.3641e-03,  ...,  3.7348e-02,  4.7674e-03,  0.0000e+00]],

         ...,

         [[-8.6810e-03,  3.8547e-02,  1.7843e-02,  ...,  6.8015e-03,  2.8110e-02, -1.2507e-02],
          [ 0.0000e+00, -1.5026e-02, -1.6236e-02,  ..., -1.2586e-02, -1.4291e-02,  0.0000e+00],
          [ 4.6051e-03,  1.6528e-02, -2.8085e-02,  ...,  1.0348e-01, -8.1958e-04,  0.0000e+00],
          [ 0.0000e+00, -1.7424e-02,  1.4610e-02,  ..., -6.6002e-03,  1.7194e-02, -1.8165e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0523e-02, -1.4342e-02,  5.3942e-03,  ..., -3.7965e-02,  2.4445e-04,  0.0000e+00],
          [ 6.7315e-02, -3.3688e-02,  2.3095e-02,  ..., -5.8303e-03,  0.0000e+00,  0.0000e+00],
          [-2.9548e-02,  1.4992e-02,  1.7414e-02,  ..., -2.3668e-03,  0.0000e+00,  0.0000e+00],
          [-1.4127e-02, -7.8554e-03, -1.0674e-02,  ...,  4.2935e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  4.4644e-03,  ..., -1.7751e-02,  2.0651e-02,  0.0000e+00]],

         [[ 2.6238e-03, -1.3979e-02,  9.6808e-03,  ...,  4.5743e-02,  9.6199e-03,  0.0000e+00],
          [ 1.7057e-02,  5.7038e-02,  2.4855e-02,  ..., -1.4373e-02,  0.0000e+00,  0.0000e+00],
          [ 2.1369e-03,  2.9435e-02, -2.0629e-02,  ...,  3.7789e-02,  0.0000e+00,  0.0000e+00],
          [-6.0929e-03,  4.5470e-03,  3.9318e-03,  ..., -4.6399e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.5606e-03,  ..., -5.1142e-03,  1.3044e-02,  0.0000e+00]]]])

2025-07-26 13:50:14.582195 GPU 1 18595 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([4, 22817014, 5, 5],"float32"), offset=Tensor([4, 18, 3, 3],"float32"), mask=Tensor([4, 9, 3, 3],"float32"), weight=Tensor([5, 22817014, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[0,0,], dilation=list[1,1,], deformable_groups=1, groups=1, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([4, 22817014, 5, 5],"float32"), offset=Tensor([4, 18, 3, 3],"float32"), mask=Tensor([4, 9, 3, 3],"float32"), weight=Tensor([5, 22817014, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[0,0,], dilation=list[1,1,], deformable_groups=1, groups=1, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1856342933 / 2281701400 (81.4%)
Greatest absolute difference: 1.9918460845947266 at index (3, 21574243, 2, 2) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 13256072, 3, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 22817014, 5, 5]), dtype=torch.float32)
tensor([[[[-6.7329e-02, -4.1928e-02, -2.0310e-02,  8.3719e-02, -1.0423e-01],
          [-1.8159e-01, -3.6599e-02, -7.6991e-03,  4.3990e-02,  7.0569e-03],
          [-1.1269e-01, -1.2732e-01, -1.2326e-01, -2.3134e-02,  3.6021e-02],
          [-1.2126e-01, -8.8703e-02,  2.6235e-02,  2.0117e-02, -1.3944e-02],
          [ 5.3939e-03, -3.1349e-03, -3.5279e-02, -6.7626e-02,  3.0802e-03]],

         [[-1.7275e-02, -8.5577e-02, -3.1010e-02,  5.2003e-02,  3.5594e-02],
          [-3.7528e-02, -1.5431e-02, -1.3300e-02,  2.5681e-02,  2.7071e-02],
          [-3.3047e-02,  7.7022e-02,  1.4534e-01,  3.3764e-02, -5.6459e-02],
          [-7.9184e-02, -1.0496e-01,  5.6316e-02,  4.8457e-02,  4.4442e-02],
          [-9.6921e-03,  3.4238e-02,  6.5865e-02, -1.3037e-01, -5.6639e-03]],

         [[ 2.3966e-02, -2.6319e-02, -7.3077e-02,  1.5724e-02, -1.1462e-01],
          [ 7.4743e-03,  1.0931e-01, -6.0105e-02,  1.5413e-02,  9.1886e-03],
          [-1.1045e-02,  1.7926e-01,  4.6779e-02,  5.1318e-02, -3.1479e-02],
          [ 3.1630e-02, -1.9895e-02,  7.6965e-02, -1.3787e-02, -2.1865e-02],
          [-5.1732e-03,  2.7216e-02,  5.2445e-02, -1.9976e-02, -9.4229e-03]],

         ...,

         [[ 4.4623e-03, -1.1078e-01, -8.1224e-02, -5.2614e-02,  1.4525e-02],
          [-1.0609e-01, -2.9393e-02, -6.9127e-02, -6.4361e-03,  2.3775e-02],
          [-1.1578e-02,  1.5554e-02,  1.2460e-01,  2.5628e-02,  5.9685e-03],
          [-3.9694e-02, -4.9132e-02, -1.8039e-02,  1.9739e-02, -1.4211e-02],
          [-2.2699e-02, -4.0336e-02, -1.1081e-01, -7.7913e-02, -6.1865e-03]],

         [[-2.0309e-02, -4.4769e-02, -5.0811e-02,  1.2676e-01,  3.6317e-02],
          [-8.5372e-02,  7.1282e-02, -2.4784e-02,  5.3759e-02,  3.4705e-02],
          [-3.5276e-02, -1.6039e-02,  1.2899e-01,  4.3565e-02,  1.6410e-02],
          [-9.6398e-02, -4.1155e-03,  7.1544e-03, -3.1217e-02, -9.9056e-03],
          [-2.7344e-02, -2.9331e-03, -3.0138e-02,  9.7140e-02,  1.8937e-02]],

         [[ 2.0863e-02, -6.4467e-02, -5.7156e-02, -1.4528e-03,  7.4179e-02],
          [ 1.2406e-01, -4.1317e-02, -1.0962e-01,  1.3267e-03, -7.0722e-03],
          [ 7.6563e-02,  2.2750e-01,  1.6980e-01,  6.9680e-02, -5.6092e-03],
          [ 7.3852e-02,  7.1356e-02,  3.5761e-02,  9.8108e-02, -3.2172e-02],
          [ 4.0001e-03,  1.6621e-02,  5.4809e-02,  1.2247e-03, -6.3127e-04]]],


        [[[ 1.3542e-02,  6.1833e-02, -2.1607e-02, -9.9631e-02, -4.5244e-02],
          [ 4.0962e-02,  1.4580e-01,  2.1202e-01, -3.2674e-02,  1.9910e-02],
          [ 1.7356e-02, -2.6727e-02,  5.7880e-02, -8.8425e-03,  7.7245e-03],
          [-7.4369e-02, -8.9178e-02, -2.0896e-02,  1.8941e-02,  1.2289e-02],
          [-4.1524e-03, -7.6585e-02, -9.4734e-02, -2.7675e-02,  2.8604e-02]],

         [[ 2.1381e-02, -5.8397e-03, -6.4530e-02,  2.5779e-02,  4.0633e-02],
          [-2.4919e-03, -6.6443e-02, -4.6829e-02,  1.0250e-02,  2.2205e-02],
          [-1.6147e-03, -9.8995e-02, -1.0759e-01, -8.1881e-02, -9.3481e-03],
          [ 1.2145e-02, -7.4662e-02, -2.9144e-02, -3.3053e-02,  6.4233e-02],
          [ 4.0649e-03, -6.9973e-02, -6.9487e-02, -1.5520e-03,  9.9027e-02]],

         [[ 3.7282e-03, -7.4936e-02, -1.5140e-01, -8.5434e-02, -8.1469e-02],
          [-1.5122e-02, -6.6859e-02, -1.9008e-01, -1.2684e-02, -6.6302e-04],
          [-1.6901e-02,  2.7704e-02, -3.3585e-02, -6.2315e-02,  6.9518e-02],
          [-7.4157e-03, -6.2042e-02, -2.4645e-02,  1.8645e-02,  3.6175e-02],
          [-1.0551e-02, -5.0660e-02, -6.9920e-02,  7.6595e-03,  2.8964e-02]],

         ...,

         [[-1.2141e-03, -6.2549e-03, -4.2561e-02,  2.6783e-02,  3.7820e-02],
          [-6.6869e-02, -9.2988e-02, -9.3132e-02, -4.6515e-02,  4.6319e-03],
          [-7.0225e-02, -8.2895e-02, -4.5347e-02, -5.2566e-03,  3.1860e-02],
          [-1.2533e-01,  1.8428e-01,  3.4412e-02,  8.0290e-03, -3.0737e-02],
          [-9.3839e-03,  2.5228e-02,  7.3888e-02,  6.4542e-02, -6.7636e-02]],

         [[ 1.2903e-02, -6.2662e-02, -5.1454e-02,  2.1184e-02,  2.2715e-02],
          [-3.7592e-02, -3.7327e-02,  6.2355e-02, -1.7915e-02,  1.5570e-02],
          [-4.5246e-02, -1.0455e-01,  1.2618e-01,  1.1279e-01,  2.1601e-02],
          [-1.3467e-02,  4.8691e-02,  2.7458e-02,  2.5796e-02, -4.2897e-02],
          [ 3.1333e-02, -4.4253e-03,  1.8480e-02,  9.1872e-02, -7.4457e-02]],

         [[ 4.8512e-03, -3.1156e-02, -2.0771e-04,  1.0021e-01,  4.0270e-02],
          [-2.9309e-02, -2.0603e-02, -1.9607e-02,  7.5462e-02, -1.2222e-02],
          [-2.3031e-02,  8.4331e-03,  2.1994e-01, -5.0290e-02, -8.9951e-02],
          [ 8.5276e-02, -1.0847e-01,  1.4220e-02,  5.8195e-02,  3.2639e-03],
          [-7.0981e-03,  5.0145e-02,  5.6687e-02,  7.1623e-02,  3.9372e-02]]],


        [[[ 1.7556e-02, -5.3526e-02, -9.6495e-02, -1.1018e-01, -1.4506e-02],
          [-1.2304e-01,  6.2618e-02, -9.2006e-02,  1.0733e-01,  1.2493e-01],
          [-7.3874e-02,  1.8413e-03, -1.0773e-01,  5.5657e-05,  6.0461e-03],
          [ 6.1553e-02,  5.3680e-03, -6.7597e-02, -3.0684e-02, -3.0293e-02],
          [ 2.1987e-02,  1.7223e-03,  1.2587e-02,  3.0607e-04,  1.8756e-02]],

         [[-3.4604e-03,  2.7052e-02,  5.3447e-02,  4.0976e-02,  2.4240e-02],
          [-6.6288e-02,  6.8663e-02,  6.3159e-02,  1.3515e-01, -3.0649e-02],
          [-5.6368e-02,  9.6684e-02,  4.2195e-02, -3.2818e-03, -1.1096e-02],
          [-1.2731e-02, -8.8172e-03,  3.4234e-02, -3.1216e-02, -1.6840e-02],
          [ 1.4521e-02, -1.6872e-02,  3.2408e-02, -5.6166e-02, -1.8080e-02]],

         [[-2.6597e-02,  9.9129e-02,  1.5203e-01, -9.1428e-03,  6.8058e-03],
          [-2.3043e-02,  1.3051e-02,  1.7428e-01, -1.9567e-02,  2.3549e-02],
          [-5.7581e-02, -9.4979e-02, -1.1450e-01, -5.4465e-02,  1.0136e-02],
          [ 2.5667e-02,  6.4167e-02, -8.6462e-02,  1.4836e-02,  1.1848e-02],
          [-8.2299e-04, -1.8659e-02,  2.5701e-03, -2.1984e-02, -1.3091e-02]],

         ...,

         [[-1.6122e-02, -6.3487e-03, -5.1216e-02,  4.1254e-03, -1.9641e-02],
          [ 1.9293e-02,  7.4781e-02, -2.6139e-02,  9.7114e-02,  1.1414e-01],
          [ 1.7483e-02,  1.0028e-01,  1.6382e-01,  1.0671e-01,  9.3410e-02],
          [-5.8777e-02,  8.3588e-02,  1.4094e-01, -5.9804e-02, -4.4618e-02],
          [-2.3231e-02, -3.9994e-02,  1.0796e-02, -2.0791e-02, -6.8792e-03]],

         [[-2.0183e-02,  3.9970e-02, -7.7079e-03, -1.2964e-01, -9.6777e-03],
          [-1.0771e-02, -1.1962e-02, -8.5207e-02, -2.4580e-02,  4.9249e-02],
          [ 8.1521e-03,  3.4552e-02, -7.2648e-02, -1.5485e-02, -3.3342e-03],
          [-1.0965e-02,  9.1821e-02,  1.2220e-01,  1.7604e-02,  8.9177e-03],
          [ 1.1760e-03,  3.2231e-02,  8.0917e-03,  1.8164e-03, -7.7844e-03]],

         [[-7.9291e-03,  4.5791e-02,  9.4207e-02,  3.0922e-02,  1.0650e-02],
          [ 7.9025e-02,  1.0982e-01, -1.9010e-02,  5.8271e-03, -9.3882e-02],
          [ 3.4671e-02,  1.4512e-01,  4.0422e-02,  5.2456e-04, -5.9904e-02],
          [-4.6497e-02,  8.5727e-02,  6.7073e-02, -5.2215e-02,  1.9254e-02],
          [-7.3523e-03, -4.2680e-02,  8.0739e-03, -2.3151e-02, -1.0494e-02]]],


        [[[ 6.2292e-03,  6.4049e-03,  8.0969e-02, -1.0666e-02, -3.1286e-02],
          [-9.9819e-03, -7.1331e-02,  1.0347e-02,  1.3140e-01,  3.3983e-02],
          [-2.6298e-02,  5.3794e-02,  1.1446e-02,  1.0552e-01, -3.8344e-02],
          [ 1.1574e-02,  1.9256e-01,  2.7716e-02, -1.5460e-02, -3.6513e-02],
          [-3.2404e-02, -2.2494e-02, -4.7332e-02, -2.6215e-02, -2.7994e-02]],

         [[-5.0208e-02,  2.8215e-02,  1.0351e-01, -5.5430e-02,  1.1864e-02],
          [-1.7449e-02,  6.3746e-02,  9.7160e-02,  2.6712e-03, -3.4787e-02],
          [-7.4605e-03,  3.1053e-02,  8.7243e-02,  1.5801e-01,  1.4950e-03],
          [-4.3921e-02, -4.5282e-02,  3.3961e-02, -6.0017e-02, -6.2506e-02],
          [-1.5811e-03, -2.9899e-02,  9.1146e-02,  1.6151e-02,  4.2697e-03]],

         [[ 8.8792e-03,  7.3598e-02, -5.2877e-02,  6.7929e-02,  1.3971e-02],
          [-3.8167e-02, -4.9644e-02,  1.7035e-04,  1.6999e-01,  8.4198e-02],
          [ 8.8007e-03, -6.5643e-02, -1.9837e-02, -4.7380e-02,  6.3316e-02],
          [ 1.0229e-02,  9.9248e-02,  1.5522e-01, -2.5006e-02,  1.8875e-02],
          [ 2.1762e-02,  3.3324e-02,  2.8846e-02, -2.8463e-02,  1.2072e-02]],

         ...,

         [[ 5.6472e-03, -6.9877e-02, -3.4396e-02, -5.7747e-02, -5.7253e-03],
          [ 1.6410e-02,  1.4428e-02,  6.2817e-02, -8.9715e-02, -5.4645e-02],
          [ 3.1401e-02,  4.8496e-02, -1.0858e-03, -4.1402e-02,  6.1825e-02],
          [-1.1878e-02, -4.3808e-02, -1.5755e-01, -1.0781e-02,  3.3251e-02],
          [ 1.8555e-02, -1.0060e-02, -9.7576e-03,  1.7578e-03,  1.1129e-02]],

         [[-1.5703e-02, -1.1518e-01, -1.2262e-03, -4.3114e-02, -7.4231e-03],
          [ 3.4700e-02,  3.7838e-03,  7.1406e-02,  6.5852e-02,  3.0697e-02],
          [ 7.2112e-02,  1.0902e-01,  4.4993e-02, -9.4910e-02,  2.6438e-02],
          [-9.2478e-03, -9.4849e-02, -4.8631e-03,  1.1768e-01,  1.6055e-01],
          [ 2.6985e-02,  3.1785e-02, -1.6888e-03,  2.1570e-02,  2.1408e-02]],

         [[-4.0965e-02,  1.8099e-02,  6.9508e-02,  4.5105e-02,  2.3487e-02],
          [ 4.1605e-02,  1.0653e-01,  8.1115e-02,  2.1311e-02, -2.3564e-02],
          [ 3.8858e-02,  1.3658e-01,  4.5345e-02,  2.8556e-02, -9.5223e-02],
          [-2.9148e-02, -8.4276e-02, -8.8266e-03, -1.4996e-01, -1.4201e-01],
          [ 3.0560e-03,  2.9154e-03,  6.1500e-02,  4.9793e-03, -1.7087e-02]]]])
DESIRED: (shape=torch.Size([4, 22817014, 5, 5]), dtype=torch.float32)
tensor([[[[-1.3466e-01, -8.3856e-02, -4.0620e-02,  1.6744e-01, -2.0845e-01],
          [-3.6318e-01, -7.3198e-02, -1.5398e-02,  8.7980e-02,  1.4114e-02],
          [-2.2539e-01, -2.5463e-01, -2.4653e-01, -4.6269e-02,  7.2042e-02],
          [-2.4253e-01, -1.7741e-01,  5.2469e-02,  4.0233e-02, -2.7888e-02],
          [ 1.0788e-02, -6.2697e-03, -7.0559e-02, -1.3525e-01,  6.1604e-03]],

         [[-3.4549e-02, -1.7115e-01, -6.2020e-02,  1.0401e-01,  7.1189e-02],
          [-7.5056e-02, -3.0862e-02, -2.6599e-02,  5.1362e-02,  5.4141e-02],
          [-6.6094e-02,  1.5404e-01,  2.9069e-01,  6.7528e-02, -1.1292e-01],
          [-1.5837e-01, -2.0992e-01,  1.1263e-01,  9.6914e-02,  8.8885e-02],
          [-1.9384e-02,  6.8475e-02,  1.3173e-01, -2.6075e-01, -1.1328e-02]],

         [[ 4.7932e-02, -5.2639e-02, -1.4615e-01,  3.1447e-02, -2.2924e-01],
          [ 1.4949e-02,  2.1863e-01, -1.2021e-01,  3.0827e-02,  1.8377e-02],
          [-2.2090e-02,  3.5852e-01,  9.3559e-02,  1.0264e-01, -6.2958e-02],
          [ 6.3259e-02, -3.9789e-02,  1.5393e-01, -2.7575e-02, -4.3729e-02],
          [-1.0346e-02,  5.4432e-02,  1.0489e-01, -3.9952e-02, -1.8846e-02]],

         ...,

         [[ 1.8979e-02,  2.3180e-02,  5.8932e-02, -1.9826e-02,  1.6364e-02],
          [ 1.0617e-01, -5.9872e-03,  2.2324e-02,  2.9518e-01,  1.3668e-01],
          [-4.5346e-02, -3.2871e-01,  1.1224e-01,  7.1641e-02,  9.6278e-02],
          [ 8.3286e-03,  2.9167e-02,  1.6168e-01, -7.5777e-02, -3.7113e-02],
          [-1.5382e-02, -1.7360e-02,  5.5142e-02, -1.4260e-01, -4.2409e-02]],

         [[-4.8482e-04,  4.6391e-02,  1.1303e-01,  1.3533e-01,  1.9451e-02],
          [ 2.9273e-02,  8.3007e-03,  3.6719e-03, -2.7847e-02,  1.3805e-01],
          [-8.4810e-02, -2.7006e-03, -1.0019e-01, -1.2886e-01, -1.0306e-01],
          [-5.9440e-02,  4.8750e-02,  1.6203e-01, -1.1860e-01, -9.8169e-03],
          [-2.0750e-02, -9.8923e-04,  1.7436e-02, -9.7896e-02, -1.3721e-01]],

         [[-1.0044e-03, -6.5648e-02, -1.1881e-01, -1.2482e-02,  4.2748e-02],
          [-2.1476e-02,  4.6712e-02, -1.1010e-01, -9.0716e-02, -5.6212e-02],
          [-1.4600e-01, -8.2004e-02,  3.7602e-02, -1.8048e-01, -4.7139e-02],
          [ 4.2377e-02,  6.0267e-01,  2.2320e-02, -2.5771e-01,  1.6236e-02],
          [ 9.8999e-03, -2.6502e-03, -6.9608e-02, -5.1768e-02,  2.3850e-03]]],


        [[[ 2.7084e-02,  1.2367e-01, -4.3213e-02, -1.9926e-01, -9.0488e-02],
          [ 8.1924e-02,  2.9159e-01,  4.2405e-01, -6.5347e-02,  3.9821e-02],
          [ 3.4712e-02, -5.3454e-02,  1.1576e-01, -1.7685e-02,  1.5449e-02],
          [-1.4874e-01, -1.7836e-01, -4.1792e-02,  3.7881e-02,  2.4578e-02],
          [-8.3047e-03, -1.5317e-01, -1.8947e-01, -5.5350e-02,  5.7208e-02]],

         [[ 4.2763e-02, -1.1679e-02, -1.2906e-01,  5.1558e-02,  8.1265e-02],
          [-4.9838e-03, -1.3289e-01, -9.3657e-02,  2.0500e-02,  4.4411e-02],
          [-3.2294e-03, -1.9799e-01, -2.1518e-01, -1.6376e-01, -1.8696e-02],
          [ 2.4290e-02, -1.4932e-01, -5.8288e-02, -6.6105e-02,  1.2847e-01],
          [ 8.1298e-03, -1.3995e-01, -1.3897e-01, -3.1040e-03,  1.9805e-01]],

         [[ 7.4564e-03, -1.4987e-01, -3.0279e-01, -1.7087e-01, -1.6294e-01],
          [-3.0244e-02, -1.3372e-01, -3.8017e-01, -2.5367e-02, -1.3260e-03],
          [-3.3802e-02,  5.5408e-02, -6.7170e-02, -1.2463e-01,  1.3904e-01],
          [-1.4831e-02, -1.2408e-01, -4.9290e-02,  3.7289e-02,  7.2349e-02],
          [-2.1103e-02, -1.0132e-01, -1.3984e-01,  1.5319e-02,  5.7928e-02]],

         ...,

         [[ 3.0057e-02, -1.5767e-01, -9.6043e-02, -1.1101e-01, -4.2093e-03],
          [-7.8101e-02, -4.4334e-02,  6.8237e-02,  9.8564e-02,  1.7602e-02],
          [-1.7150e-01, -2.3287e-01, -1.2590e-01,  1.3920e-01,  6.2359e-02],
          [-4.2167e-02, -1.2258e-01, -6.5224e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 2.0485e-01,  2.5022e-01,  3.9587e-01,  1.5596e-04, -6.4675e-03],
          [ 8.1122e-04,  2.6625e-01,  1.9843e-01,  8.0439e-02,  2.3912e-03],
          [-8.4891e-02,  5.7692e-02, -4.2779e-03,  2.7455e-02,  1.0093e-02],
          [-2.2378e-02, -8.3370e-02, -1.1196e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 2.7884e-02, -1.3307e-01, -2.1299e-01, -2.7303e-01, -1.0620e-02],
          [-9.9174e-02,  1.5090e-01, -8.3356e-02, -1.8923e-01, -1.7733e-02],
          [-5.7348e-02,  1.6971e-01,  6.0407e-02, -1.3041e-01, -5.8737e-02],
          [-1.3964e-02, -2.7556e-02,  7.0078e-03,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 3.5111e-02, -1.0705e-01, -1.9299e-01, -2.2036e-01, -2.9012e-02],
          [-2.4608e-01,  1.2524e-01, -1.8401e-01,  2.1465e-01,  2.4985e-01],
          [-1.4775e-01,  3.6825e-03, -2.1547e-01,  1.1132e-04,  1.2092e-02],
          [ 1.2311e-01,  1.0736e-02, -1.3519e-01, -6.1368e-02, -6.0587e-02],
          [ 4.3975e-02,  3.4447e-03,  2.5174e-02,  6.1214e-04,  3.7511e-02]],

         [[-6.9208e-03,  5.4103e-02,  1.0689e-01,  8.1952e-02,  4.8481e-02],
          [-1.3258e-01,  1.3733e-01,  1.2632e-01,  2.7030e-01, -6.1298e-02],
          [-1.1274e-01,  1.9337e-01,  8.4390e-02, -6.5635e-03, -2.2191e-02],
          [-2.5463e-02, -1.7634e-02,  6.8467e-02, -6.2431e-02, -3.3681e-02],
          [ 2.9041e-02, -3.3745e-02,  6.4816e-02, -1.1233e-01, -3.6161e-02]],

         [[-5.3194e-02,  1.9826e-01,  3.0405e-01, -1.8286e-02,  1.3612e-02],
          [-4.6085e-02,  2.6102e-02,  3.4857e-01, -3.9135e-02,  4.7098e-02],
          [-1.1516e-01, -1.8996e-01, -2.2901e-01, -1.0893e-01,  2.0272e-02],
          [ 5.1335e-02,  1.2833e-01, -1.7292e-01,  2.9673e-02,  2.3697e-02],
          [-1.6460e-03, -3.7318e-02,  5.1401e-03, -4.3967e-02, -2.6182e-02]],

         ...,

         [[-2.5756e-03,  2.4189e-02,  3.0055e-02, -1.4529e-02,  8.0888e-03],
          [ 2.7456e-02,  1.8921e-01, -9.0486e-03,  1.8321e-01,  1.3860e-01],
          [ 6.8918e-02,  1.1241e-01,  5.0159e-02,  9.5934e-02, -7.0576e-02],
          [-2.6985e-01, -1.1036e-01,  3.2354e-01, -6.0114e-02, -1.0352e-01],
          [-4.0392e-02, -5.4929e-02,  4.7729e-02, -2.0791e-02, -6.8792e-03]],

         [[ 1.1865e-03,  3.7024e-02, -3.8448e-02,  1.0822e-02,  6.3229e-02],
          [ 3.1047e-02,  1.3615e-01, -1.0101e-01, -9.2848e-02,  1.3337e-02],
          [ 1.2369e-01,  1.4465e-02,  1.7508e-01, -1.2398e-01, -2.5029e-02],
          [ 5.4638e-02,  2.2016e-01,  3.5571e-01,  1.4469e-02,  1.0276e-02],
          [ 2.5988e-03,  3.3763e-02,  5.2063e-02,  1.8164e-03, -7.7844e-03]],

         [[ 3.5511e-02, -1.8299e-02, -1.7024e-01,  6.8636e-03, -4.5245e-03],
          [ 6.5119e-02,  3.6399e-02, -2.0565e-01,  1.0504e-01, -4.2621e-02],
          [-6.1095e-03,  4.1367e-02,  1.2270e-01,  8.9734e-02,  1.1081e-01],
          [-1.3528e-01,  1.4441e-02,  5.6894e-02, -5.6498e-02,  7.6652e-02],
          [-1.4883e-02, -4.9352e-02,  5.4763e-03, -2.3151e-02, -1.0494e-02]]],


        [[[ 1.2458e-02,  1.2810e-02,  1.6194e-01, -2.1333e-02, -6.2571e-02],
          [-1.9964e-02, -1.4266e-01,  2.0694e-02,  2.6280e-01,  6.7965e-02],
          [-5.2596e-02,  1.0759e-01,  2.2892e-02,  2.1104e-01, -7.6688e-02],
          [ 2.3148e-02,  3.8513e-01,  5.5431e-02, -3.0920e-02, -7.3025e-02],
          [-6.4809e-02, -4.4989e-02, -9.4664e-02, -5.2429e-02, -5.5989e-02]],

         [[-1.0042e-01,  5.6430e-02,  2.0702e-01, -1.1086e-01,  2.3728e-02],
          [-3.4899e-02,  1.2749e-01,  1.9432e-01,  5.3424e-03, -6.9574e-02],
          [-1.4921e-02,  6.2106e-02,  1.7449e-01,  3.1602e-01,  2.9901e-03],
          [-8.7842e-02, -9.0564e-02,  6.7922e-02, -1.2003e-01, -1.2501e-01],
          [-3.1622e-03, -5.9799e-02,  1.8229e-01,  3.2302e-02,  8.5394e-03]],

         [[ 1.7758e-02,  1.4720e-01, -1.0575e-01,  1.3586e-01,  2.7941e-02],
          [-7.6334e-02, -9.9287e-02,  3.4071e-04,  3.3998e-01,  1.6840e-01],
          [ 1.7601e-02, -1.3129e-01, -3.9673e-02, -9.4761e-02,  1.2663e-01],
          [ 2.0457e-02,  1.9850e-01,  3.1044e-01, -5.0011e-02,  3.7751e-02],
          [ 4.3524e-02,  6.6648e-02,  5.7692e-02, -5.6926e-02,  2.4144e-02]],

         ...,

         [[ 5.6472e-03, -6.0176e-02,  8.0057e-02, -2.4436e-02, -3.1259e-03],
          [ 2.2023e-03, -1.0724e-01,  1.6963e-01, -1.3211e-01, -1.5346e-02],
          [-4.3009e-02, -1.3131e-01,  1.4843e-01,  9.7679e-02, -1.5585e-01],
          [ 1.1920e-01, -1.7467e-02, -3.6461e-01, -5.8691e-02, -5.4569e-02],
          [ 1.8882e-02,  7.3267e-02, -1.6264e-01, -1.8873e-01, -1.2871e-01]],

         [[-1.5703e-02, -1.0893e-01,  5.3516e-02, -3.9291e-02, -1.3001e-02],
          [ 3.4017e-02, -6.2094e-02,  3.7988e-02,  3.3666e-01, -3.1541e-02],
          [-3.6750e-03, -2.3687e-01,  7.1162e-02,  1.3431e-01, -1.3554e-01],
          [-8.9819e-02, -1.2915e-01,  4.6401e-01, -6.8503e-02,  1.2208e-02],
          [-1.0164e-02, -2.2483e-01, -2.5642e-01,  1.3218e-01,  3.9847e-02]],

         [[-4.0965e-02,  1.1025e-02,  1.9151e-02,  1.8703e-02,  8.9979e-03],
          [ 2.3026e-02,  9.8828e-02, -4.1122e-02, -2.3705e-01, -3.1564e-02],
          [-1.5197e-02, -2.4909e-01, -3.6905e-01,  2.6391e-01,  1.3274e-01],
          [ 1.7160e-01,  2.9507e-02, -1.8411e-01, -2.0314e-02,  6.8425e-02],
          [ 8.9391e-03, -7.5864e-02, -5.7833e-02,  2.0074e-01,  1.0865e-01]]]])

2025-07-26 13:53:47.350542 GPU 6 14613 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([5070448, 5, 5, 5],"float32"), offset=Tensor([5070448, 18, 5, 5],"float32"), mask=Tensor([5070448, 9, 5, 5],"float32"), weight=Tensor([5, 1, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=5, )
[accuracy error] backward paddle.vision.ops.deform_conv2d(x=Tensor([5070448, 5, 5, 5],"float32"), offset=Tensor([5070448, 18, 5, 5],"float32"), mask=Tensor([5070448, 9, 5, 5],"float32"), weight=Tensor([5, 1, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=5, )
Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 5 / 2281701600 (0.0%)
Greatest absolute difference: 0.03988981992006302 at index (3852212, 2, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (632496, 2, 0, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5070448, 18, 5, 5]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8317e-05],
          [ 3.0849e-03, -4.8833e-02, -2.4611e-02, -1.6140e-02, -1.1628e-03],
          [ 0.0000e+00,  6.3886e-02,  2.3387e-03, -1.1537e-02, -3.3222e-02],
          [ 0.0000e+00, -1.0881e-03,  3.8497e-04,  8.6690e-04, -2.3310e-02],
          [ 0.0000e+00, -2.1894e-03,  1.1271e-02, -3.3418e-03,  1.5706e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1747e-03],
          [ 5.2059e-03, -1.9778e-02,  3.8931e-02,  2.2195e-02,  9.0229e-04],
          [ 0.0000e+00, -2.1000e-02, -5.7219e-03,  8.9877e-03,  3.9798e-02],
          [ 0.0000e+00,  3.5681e-03,  6.8764e-05,  1.5050e-02, -6.9481e-02],
          [ 0.0000e+00, -1.3035e-03,  7.1992e-04,  6.3536e-04, -3.7315e-02]],

         [[ 0.0000e+00,  1.9086e-02,  7.4179e-03,  0.0000e+00,  8.7325e-03],
          [ 1.5188e-02,  1.4816e-02, -3.8837e-02, -5.3473e-03, -2.1273e-02],
          [ 8.0700e-03, -8.4069e-02, -6.0452e-02, -2.4266e-03,  1.9044e-02],
          [-2.2135e-02,  4.8189e-03,  9.5073e-03,  4.8850e-03,  7.2099e-03],
          [ 2.9742e-02, -2.1515e-02, -1.1917e-02, -1.7463e-02,  5.3703e-03]],

         ...,

         [[ 8.2269e-03,  1.1653e-02,  8.4828e-05, -1.4372e-02,  5.1161e-03],
          [ 6.1695e-05, -1.7977e-02,  7.1136e-03, -1.3643e-02,  2.1050e-03],
          [-2.5844e-02, -9.6510e-03, -6.9037e-04,  1.8444e-03, -6.5337e-03],
          [-1.5079e-03,  3.5168e-03,  4.1159e-03, -3.7297e-03,  2.5343e-03],
          [ 0.0000e+00, -2.8371e-05,  0.0000e+00,  4.0130e-03,  2.5801e-03]],

         [[-2.8214e-02,  2.3561e-02, -1.7534e-03,  2.1780e-02,  0.0000e+00],
          [ 2.5593e-03,  2.2103e-02, -1.7846e-02, -7.7257e-03,  1.3951e-04],
          [ 2.8659e-02, -7.8075e-03,  3.9641e-03, -5.6890e-04,  2.6297e-03],
          [ 7.9058e-03,  6.4810e-04,  2.0739e-03,  6.3834e-03,  0.0000e+00],
          [-8.0967e-03, -2.7069e-03, -1.3946e-03,  3.9021e-04,  0.0000e+00]],

         [[ 3.0696e-02, -6.8280e-02, -2.3156e-04,  2.2845e-02,  0.0000e+00],
          [ 1.2524e-03,  4.6515e-02,  7.6439e-05, -4.2047e-02,  3.4722e-03],
          [-8.6548e-03, -4.3668e-03,  1.1107e-02,  1.6288e-02,  1.8847e-02],
          [ 1.4223e-02,  1.5404e-03, -2.8123e-03, -2.8888e-02,  0.0000e+00],
          [-1.2667e-02,  2.2029e-03,  3.2101e-05, -9.7745e-05,  0.0000e+00]]],


        [[[ 2.0926e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1551e-03],
          [-1.0033e-02,  1.5277e-02,  1.0907e-03, -2.1497e-03,  2.9395e-04],
          [-3.9528e-03, -3.3597e-04,  8.2739e-04,  5.4004e-03, -1.9171e-02],
          [ 7.5502e-05,  9.2257e-03, -1.2436e-02, -1.0436e-03, -2.9039e-03],
          [ 0.0000e+00, -9.0557e-03, -1.8584e-02,  1.5524e-03,  1.6904e-02]],

         [[ 3.5325e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4800e-04],
          [-1.3019e-02, -1.1002e-02, -1.4513e-03, -7.0392e-03, -2.6942e-03],
          [ 1.1511e-02,  1.1966e-03, -5.5759e-03, -3.5183e-04,  2.7847e-02],
          [-2.5337e-02,  1.2026e-02,  1.3456e-02,  8.1894e-04,  1.5075e-02],
          [ 0.0000e+00,  4.0805e-03,  6.1193e-03,  1.2717e-02, -3.2370e-04]],

         [[ 1.3767e-03,  0.0000e+00,  1.8678e-03,  0.0000e+00,  1.3508e-02],
          [-1.3295e-02, -4.6130e-03,  4.9138e-04,  1.0530e-02, -1.9585e-03],
          [-1.2564e-02, -2.0045e-02,  2.5994e-04, -1.4362e-02,  3.4267e-03],
          [-2.4077e-02, -2.2312e-02,  4.4760e-03, -1.1309e-02,  3.6217e-02],
          [-5.0746e-03, -6.2518e-03, -4.6583e-03,  5.4524e-03, -3.9696e-02]],

         ...,

         [[-5.8571e-03, -1.9562e-03,  2.5297e-03, -2.6395e-03, -1.0073e-03],
          [-3.9583e-03,  6.7881e-03,  2.3522e-03, -3.0747e-03,  5.4074e-03],
          [-9.4527e-04,  2.1137e-02, -1.6108e-02,  1.5853e-02,  1.8445e-03],
          [ 1.7319e-02, -1.7018e-02, -2.1820e-02,  4.0290e-03, -1.1486e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8099e-03, -2.2344e-03]],

         [[-2.9079e-02, -1.4759e-02, -1.4922e-02,  2.4968e-04,  0.0000e+00],
          [-6.1021e-03, -2.7519e-03, -7.8644e-03,  2.1851e-02,  5.9348e-03],
          [ 1.5385e-02, -8.1439e-03,  2.1528e-02, -4.3263e-03,  0.0000e+00],
          [ 8.0825e-03, -8.2574e-04,  3.3168e-02,  8.0369e-04,  4.0968e-03],
          [ 0.0000e+00,  0.0000e+00, -8.9430e-03,  0.0000e+00,  0.0000e+00]],

         [[-8.2020e-03, -2.1411e-02, -2.8528e-03, -3.2622e-03,  0.0000e+00],
          [ 3.5993e-03,  1.4276e-02,  6.9375e-03,  1.5194e-02,  1.8717e-02],
          [-1.2029e-02,  3.0835e-02,  2.6239e-02, -1.1710e-03,  0.0000e+00],
          [ 1.4968e-02, -2.0738e-02, -1.3290e-02,  2.2376e-03,  1.5139e-02],
          [ 0.0000e+00,  0.0000e+00,  8.9208e-05,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7985e-03,  0.0000e+00],
          [ 2.1725e-03, -4.2207e-03, -6.2317e-03, -3.6997e-02,  1.7026e-02],
          [ 3.3037e-03, -1.5334e-02, -2.4289e-03,  9.8940e-03, -4.5188e-02],
          [ 0.0000e+00, -4.6385e-03, -3.1245e-03,  9.7219e-04,  1.8667e-02],
          [-4.1875e-03,  1.0522e-03,  3.6058e-03,  3.6300e-03, -2.1599e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0943e-04,  0.0000e+00],
          [ 5.0886e-03, -3.3454e-03,  1.4691e-03, -1.4013e-02, -7.4835e-03],
          [ 2.3332e-02, -3.4920e-02,  1.3836e-02, -1.3463e-03,  1.2968e-02],
          [ 0.0000e+00, -8.7983e-03,  2.0580e-02,  4.6890e-02,  9.9177e-03],
          [ 8.6294e-03,  9.2225e-04,  3.5899e-03,  2.3733e-02,  1.3129e-02]],

         [[ 0.0000e+00, -4.6315e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 1.3504e-02,  1.7125e-04, -8.4923e-03,  6.6375e-02,  1.9120e-03],
          [-1.8835e-02, -1.1297e-02,  1.4496e-03, -4.4576e-04, -2.1655e-02],
          [-1.9851e-03, -1.4278e-02, -5.7463e-03,  8.6711e-03, -4.6426e-02],
          [ 1.0370e-02,  4.0568e-04,  3.5408e-03, -1.7510e-02,  2.9307e-02]],

         ...,

         [[-1.7194e-02, -2.6361e-02, -3.5606e-02, -1.8316e-03, -6.9010e-04],
          [ 2.5754e-03,  4.6210e-03,  8.4187e-05,  9.6157e-03, -1.9294e-03],
          [ 3.0962e-03,  1.4845e-02,  4.1089e-04, -3.9285e-03, -3.4960e-03],
          [-3.1187e-04, -2.8361e-02,  1.8122e-03, -4.9095e-03, -3.3764e-02],
          [-1.0748e-03,  0.0000e+00,  0.0000e+00, -4.9881e-04, -4.0927e-04]],

         [[-2.4307e-02, -6.2145e-03, -7.9709e-03, -6.0510e-03, -2.6155e-03],
          [-1.4222e-02,  3.0656e-03, -1.8956e-02,  4.2982e-03, -3.1130e-03],
          [ 6.5894e-03,  1.1541e-02,  2.8569e-03,  2.2657e-04,  0.0000e+00],
          [ 1.5040e-02,  1.2187e-02,  7.9678e-03, -1.1081e-02,  0.0000e+00],
          [ 0.0000e+00,  3.4848e-03, -1.1220e-03,  0.0000e+00,  0.0000e+00]],

         [[-2.4921e-02, -2.5519e-03, -1.2477e-03,  2.0521e-03,  8.4767e-04],
          [-3.2523e-02, -1.8031e-02,  8.0609e-03, -1.8413e-03,  1.1235e-02],
          [ 6.7963e-04,  2.2042e-02, -8.5286e-03,  1.2380e-05,  0.0000e+00],
          [-1.5478e-02,  1.5247e-02,  1.1304e-02, -8.7337e-03,  0.0000e+00],
          [ 0.0000e+00, -2.6627e-05, -2.3007e-03,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[-9.5558e-05,  0.0000e+00,  2.2334e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  5.9548e-03,  5.1446e-02,  1.7320e-02, -9.9072e-03],
          [ 1.7518e-04, -3.4568e-03,  4.2448e-03, -6.3478e-03, -2.1156e-02],
          [-2.8166e-03, -5.1115e-03, -1.8621e-03, -4.6873e-02,  8.1338e-03],
          [ 0.0000e+00,  5.2279e-03,  9.1105e-03,  3.0206e-03, -6.6883e-03]],

         [[-1.3586e-03,  0.0000e+00, -3.8802e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  3.6407e-03, -5.9463e-02, -6.3533e-03,  1.3038e-02],
          [ 1.3035e-02,  8.1554e-03, -1.3418e-02, -2.2149e-02,  9.7895e-03],
          [ 1.1023e-03,  1.5921e-03,  4.1562e-03,  6.7573e-03, -1.9075e-02],
          [ 0.0000e+00,  1.9121e-02, -1.1142e-02, -1.0926e-02,  7.3898e-03]],

         [[ 7.7550e-03, -3.2615e-02, -3.1084e-03,  0.0000e+00,  0.0000e+00],
          [ 4.7396e-03,  1.0483e-02, -4.8982e-03, -4.4402e-03, -7.1672e-03],
          [ 5.6094e-02,  2.3163e-02,  3.2811e-02, -3.0486e-03, -5.6161e-03],
          [-4.7959e-03, -5.4150e-03,  2.8131e-02,  1.0141e-02,  1.0508e-03],
          [-3.0909e-03, -2.3153e-03, -5.4113e-04, -2.3812e-03,  6.0154e-03]],

         ...,

         [[-1.2766e-02, -2.8442e-02, -6.2006e-03, -1.5678e-03,  1.0824e-02],
          [-4.8445e-04,  6.1537e-03, -1.2429e-02,  5.8550e-03, -5.0319e-03],
          [ 5.8911e-03, -2.3368e-03,  8.7627e-03,  2.9113e-02,  1.3761e-02],
          [-1.2926e-02,  1.5024e-02,  4.0240e-02,  2.3081e-02,  4.2035e-03],
          [-1.3845e-03,  2.4409e-04, -8.2207e-03, -2.7537e-03,  0.0000e+00]],

         [[ 7.7079e-03,  1.5131e-02, -1.2095e-02, -3.5980e-02,  1.1030e-05],
          [-2.2016e-02,  1.1057e-02, -2.2561e-03,  2.0460e-04,  0.0000e+00],
          [ 1.7091e-02,  2.7420e-02, -3.5045e-04,  7.2195e-03,  4.6974e-03],
          [ 2.1477e-03,  2.6165e-02,  2.8087e-03, -5.6314e-03,  0.0000e+00],
          [ 0.0000e+00,  6.3268e-04,  2.4526e-02,  0.0000e+00,  0.0000e+00]],

         [[ 6.4335e-03, -4.7895e-03, -1.3337e-02, -3.6559e-02, -3.0099e-05],
          [-8.7620e-04,  1.1988e-02, -2.5520e-03, -5.7556e-04,  0.0000e+00],
          [-9.8010e-03, -1.9416e-03, -3.7617e-03, -5.5726e-03,  1.6200e-03],
          [-1.1438e-02,  1.3390e-02,  7.1302e-03,  5.6725e-03,  0.0000e+00],
          [ 0.0000e+00, -7.8323e-04, -2.0999e-02,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  1.8505e-02,  0.0000e+00, -3.1147e-03],
          [ 0.0000e+00,  4.9771e-03, -1.2477e-02, -1.5925e-02, -9.4735e-03],
          [ 0.0000e+00,  4.3384e-03, -1.3428e-03, -1.8215e-03,  1.2212e-03],
          [ 0.0000e+00,  1.4733e-02,  5.1796e-03, -1.2331e-02, -1.6476e-02],
          [ 0.0000e+00, -5.0342e-02, -3.1699e-03,  7.3149e-03,  8.8832e-02]],

         [[ 0.0000e+00,  0.0000e+00,  2.1738e-03,  0.0000e+00, -4.3133e-03],
          [ 0.0000e+00,  3.4307e-03,  5.4956e-03,  1.3218e-02,  8.8409e-03],
          [ 0.0000e+00,  5.5219e-03,  5.9494e-02, -4.7588e-03,  2.0957e-02],
          [ 0.0000e+00,  2.1650e-02, -2.9094e-04,  1.4611e-02, -1.6120e-02],
          [ 0.0000e+00,  2.7212e-02,  1.4058e-02, -5.3170e-03, -6.9189e-02]],

         [[ 0.0000e+00,  4.2906e-04,  0.0000e+00, -1.9929e-02,  0.0000e+00],
          [ 2.6811e-03, -2.4075e-03,  1.0451e-02,  1.3917e-02, -1.6403e-02],
          [-2.2975e-02,  7.5037e-04, -3.9265e-03,  1.2599e-02,  3.9478e-02],
          [ 4.0945e-02, -1.2649e-04, -1.9919e-02,  2.3088e-03, -3.8392e-03],
          [ 2.9597e-03,  1.2883e-02, -1.5414e-03,  1.5087e-02, -6.0699e-02]],

         ...,

         [[-9.2641e-03,  3.9060e-03,  8.8231e-03, -1.1494e-02, -2.9390e-03],
          [-6.0756e-03,  8.8592e-03,  5.5370e-03,  5.0156e-02,  1.0460e-02],
          [ 9.9242e-04, -1.1773e-03, -9.7930e-03,  9.6034e-04, -1.2733e-03],
          [ 4.1701e-03, -6.5096e-04,  2.1488e-02,  2.1904e-03,  2.8624e-03],
          [-8.2793e-04, -8.6205e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0289e-02, -2.1998e-04, -6.2454e-03, -2.8557e-04,  1.3471e-03],
          [ 1.3348e-02, -2.6736e-04, -6.7518e-03, -1.0211e-02,  0.0000e+00],
          [ 3.0374e-02,  7.9967e-03,  1.6575e-03,  1.5265e-04, -5.9324e-04],
          [ 1.2426e-02, -7.1720e-04, -3.1251e-03, -1.5330e-02,  0.0000e+00],
          [ 1.0229e-02,  1.3500e-02, -1.2606e-03,  0.0000e+00,  0.0000e+00]],

         [[-6.7132e-03,  2.2247e-03, -2.1737e-02, -4.5726e-05,  1.9206e-03],
          [-3.3563e-03, -1.8210e-03,  1.1778e-02, -4.7900e-02,  0.0000e+00],
          [ 1.4833e-02, -1.4776e-02,  1.3573e-02, -1.4884e-03,  1.7241e-03],
          [-1.0501e-02, -1.8635e-03,  7.6593e-04,  9.3423e-04,  0.0000e+00],
          [-6.8356e-03,  2.0481e-04, -5.7754e-04,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  6.0159e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  2.3902e-03,  2.3095e-04,  7.8643e-03,  6.6476e-03],
          [ 6.5665e-04, -1.1439e-02, -3.7443e-04, -6.8454e-02, -1.9713e-02],
          [ 7.8457e-04, -1.8651e-04,  9.5063e-03,  3.7864e-02, -9.9957e-03],
          [-8.2924e-05, -5.2273e-03,  8.7332e-03, -4.9149e-03,  1.1136e-02]],

         [[ 0.0000e+00,  1.2262e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.2138e-03,  5.8284e-04, -1.8537e-02, -5.4559e-03],
          [-1.7821e-02, -1.1193e-02,  6.8112e-04, -4.7949e-02, -1.4629e-03],
          [ 2.6165e-02,  6.8480e-03, -1.7919e-03,  3.3961e-03, -1.6772e-02],
          [ 3.2933e-03,  8.6542e-03,  5.1176e-03, -7.6746e-04,  8.4543e-03]],

         [[-5.9028e-04, -1.7806e-02,  0.0000e+00,  0.0000e+00, -6.3015e-04],
          [-7.5884e-04, -2.8383e-02,  1.5827e-02, -1.8935e-02, -8.7359e-02],
          [ 5.1759e-04, -6.0207e-03,  1.9753e-02, -1.2164e-02,  8.7674e-03],
          [-4.8517e-03,  1.6452e-03, -3.7841e-02, -1.4419e-02, -8.3297e-03],
          [ 3.9789e-03, -3.1354e-02, -3.9954e-02, -2.3010e-02,  3.4180e-02]],

         ...,

         [[ 1.5154e-03, -9.1779e-03, -8.0703e-05,  8.4531e-03, -2.0963e-03],
          [ 3.3274e-03, -1.9579e-03,  3.9010e-03,  1.6628e-03, -4.4800e-03],
          [-1.4812e-02, -1.4579e-02,  2.2092e-03, -4.7264e-03,  3.3963e-03],
          [ 1.4124e-02,  2.0356e-02,  1.1573e-02,  5.5134e-02,  1.0020e-02],
          [ 4.1652e-03,  0.0000e+00,  7.5125e-04,  0.0000e+00,  0.0000e+00]],

         [[ 2.8187e-04, -1.8974e-02,  3.6611e-02, -1.5566e-02, -3.2110e-05],
          [ 6.6351e-03, -5.4580e-02,  2.2110e-02,  6.4020e-03,  0.0000e+00],
          [ 4.9070e-03,  1.3497e-02, -4.8873e-02,  1.2342e-02,  0.0000e+00],
          [-1.2414e-03, -2.1684e-02,  1.5405e-03,  5.1515e-03,  0.0000e+00],
          [-2.7568e-02,  0.0000e+00,  3.2827e-04,  9.3425e-04,  0.0000e+00]],

         [[-3.3275e-03,  2.6660e-02,  4.7725e-02,  1.2320e-03,  3.9220e-05],
          [-1.1312e-03, -4.3202e-02,  1.5616e-03,  9.2870e-03,  0.0000e+00],
          [ 2.5230e-03, -9.3332e-04, -1.9257e-02,  3.9525e-03,  0.0000e+00],
          [ 1.2125e-02, -4.1703e-02, -1.0394e-03,  5.5424e-03,  0.0000e+00],
          [-1.3900e-02,  0.0000e+00, -1.0240e-03,  4.1691e-04,  0.0000e+00]]]])
DESIRED: (shape=torch.Size([5070448, 18, 5, 5]), dtype=torch.float32)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8316e-05],
          [ 3.0849e-03, -4.8833e-02, -2.4611e-02, -1.6140e-02, -1.1628e-03],
          [ 0.0000e+00,  6.3886e-02,  2.3387e-03, -1.1537e-02, -3.3222e-02],
          [ 0.0000e+00, -1.0881e-03,  3.8497e-04,  8.6690e-04, -2.3310e-02],
          [ 0.0000e+00, -2.1894e-03,  1.1271e-02, -3.3418e-03,  1.5706e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1747e-03],
          [ 5.2059e-03, -1.9778e-02,  3.8931e-02,  2.2195e-02,  9.0229e-04],
          [ 0.0000e+00, -2.1000e-02, -5.7219e-03,  8.9877e-03,  3.9798e-02],
          [ 0.0000e+00,  3.5681e-03,  6.8764e-05,  1.5050e-02, -6.9481e-02],
          [ 0.0000e+00, -1.3035e-03,  7.1992e-04,  6.3536e-04, -3.7315e-02]],

         [[ 0.0000e+00,  1.9086e-02,  7.4179e-03,  0.0000e+00,  8.7325e-03],
          [ 1.5188e-02,  1.4816e-02, -3.8837e-02, -5.3473e-03, -2.1273e-02],
          [ 8.0700e-03, -8.4069e-02, -6.0452e-02, -2.4266e-03,  1.9044e-02],
          [-2.2135e-02,  4.8189e-03,  9.5073e-03,  4.8850e-03,  7.2099e-03],
          [ 2.9742e-02, -2.1515e-02, -1.1917e-02, -1.7463e-02,  5.3703e-03]],

         ...,

         [[ 8.2269e-03,  1.1653e-02,  8.4828e-05, -1.4372e-02,  5.1161e-03],
          [ 6.1695e-05, -1.7977e-02,  7.1136e-03, -1.3643e-02,  2.1050e-03],
          [-2.5844e-02, -9.6510e-03, -6.9037e-04,  1.8444e-03, -6.5337e-03],
          [-1.5079e-03,  3.5168e-03,  4.1159e-03, -3.7297e-03,  2.5343e-03],
          [ 0.0000e+00, -2.8371e-05,  0.0000e+00,  4.0130e-03,  2.5801e-03]],

         [[-2.8214e-02,  2.3561e-02, -1.7534e-03,  2.1780e-02,  0.0000e+00],
          [ 2.5593e-03,  2.2103e-02, -1.7846e-02, -7.7257e-03,  1.3951e-04],
          [ 2.8659e-02, -7.8075e-03,  3.9641e-03, -5.6890e-04,  2.6297e-03],
          [ 7.9058e-03,  6.4810e-04,  2.0739e-03,  6.3834e-03,  0.0000e+00],
          [-8.0967e-03, -2.7069e-03, -1.3946e-03,  3.9021e-04,  0.0000e+00]],

         [[ 3.0696e-02, -6.8280e-02, -2.3156e-04,  2.2845e-02,  0.0000e+00],
          [ 1.2524e-03,  4.6515e-02,  7.6445e-05, -4.2047e-02,  3.4722e-03],
          [-8.6548e-03, -4.3668e-03,  1.1107e-02,  1.6288e-02,  1.8847e-02],
          [ 1.4223e-02,  1.5404e-03, -2.8123e-03, -2.8888e-02,  0.0000e+00],
          [-1.2667e-02,  2.2029e-03,  3.2101e-05, -9.7745e-05,  0.0000e+00]]],


        [[[ 2.0926e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1551e-03],
          [-1.0033e-02,  1.5277e-02,  1.0907e-03, -2.1497e-03,  2.9395e-04],
          [-3.9528e-03, -3.3597e-04,  8.2739e-04,  5.4004e-03, -1.9171e-02],
          [ 7.5502e-05,  9.2257e-03, -1.2436e-02, -1.0436e-03, -2.9039e-03],
          [ 0.0000e+00, -9.0557e-03, -1.8584e-02,  1.5524e-03,  1.6904e-02]],

         [[ 3.5325e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4800e-04],
          [-1.3019e-02, -1.1002e-02, -1.4513e-03, -7.0392e-03, -2.6942e-03],
          [ 1.1511e-02,  1.1966e-03, -5.5759e-03, -3.5183e-04,  2.7847e-02],
          [-2.5337e-02,  1.2026e-02,  1.3456e-02,  8.1894e-04,  1.5075e-02],
          [ 0.0000e+00,  4.0805e-03,  6.1193e-03,  1.2717e-02, -3.2370e-04]],

         [[ 1.3767e-03,  0.0000e+00,  1.8678e-03,  0.0000e+00,  1.3508e-02],
          [-1.3295e-02, -4.6130e-03,  4.9138e-04,  1.0530e-02, -1.9585e-03],
          [-1.2564e-02, -2.0045e-02,  2.5994e-04, -1.4362e-02,  3.4267e-03],
          [-2.4077e-02, -2.2312e-02,  4.4760e-03, -1.1309e-02,  3.6217e-02],
          [-5.0746e-03, -6.2518e-03, -4.6583e-03,  5.4524e-03, -3.9696e-02]],

         ...,

         [[-5.8571e-03, -1.9562e-03,  2.5297e-03, -2.6395e-03, -1.0073e-03],
          [-3.9583e-03,  6.7881e-03,  2.3522e-03, -3.0747e-03,  5.4074e-03],
          [-9.4527e-04,  2.1137e-02, -1.6108e-02,  1.5853e-02,  1.8445e-03],
          [ 1.7319e-02, -1.7018e-02, -2.1820e-02,  4.0290e-03, -1.1486e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8099e-03, -2.2344e-03]],

         [[-2.9079e-02, -1.4759e-02, -1.4922e-02,  2.4968e-04,  0.0000e+00],
          [-6.1021e-03, -2.7519e-03, -7.8644e-03,  2.1851e-02,  5.9348e-03],
          [ 1.5385e-02, -8.1439e-03,  2.1528e-02, -4.3263e-03,  0.0000e+00],
          [ 8.0825e-03, -8.2574e-04,  3.3168e-02,  8.0369e-04,  4.0968e-03],
          [ 0.0000e+00,  0.0000e+00, -8.9430e-03,  0.0000e+00,  0.0000e+00]],

         [[-8.2020e-03, -2.1411e-02, -2.8528e-03, -3.2622e-03,  0.0000e+00],
          [ 3.5993e-03,  1.4276e-02,  6.9375e-03,  1.5194e-02,  1.8717e-02],
          [-1.2029e-02,  3.0835e-02,  2.6239e-02, -1.1711e-03,  0.0000e+00],
          [ 1.4968e-02, -2.0738e-02, -1.3290e-02,  2.2376e-03,  1.5139e-02],
          [ 0.0000e+00,  0.0000e+00,  8.9208e-05,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7985e-03,  0.0000e+00],
          [ 2.1725e-03, -4.2207e-03, -6.2317e-03, -3.6997e-02,  1.7026e-02],
          [ 3.3037e-03, -1.5334e-02, -2.4289e-03,  9.8940e-03, -4.5188e-02],
          [ 0.0000e+00, -4.6385e-03, -3.1245e-03,  9.7219e-04,  1.8667e-02],
          [-4.1875e-03,  1.0522e-03,  3.6058e-03,  3.6300e-03, -2.1599e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0943e-04,  0.0000e+00],
          [ 5.0886e-03, -3.3454e-03,  1.4691e-03, -1.4013e-02, -7.4835e-03],
          [ 2.3332e-02, -3.4920e-02,  1.3836e-02, -1.3463e-03,  1.2968e-02],
          [ 0.0000e+00, -8.7983e-03,  2.0580e-02,  4.6890e-02,  9.9177e-03],
          [ 8.6294e-03,  9.2225e-04,  3.5899e-03,  2.3733e-02,  1.3129e-02]],

         [[ 0.0000e+00, -4.6315e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 1.3504e-02,  1.7125e-04, -8.4923e-03,  6.6375e-02,  1.9120e-03],
          [-1.8835e-02, -1.1297e-02,  1.4496e-03, -4.4576e-04, -2.1655e-02],
          [-1.9851e-03, -1.4278e-02, -5.7463e-03,  8.6711e-03, -4.6426e-02],
          [ 1.0370e-02,  4.0568e-04,  3.5408e-03, -1.7510e-02,  2.9307e-02]],

         ...,

         [[-1.7194e-02, -2.6361e-02, -3.5606e-02, -1.8316e-03, -6.9010e-04],
          [ 2.5754e-03,  4.6210e-03,  8.4187e-05,  9.6157e-03, -1.9294e-03],
          [ 3.0962e-03,  1.4845e-02,  4.1089e-04, -3.9285e-03, -3.4960e-03],
          [-3.1187e-04, -2.8361e-02,  1.8122e-03, -4.9095e-03, -3.3764e-02],
          [-1.0748e-03,  0.0000e+00,  0.0000e+00, -4.9881e-04, -4.0927e-04]],

         [[-2.4307e-02, -6.2145e-03, -7.9709e-03, -6.0510e-03, -2.6155e-03],
          [-1.4222e-02,  3.0656e-03, -1.8956e-02,  4.2982e-03, -3.1130e-03],
          [ 6.5894e-03,  1.1541e-02,  2.8569e-03,  2.2657e-04,  0.0000e+00],
          [ 1.5040e-02,  1.2187e-02,  7.9678e-03, -1.1081e-02,  0.0000e+00],
          [ 0.0000e+00,  3.4848e-03, -1.1220e-03,  0.0000e+00,  0.0000e+00]],

         [[-2.4921e-02, -2.5519e-03, -1.2477e-03,  2.0521e-03,  8.4766e-04],
          [-3.2523e-02, -1.8031e-02,  8.0609e-03, -1.8413e-03,  1.1235e-02],
          [ 6.7963e-04,  2.2042e-02, -8.5286e-03,  1.2380e-05,  0.0000e+00],
          [-1.5478e-02,  1.5247e-02,  1.1304e-02, -8.7337e-03,  0.0000e+00],
          [ 0.0000e+00, -2.6627e-05, -2.3007e-03,  0.0000e+00,  0.0000e+00]]],


        ...,


        [[[-9.5558e-05,  0.0000e+00,  2.2334e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  5.9548e-03,  5.1446e-02,  1.7320e-02, -9.9072e-03],
          [ 1.7518e-04, -3.4568e-03,  4.2448e-03, -6.3478e-03, -2.1156e-02],
          [-2.8166e-03, -5.1115e-03, -1.8621e-03, -4.6873e-02,  8.1338e-03],
          [ 0.0000e+00,  5.2279e-03,  9.1105e-03,  3.0206e-03, -6.6883e-03]],

         [[-1.3586e-03,  0.0000e+00, -3.8802e-02,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  3.6407e-03, -5.9463e-02, -6.3533e-03,  1.3038e-02],
          [ 1.3035e-02,  8.1554e-03, -1.3418e-02, -2.2149e-02,  9.7895e-03],
          [ 1.1023e-03,  1.5921e-03,  4.1562e-03,  6.7573e-03, -1.9075e-02],
          [ 0.0000e+00,  1.9121e-02, -1.1142e-02, -1.0926e-02,  7.3898e-03]],

         [[ 7.7550e-03, -3.2615e-02, -3.1084e-03,  0.0000e+00,  0.0000e+00],
          [ 4.7396e-03,  1.0483e-02, -4.8982e-03, -4.4402e-03, -7.1672e-03],
          [ 5.6094e-02,  2.3163e-02,  3.2811e-02, -3.0486e-03, -5.6161e-03],
          [-4.7959e-03, -5.4150e-03,  2.8131e-02,  1.0141e-02,  1.0508e-03],
          [-3.0909e-03, -2.3153e-03, -5.4113e-04, -2.3812e-03,  6.0154e-03]],

         ...,

         [[-1.2766e-02, -2.8442e-02, -6.2006e-03, -1.5678e-03,  1.0824e-02],
          [-4.8445e-04,  6.1537e-03, -1.2429e-02,  5.8551e-03, -5.0319e-03],
          [ 5.8911e-03, -2.3368e-03,  8.7627e-03,  2.9113e-02,  1.3761e-02],
          [-1.2926e-02,  1.5024e-02,  4.0240e-02,  2.3081e-02,  4.2035e-03],
          [-1.3845e-03,  2.4409e-04, -8.2207e-03, -2.7537e-03,  0.0000e+00]],

         [[ 7.7079e-03,  1.5131e-02, -1.2095e-02, -3.5980e-02,  1.1030e-05],
          [-2.2016e-02,  1.1057e-02, -2.2561e-03,  2.0460e-04,  0.0000e+00],
          [ 1.7091e-02,  2.7420e-02, -3.5045e-04,  7.2195e-03,  4.6974e-03],
          [ 2.1477e-03,  2.6165e-02,  2.8087e-03, -5.6314e-03,  0.0000e+00],
          [ 0.0000e+00,  6.3268e-04,  2.4526e-02,  0.0000e+00,  0.0000e+00]],

         [[ 6.4335e-03, -4.7895e-03, -1.3337e-02, -3.6559e-02, -3.0099e-05],
          [-8.7620e-04,  1.1988e-02, -2.5520e-03, -5.7556e-04,  0.0000e+00],
          [-9.8010e-03, -1.9415e-03, -3.7617e-03, -5.5726e-03,  1.6200e-03],
          [-1.1438e-02,  1.3390e-02,  7.1302e-03,  5.6725e-03,  0.0000e+00],
          [ 0.0000e+00, -7.8323e-04, -2.0999e-02,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  1.8505e-02,  0.0000e+00, -3.1147e-03],
          [ 0.0000e+00,  4.9771e-03, -1.2477e-02, -1.5925e-02, -9.4735e-03],
          [ 0.0000e+00,  4.3384e-03, -1.3428e-03, -1.8215e-03,  1.2212e-03],
          [ 0.0000e+00,  1.4733e-02,  5.1796e-03, -1.2331e-02, -1.6476e-02],
          [ 0.0000e+00, -5.0342e-02, -3.1699e-03,  7.3149e-03,  8.8832e-02]],

         [[ 0.0000e+00,  0.0000e+00,  2.1738e-03,  0.0000e+00, -4.3133e-03],
          [ 0.0000e+00,  3.4307e-03,  5.4956e-03,  1.3218e-02,  8.8409e-03],
          [ 0.0000e+00,  5.5219e-03,  5.9494e-02, -4.7588e-03,  2.0957e-02],
          [ 0.0000e+00,  2.1650e-02, -2.9094e-04,  1.4611e-02, -1.6120e-02],
          [ 0.0000e+00,  2.7212e-02,  1.4058e-02, -5.3170e-03, -6.9189e-02]],

         [[ 0.0000e+00,  4.2906e-04,  0.0000e+00, -1.9929e-02,  0.0000e+00],
          [ 2.6811e-03, -2.4075e-03,  1.0451e-02,  1.3917e-02, -1.6403e-02],
          [-2.2975e-02,  7.5037e-04, -3.9265e-03,  1.2599e-02,  3.9478e-02],
          [ 4.0945e-02, -1.2649e-04, -1.9919e-02,  2.3088e-03, -3.8392e-03],
          [ 2.9597e-03,  1.2883e-02, -1.5414e-03,  1.5087e-02, -6.0699e-02]],

         ...,

         [[-9.2641e-03,  3.9060e-03,  8.8231e-03, -1.1494e-02, -2.9390e-03],
          [-6.0756e-03,  8.8592e-03,  5.5370e-03,  5.0156e-02,  1.0460e-02],
          [ 9.9242e-04, -1.1773e-03, -9.7930e-03,  9.6034e-04, -1.2733e-03],
          [ 4.1701e-03, -6.5096e-04,  2.1488e-02,  2.1904e-03,  2.8624e-03],
          [-8.2793e-04, -8.6205e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0289e-02, -2.1998e-04, -6.2454e-03, -2.8557e-04,  1.3471e-03],
          [ 1.3348e-02, -2.6736e-04, -6.7518e-03, -1.0211e-02,  0.0000e+00],
          [ 3.0374e-02,  7.9967e-03,  1.6575e-03,  1.5265e-04, -5.9324e-04],
          [ 1.2426e-02, -7.1720e-04, -3.1251e-03, -1.5330e-02,  0.0000e+00],
          [ 1.0229e-02,  1.3500e-02, -1.2606e-03,  0.0000e+00,  0.0000e+00]],

         [[-6.7132e-03,  2.2247e-03, -2.1737e-02, -4.5726e-05,  1.9206e-03],
          [-3.3563e-03, -1.8210e-03,  1.1778e-02, -4.7900e-02,  0.0000e+00],
          [ 1.4833e-02, -1.4776e-02,  1.3573e-02, -1.4884e-03,  1.7241e-03],
          [-1.0501e-02, -1.8635e-03,  7.6593e-04,  9.3423e-04,  0.0000e+00],
          [-6.8356e-03,  2.0481e-04, -5.7754e-04,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  6.0159e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  2.3902e-03,  2.3095e-04,  7.8643e-03,  6.6476e-03],
          [ 6.5665e-04, -1.1439e-02, -3.7443e-04, -6.8454e-02, -1.9713e-02],
          [ 7.8457e-04, -1.8651e-04,  9.5063e-03,  3.7864e-02, -9.9957e-03],
          [-8.2924e-05, -5.2273e-03,  8.7332e-03, -4.9149e-03,  1.1136e-02]],

         [[ 0.0000e+00,  1.2262e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.2138e-03,  5.8284e-04, -1.8537e-02, -5.4559e-03],
          [-1.7821e-02, -1.1193e-02,  6.8112e-04, -4.7949e-02, -1.4629e-03],
          [ 2.6165e-02,  6.8480e-03, -1.7919e-03,  3.3961e-03, -1.6772e-02],
          [ 3.2933e-03,  8.6542e-03,  5.1176e-03, -7.6746e-04,  8.4543e-03]],

         [[-5.9028e-04, -1.7806e-02,  0.0000e+00,  0.0000e+00, -6.3015e-04],
          [-7.5884e-04, -2.8383e-02,  1.5827e-02, -1.8935e-02, -8.7359e-02],
          [ 5.1759e-04, -6.0207e-03,  1.9753e-02, -1.2164e-02,  8.7674e-03],
          [-4.8517e-03,  1.6452e-03, -3.7841e-02, -1.4419e-02, -8.3297e-03],
          [ 3.9789e-03, -3.1354e-02, -3.9954e-02, -2.3010e-02,  3.4180e-02]],

         ...,

         [[ 1.5154e-03, -9.1779e-03, -8.0704e-05,  8.4531e-03, -2.0963e-03],
          [ 3.3274e-03, -1.9579e-03,  3.9010e-03,  1.6628e-03, -4.4800e-03],
          [-1.4812e-02, -1.4579e-02,  2.2092e-03, -4.7264e-03,  3.3963e-03],
          [ 1.4124e-02,  2.0356e-02,  1.1573e-02,  5.5134e-02,  1.0020e-02],
          [ 4.1652e-03,  0.0000e+00,  7.5125e-04,  0.0000e+00,  0.0000e+00]],

         [[ 2.8187e-04, -1.8974e-02,  3.6611e-02, -1.5566e-02, -3.2110e-05],
          [ 6.6351e-03, -5.4580e-02,  2.2110e-02,  6.4020e-03,  0.0000e+00],
          [ 4.9070e-03,  1.3497e-02, -4.8873e-02,  1.2342e-02,  0.0000e+00],
          [-1.2414e-03, -2.1684e-02,  1.5405e-03,  5.1515e-03,  0.0000e+00],
          [-2.7568e-02,  0.0000e+00,  3.2827e-04,  9.3425e-04,  0.0000e+00]],

         [[-3.3275e-03,  2.6660e-02,  4.7725e-02,  1.2320e-03,  3.9220e-05],
          [-1.1312e-03, -4.3202e-02,  1.5616e-03,  9.2870e-03,  0.0000e+00],
          [ 2.5230e-03, -9.3332e-04, -1.9257e-02,  3.9525e-03,  0.0000e+00],
          [ 1.2125e-02, -4.1703e-02, -1.0394e-03,  5.5424e-03,  0.0000e+00],
          [-1.3900e-02,  0.0000e+00, -1.0240e-03,  4.1691e-04,  0.0000e+00]]]])

