2025-07-30 00:14:50.729853 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), )
W0730 00:15:13.464525 68761 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0730 00:15:24.624107 68761 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 2715238400, memory's size is 1939456000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):2715238400 > memory_size():1939456000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), ) 	 969728000 	 1000 	 0.010024547576904297 	 0.010907888412475586 	 2.09808349609375e-05 	 7.843971252441406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:15:34.353946 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), )
W0730 00:16:09.182557 69742 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3557386560, memory's size is 2540990464.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3557386560 > memory_size():2540990464.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), ) 	 1270495200 	 1000 	 0.01000356674194336 	 0.00991058349609375 	 1.7642974853515625e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:21.640259 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), )
W0730 00:16:48.227599 69863 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3158835200, memory's size is 1974272000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3158835200 > memory_size():1974272000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), ) 	 987136000 	 1000 	 0.0052411556243896484 	 0.0054967403411865234 	 9.775161743164062e-06 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:56.944626 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), )
W0730 00:17:31.929585 70350 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064532480, memory's size is 2540332800.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064532480 > memory_size():2540332800.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), ) 	 1270166400 	 1000 	 0.009995698928833008 	 0.006126880645751953 	 1.4781951904296875e-05 	 9.846687316894531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:17:46.817055 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), )
W0730 00:18:08.917106 70471 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), ) 	 1045504000 	 1000 	 0.005269289016723633 	 0.005475759506225586 	 1.7404556274414062e-05 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:14.563662 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), )
W0730 00:18:41.011624 70537 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), ) 	 1270124000 	 1000 	 0.005184173583984375 	 0.005435466766357422 	 1.3589859008789062e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:48.030652 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), )
W0730 00:19:22.810456 71022 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064460800, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064460800 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), ) 	 1270144000 	 1000 	 0.0052149295806884766 	 0.0054476261138916016 	 8.58306884765625e-06 	 3.266334533691406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:19:37.587058 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), )
W0730 00:20:09.743045 71441 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3556403200, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3556403200 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), ) 	 1270144000 	 1000 	 0.005268096923828125 	 0.005438566207885742 	 2.1219253540039062e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:19.911722 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), )
W0730 00:20:48.502650 72209 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), ) 	 1270144000 	 1000 	 0.005262613296508789 	 0.005460023880004883 	 1.1205673217773438e-05 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:57.165190 test begin: paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), ) 	 508352000 	 1000 	 0.004673480987548828 	 0.004947185516357422 	 6.9141387939453125e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:05.083209 test begin: paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), ) 	 508352000 	 1000 	 0.0047283172607421875 	 0.0047643184661865234 	 6.4373016357421875e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:12.806503 test begin: paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), ) 	 509000000 	 1000 	 0.004793643951416016 	 0.0048389434814453125 	 5.9604644775390625e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:20.826293 test begin: paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), ) 	 518190230 	 1000 	 0.004700183868408203 	 0.006702423095703125 	 6.67572021484375e-06 	 6.008148193359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:29.533815 test begin: paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), ) 	 508953600 	 1000 	 0.004709482192993164 	 0.004885673522949219 	 6.67572021484375e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:38.763911 test begin: paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), ) 	 508088500 	 1000 	 0.0047931671142578125 	 0.004893064498901367 	 7.152557373046875e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:46.606320 test begin: paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), ) 	 508088500 	 1000 	 0.004727602005004883 	 0.004845619201660156 	 6.198883056640625e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:55.283813 test begin: paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), ) 	 508033000 	 1000 	 0.004553556442260742 	 0.004755735397338867 	 5.9604644775390625e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:03.476944 test begin: paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), ) 	 508047360 	 1000 	 0.4640495777130127 	 0.5071878433227539 	 0.23708009719848633 	 0.25896286964416504 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:11.616420 test begin: paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), ) 	 508047360 	 1000 	 0.4640014171600342 	 0.506772518157959 	 0.23710274696350098 	 0.2589855194091797 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:21.784957 test begin: paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.49889445304870605 	 0.545013427734375 	 0.2549159526824951 	 0.27849507331848145 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:30.332092 test begin: paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.49892711639404297 	 0.5450553894042969 	 0.2549753189086914 	 0.2784841060638428 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:39.481164 test begin: paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), ) 	 508800000 	 1000 	 0.4669806957244873 	 0.5092301368713379 	 0.2386019229888916 	 0.26020383834838867 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:47.493131 test begin: paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), ) 	 508032200 	 1000 	 0.4677085876464844 	 0.5074520111083984 	 0.23897075653076172 	 0.2592911720275879 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:55.603153 test begin: paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), ) 	 512000000 	 1000 	 0.46817445755004883 	 0.5181078910827637 	 0.23921751976013184 	 0.26474833488464355 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:03.914237 test begin: paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), ) 	 508160000 	 1000 	 0.46742939949035645 	 0.5069875717163086 	 0.23952889442443848 	 0.25904178619384766 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:11.975399 test begin: paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), ) 	 512000000 	 1000 	 0.4681994915008545 	 0.5195248126983643 	 0.23925495147705078 	 0.26615309715270996 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:20.205795 test begin: paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], ) 	 508354560 	 1000 	 0.49573540687561035 	 0.5515358448028564 	 0.25327610969543457 	 0.5369997024536133 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:28.273944 test begin: paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], ) 	 508178560 	 1000 	 0.5065205097198486 	 0.5686943531036377 	 0.25879526138305664 	 0.5539836883544922 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:37.653913 test begin: paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6389617919921875 	 0.5275378227233887 	 0.32650279998779297 	 0.5124545097351074 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:45.849633 test begin: paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5422403812408447 	 0.5249161720275879 	 0.27709174156188965 	 0.5103135108947754 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:54.369802 test begin: paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5422537326812744 	 0.5250005722045898 	 0.2770721912384033 	 0.5100185871124268 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:02.475847 test begin: paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.638974666595459 	 0.5288350582122803 	 0.3264760971069336 	 0.514150857925415 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:10.568133 test begin: paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], ) 	 554880000 	 1000 	 0.5379965305328369 	 0.7145693302154541 	 0.5254573822021484 	 0.6998741626739502 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:19.558702 test begin: paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], ) 	 508270080 	 1000 	 0.49486374855041504 	 0.6541945934295654 	 0.47440052032470703 	 0.6397054195404053 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:28.098578 test begin: paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6210551261901855 	 0.5354118347167969 	 0.31731319427490234 	 0.5207188129425049 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:38.216973 test begin: paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6224365234375 	 0.53537917137146 	 0.31737804412841797 	 0.520336389541626 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:47.443576 test begin: paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], ) 	 552960000 	 1000 	 0.5367062091827393 	 0.5987701416015625 	 0.27423882484436035 	 0.5842006206512451 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:56.354793 test begin: paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], ) 	 609408000 	 1000 	 0.6039133071899414 	 0.6808931827545166 	 0.3086092472076416 	 0.666388750076294 	 None 	 None 	 None 	 None 	 
2025-07-30 00:25:06.172569 test begin: paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", ) 	 508559360 	 1000 	 0.003434896469116211 	 0.002324819564819336 	 8.106231689453125e-06 	 3.981590270996094e-05 	 0.032956838607788086 	 0.05930829048156738 	 3.170967102050781e-05 	 5.7220458984375e-05 	 
2025-07-30 00:25:22.208423 test begin: paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", ) 	 508559360 	 1000 	 0.003309965133666992 	 0.0022072792053222656 	 1.1205673217773438e-05 	 1.9311904907226562e-05 	 0.03250837326049805 	 0.058882951736450195 	 5.2928924560546875e-05 	 7.653236389160156e-05 	 
2025-07-30 00:25:39.702676 test begin: paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", ) 	 671088640 	 1000 	 0.0032777786254882812 	 0.002258777618408203 	 6.9141387939453125e-06 	 1.6927719116210938e-05 	 0.02933359146118164 	 0.06041240692138672 	 2.0503997802734375e-05 	 6.175041198730469e-05 	 
2025-07-30 00:26:00.723499 test begin: paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), ) 	 1016565760 	 1000 	 0.0007977485656738281 	 0.002827882766723633 	 8.344650268554688e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:32.267607 test begin: paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), ) 	 1016565760 	 1000 	 0.0007815361022949219 	 0.0028257369995117188 	 1.049041748046875e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:27:04.428903 test begin: paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007729530334472656 	 0.0027773380279541016 	 1.0967254638671875e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:27:42.474311 test begin: paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007817745208740234 	 0.002797365188598633 	 1.0013580322265625e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:28:21.174740 test begin: paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007801055908203125 	 0.002803325653076172 	 1.1205673217773438e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:28:56.580187 test begin: paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), ) 	 1016821760 	 1000 	 0.0007536411285400391 	 0.0015707015991210938 	 1.0251998901367188e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:29:12.291649 test begin: paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0008409023284912109 	 0.0018815994262695312 	 1.5497207641601562e-05 	 2.7418136596679688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:29:29.457022 test begin: paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007171630859375 	 0.0015344619750976562 	 1.1444091796875e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:29:45.485461 test begin: paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007116794586181641 	 0.0015692710876464844 	 6.9141387939453125e-06 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:30:01.474008 test begin: paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), ) 	 1016821760 	 1000 	 0.0007231235504150391 	 0.0015463829040527344 	 7.867813110351562e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:30:20.665247 test begin: paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), ) 	 1016243200 	 1000 	 0.0007295608520507812 	 0.0015444755554199219 	 7.867813110351562e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:30:39.330449 test begin: paddle.Tensor.equal_all(Tensor([2540160101],"int64"), Tensor([8],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([2540160101],"int64"), Tensor([8],"int64"), ) 	 2540160109 	 1000 	 0.01821422576904297 	 0.002785921096801758 	 2.288818359375e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:16.214927 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), ) 	 25402402 	 1000 	 0.017613649368286133 	 0.002679109573364258 	 1.9073486328125e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:18.346298 test begin: paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), ) 	 2543338404 	 1000 	 0.01743006706237793 	 0.002644062042236328 	 1.5735626220703125e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:55.281287 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), ) 	 2543338404 	 1000 	 0.01751112937927246 	 0.0026493072509765625 	 1.430511474609375e-05 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:32:31.830515 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 25404006 	 1000 	 0.017383575439453125 	 0.0025947093963623047 	 1.239776611328125e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:32:32.481839 test begin: paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), ) 	 25402402 	 1000 	 0.017534971237182617 	 0.0026521682739257812 	 8.58306884765625e-06 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:32:32.899211 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), ) 	 25404006 	 1000 	 0.017290353775024414 	 0.002675294876098633 	 1.7881393432617188e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:32:33.298643 test begin: paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), ) 	 2540160327 	 1000 	 0.01741337776184082 	 0.002734661102294922 	 1.9073486328125e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:33:08.771968 test begin: paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), ) 	 2540160109 	 1000 	 0.017542362213134766 	 0.0026912689208984375 	 2.3126602172851562e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:33:49.457002 test begin: paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.02366352081298828 	 0.01134800910949707 	 4.76837158203125e-05 	 3.457069396972656e-05 	 0.0366358757019043 	 0.05162453651428223 	 3.0279159545898438e-05 	 9.012222290039062e-05 	 combined
2025-07-30 00:34:05.757551 test begin: paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.023184537887573242 	 0.011171579360961914 	 2.2411346435546875e-05 	 3.4332275390625e-05 	 0.03196525573730469 	 0.05865812301635742 	 2.2172927856445312e-05 	 5.4836273193359375e-05 	 combined
2025-07-30 00:34:21.946462 test begin: paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 1684480000 	 1000 	 0.005919456481933594 	 0.004452228546142578 	 1.1682510375976562e-05 	 2.3365020751953125e-05 	 0.041615962982177734 	 0.07514119148254395 	 3.743171691894531e-05 	 7.963180541992188e-05 	 
2025-07-30 00:35:15.481440 test begin: paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, ) 	 509788160 	 1000 	 0.005461215972900391 	 0.006013154983520508 	 1.2159347534179688e-05 	 7.343292236328125e-05 	 0.041414737701416016 	 0.0696265697479248 	 3.647804260253906e-05 	 3.600120544433594e-05 	 
2025-07-30 00:35:31.752215 test begin: paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, ) 	 1019576320 	 1000 	 0.005490303039550781 	 0.004225730895996094 	 1.5497207641601562e-05 	 2.09808349609375e-05 	 0.04174232482910156 	 0.06948995590209961 	 3.8623809814453125e-05 	 5.459785461425781e-05 	 
2025-07-30 00:36:10.221602 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.005396127700805664 	 0.004252195358276367 	 1.1682510375976562e-05 	 2.0265579223632812e-05 	 0.04240274429321289 	 0.05979800224304199 	 5.14984130859375e-05 	 9.036064147949219e-05 	 
2025-07-30 00:36:26.740554 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.005461692810058594 	 0.004273414611816406 	 9.775161743164062e-06 	 2.1457672119140625e-05 	 0.04148507118225098 	 0.06886839866638184 	 2.3126602172851562e-05 	 5.745887756347656e-05 	 
2025-07-30 00:37:05.487958 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, ) 	 513802240 	 1000 	 0.005762338638305664 	 0.004236459732055664 	 3.5762786865234375e-05 	 1.8835067749023438e-05 	 0.04161667823791504 	 0.07066869735717773 	 3.981590270996094e-05 	 7.700920104980469e-05 	 
2025-07-30 00:37:22.086731 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, ) 	 1027604480 	 1000 	 0.005460262298583984 	 0.0042722225189208984 	 9.5367431640625e-06 	 2.002716064453125e-05 	 0.04282689094543457 	 0.06903243064880371 	 5.221366882324219e-05 	 6.4849853515625e-05 	 
2025-07-30 00:38:00.754071 test begin: paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.00551295280456543 	 0.007752418518066406 	 1.3113021850585938e-05 	 7.43865966796875e-05 	 0.041333675384521484 	 0.07147622108459473 	 4.410743713378906e-05 	 6.723403930664062e-05 	 
2025-07-30 00:38:17.338193 test begin: paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 526400000 	 1000 	 0.005913257598876953 	 0.004403829574584961 	 1.4066696166992188e-05 	 2.0503997802734375e-05 	 0.041605234146118164 	 0.07052040100097656 	 2.288818359375e-05 	 5.245208740234375e-05 	 
2025-07-30 00:38:34.210505 test begin: paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 539033600 	 1000 	 0.005894660949707031 	 0.004358530044555664 	 1.2636184692382812e-05 	 1.8596649169921875e-05 	 0.04150819778442383 	 0.07178163528442383 	 2.1457672119140625e-05 	 8.654594421386719e-05 	 
2025-07-30 00:38:52.298472 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, ) 	 519680000 	 1000 	 0.005807638168334961 	 0.004379987716674805 	 1.2159347534179688e-05 	 1.8835067749023438e-05 	 0.042487144470214844 	 0.06967306137084961 	 5.412101745605469e-05 	 4.8160552978515625e-05 	 
2025-07-30 00:39:09.175194 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, ) 	 529408000 	 1000 	 0.005853891372680664 	 0.00439906120300293 	 2.1457672119140625e-05 	 5.984306335449219e-05 	 0.043235063552856445 	 0.07151484489440918 	 4.172325134277344e-05 	 8.416175842285156e-05 	 
2025-07-30 00:39:26.077538 test begin: paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.0055255889892578125 	 0.0041387081146240234 	 1.33514404296875e-05 	 2.002716064453125e-05 	 0.0773324966430664 	 0.07052087783813477 	 5.888938903808594e-05 	 6.937980651855469e-05 	 
2025-07-30 00:40:05.056595 test begin: paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, ) 	 508032080 	 1000 	 0.010252714157104492 	 1.3232166767120361 	 1.8835067749023438e-05 	 7.390975952148438e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:40:16.060126 test begin: paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, ) 	 508032400 	 1000 	 0.010135650634765625 	 13.280006647109985 	 1.33514404296875e-05 	 0.0002269744873046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:40:39.158269 test begin: paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, ) 	 508036000 	 1000 	 0.17139601707458496 	 140.22138571739197 	 0.16133737564086914 	 0.000492095947265625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:43:10.110739 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), ) 	 50816225 	 1000 	 0.010015010833740234 	 0.013601541519165039 	 1.621246337890625e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:43:13.075286 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50821425 	 1000 	 0.009701728820800781 	 0.013450145721435547 	 1.4781951904296875e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:43:14.084417 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), ) 	 50812325 	 1000 	 0.00985097885131836 	 0.015096664428710938 	 1.5020370483398438e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:43:15.054883 test begin: paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50824957 	 1000 	 3.1382334232330322 	 2.7517404556274414 	 3.12835955619812 	 2.737675428390503 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:43:27.727007 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), ) 	 2552921100 	 1000 	 0.003622293472290039 	 0.0016367435455322266 	 8.344650268554688e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:44:19.398095 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), ) 	 2552884920 	 1000 	 0.0035848617553710938 	 0.0016050338745117188 	 6.9141387939453125e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:45:08.531878 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), ) 	 2552884920 	 1000 	 0.0035669803619384766 	 0.0015685558319091797 	 1.0967254638671875e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:45:56.798068 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), ) 	 2552921100 	 1000 	 0.003608226776123047 	 0.0015807151794433594 	 9.775161743164062e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:46:45.700958 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), ) 	 2553504000 	 1000 	 0.006846189498901367 	 0.0016455650329589844 	 1.2874603271484375e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:47:35.669875 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), ) 	 2553504000 	 1000 	 0.003563404083251953 	 0.001562356948852539 	 1.0013580322265625e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:48:24.321142 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), ) 	 2540412000 	 1000 	 0.0036127567291259766 	 0.0015952587127685547 	 1.1920928955078125e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:49:17.507447 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), ) 	 2540412000 	 1000 	 0.006696224212646484 	 0.0015628337860107422 	 1.0013580322265625e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:50:05.672235 test begin: paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), ) 	 2548657300 	 1000 	 0.0035560131072998047 	 0.0015761852264404297 	 7.3909759521484375e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:50:55.540576 test begin: paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), ) 	 2548639240 	 1000 	 0.0035858154296875 	 0.0015943050384521484 	 1.1444091796875e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 7, in <module>
    import numpy
  File "/usr/local/lib/python3.10/dist-packages/numpy/__init__.py", line 157, in <module>
    from . import random
  File "/usr/local/lib/python3.10/dist-packages/numpy/random/__init__.py", line 180, in <module>
    from . import _pickle
  File "/usr/local/lib/python3.10/dist-packages/numpy/random/_pickle.py", line 1, in <module>
    from .mtrand import RandomState
  File "numpy/random/mtrand.pyx", line 1, in init numpy.random.mtrand
  File "bit_generator.pyx", line 40, in init numpy.random.bit_generator
  File "/usr/lib/python3.10/secrets.py", line 18, in <module>
    from hmac import compare_digest
  File "/usr/lib/python3.10/hmac.py", line 8, in <module>
    import _hashlib as _hashopenssl
KeyboardInterrupt
2025-07-30 00:14:53.999284 test begin: paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), )
W0730 00:15:43.980212 68810 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), ) 	 2540404000 	 1000 	 0.003699064254760742 	 0.0021212100982666016 	 1.239776611328125e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:15:51.382249 test begin: paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, ) 	 2552861001 	 1000 	 0.01961994171142578 	 0.029313087463378906 	 1.1205673217773438e-05 	 8.225440979003906e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:16:31.598578 test begin: paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, ) 	 2552861001 	 1000 	 0.02379631996154785 	 0.028350353240966797 	 1.33514404296875e-05 	 6.318092346191406e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:17:14.497169 test begin: paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, ) 	 2540160101 	 1000 	 0.019403934478759766 	 0.0290374755859375 	 1.1920928955078125e-05 	 0.00010728836059570312 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:18:05.017106 test begin: paddle.Tensor.logical_not(Tensor([508032010],"bool"), )
[Prof] paddle.Tensor.logical_not 	 paddle.Tensor.logical_not(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.7853076457977295 	 0.7482852935791016 	 0.7761218547821045 	 0.7337179183959961 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:13.801126 test begin: paddle.Tensor.lu(Tensor([1693, 300],"float32"), )
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:924: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  LU, pivots, infos = torch._lu_with_info(
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([1693, 300],"float32"), ) 	 507900 	 1000 	 2.8707900047302246 	 11.16537356376648 	 7.748603820800781e-05 	 0.0005967617034912109 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:18:30.310644 test begin: paddle.Tensor.lu(Tensor([301, 1193],"float32"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 1193],"float32"), ) 	 359093 	 1000 	 1.3672988414764404 	 8.201563596725464 	 5.745887756347656e-05 	 0.0003306865692138672 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:18:40.461226 test begin: paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), ) 	 381066 	 1000 	 8.091911792755127 	 0.12285542488098145 	 0.0001366138458251953 	 9.965896606445312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:18:52.111674 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.012886524200439453 	 0.00906991958618164 	 1.33514404296875e-05 	 6.365776062011719e-05 	 0.054947853088378906 	 0.08040571212768555 	 6.4849853515625e-05 	 7.915496826171875e-05 	 
2025-07-30 00:19:02.297854 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.007673740386962891 	 0.005839347839355469 	 9.5367431640625e-06 	 3.361701965332031e-05 	 0.03983306884765625 	 0.05491209030151367 	 4.124641418457031e-05 	 0.00011682510375976562 	 
2025-07-30 00:19:13.107411 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, ) 	 254016240 	 1000 	 0.006834983825683594 	 0.008794069290161133 	 9.775161743164062e-06 	 3.361701965332031e-05 	 0.0398404598236084 	 0.07199978828430176 	 3.6716461181640625e-05 	 8.487701416015625e-05 	 
2025-07-30 00:19:24.086186 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.0070362091064453125 	 0.004762172698974609 	 1.2874603271484375e-05 	 2.7179718017578125e-05 	 0.039850711822509766 	 0.061943769454956055 	 3.62396240234375e-05 	 6.651878356933594e-05 	 
2025-07-30 00:19:33.689807 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007608890533447266 	 0.005845785140991211 	 8.821487426757812e-06 	 2.2172927856445312e-05 	 0.03975415229797363 	 0.0542757511138916 	 3.838539123535156e-05 	 5.412101745605469e-05 	 
2025-07-30 00:19:43.617035 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.007054805755615234 	 0.0047299861907958984 	 1.0251998901367188e-05 	 2.9087066650390625e-05 	 0.03968358039855957 	 0.05417299270629883 	 2.7418136596679688e-05 	 5.53131103515625e-05 	 
2025-07-30 00:19:53.412235 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.011864185333251953 	 0.005803823471069336 	 3.8623809814453125e-05 	 2.7418136596679688e-05 	 0.06516242027282715 	 0.053967952728271484 	 7.677078247070312e-05 	 6.127357482910156e-05 	 
2025-07-30 00:20:05.085446 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, ) 	 254016400 	 1000 	 0.006876707077026367 	 0.004782199859619141 	 1.2874603271484375e-05 	 3.647804260253906e-05 	 0.0397028923034668 	 0.05360531806945801 	 3.743171691894531e-05 	 5.626678466796875e-05 	 
2025-07-30 00:20:14.908225 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.007386684417724609 	 0.0048809051513671875 	 3.647804260253906e-05 	 3.1948089599609375e-05 	 0.040289878845214844 	 0.06587338447570801 	 5.626678466796875e-05 	 9.250640869140625e-05 	 
2025-07-30 00:20:27.214115 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.007627725601196289 	 0.0057752132415771484 	 7.867813110351562e-06 	 2.7418136596679688e-05 	 0.03983569145202637 	 0.0558927059173584 	 3.361701965332031e-05 	 7.152557373046875e-05 	 
2025-07-30 00:20:38.883326 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, ) 	 254016600 	 1000 	 0.011961221694946289 	 0.008790254592895508 	 2.6702880859375e-05 	 2.8371810913085938e-05 	 0.04853200912475586 	 0.05985116958618164 	 5.173683166503906e-05 	 5.817413330078125e-05 	 
2025-07-30 00:20:52.634266 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.0072784423828125 	 0.004797220230102539 	 1.0967254638671875e-05 	 3.0040740966796875e-05 	 0.03976607322692871 	 0.058769941329956055 	 3.7670135498046875e-05 	 6.365776062011719e-05 	 
2025-07-30 00:21:02.653372 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007627248764038086 	 0.005910634994506836 	 9.059906005859375e-06 	 4.482269287109375e-05 	 0.03978610038757324 	 0.06218862533569336 	 3.504753112792969e-05 	 9.34600830078125e-05 	 
2025-07-30 00:21:12.488135 test begin: paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, ) 	 254016300 	 1000 	 0.006955623626708984 	 0.006057024002075195 	 9.5367431640625e-06 	 7.128715515136719e-05 	 0.04575920104980469 	 0.06135272979736328 	 4.410743713378906e-05 	 6.031990051269531e-05 	 
2025-07-30 00:21:22.354469 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), ) 	 519045120 	 1000 	 0.04228544235229492 	 0.029763460159301758 	 3.266334533691406e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:21:31.567684 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), ) 	 519045120 	 1000 	 0.04096412658691406 	 0.029986143112182617 	 3.695487976074219e-05 	 6.628036499023438e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:21:40.402973 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), ) 	 519045120 	 1000 	 0.05698275566101074 	 0.03787946701049805 	 3.0279159545898438e-05 	 8.082389831542969e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:21:49.929214 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), ) 	 519045120 	 1000 	 0.041344642639160156 	 0.03014397621154785 	 2.86102294921875e-05 	 5.555152893066406e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:21:59.168009 test begin: paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), ) 	 508055040 	 1000 	 0.05428004264831543 	 0.03785061836242676 	 4.3392181396484375e-05 	 8.273124694824219e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:11.467374 test begin: paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), ) 	 513146880 	 1000 	 0.04185009002685547 	 0.029708385467529297 	 4.506111145019531e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:19.518018 test begin: paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), ) 	 513146880 	 1000 	 0.04081249237060547 	 0.029691696166992188 	 3.647804260253906e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:27.376799 test begin: paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.041153669357299805 	 0.029988527297973633 	 3.0040740966796875e-05 	 7.295608520507812e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:36.075284 test begin: paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.054779052734375 	 0.03735804557800293 	 4.172325134277344e-05 	 7.724761962890625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:44.438744 test begin: paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), ) 	 508101120 	 1000 	 0.041259050369262695 	 0.02972888946533203 	 3.504753112792969e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:53.326291 test begin: paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], )
[Prof] paddle.Tensor.reshape 	 paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], ) 	 1016135680 	 1000 	 0.0054950714111328125 	 0.003966093063354492 	 1.239776611328125e-05 	 2.9802322387695312e-05 	 0.04542684555053711 	 4.497892141342163 	 4.792213439941406e-05 	 2.299020290374756 	 
2025-07-30 00:23:44.661252 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, ) 	 50805216 	 1000 	 0.09618520736694336 	 0.002279520034790039 	 3.0994415283203125e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:45.502823 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, ) 	 50805204 	 1000 	 0.036168575286865234 	 0.0022878646850585938 	 2.0742416381835938e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:46.281818 test begin: paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, ) 	 50807704 	 1000 	 0.03617429733276367 	 0.0022630691528320312 	 2.1457672119140625e-05 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:47.052526 test begin: paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.013213157653808594 	 0.020395755767822266 	 1.3828277587890625e-05 	 3.528594970703125e-05 	 4.863959550857544 	 4.628023862838745 	 2.4876272678375244 	 2.364199638366699 	 combined
2025-07-30 00:24:08.024077 test begin: paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.007402181625366211 	 0.013753652572631836 	 1.1444091796875e-05 	 2.5987625122070312e-05 	 1.5164647102355957 	 1.3170497417449951 	 0.7753517627716064 	 0.6729159355163574 	 combined
2025-07-30 00:24:18.951113 test begin: paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 254016320 	 1000 	 0.014646053314208984 	 3.066542625427246 	 1.2636184692382812e-05 	 1.0420217514038086 	 3.100064516067505 	 3.069561719894409 	 0.5267341136932373 	 0.7827291488647461 	 
2025-07-30 00:24:39.916965 test begin: paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.004271507263183594 	 0.004151582717895508 	 1.1682510375976562e-05 	 2.574920654296875e-05 	 0.041806697845458984 	 0.04923653602600098 	 3.24249267578125e-05 	 9.298324584960938e-05 	 
2025-07-30 00:25:04.443926 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.004380464553833008 	 0.0041844844818115234 	 9.059906005859375e-06 	 2.09808349609375e-05 	 0.04381418228149414 	 0.056021928787231445 	 4.3392181396484375e-05 	 5.0067901611328125e-05 	 
2025-07-30 00:25:20.004104 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, ) 	 1179648000 	 1000 	 0.004860639572143555 	 0.00416874885559082 	 3.1948089599609375e-05 	 2.7418136596679688e-05 	 0.04175424575805664 	 0.04933452606201172 	 4.00543212890625e-05 	 7.05718994140625e-05 	 
2025-07-30 00:26:04.491274 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004218339920043945 	 0.004209995269775391 	 1.0728836059570312e-05 	 2.7418136596679688e-05 	 0.04165148735046387 	 0.048863887786865234 	 3.647804260253906e-05 	 5.841255187988281e-05 	 
2025-07-30 00:26:22.212805 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.004922389984130859 	 0.0043315887451171875 	 3.528594970703125e-05 	 3.218650817871094e-05 	 0.041956424713134766 	 0.07407212257385254 	 4.76837158203125e-05 	 0.00012230873107910156 	 
2025-07-30 00:26:40.907841 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, ) 	 508044800 	 1000 	 0.004370689392089844 	 0.00422215461730957 	 8.106231689453125e-06 	 2.6702880859375e-05 	 0.041960716247558594 	 0.05170726776123047 	 4.029273986816406e-05 	 4.458427429199219e-05 	 
2025-07-30 00:26:59.030309 test begin: paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, ) 	 652800000 	 1000 	 0.00424647331237793 	 0.004088640213012695 	 8.821487426757812e-06 	 2.6702880859375e-05 	 0.041756391525268555 	 0.04884839057922363 	 5.412101745605469e-05 	 4.792213439941406e-05 	 
2025-07-30 00:27:21.211203 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, ) 	 508036000 	 1000 	 0.004339456558227539 	 0.004342317581176758 	 1.2874603271484375e-05 	 2.5510787963867188e-05 	 0.04193592071533203 	 0.0520014762878418 	 4.00543212890625e-05 	 4.887580871582031e-05 	 
2025-07-30 00:27:38.826242 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, ) 	 526848000 	 1000 	 0.0043833255767822266 	 0.004232645034790039 	 1.0251998901367188e-05 	 2.6941299438476562e-05 	 0.04409050941467285 	 0.057518720626831055 	 4.5299530029296875e-05 	 8.821487426757812e-05 	 
2025-07-30 00:28:01.741763 test begin: paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, ) 	 602112000 	 1000 	 0.0042858123779296875 	 0.004105091094970703 	 1.4066696166992188e-05 	 2.574920654296875e-05 	 0.04137587547302246 	 0.04857492446899414 	 3.981590270996094e-05 	 5.6743621826171875e-05 	 
2025-07-30 00:28:20.288574 test begin: paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.0043408870697021484 	 0.008126258850097656 	 8.106231689453125e-06 	 2.288818359375e-05 	 0.04207777976989746 	 0.05316305160522461 	 4.267692565917969e-05 	 7.176399230957031e-05 	 
2025-07-30 00:28:39.077183 test begin: paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, ) 	 508784640 	 1000 	 0.0044078826904296875 	 0.00429987907409668 	 1.3589859008789062e-05 	 2.6702880859375e-05 	 0.041747331619262695 	 0.06304693222045898 	 4.5299530029296875e-05 	 9.083747863769531e-05 	 
2025-07-30 00:28:55.060709 test begin: paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], ) 	 1017036800 	 1000 	 0.0034148693084716797 	 0.0045735836029052734 	 1.1444091796875e-05 	 3.075599670410156e-05 	 0.04312872886657715 	 4.502103567123413 	 4.7206878662109375e-05 	 2.299802780151367 	 
2025-07-30 00:29:30.975312 test begin: paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], ) 	 1017057280 	 1000 	 0.0073816776275634766 	 0.008667469024658203 	 1.4543533325195312e-05 	 3.123283386230469e-05 	 0.05200028419494629 	 4.499336004257202 	 7.43865966796875e-05 	 2.29683780670166 	 
2025-07-30 00:30:17.632983 test begin: paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], ) 	 1016821760 	 1000 	 0.0034046173095703125 	 0.00480341911315918 	 8.344650268554688e-06 	 5.030632019042969e-05 	 0.04375004768371582 	 4.501077890396118 	 4.458427429199219e-05 	 2.299328565597534 	 
2025-07-30 00:30:53.648781 test begin: paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], ) 	 1016135680 	 1000 	 0.003446817398071289 	 0.0047647953033447266 	 1.239776611328125e-05 	 5.650520324707031e-05 	 0.04468512535095215 	 4.4977943897247314 	 7.843971252441406e-05 	 2.298877239227295 	 
2025-07-30 00:31:37.238861 test begin: paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), ) 	 508032280 	 1000 	 0.01575779914855957 	 2.9285755157470703 	 0.0001010894775390625 	 2.9144206047058105 	 0.049790382385253906 	 1.3128807544708252 	 1.9550323486328125e-05 	 1.2444262504577637 	 
2025-07-30 00:32:04.287211 test begin: paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), ) 	 508032160 	 1000 	 0.008559703826904297 	 2.939091682434082 	 1.2874603271484375e-05 	 2.9076337814331055 	 0.05156755447387695 	 1.3131680488586426 	 2.8848648071289062e-05 	 1.244798183441162 	 
2025-07-30 00:32:28.190247 test begin: paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), ) 	 508032160 	 1000 	 0.008539915084838867 	 2.9293181896209717 	 1.1205673217773438e-05 	 2.91630482673645 	 0.04972195625305176 	 1.3114395141601562 	 3.7670135498046875e-05 	 1.2478582859039307 	 
2025-07-30 00:32:50.832110 test begin: paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), ) 	 508032280 	 1000 	 0.008401870727539062 	 2.9317195415496826 	 1.7404556274414062e-05 	 2.9187705516815186 	 0.05286121368408203 	 1.3116519451141357 	 0.00010538101196289062 	 1.2308876514434814 	 
2025-07-30 00:33:19.190363 test begin: paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), ) 	 508032080 	 1000 	 0.015898466110229492 	 2.9293806552886963 	 4.267692565917969e-05 	 2.9115192890167236 	 0.0602266788482666 	 1.3116419315338135 	 6.508827209472656e-05 	 1.2438929080963135 	 
2025-07-30 00:33:46.972219 test begin: paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), ) 	 508032640 	 1000 	 0.015506744384765625 	 2.9293859004974365 	 1.7404556274414062e-05 	 2.917795181274414 	 0.05876016616821289 	 1.312819480895996 	 4.315376281738281e-05 	 1.2509846687316895 	 
2025-07-30 00:34:12.551702 test begin: paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), ) 	 508032080 	 1000 	 0.015380620956420898 	 2.9343087673187256 	 2.9087066650390625e-05 	 2.907524824142456 	 0.060308218002319336 	 1.3114562034606934 	 4.982948303222656e-05 	 1.2286627292633057 	 
2025-07-30 00:34:39.037088 test begin: paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.06395339965820312 	 0.032968997955322266 	 2.5033950805664062e-05 	 0.00013637542724609375 	 3.5286521911621094 	 2.967898368835449 	 3.429872512817383 	 2.6467299461364746 	 
2025-07-30 00:35:04.450531 test begin: paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, ) 	 508408320 	 1000 	 0.03922677040100098 	 0.032495975494384766 	 3.528594970703125e-05 	 7.62939453125e-05 	 3.5258195400238037 	 2.9652135372161865 	 3.426556348800659 	 2.68829083442688 	 
2025-07-30 00:35:29.342191 test begin: paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, ) 	 510105600 	 1000 	 0.039136409759521484 	 0.045737266540527344 	 1.7642974853515625e-05 	 7.557868957519531e-05 	 3.5416953563690186 	 2.977254867553711 	 3.442983627319336 	 2.70076584815979 	 
2025-07-30 00:35:52.137240 test begin: paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, ) 	 508147200 	 1000 	 0.04478263854980469 	 0.03985905647277832 	 2.193450927734375e-05 	 4.506111145019531e-05 	 3.5243029594421387 	 2.96407151222229 	 3.410647392272949 	 2.674328327178955 	 
2025-07-30 00:36:17.525535 test begin: paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, ) 	 513112320 	 1000 	 0.03897500038146973 	 0.032529592514038086 	 1.4543533325195312e-05 	 4.935264587402344e-05 	 3.5556509494781494 	 2.9922268390655518 	 3.4564030170440674 	 2.707090139389038 	 
2025-07-30 00:36:45.868135 test begin: paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, ) 	 509276160 	 1000 	 0.04475879669189453 	 0.03997302055358887 	 1.7881393432617188e-05 	 5.555152893066406e-05 	 3.531195878982544 	 2.971558094024658 	 3.4225199222564697 	 2.6893975734710693 	 
2025-07-30 00:37:10.192750 test begin: paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, ) 	 513676800 	 1000 	 0.04222512245178223 	 0.03349661827087402 	 6.246566772460938e-05 	 9.369850158691406e-05 	 3.562757968902588 	 2.995410442352295 	 3.459775447845459 	 2.672217845916748 	 
2025-07-30 00:37:39.538615 test begin: paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.039083003997802734 	 0.0327000617980957 	 2.002716064453125e-05 	 4.291534423828125e-05 	 3.5286288261413574 	 2.968151330947876 	 3.429001569747925 	 2.6890149116516113 	 
2025-07-30 00:38:02.018920 test begin: paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, ) 	 541900800 	 1000 	 0.06316733360290527 	 0.05238604545593262 	 5.602836608886719e-05 	 5.745887756347656e-05 	 3.756659507751465 	 3.1508212089538574 	 3.6257174015045166 	 2.734251022338867 	 
2025-07-30 00:38:25.907093 test begin: paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, ) 	 602112000 	 1000 	 0.062123775482177734 	 0.05213475227355957 	 1.6689300537109375e-05 	 8.654594421386719e-05 	 4.181309700012207 	 3.5015931129455566 	 4.0500171184539795 	 3.023076057434082 	 
2025-07-30 00:38:55.842698 test begin: paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, ) 	 530841600 	 1000 	 0.07522988319396973 	 0.0768423080444336 	 3.7670135498046875e-05 	 7.963180541992188e-05 	 3.6833157539367676 	 3.08506441116333 	 3.5364668369293213 	 2.579286575317383 	 
2025-07-30 00:39:21.813388 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, )
Warning: The core code of paddle.Tensor.unsqueeze is too complex.
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, ) 	 509009920 	 1000 	 0.009716987609863281 	 0.007181882858276367 	 0.00017976760864257812 	 3.719329833984375e-05 	 0.04953598976135254 	 0.07931041717529297 	 3.409385681152344e-05 	 0.00012159347534179688 	 
2025-07-30 00:39:42.578478 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, ) 	 509009920 	 1000 	 0.003990888595581055 	 0.005568265914916992 	 8.821487426757812e-06 	 8.225440979003906e-05 	 0.04242730140686035 	 0.05199122428894043 	 2.0503997802734375e-05 	 3.9577484130859375e-05 	 
2025-07-30 00:39:59.356846 test begin: paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.00400090217590332 	 0.003780364990234375 	 1.1682510375976562e-05 	 2.6464462280273438e-05 	 0.0668344497680664 	 0.05269575119018555 	 5.412101745605469e-05 	 5.817413330078125e-05 	 
2025-07-30 00:40:23.927000 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, ) 	 508096000 	 1000 	 0.003951072692871094 	 0.0037522315979003906 	 7.152557373046875e-06 	 2.9087066650390625e-05 	 0.042463064193725586 	 0.05302166938781738 	 3.910064697265625e-05 	 7.772445678710938e-05 	 
2025-07-30 00:40:40.172533 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, ) 	 508096000 	 1000 	 0.008481502532958984 	 0.007404804229736328 	 1.239776611328125e-05 	 5.8650970458984375e-05 	 0.050023794174194336 	 0.06900358200073242 	 4.1484832763671875e-05 	 0.00010514259338378906 	 
2025-07-30 00:41:01.633576 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, ) 	 508096000 	 1000 	 0.004014253616333008 	 0.007001161575317383 	 6.9141387939453125e-06 	 3.075599670410156e-05 	 0.04981088638305664 	 0.05972552299499512 	 5.984306335449219e-05 	 0.00010919570922851562 	 
2025-07-30 00:41:18.297793 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, ) 	 508096000 	 1000 	 0.004101991653442383 	 0.003803730010986328 	 1.049041748046875e-05 	 2.8848648071289062e-05 	 0.04234194755554199 	 0.05424165725708008 	 4.291534423828125e-05 	 7.510185241699219e-05 	 
2025-07-30 00:41:37.025238 test begin: paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.0040225982666015625 	 0.0038406848907470703 	 1.1205673217773438e-05 	 2.9087066650390625e-05 	 0.04226994514465332 	 0.06932592391967773 	 4.553794860839844e-05 	 6.413459777832031e-05 	 
2025-07-30 00:41:55.689183 test begin: paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.003986358642578125 	 0.0037889480590820312 	 8.58306884765625e-06 	 2.574920654296875e-05 	 0.04288220405578613 	 0.05289435386657715 	 3.981590270996094e-05 	 7.772445678710938e-05 	 
2025-07-30 00:42:11.502320 test begin: paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, ) 	 508032500 	 1000 	 0.46852922439575195 	 0.50787353515625 	 0.23937726020812988 	 0.25948333740234375 	 None 	 None 	 None 	 None 	 
2025-07-30 00:42:19.669160 test begin: paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, ) 	 508032300 	 1000 	 0.4697399139404297 	 0.5105106830596924 	 0.24060678482055664 	 0.26077961921691895 	 None 	 None 	 None 	 None 	 
2025-07-30 00:42:27.706415 test begin: paddle.all(Tensor([508032010],"bool"), )
[Prof] paddle.all 	 paddle.all(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.4707944393157959 	 0.5079367160797119 	 0.24058318138122559 	 0.25955915451049805 	 None 	 None 	 None 	 None 	 
2025-07-30 00:42:38.658074 test begin: paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, ) 	 508032600 	 1000 	 0.466278076171875 	 0.507946252822876 	 0.23824000358581543 	 0.25954270362854004 	 None 	 None 	 None 	 None 	 
2025-07-30 00:42:47.894673 test begin: paddle.any(Tensor([10, 12404, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 12404, 4096],"bool"), ) 	 508067840 	 1000 	 0.4660522937774658 	 0.528364896774292 	 0.2381277084350586 	 0.26996755599975586 	 None 	 None 	 None 	 None 	 
2025-07-30 00:42:56.628416 test begin: paddle.any(Tensor([10, 300, 169345],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 300, 169345],"bool"), ) 	 508035000 	 1000 	 0.46735548973083496 	 0.5294063091278076 	 0.2381596565246582 	 0.27051424980163574 	 None 	 None 	 None 	 None 	 
2025-07-30 00:43:04.753153 test begin: paddle.any(Tensor([11240, 45199],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([11240, 45199],"bool"), ) 	 508036760 	 1000 	 0.46607375144958496 	 0.5298521518707275 	 0.23816633224487305 	 0.27147531509399414 	 None 	 None 	 None 	 None 	 
2025-07-30 00:43:13.369061 test begin: paddle.any(Tensor([15876010, 32],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.4637751579284668 	 0.5293848514556885 	 0.23698186874389648 	 0.2704927921295166 	 None 	 None 	 None 	 None 	 
2025-07-30 00:43:21.884497 test begin: paddle.any(Tensor([420, 300, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([420, 300, 4096],"bool"), ) 	 516096000 	 1000 	 0.47320556640625 	 0.5393071174621582 	 0.24176692962646484 	 0.27559828758239746 	 None 	 None 	 None 	 None 	 
2025-07-30 00:43:33.013735 test begin: paddle.any(Tensor([5120, 99226],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([5120, 99226],"bool"), ) 	 508037120 	 1000 	 0.4671013355255127 	 0.5312094688415527 	 0.23795151710510254 	 0.2713930606842041 	 None 	 None 	 None 	 None 	 
2025-07-30 00:43:41.227190 test begin: paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.0031943321228027344 	 0.0044634342193603516 	 8.58306884765625e-06 	 2.09808349609375e-05 	 0.03908252716064453 	 0.05347776412963867 	 4.076957702636719e-05 	 3.6716461181640625e-05 	 
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 9, in <module>
    import torch
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 2240, in <module>
    from torch import quantization as quantization  # usort: skip
  File "/usr/local/lib/python3.10/dist-packages/torch/quantization/__init__.py", line 2, in <module>
    from .fake_quantize import *  # noqa: F403
  File "/usr/local/lib/python3.10/dist-packages/torch/quantization/fake_quantize.py", line 10, in <module>
    from torch.ao.quantization.fake_quantize import (
  File "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/__init__.py", line 12, in <module>
    from .pt2e._numeric_debugger import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/pt2e/_numeric_debugger.py", line 9, in <module>
    from torch.ao.quantization.pt2e.graph_utils import bfs_trace_with_node_process
  File "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/pt2e/graph_utils.py", line 9, in <module>
    from torch.export import ExportedProgram
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 17, in <module>
    from torch.fx.passes.infra.pass_base import PassResult
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/__init__.py", line 1, in <module>
    from . import (
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/net_min_base.py", line 12, in <module>
    from .split_utils import split_by_tags
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/split_utils.py", line 9, in <module>
    from torch.fx.passes.utils import HolderModule, lift_subgraph_as_module
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/utils/__init__.py", line 1, in <module>
    from .common import compare_graphs, HolderModule, lift_subgraph_as_module
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/utils/common.py", line 6, in <module>
    from torch.fx.passes.utils.matcher_utils import SubgraphMatcher
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/utils/matcher_utils.py", line 38, in <module>
    class InternalMatch:
  File "/usr/lib/python3.10/dataclasses.py", line 1184, in dataclass
    return wrap(cls)
  File "/usr/lib/python3.10/dataclasses.py", line 1175, in wrap
    return _process_class(cls, init, repr, eq, order, unsafe_hash,
  File "/usr/lib/python3.10/dataclasses.py", line 1024, in _process_class
    _init_fn(all_init_fields,
  File "/usr/lib/python3.10/dataclasses.py", line 579, in _init_fn
    return _create_fn('__init__',
  File "/usr/lib/python3.10/dataclasses.py", line 432, in _create_fn
    exec(txt, globals, ns)
  File "<string>", line 1, in <module>
KeyboardInterrupt
2025-07-30 00:14:59.908366 test begin: paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), )
W0730 00:15:08.558241 68998 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.0031452178955078125 	 0.004869937896728516 	 1.0013580322265625e-05 	 2.5987625122070312e-05 	 0.03877758979797363 	 0.0766909122467041 	 2.7179718017578125e-05 	 7.224082946777344e-05 	 
2025-07-30 00:15:14.696216 test begin: paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), ) 	 508108800 	 1000 	 0.0031087398529052734 	 0.0044939517974853516 	 1.33514404296875e-05 	 2.1696090698242188e-05 	 0.04124855995178223 	 0.05294179916381836 	 4.863739013671875e-05 	 3.647804260253906e-05 	 
2025-07-30 00:15:28.183037 test begin: paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), ) 	 508559360 	 1000 	 0.0031325817108154297 	 0.004525899887084961 	 1.3113021850585938e-05 	 2.1696090698242188e-05 	 0.03841900825500488 	 0.0533595085144043 	 4.172325134277344e-05 	 7.104873657226562e-05 	 
2025-07-30 00:15:41.898655 test begin: paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), ) 	 508108800 	 1000 	 0.0031239986419677734 	 0.0045468807220458984 	 1.1682510375976562e-05 	 1.811981201171875e-05 	 0.037960052490234375 	 0.05353665351867676 	 4.029273986816406e-05 	 5.817413330078125e-05 	 
2025-07-30 00:15:55.337126 test begin: paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.017406225204467773 	 0.004548072814941406 	 2.1457672119140625e-05 	 2.0503997802734375e-05 	 1.5004823207855225 	 1.3159120082855225 	 0.7663836479187012 	 0.6726701259613037 	 
2025-07-30 00:16:07.598478 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.017195463180541992 	 0.004605293273925781 	 1.7642974853515625e-05 	 1.9073486328125e-05 	 1.5127038955688477 	 1.3146436214447021 	 0.7738752365112305 	 0.6714553833007812 	 
2025-07-30 00:16:29.664706 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.017310142517089844 	 0.00816488265991211 	 1.52587890625e-05 	 2.09808349609375e-05 	 1.5129749774932861 	 1.3158042430877686 	 0.7733428478240967 	 0.6721739768981934 	 
2025-07-30 00:16:58.258727 test begin: paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.022423267364501953 	 0.008077859878540039 	 2.3126602172851562e-05 	 2.4080276489257812e-05 	 1.5017833709716797 	 1.314527988433838 	 0.7676196098327637 	 0.6713273525238037 	 
2025-07-30 00:17:14.134935 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.017307281494140625 	 0.004684925079345703 	 1.9550323486328125e-05 	 4.744529724121094e-05 	 1.516613245010376 	 1.3161473274230957 	 0.7758026123046875 	 0.6728413105010986 	 
2025-07-30 00:17:37.051570 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.017412185668945312 	 0.004670619964599609 	 1.3113021850585938e-05 	 1.9073486328125e-05 	 1.513376235961914 	 1.3156647682189941 	 0.7732267379760742 	 0.6720359325408936 	 
2025-07-30 00:18:06.992115 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Error] CUDA out of memory. Tried to allocate 18.93 GiB. GPU 0 has a total capacity of 39.39 GiB of which 18.08 GiB is free. Process 144313 has 21.30 GiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-30 00:19:00.206762 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
W0730 00:19:46.558224 71132 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0030252933502197266 	 0.011469364166259766 	 1.2636184692382812e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:02.431013 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.002798795700073242 	 0.0076029300689697266 	 9.775161743164062e-06 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:56.233492 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0015864372253417969 	 0.006338357925415039 	 8.58306884765625e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:10.474421 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Error] CUDA out of memory. Tried to allocate 18.99 GiB. GPU 0 has a total capacity of 39.39 GiB of which 1022.31 MiB is free. Process 42389 has 38.39 GiB memory in use. Of the allocated memory 189.00 KiB is allocated by PyTorch, and 1.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-30 00:23:15.084393 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
W0730 00:23:58.617292 76209 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.002914905548095703 	 0.008900880813598633 	 1.1444091796875e-05 	 4.172325134277344e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:24:08.725602 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.002790689468383789 	 0.009610176086425781 	 1.3113021850585938e-05 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:25:02.821773 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.005461215972900391 	 0.007345676422119141 	 3.981590270996094e-05 	 2.7418136596679688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:25:03.558752 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.00549626350402832 	 0.0077266693115234375 	 4.601478576660156e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:25:57.897610 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0027616024017333984 	 0.007449150085449219 	 7.152557373046875e-06 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:26:51.791460 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0027217864990234375 	 0.0074100494384765625 	 6.9141387939453125e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:26:52.496252 test begin: paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0027723312377929688 	 0.007460355758666992 	 1.811981201171875e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:27:50.945850 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.002874612808227539 	 0.00742340087890625 	 2.288818359375e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:45.428512 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0027399063110351562 	 0.007467985153198242 	 9.059906005859375e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:29:39.761577 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.0028264522552490234 	 0.007465362548828125 	 1.3113021850585938e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:30:34.200563 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.002773761749267578 	 0.007372856140136719 	 1.0013580322265625e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:30:34.921060 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.002862215042114258 	 0.00735783576965332 	 9.775161743164062e-06 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:28.639522 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0027437210083007812 	 0.010218381881713867 	 6.67572021484375e-06 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:29.440474 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0015785694122314453 	 0.0062749385833740234 	 7.867813110351562e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:32:23.579237 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0027680397033691406 	 0.007368564605712891 	 1.1682510375976562e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:33:16.972961 test begin: paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0027425289154052734 	 0.010220766067504883 	 9.298324584960938e-06 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:34:20.134158 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0025243759155273438 	 0.00624537467956543 	 4.00543212890625e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:35:13.516861 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0030825138092041016 	 0.007359027862548828 	 3.0994415283203125e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:36:07.092599 test begin: paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0027484893798828125 	 0.007445335388183594 	 8.821487426757812e-06 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:36:07.741928 test begin: paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.00273895263671875 	 0.0074040889739990234 	 1.430511474609375e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:37:02.981334 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0027923583984375 	 0.012206554412841797 	 6.67572021484375e-06 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:37:03.641240 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0015347003936767578 	 0.00809025764465332 	 8.106231689453125e-06 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:37:57.074534 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0027320384979248047 	 0.007404804229736328 	 1.049041748046875e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:38:51.753098 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0038542747497558594 	 0.007474660873413086 	 9.5367431640625e-06 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:39:45.043756 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0037391185760498047 	 0.007442951202392578 	 9.775161743164062e-06 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:40:49.680563 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003636598587036133 	 0.007412433624267578 	 8.106231689453125e-06 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:41:54.922230 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003663778305053711 	 0.00747227668762207 	 1.239776611328125e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:42:53.024317 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0018923282623291016 	 0.006335735321044922 	 1.0013580322265625e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:43:54.765989 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.003772258758544922 	 0.007390022277832031 	 1.1205673217773438e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:44:48.566298 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.005185604095458984 	 0.007374286651611328 	 3.0279159545898438e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:45:42.709679 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.003760099411010742 	 0.007769346237182617 	 1.239776611328125e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:46:56.657294 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.0037610530853271484 	 0.007485628128051758 	 1.2874603271484375e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:47:55.683395 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.003787517547607422 	 0.007379770278930664 	 1.1444091796875e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:49:05.172486 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0037920475006103516 	 0.007422447204589844 	 9.059906005859375e-06 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:49:06.179363 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.007373332977294922 	 0.007401943206787109 	 1.3828277587890625e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:49:59.945104 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0037620067596435547 	 0.007633686065673828 	 9.298324584960938e-06 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:50:55.180810 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0037491321563720703 	 0.008199691772460938 	 7.152557373046875e-06 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:50:55.906874 test begin: paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0037593841552734375 	 0.0074574947357177734 	 1.1920928955078125e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:51:49.458343 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0037374496459960938 	 0.0074155330657958984 	 7.62939453125e-06 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:52:55.612416 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0037550926208496094 	 0.00726771354675293 	 7.62939453125e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:53:49.949519 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.003720521926879883 	 0.007226467132568359 	 6.67572021484375e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:54:55.336515 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003709554672241211 	 0.007263660430908203 	 1.1444091796875e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:54:56.046361 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.003712177276611328 	 0.0073435306549072266 	 8.106231689453125e-06 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:56:02.205530 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003769397735595703 	 0.007487297058105469 	 1.5735626220703125e-05 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:56:03.014205 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0019431114196777344 	 0.0062177181243896484 	 1.2636184692382812e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:57:08.527701 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0037572383880615234 	 0.010107755661010742 	 1.049041748046875e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:58:13.001831 test begin: paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0037441253662109375 	 0.007308006286621094 	 7.62939453125e-06 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:59:19.381231 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0019004344940185547 	 0.006270408630371094 	 1.1205673217773438e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:00:13.305641 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.005264759063720703 	 0.007348060607910156 	 2.1457672119140625e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:01:18.166009 test begin: paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003655672073364258 	 0.007329702377319336 	 7.62939453125e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:01:18.849669 test begin: paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003685474395751953 	 0.012143373489379883 	 1.33514404296875e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:02:15.057438 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.00737762451171875 	 0.015611886978149414 	 3.9577484130859375e-05 	 9.417533874511719e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:02:15.727154 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.003674030303955078 	 0.0064122676849365234 	 9.775161743164062e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:03:09.140880 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.003658294677734375 	 0.007388591766357422 	 1.1920928955078125e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:04:13.638387 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004799365997314453 	 0.0074160099029541016 	 1.71661376953125e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:05:28.897004 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004551410675048828 	 0.0074732303619384766 	 1.1920928955078125e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:06:30.772984 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0046617984771728516 	 0.007266044616699219 	 1.4781951904296875e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:07:28.472129 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0078046321868896484 	 0.007193803787231445 	 3.5762786865234375e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:08:22.417489 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0027894973754882812 	 0.006380558013916016 	 3.075599670410156e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:09:24.625562 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.00474095344543457 	 0.007267475128173828 	 8.821487426757812e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:10:28.705875 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.004759788513183594 	 0.007355690002441406 	 9.775161743164062e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:11:31.182672 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.004729270935058594 	 0.007341623306274414 	 7.3909759521484375e-06 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:12:25.480036 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.004711151123046875 	 0.007373809814453125 	 7.62939453125e-06 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:13:24.557508 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004767417907714844 	 0.007344484329223633 	 1.2159347534179688e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:14:26.857792 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004599332809448242 	 0.007274627685546875 	 1.0251998901367188e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:14:27.575111 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.00475311279296875 	 0.007314205169677734 	 1.2159347534179688e-05 	 2.7418136596679688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:15:32.272566 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004725933074951172 	 0.007303714752197266 	 1.1205673217773438e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:16:39.867218 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004637002944946289 	 0.007380008697509766 	 6.9141387939453125e-06 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:16:41.095917 test begin: paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0047283172607421875 	 0.007295846939086914 	 1.2159347534179688e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:17:35.115596 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.004662275314331055 	 0.007391691207885742 	 1.1682510375976562e-05 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:18:40.644682 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.004697561264038086 	 0.0072515010833740234 	 6.67572021484375e-06 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:19:34.581720 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.004690647125244141 	 0.007316112518310547 	 9.5367431640625e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:20:29.234843 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004606008529663086 	 0.007359981536865234 	 6.198883056640625e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:20:29.987956 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0046482086181640625 	 0.0073871612548828125 	 1.1205673217773438e-05 	 4.4345855712890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:21:44.346738 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0045812129974365234 	 0.007220029830932617 	 9.298324584960938e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:21:45.115743 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0022084712982177734 	 0.006238460540771484 	 1.0728836059570312e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:22:39.207625 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0047607421875 	 0.0073299407958984375 	 9.059906005859375e-06 	 3.361701965332031e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 01:23:42.184470 test begin: paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.004666566848754883 	 0.011945724487304688 	 1.0728836059570312e-05 	 2.7418136596679688e-05 	 None 	 None 	 None 	 None 	 
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 9, in <module>
    import torch
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 2611, in <module>
    from torch import _meta_registrations
  File "/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py", line 12, in <module>
    from torch._decomp import (
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py", line 276, in <module>
    import torch._decomp.decompositions
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py", line 16, in <module>
    import torch._prims as prims
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 525, in <module>
    abs = _make_elementwise_unary_prim(
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 493, in _make_elementwise_unary_prim
    return _make_prim(
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 321, in _make_prim
    prim_def = torch.library.custom_op(
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/custom_ops.py", line 173, in custom_op
    return inner(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/custom_ops.py", line 154, in inner
    result = CustomOpDef(namespace, opname, schema_str, fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/custom_ops.py", line 204, in __init__
    self._register_to_dispatcher()
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/custom_ops.py", line 624, in _register_to_dispatcher
    lib._register_fake(self._name, fake_impl, _stacklevel=4)
  File "/usr/local/lib/python3.10/dist-packages/torch/library.py", line 193, in _register_fake
    source = torch._library.utils.get_source(_stacklevel + 1)
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 54, in get_source
    frame = inspect.getframeinfo(sys._getframe(stacklevel))
  File "/usr/lib/python3.10/inspect.py", line 1624, in getframeinfo
    lines, lnum = findsource(frame)
  File "/usr/lib/python3.10/inspect.py", line 952, in findsource
    module = getmodule(object, file)
  File "/usr/lib/python3.10/inspect.py", line 875, in getmodule
    f = getabsfile(module)
  File "/usr/lib/python3.10/inspect.py", line 844, in getabsfile
    _filename = getsourcefile(object) or getfile(object)
  File "/usr/lib/python3.10/inspect.py", line 820, in getsourcefile
    if any(filename.endswith(s) for s in all_bytecode_suffixes):
KeyboardInterrupt
2025-07-30 00:15:02.824862 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), )
W0730 00:15:59.915755 69046 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0029850006103515625 	 0.008065223693847656 	 3.9577484130859375e-05 	 6.747245788574219e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:06.921928 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004878044128417969 	 0.007788658142089844 	 6.67572021484375e-06 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:17:00.335899 test begin: paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004801273345947266 	 0.010676383972167969 	 7.867813110351562e-06 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:17:00.970593 test begin: paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.004614114761352539 	 0.007588386535644531 	 1.0728836059570312e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:22.635620 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.005006313323974609 	 0.0075359344482421875 	 9.059906005859375e-06 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:23.265583 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.002270936965942383 	 0.006400585174560547 	 1.621246337890625e-05 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:19:12.001541 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004691123962402344 	 0.01059269905090332 	 9.775161743164062e-06 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:04.709741 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 508036320 	 1000 	 0.8583524227142334 	 0.7506880760192871 	 0.8430233001708984 	 0.7352199554443359 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:13.905340 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 508042800 	 1000 	 0.8473739624023438 	 0.7488398551940918 	 0.8388364315032959 	 0.7339134216308594 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:22.346112 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 508053600 	 1000 	 0.8584139347076416 	 0.7470133304595947 	 0.8497979640960693 	 0.7348127365112305 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:31.123267 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 508037400 	 1000 	 0.8588213920593262 	 0.7594161033630371 	 0.8503818511962891 	 0.735684871673584 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:39.806166 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8584020137786865 	 0.7484970092773438 	 0.8499577045440674 	 0.7366695404052734 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:48.353114 test begin: paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8584070205688477 	 0.747063159942627 	 0.8502357006072998 	 0.7288186550140381 	 None 	 None 	 None 	 None 	 
2025-07-30 00:20:57.303468 test begin: paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.858367919921875 	 0.7469851970672607 	 0.8433232307434082 	 0.7285535335540771 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:07.332924 test begin: paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508042800 	 1000 	 0.8487255573272705 	 0.7474765777587891 	 0.8403005599975586 	 0.7356488704681396 	 None 	 None 	 None 	 None 	 
2025-07-30 00:21:15.812057 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), ) 	 2540160109 	 1000 	 0.011157035827636719 	 0.011156797409057617 	 2.9087066650390625e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:22:04.177286 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, ) 	 2540160109 	 1000 	 0.011379003524780273 	 0.01115870475769043 	 2.5272369384765625e-05 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:06.555635 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), ) 	 25402405 	 1000 	 0.018384456634521484 	 0.017156124114990234 	 1.33514404296875e-05 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:07.098341 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 25402405 	 1000 	 0.011604785919189453 	 0.011236429214477539 	 1.5974044799804688e-05 	 3.24249267578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:07.649126 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, ) 	 25402405 	 1000 	 0.011374235153198242 	 0.012476444244384766 	 1.9788742065429688e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:08.173845 test begin: paddle.combinations(Tensor([2540160101],"int64"), 0, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([2540160101],"int64"), 0, True, ) 	 2540160101 	 1000 	 0.016909360885620117 	 0.004172801971435547 	 2.4080276489257812e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:24:00.291778 test begin: paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, ) 	 20802080 	 1000 	 5.704125642776489 	 5.704141139984131 	 5.691061019897461 	 5.688742637634277 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:24:13.571958 test begin: paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, ) 	 20800100 	 1000 	 0.5542597770690918 	 3.508197546005249 	 0.5335071086883545 	 3.4852278232574463 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:24:19.445132 test begin: paddle.diag(Tensor([20000, 25402],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), ) 	 508040000 	 1000 	 0.008630514144897461 	 0.025416135787963867 	 1.1682510375976562e-05 	 8.702278137207031e-05 	 1.5214283466339111 	 1.3265695571899414 	 0.7780320644378662 	 0.6777431964874268 	 
2025-07-30 00:24:30.771988 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.010683298110961914 	 0.01762247085571289 	 6.031990051269531e-05 	 6.937980651855469e-05 	 1.521726131439209 	 1.3284904956817627 	 0.7776670455932617 	 0.6779768466949463 	 
2025-07-30 00:24:41.552120 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=1, ) 	 508040000 	 1000 	 0.00924992561340332 	 0.01771402359008789 	 1.4543533325195312e-05 	 4.9591064453125e-05 	 1.5220489501953125 	 1.3276128768920898 	 0.7782502174377441 	 0.6786501407623291 	 
2025-07-30 00:24:54.482417 test begin: paddle.diag(Tensor([254020, 2000],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), ) 	 508040000 	 1000 	 0.008988142013549805 	 0.01755809783935547 	 1.8358230590820312e-05 	 0.000102996826171875 	 1.512242317199707 	 1.3199148178100586 	 0.7724010944366455 	 0.6751365661621094 	 
2025-07-30 00:25:06.134934 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.009192466735839844 	 0.017856121063232422 	 1.6450881958007812e-05 	 5.53131103515625e-05 	 1.5128896236419678 	 1.3181407451629639 	 0.772820234298706 	 0.6734704971313477 	 
2025-07-30 00:25:16.721392 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=1, ) 	 508040000 	 1000 	 0.009246349334716797 	 0.017790794372558594 	 1.5020370483398438e-05 	 5.1975250244140625e-05 	 1.510580062866211 	 1.318204641342163 	 0.7716832160949707 	 0.6735141277313232 	 
2025-07-30 00:25:27.382563 test begin: paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032200 	 1000 	 0.7656219005584717 	 0.7764403820037842 	 0.19524502754211426 	 0.26363277435302734 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:25:43.881488 test begin: paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032110 	 1000 	 0.766042947769165 	 0.7787013053894043 	 0.19535493850708008 	 0.2649235725402832 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:00.068279 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], )
W0730 00:26:09.419979 79577 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.03077220916748047 	 0.010268211364746094 	 2.6226043701171875e-05 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:11.026436 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], )
W0730 00:26:17.574505 79764 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.0166475772857666 	 0.007355928421020508 	 1.6927719116210938e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:18.468973 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], )
W0730 00:26:25.252256 79939 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.023407459259033203 	 0.014399290084838867 	 2.0503997802734375e-05 	 8.58306884765625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:26.191330 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], )
W0730 00:26:35.101172 80103 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.030136585235595703 	 0.01138162612915039 	 1.4543533325195312e-05 	 6.747245788574219e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:39.694014 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], )
W0730 00:26:46.380424 80287 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.016524791717529297 	 0.007589101791381836 	 1.4781951904296875e-05 	 3.218650817871094e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:47.182687 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], )
W0730 00:26:55.077031 80787 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.02335524559020996 	 0.01383829116821289 	 1.7404556274414062e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:26:59.336098 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], )
W0730 00:27:09.203992 81031 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.030533552169799805 	 0.010304450988769531 	 2.0503997802734375e-05 	 3.1948089599609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:27:10.689513 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], )
W0730 00:27:17.366843 81209 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.016577482223510742 	 0.012191534042358398 	 1.3828277587890625e-05 	 3.0279159545898438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:27:18.638222 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], )
W0730 00:27:26.154975 81377 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.023540258407592773 	 0.009024858474731445 	 2.384185791015625e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:27:28.213514 test begin: paddle.empty_like(Tensor([1016064010],"uint8"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([1016064010],"uint8"), ) 	 1016064010 	 1000 	 0.01162576675415039 	 1.3484864234924316 	 1.2159347534179688e-05 	 0.0001049041748046875 	 None 	 None 	 None 	 None 	 
2025-07-30 00:27:38.838478 test begin: paddle.empty_like(Tensor([40960, 12404],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"bool"), ) 	 508067840 	 1000 	 0.011722564697265625 	 0.00577235221862793 	 1.0251998901367188e-05 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:27:45.675213 test begin: paddle.empty_like(Tensor([40960, 12404],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"float32"), ) 	 508067840 	 1000 	 0.011645078659057617 	 0.006470680236816406 	 1.3113021850585938e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:27:53.692457 test begin: paddle.empty_like(Tensor([7938010, 64],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"bool"), ) 	 508032640 	 1000 	 0.011569499969482422 	 0.014320850372314453 	 1.239776611328125e-05 	 0.00010800361633300781 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:01.686277 test begin: paddle.empty_like(Tensor([7938010, 64],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"float32"), ) 	 508032640 	 1000 	 0.011668205261230469 	 0.006264448165893555 	 1.0251998901367188e-05 	 4.696846008300781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:09.321687 test begin: paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.017868518829345703 	 0.0025899410247802734 	 1.3828277587890625e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:10.037138 test begin: paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), ) 	 50816002 	 1000 	 0.017742633819580078 	 0.0025510787963867188 	 1.4066696166992188e-05 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:10.880440 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.017699003219604492 	 0.0025758743286132812 	 1.1682510375976562e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:11.617341 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.017776012420654297 	 0.002589702606201172 	 1.049041748046875e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:12.421511 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), ) 	 50828832 	 1000 	 0.017679691314697266 	 0.0026285648345947266 	 1.4781951904296875e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:13.219310 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 50828832 	 1000 	 0.017176389694213867 	 0.002588033676147461 	 8.58306884765625e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:14.011288 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.0191805362701416 	 0.0026111602783203125 	 4.315376281738281e-05 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:14.802050 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), ) 	 50816002 	 1000 	 0.01833629608154297 	 0.0027985572814941406 	 3.314018249511719e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:28:15.639326 test begin: paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 508157440 	 1000 	 0.005791664123535156 	 0.004408121109008789 	 1.4781951904296875e-05 	 2.288818359375e-05 	 0.04005169868469238 	 0.06591558456420898 	 4.3392181396484375e-05 	 5.841255187988281e-05 	 
2025-07-30 00:28:31.466343 test begin: paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 509788160 	 1000 	 0.005671262741088867 	 0.004317045211791992 	 1.1682510375976562e-05 	 3.337860107421875e-05 	 0.04006767272949219 	 0.06761312484741211 	 5.7697296142578125e-05 	 7.271766662597656e-05 	 
2025-07-30 00:28:47.426200 test begin: paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 513802240 	 1000 	 0.005660533905029297 	 0.00456690788269043 	 8.106231689453125e-06 	 4.9114227294921875e-05 	 0.03989553451538086 	 0.06760144233703613 	 4.601478576660156e-05 	 6.866455078125e-05 	 
2025-07-30 00:29:03.511984 test begin: paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, ) 	 532480000 	 1000 	 0.0055751800537109375 	 0.0041844844818115234 	 1.1920928955078125e-05 	 2.2172927856445312e-05 	 0.0427243709564209 	 0.06899452209472656 	 4.4345855712890625e-05 	 8.20159912109375e-05 	 
2025-07-30 00:29:22.413327 test begin: paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, ) 	 508144000 	 1000 	 0.005575895309448242 	 0.004130363464355469 	 1.049041748046875e-05 	 2.0265579223632812e-05 	 0.039818525314331055 	 0.06694173812866211 	 3.790855407714844e-05 	 6.031990051269531e-05 	 
2025-07-30 00:29:42.064283 test begin: paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, ) 	 514375680 	 1000 	 0.005658388137817383 	 0.004231929779052734 	 1.4781951904296875e-05 	 2.0503997802734375e-05 	 0.039937496185302734 	 0.07349324226379395 	 4.315376281738281e-05 	 8.153915405273438e-05 	 
2025-07-30 00:29:58.555125 test begin: paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.0054895877838134766 	 0.004204273223876953 	 7.152557373046875e-06 	 2.0503997802734375e-05 	 0.040160417556762695 	 0.06760549545288086 	 3.0517578125e-05 	 5.245208740234375e-05 	 
2025-07-30 00:30:14.895969 test begin: paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, ) 	 524288000 	 1000 	 0.005570650100708008 	 0.0041866302490234375 	 8.344650268554688e-06 	 2.0503997802734375e-05 	 0.04339885711669922 	 0.06834173202514648 	 4.506111145019531e-05 	 7.367134094238281e-05 	 
2025-07-30 00:30:31.463559 test begin: paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, ) 	 513802240 	 1000 	 0.005590677261352539 	 0.004203081130981445 	 7.867813110351562e-06 	 1.9788742065429688e-05 	 0.03987574577331543 	 0.06714200973510742 	 4.220008850097656e-05 	 5.626678466796875e-05 	 
2025-07-30 00:30:47.612721 test begin: paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.005496025085449219 	 0.004204273223876953 	 1.049041748046875e-05 	 2.0742416381835938e-05 	 0.03975200653076172 	 0.06714081764221191 	 3.361701965332031e-05 	 6.628036499023438e-05 	 
2025-07-30 00:31:03.559612 test begin: paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6572291851043701 	 0.6579232215881348 	 0.6386044025421143 	 0.6374905109405518 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:13.136938 test begin: paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6588118076324463 	 0.6578962802886963 	 0.6404123306274414 	 0.6378624439239502 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:22.189174 test begin: paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 545259520 	 1000 	 0.7066984176635742 	 0.705470085144043 	 0.6963558197021484 	 0.6922588348388672 	 None 	 None 	 None 	 None 	 
2025-07-30 00:31:30.954403 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 52918864 	 1000 	 0.011342763900756836 	 80.74727535247803 	 1.1920928955078125e-05 	 0.0002448558807373047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:52.796069 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), ) 	 52917364 	 1000 	 0.011121511459350586 	 23.647137880325317 	 1.239776611328125e-05 	 0.0002219676971435547 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:33:17.454790 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102473328 	 1000 	 0.010900497436523438 	 62.799041986465454 	 1.5497207641601562e-05 	 0.00023746490478515625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:34:22.230150 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102473404 	 1000 	 0.01074671745300293 	 85.78396773338318 	 1.3113021850585938e-05 	 0.0002467632293701172 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:35:49.963311 test begin: paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102573116 	 1000 	 0.012132644653320312 	 63.07836127281189 	 0.001310586929321289 	 0.0002281665802001953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:36:55.021600 test begin: paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102598240 	 1000 	 0.011195898056030273 	 65.98836278915405 	 2.9087066650390625e-05 	 0.0002372264862060547 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:38:03.092390 test begin: paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 26674703 	 1000 	 0.3956773281097412 	 0.011537790298461914 	 3.528594970703125e-05 	 4.00543212890625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:38:04.573277 test begin: paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", ) 	 533436623 	 1000 	 0.9323976039886475 	 0.01206660270690918 	 4.100799560546875e-05 	 4.315376281738281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:38:28.359314 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 533436623 	 1000 	 2.301974058151245 	 0.01164388656616211 	 8.606910705566406e-05 	 3.695487976074219e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:38:54.824364 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, ) 	 508032050 	 1000 	 0.12167882919311523 	 0.024569034576416016 	 2.956390380859375e-05 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:39:06.994383 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, ) 	 508032050 	 1000 	 0.09747552871704102 	 0.01902174949645996 	 2.7418136596679688e-05 	 0.00048041343688964844 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:39:16.880696 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], )
W0730 00:39:26.658829 102076 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.051924705505371094 	 0.015638351440429688 	 3.528594970703125e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:39:28.557282 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], )
W0730 00:39:35.172115 102552 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.016921520233154297 	 0.00759434700012207 	 1.2636184692382812e-05 	 2.8371810913085938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:39:38.840548 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], )
W0730 00:39:45.572803 102870 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.023441314697265625 	 0.008931875228881836 	 1.2874603271484375e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:39:46.262678 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], )
W0730 00:39:56.160573 103038 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.030666589736938477 	 0.026755094528198242 	 1.7404556274414062e-05 	 3.695487976074219e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:39:59.830642 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], )
W0730 00:40:06.514981 103513 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.027867794036865234 	 0.012421369552612305 	 1.621246337890625e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:40:08.309346 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], )
W0730 00:40:15.461939 103773 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.023426532745361328 	 0.013588190078735352 	 1.5735626220703125e-05 	 6.365776062011719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:40:17.565645 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], )
W0730 00:40:28.606549 104103 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.030301570892333984 	 0.010347604751586914 	 1.3589859008789062e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:40:30.576245 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], )
W0730 00:40:38.375319 104579 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.030886411666870117 	 0.014729499816894531 	 6.246566772460938e-05 	 7.2479248046875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:40:42.312145 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], )
W0730 00:40:49.876340 105257 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.023722410202026367 	 0.008960485458374023 	 3.7670135498046875e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:40:51.611080 test begin: paddle.is_complex(Tensor([1003520, 507],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([1003520, 507],"float32"), ) 	 508784640 	 1000 	 0.0048139095306396484 	 0.0016674995422363281 	 1.2159347534179688e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:41:01.310077 test begin: paddle.is_complex(Tensor([5070, 100352],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([5070, 100352],"float32"), ) 	 508784640 	 1000 	 0.003614187240600586 	 0.0016727447509765625 	 1.0013580322265625e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:41:09.857403 test begin: paddle.is_complex(Tensor([62020, 8192],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([62020, 8192],"float32"), ) 	 508067840 	 1000 	 0.0036897659301757812 	 0.0017399787902832031 	 9.775161743164062e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:41:18.293359 test begin: paddle.is_complex(Tensor([81920, 6202],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([81920, 6202],"float32"), ) 	 508067840 	 1000 	 0.004690885543823242 	 0.002084016799926758 	 1.0013580322265625e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:41:26.715133 test begin: paddle.is_complex(Tensor([8860, 57344],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([8860, 57344],"float32"), ) 	 508067840 	 1000 	 0.0047779083251953125 	 0.0017271041870117188 	 8.821487426757812e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:41:36.952637 test begin: paddle.is_empty(Tensor([101606410, 5],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([101606410, 5],"float32"), ) 	 508032050 	 1000 	 0.0034351348876953125 	 0.0016455650329589844 	 8.58306884765625e-06 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:41:44.869488 test begin: paddle.is_empty(Tensor([169344010, 3],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([169344010, 3],"float32"), ) 	 508032030 	 1000 	 0.007528543472290039 	 0.002265453338623047 	 1.621246337890625e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 combined
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 9, in <module>
    import torch
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 409, in <module>
    from torch._C import *  # noqa: F403
  File "<frozen importlib._bootstrap>", line 216, in _lock_unlock_module
KeyboardInterrupt
2025-07-30 00:15:08.343286 test begin: paddle.is_empty(Tensor([20, 25401601],"float32"), )
W0730 00:15:17.486213 69256 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([20, 25401601],"float32"), ) 	 508032020 	 1000 	 0.003703594207763672 	 0.0020613670349121094 	 1.0251998901367188e-05 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:15:18.391486 test begin: paddle.is_empty(Tensor([30, 16934401],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([30, 16934401],"float32"), ) 	 508032030 	 1000 	 0.003588438034057617 	 0.001583099365234375 	 1.52587890625e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:15:26.472378 test begin: paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), ) 	 508033280 	 1000 	 0.003813028335571289 	 0.0015549659729003906 	 1.2874603271484375e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:15:36.229472 test begin: paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), ) 	 508033280 	 1000 	 0.003751993179321289 	 0.0015690326690673828 	 1.1205673217773438e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:15:44.407354 test begin: paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), ) 	 508037120 	 1000 	 0.003753185272216797 	 0.0016167163848876953 	 1.1920928955078125e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:15:52.682695 test begin: paddle.isreal(Tensor([15876010, 32],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.3837745189666748 	 0.3316650390625 	 0.36672425270080566 	 0.31850481033325195 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:00.469426 test begin: paddle.isreal(Tensor([31752010, 32],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"bfloat16"), ) 	 1016064320 	 1000 	 0.7644555568695068 	 0.6604411602020264 	 0.7482142448425293 	 0.644808292388916 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:18.732170 test begin: paddle.isreal(Tensor([31752010, 32],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"float16"), ) 	 1016064320 	 1000 	 1.2139840126037598 	 0.6579234600067139 	 0.747734785079956 	 0.6455295085906982 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:40.404618 test begin: paddle.isreal(Tensor([640, 1587601],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"bfloat16"), ) 	 1016064640 	 1000 	 0.7654528617858887 	 0.6579556465148926 	 0.7481539249420166 	 0.645970344543457 	 None 	 None 	 None 	 None 	 
2025-07-30 00:16:58.406345 test begin: paddle.isreal(Tensor([640, 1587601],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"float16"), ) 	 1016064640 	 1000 	 0.7644069194793701 	 0.6578695774078369 	 0.7482450008392334 	 0.6459405422210693 	 None 	 None 	 None 	 None 	 
2025-07-30 00:17:19.352725 test begin: paddle.isreal(Tensor([640, 793801],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 793801],"bool"), ) 	 508032640 	 1000 	 0.3837244510650635 	 0.33051514625549316 	 0.3675534725189209 	 0.319014310836792 	 None 	 None 	 None 	 None 	 
2025-07-30 00:17:27.095823 test begin: paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.004548788070678711 	 0.00377655029296875 	 1.0013580322265625e-05 	 1.9550323486328125e-05 	 0.041875600814819336 	 0.06143832206726074 	 2.956390380859375e-05 	 6.580352783203125e-05 	 combined
2025-07-30 00:17:44.904649 test begin: paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.008960247039794922 	 0.007484912872314453 	 2.8133392333984375e-05 	 7.581710815429688e-05 	 0.05222678184509277 	 0.0781545639038086 	 7.343292236328125e-05 	 4.935264587402344e-05 	 combined
2025-07-30 00:18:03.944304 test begin: paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.004513978958129883 	 0.003831148147583008 	 7.3909759521484375e-06 	 2.288818359375e-05 	 0.040944576263427734 	 0.05669903755187988 	 4.553794860839844e-05 	 8.58306884765625e-05 	 combined
2025-07-30 00:18:20.836679 test begin: paddle.logical_not(Tensor([2150400, 237],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2150400, 237],"bool"), ) 	 509644800 	 1000 	 0.7808537483215332 	 0.750422477722168 	 0.7722928524017334 	 0.7363402843475342 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:29.788453 test begin: paddle.logical_not(Tensor([2204160, 231],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2204160, 231],"bool"), ) 	 509160960 	 1000 	 0.7841384410858154 	 1.4178411960601807 	 0.7755718231201172 	 0.7364494800567627 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:39.634738 test begin: paddle.logical_not(Tensor([2257920, 226],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2257920, 226],"bool"), ) 	 510289920 	 1000 	 0.7820279598236084 	 0.7503061294555664 	 0.7734115123748779 	 0.737952470779419 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:48.532113 test begin: paddle.logical_not(Tensor([6350410, 80],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([6350410, 80],"bool"), ) 	 508032800 	 1000 	 0.7781867980957031 	 0.748525857925415 	 0.7697193622589111 	 0.7361154556274414 	 None 	 None 	 None 	 None 	 
2025-07-30 00:18:57.155233 test begin: paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), ) 	 1016064080 	 1000 	 0.004502058029174805 	 0.0038318634033203125 	 1.4066696166992188e-05 	 2.8371810913085938e-05 	 0.041646480560302734 	 0.055299997329711914 	 6.198883056640625e-05 	 8.058547973632812e-05 	 combined
2025-07-30 00:19:39.649886 test begin: paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), ) 	 1016064060 	 1000 	 0.004519224166870117 	 0.0038335323333740234 	 1.0251998901367188e-05 	 2.0265579223632812e-05 	 0.04047346115112305 	 0.05431103706359863 	 4.00543212890625e-05 	 5.078315734863281e-05 	 combined
2025-07-30 00:20:18.660663 test begin: paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), ) 	 254016060 	 1000 	 0.0045795440673828125 	 0.003723621368408203 	 1.4066696166992188e-05 	 2.002716064453125e-05 	 0.0408170223236084 	 0.0555262565612793 	 5.054473876953125e-05 	 5.602836608886719e-05 	 combined
2025-07-30 00:20:29.377284 test begin: paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.0068874359130859375 	 0.0037755966186523438 	 1.6927719116210938e-05 	 1.9073486328125e-05 	 0.04068136215209961 	 0.053023338317871094 	 4.1961669921875e-05 	 5.7697296142578125e-05 	 combined
2025-07-30 00:20:46.184376 test begin: paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), ) 	 254016080 	 1000 	 0.004532575607299805 	 0.0037713050842285156 	 8.58306884765625e-06 	 1.811981201171875e-05 	 0.04068160057067871 	 0.05559706687927246 	 3.361701965332031e-05 	 6.4849853515625e-05 	 combined
2025-07-30 00:20:56.913354 test begin: paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.004479169845581055 	 0.003748655319213867 	 1.33514404296875e-05 	 1.7642974853515625e-05 	 0.041205644607543945 	 0.0532536506652832 	 5.1021575927734375e-05 	 7.009506225585938e-05 	 combined
2025-07-30 00:21:13.694267 test begin: paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), ) 	 254016120 	 1000 	 0.004718303680419922 	 0.0038118362426757812 	 2.5510787963867188e-05 	 2.1219253540039062e-05 	 0.04529261589050293 	 0.05427384376525879 	 5.3882598876953125e-05 	 9.703636169433594e-05 	 combined
2025-07-30 00:21:24.318059 test begin: paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.004445075988769531 	 0.0037631988525390625 	 9.775161743164062e-06 	 1.9788742065429688e-05 	 0.040358781814575195 	 0.05302548408508301 	 4.0531158447265625e-05 	 5.364418029785156e-05 	 combined
2025-07-30 00:21:41.337010 test begin: paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), ) 	 1016064120 	 1000 	 0.0045506954193115234 	 0.0037338733673095703 	 1.1205673217773438e-05 	 2.4557113647460938e-05 	 0.04042172431945801 	 0.05709481239318848 	 2.4318695068359375e-05 	 6.4849853515625e-05 	 combined
2025-07-30 00:22:20.150339 test begin: paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018100 	 1000 	 0.008785247802734375 	 0.006078243255615234 	 9.059906005859375e-06 	 2.0265579223632812e-05 	 0.040482282638549805 	 0.054471492767333984 	 5.602836608886719e-05 	 5.984306335449219e-05 	 
2025-07-30 00:22:30.848814 test begin: paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017680 	 1000 	 0.008309602737426758 	 0.006134748458862305 	 1.2874603271484375e-05 	 1.9550323486328125e-05 	 0.04064583778381348 	 0.06136059761047363 	 4.291534423828125e-05 	 8.845329284667969e-05 	 
2025-07-30 00:22:41.582225 test begin: paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017200 	 1000 	 0.008139848709106445 	 0.006070613861083984 	 8.821487426757812e-06 	 2.002716064453125e-05 	 0.040108680725097656 	 0.05505633354187012 	 3.457069396972656e-05 	 6.818771362304688e-05 	 
2025-07-30 00:22:52.274925 test begin: paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018800 	 1000 	 0.008214712142944336 	 0.006084918975830078 	 1.2636184692382812e-05 	 2.384185791015625e-05 	 0.04037904739379883 	 0.05466938018798828 	 3.361701965332031e-05 	 5.698204040527344e-05 	 
2025-07-30 00:23:03.117865 test begin: paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254020200 	 1000 	 0.008190155029296875 	 0.00619196891784668 	 1.33514404296875e-05 	 3.24249267578125e-05 	 0.04077005386352539 	 0.05542325973510742 	 3.838539123535156e-05 	 7.891654968261719e-05 	 
2025-07-30 00:23:13.908002 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.0070917606353759766 	 0.004686594009399414 	 8.344650268554688e-06 	 1.9550323486328125e-05 	 0.05544638633728027 	 0.05622291564941406 	 5.507469177246094e-05 	 7.343292236328125e-05 	 
2025-07-30 00:23:24.625067 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.007734537124633789 	 0.00605320930480957 	 2.6226043701171875e-05 	 2.6702880859375e-05 	 0.040616750717163086 	 0.05493950843811035 	 5.030632019042969e-05 	 4.2438507080078125e-05 	 
2025-07-30 00:23:36.583208 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.007125377655029297 	 0.004693031311035156 	 1.52587890625e-05 	 2.0265579223632812e-05 	 0.042760372161865234 	 0.05675625801086426 	 4.696846008300781e-05 	 7.176399230957031e-05 	 
2025-07-30 00:23:47.425653 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007732391357421875 	 0.008107423782348633 	 1.3828277587890625e-05 	 5.841255187988281e-05 	 0.04022693634033203 	 0.055253028869628906 	 4.57763671875e-05 	 5.91278076171875e-05 	 
2025-07-30 00:23:58.162052 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.00716853141784668 	 0.0047304630279541016 	 1.1920928955078125e-05 	 2.002716064453125e-05 	 0.04051637649536133 	 0.054720163345336914 	 2.8371810913085938e-05 	 4.982948303222656e-05 	 
2025-07-30 00:24:08.862993 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.007639408111572266 	 0.006165742874145508 	 8.821487426757812e-06 	 2.7179718017578125e-05 	 0.04027700424194336 	 0.0648341178894043 	 2.7894973754882812e-05 	 6.365776062011719e-05 	 
2025-07-30 00:24:19.587693 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.007189512252807617 	 0.0046520233154296875 	 1.2159347534179688e-05 	 1.9073486328125e-05 	 0.040335655212402344 	 0.05567169189453125 	 3.886222839355469e-05 	 6.794929504394531e-05 	 
2025-07-30 00:24:30.249930 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.0075223445892333984 	 0.006039142608642578 	 1.239776611328125e-05 	 2.09808349609375e-05 	 0.04415249824523926 	 0.05572104454040527 	 4.7206878662109375e-05 	 6.961822509765625e-05 	 
2025-07-30 00:24:42.016490 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.007161140441894531 	 0.004679203033447266 	 9.298324584960938e-06 	 2.4318695068359375e-05 	 0.04029417037963867 	 0.054792165756225586 	 2.9087066650390625e-05 	 5.53131103515625e-05 	 
2025-07-30 00:24:52.723199 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007681131362915039 	 0.006074666976928711 	 9.059906005859375e-06 	 2.2172927856445312e-05 	 0.04036307334899902 	 0.05490231513977051 	 4.3392181396484375e-05 	 6.079673767089844e-05 	 
2025-07-30 00:25:03.386448 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), ) 	 101607009 	 1000 	 2.0235793590545654 	 15.575815200805664 	 0.00010085105895996094 	 0.00024318695068359375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:25:24.932312 test begin: paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016093120 	 1000 	 0.001096487045288086 	 0.007045269012451172 	 1.0013580322265625e-05 	 3.790855407714844e-05 	 0.03226423263549805 	 4.485003232955933 	 2.956390380859375e-05 	 2.290926456451416 	 combined
2025-07-30 00:26:02.664626 test begin: paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016133120 	 1000 	 0.0010197162628173828 	 0.007104158401489258 	 7.867813110351562e-06 	 2.4318695068359375e-05 	 0.03253364562988281 	 4.487962245941162 	 2.8848648071289062e-05 	 2.2940196990966797 	 combined
2025-07-30 00:26:41.181940 test begin: paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016076800 	 1000 	 0.001009225845336914 	 0.006955623626708984 	 1.0013580322265625e-05 	 2.2172927856445312e-05 	 0.03204607963562012 	 4.486220836639404 	 1.8835067749023438e-05 	 2.292341947555542 	 combined
2025-07-30 00:27:23.933465 test begin: paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016099200 	 1000 	 0.0010058879852294922 	 0.007108211517333984 	 8.821487426757812e-06 	 2.3126602172851562e-05 	 0.03284573554992676 	 4.483958959579468 	 4.7206878662109375e-05 	 2.290572166442871 	 combined
2025-07-30 00:28:04.111674 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 00:28:06.939630 82163 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101748608 	 1000 	 0.3731997013092041 	 0.9202132225036621 	 0.36148571968078613 	 0.898566484451294 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:28:08.463823 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 00:28:18.150887 82244 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101712896 	 1000 	 1.7683515548706055 	 5.509079456329346 	 1.7540647983551025 	 5.486840009689331 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:28:24.312524 test begin: paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 00:28:33.956831 82520 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 102070373 	 1000 	 1.8855338096618652 	 5.536152124404907 	 1.8690869808197021 	 5.512722730636597 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:28:40.175626 test begin: paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, ) 	 102434304 	 1000 	 7.197170734405518 	 22.279423713684082 	 7.182800531387329 	 22.25664973258972 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:29:52.454312 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.5551800727844238 	 0.550553560256958 	 0.5426597595214844 	 0.5319225788116455 	 3.287524700164795 	 3.0805270671844482 	 1.6792089939117432 	 1.5746760368347168 	 
2025-07-30 00:30:10.553865 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, ) 	 509740000 	 1000 	 0.10266566276550293 	 0.09871149063110352 	 0.09081506729125977 	 0.08030200004577637 	 1.7924554347991943 	 1.5915560722351074 	 0.9147920608520508 	 0.8130826950073242 	 
2025-07-30 00:30:22.706507 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.5693309307098389 	 1.045184850692749 	 0.5563216209411621 	 0.5480122566223145 	 3.3541674613952637 	 3.1653945446014404 	 1.713010549545288 	 1.6176669597625732 	 
2025-07-30 00:30:41.219051 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 614912000 	 1000 	 0.5985119342803955 	 0.5863363742828369 	 0.5866014957427979 	 0.5679001808166504 	 3.6486170291900635 	 3.350830078125 	 1.8648419380187988 	 1.1413648128509521 	 
2025-07-30 00:30:59.812224 test begin: paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, ) 	 552161280 	 1000 	 1.3589353561401367 	 0.7396240234375 	 0.7074522972106934 	 0.7197062969207764 	 4.19310998916626 	 3.841580390930176 	 2.225632905960083 	 1.963301658630371 	 
2025-07-30 00:31:21.209995 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7889416217803955 	 0.8265056610107422 	 0.7770025730133057 	 0.794182300567627 	 4.290815353393555 	 4.117905378341675 	 2.1935222148895264 	 2.103179931640625 	 
2025-07-30 00:31:42.905342 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, ) 	 509964000 	 1000 	 0.13514256477355957 	 0.12898039817810059 	 0.12300801277160645 	 0.11075711250305176 	 1.8939120769500732 	 1.6831080913543701 	 0.9676744937896729 	 0.8609261512756348 	 
2025-07-30 00:31:55.149252 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7885863780975342 	 0.8126351833343506 	 0.7766892910003662 	 0.7941441535949707 	 4.3418967723846436 	 4.164873838424683 	 2.219447135925293 	 2.1274492740631104 	 
2025-07-30 00:32:15.066800 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 642048000 	 1000 	 0.833425760269165 	 0.8582742214202881 	 0.8217158317565918 	 0.8325991630554199 	 4.681278228759766 	 4.466395616531372 	 2.3911633491516113 	 1.5221459865570068 	 
2025-07-30 00:32:37.173596 test begin: paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, ) 	 534973440 	 1000 	 0.5196068286895752 	 0.5104005336761475 	 0.5079007148742676 	 0.4920156002044678 	 3.1582977771759033 	 2.917203903198242 	 1.6136369705200195 	 1.4905169010162354 	 
2025-07-30 00:32:53.066177 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2540162448 	 1000 	 0.043912649154663086 	 0.04157686233520508 	 4.982948303222656e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:53.248610 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 5080322448 	 1000 	 0.03674602508544922 	 0.040717363357543945 	 2.4318695068359375e-05 	 6.437301635742188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:53.535676 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5080322448 	 1000 	 0.03740954399108887 	 0.04089522361755371 	 3.0279159545898438e-05 	 6.246566772460938e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:53.698784 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262247006 	 1000 	 0.04268193244934082 	 0.041022539138793945 	 3.695487976074219e-05 	 6.008148193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:53.867805 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696685406 	 1000 	 0.04446768760681152 	 0.041539669036865234 	 2.5987625122070312e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:54.043165 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131125927 	 1000 	 0.04241538047790527 	 0.04074668884277344 	 2.0742416381835938e-05 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:54.213564 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131123806 	 1000 	 0.04244732856750488 	 0.04144287109375 	 3.886222839355469e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:54.383642 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564327 	 1000 	 0.043678998947143555 	 0.04119706153869629 	 2.8848648071289062e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:54.551790 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564832 	 1000 	 0.042253732681274414 	 0.04104447364807129 	 2.3126602172851562e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:54.719355 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25404048 	 1000 	 0.04243803024291992 	 0.04147744178771973 	 2.5987625122070312e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:54.886614 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 5131125927 	 1000 	 0.036276817321777344 	 0.03991580009460449 	 3.266334533691406e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:55.047805 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131125927 	 1000 	 0.03953218460083008 	 0.04107379913330078 	 2.6464462280273438e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:55.217090 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 5131126432 	 1000 	 0.036164283752441406 	 0.03965163230895996 	 2.3126602172851562e-05 	 5.7220458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:55.378744 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131126432 	 1000 	 0.037169456481933594 	 0.03890109062194824 	 3.0994415283203125e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:55.538508 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50805648 	 1000 	 0.03601574897766113 	 0.04112076759338379 	 2.0503997802734375e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:55.704384 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50805648 	 1000 	 0.036837100982666016 	 0.03915977478027344 	 2.09808349609375e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:55.864550 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131124816 	 1000 	 0.04637718200683594 	 0.04062652587890625 	 2.6941299438476562e-05 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:56.036687 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131126432 	 1000 	 0.04499173164367676 	 0.04084372520446777 	 2.8371810913085938e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:56.205744 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696686416 	 1000 	 0.04235196113586426 	 0.040714263916015625 	 2.2172927856445312e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:56.371601 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262248016 	 1000 	 0.04274272918701172 	 0.04792356491088867 	 2.6702880859375e-05 	 6.67572021484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:56.557105 test begin: paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080324848 	 1000 	 0.04309892654418945 	 0.04067182540893555 	 3.170967102050781e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:56.757343 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50805648 	 1000 	 0.042456865310668945 	 0.04131937026977539 	 2.4557113647460938e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:56.924826 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2590965648 	 1000 	 0.04407382011413574 	 0.0428311824798584 	 2.4557113647460938e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:57.095371 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080322448 	 1000 	 0.042574167251586914 	 0.04115128517150879 	 3.1948089599609375e-05 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:57.269595 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5105724048 	 1000 	 0.04286813735961914 	 0.043657779693603516 	 3.719329833984375e-05 	 6.4849853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:57.439586 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10160644848 	 1000 	 0.04229021072387695 	 0.04042410850524902 	 2.5033950805664062e-05 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:57.604933 test begin: paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.06061673164367676 	 0.08670401573181152 	 0.030964136123657227 	 0.04377245903015137 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:58.044227 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164015264 	 1000 	 0.06061434745788574 	 0.08594298362731934 	 0.030937910079956055 	 0.043749094009399414 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:58.457327 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.0606386661529541 	 0.0859062671661377 	 0.030964374542236328 	 0.0437312126159668 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:58.878950 test begin: paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.022984743118286133 	 0.030624866485595703 	 0.0006201267242431641 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:59.079476 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10162198944 	 1000 	 0.024283170700073242 	 0.030507326126098633 	 0.00041031837463378906 	 5.173683166503906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:32:59.277520 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.02294158935546875 	 0.030387163162231445 	 0.0008533000946044922 	 4.792213439941406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/base/libpaddle.so
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 38, in <module>
    from . import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/backward.py", line 28, in <module>
    from . import core, framework, log_helper, unique_name
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/core.py", line 388, in <module>
    raise e
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/core.py", line 267, in <module>
    from . import libpaddle
ImportError: initialization failed
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 9, in <module>
    import torch
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 2240, in <module>
    from torch import quantization as quantization  # usort: skip
  File "/usr/local/lib/python3.10/dist-packages/torch/quantization/__init__.py", line 2, in <module>
    from .fake_quantize import *  # noqa: F403
  File "/usr/local/lib/python3.10/dist-packages/torch/quantization/fake_quantize.py", line 10, in <module>
    from torch.ao.quantization.fake_quantize import (
  File "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/__init__.py", line 12, in <module>
    from .pt2e._numeric_debugger import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/pt2e/_numeric_debugger.py", line 9, in <module>
    from torch.ao.quantization.pt2e.graph_utils import bfs_trace_with_node_process
  File "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/pt2e/graph_utils.py", line 9, in <module>
    from torch.export import ExportedProgram
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 17, in <module>
    from torch.fx.passes.infra.pass_base import PassResult
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/__init__.py", line 1, in <module>
    from . import (
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/net_min_base.py", line 12, in <module>
    from .split_utils import split_by_tags
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/split_utils.py", line 9, in <module>
    from torch.fx.passes.utils import HolderModule, lift_subgraph_as_module
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/utils/__init__.py", line 1, in <module>
    from .common import compare_graphs, HolderModule, lift_subgraph_as_module
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/utils/common.py", line 6, in <module>
    from torch.fx.passes.utils.matcher_utils import SubgraphMatcher
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/passes/utils/matcher_utils.py", line 38, in <module>
    class InternalMatch:
  File "/usr/lib/python3.10/dataclasses.py", line 1184, in dataclass
    return wrap(cls)
  File "/usr/lib/python3.10/dataclasses.py", line 1175, in wrap
    return _process_class(cls, init, repr, eq, order, unsafe_hash,
  File "/usr/lib/python3.10/dataclasses.py", line 1053, in _process_class
    _cmp_fn('__eq__', '==',
  File "/usr/lib/python3.10/dataclasses.py", line 629, in _cmp_fn
    return _create_fn(name,
  File "/usr/lib/python3.10/dataclasses.py", line 432, in _create_fn
    exec(txt, globals, ns)
  File "<string>", line 1, in <module>
KeyboardInterrupt
2025-07-30 00:15:10.266020 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
W0730 00:15:10.526577 69362 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.031905174255371094 	 0.04583454132080078 	 2.2411346435546875e-05 	 7.128715515136719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:11.119999 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.022436141967773438 	 0.033379554748535156 	 1.8835067749023438e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:11.285265 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.05898857116699219 	 0.08542823791503906 	 0.030060529708862305 	 0.04350614547729492 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:11.729995 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10165402496 	 1000 	 0.02381610870361328 	 0.038468360900878906 	 2.3603439331054688e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:11.950890 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.022301197052001953 	 0.03269028663635254 	 2.3603439331054688e-05 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:12.151685 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10164173504 	 1000 	 0.03145003318786621 	 0.03016376495361328 	 2.2172927856445312e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:12.394735 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.02263951301574707 	 0.03020763397216797 	 2.384185791015625e-05 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:12.595168 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.03656911849975586 	 0.030344009399414062 	 2.2172927856445312e-05 	 4.4345855712890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:12.814833 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.022075176239013672 	 0.03045797348022461 	 2.4080276489257812e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:13.027612 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.022420406341552734 	 0.030516624450683594 	 2.3365020751953125e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:13.233271 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.023790597915649414 	 0.042780399322509766 	 2.6226043701171875e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:13.492449 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10176284196 	 1000 	 0.05880141258239746 	 0.08889627456665039 	 0.029973506927490234 	 0.04364967346191406 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:13.951753 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.060842275619506836 	 0.08812928199768066 	 0.02979898452758789 	 0.04352712631225586 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:14.399616 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10168679808 	 1000 	 0.022521257400512695 	 0.03084278106689453 	 1.6689300537109375e-05 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:14.558441 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.022247791290283203 	 0.030843019485473633 	 1.9550323486328125e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:14.717919 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.02215409278869629 	 0.030858516693115234 	 1.7881393432617188e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:14.882147 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.027991771697998047 	 0.030814647674560547 	 2.002716064453125e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:15.064594 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.03829360008239746 	 0.03306245803833008 	 2.7418136596679688e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:15.277494 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.022735595703125 	 0.03454947471618652 	 1.621246337890625e-05 	 6.437301635742188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:15.443944 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.022275209426879883 	 0.030985593795776367 	 1.621246337890625e-05 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:15.602947 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164992832 	 1000 	 0.022405624389648438 	 0.030799388885498047 	 2.6464462280273438e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:15.762089 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.022181034088134766 	 0.03193783760070801 	 1.5974044799804688e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:15.923645 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164647178 	 1000 	 0.0222780704498291 	 0.033191680908203125 	 1.6450881958007812e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:16.085592 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10165300080 	 1000 	 0.058769941329956055 	 0.09149885177612305 	 0.027295351028442383 	 0.04365086555480957 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:16.564683 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.059082746505737305 	 0.08848166465759277 	 0.030072927474975586 	 0.04371786117553711 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:16.991255 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164173504 	 1000 	 0.059218406677246094 	 0.08584141731262207 	 0.030152559280395508 	 0.04369091987609863 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:17.412254 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.05908012390136719 	 0.08580398559570312 	 0.0301058292388916 	 0.04367828369140625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:17.831389 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.05919671058654785 	 0.08582639694213867 	 0.03015279769897461 	 0.043694496154785156 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:18.268972 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.059059858322143555 	 0.08573675155639648 	 0.030088186264038086 	 0.043665409088134766 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:18.702686 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.05923128128051758 	 0.08578300476074219 	 0.030177593231201172 	 0.04368185997009277 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:19.144638 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.05908918380737305 	 0.0858008861541748 	 0.030099153518676758 	 0.043659210205078125 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:19.579987 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.02314162254333496 	 0.03109288215637207 	 2.2649765014648438e-05 	 7.510185241699219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:19.792462 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10166375448 	 1000 	 0.02235722541809082 	 0.030361175537109375 	 2.288818359375e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:20.042982 test begin: paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.034188032150268555 	 0.039388418197631836 	 2.3365020751953125e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:20.251801 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.031102418899536133 	 0.03976011276245117 	 3.075599670410156e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:20.453458 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10161861696 	 1000 	 0.03221249580383301 	 0.04154038429260254 	 2.5510787963867188e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:20.643232 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5080356720 	 1000 	 0.0402226448059082 	 0.04284477233886719 	 4.172325134277344e-05 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:20.805217 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5080356720 	 1000 	 0.03892350196838379 	 0.04357266426086426 	 3.337860107421875e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:20.965562 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2540196720 	 1000 	 0.030254125595092773 	 0.03719353675842285 	 2.2649765014648438e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.102387 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.030280590057373047 	 0.034140825271606445 	 2.1219253540039062e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.240650 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131141380 	 1000 	 0.029590129852294922 	 0.033267974853515625 	 1.811981201171875e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.377996 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.029381275177001953 	 0.0332944393157959 	 2.384185791015625e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.519744 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.02927541732788086 	 0.033566951751708984 	 1.5735626220703125e-05 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.655833 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565607050 	 1000 	 0.029355525970458984 	 0.03380465507507324 	 1.5735626220703125e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.793247 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.029394865036010742 	 0.033571720123291016 	 1.4781951904296875e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:21.932692 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696702980 	 1000 	 0.02907085418701172 	 0.03319811820983887 	 1.4781951904296875e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.072202 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696702980 	 1000 	 0.0295412540435791 	 0.033815622329711914 	 1.6927719116210938e-05 	 4.267692565917969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.212830 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.02946925163269043 	 0.03367257118225098 	 1.811981201171875e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.347809 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131137744 	 1000 	 0.029279470443725586 	 0.033608198165893555 	 1.5020370483398438e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.484679 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.028967857360839844 	 0.03345632553100586 	 1.3589859008789062e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.618615 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.044458627700805664 	 0.0334625244140625 	 2.0742416381835938e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.775761 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565605232 	 1000 	 0.029484033584594727 	 0.03338813781738281 	 1.5497207641601562e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:22.918933 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.03063797950744629 	 0.03394293785095215 	 3.24249267578125e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.061267 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696699344 	 1000 	 0.030075550079345703 	 0.03661823272705078 	 2.3126602172851562e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.207967 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696699344 	 1000 	 0.029570817947387695 	 0.03336524963378906 	 2.0265579223632812e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.346253 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.029520273208618164 	 0.0333712100982666 	 1.5974044799804688e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.482708 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131135320 	 1000 	 0.030312061309814453 	 0.03330636024475098 	 1.5974044799804688e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.620306 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.030089855194091797 	 0.03338003158569336 	 2.3603439331054688e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.756673 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.029216766357421875 	 0.03347134590148926 	 1.9311904907226562e-05 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:23.895696 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565604020 	 1000 	 0.031237363815307617 	 0.034285783767700195 	 2.288818359375e-05 	 8.0108642578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.042399 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.030251502990722656 	 0.03347015380859375 	 1.8358230590820312e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.179798 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696696920 	 1000 	 0.030080318450927734 	 0.04261612892150879 	 3.4809112548828125e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.336553 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696696920 	 1000 	 0.03566765785217285 	 0.034337759017944336 	 3.0517578125e-05 	 4.696846008300781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.489702 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565610080 	 1000 	 0.030066967010498047 	 0.03318309783935547 	 1.4066696166992188e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.626573 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.029450178146362305 	 0.03337597846984863 	 1.6689300537109375e-05 	 4.9591064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.765087 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.029488801956176758 	 0.033608198165893555 	 1.8835067749023438e-05 	 4.863739013671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:24.914739 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.029404163360595703 	 0.033394813537597656 	 2.1457672119140625e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.052403 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131165620 	 1000 	 0.029590845108032227 	 0.033872365951538086 	 1.8835067749023438e-05 	 6.961822509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.188130 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131165620 	 1000 	 0.03029489517211914 	 0.0338442325592041 	 1.7404556274414062e-05 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.330925 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131166832 	 1000 	 0.030070066452026367 	 0.03390073776245117 	 2.6702880859375e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.468018 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131166832 	 1000 	 0.029403209686279297 	 0.03356599807739258 	 1.52587890625e-05 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.605897 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131168650 	 1000 	 0.02966928482055664 	 0.03311491012573242 	 2.288818359375e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.741875 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131168650 	 1000 	 0.029607057571411133 	 0.03321552276611328 	 2.002716064453125e-05 	 4.792213439941406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:25.880959 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131171680 	 1000 	 0.03010845184326172 	 0.03342247009277344 	 1.6450881958007812e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.022163 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131171680 	 1000 	 0.029455184936523438 	 0.03330540657043457 	 1.811981201171875e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.161853 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50839920 	 1000 	 0.0292661190032959 	 0.03423428535461426 	 1.5497207641601562e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.297966 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50839920 	 1000 	 0.030747175216674805 	 0.03469538688659668 	 1.8835067749023438e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.439759 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25438320 	 1000 	 0.06751656532287598 	 0.03402543067932129 	 3.886222839355469e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.635009 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262258520 	 1000 	 0.0666956901550293 	 0.03392910957336426 	 2.6464462280273438e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.835231 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262258520 	 1000 	 0.029535293579101562 	 0.03318333625793457 	 2.3126602172851562e-05 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:26.975834 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262260944 	 1000 	 0.029839754104614258 	 0.03337907791137695 	 1.430511474609375e-05 	 4.2438507080078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:27.112852 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262260944 	 1000 	 0.030066967010498047 	 0.03325819969177246 	 1.9073486328125e-05 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:27.251657 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262264580 	 1000 	 0.029984235763549805 	 0.0334172248840332 	 1.811981201171875e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:27.388362 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262264580 	 1000 	 0.04946494102478027 	 0.033948421478271484 	 4.482269287109375e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:15:27.574994 test begin: paddle.numel(Tensor([508032010],"float32"), )
[Prof] paddle.numel 	 paddle.numel(Tensor([508032010],"float32"), ) 	 508032010 	 1000 	 0.009060382843017578 	 0.03702187538146973 	 2.7418136596679688e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:15:38.877749 test begin: paddle.positive(Tensor([100, 5080321],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.001703023910522461 	 0.0002014636993408203 	 8.821487426757812e-06 	 1.430511474609375e-05 	 0.03091144561767578 	 0.048105716705322266 	 1.9788742065429688e-05 	 5.626678466796875e-05 	 combined
2025-07-30 00:15:55.883830 test begin: paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), ) 	 1016064600 	 1000 	 0.003222942352294922 	 0.00020575523376464844 	 2.8371810913085938e-05 	 1.4543533325195312e-05 	 0.0305633544921875 	 0.04424476623535156 	 1.8358230590820312e-05 	 3.0279159545898438e-05 	 combined
2025-07-30 00:16:36.737907 test begin: paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), ) 	 508032400 	 1000 	 0.0017230510711669922 	 0.00020384788513183594 	 5.0067901611328125e-06 	 1.4781951904296875e-05 	 0.030643701553344727 	 0.049514055252075195 	 1.8596649169921875e-05 	 5.221366882324219e-05 	 combined
2025-07-30 00:16:53.956374 test begin: paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), ) 	 1016064400 	 1000 	 0.0017619132995605469 	 0.0002048015594482422 	 1.0728836059570312e-05 	 1.4781951904296875e-05 	 0.03138446807861328 	 0.04451608657836914 	 3.457069396972656e-05 	 4.458427429199219e-05 	 combined
2025-07-30 00:17:32.532272 test begin: paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), ) 	 508032300 	 1000 	 0.001708984375 	 0.0002052783966064453 	 5.7220458984375e-06 	 1.5020370483398438e-05 	 0.030747413635253906 	 0.047202110290527344 	 1.811981201171875e-05 	 6.842613220214844e-05 	 combined
2025-07-30 00:17:49.080515 test begin: paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), ) 	 1016064300 	 1000 	 0.0017249584197998047 	 0.0002040863037109375 	 6.9141387939453125e-06 	 1.4781951904296875e-05 	 0.030759096145629883 	 0.04616856575012207 	 3.647804260253906e-05 	 6.031990051269531e-05 	 combined
2025-07-30 00:18:27.682680 test begin: paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), ) 	 508032240 	 1000 	 0.002789735794067383 	 0.00020551681518554688 	 6.437301635742188e-05 	 1.4781951904296875e-05 	 0.03066110610961914 	 0.04434657096862793 	 2.6226043701171875e-05 	 4.482269287109375e-05 	 combined
2025-07-30 00:18:44.212924 test begin: paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), ) 	 1016064240 	 1000 	 0.0017125606536865234 	 0.00021123886108398438 	 5.7220458984375e-06 	 1.5497207641601562e-05 	 0.030637741088867188 	 0.04405045509338379 	 1.811981201171875e-05 	 3.24249267578125e-05 	 combined
2025-07-30 00:15:12.722233 test begin: paddle.positive(Tensor([496130, 1024],"float32"), )
W0730 00:15:20.666658 69479 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.positive 	 paddle.positive(Tensor([496130, 1024],"float32"), ) 	 508037120 	 1000 	 0.0017294883728027344 	 0.000202178955078125 	 1.4066696166992188e-05 	 1.6689300537109375e-05 	 0.030988693237304688 	 0.05127525329589844 	 2.9802322387695312e-05 	 5.745887756347656e-05 	 combined
2025-07-30 00:15:30.161900 test begin: paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), ) 	 508032600 	 1000 	 0.002619504928588867 	 0.00022339820861816406 	 1.8835067749023438e-05 	 1.5974044799804688e-05 	 0.03434276580810547 	 0.04784893989562988 	 3.886222839355469e-05 	 6.103515625e-05 	 combined
2025-07-30 00:15:47.871689 test begin: paddle.rank(input=Tensor([1270080101, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([1270080101, 2],"float64"), ) 	 2540160202 	 1000 	 0.04110574722290039 	 0.02934432029724121 	 3.2901763916015625e-05 	 3.910064697265625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:16:56.213669 test begin: paddle.rank(input=Tensor([201, 12700801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([201, 12700801],"float64"), ) 	 2552861001 	 1000 	 0.05457139015197754 	 0.037458181381225586 	 4.57763671875e-05 	 6.985664367675781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:18:00.619505 test begin: paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), ) 	 2548628404 	 1000 	 0.05326724052429199 	 0.03712940216064453 	 5.316734313964844e-05 	 9.417533874511719e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:18:54.995920 test begin: paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), ) 	 2548628404 	 1000 	 0.040758371353149414 	 0.029235124588012695 	 2.1457672119140625e-05 	 7.796287536621094e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:19:58.278791 test begin: paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), ) 	 2548628404 	 1000 	 0.04255104064941406 	 0.029023170471191406 	 2.86102294921875e-05 	 4.100799560546875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:21:09.576718 test begin: paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), ) 	 2540160808 	 1000 	 0.04054856300354004 	 0.029400348663330078 	 1.8596649169921875e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:22:06.216323 test begin: paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], )
[Prof] paddle.reshape 	 paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], ) 	 1016135680 	 1000 	 0.01037907600402832 	 0.003997087478637695 	 9.775161743164062e-06 	 5.125999450683594e-05 	 0.045209646224975586 	 4.498095273971558 	 1.8596649169921875e-05 	 2.297741413116455 	 
2025-07-30 00:22:47.312995 test begin: paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), ) 	 2540160613 	 1000 	 0.009825944900512695 	 0.010653495788574219 	 0.0019176006317138672 	 2.765655517578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:42.641197 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), ) 	 25452802 	 1000 	 0.010199546813964844 	 0.010699272155761719 	 0.002013683319091797 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:44.509717 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), ) 	 50854402 	 1000 	 0.010930538177490234 	 0.010918378829956055 	 0.0027222633361816406 	 6.246566772460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:45.324373 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), ) 	 50854402 	 1000 	 0.010999679565429688 	 0.010765314102172852 	 0.0028231143951416016 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 00:23:45.958189 test begin: paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, ) 	 508035600 	 1000 	 0.02068018913269043 	 3.0666816234588623 	 2.288818359375e-05 	 1.0426008701324463 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:24:05.807963 test begin: paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, ) 	 317520300 	 1000 	 0.7566256523132324 	 3.809764862060547 	 0.727733850479126 	 1.295393466949463 	 6.892765760421753 	 4.51380729675293 	 0.8787703514099121 	 1.429088830947876 	 
2025-07-30 00:24:37.519259 test begin: paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, ) 	 254016600 	 1000 	 0.01981806755065918 	 3.0674538612365723 	 1.7881393432617188e-05 	 1.0436720848083496 	 3.108614683151245 	 3.0709900856018066 	 0.39481377601623535 	 0.7841372489929199 	 
2025-07-30 00:25:01.649417 test begin: paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, ) 	 50803280 	 1000 	 0.019833803176879883 	 0.3161637783050537 	 1.8835067749023438e-05 	 0.10743594169616699 	 0.33014965057373047 	 0.31818604469299316 	 0.0419154167175293 	 0.08108758926391602 	 
2025-07-30 00:25:04.202160 test begin: paddle.shape(Tensor([10, 1600, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([10, 1600, 376, 280],"float32"), ) 	 1684480000 	 1000 	 0.00928807258605957 	 0.03991413116455078 	 1.52587890625e-05 	 8.440017700195312e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:25:33.432661 test begin: paddle.shape(Tensor([130, 128, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([130, 128, 256, 256],"float16"), ) 	 1090519040 	 1000 	 0.004425048828125 	 0.030918598175048828 	 8.58306884765625e-06 	 8.58306884765625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:25:54.698299 test begin: paddle.shape(Tensor([40, 121, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 121, 376, 280],"float32"), ) 	 509555200 	 1000 	 0.009298086166381836 	 0.03936195373535156 	 1.0967254638671875e-05 	 6.890296936035156e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:26:03.125762 test begin: paddle.shape(Tensor([40, 128, 256, 388],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 388],"float32"), ) 	 508559360 	 1000 	 0.009357929229736328 	 0.03945779800415039 	 1.52587890625e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:26:11.764931 test begin: paddle.shape(Tensor([40, 128, 256, 776],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 776],"float16"), ) 	 1017118720 	 1000 	 0.0044367313385009766 	 0.03096628189086914 	 1.5497207641601562e-05 	 9.250640869140625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:26:30.578215 test begin: paddle.shape(Tensor([40, 128, 388, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 388, 256],"float32"), ) 	 508559360 	 1000 	 0.00439763069152832 	 0.03350377082824707 	 1.0728836059570312e-05 	 0.00011491775512695312 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:26:40.290296 test begin: paddle.shape(Tensor([40, 128, 776, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 776, 256],"float16"), ) 	 1017118720 	 1000 	 0.009352445602416992 	 0.03954005241394043 	 1.6927719116210938e-05 	 6.67572021484375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:26:59.409615 test begin: paddle.shape(Tensor([40, 1600, 29, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 29, 280],"float32"), ) 	 519680000 	 1000 	 0.00931859016418457 	 0.03995108604431152 	 1.9311904907226562e-05 	 9.489059448242188e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:27:08.483995 test begin: paddle.shape(Tensor([40, 1600, 376, 22],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 376, 22],"float32"), ) 	 529408000 	 1000 	 0.009356975555419922 	 0.03967118263244629 	 3.075599670410156e-05 	 7.104873657226562e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:27:18.402280 test begin: paddle.shape(Tensor([40, 194, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 194, 256, 256],"float32"), ) 	 508559360 	 1000 	 0.0044629573822021484 	 0.03147625923156738 	 1.52587890625e-05 	 9.1552734375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:27:27.569257 test begin: paddle.shape(Tensor([40, 388, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 388, 256, 256],"float16"), ) 	 1017118720 	 1000 	 0.004444122314453125 	 0.031019210815429688 	 2.5033950805664062e-05 	 5.9604644775390625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:27:46.643589 test begin: paddle.shape(Tensor([70, 128, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([70, 128, 256, 256],"float32"), ) 	 587202560 	 1000 	 0.00442957878112793 	 0.030940771102905273 	 1.1920928955078125e-05 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:27:55.554910 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0730 00:28:11.166059 81994 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016099200 	 1000 	 0.008261680603027344 	 0.012938261032104492 	 3.981590270996094e-05 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:28:13.300235 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0730 00:28:30.422616 82343 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016099200 	 1000 	 0.007786750793457031 	 0.012693166732788086 	 1.0728836059570312e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:28:33.310163 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0730 00:28:48.836671 82684 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016099200 	 1000 	 0.0080108642578125 	 0.015752315521240234 	 1.0967254638671875e-05 	 7.462501525878906e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:28:50.981395 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0730 00:29:06.244907 83351 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016076800 	 1000 	 0.010673046112060547 	 0.020283937454223633 	 4.220008850097656e-05 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:29:09.829118 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0730 00:29:27.417481 83696 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016076800 	 1000 	 0.007947444915771484 	 0.012799739837646484 	 1.33514404296875e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:29:29.646748 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0730 00:29:48.068164 84043 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016076800 	 1000 	 0.00789785385131836 	 0.012984037399291992 	 3.504753112792969e-05 	 3.0994415283203125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:29:50.145143 test begin: paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508035600 	 1000 	 0.015560150146484375 	 3.06982159614563 	 1.3589859008789062e-05 	 1.0425786972045898 	 3.104264736175537 	 3.0756001472473145 	 0.5275120735168457 	 0.6284768581390381 	 combined
2025-07-30 00:30:20.247531 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 254020320 	 1000 	 0.023710250854492188 	 3.082720994949341 	 1.52587890625e-05 	 1.0427591800689697 	 3.0970849990844727 	 3.0749385356903076 	 0.5262231826782227 	 0.6272571086883545 	 combined
2025-07-30 00:30:44.669398 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508036320 	 1000 	 0.024022340774536133 	 3.082839012145996 	 2.7418136596679688e-05 	 1.0426523685455322 	 3.0863568782806396 	 3.0762743949890137 	 0.5244097709655762 	 0.6286702156066895 	 combined
2025-07-30 00:31:16.398443 test begin: paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.009653091430664062 	 0.008782625198364258 	 1.8358230590820312e-05 	 2.5272369384765625e-05 	 0.0494389533996582 	 0.060185909271240234 	 4.696846008300781e-05 	 7.343292236328125e-05 	 
2025-07-30 00:31:38.108884 test begin: paddle.squeeze(Tensor([1053440, 483],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([1053440, 483],"float32"), ) 	 508811520 	 1000 	 0.003889322280883789 	 0.006847381591796875 	 7.152557373046875e-06 	 2.6702880859375e-05 	 0.04924321174621582 	 0.055185794830322266 	 4.363059997558594e-05 	 6.198883056640625e-05 	 
2025-07-30 00:31:58.347474 test begin: paddle.squeeze(Tensor([3969010, 128],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([3969010, 128],"float32"), ) 	 508033280 	 1000 	 0.008531570434570312 	 0.003674745559692383 	 5.173683166503906e-05 	 2.0265579223632812e-05 	 0.041461944580078125 	 0.0671236515045166 	 5.316734313964844e-05 	 0.00012183189392089844 	 
2025-07-30 00:32:14.587250 test begin: paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, ) 	 526400000 	 1000 	 0.00923013687133789 	 0.007177591323852539 	 1.239776611328125e-05 	 2.5510787963867188e-05 	 0.05127882957458496 	 0.07410931587219238 	 7.2479248046875e-05 	 0.00011444091796875 	 
2025-07-30 00:32:34.326101 test begin: paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, ) 	 522188800 	 1000 	 0.004681587219238281 	 0.003917694091796875 	 1.7404556274414062e-05 	 2.1219253540039062e-05 	 0.04149889945983887 	 0.0647881031036377 	 3.4332275390625e-05 	 5.507469177246094e-05 	 
2025-07-30 00:32:50.734181 test begin: paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, ) 	 508033000 	 1000 	 0.004839897155761719 	 0.003968238830566406 	 1.0013580322265625e-05 	 2.5272369384765625e-05 	 0.04166102409362793 	 0.06401467323303223 	 5.0067901611328125e-05 	 4.863739013671875e-05 	 
2025-07-30 00:33:06.822785 test begin: paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.004712581634521484 	 0.004931211471557617 	 7.867813110351562e-06 	 2.288818359375e-05 	 0.041286468505859375 	 0.07172489166259766 	 3.62396240234375e-05 	 5.316734313964844e-05 	 
2025-07-30 00:33:23.000505 test begin: paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.004747152328491211 	 0.005032777786254883 	 1.239776611328125e-05 	 2.2411346435546875e-05 	 0.041402339935302734 	 0.0757606029510498 	 4.100799560546875e-05 	 8.082389831542969e-05 	 
2025-07-30 00:33:41.670163 test begin: paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], ) 	 819200000 	 1000 	 0.004831790924072266 	 0.004937410354614258 	 8.821487426757812e-06 	 2.09808349609375e-05 	 0.041216135025024414 	 0.06554746627807617 	 2.4318695068359375e-05 	 5.698204040527344e-05 	 
2025-07-30 00:34:07.341605 test begin: paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], ) 	 508800000 	 1000 	 0.004749774932861328 	 0.004946470260620117 	 1.2636184692382812e-05 	 2.86102294921875e-05 	 0.0413358211517334 	 0.07059812545776367 	 5.0067901611328125e-05 	 5.4836273193359375e-05 	 
2025-07-30 00:34:27.464849 test begin: paddle.t(Tensor([100, 5080321],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.0041882991790771484 	 0.008985757827758789 	 1.3589859008789062e-05 	 5.793571472167969e-05 	 0.03990006446838379 	 0.0685110092163086 	 5.555152893066406e-05 	 6.389617919921875e-05 	 
2025-07-30 00:34:43.537619 test begin: paddle.t(Tensor([200, 2540161],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.004163026809692383 	 0.0034911632537841797 	 1.4543533325195312e-05 	 1.9311904907226562e-05 	 0.0398097038269043 	 0.07213497161865234 	 2.1219253540039062e-05 	 7.867813110351562e-05 	 
2025-07-30 00:34:59.527410 test begin: paddle.t(Tensor([25401610, 20],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.004166364669799805 	 0.0035750865936279297 	 1.1682510375976562e-05 	 2.002716064453125e-05 	 0.04003024101257324 	 0.06869316101074219 	 6.270408630371094e-05 	 7.295608520507812e-05 	 
2025-07-30 00:35:15.405563 test begin: paddle.t(Tensor([496130, 512],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([496130, 512],"int64"), ) 	 254018560 	 1000 	 0.004136085510253906 	 0.003548145294189453 	 5.9604644775390625e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:35:23.770053 test begin: paddle.t(Tensor([50803210, 10],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([50803210, 10],"float32"), ) 	 508032100 	 1000 	 0.0041315555572509766 	 0.0067005157470703125 	 8.106231689453125e-06 	 2.1696090698242188e-05 	 0.03988003730773926 	 0.05783271789550781 	 3.9577484130859375e-05 	 9.560585021972656e-05 	 
2025-07-30 00:35:41.666953 test begin: paddle.t(Tensor([5120, 49613],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([5120, 49613],"int64"), ) 	 254018560 	 1000 	 0.004179954528808594 	 0.0034568309783935547 	 7.3909759521484375e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:35:49.278870 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803807 	 1000 	 0.08616042137145996 	 0.1212928295135498 	 2.6941299438476562e-05 	 8.20159912109375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:35:50.916552 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803806 	 1000 	 0.13165616989135742 	 0.17063450813293457 	 2.2172927856445312e-05 	 0.00017333030700683594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:35:52.279793 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", ) 	 25405611 	 1000 	 0.0553741455078125 	 0.04304218292236328 	 1.430511474609375e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:35:53.027852 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, )
W0730 00:35:59.589335 94540 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.025014638900756836 	 0.007666349411010742 	 1.811981201171875e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:00.623776 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0730 00:36:07.207348 94852 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.03190112113952637 	 0.02844524383544922 	 2.002716064453125e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:08.083475 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0730 00:36:14.633512 95167 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.02460503578186035 	 0.007624387741088867 	 1.6927719116210938e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:15.581678 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, )
W0730 00:36:22.869762 95407 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.04057741165161133 	 0.011654853820800781 	 3.838539123535156e-05 	 7.748603820800781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:25.558445 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0730 00:36:32.774816 95735 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.03176569938659668 	 0.014443397521972656 	 1.7881393432617188e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:34.972295 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0730 00:36:41.478358 96129 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.024686098098754883 	 0.007707118988037109 	 3.695487976074219e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:42.678530 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, )
W0730 00:36:49.875571 96632 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.04071617126464844 	 0.007662534713745117 	 2.1457672119140625e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:51.847581 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, )
W0730 00:36:58.461985 96952 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.03216862678527832 	 0.009011507034301758 	 3.814697265625e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:36:59.384855 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, )
W0730 00:37:06.123382 97192 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.02497243881225586 	 0.007703065872192383 	 1.5020370483398438e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:37:06.785021 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, )
W0730 00:37:13.378924 97439 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, ) 	 254016640 	 1000 	 0.024973154067993164 	 0.007776021957397461 	 2.5987625122070312e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:37:14.290075 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, )
W0730 00:37:21.385731 97753 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, ) 	 254016640 	 1000 	 0.03250861167907715 	 0.014597892761230469 	 4.267692565917969e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:37:23.306794 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, )
W0730 00:37:30.147876 98085 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, ) 	 254016640 	 1000 	 0.02516651153564453 	 0.01581740379333496 	 2.002716064453125e-05 	 6.818771362304688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:37:33.820274 test begin: paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], ) 	 786432000 	 1000 	 0.0034418106079101562 	 0.00453495979309082 	 1.4066696166992188e-05 	 1.9550323486328125e-05 	 0.03969144821166992 	 0.0698697566986084 	 4.029273986816406e-05 	 4.291534423828125e-05 	 
2025-07-30 00:37:58.501083 test begin: paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.008989095687866211 	 0.008228778839111328 	 4.9591064453125e-05 	 2.5033950805664062e-05 	 0.05125904083251953 	 4.548223257064819 	 5.173683166503906e-05 	 2.326793909072876 	 
2025-07-30 00:38:45.258882 test begin: paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.003398895263671875 	 0.004522800445556641 	 7.3909759521484375e-06 	 2.3126602172851562e-05 	 0.03977513313293457 	 0.06990361213684082 	 5.412101745605469e-05 	 6.604194641113281e-05 	 
2025-07-30 00:39:00.932775 test begin: paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.0034284591674804688 	 0.004477262496948242 	 7.152557373046875e-06 	 2.002716064453125e-05 	 0.03963470458984375 	 0.07750892639160156 	 3.1948089599609375e-05 	 5.269050598144531e-05 	 
2025-07-30 00:39:16.922557 test begin: paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.0034568309783935547 	 0.0046274662017822266 	 1.2159347534179688e-05 	 2.5987625122070312e-05 	 0.0433652400970459 	 4.5502684116363525 	 6.508827209472656e-05 	 2.3235015869140625 	 
2025-07-30 00:39:53.104641 test begin: paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], ) 	 513802240 	 1000 	 0.0033960342407226562 	 0.004574775695800781 	 9.059906005859375e-06 	 2.4080276489257812e-05 	 0.047333717346191406 	 0.05430150032043457 	 3.933906555175781e-05 	 9.72747802734375e-05 	 
2025-07-30 00:40:12.898194 test begin: paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.003389120101928711 	 0.0045659542083740234 	 9.5367431640625e-06 	 2.0742416381835938e-05 	 0.043262481689453125 	 4.498843193054199 	 4.458427429199219e-05 	 2.2981417179107666 	 
2025-07-30 00:40:49.234277 test begin: paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0038421154022216797 	 0.004464387893676758 	 2.5033950805664062e-05 	 1.9788742065429688e-05 	 0.04316115379333496 	 4.50030517578125 	 4.673004150390625e-05 	 2.2995007038116455 	 
2025-07-30 00:41:25.840709 test begin: paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.003411531448364258 	 0.004559993743896484 	 9.5367431640625e-06 	 4.673004150390625e-05 	 0.04501748085021973 	 4.499200344085693 	 3.7670135498046875e-05 	 2.298635721206665 	 
2025-07-30 00:42:02.390461 test begin: paddle.trunc(Tensor([200, 2540161],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.008142948150634766 	 2.9316539764404297 	 1.33514404296875e-05 	 2.9200973510742188 	 0.049839019775390625 	 1.311279296875 	 2.6464462280273438e-05 	 1.2205731868743896 	 
2025-07-30 00:42:25.148616 test begin: paddle.trunc(Tensor([25401610, 20],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.008122444152832031 	 2.9370620250701904 	 1.430511474609375e-05 	 2.917654037475586 	 0.049573659896850586 	 1.3113059997558594 	 4.3392181396484375e-05 	 1.2295904159545898 	 
2025-07-30 00:42:47.805090 test begin: paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.008255243301391602 	 2.9195663928985596 	 1.7404556274414062e-05 	 2.9076273441314697 	 0.05286216735839844 	 1.3117499351501465 	 0.00010013580322265625 	 1.2278094291687012 	 
2025-07-30 00:43:06.496045 test begin: paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), ) 	 254028960 	 1000 	 0.008403778076171875 	 2.914613723754883 	 1.2159347534179688e-05 	 2.9027974605560303 	 0.04900479316711426 	 1.3149962425231934 	 4.124641418457031e-05 	 1.2298343181610107 	 
2025-07-30 00:43:24.898613 test begin: paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.00833272933959961 	 3.593485116958618 	 1.1920928955078125e-05 	 2.8989741802215576 	 0.07192230224609375 	 1.3157427310943604 	 4.935264587402344e-05 	 1.2192003726959229 	 
2025-07-30 00:43:41.854648 test begin: paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.008334636688232422 	 2.9172415733337402 	 1.1205673217773438e-05 	 2.905369281768799 	 0.05563163757324219 	 1.311837911605835 	 3.933906555175781e-05 	 1.2275094985961914 	 
2025-07-30 00:43:58.600889 test begin: paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), ) 	 254022480 	 1000 	 0.008376598358154297 	 2.915792465209961 	 1.0967254638671875e-05 	 2.90382981300354 	 0.04978680610656738 	 1.3171617984771729 	 3.600120544433594e-05 	 1.2332639694213867 	 
2025-07-30 00:44:16.625240 test begin: paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), ) 	 254022480 	 1000 	 0.01547384262084961 	 2.9184677600860596 	 1.430511474609375e-05 	 2.900421142578125 	 0.05840015411376953 	 1.3118577003479004 	 4.0531158447265625e-05 	 1.2182798385620117 	 
2025-07-30 00:44:32.422054 test begin: paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.015563488006591797 	 2.9152228832244873 	 2.193450927734375e-05 	 2.9033241271972656 	 0.06454062461853027 	 1.3151617050170898 	 5.3882598876953125e-05 	 1.224052906036377 	 
2025-07-30 00:44:51.598244 test begin: paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), ) 	 254018160 	 1000 	 0.008280754089355469 	 2.928680896759033 	 1.3113021850585938e-05 	 2.905885696411133 	 0.04951620101928711 	 1.3134374618530273 	 5.078315734863281e-05 	 1.2366375923156738 	 
2025-07-30 00:45:07.251138 test begin: paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), ) 	 254018160 	 1000 	 0.008456945419311523 	 2.915672779083252 	 1.3589859008789062e-05 	 2.9038848876953125 	 0.04963517189025879 	 1.3134231567382812 	 4.57763671875e-05 	 1.2451918125152588 	 
2025-07-30 00:45:23.803576 test begin: paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, ) 	 508032480 	 1000 	 0.03362894058227539 	 0.0253751277923584 	 2.3126602172851562e-05 	 6.318092346191406e-05 	 3.6324455738067627 	 3.0434165000915527 	 3.5426647663116455 	 2.7985403537750244 	 
2025-07-30 00:45:52.045184 test begin: paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, ) 	 508032480 	 1000 	 0.02800154685974121 	 0.022819995880126953 	 1.71661376953125e-05 	 3.552436828613281e-05 	 3.633474826812744 	 3.0438895225524902 	 3.546712636947632 	 2.830634117126465 	 
2025-07-30 00:46:14.915977 test begin: paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, ) 	 508033280 	 1000 	 0.02808213233947754 	 0.025735139846801758 	 1.9073486328125e-05 	 5.650520324707031e-05 	 3.5217490196228027 	 2.983386278152466 	 3.4335777759552 	 2.7357547283172607 	 
2025-07-30 00:46:39.756185 test begin: paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, ) 	 508032150 	 1000 	 0.037679433822631836 	 0.03227972984313965 	 2.5510787963867188e-05 	 3.3855438232421875e-05 	 3.6753766536712646 	 3.0662593841552734 	 3.5746243000030518 	 2.8045897483825684 	 
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 90, in <module>
    import paddle.distributed.fleet
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/__init__.py", line 21, in <module>
    from paddle.distributed.fleet.base.topology import ParallelMode
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/fleet/__init__.py", line 17, in <module>
    from .base.distributed_strategy import DistributedStrategy
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/fleet/base/distributed_strategy.py", line 28, in <module>
    from paddle.distributed.fleet.utils.log_util import logger
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/fleet/utils/__init__.py", line 20, in <module>
    from . import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/fleet/utils/hybrid_parallel_util.py", line 20, in <module>
    from paddle.distributed.parallel import (
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/parallel.py", line 33, in <module>
    from paddle.distributed.collective import (
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/collective.py", line 32, in <module>
    from .fleet.layers.mpu.mp_ops import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/fleet/layers/mpu/__init__.py", line 15, in <module>
    from .mp_layers import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/distributed/fleet/layers/mpu/mp_layers.py", line 21, in <module>
    from paddle.nn import functional as F
  File "/usr/local/lib/python3.10/dist-packages/paddle/nn/__init__.py", line 15, in <module>
    from . import functional, initializer, quant, utils  # noqa: F401
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1012, in get_code
  File "<frozen importlib._bootstrap_external>", line 672, in _compile_bytecode
KeyboardInterrupt
2025-07-30 00:15:15.883372 test begin: paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, )
W0730 00:15:16.632453 69561 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, ) 	 25486272 	 1000 	 0.004123687744140625 	 0.005202531814575195 	 1.0728836059570312e-05 	 2.9802322387695312e-05 	 0.15052390098571777 	 0.1403036117553711 	 0.07673144340515137 	 0.06610727310180664 	 
2025-07-30 00:15:17.446371 test begin: paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, ) 	 25401603 	 1000 	 0.00408482551574707 	 0.005294084548950195 	 3.337860107421875e-05 	 6.175041198730469e-05 	 0.1466066837310791 	 0.13816094398498535 	 0.0748600959777832 	 0.06870818138122559 	 
2025-07-30 00:15:18.281704 test begin: paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), ) 	 8664 	 1000 	 0.011222362518310547 	 157.84975743293762 	 1.1444091796875e-05 	 0.000438690185546875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:17:56.398437 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), ) 	 462864 	 1000 	 0.010852336883544922 	 81.58641910552979 	 1.2159347534179688e-05 	 0.0002808570861816406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:19:18.157554 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), ) 	 50920464 	 1000 	 0.6702358722686768 	 79.64452743530273 	 3.719329833984375e-05 	 0.00022840499877929688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:20:40.353103 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), ) 	 50997264 	 1000 	 0.010646820068359375 	 75.82396149635315 	 1.1682510375976562e-05 	 0.0002079010009765625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:21:57.264670 test begin: paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.010689973831176758 	 75.90469884872437 	 1.1682510375976562e-05 	 0.00024247169494628906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:23:14.307088 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.011004924774169922 	 56.95532298088074 	 1.5020370483398438e-05 	 0.00022125244140625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:24:12.330466 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.013453483581542969 	 75.50904321670532 	 2.4080276489257812e-05 	 0.00022673606872558594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:25:28.981602 test begin: paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.010696172714233398 	 57.031519651412964 	 1.2874603271484375e-05 	 9.608268737792969e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:26:27.260202 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.011122703552246094 	 56.677000284194946 	 1.71661376953125e-05 	 0.0002300739288330078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:27:25.043111 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.010845422744750977 	 57.29641556739807 	 1.1682510375976562e-05 	 0.000225067138671875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:28:23.390462 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), ) 	 50843140 	 1000 	 0.010869264602661133 	 57.91228771209717 	 1.3113021850585938e-05 	 0.0002281665802001953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:29:22.374341 test begin: paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], ) 	 5150 	 1000 	 0.5868949890136719 	 1.1184272766113281 	 0.08561134338378906 	 0.2850949764251709 	 110.80600619316101 	 0.5240726470947266 	 28.264296770095825 	 0.10705780982971191 	 
2025-07-30 00:31:18.379262 test begin: paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], ) 	 5140 	 1000 	 0.5334029197692871 	 1.0126056671142578 	 0.07748007774353027 	 0.2582228183746338 	 78.45757055282593 	 0.47856664657592773 	 20.141013145446777 	 0.0977315902709961 	 
2025-07-30 00:32:40.716076 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], ) 	 5150 	 1000 	 0.3622627258300781 	 0.5280694961547852 	 0.05268669128417969 	 0.13506722450256348 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:33:42.165832 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], ) 	 948 	 1000 	 0.4737122058868408 	 0.706275224685669 	 0.0687711238861084 	 0.18016695976257324 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 00:35:00.650429 test begin: paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.019097328186035156 	 0.018976449966430664 	 2.0742416381835938e-05 	 2.765655517578125e-05 	 0.14774632453918457 	 0.16879892349243164 	 0.09790873527526855 	 0.013309240341186523 	 combined
2025-07-30 00:35:01.551603 test begin: paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.018219470977783203 	 0.031561851501464844 	 1.8358230590820312e-05 	 3.266334533691406e-05 	 0.1505875587463379 	 0.16915535926818848 	 0.10060858726501465 	 0.01917433738708496 	 combined
2025-07-30 00:35:02.504946 test begin: paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.018190622329711914 	 0.01962113380432129 	 1.3828277587890625e-05 	 4.9114227294921875e-05 	 0.1460578441619873 	 0.16640114784240723 	 0.09564971923828125 	 0.018857955932617188 	 combined
2025-07-30 00:35:03.457235 test begin: paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], ) 	 25486272 	 1000 	 0.019669532775878906 	 0.013113975524902344 	 2.47955322265625e-05 	 2.0503997802734375e-05 	 0.14600324630737305 	 0.14972567558288574 	 0.0962367057800293 	 0.030524253845214844 	 combined
2025-07-30 00:35:04.311362 test begin: paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], ) 	 25401603 	 1000 	 0.01925802230834961 	 0.012831926345825195 	 1.621246337890625e-05 	 2.2411346435546875e-05 	 0.1466383934020996 	 0.14304304122924805 	 0.09393048286437988 	 0.036544084548950195 	 combined
2025-07-30 00:35:05.167643 test begin: paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.003962993621826172 	 0.004270315170288086 	 1.33514404296875e-05 	 1.811981201171875e-05 	 0.14647197723388672 	 0.13854622840881348 	 0.07477688789367676 	 0.06764030456542969 	 
2025-07-30 00:35:05.985107 test begin: paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), ) 	 25401744 	 1000 	 0.003939628601074219 	 0.004938602447509766 	 7.62939453125e-06 	 6.580352783203125e-05 	 0.14715194702148438 	 0.138594388961792 	 0.07513284683227539 	 0.06827616691589355 	 
2025-07-30 00:35:06.818963 test begin: paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), ) 	 25443936 	 1000 	 0.003875732421875 	 0.0042493343353271484 	 6.9141387939453125e-06 	 1.6450881958007812e-05 	 0.14649701118469238 	 0.13937020301818848 	 0.07475829124450684 	 0.06967639923095703 	 
2025-07-30 00:35:07.674266 test begin: paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), ) 	 25443936 	 1000 	 0.003980875015258789 	 0.004271030426025391 	 6.4373016357421875e-06 	 2.8133392333984375e-05 	 0.14694547653198242 	 0.13934540748596191 	 0.07498049736022949 	 0.058753252029418945 	 
2025-07-30 00:35:08.524103 test begin: paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), ) 	 25443936 	 1000 	 0.003931522369384766 	 0.004212379455566406 	 7.867813110351562e-06 	 2.5987625122070312e-05 	 0.14675307273864746 	 0.13931584358215332 	 0.07496070861816406 	 0.06989359855651855 	 
2025-07-30 00:35:09.356295 test begin: paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.004143714904785156 	 0.0045506954193115234 	 6.67572021484375e-06 	 2.574920654296875e-05 	 0.15053367614746094 	 0.14220142364501953 	 0.07682609558105469 	 0.06925129890441895 	 
2025-07-30 00:35:10.195867 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), ) 	 25443936 	 1000 	 0.003843069076538086 	 0.004134416580200195 	 7.3909759521484375e-06 	 1.7642974853515625e-05 	 0.14662432670593262 	 0.139312744140625 	 0.07477974891662598 	 0.06926393508911133 	 
2025-07-30 00:35:11.068365 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), ) 	 25443936 	 1000 	 0.003939628601074219 	 0.00780177116394043 	 7.62939453125e-06 	 0.000141143798828125 	 0.14685869216918945 	 0.13933539390563965 	 0.07495617866516113 	 0.06187582015991211 	 
2025-07-30 00:35:11.873669 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.0041484832763671875 	 0.0046732425689697266 	 6.67572021484375e-06 	 1.7642974853515625e-05 	 0.16420722007751465 	 0.15424895286560059 	 0.08388328552246094 	 0.07877779006958008 	 
2025-07-30 00:35:12.907757 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), ) 	 25443936 	 1000 	 0.00417327880859375 	 0.004262208938598633 	 1.4066696166992188e-05 	 1.7881393432617188e-05 	 0.14694786071777344 	 0.1393435001373291 	 0.07496786117553711 	 0.06883621215820312 	 
2025-07-30 00:35:13.745049 test begin: paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, ) 	 25528608 	 1000 	 0.06965994834899902 	 0.0479128360748291 	 1.5974044799804688e-05 	 4.744529724121094e-05 	 0.17388606071472168 	 0.1619572639465332 	 0.022207021713256836 	 0.00011396408081054688 	 
2025-07-30 00:35:14.805770 test begin: paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, ) 	 25528608 	 1000 	 0.06853127479553223 	 0.03659415245056152 	 1.71661376953125e-05 	 6.866455078125e-05 	 0.17409992218017578 	 0.19176101684570312 	 0.022264719009399414 	 9.202957153320312e-05 	 
2025-07-30 00:35:15.814984 test begin: paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), ) 	 25465104 	 1000 	 0.0919959545135498 	 0.06233549118041992 	 1.7881393432617188e-05 	 4.863739013671875e-05 	 0.16974449157714844 	 0.19169211387634277 	 0.021686553955078125 	 0.00011539459228515625 	 
2025-07-30 00:35:16.867090 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08779335021972656 	 15.466399908065796 	 0.07669329643249512 	 0.0002353191375732422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:35:34.364312 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.7634849548339844 	 16.527509212493896 	 0.07274985313415527 	 0.00025391578674316406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:35:53.922423 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09234809875488281 	 20.354469060897827 	 0.07493853569030762 	 0.00022602081298828125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:36:16.001244 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08677887916564941 	 15.453275203704834 	 0.06946253776550293 	 9.72747802734375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:36:33.285801 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.08958101272583008 	 15.649911880493164 	 0.07945585250854492 	 0.00023365020751953125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:36:50.699228 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09304261207580566 	 16.456156015396118 	 0.08086133003234863 	 0.00022363662719726562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:37:08.940574 test begin: paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_mean 	 paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), ) 	 5097435 	 1000 	 0.06838655471801758 	 0.26560354232788086 	 3.910064697265625e-05 	 6.699562072753906e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:37:13.709680 test begin: paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), ) 	 6400 	 1000 	 0.010812520980834961 	 202.9064416885376 	 1.0013580322265625e-05 	 0.00023412704467773438 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:40:37.148202 test begin: paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), ) 	 6400 	 1000 	 0.010793924331665039 	 207.42021322250366 	 1.5497207641601562e-05 	 0.00023651123046875 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:44:04.826783 test begin: paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), ) 	 8960 	 1000 	 0.01082468032836914 	 280.902587890625 	 1.430511474609375e-05 	 0.00023365020751953125 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:48:46.031474 test begin: paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), ) 	 4800 	 1000 	 0.010807514190673828 	 150.30764889717102 	 1.33514404296875e-05 	 0.00023245811462402344 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:51:16.508897 test begin: paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), ) 	 9120 	 1000 	 0.010814189910888672 	 294.44739747047424 	 1.0251998901367188e-05 	 0.0002338886260986328 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:56:11.274411 test begin: paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), ) 	 9120 	 1000 	 0.010946512222290039 	 290.2489695549011 	 1.1444091796875e-05 	 0.00026106834411621094 	 None 	 None 	 None 	 None 	 combined
2025-07-30 01:01:01.860461 test begin: paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), ) 	 4800 	 1000 	 0.013441085815429688 	 152.1267910003662 	 3.266334533691406e-05 	 0.0002372264862060547 	 None 	 None 	 None 	 None 	 combined
2025-07-30 01:03:34.165605 test begin: paddle.nn.functional.gather_tree(Tensor([200, 4, 4],"int64"), Tensor([200, 4, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([200, 4, 4],"int64"), Tensor([200, 4, 4],"int64"), ) 	 6400 	 1000 	 0.01111912727355957 	 205.40696597099304 	 1.7881393432617188e-05 	 0.00025010108947753906 	 None 	 None 	 None 	 None 	 combined
2025-07-30 01:06:59.970045 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, ) 	 25443143 	 1000 	 0.04275655746459961 	 0.054236412048339844 	 2.0503997802734375e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 01:07:00.808875 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, ) 	 25443143 	 1000 	 0.029596805572509766 	 0.023029088973999023 	 1.9788742065429688e-05 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 01:07:01.540405 test begin: paddle.scatter_nd(Tensor([1280, 2],"int64"), Tensor([1280, 9, 10],"float32"), list[3,5,9,10,], )
[Prof] paddle.scatter_nd 	 paddle.scatter_nd(Tensor([1280, 2],"int64"), Tensor([1280, 9, 10],"float32"), list[3,5,9,10,], ) 	 117760 	 1000 	 0.03650093078613281 	 160.57064771652222 	 1.6927719116210938e-05 	 0.00020837783813476562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 01:09:42.426555 test begin: paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 25486272 	 1000 	 0.0063533782958984375 	 0.20792365074157715 	 2.5033950805664062e-05 	 6.914138793945312e-05 	 0.15175366401672363 	 0.24981188774108887 	 0.07749462127685547 	 0.003943681716918945 	 combined
2025-07-30 01:09:44.141362 test begin: paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, ) 	 2540160 	 1000 	 0.06484007835388184 	 0.020241975784301758 	 3.0517578125e-05 	 3.1948089599609375e-05 	 0.16800904273986816 	 0.0862736701965332 	 2.8371810913085938e-05 	 5.3882598876953125e-05 	 combined
2025-07-30 01:09:44.651849 test begin: paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, ) 	 2540160 	 1000 	 0.06819629669189453 	 0.020406484603881836 	 3.409385681152344e-05 	 5.984306335449219e-05 	 0.1371326446533203 	 0.10245609283447266 	 4.124641418457031e-05 	 6.29425048828125e-05 	 combined
2025-07-30 01:09:45.049142 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.06464076042175293 	 0.020685195922851562 	 2.3126602172851562e-05 	 5.030632019042969e-05 	 0.7579588890075684 	 0.1380620002746582 	 4.57763671875e-05 	 0.05369162559509277 	 combined
2025-07-30 01:09:46.560105 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401606 	 1000 	 0.0787363052368164 	 0.03085780143737793 	 2.3365020751953125e-05 	 5.507469177246094e-05 	 0.7662794589996338 	 0.13804054260253906 	 0.0001251697540283203 	 0.05094099044799805 	 combined
2025-07-30 01:09:48.118183 test begin: paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, ) 	 25401604 	 1000 	 0.06672501564025879 	 0.019881248474121094 	 3.528594970703125e-05 	 3.24249267578125e-05 	 0.6030392646789551 	 0.13944363594055176 	 4.1484832763671875e-05 	 0.0439755916595459 	 combined
2025-07-30 01:09:49.543045 test begin: paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, ) 	 508032270 	 1000 	 0.03755784034729004 	 0.03294205665588379 	 2.5510787963867188e-05 	 4.029273986816406e-05 	 3.6848251819610596 	 3.077202320098877 	 3.5778777599334717 	 2.8010213375091553 	 
2025-07-30 01:10:15.812164 test begin: paddle.unbind(Tensor([40, 2116801, 6],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 2116801, 6],"float32"), ) 	 508032240 	 1000 	 0.051534175872802734 	 0.04200172424316406 	 3.743171691894531e-05 	 8.058547973632812e-05 	 3.66907000541687 	 3.05348801612854 	 3.553605556488037 	 2.7040276527404785 	 
2025-07-30 01:10:42.668269 test begin: paddle.unbind(Tensor([40, 5, 2540161],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 5, 2540161],"float32"), ) 	 508032200 	 1000 	 0.04861116409301758 	 0.04163694381713867 	 2.2411346435546875e-05 	 7.009506225585938e-05 	 3.6750690937042236 	 3.053701400756836 	 3.535977363586426 	 2.722334146499634 	 
2025-07-30 01:11:07.951205 test begin: paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032242 	 1000 	 0.12589430809020996 	 0.004969120025634766 	 3.719329833984375e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 01:11:24.690234 test begin: paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032642 	 1000 	 0.1354513168334961 	 0.009466171264648438 	 5.173683166503906e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 01:11:43.850772 test begin: paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032962 	 1000 	 0.10182952880859375 	 0.005052328109741211 	 2.3603439331054688e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 01:12:01.674583 test begin: paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, ) 	 1016064050 	 1000 	 0.01685190200805664 	 0.00431060791015625 	 1.2874603271484375e-05 	 2.002716064453125e-05 	 41.164504289627075 	 41.01220107078552 	 41.11016345024109 	 13.987873792648315 	 
2025-07-30 01:15:15.108876 test begin: paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, )
Warning: The core code of paddle.unsqueeze is too complex.
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, ) 	 262144000 	 1000 	 0.008800745010375977 	 0.003627300262451172 	 1.0728836059570312e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:15:23.941515 test begin: paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, ) 	 508160000 	 1000 	 0.0046694278717041016 	 0.0037059783935546875 	 8.106231689453125e-06 	 2.5033950805664062e-05 	 0.040868520736694336 	 0.05889296531677246 	 5.0067901611328125e-05 	 6.413459777832031e-05 	 
2025-07-30 01:15:41.028080 test begin: paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, ) 	 254033920 	 1000 	 0.004372358322143555 	 0.0036056041717529297 	 7.62939453125e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:15:49.151334 test begin: paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, ) 	 254033920 	 1000 	 0.0043985843658447266 	 0.003632783889770508 	 9.5367431640625e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:15:59.907017 test begin: paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, ) 	 509050880 	 1000 	 0.004589080810546875 	 0.0036444664001464844 	 1.5020370483398438e-05 	 1.9073486328125e-05 	 0.04040122032165527 	 0.05685114860534668 	 4.482269287109375e-05 	 6.699562072753906e-05 	 
2025-07-30 01:16:17.037177 test begin: paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, ) 	 508144000 	 1000 	 0.004615068435668945 	 0.006807804107666016 	 1.0967254638671875e-05 	 2.3126602172851562e-05 	 0.0406031608581543 	 0.06736207008361816 	 4.267692565917969e-05 	 6.794929504394531e-05 	 
2025-07-30 01:16:40.252463 test begin: paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, ) 	 508559360 	 1000 	 0.004565715789794922 	 0.005789756774902344 	 1.1444091796875e-05 	 5.793571472167969e-05 	 0.0404207706451416 	 0.05701160430908203 	 2.2411346435546875e-05 	 6.103515625e-05 	 
2025-07-30 01:16:57.139915 test begin: paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, ) 	 508160000 	 1000 	 0.004634380340576172 	 0.0036525726318359375 	 1.2159347534179688e-05 	 2.0742416381835938e-05 	 0.04057621955871582 	 0.05655860900878906 	 4.696846008300781e-05 	 4.8160552978515625e-05 	 
2025-07-30 01:17:14.004134 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013863801956176758 	 0.0072863101959228516 	 1.2636184692382812e-05 	 1.9550323486328125e-05 	 0.049878835678100586 	 0.06427478790283203 	 5.435943603515625e-05 	 8.130073547363281e-05 	 
2025-07-30 01:17:31.248164 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.019067764282226562 	 0.003929853439331055 	 1.430511474609375e-05 	 1.9788742065429688e-05 	 0.04178452491760254 	 0.056177377700805664 	 2.6226043701171875e-05 	 5.173683166503906e-05 	 
2025-07-30 01:17:52.701035 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.020226001739501953 	 0.004990816116333008 	 3.170967102050781e-05 	 7.367134094238281e-05 	 0.04058361053466797 	 0.06976580619812012 	 3.170967102050781e-05 	 7.367134094238281e-05 	 
2025-07-30 01:18:10.102865 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013972759246826172 	 0.0039484500885009766 	 1.3113021850585938e-05 	 1.8835067749023438e-05 	 0.04014754295349121 	 0.056795358657836914 	 3.218650817871094e-05 	 6.246566772460938e-05 	 
2025-07-30 01:18:30.118283 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013892650604248047 	 0.003753662109375 	 1.6927719116210938e-05 	 2.002716064453125e-05 	 0.040609121322631836 	 0.05502581596374512 	 4.673004150390625e-05 	 5.8650970458984375e-05 	 
2025-07-30 01:18:47.257552 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.014154434204101562 	 0.004023313522338867 	 1.8358230590820312e-05 	 1.8596649169921875e-05 	 0.042182207107543945 	 0.05725741386413574 	 5.269050598144531e-05 	 4.38690185546875e-05 	 
2025-07-30 01:19:04.497257 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.018960952758789062 	 0.003832578659057617 	 1.52587890625e-05 	 2.002716064453125e-05 	 0.04049801826477051 	 0.055367231369018555 	 4.8160552978515625e-05 	 6.031990051269531e-05 	 
2025-07-30 01:19:21.743977 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013878822326660156 	 0.00400090217590332 	 1.3113021850585938e-05 	 1.8835067749023438e-05 	 0.04343819618225098 	 0.05730700492858887 	 4.315376281738281e-05 	 7.915496826171875e-05 	 
2025-07-30 01:19:40.618050 test begin: paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), )
[Prof] paddle.view_as 	 paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), ) 	 101608000 	 1000 	 0.014798402786254883 	 0.003289937973022461 	 1.5735626220703125e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 01:19:43.259080 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], )
W0730 01:19:55.403155 143502 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.03148937225341797 	 0.008947134017944336 	 2.5272369384765625e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:19:57.863847 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], )
W0730 01:20:05.002034 144977 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.029755353927612305 	 0.018352508544921875 	 6.151199340820312e-05 	 3.24249267578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:20:07.086246 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], )
W0730 01:20:14.266286 145891 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.026703596115112305 	 0.00881052017211914 	 3.075599670410156e-05 	 8.130073547363281e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:20:17.151065 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], )
W0730 01:20:27.777937 146628 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.031327009201049805 	 0.008970022201538086 	 1.6689300537109375e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:20:29.548607 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], )
W0730 01:20:37.975828 147830 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.01734447479248047 	 0.0066986083984375 	 1.2874603271484375e-05 	 2.7418136596679688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:20:40.076384 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], )
W0730 01:20:47.393368 148750 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.03330659866333008 	 0.007749795913696289 	 6.985664367675781e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:20:49.458588 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], )
W0730 01:21:00.711762 150077 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.03292703628540039 	 0.010739326477050781 	 4.935264587402344e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:21:04.144390 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], )
W0730 01:21:11.230343 151462 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.017133712768554688 	 0.007610797882080078 	 1.0728836059570312e-05 	 8.296966552734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 01:21:12.332998 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], )
W0730 01:21:20.634670 151934 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.02434372901916504 	 0.007788419723510742 	 2.6941299438476562e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 9, in <module>
    import torch
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 2611, in <module>
    from torch import _meta_registrations
  File "/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py", line 12, in <module>
    from torch._decomp import (
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py", line 276, in <module>
    import torch._decomp.decompositions
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py", line 16, in <module>
    import torch._prims as prims
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 982, in <module>
    bitwise_or = _make_elementwise_binary_prim(
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 508, in _make_elementwise_binary_prim
    return _make_prim(
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 339, in _make_prim
    overload_tags = [
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py", line 340, in <listcomp>
    getattr(aten_packet, overload).tags for overload in aten_packet.overloads()
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 1129, in __getattr__
    OpOverload(self, op_, op_dk_, schema, tags)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 689, in __init__
    super().__init__()
KeyboardInterrupt
