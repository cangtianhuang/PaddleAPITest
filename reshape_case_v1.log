2025-07-29 14:54:41.559859 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), )
W0729 14:54:56.236955  4117 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0729 14:55:06.493513  4117 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 2715238400, memory's size is 1939456000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):2715238400 > memory_size():1939456000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), ) 	 969728000 	 1000 	 0.009872913360595703 	 0.010399103164672852 	 1.1920928955078125e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:15.001271 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), )
W0729 14:55:51.455294  5083 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3557386560, memory's size is 2540990464.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3557386560 > memory_size():2540990464.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), ) 	 1270495200 	 1000 	 0.010077476501464844 	 0.00986480712890625 	 1.6450881958007812e-05 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:56:03.886582 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), )
W0729 14:56:31.049332  5285 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3158835200, memory's size is 1974272000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3158835200 > memory_size():1974272000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), ) 	 987136000 	 1000 	 0.00998377799987793 	 0.009938478469848633 	 9.775161743164062e-06 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:56:42.458421 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), )
W0729 14:57:20.328047  5905 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064532480, memory's size is 2540332800.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064532480 > memory_size():2540332800.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), ) 	 1270166400 	 1000 	 0.005331754684448242 	 0.0053975582122802734 	 8.344650268554688e-06 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:57:32.911468 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), )
W0729 14:57:57.222442  6127 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), ) 	 1045504000 	 1000 	 0.005221366882324219 	 0.009863138198852539 	 9.059906005859375e-06 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:58:04.477920 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), )
W0729 14:58:31.014371  6242 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), ) 	 1270124000 	 1000 	 0.005268573760986328 	 0.005405902862548828 	 9.5367431640625e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:58:39.802829 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), )
W0729 14:59:14.700079  6378 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064460800, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064460800 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), ) 	 1270144000 	 1000 	 0.0052950382232666016 	 0.005441427230834961 	 9.059906005859375e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:59:27.062777 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), )
W0729 15:00:02.963784  6933 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3556403200, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3556403200 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), ) 	 1270144000 	 1000 	 0.005252838134765625 	 0.0053768157958984375 	 8.58306884765625e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:14.460644 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), )
W0729 15:00:42.029415  7206 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), ) 	 1270144000 	 1000 	 0.01035618782043457 	 0.005406379699707031 	 2.7894973754882812e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:49.774807 test begin: paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), ) 	 508352000 	 1000 	 0.004746437072753906 	 0.004868984222412109 	 6.198883056640625e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:58.268254 test begin: paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), ) 	 508352000 	 1000 	 0.004888772964477539 	 0.0050237178802490234 	 6.198883056640625e-06 	 4.100799560546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:06.470734 test begin: paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), ) 	 509000000 	 1000 	 0.004763603210449219 	 0.004809379577636719 	 6.4373016357421875e-06 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:14.685090 test begin: paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), ) 	 518190230 	 1000 	 0.004767417907714844 	 0.004785776138305664 	 5.9604644775390625e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:23.150582 test begin: paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), ) 	 508953600 	 1000 	 0.004817962646484375 	 0.004812717437744141 	 6.198883056640625e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:31.420058 test begin: paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), ) 	 508088500 	 1000 	 0.004911661148071289 	 0.004798173904418945 	 6.67572021484375e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:39.629655 test begin: paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), ) 	 508088500 	 1000 	 0.0048367977142333984 	 0.004826784133911133 	 6.67572021484375e-06 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:47.747521 test begin: paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), ) 	 508033000 	 1000 	 0.004736423492431641 	 0.004826545715332031 	 6.198883056640625e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:55.884617 test begin: paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), ) 	 508047360 	 1000 	 0.4640512466430664 	 0.5068469047546387 	 0.23713207244873047 	 0.2590053081512451 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:05.311274 test begin: paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), ) 	 508047360 	 1000 	 0.4639906883239746 	 0.5067286491394043 	 0.2370903491973877 	 0.2588961124420166 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:13.298986 test begin: paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.49892091751098633 	 0.5443871021270752 	 0.2549247741699219 	 0.27817273139953613 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:22.061457 test begin: paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.498931884765625 	 0.5449001789093018 	 0.2549312114715576 	 0.2784290313720703 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:30.855675 test begin: paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), ) 	 508800000 	 1000 	 0.46698546409606934 	 0.5092823505401611 	 0.23862600326538086 	 0.26024842262268066 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:39.410217 test begin: paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), ) 	 508032200 	 1000 	 0.46845221519470215 	 0.5075445175170898 	 0.23976635932922363 	 0.259357213973999 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:47.524841 test begin: paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), ) 	 512000000 	 1000 	 0.46822047233581543 	 0.5181436538696289 	 0.239274263381958 	 0.2647528648376465 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:55.598682 test begin: paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), ) 	 508160000 	 1000 	 0.4661085605621338 	 0.5070483684539795 	 0.23818492889404297 	 0.25910019874572754 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:03.676872 test begin: paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), ) 	 512000000 	 1000 	 0.4682345390319824 	 0.5182301998138428 	 0.23926067352294922 	 0.26477837562561035 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:12.197763 test begin: paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], ) 	 508354560 	 1000 	 0.4970054626464844 	 0.5514872074127197 	 0.2539339065551758 	 0.5361931324005127 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:20.446870 test begin: paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], ) 	 508178560 	 1000 	 0.5064659118652344 	 0.5686497688293457 	 0.25879526138305664 	 0.5540969371795654 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:28.542315 test begin: paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6390323638916016 	 0.5275752544403076 	 0.32652854919433594 	 0.5131206512451172 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:38.419214 test begin: paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5422182083129883 	 0.5249364376068115 	 0.27706313133239746 	 0.5104544162750244 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:46.423405 test begin: paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5422317981719971 	 0.5249433517456055 	 0.2770674228668213 	 0.5103704929351807 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:54.610351 test begin: paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6389901638031006 	 0.5274276733398438 	 0.326509952545166 	 0.5131475925445557 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:02.687523 test begin: paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], ) 	 554880000 	 1000 	 0.5380434989929199 	 0.7132260799407959 	 0.5260818004608154 	 0.6966652870178223 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:11.833408 test begin: paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], ) 	 508270080 	 1000 	 0.49486851692199707 	 0.6542038917541504 	 0.4829888343811035 	 0.6397876739501953 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:19.981939 test begin: paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6210105419158936 	 0.5353813171386719 	 0.31731581687927246 	 0.5209319591522217 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:28.303582 test begin: paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6210944652557373 	 0.5355391502380371 	 0.31731748580932617 	 0.5208826065063477 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:37.918716 test begin: paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], ) 	 552960000 	 1000 	 0.5367646217346191 	 0.5987703800201416 	 0.2742741107940674 	 0.5843915939331055 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:46.623059 test begin: paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], ) 	 609408000 	 1000 	 0.6039741039276123 	 0.6796393394470215 	 0.30861926078796387 	 0.6652359962463379 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:56.647745 test begin: paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", ) 	 508559360 	 1000 	 0.0042994022369384766 	 0.0023190975189208984 	 3.24249267578125e-05 	 1.8835067749023438e-05 	 0.031113862991333008 	 0.0660696029663086 	 1.8835067749023438e-05 	 6.961822509765625e-05 	 
2025-07-29 15:05:13.379013 test begin: paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", ) 	 508559360 	 1000 	 0.003208637237548828 	 0.0022590160369873047 	 7.3909759521484375e-06 	 1.811981201171875e-05 	 0.02947258949279785 	 0.044191837310791016 	 2.9325485229492188e-05 	 6.103515625e-05 	 
2025-07-29 15:05:30.274665 test begin: paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", ) 	 671088640 	 1000 	 0.003331422805786133 	 0.002331972122192383 	 6.9141387939453125e-06 	 1.8835067749023438e-05 	 0.029680728912353516 	 0.044069766998291016 	 2.0503997802734375e-05 	 4.7206878662109375e-05 	 
2025-07-29 15:05:52.621230 test begin: paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), ) 	 1016565760 	 1000 	 0.0007922649383544922 	 0.0029859542846679688 	 1.1682510375976562e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:06:27.023540 test begin: paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), ) 	 1016565760 	 1000 	 0.0007750988006591797 	 0.0030188560485839844 	 7.152557373046875e-06 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:07:00.633956 test begin: paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007805824279785156 	 0.0030214786529541016 	 6.4373016357421875e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:07:34.169063 test begin: paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007736682891845703 	 0.003001689910888672 	 1.1444091796875e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:08:07.475050 test begin: paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), ) 	 1016135680 	 1000 	 0.0011756420135498047 	 0.005047798156738281 	 9.775161743164062e-06 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn2025-07-29 15:11:06.481992 test begin: paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), )
W0729 15:11:22.963172 11857 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), ) 	 1016821760 	 1000 	 0.0006802082061767578 	 0.001730203628540039 	 1.049041748046875e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:11:24.232198 test begin: paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0019593238830566406 	 0.0016307830810546875 	 4.601478576660156e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:11:41.260949 test begin: paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), ) 	 1016135680 	 1000 	 0.0006427764892578125 	 0.0015368461608886719 	 9.059906005859375e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:11:58.364198 test begin: paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), ) 	 1016135680 	 1000 	 0.0006635189056396484 	 0.0015022754669189453 	 9.059906005859375e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:16.292763 test begin: paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), ) 	 1016821760 	 1000 	 0.0006473064422607422 	 0.0015211105346679688 	 9.298324584960938e-06 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:33.544816 test begin: paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), ) 	 1016243200 	 1000 	 0.0007226467132568359 	 0.0016429424285888672 	 1.0013580322265625e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:50.835704 test begin: paddle.Tensor.equal_all(Tensor([2540160101],"int64"), Tensor([8],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([2540160101],"int64"), Tensor([8],"int64"), ) 	 2540160109 	 1000 	 0.017085790634155273 	 0.0026788711547851562 	 1.3113021850585938e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:13:32.399142 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), ) 	 25402402 	 1000 	 0.023386478424072266 	 0.004759073257446289 	 1.52587890625e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 2025-07-29 15:14:13.961008 test begin: paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), )
W0729 15:14:57.578438 12925 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), ) 	 2543338404 	 1000 	 0.0172882080078125 	 0.0030117034912109375 	 4.00543212890625e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:15:05.552260 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), ) 	 2543338404 	 1000 	 0.016900062561035156 	 0.0027213096618652344 	 1.430511474609375e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:15:47.163952 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 25404006 	 1000 	 0.01696944236755371 	 0.002702951431274414 	 1.239776611328125e-05 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:15:47.768788 test begin: paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), ) 	 25402402 	 1000 	 0.017251253128051758 	 0.002719879150390625 	 1.4781951904296875e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:15:48.236904 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), ) 	 25404006 	 1000 	 0.017470121383666992 	 0.004969358444213867 	 1.4781951904296875e-05 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:15:48.703037 test begin: paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), ) 	 2540160327 	 1000 	 0.01710677146911621 	 0.002711772918701172 	 1.3589859008789062e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:16:29.541130 test begin: paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), ) 	 2540160109 	 1000 	 0.01712322235107422 	 0.0026803016662597656 	 4.673004150390625e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:17:10.164393 test begin: paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.024864912033081055 	 0.010610818862915039 	 5.316734313964844e-05 	 3.170967102050781e-05 	 0.03279829025268555 	 0.0560147762298584 	 2.6702880859375e-05 	 6.985664367675781e-05 	 combined
2025-07-29 15:17:27.442727 test begin: paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.023380756378173828 	 0.010472774505615234 	 2.6464462280273438e-05 	 3.0040740966796875e-05 	 0.03308439254760742 	 0.04387474060058594 	 5.173683166503906e-05 	 4.744529724121094e-05 	 combined
2025-07-29 15:17:44.133488 test begin: paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 1684480000 	 1000 	 0.006029367446899414 	 0.0047338008880615234 	 1.1205673217773438e-05 	 2.2411346435546875e-05 	 0.0431520938873291 	 0.05394244194030762 	 4.458427429199219e-05 	 8.153915405273438e-05 	 
2025-07-29 15:18:39.940828 test begin: paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, ) 	 509788160 	 1000 	 0.006235837936401367 	 0.004584312438964844 	 2.6702880859375e-05 	 2.09808349609375e-05 	 0.04302859306335449 	 0.053078651428222656 	 7.62939453125e-05 	 5.245208740234375e-05 	 
2025-07-29 15:18:57.115151 test begin: paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, ) 	 1019576320 	 1000 	 0.005455493927001953 	 0.004582881927490234 	 8.821487426757812e-06 	 2.0265579223632812e-05 	 0.04300880432128906 	 0.05488276481628418 	 4.1484832763671875e-05 	 7.653236389160156e-05 	 
2025-07-29 15:19:40.924998 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.005529165267944336 	 0.004578113555908203 	 3.409385681152344e-05 	 2.0265579223632812e-05 	 0.042812347412109375 	 0.05821394920349121 	 3.528594970703125e-05 	 6.771087646484375e-05 	 
2025-07-29 15:19:57.975779 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.005472421646118164 	 0.004543781280517578 	 1.3113021850585938e-05 	 1.8835067749023438e-05 	 0.04269289970397949 	 0.0623011589050293 	 4.863739013671875e-05 	 7.390975952148438e-05 	 
2025-07-29 15:20:37.144732 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, ) 	 513802240 	 1000 	 0.005644559860229492 	 0.004614353179931641 	 3.743171691894531e-05 	 2.002716064453125e-05 	 0.04276156425476074 	 0.06053471565246582 	 3.457069396972656e-05 	 5.8650970458984375e-05 	 
2025-07-29 15:20:54.033471 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, ) 	 1027604480 	 1000 	 0.005461215972900391 	 0.004617214202880859 	 4.315376281738281e-05 	 2.193450927734375e-05 	 0.04302525520324707 	 0.06181073188781738 	 3.647804260253906e-05 	 7.772445678710938e-05 	 
2025-07-29 15:21:34.029624 test begin: paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.005517482757568359 	 0.0045092105865478516 	 2.574920654296875e-05 	 2.5272369384765625e-05 	 0.04273223876953125 	 0.05466628074645996 	 5.340576171875e-05 	 7.128715515136719e-05 	 
2025-07-29 15:21:51.083175 test begin: paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 526400000 	 1000 	 0.007357120513916016 	 0.007594585418701172 	 3.2901763916015625e-05 	 7.700920104980469e-05 	 0.04398512840270996 	 0.05330967903137207 	 3.9577484130859375e-05 	 6.461143493652344e-05 	 
2025-07-29 15:22:08.573318 test begin: paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 539033600 	 1000 	 0.005923748016357422 	 0.004663944244384766 	 9.059906005859375e-06 	 1.9550323486328125e-05 	 0.04274773597717285 	 0.05464625358581543 	 2.7894973754882812e-05 	 7.152557373046875e-05 	 
2025-07-29 15:22:26.132805 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, ) 	 519680000 	 1000 	 0.005857944488525391 	 0.0047223567962646484 	 8.106231689453125e-06 	 2.1219253540039062e-05 	 0.04648399353027344 	 0.05577588081359863 	 7.367134094238281e-05 	 7.843971252441406e-05 	 
2025-07-29 15:22:43.875704 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, ) 	 529408000 	 1000 	 0.0058879852294921875 	 0.004651546478271484 	 8.58306884765625e-06 	 2.09808349609375e-05 	 0.042694807052612305 	 0.0535740852355957 	 3.4332275390625e-05 	 7.486343383789062e-05 	 
2025-07-29 15:23:01.383261 test begin: paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.0055353641510009766 	 0.004580497741699219 	 1.1682510375976562e-05 	 2.5272369384765625e-05 	 0.042833805084228516 	 0.07106876373291016 	 3.9577484130859375e-05 	 0.00010538101196289062 	 
2025-07-29 15:23:40.480806 test begin: paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, ) 	 508032080 	 1000 	 0.010336875915527344 	 1.3449230194091797 	 1.6450881958007812e-05 	 0.00010323524475097656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:23:51.700167 test begin: paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, ) 	 508032400 	 1000 	 0.01009058952331543 	 13.562718152999878 	 1.5497207641601562e-05 	 0.00023031234741210938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:24:15.211292 test begin: paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, ) 	 508036000 	 1000 	 0.17167425155639648 	 145.07793521881104 	 0.1615142822265625 	 0.0004246234893798828 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:18:21.026198 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), )
W0729 17:18:22.333709 23143 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), ) 	 50816225 	 1000 	 0.016667842864990234 	 0.014567375183105469 	 3.218650817871094e-05 	 6.604194641113281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:18:23.301256 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50821425 	 1000 	 0.009595870971679688 	 0.013372659683227539 	 2.3365020751953125e-05 	 3.719329833984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:54:42.563765 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), )
W0729 14:54:43.519086  4140 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), ) 	 50812325 	 1000 	 0.0126953125 	 0.014836788177490234 	 1.33514404296875e-05 	 6.890296936035156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:54:44.406260 test begin: paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50824957 	 1000 	 3.1270484924316406 	 2.743812322616577 	 3.1172921657562256 	 2.725815773010254 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:54:57.591681 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), ) 	 2552921100 	 1000 	 0.0036232471466064453 	 0.0016443729400634766 	 7.3909759521484375e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:54.831522 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), ) 	 2552884920 	 1000 	 0.004117488861083984 	 0.0016260147094726562 	 3.314018249511719e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:56:48.115146 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), ) 	 2552884920 	 1000 	 0.004490852355957031 	 0.0016522407531738281 	 1.1920928955078125e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:57:53.289750 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), ) 	 2552921100 	 1000 	 0.0035851001739501953 	 0.0015742778778076172 	 1.049041748046875e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:58:46.144869 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), ) 	 2553504000 	 1000 	 0.004469633102416992 	 0.001634359359741211 	 1.33514404296875e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:59:39.559033 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), ) 	 2553504000 	 1000 	 0.003675222396850586 	 0.0015997886657714844 	 1.049041748046875e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:46.180138 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), ) 	 2540412000 	 1000 	 0.0036618709564208984 	 0.0016260147094726562 	 1.0251998901367188e-05 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:39.705891 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), ) 	 2540412000 	 1000 	 0.0036013126373291016 	 0.001611471176147461 	 8.58306884765625e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:33.184794 test begin: paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), ) 	 2548657300 	 1000 	 0.003620147705078125 	 0.0016243457794189453 	 9.775161743164062e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:26.625441 test begin: paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), ) 	 2548639240 	 1000 	 0.003639698028564453 	 0.002092599868774414 	 7.62939453125e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:21.514746 test begin: paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), ) 	 2540404000 	 1000 	 0.0036728382110595703 	 0.0015990734100341797 	 9.5367431640625e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:05:15.000392 test begin: paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, ) 	 2552861001 	 1000 	 0.020925283432006836 	 0.028216123580932617 	 1.6689300537109375e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:06:09.291818 test begin: paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, ) 	 2552861001 	 1000 	 0.02489638328552246 	 0.040413618087768555 	 1.71661376953125e-05 	 7.295608520507812e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:06:50.851227 test begin: paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, ) 	 2540160101 	 1000 	 0.019858598709106445 	 0.03047633171081543 	 1.2636184692382812e-05 	 5.7220458984375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:07:32.303731 test begin: paddle.Tensor.logical_not(Tensor([508032010],"bool"), )
[Prof] paddle.Tensor.logical_not 	 paddle.Tensor.logical_not(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.7899513244628906 	 0.7470200061798096 	 0.7812285423278809 	 0.7347347736358643 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:41.188899 test begin: paddle.Tensor.lu(Tensor([169301, 3],"float32"), )
W0729 15:07:51.636399 10259 backward.cc:466] While running Node (LuGradNode) raises a std::exception: paddle::memory::allocation::BadAlloc
2025-07-29 15:07:51.637092 test begin: paddle.Tensor.lu(Tensor([301, 1193],"float32"), )
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:924: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  LU, pivots, infos = torch._lu_with_info(
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 1193],"float32"), ) 	 359093 	 1000 	 1.3635475635528564 	 3.9059743881225586 	 6.461143493652344e-05 	 0.00011014938354492188 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:07:57.647160 test begin: paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), ) 	 381066 	 1000 	 7.793359041213989 	 0.11996722221374512 	 0.00010991096496582031 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:08:08.619015 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.007776975631713867 	 0.004988670349121094 	 1.3828277587890625e-05 	 2.2411346435546875e-05 	 0.03992938995361328 	 0.07012224197387695 	 3.504753112792969e-05 	 7.009506225585938e-05 	 
2025-07-29 15:08:21.947162 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.007925033569335938 	 0.005941629409790039 	 1.1444091796875e-05 	 2.4557113647460938e-05 	 0.042839765548706055 	 0.05361437797546387 	 5.888938903808594e-05 	 7.510185241699219e-05 	 
2025-07-29 15:08:34.077377 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, ) 	 254016240 	 1000 	 0.007066249847412109 	 0.0048406124114990234 	 1.1205673217773438e-05 	 2.0503997802734375e-05 	 0.03995919227600098 	 0.05255460739135742 	 2.8133392333984375e-05 	 5.841255187988281e-05 	 
2025-07-29 15:08:44.718680 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.007340669631958008 	 0.00492095947265625 	 2.09808349609375e-05 	 2.0742416381835938e-05 	 0.04104208946228027 	 0.05545926094055176 	 4.5299530029296875e-05 	 8.726119995117188e-05 	 
2025-07-29 15:08:55.382934 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007626533508300781 	 0.0058519840240478516 	 1.1920928955078125e-05 	 2.0742416381835938e-05 	 0.039891719818115234 	 0.05398988723754883 	 2.5987625122070312e-05 	 5.626678466796875e-05 	 
2025-07-29 15:09:06.190014 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.007199287414550781 	 0.004919528961181641 	 9.298324584960938e-06 	 2.09808349609375e-05 	 0.04035639762878418 	 0.05297207832336426 	 3.62396240234375e-05 	 5.555152893066406e-05 	 
2025-07-29 15:09:16.708457 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.007745027542114258 	 0.0059413909912109375 	 7.867813110351562e-06 	 2.6702880859375e-05 	 0.03988242149353027 	 0.052884817123413086 	 3.838539123535156e-05 	 5.7220458984375e-05 	 
2025-07-29 15:09:27.083422 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, ) 	 254016400 	 1000 	 0.006995201110839844 	 0.004950523376464844 	 9.5367431640625e-06 	 6.842613220214844e-05 	 0.0397951602935791 	 0.06962084770202637 	 3.5762786865234375e-05 	 8.440017700195312e-05 	 
2025-07-29 15:09:40.101616 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.007292747497558594 	 0.004864692687988281 	 1.7404556274414062e-05 	 2.1219253540039062e-05 	 0.03960609436035156 	 0.06016945838928223 	 4.1484832763671875e-05 	 6.747245788574219e-05 	 
2025-07-29 15:09:50.672841 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.007965326309204102 	 0.0059375762939453125 	 3.0994415283203125e-05 	 4.3392181396484375e-05 	 0.0404360294342041 	 0.05409860610961914 	 3.0517578125e-05 	 5.2928924560546875e-05 	 
2025-07-29 15:10:01.590861 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, ) 	 254016600 	 1000 	 0.00724482536315918 	 0.004915952682495117 	 1.1920928955078125e-05 	 4.744529724121094e-05 	 0.03967761993408203 	 0.05267000198364258 	 1.8596649169921875e-05 	 7.367134094238281e-05 	 
2025-07-29 15:10:12.390838 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.007287025451660156 	 0.004877328872680664 	 1.1205673217773438e-05 	 2.1457672119140625e-05 	 0.040170907974243164 	 0.05357933044433594 	 4.6253204345703125e-05 	 8.511543273925781e-05 	 
2025-07-29 15:10:23.162046 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007701873779296875 	 0.005950450897216797 	 9.775161743164062e-06 	 2.0742416381835938e-05 	 0.03977155685424805 	 0.0536651611328125 	 2.5987625122070312e-05 	 5.1975250244140625e-05 	 
2025-07-29 15:10:34.083022 test begin: paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, ) 	 254016300 	 1000 	 0.007145881652832031 	 0.0047740936279296875 	 1.1682510375976562e-05 	 2.1696090698242188e-05 	 0.039736032485961914 	 0.05251932144165039 	 2.0503997802734375e-05 	 6.270408630371094e-05 	 
2025-07-29 15:10:46.467142 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), ) 	 519045120 	 1000 	 0.05785250663757324 	 0.039513349533081055 	 2.384185791015625e-05 	 6.532669067382812e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:10:58.720801 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), ) 	 519045120 	 1000 	 0.040409088134765625 	 0.029580116271972656 	 1.6450881958007812e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:07.770611 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), ) 	 519045120 	 1000 	 0.0400240421295166 	 0.031241893768310547 	 2.47955322265625e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:16.282255 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), ) 	 519045120 	 1000 	 0.040131330490112305 	 0.029339075088500977 	 2.0742416381835938e-05 	 4.076957702636719e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:24.620320 test begin: paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), ) 	 508055040 	 1000 	 0.040195465087890625 	 0.029345273971557617 	 1.52587890625e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:32.829309 test begin: paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), ) 	 513146880 	 1000 	 0.040369272232055664 	 0.029652833938598633 	 3.24249267578125e-05 	 4.1961669921875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:41.182463 test begin: paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), ) 	 513146880 	 1000 	 0.040189504623413086 	 0.029610395431518555 	 2.5987625122070312e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:49.893654 test begin: paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.044504404067993164 	 0.02947235107421875 	 2.7894973754882812e-05 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:11:59.249835 test begin: paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.04003000259399414 	 0.02953195571899414 	 2.1219253540039062e-05 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:12:07.471661 test begin: paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), ) 	 508101120 	 1000 	 0.039995670318603516 	 0.03028583526611328 	 2.765655517578125e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:12:15.613993 test begin: paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], )
[Prof] paddle.Tensor.reshape 	 paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], ) 	 1016135680 	 1000 	 0.005539655685424805 	 0.004100799560546875 	 1.33514404296875e-05 	 2.2649765014648438e-05 	 0.044985055923461914 	 4.496650218963623 	 2.09808349609375e-05 	 2.297689199447632 	 
2025-07-29 15:12:54.166088 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, ) 	 50805216 	 1000 	 0.09313154220581055 	 0.0038819313049316406 	 3.0994415283203125e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:56.385377 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, ) 	 50805204 	 1000 	 0.03604888916015625 	 0.002300262451171875 	 1.71661376953125e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:57.203642 test begin: paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, ) 	 50807704 	 1000 	 0.04609203338623047 	 0.003734111785888672 	 4.6253204345703125e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:58.057955 test begin: paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.007520198822021484 	 0.013396024703979492 	 9.298324584960938e-06 	 2.6941299438476562e-05 	 4.824779510498047 	 4.625956296920776 	 2.4655845165252686 	 2.3636727333068848 	 combined
2025-07-29 15:13:17.819438 test begin: paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.007343769073486328 	 0.013282537460327148 	 1.811981201171875e-05 	 4.1961669921875e-05 	 1.5081331729888916 	 1.3170733451843262 	 0.7708225250244141 	 0.6728780269622803 	 combined
2025-07-29 15:13:32.120777 test begin: paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 254016320 	 1000 	 0.01453542709350586 	 3.0656445026397705 	 9.775161743164062e-06 	 1.0422041416168213 	 3.026762008666992 	 3.0684523582458496 	 0.5144693851470947 	 0.7824249267578125 	 
2025-07-29 15:13:52.119785 test begin: paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.004546642303466797 	 0.004065513610839844 	 1.0728836059570312e-05 	 2.3365020751953125e-05 	 0.04152989387512207 	 0.04850459098815918 	 2.8371810913085938e-05 	 5.7697296142578125e-05 	 
2025-07-29 15:14:17.975267 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.004676342010498047 	 0.007719993591308594 	 1.0967254638671875e-05 	 2.5272369384765625e-05 	 0.04886341094970703 	 0.07482099533081055 	 7.2479248046875e-05 	 0.00013637542724609375 	 
2025-07-29 15:14:34.682870 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, ) 	 1179648000 	 1000 	 0.004570722579956055 	 0.0041162967681884766 	 1.1682510375976562e-05 	 2.002716064453125e-05 	 0.041487932205200195 	 0.04810047149658203 	 2.5272369384765625e-05 	 3.695487976074219e-05 	 
2025-07-29 15:15:12.989494 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004519462585449219 	 0.004111289978027344 	 6.9141387939453125e-06 	 2.0503997802734375e-05 	 0.041762351989746094 	 0.04807615280151367 	 4.696846008300781e-05 	 4.792213439941406e-05 	 
2025-07-29 15:15:29.788968 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.004536867141723633 	 0.004252195358276367 	 1.3113021850585938e-05 	 2.2411346435546875e-05 	 0.04221773147583008 	 0.05138850212097168 	 2.7179718017578125e-05 	 5.1975250244140625e-05 	 
2025-07-29 15:15:46.643014 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, ) 	 508044800 	 1000 	 0.004584312438964844 	 0.0042569637298583984 	 1.2636184692382812e-05 	 2.09808349609375e-05 	 0.04162478446960449 	 0.07639336585998535 	 3.218650817871094e-05 	 9.417533874511719e-05 	 
2025-07-29 15:16:08.769812 test begin: paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, ) 	 652800000 	 1000 	 0.004528045654296875 	 0.004107475280761719 	 9.775161743164062e-06 	 2.002716064453125e-05 	 0.04393720626831055 	 0.04793596267700195 	 3.0040740966796875e-05 	 4.887580871582031e-05 	 
2025-07-29 15:16:30.474679 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, ) 	 508036000 	 1000 	 0.004527091979980469 	 0.004207611083984375 	 7.152557373046875e-06 	 2.09808349609375e-05 	 0.041670799255371094 	 0.0511012077331543 	 2.7418136596679688e-05 	 3.62396240234375e-05 	 
2025-07-29 15:16:47.253276 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, ) 	 526848000 	 1000 	 0.004496097564697266 	 0.0055387020111083984 	 7.867813110351562e-06 	 2.2411346435546875e-05 	 0.04168200492858887 	 0.051561594009399414 	 2.4080276489257812e-05 	 5.8650970458984375e-05 	 
2025-07-29 15:17:04.607959 test begin: paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, ) 	 602112000 	 1000 	 0.0045125484466552734 	 0.004101991653442383 	 7.62939453125e-06 	 2.0503997802734375e-05 	 0.04125213623046875 	 0.048384904861450195 	 2.5987625122070312e-05 	 5.793571472167969e-05 	 
2025-07-29 15:17:24.300351 test begin: paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.004537820816040039 	 0.00417780876159668 	 8.58306884765625e-06 	 3.814697265625e-05 	 0.0448908805847168 	 0.05098223686218262 	 3.147125244140625e-05 	 5.221366882324219e-05 	 
2025-07-29 15:17:41.054620 test begin: paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, ) 	 508784640 	 1000 	 0.00459742546081543 	 0.004216194152832031 	 1.5497207641601562e-05 	 2.0742416381835938e-05 	 0.041361093521118164 	 0.052040815353393555 	 3.838539123535156e-05 	 5.6743621826171875e-05 	 
2025-07-29 15:17:57.847782 test begin: paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], ) 	 1017036800 	 1000 	 0.0034637451171875 	 0.0048067569732666016 	 8.106231689453125e-06 	 4.1961669921875e-05 	 0.0431976318359375 	 4.500718832015991 	 1.8596649169921875e-05 	 2.2997913360595703 	 
2025-07-29 15:18:35.148192 test begin: paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], ) 	 1017057280 	 1000 	 0.0034334659576416016 	 0.004707813262939453 	 8.58306884765625e-06 	 2.1696090698242188e-05 	 0.04329323768615723 	 4.500779390335083 	 2.1457672119140625e-05 	 2.299947500228882 	 
2025-07-29 15:19:13.244374 test begin: paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], ) 	 1016821760 	 1000 	 0.0073091983795166016 	 0.004632472991943359 	 1.3113021850585938e-05 	 2.4080276489257812e-05 	 0.043233633041381836 	 4.499582529067993 	 2.3603439331054688e-05 	 2.2992241382598877 	 
2025-07-29 15:19:51.303303 test begin: paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], ) 	 1016135680 	 1000 	 0.003473043441772461 	 0.004637241363525391 	 1.1205673217773438e-05 	 2.2649765014648438e-05 	 0.04344534873962402 	 4.496510982513428 	 2.956390380859375e-05 	 2.2976291179656982 	 
2025-07-29 15:20:30.201828 test begin: paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), ) 	 508032280 	 1000 	 0.008571624755859375 	 2.9281773567199707 	 1.2636184692382812e-05 	 2.9172277450561523 	 0.04901385307312012 	 1.311314582824707 	 2.1696090698242188e-05 	 1.2448055744171143 	 
2025-07-29 15:20:53.415892 test begin: paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), ) 	 508032160 	 1000 	 0.009896039962768555 	 2.928344249725342 	 2.7179718017578125e-05 	 2.9069056510925293 	 0.049858808517456055 	 1.3112468719482422 	 3.5762786865234375e-05 	 1.2503325939178467 	 
2025-07-29 15:21:19.803340 test begin: paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), ) 	 508032160 	 1000 	 0.008571863174438477 	 2.941422462463379 	 1.239776611328125e-05 	 2.9149816036224365 	 0.04886126518249512 	 1.3115851879119873 	 2.2411346435546875e-05 	 1.2486681938171387 	 
2025-07-29 15:21:44.743607 test begin: paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), ) 	 508032280 	 1000 	 0.008647441864013672 	 2.9283080101013184 	 1.3113021850585938e-05 	 2.9176113605499268 	 0.04914140701293945 	 1.3114087581634521 	 2.6464462280273438e-05 	 1.2505574226379395 	 
2025-07-29 15:22:08.659613 test begin: paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), ) 	 508032080 	 1000 	 0.008736133575439453 	 2.928367853164673 	 1.811981201171875e-05 	 2.917357921600342 	 0.05109882354736328 	 1.311326265335083 	 3.3855438232421875e-05 	 1.2507643699645996 	 
2025-07-29 15:22:32.301400 test begin: paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), ) 	 508032640 	 1000 	 0.008632421493530273 	 2.928417682647705 	 1.049041748046875e-05 	 2.9174561500549316 	 0.051305294036865234 	 1.311255693435669 	 2.765655517578125e-05 	 1.2501306533813477 	 
2025-07-29 15:22:56.036125 test begin: paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), ) 	 508032080 	 1000 	 0.008616924285888672 	 2.9283883571624756 	 9.298324584960938e-06 	 2.9159631729125977 	 0.04935574531555176 	 1.311251163482666 	 3.5762786865234375e-05 	 1.2470378875732422 	 
2025-07-29 15:23:19.791157 test begin: paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.04090166091918945 	 0.03964710235595703 	 5.340576171875e-05 	 3.075599670410156e-05 	 3.5272090435028076 	 2.9656050205230713 	 3.4265027046203613 	 2.668092966079712 	 
2025-07-29 15:23:45.232052 test begin: paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, ) 	 508408320 	 1000 	 0.04653477668762207 	 0.044152259826660156 	 3.933906555175781e-05 	 7.534027099609375e-05 	 3.522132396697998 	 2.9644618034362793 	 3.404500722885132 	 2.6801767349243164 	 
2025-07-29 15:24:08.729641 test begin: paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, ) 	 510105600 	 1000 	 0.039650917053222656 	 0.037575721740722656 	 1.621246337890625e-05 	 6.604194641113281e-05 	 3.5357720851898193 	 2.9733755588531494 	 3.430817127227783 	 2.663189649581909 	 
2025-07-29 15:24:32.725713 test begin: paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, ) 	 508147200 	 1000 	 0.04008984565734863 	 0.03597211837768555 	 4.863739013671875e-05 	 5.6743621826171875e-05 	 3.5243523120880127 	 2.962632417678833 	 3.4265854358673096 	 2.683666467666626 	 
2025-07-29 15:24:56.449515 test begin: paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, ) 	 513112320 	 1000 	 0.04059958457946777 	 0.03247690200805664 	 3.075599670410156e-05 	 3.2901763916015625e-05 	 3.552675247192383 	 2.9927048683166504 	 3.447822332382202 	 2.695373773574829 	 
2025-07-29 15:25:20.274778 test begin: paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, ) 	 509276160 	 1000 	 0.04117441177368164 	 0.04049396514892578 	 3.0040740966796875e-05 	 4.3392181396484375e-05 	 3.526254653930664 	 2.969318389892578 	 3.4279870986938477 	 2.6616976261138916 	 
2025-07-29 15:25:44.220680 test begin: paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, ) 	 513676800 	 1000 	 0.04008054733276367 	 0.04024982452392578 	 4.887580871582031e-05 	 5.0067901611328125e-05 	 3.563533067703247 	 2.9953196048736572 	 3.4554967880249023 	 2.710911989212036 	 
2025-07-29 15:26:08.256401 test begin: paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.04460549354553223 	 0.03215789794921875 	 4.291534423828125e-05 	 3.409385681152344e-05 	 3.527373790740967 	 2.965327501296997 	 3.4280314445495605 	 2.6653048992156982 	 
2025-07-29 15:26:31.852638 test begin: paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, ) 	 541900800 	 1000 	 0.06352734565734863 	 0.06176042556762695 	 5.3882598876953125e-05 	 4.3392181396484375e-05 	 3.7544972896575928 	 3.148475170135498 	 3.625870943069458 	 2.7070305347442627 	 
2025-07-29 15:26:58.743058 test begin: paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, ) 	 602112000 	 1000 	 0.06234312057495117 	 0.052370548248291016 	 1.5974044799804688e-05 	 3.6716461181640625e-05 	 4.178553581237793 	 3.501316785812378 	 4.049340724945068 	 3.0723087787628174 	 
2025-07-29 15:27:26.439173 test begin: paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, ) 	 530841600 	 1000 	 0.07361626625061035 	 0.06166577339172363 	 2.09808349609375e-05 	 3.719329833984375e-05 	 3.687209129333496 	 3.0834906101226807 	 3.5417463779449463 	 2.58858323097229 	 
2025-07-29 15:27:51.164006 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, )
Warning: The core code of paddle.Tensor.unsqueeze is too complex.
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, ) 	 509009920 	 1000 	 0.00436711311340332 	 0.0038840770721435547 	 1.1444091796875e-05 	 2.1457672119140625e-05 	 0.04162931442260742 	 0.051989078521728516 	 3.7670135498046875e-05 	 6.890296936035156e-05 	 
2025-07-29 15:28:07.810440 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, ) 	 509009920 	 1000 	 0.0043904781341552734 	 0.0038187503814697266 	 1.2636184692382812e-05 	 2.193450927734375e-05 	 0.04339957237243652 	 0.05196332931518555 	 4.76837158203125e-05 	 7.700920104980469e-05 	 
2025-07-29 15:28:24.529103 test begin: paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.004281520843505859 	 0.0038352012634277344 	 1.2159347534179688e-05 	 2.09808349609375e-05 	 0.04203009605407715 	 0.05539751052856445 	 4.887580871582031e-05 	 7.724761962890625e-05 	 
2025-07-29 15:28:50.454598 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, ) 	 508096000 	 1000 	 0.00426030158996582 	 0.003824949264526367 	 7.867813110351562e-06 	 1.9788742065429688e-05 	 0.04178571701049805 	 0.0511627197265625 	 3.552436828613281e-05 	 3.4809112548828125e-05 	 
2025-07-29 15:29:07.921446 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, ) 	 508096000 	 1000 	 0.005877971649169922 	 0.00394749641418457 	 8.106231689453125e-06 	 2.6702880859375e-05 	 0.04205179214477539 	 0.07100248336791992 	 4.673004150390625e-05 	 8.034706115722656e-05 	 
2025-07-29 15:29:27.967497 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, ) 	 508096000 	 1000 	 0.004313230514526367 	 0.003920078277587891 	 1.239776611328125e-05 	 2.002716064453125e-05 	 0.042205810546875 	 0.05230593681335449 	 2.47955322265625e-05 	 7.796287536621094e-05 	 
2025-07-29 15:29:44.863851 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, ) 	 508096000 	 1000 	 0.004357337951660156 	 0.003894329071044922 	 6.67572021484375e-06 	 2.288818359375e-05 	 0.042127132415771484 	 0.05261087417602539 	 3.4809112548828125e-05 	 7.104873657226562e-05 	 
2025-07-29 15:30:01.702194 test begin: paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.0042934417724609375 	 0.003926515579223633 	 7.867813110351562e-06 	 1.9550323486328125e-05 	 0.04155540466308594 	 0.051579952239990234 	 4.1961669921875e-05 	 4.57763671875e-05 	 
2025-07-29 15:30:18.418966 test begin: paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004277944564819336 	 0.0039234161376953125 	 1.0728836059570312e-05 	 2.1219253540039062e-05 	 0.04181027412414551 	 0.0519256591796875 	 2.8133392333984375e-05 	 7.510185241699219e-05 	 
2025-07-29 15:30:36.537084 test begin: paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, ) 	 508032500 	 1000 	 0.47032833099365234 	 0.5079216957092285 	 0.24030852317810059 	 0.2595391273498535 	 None 	 None 	 None 	 None 	 
2025-07-29 14:54:47.210097 test begin: paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, )
W0729 14:54:54.308406  4265 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.all 	 paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, ) 	 508032300 	 1000 	 0.4647808074951172 	 0.508289098739624 	 0.23743987083435059 	 0.2595508098602295 	 None 	 None 	 None 	 None 	 
2025-07-29 14:54:55.584263 test begin: paddle.all(Tensor([508032010],"bool"), )
[Prof] paddle.all 	 paddle.all(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.4674718379974365 	 0.5080225467681885 	 0.23883461952209473 	 0.25957632064819336 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:07.669861 test begin: paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, ) 	 508032600 	 1000 	 0.46539950370788574 	 0.5077226161956787 	 0.237260103225708 	 0.2594332695007324 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:15.600663 test begin: paddle.any(Tensor([10, 12404, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 12404, 4096],"bool"), ) 	 508067840 	 1000 	 0.46567869186401367 	 0.5293433666229248 	 0.2374095916748047 	 0.27050113677978516 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:23.596462 test begin: paddle.any(Tensor([10, 300, 169345],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 300, 169345],"bool"), ) 	 508035000 	 1000 	 0.46483469009399414 	 0.529822587966919 	 0.23752617835998535 	 0.2707557678222656 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:31.447396 test begin: paddle.any(Tensor([11240, 45199],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([11240, 45199],"bool"), ) 	 508036760 	 1000 	 0.4636678695678711 	 0.5299577713012695 	 0.236952543258667 	 0.27080774307250977 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:40.835174 test begin: paddle.any(Tensor([15876010, 32],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.46702146530151367 	 0.5300133228302002 	 0.23861145973205566 	 0.2708134651184082 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:48.965127 test begin: paddle.any(Tensor([420, 300, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([420, 300, 4096],"bool"), ) 	 516096000 	 1000 	 0.4732546806335449 	 0.5400412082672119 	 0.24125361442565918 	 0.2759411334991455 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:57.064337 test begin: paddle.any(Tensor([5120, 99226],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([5120, 99226],"bool"), ) 	 508037120 	 1000 	 0.46678662300109863 	 0.5282189846038818 	 0.2385399341583252 	 0.2698843479156494 	 None 	 None 	 None 	 None 	 
2025-07-29 14:56:05.063646 test begin: paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.0031120777130126953 	 0.004561424255371094 	 2.0265579223632812e-05 	 2.2649765014648438e-05 	 0.03902101516723633 	 0.060089111328125 	 6.222724914550781e-05 	 7.486343383789062e-05 	 
2025-07-29 14:56:18.561497 test begin: paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.0030574798583984375 	 0.004594564437866211 	 9.775161743164062e-06 	 2.384185791015625e-05 	 0.03770852088928223 	 0.05752372741699219 	 4.506111145019531e-05 	 6.818771362304688e-05 	 
2025-07-29 14:56:32.083609 test begin: paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), ) 	 508108800 	 1000 	 0.0030002593994140625 	 0.004540920257568359 	 1.1920928955078125e-05 	 2.288818359375e-05 	 0.037628889083862305 	 0.052857160568237305 	 3.933906555175781e-05 	 5.221366882324219e-05 	 
2025-07-29 14:56:46.044506 test begin: paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), ) 	 508559360 	 1000 	 0.003075838088989258 	 0.004622220993041992 	 8.106231689453125e-06 	 2.002716064453125e-05 	 0.037576913833618164 	 0.056769371032714844 	 3.910064697265625e-05 	 8.440017700195312e-05 	 
2025-07-29 14:56:59.592165 test begin: paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), ) 	 508108800 	 1000 	 0.003011941909790039 	 0.004502296447753906 	 1.1205673217773438e-05 	 1.9550323486328125e-05 	 0.03773975372314453 	 0.05350065231323242 	 3.838539123535156e-05 	 6.175041198730469e-05 	 
2025-07-29 14:57:13.039933 test begin: paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.017258882522583008 	 0.004677295684814453 	 1.6689300537109375e-05 	 2.3603439331054688e-05 	 1.4969964027404785 	 1.3142223358154297 	 0.7645213603973389 	 0.671318769454956 	 
2025-07-29 14:57:24.187474 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.019324064254760742 	 0.0045201778411865234 	 3.647804260253906e-05 	 2.1696090698242188e-05 	 1.5149083137512207 	 1.3174381256103516 	 0.7742049694061279 	 0.673853874206543 	 
2025-07-29 14:57:49.355965 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.017290353775024414 	 0.004674673080444336 	 1.811981201171875e-05 	 2.2172927856445312e-05 	 1.5154340267181396 	 1.3156752586364746 	 0.7738003730773926 	 0.6720066070556641 	 
2025-07-29 14:58:11.567880 test begin: paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.017304420471191406 	 0.0045664310455322266 	 4.076957702636719e-05 	 2.1696090698242188e-05 	 1.4973406791687012 	 1.3142480850219727 	 0.7650084495544434 	 0.6712646484375 	 
2025-07-29 14:58:22.494289 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.017098665237426758 	 0.0046007633209228516 	 1.8596649169921875e-05 	 2.0503997802734375e-05 	 1.5150916576385498 	 1.314936876296997 	 0.774254560470581 	 0.6716372966766357 	 
2025-07-29 14:58:44.515280 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.01999807357788086 	 0.008165359497070312 	 6.818771362304688e-05 	 2.6226043701171875e-05 	 1.514841079711914 	 1.3157377243041992 	 0.7735707759857178 	 0.6721203327178955 	 
2025-07-29 15:00:05.731217 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
W0729 15:00:51.477294  7190 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.002909421920776367 	 0.009336709976196289 	 1.0013580322265625e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:01.758511 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.002783060073852539 	 0.00897836685180664 	 1.1444091796875e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:55.595367 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0027959346771240234 	 0.0072841644287109375 	 9.775161743164062e-06 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:49.453395 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0015647411346435547 	 0.006242990493774414 	 6.67572021484375e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:42.236985 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
W0729 15:05:25.114405  9229 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.0029573440551757812 	 0.009022951126098633 	 1.1205673217773438e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:05:35.336149 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.0028192996978759766 	 0.007534503936767578 	 8.106231689453125e-06 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:06:40.868993 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.00281524658203125 	 0.010395050048828125 	 1.1205673217773438e-05 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:37.605483 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.002810955047607422 	 0.007379293441772461 	 1.0013580322265625e-05 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:39.164426 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.002815723419189453 	 0.010463953018188477 	 8.821487426757812e-06 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:08:41.815094 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0028464794158935547 	 0.0074462890625 	 9.059906005859375e-06 	 2.8371810913085938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:09:35.879349 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0028405189514160156 	 0.010455846786499023 	 1.33514404296875e-05 	 4.172325134277344e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:09:37.653941 test begin: paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0027976036071777344 	 0.007833003997802734 	 1.0013580322265625e-05 	 5.364418029785156e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:10:41.894749 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.002780914306640625 	 0.010479927062988281 	 8.344650268554688e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:11:47.847587 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.002873659133911133 	 0.007500648498535156 	 1.6450881958007812e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:12:42.450932 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.0027990341186523438 	 0.007407188415527344 	 7.3909759521484375e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:13:47.887165 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.002783060073852539 	 0.0074689388275146484 	 9.059906005859375e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:13:48.591583 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.002806425094604492 	 0.0074236392974853516 	 1.0728836059570312e-05 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:14:57.363748 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0027875900268554688 	 0.007411003112792969 	 6.198883056640625e-06 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:14:58.071613 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0016126632690429688 	 0.006250619888305664 	 7.867813110351562e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:15:51.103349 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0028383731842041016 	 0.010419845581054688 	 1.1444091796875e-05 	 2.765655517578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:17:05.343744 test begin: paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.002846240997314453 	 0.007375240325927734 	 1.3828277587890625e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:18:08.650536 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0015757083892822266 	 0.006238222122192383 	 1.0013580322265625e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:01.717733 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0028209686279296875 	 0.007659912109375 	 7.152557373046875e-06 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:55.477655 test begin: paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.002761363983154297 	 0.007639408111572266 	 1.1205673217773438e-05 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:56.125225 test begin: paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0027456283569335938 	 0.0074176788330078125 	 1.3113021850585938e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:20:49.779348 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.00279998779296875 	 0.007451295852661133 	 6.9141387939453125e-06 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:20:50.431731 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0015621185302734375 	 0.007662534713745117 	 1.0013580322265625e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:21:46.195204 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0027730464935302734 	 0.00771784782409668 	 8.58306884765625e-06 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:22:41.295921 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0038394927978515625 	 0.007418155670166016 	 9.298324584960938e-06 	 3.266334533691406e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:23:34.493556 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.003710031509399414 	 0.007416963577270508 	 9.298324584960938e-06 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:24:39.565131 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0036458969116210938 	 0.0074274539947509766 	 1.3589859008789062e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:25:32.728072 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003617525100708008 	 0.007507801055908203 	 1.1682510375976562e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:26:40.576718 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0018773078918457031 	 0.0063343048095703125 	 1.0728836059570312e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:27:46.670142 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.0041904449462890625 	 0.007426261901855469 	 1.9311904907226562e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:28:51.407184 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.0038385391235351562 	 0.010411262512207031 	 1.3828277587890625e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:29:52.438700 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.0037865638732910156 	 0.007301807403564453 	 1.3589859008789062e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:31:08.316234 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.0038275718688964844 	 0.007256746292114258 	 1.0728836059570312e-05 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:32:17.901154 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.00373077392578125 	 0.007362842559814453 	 1.1920928955078125e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:33:23.617616 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0037386417388916016 	 0.007428884506225586 	 6.9141387939453125e-06 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:33:24.466596 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0037987232208251953 	 0.010444402694702148 	 1.1205673217773438e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:34:33.098623 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.003750324249267578 	 0.007384538650512695 	 9.298324584960938e-06 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:35:40.970013 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0037581920623779297 	 0.00762939453125 	 1.1682510375976562e-05 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:35:43.129487 test begin: paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.003767728805541992 	 0.007205009460449219 	 1.049041748046875e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:36:39.502043 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0037446022033691406 	 0.007283449172973633 	 9.298324584960938e-06 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:37:47.513818 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0037660598754882812 	 0.007544279098510742 	 1.0013580322265625e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:38:43.779062 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.0037627220153808594 	 0.007257699966430664 	 1.239776611328125e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:39:48.659674 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003782987594604492 	 0.008182525634765625 	 7.3909759521484375e-06 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:39:49.371351 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0037398338317871094 	 0.0073909759521484375 	 1.049041748046875e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:41:00.665147 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003693103790283203 	 0.00751185417175293 	 7.62939453125e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:41:03.217883 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0018889904022216797 	 0.006499767303466797 	 9.059906005859375e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:41:56.288454 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0037505626678466797 	 0.0076045989990234375 	 1.0251998901367188e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:42:50.228658 test begin: paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.003757953643798828 	 0.007295846939086914 	 1.3113021850585938e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:43:45.464691 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.00189208984375 	 0.010343790054321289 	 1.1205673217773438e-05 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:44:39.746792 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0037603378295898438 	 0.015800952911376953 	 1.0728836059570312e-05 	 6.818771362304688e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:45:45.970576 test begin: paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0037076473236083984 	 0.007286548614501953 	 7.3909759521484375e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:45:46.620114 test begin: paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0036363601684570312 	 0.007549762725830078 	 7.867813110351562e-06 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:46:53.203055 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.003743410110473633 	 0.007418155670166016 	 1.2636184692382812e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:46:53.865167 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0020835399627685547 	 0.006626129150390625 	 1.2636184692382812e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:47:47.931573 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.003710031509399414 	 0.007231473922729492 	 8.344650268554688e-06 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:48:57.858470 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004778385162353516 	 0.007195949554443359 	 1.1920928955078125e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:50:02.067588 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004559993743896484 	 0.007252216339111328 	 6.4373016357421875e-06 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:51:05.119372 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0045452117919921875 	 0.0073833465576171875 	 1.0251998901367188e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:52:17.259021 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.006107807159423828 	 0.007323026657104492 	 3.147125244140625e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:53:24.228673 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.002222776412963867 	 0.006315946578979492 	 1.049041748046875e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:54:28.434590 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.004721879959106445 	 0.007363319396972656 	 9.298324584960938e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:55:38.924050 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.004749774932861328 	 0.007302284240722656 	 1.0013580322265625e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:56:44.789863 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.0047566890716552734 	 0.007355451583862305 	 1.71661376953125e-05 	 3.075599670410156e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:58:03.345919 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.004735231399536133 	 0.007346630096435547 	 1.1682510375976562e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:58:57.474399 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0047910213470458984 	 0.007172584533691406 	 1.430511474609375e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:00:11.917424 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004704475402832031 	 0.007340908050537109 	 6.198883056640625e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:00:12.753949 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.004691600799560547 	 0.007305622100830078 	 7.3909759521484375e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:01:15.730271 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004727840423583984 	 0.007311344146728516 	 7.152557373046875e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:02:16.946457 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004671573638916016 	 0.007646083831787109 	 8.821487426757812e-06 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:54:51.339697 test begin: paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
W0729 14:55:41.803071  4393 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0050525665283203125 	 0.008820056915283203 	 1.0967254638671875e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:51.245985 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.004721403121948242 	 0.007473945617675781 	 9.775161743164062e-06 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:56:59.275736 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.004770517349243164 	 0.0073621273040771484 	 1.0967254638671875e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:58:09.960373 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.004739999771118164 	 0.007430315017700195 	 1.2636184692382812e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:59:07.457519 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004714012145996094 	 0.007650136947631836 	 1.1444091796875e-05 	 6.270408630371094e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:59:08.151017 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.004754781723022461 	 0.0074138641357421875 	 7.3909759521484375e-06 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:01.878945 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004655361175537109 	 0.007453203201293945 	 6.9141387939453125e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:02.583570 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0022873878479003906 	 0.00634765625 	 1.049041748046875e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:00:55.572236 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.004817485809326172 	 0.007436275482177734 	 1.1682510375976562e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:01:48.135337 test begin: paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.004949092864990234 	 0.007460355758666992 	 2.1696090698242188e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:02:43.359133 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0022745132446289062 	 0.006276607513427734 	 9.059906005859375e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:03:36.222066 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.00478816032409668 	 0.007436037063598633 	 9.775161743164062e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:29.017638 test begin: paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0046460628509521484 	 0.0074765682220458984 	 7.152557373046875e-06 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:04:29.672286 test begin: paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.004606485366821289 	 0.007494211196899414 	 1.1205673217773438e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:05:23.184513 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004756927490234375 	 0.007353305816650391 	 1.0013580322265625e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:05:23.833232 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0022690296173095703 	 0.006334543228149414 	 9.775161743164062e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:06:16.596053 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004670143127441406 	 0.007466793060302734 	 1.0967254638671875e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:09.654638 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 508036320 	 1000 	 0.8479118347167969 	 0.7481334209442139 	 0.8394739627838135 	 0.7342362403869629 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:18.539165 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 508042800 	 1000 	 0.8586633205413818 	 0.7528688907623291 	 0.850212574005127 	 0.7346405982971191 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:29.616407 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 508053600 	 1000 	 0.848912239074707 	 1.4464800357818604 	 0.8404309749603271 	 0.7340009212493896 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:39.820077 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 508037400 	 1000 	 0.8587596416473389 	 0.7468364238739014 	 0.8502688407897949 	 0.7349209785461426 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:48.485383 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8492121696472168 	 0.7468018531799316 	 0.8407814502716064 	 0.7350153923034668 	 None 	 None 	 None 	 None 	 
2025-07-29 15:07:57.209382 test begin: paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8489358425140381 	 0.7467639446258545 	 0.8404991626739502 	 0.7348730564117432 	 None 	 None 	 None 	 None 	 
2025-07-29 15:08:05.861637 test begin: paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8489353656768799 	 0.76090407371521 	 0.8405649662017822 	 0.73443603515625 	 None 	 None 	 None 	 None 	 
2025-07-29 15:08:14.658222 test begin: paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508042800 	 1000 	 0.8586235046386719 	 0.7472941875457764 	 0.8502750396728516 	 0.73533034324646 	 None 	 None 	 None 	 None 	 
2025-07-29 15:08:23.342748 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), ) 	 2540160109 	 1000 	 0.010920286178588867 	 0.010927915573120117 	 1.5497207641601562e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:09:15.405522 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, ) 	 2540160109 	 1000 	 0.011166810989379883 	 0.011160135269165039 	 1.5735626220703125e-05 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:10:07.639898 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), ) 	 25402405 	 1000 	 0.011972665786743164 	 0.01087498664855957 	 2.7179718017578125e-05 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:10:08.201671 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 25402405 	 1000 	 0.01126241683959961 	 0.010943412780761719 	 1.4781951904296875e-05 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:10:08.759416 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, ) 	 25402405 	 1000 	 0.011085748672485352 	 0.011226654052734375 	 1.5020370483398438e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:56:02.241607 test begin: paddle.combinations(Tensor([2540160101],"int64"), 0, True, )
W0729 15:56:48.946697 98173 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.combinations 	 paddle.combinations(Tensor([2540160101],"int64"), 0, True, ) 	 2540160101 	 1000 	 0.012939691543579102 	 0.004525899887084961 	 1.3589859008789062e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:02:52.826171 test begin: paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, )
W0729 16:02:53.520310 120351 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.cummax 	 paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, ) 	 20802080 	 1000 	 5.64052152633667 	 5.640805006027222 	 5.627002477645874 	 5.624201536178589 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:03:06.643005 test begin: paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, ) 	 20800100 	 1000 	 0.5727462768554688 	 3.513213872909546 	 0.5416722297668457 	 3.497072458267212 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:03:12.563111 test begin: paddle.diag(Tensor([20000, 25402],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), ) 	 508040000 	 1000 	 0.008649587631225586 	 0.017914533615112305 	 1.8835067749023438e-05 	 5.269050598144531e-05 	 1.5082032680511475 	 1.3268787860870361 	 0.7706341743469238 	 0.6779203414916992 	 
2025-07-29 16:03:23.763722 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.008824348449707031 	 0.017654895782470703 	 2.5033950805664062e-05 	 4.839897155761719e-05 	 1.5067152976989746 	 1.3305633068084717 	 0.7706968784332275 	 0.6796090602874756 	 
2025-07-29 16:03:35.235965 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=1, ) 	 508040000 	 1000 	 0.00869607925415039 	 0.018421173095703125 	 1.2636184692382812e-05 	 5.6743621826171875e-05 	 1.504793405532837 	 1.331305980682373 	 0.7687256336212158 	 0.6806561946868896 	 
2025-07-29 16:03:46.345912 test begin: paddle.diag(Tensor([254020, 2000],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), ) 	 508040000 	 1000 	 0.008525371551513672 	 0.017581939697265625 	 1.4781951904296875e-05 	 4.601478576660156e-05 	 1.495985984802246 	 1.3200206756591797 	 0.7642159461975098 	 0.6750798225402832 	 
2025-07-29 16:03:57.375414 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.011704683303833008 	 0.01794290542602539 	 1.8358230590820312e-05 	 3.719329833984375e-05 	 1.4983630180358887 	 1.3199996948242188 	 0.7670228481292725 	 0.6737749576568604 	 
2025-07-29 16:04:08.424090 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=1, ) 	 508040000 	 1000 	 0.008738279342651367 	 0.017568349838256836 	 1.5974044799804688e-05 	 3.790855407714844e-05 	 1.4950637817382812 	 1.31854248046875 	 0.7638967037200928 	 0.673698902130127 	 
2025-07-29 16:16:04.553174 test begin: paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, )
W0729 16:16:12.583722  9464 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032200 	 1000 	 0.7773630619049072 	 0.7754266262054443 	 0.19815468788146973 	 0.263350248336792 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:16:22.981578 test begin: paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032110 	 1000 	 0.7802028656005859 	 0.7814023494720459 	 0.199615478515625 	 0.26473498344421387 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:16:40.065549 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], )
W0729 16:16:51.123766 11855 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.03202033042907715 	 0.010268211364746094 	 1.8358230590820312e-05 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:16:54.099594 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], )
W0729 16:17:01.527665 13014 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.028056621551513672 	 0.007637977600097656 	 2.3603439331054688e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:17:03.240441 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], )
W0729 16:17:10.571130 13637 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.024361133575439453 	 0.014237165451049805 	 1.8596649169921875e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:17:12.774940 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], )
W0729 16:17:22.388852 14259 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.031416893005371094 	 0.015973329544067383 	 1.4543533325195312e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:17:24.133610 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], )
W0729 16:17:31.341564 15054 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.016953229904174805 	 0.007727146148681641 	 1.3113021850585938e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:17:32.582927 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], )
W0729 16:17:39.791054 15786 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.025803089141845703 	 0.00898599624633789 	 2.9802322387695312e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:17:41.110983 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], )
W0729 16:17:51.734426 16255 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.03143477439880371 	 0.010236024856567383 	 2.1696090698242188e-05 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:17:53.681485 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], )
W0729 16:18:00.783933 17161 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.0173187255859375 	 0.007662773132324219 	 1.4543533325195312e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:18:02.174508 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], )
W0729 16:18:09.368940 17486 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.02423834800720215 	 0.00895380973815918 	 1.7642974853515625e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 16:18:10.550697 test begin: paddle.empty_like(Tensor([1016064010],"uint8"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([1016064010],"uint8"), ) 	 1016064010 	 1000 	 0.014435052871704102 	 0.005957126617431641 	 1.9550323486328125e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:19.645952 test begin: paddle.empty_like(Tensor([40960, 12404],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"bool"), ) 	 508067840 	 1000 	 0.019557476043701172 	 0.00567317008972168 	 2.0265579223632812e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:26.838612 test begin: paddle.empty_like(Tensor([40960, 12404],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"float32"), ) 	 508067840 	 1000 	 0.012461185455322266 	 1.1375980377197266 	 1.1920928955078125e-05 	 8.344650268554688e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:37.059758 test begin: paddle.empty_like(Tensor([7938010, 64],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"bool"), ) 	 508032640 	 1000 	 0.011750221252441406 	 0.009497880935668945 	 1.6927719116210938e-05 	 3.910064697265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:44.499263 test begin: paddle.empty_like(Tensor([7938010, 64],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"float32"), ) 	 508032640 	 1000 	 0.011876106262207031 	 0.006022930145263672 	 2.3365020751953125e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:52.743819 test begin: paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.019600629806518555 	 0.0028438568115234375 	 2.9325485229492188e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:53.500936 test begin: paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), ) 	 50816002 	 1000 	 0.018015384674072266 	 0.0031058788299560547 	 2.3603439331054688e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:54.383246 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.024702787399291992 	 0.004391670227050781 	 3.24249267578125e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:55.143250 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.01743030548095703 	 0.002555370330810547 	 1.5974044799804688e-05 	 1.52587890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:55.988501 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), ) 	 50828832 	 1000 	 0.01735544204711914 	 0.002636432647705078 	 1.0251998901367188e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:56.849870 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 50828832 	 1000 	 0.017122268676757812 	 0.002569913864135742 	 8.106231689453125e-06 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:57.714974 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.01723337173461914 	 0.0025565624237060547 	 9.059906005859375e-06 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:18:58.963858 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), ) 	 50816002 	 1000 	 0.017367124557495117 	 0.0025348663330078125 	 8.58306884765625e-06 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 16:22:32.789665 test begin: paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
W0729 16:22:41.216689 36161 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 508157440 	 1000 	 0.005889892578125 	 0.004868745803833008 	 1.8596649169921875e-05 	 3.719329833984375e-05 	 0.04544472694396973 	 0.07432246208190918 	 5.14984130859375e-05 	 5.5789947509765625e-05 	 
2025-07-29 16:22:56.309926 test begin: paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 509788160 	 1000 	 0.0057103633880615234 	 0.004555702209472656 	 1.0251998901367188e-05 	 3.600120544433594e-05 	 0.04396200180053711 	 0.05870866775512695 	 6.079673767089844e-05 	 8.249282836914062e-05 	 
2025-07-29 16:23:13.078375 test begin: paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 513802240 	 1000 	 0.005648612976074219 	 0.00442814826965332 	 1.52587890625e-05 	 2.4557113647460938e-05 	 0.04363679885864258 	 0.07690930366516113 	 3.218650817871094e-05 	 6.0558319091796875e-05 	 
2025-07-29 16:23:30.219000 test begin: paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, ) 	 532480000 	 1000 	 0.005703449249267578 	 0.0042459964752197266 	 1.3589859008789062e-05 	 2.09808349609375e-05 	 0.04391932487487793 	 0.0673224925994873 	 6.580352783203125e-05 	 4.601478576660156e-05 	 
2025-07-29 16:23:51.928961 test begin: paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, ) 	 508144000 	 1000 	 0.005682945251464844 	 0.004328489303588867 	 1.1444091796875e-05 	 2.7179718017578125e-05 	 0.04358530044555664 	 0.06973147392272949 	 4.5299530029296875e-05 	 5.888938903808594e-05 	 
2025-07-29 16:24:09.054020 test begin: paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, ) 	 514375680 	 1000 	 0.005657196044921875 	 0.004178762435913086 	 2.3365020751953125e-05 	 2.1219253540039062e-05 	 0.04384565353393555 	 0.0686492919921875 	 6.961822509765625e-05 	 5.9604644775390625e-05 	 
2025-07-29 16:24:30.945546 test begin: paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.005567073822021484 	 0.004452228546142578 	 1.2874603271484375e-05 	 2.3126602172851562e-05 	 0.046636104583740234 	 0.06912779808044434 	 3.0517578125e-05 	 4.76837158203125e-05 	 
2025-07-29 16:24:47.908461 test begin: paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, ) 	 524288000 	 1000 	 0.005690097808837891 	 0.0041658878326416016 	 1.1682510375976562e-05 	 2.0742416381835938e-05 	 0.04353737831115723 	 0.06794166564941406 	 3.504753112792969e-05 	 4.935264587402344e-05 	 
2025-07-29 16:25:05.269787 test begin: paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, ) 	 513802240 	 1000 	 0.005579471588134766 	 0.004243612289428711 	 9.298324584960938e-06 	 2.0503997802734375e-05 	 0.043503522872924805 	 0.06936860084533691 	 2.384185791015625e-05 	 4.482269287109375e-05 	 
2025-07-29 14:54:55.456586 test begin: paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, )
W0729 14:55:03.786293  4523 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.010837078094482422 	 0.0078582763671875 	 1.0967254638671875e-05 	 3.0040740966796875e-05 	 0.05224490165710449 	 0.07526898384094238 	 5.817413330078125e-05 	 7.486343383789062e-05 	 
2025-07-29 14:55:13.306968 test begin: paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6574811935424805 	 0.6611151695251465 	 0.6466464996337891 	 0.6417543888092041 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:21.696294 test begin: paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6587975025177002 	 0.6605894565582275 	 0.6468162536621094 	 0.6448814868927002 	 None 	 None 	 None 	 None 	 
2025-07-29 14:55:33.300891 test begin: paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 545259520 	 1000 	 1.2142951488494873 	 0.7183530330657959 	 0.6945314407348633 	 0.6927745342254639 	 None 	 None 	 None 	 None 	 
2025-07-29 17:07:55.616459 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), )
W0729 17:07:56.697679 126896 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 52918864 	 1000 	 0.01151895523071289 	 81.37285494804382 	 1.5735626220703125e-05 	 0.00044798851013183594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:09:18.848894 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), ) 	 52917364 	 1000 	 0.011677742004394531 	 19.395009756088257 	 1.1444091796875e-05 	 0.00032329559326171875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:09:39.473964 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102473328 	 1000 	 0.019104719161987305 	 63.790366649627686 	 2.288818359375e-05 	 0.00045680999755859375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:10:45.725169 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102473404 	 1000 	 0.019052982330322266 	 64.78770279884338 	 1.8358230590820312e-05 	 0.0002415180206298828 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:11:52.526584 test begin: paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102573116 	 1000 	 0.01151132583618164 	 59.906275033950806 	 0.00048613548278808594 	 0.000225067138671875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:12:54.506330 test begin: paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102598240 	 1000 	 0.011139631271362305 	 63.39810013771057 	 1.5735626220703125e-05 	 0.00023031234741210938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:54:44.268080 test begin: paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
W0729 17:54:45.334792 95857 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 26674703 	 1000 	 0.08522653579711914 	 0.01221919059753418 	 5.7697296142578125e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:54:46.756326 test begin: paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", ) 	 533436623 	 1000 	 0.08863377571105957 	 0.011778116226196289 	 4.887580871582031e-05 	 7.200241088867188e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:55:09.175331 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 533436623 	 1000 	 0.09466886520385742 	 0.011490345001220703 	 5.817413330078125e-05 	 3.2901763916015625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 17:55:30.613415 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, ) 	 508032050 	 1000 	 0.17682814598083496 	 0.01639533042907715 	 3.218650817871094e-05 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 17:55:40.150971 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, ) 	 508032050 	 1000 	 0.10042953491210938 	 0.0162966251373291 	 2.288818359375e-05 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 17:55:48.161034 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], )
W0729 17:55:58.234285 102613 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.032912254333496094 	 0.009842157363891602 	 1.7642974853515625e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:01.035780 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], )
W0729 17:56:07.761060 104061 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.017843961715698242 	 0.0074045658111572266 	 1.811981201171875e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:08.642880 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], )
W0729 17:56:15.833568 104708 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.029558658599853516 	 0.008603572845458984 	 2.956390380859375e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:16.658008 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], )
W0729 17:56:26.541172 105776 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.03316092491149902 	 0.010658979415893555 	 5.602836608886719e-05 	 6.985664367675781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:28.237316 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], )
W0729 17:56:36.755275 107086 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.0453798770904541 	 0.00739741325378418 	 9.202957153320312e-05 	 3.0279159545898438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:40.120889 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], )
W0729 17:56:46.797607 108353 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.02496504783630371 	 0.008660554885864258 	 1.5974044799804688e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:47.752713 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], )
W0729 17:56:56.775049 109391 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.03218269348144531 	 0.016094684600830078 	 3.0994415283203125e-05 	 3.719329833984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:56:57.736832 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], )
W0729 17:57:05.290385 110585 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.01781177520751953 	 0.007431745529174805 	 1.3589859008789062e-05 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 17:57:06.596101 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], )
W0729 17:57:13.377820 111500 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.02490091323852539 	 0.008516073226928711 	 2.765655517578125e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn

2025-07-29 18:09:44.189631 test begin: paddle.is_complex(Tensor([1003520, 507],"float32"), )
W0729 18:09:52.042619 30390 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([1003520, 507],"float32"), ) 	 508784640 	 1000 	 0.0036325454711914062 	 0.002059459686279297 	 1.239776611328125e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 18:09:52.671492 test begin: paddle.is_complex(Tensor([5070, 100352],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([5070, 100352],"float32"), ) 	 508784640 	 1000 	 0.003604412078857422 	 0.00177764892578125 	 1.0251998901367188e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 18:10:00.996014 test begin: paddle.is_complex(Tensor([62020, 8192],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([62020, 8192],"float32"), ) 	 508067840 	 1000 	 0.0035371780395507812 	 0.0033986568450927734 	 6.4373016357421875e-06 	 6.818771362304688e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 18:10:10.374977 test begin: paddle.is_complex(Tensor([81920, 6202],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([81920, 6202],"float32"), ) 	 508067840 	 1000 	 0.0035772323608398438 	 0.0017819404602050781 	 1.0728836059570312e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 18:10:18.738002 test begin: paddle.is_complex(Tensor([8860, 57344],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([8860, 57344],"float32"), ) 	 508067840 	 1000 	 0.003573894500732422 	 0.001735687255859375 	 1.0251998901367188e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 18:10:27.106826 test begin: paddle.is_empty(Tensor([101606410, 5],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([101606410, 5],"float32"), ) 	 508032050 	 1000 	 0.007662773132324219 	 0.0023276805877685547 	 1.0013580322265625e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:10:38.886221 test begin: paddle.is_empty(Tensor([169344010, 3],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([169344010, 3],"float32"), ) 	 508032030 	 1000 	 0.0035631656646728516 	 0.0024194717407226562 	 1.1444091796875e-05 	 5.698204040527344e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:10:50.805832 test begin: paddle.is_empty(Tensor([20, 25401601],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([20, 25401601],"float32"), ) 	 508032020 	 1000 	 0.0036046504974365234 	 0.001589059829711914 	 7.152557373046875e-06 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:10:59.420285 test begin: paddle.is_empty(Tensor([30, 16934401],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([30, 16934401],"float32"), ) 	 508032030 	 1000 	 0.003582477569580078 	 0.0015749931335449219 	 1.1444091796875e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:11:07.852881 test begin: paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), ) 	 508033280 	 1000 	 0.0036649703979492188 	 0.0015683174133300781 	 1.1444091796875e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:11:16.119766 test begin: paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), ) 	 508033280 	 1000 	 0.0038492679595947266 	 0.0015294551849365234 	 1.4781951904296875e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:11:24.443848 test begin: paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), ) 	 508037120 	 1000 	 0.0036432743072509766 	 0.0015597343444824219 	 1.049041748046875e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 18:11:32.687276 test begin: paddle.isreal(Tensor([15876010, 32],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.3863701820373535 	 0.3385908603668213 	 0.3697071075439453 	 0.31885528564453125 	 None 	 None 	 None 	 None 	 
2025-07-29 18:11:41.410422 test begin: paddle.isreal(Tensor([31752010, 32],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"bfloat16"), ) 	 1016064320 	 1000 	 0.7666816711425781 	 0.6580584049224854 	 0.7492883205413818 	 0.6461386680603027 	 None 	 None 	 None 	 None 	 
2025-07-29 18:12:02.629688 test begin: paddle.isreal(Tensor([31752010, 32],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"float16"), ) 	 1016064320 	 1000 	 0.764359712600708 	 0.6594293117523193 	 0.7477378845214844 	 0.6476035118103027 	 None 	 None 	 None 	 None 	 
2025-07-29 18:12:23.517515 test begin: paddle.isreal(Tensor([640, 1587601],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"bfloat16"), ) 	 1016064640 	 1000 	 0.7654156684875488 	 0.6701736450195312 	 0.7390937805175781 	 0.6395189762115479 	 None 	 None 	 None 	 None 	 
2025-07-29 18:12:45.604040 test begin: paddle.isreal(Tensor([640, 1587601],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"float16"), ) 	 1016064640 	 1000 	 0.7643318176269531 	 0.6615972518920898 	 0.7478101253509521 	 0.6488430500030518 	 None 	 None 	 None 	 None 	 
2025-07-29 18:13:13.428485 test begin: paddle.isreal(Tensor([640, 793801],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 793801],"bool"), ) 	 508032640 	 1000 	 0.38367509841918945 	 0.3333866596221924 	 0.3665478229522705 	 0.31900572776794434 	 None 	 None 	 None 	 None 	 
2025-07-29 18:13:22.564418 test begin: paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.004936695098876953 	 0.0059888362884521484 	 1.9788742065429688e-05 	 2.6464462280273438e-05 	 0.04083991050720215 	 0.05896472930908203 	 2.8371810913085938e-05 	 6.914138793945312e-05 	 combined
2025-07-29 18:13:40.546533 test begin: paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.0043528079986572266 	 0.003651857376098633 	 1.52587890625e-05 	 2.193450927734375e-05 	 0.04183793067932129 	 0.05525541305541992 	 2.6464462280273438e-05 	 8.249282836914062e-05 	 combined
2025-07-29 18:13:57.273337 test begin: paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.004304647445678711 	 0.0037698745727539062 	 1.2159347534179688e-05 	 2.2411346435546875e-05 	 0.04068613052368164 	 0.05360698699951172 	 4.0531158447265625e-05 	 5.435943603515625e-05 	 combined
2025-07-29 18:14:14.373887 test begin: paddle.logical_not(Tensor([2150400, 237],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2150400, 237],"bool"), ) 	 509644800 	 1000 	 0.7808654308319092 	 0.7523272037506104 	 0.7722330093383789 	 0.7392566204071045 	 None 	 None 	 None 	 None 	 
2025-07-29 18:14:23.425947 test begin: paddle.logical_not(Tensor([2204160, 231],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2204160, 231],"bool"), ) 	 509160960 	 1000 	 0.7870752811431885 	 0.7490170001983643 	 0.7749533653259277 	 0.7367920875549316 	 None 	 None 	 None 	 None 	 
2025-07-29 18:14:32.011724 test begin: paddle.logical_not(Tensor([2257920, 226],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2257920, 226],"bool"), ) 	 510289920 	 1000 	 0.7831447124481201 	 0.7577857971191406 	 0.7745609283447266 	 0.737736701965332 	 None 	 None 	 None 	 None 	 
2025-07-29 18:14:40.676339 test begin: paddle.logical_not(Tensor([6350410, 80],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([6350410, 80],"bool"), ) 	 508032800 	 1000 	 0.7779033184051514 	 0.7544360160827637 	 0.7694180011749268 	 0.7364034652709961 	 None 	 None 	 None 	 None 	 
2025-07-29 18:14:49.549985 test begin: paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), ) 	 1016064080 	 1000 	 0.004311084747314453 	 0.003838062286376953 	 1.1920928955078125e-05 	 2.1457672119140625e-05 	 0.04002046585083008 	 0.05234813690185547 	 4.1961669921875e-05 	 4.0531158447265625e-05 	 combined
2025-07-29 18:15:27.941643 test begin: paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), ) 	 1016064060 	 1000 	 0.0042955875396728516 	 0.003656148910522461 	 1.0728836059570312e-05 	 2.0742416381835938e-05 	 0.03983473777770996 	 0.052416324615478516 	 3.0040740966796875e-05 	 6.413459777832031e-05 	 combined
2025-07-29 18:16:09.591150 test begin: paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), ) 	 254016060 	 1000 	 0.004330873489379883 	 0.0037403106689453125 	 1.0013580322265625e-05 	 2.0503997802734375e-05 	 0.040207624435424805 	 0.05250668525695801 	 4.601478576660156e-05 	 5.316734313964844e-05 	 combined
2025-07-29 18:16:22.210925 test begin: paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.004366636276245117 	 0.007261037826538086 	 1.0728836059570312e-05 	 2.2649765014648438e-05 	 0.04283618927001953 	 0.059626102447509766 	 5.316734313964844e-05 	 4.458427429199219e-05 	 combined
2025-07-29 18:16:41.540859 test begin: paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), ) 	 254016080 	 1000 	 0.00900411605834961 	 0.00721287727355957 	 1.4543533325195312e-05 	 2.2411346435546875e-05 	 0.039992570877075195 	 0.07641005516052246 	 5.340576171875e-05 	 0.00011730194091796875 	 combined
2025-07-29 18:16:55.066214 test begin: paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.009103059768676758 	 0.003784656524658203 	 1.8358230590820312e-05 	 2.002716064453125e-05 	 0.04288625717163086 	 0.07037091255187988 	 5.078315734863281e-05 	 8.606910705566406e-05 	 combined
2025-07-29 18:17:14.917053 test begin: paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), ) 	 254016120 	 1000 	 0.004322052001953125 	 0.00377655029296875 	 9.775161743164062e-06 	 2.1219253540039062e-05 	 0.04032397270202637 	 0.05252480506896973 	 3.7670135498046875e-05 	 6.461143493652344e-05 	 combined
2025-07-29 18:17:25.518951 test begin: paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.004334449768066406 	 0.007341861724853516 	 1.1444091796875e-05 	 2.5033950805664062e-05 	 0.05075716972351074 	 0.0637967586517334 	 5.054473876953125e-05 	 8.249282836914062e-05 	 combined
2025-07-29 18:17:42.019984 test begin: paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), ) 	 1016064120 	 1000 	 0.004442691802978516 	 0.003604888916015625 	 8.821487426757812e-06 	 2.1457672119140625e-05 	 0.03981947898864746 	 0.05876898765563965 	 3.6716461181640625e-05 	 8.392333984375e-05 	 combined
2025-07-29 18:18:21.262994 test begin: paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018100 	 1000 	 0.008805274963378906 	 0.006086826324462891 	 1.5735626220703125e-05 	 2.1219253540039062e-05 	 0.039650917053222656 	 0.05420827865600586 	 3.337860107421875e-05 	 4.1961669921875e-05 	 
2025-07-29 18:18:31.918836 test begin: paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017680 	 1000 	 0.008120059967041016 	 0.005974769592285156 	 2.0503997802734375e-05 	 2.5272369384765625e-05 	 0.04035377502441406 	 0.054319143295288086 	 3.266334533691406e-05 	 5.602836608886719e-05 	 
2025-07-29 18:18:44.446186 test begin: paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017200 	 1000 	 0.008066177368164062 	 0.010420799255371094 	 9.775161743164062e-06 	 2.6226043701171875e-05 	 0.04680323600769043 	 0.09473419189453125 	 3.409385681152344e-05 	 7.915496826171875e-05 	 
2025-07-29 18:18:57.540668 test begin: paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018800 	 1000 	 0.013052940368652344 	 0.006012439727783203 	 1.2874603271484375e-05 	 2.2649765014648438e-05 	 0.0444490909576416 	 0.05368852615356445 	 4.553794860839844e-05 	 3.814697265625e-05 	 
2025-07-29 18:19:08.218859 test begin: paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254020200 	 1000 	 0.007995843887329102 	 0.006247997283935547 	 1.1205673217773438e-05 	 3.4332275390625e-05 	 0.03982663154602051 	 0.05694842338562012 	 3.314018249511719e-05 	 5.817413330078125e-05 	 
2025-07-29 18:19:19.184089 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.00707554817199707 	 0.0047190189361572266 	 8.821487426757812e-06 	 2.2411346435546875e-05 	 0.039783477783203125 	 0.05455207824707031 	 4.863739013671875e-05 	 5.435943603515625e-05 	 
2025-07-29 18:19:29.944632 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.007567167282104492 	 0.005905628204345703 	 7.62939453125e-06 	 2.384185791015625e-05 	 0.03984642028808594 	 0.054010868072509766 	 4.410743713378906e-05 	 4.00543212890625e-05 	 
2025-07-29 18:19:40.758339 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.006930351257324219 	 0.0047588348388671875 	 8.821487426757812e-06 	 2.0503997802734375e-05 	 0.03986692428588867 	 0.05452752113342285 	 3.1948089599609375e-05 	 6.580352783203125e-05 	 
2025-07-29 18:19:51.473501 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007589817047119141 	 0.0060083866119384766 	 1.0728836059570312e-05 	 2.002716064453125e-05 	 0.03972434997558594 	 0.05432772636413574 	 4.100799560546875e-05 	 4.506111145019531e-05 	 
2025-07-29 18:20:04.106668 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.006930112838745117 	 0.004681110382080078 	 1.0013580322265625e-05 	 2.1219253540039062e-05 	 0.03971457481384277 	 0.05379462242126465 	 3.0517578125e-05 	 6.437301635742188e-05 	 
2025-07-29 18:20:14.787798 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.007542133331298828 	 0.006003856658935547 	 1.1920928955078125e-05 	 2.1457672119140625e-05 	 0.03971147537231445 	 0.06166529655456543 	 3.409385681152344e-05 	 7.176399230957031e-05 	 
2025-07-29 18:20:25.527117 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.00708317756652832 	 0.0047454833984375 	 1.9311904907226562e-05 	 2.0503997802734375e-05 	 0.03957414627075195 	 0.0550236701965332 	 3.218650817871094e-05 	 7.62939453125e-05 	 
2025-07-29 18:20:39.379676 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.007447957992553711 	 0.006012678146362305 	 1.1920928955078125e-05 	 2.1696090698242188e-05 	 0.03991127014160156 	 0.05429553985595703 	 3.933906555175781e-05 	 4.887580871582031e-05 	 
2025-07-29 18:20:50.098429 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.007196664810180664 	 0.0047299861907958984 	 1.621246337890625e-05 	 2.0265579223632812e-05 	 0.03978395462036133 	 0.05518007278442383 	 3.457069396972656e-05 	 5.5789947509765625e-05 	 
2025-07-29 18:21:02.459460 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.00745844841003418 	 0.005915164947509766 	 9.775161743164062e-06 	 2.1696090698242188e-05 	 0.03980422019958496 	 0.054914236068725586 	 3.361701965332031e-05 	 4.267692565917969e-05 	 
2025-07-29 18:21:12.935981 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), ) 	 101607009 	 1000 	 2.071843147277832 	 15.649921655654907 	 5.888938903808594e-05 	 0.00025010108947753906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 18:21:34.568767 test begin: paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016093120 	 1000 	 0.0010957717895507812 	 0.009746313095092773 	 1.5735626220703125e-05 	 2.86102294921875e-05 	 0.03696775436401367 	 4.493137359619141 	 4.553794860839844e-05 	 2.300736665725708 	 combined
2025-07-29 18:22:17.417713 test begin: paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016133120 	 1000 	 0.001962423324584961 	 0.00692439079284668 	 1.0251998901367188e-05 	 2.1457672119140625e-05 	 0.03693270683288574 	 4.495044231414795 	 3.838539123535156e-05 	 2.299625873565674 	 combined
2025-07-29 18:22:55.865750 test begin: paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016076800 	 1000 	 0.0020456314086914062 	 0.006813764572143555 	 3.5762786865234375e-05 	 2.0742416381835938e-05 	 0.05551028251647949 	 4.494537353515625 	 6.008148193359375e-05 	 2.2977631092071533 	 combined
2025-07-29 14:54:59.626470 test begin: paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
W0729 14:55:15.290010  4662 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016099200 	 1000 	 0.001069784164428711 	 0.00812983512878418 	 7.3909759521484375e-06 	 4.76837158203125e-05 	 0.03288578987121582 	 4.482693672180176 	 3.337860107421875e-05 	 2.2905197143554688 	 combined
2025-07-29 14:55:41.647861 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0729 14:55:44.647816  5202 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101748608 	 1000 	 0.3733971118927002 	 0.9219415187835693 	 0.3618621826171875 	 0.9009065628051758 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:46.170562 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0729 14:55:55.801095  5230 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101712896 	 1000 	 1.7880048751831055 	 5.511830806732178 	 1.773909568786621 	 5.490293264389038 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:56:02.216207 test begin: paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0729 14:56:11.741725  5280 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 102070373 	 1000 	 1.8846008777618408 	 5.542823076248169 	 1.8716731071472168 	 5.516437530517578 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad

2025-07-29 14:59:39.303327 test begin: paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, ) 	 102434304 	 1000 	 7.177538156509399 	 22.20586395263672 	 7.1663877964019775 	 22.181387901306152 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:21:32.913374 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
W0729 16:21:41.751586 32452 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.5550689697265625 	 0.5496459007263184 	 0.5352787971496582 	 0.521249532699585 	 3.3083062171936035 	 3.056673765182495 	 1.6933379173278809 	 1.564620018005371 	 
2025-07-29 16:21:50.768172 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, ) 	 509740000 	 1000 	 0.10316157341003418 	 0.09881925582885742 	 0.09104418754577637 	 0.08069419860839844 	 1.795318603515625 	 1.591688632965088 	 0.91562819480896 	 0.8131825923919678 	 
2025-07-29 16:22:02.609643 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.5711190700531006 	 0.5659573078155518 	 0.5512769222259521 	 0.547111988067627 	 3.373865842819214 	 3.1644694805145264 	 1.722658634185791 	 1.617475986480713 	 
2025-07-29 16:22:19.451378 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 614912000 	 1000 	 0.5996603965759277 	 1.4862017631530762 	 0.5872697830200195 	 0.5681955814361572 	 3.6393845081329346 	 3.3535077571868896 	 1.8598721027374268 	 1.1412503719329834 	 
2025-07-29 16:22:43.106934 test begin: paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, ) 	 552161280 	 1000 	 0.7181062698364258 	 0.7403955459594727 	 0.7057034969329834 	 0.7214548587799072 	 4.02077054977417 	 3.8452110290527344 	 2.053736925125122 	 1.9625611305236816 	 
2025-07-29 16:23:02.021900 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7880294322967529 	 0.8161697387695312 	 0.7712836265563965 	 0.7961182594299316 	 4.284399032592773 	 4.124824047088623 	 2.187044382095337 	 2.108961582183838 	 
2025-07-29 16:23:21.620003 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, ) 	 509964000 	 1000 	 0.13517093658447266 	 0.128464937210083 	 0.12317490577697754 	 0.11039400100708008 	 1.8742296695709229 	 1.6854779720306396 	 0.9579970836639404 	 0.8602690696716309 	 
2025-07-29 16:23:33.469949 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7909016609191895 	 0.8154888153076172 	 0.7767043113708496 	 0.7899012565612793 	 4.337871789932251 	 4.168603897094727 	 2.213599920272827 	 2.1291658878326416 	 
2025-07-29 16:23:53.500034 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 642048000 	 1000 	 0.8374295234680176 	 0.8581783771514893 	 0.8224890232086182 	 0.8396804332733154 	 4.680904150009155 	 4.472623109817505 	 2.3928842544555664 	 1.523465633392334 	 
2025-07-29 16:24:15.622267 test begin: paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, ) 	 534973440 	 1000 	 0.5198626518249512 	 0.5146358013153076 	 0.5078778266906738 	 0.49282050132751465 	 3.1496450901031494 	 2.914604663848877 	 1.6083838939666748 	 1.489875316619873 	 
2025-07-29 16:24:33.094933 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2540162448 	 1000 	 0.04623746871948242 	 0.041663169860839844 	 6.318092346191406e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:33.378166 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 5080322448 	 1000 	 0.03719687461853027 	 0.03928399085998535 	 2.5272369384765625e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:33.536397 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5080322448 	 1000 	 0.038100242614746094 	 0.03930044174194336 	 1.4781951904296875e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:33.695736 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262247006 	 1000 	 0.0424504280090332 	 0.05506134033203125 	 1.1682510375976562e-05 	 6.580352783203125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:33.874522 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696685406 	 1000 	 0.0432279109954834 	 0.04080915451049805 	 1.8835067749023438e-05 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:34.039944 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131125927 	 1000 	 0.04324483871459961 	 0.04243302345275879 	 1.52587890625e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:34.213873 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131123806 	 1000 	 0.042633771896362305 	 0.04091978073120117 	 2.5987625122070312e-05 	 4.863739013671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:34.385796 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564327 	 1000 	 0.043006181716918945 	 0.041130781173706055 	 1.8596649169921875e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:34.551736 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564832 	 1000 	 0.04405379295349121 	 0.0411534309387207 	 3.075599670410156e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:34.719376 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25404048 	 1000 	 0.04308056831359863 	 0.041121721267700195 	 2.1696090698242188e-05 	 6.556510925292969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:34.888507 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 5131125927 	 1000 	 0.052195072174072266 	 0.03949427604675293 	 3.981590270996094e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:35.088878 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131125927 	 1000 	 0.0382084846496582 	 0.039452314376831055 	 2.8371810913085938e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:37.057281 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 5131126432 	 1000 	 0.037001609802246094 	 0.03948688507080078 	 2.3365020751953125e-05 	 3.361701965332031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:38.906182 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131126432 	 1000 	 0.038539886474609375 	 0.039574384689331055 	 3.0994415283203125e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:39.080254 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50805648 	 1000 	 0.03700876235961914 	 0.04332780838012695 	 1.71661376953125e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:39.250612 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50805648 	 1000 	 0.03774738311767578 	 0.04375433921813965 	 1.33514404296875e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:39.826309 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131124816 	 1000 	 0.06284809112548828 	 0.05387139320373535 	 3.266334533691406e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:40.045151 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131126432 	 1000 	 0.06285619735717773 	 0.056763410568237305 	 2.956390380859375e-05 	 5.626678466796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:40.266305 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696686416 	 1000 	 0.07814264297485352 	 0.05406665802001953 	 4.029273986816406e-05 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:40.526847 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262248016 	 1000 	 0.06243300437927246 	 0.05400228500366211 	 2.5272369384765625e-05 	 6.604194641113281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:40.747851 test begin: paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080324848 	 1000 	 0.0625765323638916 	 0.05397987365722656 	 3.0517578125e-05 	 7.343292236328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:40.971461 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50805648 	 1000 	 0.04273676872253418 	 0.04625725746154785 	 2.4557113647460938e-05 	 8.702278137207031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:41.144791 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2590965648 	 1000 	 0.04700350761413574 	 0.041294097900390625 	 4.458427429199219e-05 	 4.8160552978515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:41.316551 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080322448 	 1000 	 0.04329633712768555 	 0.040970802307128906 	 3.147125244140625e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:41.484039 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5105724048 	 1000 	 0.0426485538482666 	 0.04115176200866699 	 1.9550323486328125e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:41.650599 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10160644848 	 1000 	 0.04271221160888672 	 0.04142165184020996 	 2.5033950805664062e-05 	 5.9604644775390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:41.817571 test begin: paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.0587310791015625 	 0.0859372615814209 	 0.02995753288269043 	 0.043756723403930664 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:42.263696 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164015264 	 1000 	 0.05869102478027344 	 0.08587098121643066 	 0.02995896339416504 	 0.0437159538269043 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:42.684455 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.058699846267700195 	 0.08592629432678223 	 0.029958724975585938 	 0.042890071868896484 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:43.096369 test begin: paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.0227358341217041 	 0.032617807388305664 	 2.3365020751953125e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:43.298171 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10162198944 	 1000 	 0.024018049240112305 	 0.030623197555541992 	 3.0040740966796875e-05 	 6.127357482910156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:43.493011 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.022617816925048828 	 0.030484437942504883 	 2.4318695068359375e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:43.683966 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.022415637969970703 	 0.031505584716796875 	 2.3126602172851562e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:43.879589 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.022967815399169922 	 0.03263068199157715 	 1.5735626220703125e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:44.078795 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.060064077377319336 	 0.08868861198425293 	 0.023842334747314453 	 0.04373764991760254 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:44.662688 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10165402496 	 1000 	 0.025962352752685547 	 0.030855894088745117 	 2.3365020751953125e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:44.860539 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.023699283599853516 	 0.03648185729980469 	 2.3365020751953125e-05 	 4.673004150390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:45.182424 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10164173504 	 1000 	 0.03422880172729492 	 0.030312538146972656 	 2.384185791015625e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:45.424110 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.022705078125 	 0.03026556968688965 	 2.384185791015625e-05 	 4.4345855712890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:45.614567 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.03126668930053711 	 0.0396733283996582 	 2.1457672119140625e-05 	 9.894371032714844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:45.871418 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.037748098373413086 	 0.0313873291015625 	 2.3365020751953125e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:46.108387 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.03240680694580078 	 0.039177894592285156 	 2.8133392333984375e-05 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:46.333519 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.03160381317138672 	 0.040883779525756836 	 2.1696090698242188e-05 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:46.554693 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10176284196 	 1000 	 0.05874013900756836 	 0.08649277687072754 	 0.02678060531616211 	 0.043710947036743164 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:46.985817 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.05872225761413574 	 0.08629965782165527 	 0.029987812042236328 	 0.04373311996459961 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:47.461693 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10168679808 	 1000 	 0.02977299690246582 	 0.04010200500488281 	 1.8835067749023438e-05 	 6.127357482910156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:47.663119 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.024183273315429688 	 0.03109145164489746 	 1.7642974853515625e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:47.818407 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.022696733474731445 	 0.03417634963989258 	 2.4080276489257812e-05 	 6.175041198730469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:47.978490 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.023825883865356445 	 0.030972957611083984 	 2.2172927856445312e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:48.133743 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.02263784408569336 	 0.040381431579589844 	 2.0742416381835938e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:48.302908 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.03294038772583008 	 0.03173542022705078 	 2.5272369384765625e-05 	 8.726119995117188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:48.508618 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.02280426025390625 	 0.04339241981506348 	 1.621246337890625e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:48.680944 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164992832 	 1000 	 0.022960186004638672 	 0.03520631790161133 	 2.0742416381835938e-05 	 6.127357482910156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:48.943269 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.02385258674621582 	 0.032378435134887695 	 2.0265579223632812e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:49.113617 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164647178 	 1000 	 0.022817373275756836 	 0.03211021423339844 	 1.8596649169921875e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:49.284646 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10165300080 	 1000 	 0.05874204635620117 	 0.09985089302062988 	 0.02998208999633789 	 0.04371905326843262 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:49.735531 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.05881237983703613 	 0.09244871139526367 	 0.026073455810546875 	 0.04371356964111328 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:50.211370 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164173504 	 1000 	 0.058763742446899414 	 0.08591747283935547 	 0.030011653900146484 	 0.043692827224731445 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:50.665575 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.058721303939819336 	 0.08585071563720703 	 0.030003070831298828 	 0.04369711875915527 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:51.081994 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.05868935585021973 	 0.08590245246887207 	 0.029961347579956055 	 0.04370546340942383 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:51.505807 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.05868363380432129 	 0.08828115463256836 	 0.02996826171875 	 0.04371333122253418 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:51.970042 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.05870771408081055 	 0.08587408065795898 	 0.02996373176574707 	 0.04369330406188965 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:52.412175 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.05870509147644043 	 0.0858457088470459 	 0.02998042106628418 	 0.04369950294494629 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:52.850516 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.023108720779418945 	 0.04982924461364746 	 2.3365020751953125e-05 	 6.723403930664062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:53.221933 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10166375448 	 1000 	 0.03840947151184082 	 0.04422807693481445 	 6.079673767089844e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:53.525006 test begin: paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.0222933292388916 	 0.04004216194152832 	 1.6689300537109375e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:53.695271 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.022234439849853516 	 0.04369044303894043 	 1.5497207641601562e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:54.040184 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10161861696 	 1000 	 0.02276754379272461 	 0.052535057067871094 	 1.5735626220703125e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:54.455575 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5080356720 	 1000 	 0.029264450073242188 	 0.03337526321411133 	 1.8358230590820312e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:54.586094 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5080356720 	 1000 	 0.029549837112426758 	 0.034295082092285156 	 2.0742416381835938e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 16:24:54.715932 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2540196720 	 1000 	 0.05962634086608887 	 0.03421592712402344 	 2.288818359375e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:03.524618 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
W0729 14:55:03.760345  4814 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.029021263122558594 	 0.03471732139587402 	 2.2172927856445312e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:04.293756 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131141380 	 1000 	 0.03111720085144043 	 0.034630537033081055 	 2.1219253540039062e-05 	 5.3882598876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:04.432887 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.028563261032104492 	 0.033565521240234375 	 2.2411346435546875e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:04.570161 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.02907538414001465 	 0.03333020210266113 	 2.193450927734375e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:04.700770 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565607050 	 1000 	 0.0314486026763916 	 0.03304147720336914 	 3.528594970703125e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:04.837251 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.02852153778076172 	 0.03318381309509277 	 3.2901763916015625e-05 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:04.967927 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696702980 	 1000 	 0.028812885284423828 	 0.03330683708190918 	 2.6464462280273438e-05 	 6.532669067382812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:05.098318 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696702980 	 1000 	 0.02892303466796875 	 0.03332185745239258 	 2.86102294921875e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:05.234071 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.028801918029785156 	 0.03331255912780762 	 3.3855438232421875e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:05.366927 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131137744 	 1000 	 0.030359745025634766 	 0.03302907943725586 	 2.4318695068359375e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:05.502984 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.028918027877807617 	 0.0330507755279541 	 2.765655517578125e-05 	 5.173683166503906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:05.633582 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.030511140823364258 	 0.03319668769836426 	 3.4332275390625e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:05.895043 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565605232 	 1000 	 0.02823185920715332 	 0.03312849998474121 	 2.6464462280273438e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.029427 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.02824711799621582 	 0.03312063217163086 	 2.0265579223632812e-05 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.160563 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696699344 	 1000 	 0.028470277786254883 	 0.03278684616088867 	 2.5272369384765625e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.289042 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696699344 	 1000 	 0.028831005096435547 	 0.03293919563293457 	 2.4080276489257812e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.425530 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.028384685516357422 	 0.032663583755493164 	 1.6927719116210938e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.554108 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131135320 	 1000 	 0.028861284255981445 	 0.03314495086669922 	 1.5497207641601562e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.686299 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.028406381607055664 	 0.03304600715637207 	 2.1696090698242188e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.816512 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.028536319732666016 	 0.035749197006225586 	 2.3365020751953125e-05 	 6.4849853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:06.968531 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565604020 	 1000 	 0.028301239013671875 	 0.03404808044433594 	 2.0503997802734375e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.100866 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.02840447425842285 	 0.03290820121765137 	 2.6941299438476562e-05 	 5.698204040527344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.230675 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696696920 	 1000 	 0.031517744064331055 	 0.035861968994140625 	 1.9788742065429688e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.368977 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696696920 	 1000 	 0.03390955924987793 	 0.03338909149169922 	 2.9087066650390625e-05 	 5.555152893066406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.508372 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565610080 	 1000 	 0.028100252151489258 	 0.03351116180419922 	 1.5735626220703125e-05 	 5.364418029785156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.637770 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.028571605682373047 	 0.03276419639587402 	 1.9311904907226562e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.772883 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.028267383575439453 	 0.03426170349121094 	 1.52587890625e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:07.933112 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.028588056564331055 	 0.03307604789733887 	 1.811981201171875e-05 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.062723 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131165620 	 1000 	 0.028501033782958984 	 0.036655426025390625 	 3.719329833984375e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.216012 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131165620 	 1000 	 0.02826404571533203 	 0.0334320068359375 	 2.0265579223632812e-05 	 6.866455078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.348233 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131166832 	 1000 	 0.028321027755737305 	 0.03476309776306152 	 2.0742416381835938e-05 	 6.532669067382812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.479368 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131166832 	 1000 	 0.028934955596923828 	 0.03312373161315918 	 2.1696090698242188e-05 	 5.698204040527344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.611450 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131168650 	 1000 	 0.02832818031311035 	 0.03307509422302246 	 2.0742416381835938e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.746344 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131168650 	 1000 	 0.028432130813598633 	 0.0362696647644043 	 2.0503997802734375e-05 	 6.771087646484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:08.886786 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131171680 	 1000 	 0.029577970504760742 	 0.033172607421875 	 2.0503997802734375e-05 	 5.7220458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.024973 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131171680 	 1000 	 0.02922797203063965 	 0.03365039825439453 	 2.7179718017578125e-05 	 7.62939453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.164127 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50839920 	 1000 	 0.030719280242919922 	 0.03298449516296387 	 1.9550323486328125e-05 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.295966 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50839920 	 1000 	 0.028249502182006836 	 0.04752635955810547 	 2.1696090698242188e-05 	 7.081031799316406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.449728 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25438320 	 1000 	 0.02796149253845215 	 0.03287506103515625 	 1.3828277587890625e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.578571 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262258520 	 1000 	 0.027861356735229492 	 0.0328214168548584 	 1.430511474609375e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.705998 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262258520 	 1000 	 0.07415628433227539 	 0.034087181091308594 	 3.5762786865234375e-05 	 7.176399230957031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:09.894594 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262260944 	 1000 	 0.029685020446777344 	 0.03280019760131836 	 2.7179718017578125e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:10.027739 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262260944 	 1000 	 0.028201818466186523 	 0.05124521255493164 	 1.9311904907226562e-05 	 8.797645568847656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:10.190291 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262264580 	 1000 	 0.02872610092163086 	 0.03342890739440918 	 2.956390380859375e-05 	 6.127357482910156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 14:55:10.320922 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262264580 	 1000 	 0.028697729110717773 	 0.033902883529663086 	 2.4557113647460938e-05 	 6.771087646484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad2025-07-29 14:57:29.134552 test begin: paddle.numel(Tensor([508032010],"float32"), )
W0729 14:57:39.823336  6115 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.numel 	 paddle.numel(Tensor([508032010],"float32"), ) 	 508032010 	 1000 	 0.01122283935546875 	 0.030181407928466797 	 2.5272369384765625e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 14:57:40.870864 test begin: paddle.positive(Tensor([100, 5080321],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.0029141902923583984 	 0.00020623207092285156 	 8.344650268554688e-06 	 1.5735626220703125e-05 	 0.03604865074157715 	 0.06341743469238281 	 5.054473876953125e-05 	 7.796287536621094e-05 	 combined
2025-07-29 14:57:58.951115 test begin: paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), ) 	 1016064600 	 1000 	 0.001974821090698242 	 0.0002079010009765625 	 5.9604644775390625e-06 	 1.6450881958007812e-05 	 0.034180402755737305 	 0.05501818656921387 	 2.7894973754882812e-05 	 5.340576171875e-05 	 combined
2025-07-29 14:58:39.890535 test begin: paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), ) 	 508032400 	 1000 	 0.0019378662109375 	 0.0002219676971435547 	 7.152557373046875e-06 	 1.811981201171875e-05 	 0.02980828285217285 	 0.045081138610839844 	 6.413459777832031e-05 	 5.841255187988281e-05 	 combined
2025-07-29 14:58:56.547755 test begin: paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), ) 	 1016064400 	 1000 	 0.0019693374633789062 	 0.00021719932556152344 	 2.0503997802734375e-05 	 1.5020370483398438e-05 	 0.03076171875 	 0.04522061347961426 	 5.269050598144531e-05 	 4.7206878662109375e-05 	 combined
2025-07-29 14:59:36.990099 test begin: paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), ) 	 508032300 	 1000 	 0.001932382583618164 	 0.0002300739288330078 	 1.5020370483398438e-05 	 1.6927719116210938e-05 	 0.02967047691345215 	 0.045171499252319336 	 2.6941299438476562e-05 	 5.602836608886719e-05 	 combined
2025-07-29 14:59:55.221756 test begin: paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), ) 	 1016064300 	 1000 	 0.001928567886352539 	 0.00021767616271972656 	 5.9604644775390625e-06 	 1.52587890625e-05 	 0.029703855514526367 	 0.04533267021179199 	 6.556510925292969e-05 	 6.198883056640625e-05 	 combined
2025-07-29 15:00:34.426192 test begin: paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), ) 	 508032240 	 1000 	 0.00193023681640625 	 0.00021529197692871094 	 9.298324584960938e-06 	 1.4543533325195312e-05 	 0.02957463264465332 	 0.04765439033508301 	 5.602836608886719e-05 	 7.915496826171875e-05 	 combined
2025-07-29 15:00:51.236657 test begin: paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), ) 	 1016064240 	 1000 	 0.001932382583618164 	 0.00021767616271972656 	 6.67572021484375e-06 	 1.5735626220703125e-05 	 0.029582738876342773 	 0.04592609405517578 	 2.9325485229492188e-05 	 6.604194641113281e-05 	 combined
2025-07-29 15:01:30.274090 test begin: paddle.positive(Tensor([496130, 1024],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([496130, 1024],"float32"), ) 	 508037120 	 1000 	 0.0019550323486328125 	 0.00021719932556152344 	 1.1682510375976562e-05 	 1.5497207641601562e-05 	 0.030667543411254883 	 0.04518318176269531 	 5.0067901611328125e-05 	 7.128715515136719e-05 	 combined
2025-07-29 15:01:50.316645 test begin: paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), ) 	 508032600 	 1000 	 0.0019049644470214844 	 0.00021648406982421875 	 7.62939453125e-06 	 1.5735626220703125e-05 	 0.029510498046875 	 0.0477445125579834 	 2.1696090698242188e-05 	 8.0108642578125e-05 	 combined
2025-07-29 15:02:08.028928 test begin: paddle.rank(input=Tensor([1270080101, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([1270080101, 2],"float64"), ) 	 2540160202 	 1000 	 0.042398691177368164 	 0.02904534339904785 	 2.3126602172851562e-05 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:00.922922 test begin: paddle.rank(input=Tensor([201, 12700801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([201, 12700801],"float64"), ) 	 2552861001 	 1000 	 0.040718793869018555 	 0.029156208038330078 	 2.4318695068359375e-05 	 6.866455078125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:55.225895 test begin: paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), ) 	 2548628404 	 1000 	 0.041327476501464844 	 0.0291593074798584 	 2.86102294921875e-05 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:04:48.385193 test begin: paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), ) 	 2548628404 	 1000 	 0.04111289978027344 	 0.029201984405517578 	 3.7670135498046875e-05 	 7.605552673339844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:05:51.683016 test begin: paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), ) 	 2548628404 	 1000 	 0.041165828704833984 	 0.029161691665649414 	 1.9311904907226562e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:06:45.645058 test begin: paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), ) 	 2540160808 	 1000 	 0.04114651679992676 	 0.02916717529296875 	 5.173683166503906e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:07:39.001476 test begin: paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], )
[Prof] paddle.reshape 	 paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], ) 	 1016135680 	 1000 	 0.005489349365234375 	 0.0038940906524658203 	 1.049041748046875e-05 	 2.5033950805664062e-05 	 0.045454978942871094 	 4.496832847595215 	 3.0279159545898438e-05 	 2.297654867172241 	 
2025-07-29 15:18:22.010608 test begin: paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), )
W0729 15:19:09.217422 14446 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), ) 	 2540160613 	 1000 	 0.009948253631591797 	 0.011970758438110352 	 0.0018231868743896484 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:15.046118 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), ) 	 25452802 	 1000 	 0.01035451889038086 	 0.011169195175170898 	 0.0021483898162841797 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:15.695040 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), ) 	 50854402 	 1000 	 0.011073827743530273 	 0.010954141616821289 	 0.002827882766723633 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:16.522038 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), ) 	 50854402 	 1000 	 0.010850191116333008 	 0.010866403579711914 	 0.002840280532836914 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-29 15:19:17.114202 test begin: paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, ) 	 508035600 	 1000 	 0.020401954650878906 	 3.0687289237976074 	 1.6689300537109375e-05 	 1.0430922508239746 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:19:35.108938 test begin: paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, ) 	 317520300 	 1000 	 0.7557246685028076 	 3.824317693710327 	 0.7355425357818604 	 1.2955751419067383 	 6.805097579956055 	 4.1398444175720215 	 0.867805004119873 	 1.0563361644744873 	 
2025-07-29 15:20:02.693876 test begin: paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, ) 	 254016600 	 1000 	 0.019794464111328125 	 3.067927360534668 	 1.6450881958007812e-05 	 1.0429167747497559 	 3.031672954559326 	 3.0689663887023926 	 0.38501548767089844 	 0.7825853824615479 	 
2025-07-29 15:20:22.424926 test begin: paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, ) 	 50803280 	 1000 	 0.02019643783569336 	 0.31945347785949707 	 1.7642974853515625e-05 	 0.10757756233215332 	 0.3218114376068115 	 0.3184080123901367 	 0.040863037109375 	 0.08117389678955078 	 
2025-07-29 15:20:27.734304 test begin: paddle.shape(Tensor([10, 1600, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([10, 1600, 376, 280],"float32"), ) 	 1684480000 	 1000 	 0.004529714584350586 	 0.03206801414489746 	 1.1444091796875e-05 	 4.315376281738281e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:20:54.768214 test begin: paddle.shape(Tensor([130, 128, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([130, 128, 256, 256],"float16"), ) 	 1090519040 	 1000 	 0.004574775695800781 	 0.032283782958984375 	 1.2874603271484375e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:21:15.385211 test begin: paddle.shape(Tensor([40, 121, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 121, 376, 280],"float32"), ) 	 509555200 	 1000 	 0.004541635513305664 	 0.03291821479797363 	 1.2159347534179688e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:21:23.542289 test begin: paddle.shape(Tensor([40, 128, 256, 388],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 388],"float32"), ) 	 508559360 	 1000 	 0.004594087600708008 	 0.03149986267089844 	 4.649162292480469e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:21:32.976883 test begin: paddle.shape(Tensor([40, 128, 256, 776],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 776],"float16"), ) 	 1017118720 	 1000 	 0.004528522491455078 	 0.03149700164794922 	 2.5033950805664062e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:21:51.848804 test begin: paddle.shape(Tensor([40, 128, 388, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 388, 256],"float32"), ) 	 508559360 	 1000 	 0.004422664642333984 	 0.032380104064941406 	 1.0251998901367188e-05 	 6.651878356933594e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:22:00.008112 test begin: paddle.shape(Tensor([40, 128, 776, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 776, 256],"float16"), ) 	 1017118720 	 1000 	 0.004434823989868164 	 0.03158116340637207 	 8.58306884765625e-06 	 5.9604644775390625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:22:18.855708 test begin: paddle.shape(Tensor([40, 1600, 29, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 29, 280],"float32"), ) 	 519680000 	 1000 	 0.0045282840728759766 	 0.031706809997558594 	 9.298324584960938e-06 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:22:27.170892 test begin: paddle.shape(Tensor([40, 1600, 376, 22],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 376, 22],"float32"), ) 	 529408000 	 1000 	 0.0046215057373046875 	 0.0324397087097168 	 4.982948303222656e-05 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:22:36.540023 test begin: paddle.shape(Tensor([40, 194, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 194, 256, 256],"float32"), ) 	 508559360 	 1000 	 0.004523515701293945 	 0.03503227233886719 	 1.049041748046875e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:22:45.022020 test begin: paddle.shape(Tensor([40, 388, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 388, 256, 256],"float16"), ) 	 1017118720 	 1000 	 0.004593849182128906 	 0.03252220153808594 	 4.57763671875e-05 	 5.269050598144531e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:23:03.971328 test begin: paddle.shape(Tensor([70, 128, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([70, 128, 256, 256],"float32"), ) 	 587202560 	 1000 	 0.004506111145019531 	 0.03135800361633301 	 9.059906005859375e-06 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:23:13.389292 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0729 15:23:28.942647 16458 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016099200 	 1000 	 0.008261442184448242 	 0.013472795486450195 	 2.8371810913085938e-05 	 3.075599670410156e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:23:31.488756 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0729 15:23:46.905195 16498 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016099200 	 1000 	 0.007875442504882812 	 0.013838768005371094 	 1.3113021850585938e-05 	 3.0994415283203125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:23:49.851191 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0729 15:24:05.625067 16540 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016099200 	 1000 	 0.007891416549682617 	 0.013810396194458008 	 9.298324584960938e-06 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:24:08.166004 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0729 15:24:23.872669 16584 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016076800 	 1000 	 0.00780034065246582 	 0.013600826263427734 	 1.0728836059570312e-05 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:24:26.391492 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0729 15:24:42.030383 16624 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016076800 	 1000 	 0.00789499282836914 	 0.013358831405639648 	 1.52587890625e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:24:44.536953 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0729 15:25:00.435834 17062 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016076800 	 1000 	 0.007816314697265625 	 0.013555049896240234 	 9.5367431640625e-06 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-29 15:25:04.572515 test begin: paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508035600 	 1000 	 0.015433549880981445 	 3.0685057640075684 	 1.0967254638671875e-05 	 1.0431044101715088 	 3.0831785202026367 	 3.073686122894287 	 0.5241453647613525 	 0.6270022392272949 	 combined
2025-07-29 15:25:30.800795 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 254020320 	 1000 	 0.015238285064697266 	 3.069145679473877 	 1.0013580322265625e-05 	 1.043243408203125 	 3.086500406265259 	 3.074284553527832 	 0.5244226455688477 	 0.6270737648010254 	 combined
2025-07-29 15:25:50.654232 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508036320 	 1000 	 0.01582622528076172 	 3.068695068359375 	 2.2172927856445312e-05 	 1.043208360671997 	 3.093153715133667 	 3.07401180267334 	 0.5258364677429199 	 0.6270737648010254 	 combined
2025-07-29 14:55:08.229067 test begin: paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], )
W0729 14:55:16.093434  5011 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.004799842834472656 	 0.005330324172973633 	 2.193450927734375e-05 	 3.0040740966796875e-05 	 0.04960751533508301 	 0.07251811027526855 	 5.221366882324219e-05 	 7.009506225585938e-05 	 
2025-07-29 14:55:25.562775 test begin: paddle.squeeze(Tensor([1053440, 483],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([1053440, 483],"float32"), ) 	 508811520 	 1000 	 0.003912448883056641 	 0.003858327865600586 	 2.6702880859375e-05 	 2.3126602172851562e-05 	 0.04285430908203125 	 0.06248974800109863 	 5.9604644775390625e-05 	 3.7670135498046875e-05 	 
2025-07-29 14:55:43.013004 test begin: paddle.squeeze(Tensor([3969010, 128],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([3969010, 128],"float32"), ) 	 508033280 	 1000 	 0.0037887096405029297 	 0.003841400146484375 	 7.867813110351562e-06 	 4.029273986816406e-05 	 0.04293560981750488 	 0.06278562545776367 	 6.67572021484375e-05 	 5.4836273193359375e-05 	 
2025-07-29 14:55:59.818670 test begin: paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, ) 	 526400000 	 1000 	 0.007391452789306641 	 0.003966093063354492 	 4.649162292480469e-05 	 2.09808349609375e-05 	 0.0429081916809082 	 0.06450510025024414 	 5.793571472167969e-05 	 5.5789947509765625e-05 	 
2025-07-29 14:56:17.533846 test begin: paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, ) 	 522188800 	 1000 	 0.004765033721923828 	 0.004026174545288086 	 1.0967254638671875e-05 	 2.2172927856445312e-05 	 0.04231739044189453 	 0.06810331344604492 	 2.002716064453125e-05 	 6.628036499023438e-05 	 
2025-07-29 14:56:34.949895 test begin: paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, ) 	 508033000 	 1000 	 0.008994340896606445 	 0.004089832305908203 	 1.1682510375976562e-05 	 1.8358230590820312e-05 	 0.04600119590759277 	 0.06518340110778809 	 2.5987625122070312e-05 	 6.937980651855469e-05 	 
2025-07-29 14:56:52.453334 test begin: paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.004827022552490234 	 0.004975318908691406 	 9.298324584960938e-06 	 1.9073486328125e-05 	 0.043070316314697266 	 0.07294201850891113 	 3.838539123535156e-05 	 5.245208740234375e-05 	 
2025-07-29 14:57:09.463783 test begin: paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.009361028671264648 	 0.009028911590576172 	 1.3113021850585938e-05 	 2.2649765014648438e-05 	 0.050116539001464844 	 0.07784152030944824 	 4.100799560546875e-05 	 5.3882598876953125e-05 	 
2025-07-29 14:57:26.884608 test begin: paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], ) 	 819200000 	 1000 	 0.006735086441040039 	 0.004918336868286133 	 2.7894973754882812e-05 	 2.09808349609375e-05 	 0.042449235916137695 	 0.06459379196166992 	 4.76837158203125e-05 	 3.9577484130859375e-05 	 
2025-07-29 14:57:56.166070 test begin: paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], ) 	 508800000 	 1000 	 0.0047149658203125 	 0.004901885986328125 	 1.33514404296875e-05 	 2.3603439331054688e-05 	 0.043702125549316406 	 0.06953883171081543 	 4.4345855712890625e-05 	 4.863739013671875e-05 	 
2025-07-29 14:59:31.557875 test begin: paddle.t(Tensor([100, 5080321],"float32"), )
W0729 14:59:39.808074  7027 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.t 	 paddle.t(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.0052073001861572266 	 0.004347085952758789 	 2.9325485229492188e-05 	 3.8623809814453125e-05 	 0.04348111152648926 	 0.07124614715576172 	 4.00543212890625e-05 	 9.131431579589844e-05 	 
2025-07-29 14:59:50.505480 test begin: paddle.t(Tensor([200, 2540161],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.004769563674926758 	 0.0039215087890625 	 2.9087066650390625e-05 	 2.4557113647460938e-05 	 0.04291367530822754 	 0.06907248497009277 	 3.600120544433594e-05 	 8.058547973632812e-05 	 
2025-07-29 15:00:07.556383 test begin: paddle.t(Tensor([25401610, 20],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.004105567932128906 	 0.003863096237182617 	 7.3909759521484375e-06 	 2.1457672119140625e-05 	 0.06747937202453613 	 0.058824777603149414 	 4.267692565917969e-05 	 5.173683166503906e-05 	 
2025-07-29 15:00:24.751455 test begin: paddle.t(Tensor([496130, 512],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([496130, 512],"int64"), ) 	 254018560 	 1000 	 0.0041768550872802734 	 0.003887653350830078 	 1.049041748046875e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:00:32.844019 test begin: paddle.t(Tensor([50803210, 10],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([50803210, 10],"float32"), ) 	 508032100 	 1000 	 0.00413203239440918 	 0.0038297176361083984 	 7.867813110351562e-06 	 2.09808349609375e-05 	 0.04314160346984863 	 0.05919504165649414 	 3.719329833984375e-05 	 6.556510925292969e-05 	 
2025-07-29 15:00:49.850665 test begin: paddle.t(Tensor([5120, 49613],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([5120, 49613],"int64"), ) 	 254018560 	 1000 	 0.004195213317871094 	 0.00385284423828125 	 1.0251998901367188e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:00:57.973085 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803807 	 1000 	 0.08814787864685059 	 0.12027144432067871 	 2.1457672119140625e-05 	 7.343292236328125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:01:01.780967 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803806 	 1000 	 0.08847808837890625 	 0.12177801132202148 	 1.6689300537109375e-05 	 7.677078247070312e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:01:03.143290 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", ) 	 25405611 	 1000 	 0.0574793815612793 	 0.044141292572021484 	 2.5033950805664062e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:02:11.331883 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, )
W0729 15:02:15.021880  8004 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0729 15:02:18.596474  8004 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.024405717849731445 	 0.008744001388549805 	 2.5510787963867188e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:02:20.123347 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0729 15:02:27.143630  8027 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.032782554626464844 	 0.009371519088745117 	 5.793571472167969e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:02:28.324554 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0729 15:02:36.659859  8047 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.024172544479370117 	 0.007902145385742188 	 1.4543533325195312e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:02:39.155766 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, )
W0729 15:02:46.133857  8070 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.04036116600036621 	 0.01278233528137207 	 2.3126602172851562e-05 	 2.6941299438476562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:02:47.325336 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0729 15:02:54.508806  8483 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.030745744705200195 	 0.009184837341308594 	 2.384185791015625e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:02:55.719482 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0729 15:03:02.891568  8505 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.025032758712768555 	 0.00799870491027832 	 3.314018249511719e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:04.106524 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, )
W0729 15:03:11.980912  8528 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.024221181869506836 	 0.007858753204345703 	 1.8835067749023438e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:13.165328 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, )
W0729 15:03:20.134872  8544 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.03178715705871582 	 0.009818077087402344 	 1.5020370483398438e-05 	 7.653236389160156e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:21.325882 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, )
W0729 15:03:28.443672  8569 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.024577856063842773 	 0.007930994033813477 	 4.00543212890625e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:29.627207 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, )
W0729 15:03:39.016569  8586 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, ) 	 254016640 	 1000 	 0.02415323257446289 	 0.012891054153442383 	 3.8623809814453125e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:40.433910 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, )
W0729 15:03:47.680121  8613 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, ) 	 254016640 	 1000 	 0.030957698822021484 	 0.009246349334716797 	 1.7881393432617188e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:03:48.832423 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, )
W0729 15:03:56.053556  8630 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, ) 	 254016640 	 1000 	 0.024147510528564453 	 0.007916450500488281 	 1.33514404296875e-05 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn2025-07-29 15:13:34.694170 test begin: paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], )
W0729 15:13:47.022153 12753 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], ) 	 786432000 	 1000 	 0.0035676956176757812 	 0.0051915645599365234 	 6.9141387939453125e-06 	 2.86102294921875e-05 	 0.0410001277923584 	 0.05608415603637695 	 4.9591064453125e-05 	 6.651878356933594e-05 	 
2025-07-29 15:14:03.260588 test begin: paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.0035660266876220703 	 0.005377292633056641 	 1.430511474609375e-05 	 5.221366882324219e-05 	 0.052581787109375 	 4.546586751937866 	 7.486343383789062e-05 	 2.3231887817382812 	 
2025-07-29 15:14:43.790274 test begin: paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.003606557846069336 	 0.0048656463623046875 	 2.7179718017578125e-05 	 2.4557113647460938e-05 	 0.04023909568786621 	 0.05943608283996582 	 3.266334533691406e-05 	 4.5299530029296875e-05 	 
2025-07-29 15:15:02.849986 test begin: paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.007544040679931641 	 0.008412361145019531 	 1.049041748046875e-05 	 2.1696090698242188e-05 	 0.047599077224731445 	 0.07984280586242676 	 5.173683166503906e-05 	 0.00010824203491210938 	 
2025-07-29 15:15:19.087106 test begin: paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.007587432861328125 	 0.008367061614990234 	 1.4543533325195312e-05 	 2.86102294921875e-05 	 0.051911354064941406 	 4.548401594161987 	 2.8848648071289062e-05 	 2.3247883319854736 	 
2025-07-29 15:16:05.406728 test begin: paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], ) 	 513802240 	 1000 	 0.0035562515258789062 	 0.0048274993896484375 	 7.152557373046875e-06 	 2.002716064453125e-05 	 0.03992319107055664 	 0.054326534271240234 	 3.647804260253906e-05 	 6.794929504394531e-05 	 
2025-07-29 15:16:22.671219 test begin: paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.003639698028564453 	 0.004702568054199219 	 4.076957702636719e-05 	 2.3126602172851562e-05 	 0.043709516525268555 	 4.497223138809204 	 3.8623809814453125e-05 	 2.2979378700256348 	 
2025-07-29 15:17:04.956505 test begin: paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0036110877990722656 	 0.0047032833099365234 	 6.4373016357421875e-06 	 3.123283386230469e-05 	 0.04407477378845215 	 4.497558116912842 	 3.24249267578125e-05 	 2.298182249069214 	 
2025-07-29 15:17:44.836789 test begin: paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0039784908294677734 	 0.008443117141723633 	 3.504753112792969e-05 	 5.054473876953125e-05 	 0.054537296295166016 	 4.497524976730347 	 4.100799560546875e-05 	 2.2983124256134033 	 
2025-07-29 15:18:25.376522 test begin: paddle.trunc(Tensor([200, 2540161],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.008492231369018555 	 2.9251139163970947 	 1.9073486328125e-05 	 2.9134068489074707 	 0.05521678924560547 	 1.3112165927886963 	 3.528594970703125e-05 	 1.247863531112671 	 
2025-07-29 15:18:49.591557 test begin: paddle.trunc(Tensor([25401610, 20],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.00850367546081543 	 2.9251089096069336 	 1.811981201171875e-05 	 2.913559913635254 	 0.04937005043029785 	 1.3111951351165771 	 3.409385681152344e-05 	 1.2505879402160645 	 
2025-07-29 15:19:13.781085 test begin: paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.455613374710083 	 2.913029193878174 	 4.673004150390625e-05 	 2.90106201171875 	 0.05182218551635742 	 1.3117263317108154 	 3.814697265625e-05 	 1.248936653137207 	 
2025-07-29 15:19:31.139425 test begin: paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), ) 	 254028960 	 1000 	 0.46831774711608887 	 2.9197030067443848 	 5.698204040527344e-05 	 2.8924996852874756 	 0.058080434799194336 	 1.3118813037872314 	 2.9087066650390625e-05 	 1.2416059970855713 	 
2025-07-29 15:19:50.054276 test begin: paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.008762121200561523 	 2.912970542907715 	 1.9788742065429688e-05 	 2.900993824005127 	 0.0488591194152832 	 1.3117282390594482 	 2.8133392333984375e-05 	 1.2463185787200928 	 
2025-07-29 15:20:06.645475 test begin: paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.016571998596191406 	 2.913147211074829 	 2.9325485229492188e-05 	 2.894805431365967 	 0.06307625770568848 	 1.311842441558838 	 3.0279159545898438e-05 	 1.2411532402038574 	 
2025-07-29 15:20:25.004047 test begin: paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), ) 	 254022480 	 1000 	 0.019248247146606445 	 2.9130890369415283 	 3.2901763916015625e-05 	 2.8945722579956055 	 0.0589447021484375 	 1.312187910079956 	 6.747245788574219e-05 	 1.2488300800323486 	 
2025-07-29 15:20:41.795041 test begin: paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), ) 	 254022480 	 1000 	 0.012031316757202148 	 2.913062572479248 	 2.3126602172851562e-05 	 2.9010374546051025 	 0.04956841468811035 	 1.3118231296539307 	 3.075599670410156e-05 	 1.2485744953155518 	 
2025-07-29 15:20:58.298046 test begin: paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.008711576461791992 	 2.914142608642578 	 1.430511474609375e-05 	 2.9008381366729736 	 0.04983234405517578 	 1.3124418258666992 	 3.910064697265625e-05 	 1.248819351196289 	 
2025-07-29 15:21:15.857845 test begin: paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), ) 	 254018160 	 1000 	 0.015563726425170898 	 2.912976026535034 	 2.288818359375e-05 	 2.900479793548584 	 0.04946637153625488 	 1.3119862079620361 	 4.458427429199219e-05 	 1.2254040241241455 	 
2025-07-29 15:21:33.120472 test begin: paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), ) 	 254018160 	 1000 	 0.24312639236450195 	 2.9129672050476074 	 4.57763671875e-05 	 2.9009430408477783 	 0.04899334907531738 	 1.3119089603424072 	 2.0503997802734375e-05 	 1.2491600513458252 	 
2025-07-29 15:21:50.232347 test begin: paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, ) 	 508032480 	 1000 	 0.03425788879394531 	 0.03056812286376953 	 2.0742416381835938e-05 	 3.337860107421875e-05 	 3.630788803100586 	 3.044142007827759 	 3.5318217277526855 	 2.8322386741638184 	 
2025-07-29 15:22:14.107090 test begin: paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, ) 	 508032480 	 1000 	 0.035182952880859375 	 0.03092217445373535 	 3.0040740966796875e-05 	 2.574920654296875e-05 	 3.6311404705047607 	 3.043966770172119 	 3.533961534500122 	 2.819432020187378 	 
2025-07-29 15:22:42.658748 test begin: paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, ) 	 508033280 	 1000 	 0.03441810607910156 	 0.031011581420898438 	 2.4557113647460938e-05 	 3.0279159545898438e-05 	 3.522658109664917 	 2.9880306720733643 	 3.4277381896972656 	 2.7653133869171143 	 
2025-07-29 15:23:06.320300 test begin: paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, ) 	 508032150 	 1000 	 0.04377317428588867 	 0.04497838020324707 	 1.6927719116210938e-05 	 0.0001614093780517578 	 3.669935941696167 	 3.06815505027771 	 3.5602495670318604 	 2.7838282585144043 	 
2025-07-29 15:23:30.195192 test begin: paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, ) 	 508032270 	 1000 	 0.043962955474853516 	 0.04169917106628418 	 3.743171691894531e-05 	 3.2901763916015625e-05 	 3.6668360233306885 	 3.0695343017578125 	 3.5534284114837646 	 2.775867223739624 	 
2025-07-29 15:23:56.272833 test begin: paddle.unbind(Tensor([40, 2116801, 6],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 2116801, 6],"float32"), ) 	 508032240 	 1000 	 0.04901456832885742 	 0.049813032150268555 	 1.430511474609375e-05 	 6.0558319091796875e-05 	 3.662677049636841 	 3.0457799434661865 	 3.546201705932617 	 2.7105207443237305 	 
2025-07-29 15:24:20.205733 test begin: paddle.unbind(Tensor([40, 5, 2540161],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 5, 2540161],"float32"), ) 	 508032200 	 1000 	 0.049120187759399414 	 0.04347038269042969 	 1.7404556274414062e-05 	 3.457069396972656e-05 	 3.66758131980896 	 3.0512912273406982 	 3.5350708961486816 	 2.710599660873413 	 
2025-07-29 15:24:49.620709 test begin: paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032242 	 1000 	 0.0938258171081543 	 0.005312204360961914 	 3.9577484130859375e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:25:06.392574 test begin: paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032642 	 1000 	 0.09197330474853516 	 0.0053539276123046875 	 3.910064697265625e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:25:23.174239 test begin: paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032962 	 1000 	 0.12694740295410156 	 0.009481668472290039 	 2.002716064453125e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 15:25:41.768886 test begin: paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, ) 	 1016064050 	 1000 	 0.016811847686767578 	 0.008340597152709961 	 1.1444091796875e-05 	 2.47955322265625e-05 	 41.10404586791992 	 40.94014930725098 	 41.04786157608032 	 13.960713624954224 	 
2025-07-29 15:28:53.067651 test begin: paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, )
Warning: The core code of paddle.unsqueeze is too complex.
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, ) 	 262144000 	 1000 	 0.0042705535888671875 	 0.003975868225097656 	 9.059906005859375e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:29:01.679414 test begin: paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, ) 	 508160000 	 1000 	 0.004456520080566406 	 0.00388336181640625 	 1.4066696166992188e-05 	 1.8596649169921875e-05 	 0.04203963279724121 	 0.05513191223144531 	 3.62396240234375e-05 	 5.221366882324219e-05 	 
2025-07-29 15:29:18.328846 test begin: paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, ) 	 254033920 	 1000 	 0.004174947738647461 	 0.0038738250732421875 	 9.5367431640625e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:29:26.725175 test begin: paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, ) 	 254033920 	 1000 	 0.004149436950683594 	 0.0038826465606689453 	 1.2874603271484375e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:29:37.057509 test begin: paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, ) 	 509050880 	 1000 	 0.004430532455444336 	 0.003810405731201172 	 1.2159347534179688e-05 	 2.4557113647460938e-05 	 0.0421755313873291 	 0.053888797760009766 	 3.3855438232421875e-05 	 5.125999450683594e-05 	 
2025-07-29 15:29:53.898205 test begin: paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, ) 	 508144000 	 1000 	 0.004413127899169922 	 0.0038051605224609375 	 1.0728836059570312e-05 	 2.1457672119140625e-05 	 0.06584405899047852 	 0.07098746299743652 	 3.7670135498046875e-05 	 8.177757263183594e-05 	 
2025-07-29 15:30:12.430005 test begin: paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, ) 	 508559360 	 1000 	 0.004436969757080078 	 0.003924369812011719 	 1.1205673217773438e-05 	 2.2172927856445312e-05 	 0.04231882095336914 	 0.052980661392211914 	 4.982948303222656e-05 	 4.601478576660156e-05 	 
2025-07-29 15:30:29.189589 test begin: paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, ) 	 508160000 	 1000 	 0.008798599243164062 	 0.0038437843322753906 	 1.4781951904296875e-05 	 2.0265579223632812e-05 	 0.0421605110168457 	 0.06957459449768066 	 2.384185791015625e-05 	 5.412101745605469e-05 	 
2025-07-29 15:30:50.292311 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013601303100585938 	 0.00421595573425293 	 1.52587890625e-05 	 1.8596649169921875e-05 	 0.041548728942871094 	 0.051537275314331055 	 2.1219253540039062e-05 	 5.245208740234375e-05 	 
2025-07-29 15:31:09.776206 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013467550277709961 	 0.004491329193115234 	 1.0728836059570312e-05 	 1.9073486328125e-05 	 0.041788339614868164 	 0.06633305549621582 	 3.62396240234375e-05 	 6.914138793945312e-05 	 
2025-07-29 15:31:26.575463 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013855934143066406 	 0.004281044006347656 	 1.811981201171875e-05 	 1.8835067749023438e-05 	 0.04178500175476074 	 0.05162692070007324 	 2.3603439331054688e-05 	 6.771087646484375e-05 	 
2025-07-29 15:31:43.525071 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013520479202270508 	 0.004304647445678711 	 1.1205673217773438e-05 	 2.0742416381835938e-05 	 0.04186224937438965 	 0.05472302436828613 	 3.528594970703125e-05 	 6.008148193359375e-05 	 
2025-07-29 15:32:00.680014 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013654470443725586 	 0.004200935363769531 	 1.52587890625e-05 	 1.8596649169921875e-05 	 0.04163336753845215 	 0.051362037658691406 	 3.4332275390625e-05 	 6.4849853515625e-05 	 
2025-07-29 15:32:17.785037 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013493537902832031 	 0.004294872283935547 	 1.239776611328125e-05 	 2.002716064453125e-05 	 0.04165530204772949 	 0.05374431610107422 	 2.4318695068359375e-05 	 7.200241088867188e-05 	 
2025-07-29 15:32:34.737290 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013548612594604492 	 0.007795095443725586 	 1.6927719116210938e-05 	 2.2649765014648438e-05 	 0.04916667938232422 	 0.07466840744018555 	 4.553794860839844e-05 	 0.00010466575622558594 	 
2025-07-29 15:32:52.593933 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013719558715820312 	 0.004280567169189453 	 1.5020370483398438e-05 	 1.8596649169921875e-05 	 0.04150819778442383 	 0.05229306221008301 	 2.47955322265625e-05 	 5.7697296142578125e-05 	 
2025-07-29 15:33:09.808188 test begin: paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), )
[Prof] paddle.view_as 	 paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), ) 	 101608000 	 1000 	 0.014454126358032227 	 0.005263566970825195 	 2.3126602172851562e-05 	 6.699562072753906e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-29 15:33:12.429701 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], )
W0729 15:33:23.077443 29402 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.032944440841674805 	 0.009624719619750977 	 3.0517578125e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:33:25.179935 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], )
W0729 15:33:32.320770 29912 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.01732325553894043 	 0.007142066955566406 	 1.2159347534179688e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:33:33.478631 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], )
W0729 15:33:40.739952 30152 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.03508901596069336 	 0.008243799209594727 	 4.1484832763671875e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:33:42.121655 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], )
W0729 15:33:52.968336 30330 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.05304360389709473 	 0.009607791900634766 	 2.3126602172851562e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:33:54.720385 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], )
W0729 15:34:01.905356 30804 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.017177343368530273 	 0.007251262664794922 	 1.1444091796875e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:34:03.302292 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], )
W0729 15:34:10.919071 31121 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.024078369140625 	 0.008637428283691406 	 2.002716064453125e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:34:12.151045 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], )
W0729 15:34:22.806584 31443 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.03132224082946777 	 0.009600400924682617 	 2.0503997802734375e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:34:24.978362 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], )
W0729 15:34:33.236022 31910 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.017098188400268555 	 0.0070209503173828125 	 1.2159347534179688e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 15:34:35.212214 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], )
W0729 15:34:42.231976 32223 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.024175643920898438 	 0.008311271667480469 	 8.106231689453125e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn

2025-07-29 23:50:21.702642 test begin: paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), )
W0729 23:50:21.948261 112496 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), ) 	 8664 	 1000 	 0.024470090866088867 	 165.8681285381317 	 2.765655517578125e-05 	 0.00029540061950683594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:53:08.494406 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), ) 	 462864 	 1000 	 0.018198251724243164 	 79.87748694419861 	 1.71661376953125e-05 	 0.00022292137145996094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:54:28.598112 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), ) 	 50920464 	 1000 	 0.018262147903442383 	 85.16428565979004 	 1.9073486328125e-05 	 0.00023221969604492188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:55:54.877045 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), ) 	 50997264 	 1000 	 0.01823878288269043 	 82.34605932235718 	 1.3113021850585938e-05 	 0.00011682510375976562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:57:18.374406 test begin: paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.018399715423583984 	 85.39027643203735 	 2.1696090698242188e-05 	 0.0002281665802001953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:58:47.352221 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.01045989990234375 	 58.6316351890564 	 1.621246337890625e-05 	 0.00023293495178222656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:59:48.495927 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.010261774063110352 	 78.38561081886292 	 1.239776611328125e-05 	 0.00024628639221191406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 00:01:09.794179 test begin: paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.010311603546142578 	 58.540305852890015 	 1.2159347534179688e-05 	 0.00012230873107910156 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 205, in <module>
    __bootstrap__()
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 197, in __bootstrap__
    core.init_devices()
KeyboardInterrupt
2025-07-29 23:50:24.868844 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), )
W0729 23:50:25.843111 112618 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.018448829650878906 	 65.2669358253479 	 1.430511474609375e-05 	 0.0002665519714355469 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:51:31.836142 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.010452985763549805 	 59.79571270942688 	 1.5020370483398438e-05 	 0.0002224445343017578 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:52:32.776992 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), ) 	 50843140 	 1000 	 0.01038813591003418 	 59.65098237991333 	 1.6689300537109375e-05 	 0.0002276897430419922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:53:33.518858 test begin: paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], ) 	 5150 	 1000 	 0.5858323574066162 	 1.1160154342651367 	 0.0855245590209961 	 0.286346435546875 	 110.71585702896118 	 0.5266544818878174 	 28.24329400062561 	 0.10728120803833008 	 
2025-07-29 23:55:27.098511 test begin: paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], ) 	 5140 	 1000 	 0.5311603546142578 	 1.0094211101531982 	 0.07744002342224121 	 0.25800609588623047 	 78.1932942867279 	 0.479295015335083 	 19.947845697402954 	 0.09789180755615234 	 
2025-07-29 23:56:47.847017 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], ) 	 5150 	 1000 	 0.36373281478881836 	 0.5283734798431396 	 0.0524907112121582 	 0.1351637840270996 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-29 23:57:49.493270 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], ) 	 948 	 1000 	 0.47426581382751465 	 0.7038547992706299 	 0.06915855407714844 	 0.17972040176391602 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 9, in <module>
    import torch
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 2744, in <module>
    _logging._init_logs()
  File "/usr/local/lib/python3.10/dist-packages/torch/_logging/_internal.py", line 969, in _init_logs
    _reset_logs()
  File "/usr/local/lib/python3.10/dist-packages/torch/_logging/_internal.py", line 941, in _reset_logs
    log.setLevel(logging.WARNING)
  File "/usr/lib/python3.10/logging/__init__.py", line 1453, in setLevel
    self.manager._clear_cache()
  File "/usr/lib/python3.10/logging/__init__.py", line 1411, in _clear_cache
    if isinstance(logger, Logger):
KeyboardInterrupt
2025-07-29 23:50:27.583807 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), )
W0729 23:50:28.670120 112729 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08909058570861816 	 16.558514833450317 	 0.07856059074401855 	 0.0003542900085449219 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:50:46.419572 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.09021997451782227 	 17.350998640060425 	 0.07332110404968262 	 0.0002238750457763672 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:51:05.869715 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.10510110855102539 	 18.738159656524658 	 0.07657909393310547 	 0.00012087821960449219 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:51:29.012770 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08828115463256836 	 16.258124351501465 	 0.07138967514038086 	 0.000225067138671875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:51:46.934832 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.09094834327697754 	 22.124909162521362 	 0.08018851280212402 	 0.0002486705780029297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:52:11.104074 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09151959419250488 	 19.37879252433777 	 0.08204936981201172 	 0.0006804466247558594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:52:32.266350 test begin: paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_mean 	 paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), ) 	 5097435 	 1000 	 0.08756494522094727 	 0.28777360916137695 	 5.841255187988281e-05 	 0.00011014938354492188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:52:39.531793 test begin: paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), ) 	 8960 	 1000 	 0.010665655136108398 	 302.3772556781769 	 1.621246337890625e-05 	 0.0003159046173095703 	 None 	 None 	 None 	 None 	 combined
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 205, in <module>
    __bootstrap__()
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 197, in __bootstrap__
    core.init_devices()
KeyboardInterrupt
2025-07-29 23:50:30.566650 test begin: paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), )
W0729 23:50:30.791116 112868 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), ) 	 6400 	 1000 	 0.018113374710083008 	 223.72389221191406 	 1.9788742065429688e-05 	 0.0003561973571777344 	 None 	 None 	 None 	 None 	 combined
2025-07-29 23:54:14.898965 test begin: paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), ) 	 6400 	 1000 	 0.017983675003051758 	 215.71402430534363 	 1.9073486328125e-05 	 0.000331878662109375 	 None 	 None 	 None 	 None 	 combined
2025-07-29 23:57:50.997828 test begin: paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), ) 	 4800 	 1000 	 0.018031835556030273 	 157.0075168609619 	 2.956390380859375e-05 	 0.00022792816162109375 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:00:28.261818 test begin: paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), ) 	 9120 	 1000 	 0.0178983211517334 	 296.4778971672058 	 2.09808349609375e-05 	 0.00025010108947753906 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:05:25.193050 test begin: paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), ) 	 9120 	 1000 	 0.017973899841308594 	 293.0863072872162 	 1.5020370483398438e-05 	 0.0002338886260986328 	 None 	 None 	 None 	 None 	 combined
2025-07-30 00:10:18.768683 test begin: paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 86, in func_timeout
    thread.join(timeout)
  File "/usr/lib/python3.10/threading.py", line 1100, in join
    self._wait_for_tstate_lock(timeout=max(timeout, 0))
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753805508 (unix time) try "date -d @1753805508" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b80d) received by PID 112653 (TID 0x7fd62f9f8640) from PID 112653 ***]

Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 205, in <module>
    __bootstrap__()
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 197, in __bootstrap__
    core.init_devices()
KeyboardInterrupt
2025-07-29 23:50:33.608834 test begin: paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, )
W0729 23:50:34.401083 113008 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, ) 	 25486272 	 1000 	 0.003884553909301758 	 0.0051212310791015625 	 1.7404556274414062e-05 	 2.6941299438476562e-05 	 0.1510009765625 	 0.14042925834655762 	 0.07694673538208008 	 0.02935051918029785 	 
2025-07-29 23:50:36.887586 test begin: paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, ) 	 25401603 	 1000 	 0.003947734832763672 	 0.008918285369873047 	 2.1696090698242188e-05 	 8.96453857421875e-05 	 0.14696288108825684 	 0.1409156322479248 	 0.07488465309143066 	 0.037169456481933594 	 
2025-07-29 23:50:39.062945 test begin: paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, ) 	 2540160 	 1000 	 1.5280416011810303 	 0.021391868591308594 	 9.1552734375e-05 	 9.250640869140625e-05 	 0.6017510890960693 	 0.07885217666625977 	 7.176399230957031e-05 	 6.651878356933594e-05 	 combined
2025-07-29 23:50:41.382575 test begin: paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, ) 	 2540160 	 1000 	 0.2708587646484375 	 0.02008986473083496 	 4.267692565917969e-05 	 3.337860107421875e-05 	 0.5733895301818848 	 0.0834965705871582 	 5.1975250244140625e-05 	 5.412101745605469e-05 	 combined
2025-07-29 23:50:42.386235 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.5973391532897949 	 0.036889076232910156 	 0.00010800361633300781 	 0.00017380714416503906 	 1.0989336967468262 	 0.1385514736175537 	 8.058547973632812e-05 	 0.060158729553222656 	 combined
2025-07-29 23:50:44.833469 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401606 	 1000 	 0.39133405685424805 	 0.020496129989624023 	 4.601478576660156e-05 	 4.291534423828125e-05 	 1.2307074069976807 	 0.13846969604492188 	 3.7670135498046875e-05 	 0.05610489845275879 	 combined
2025-07-29 23:50:47.145145 test begin: paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, ) 	 25401604 	 1000 	 0.7351224422454834 	 0.020377397537231445 	 4.649162292480469e-05 	 3.814697265625e-05 	 1.012681245803833 	 0.13844609260559082 	 5.7697296142578125e-05 	 0.06247401237487793 	 combined
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 38, in <module>
    from . import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/backward.py", line 28, in <module>
    from . import core, framework, log_helper, unique_name
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/core.py", line 610, in <module>
    __check_and_set_prim_all_enabled(print_flag=True)
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/core.py", line 592, in __check_and_set_prim_all_enabled
    from paddle.utils.environments import strtobool
  File "/usr/local/lib/python3.10/dist-packages/paddle/utils/__init__.py", line 16, in <module>
    from . import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/utils/cpp_extension/__init__.py", line 15, in <module>
    from .cpp_extension import (
  File "/usr/local/lib/python3.10/dist-packages/paddle/utils/cpp_extension/cpp_extension.py", line 23, in <module>
    import setuptools
  File "/usr/lib/python3/dist-packages/setuptools/__init__.py", line 16, in <module>
    import setuptools.version
  File "/usr/lib/python3/dist-packages/setuptools/version.py", line 1, in <module>
    import pkg_resources
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 3267, in <module>
    def _initialize_master_working_set():
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 3241, in _call_aside
    f(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 3302, in _initialize_master_working_set
    list(map(working_set.add_entry, sys.path))
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 613, in add_entry
    for dist in find_distributions(entry, True):
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 2073, in find_on_path
    path_item_entries = _by_version_descending(filtered)
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 2043, in _by_version_descending
    return sorted(names, key=_by_version, reverse=True)
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 2069, in <genexpr>
    if dist_factory(path_item, entry, only)
  File "/usr/lib/python3/dist-packages/pkg_resources/__init__.py", line 2087, in dist_factory
    os.path.isdir(os.path.join(path_item, entry))
  File "/usr/lib/python3.10/posixpath.py", line 83, in join
    if b.startswith(sep):
KeyboardInterrupt
2025-07-29 23:50:36.032918 test begin: paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
W0729 23:50:39.253492 113137 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.019145965576171875 	 0.02009749412536621 	 2.8133392333984375e-05 	 2.9325485229492188e-05 	 0.15334558486938477 	 0.16176271438598633 	 0.09888529777526855 	 0.010747194290161133 	 combined
2025-07-29 23:50:40.344888 test begin: paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.018400192260742188 	 0.019293546676635742 	 1.8596649169921875e-05 	 2.288818359375e-05 	 0.15474271774291992 	 0.1703808307647705 	 0.10182356834411621 	 0.004906415939331055 	 combined
2025-07-29 23:50:41.243949 test begin: paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.027224063873291016 	 0.019251585006713867 	 7.081031799316406e-05 	 3.1948089599609375e-05 	 0.15247797966003418 	 0.17364931106567383 	 0.09314465522766113 	 0.00011730194091796875 	 combined
2025-07-29 23:50:42.141503 test begin: paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], ) 	 25486272 	 1000 	 0.029780864715576172 	 0.020577192306518555 	 3.1948089599609375e-05 	 3.1948089599609375e-05 	 0.1463489532470703 	 0.1504380702972412 	 0.08395123481750488 	 0.014913797378540039 	 combined
2025-07-29 23:50:42.994401 test begin: paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], ) 	 25401603 	 1000 	 0.027740955352783203 	 0.020666837692260742 	 2.5510787963867188e-05 	 2.4080276489257812e-05 	 0.14620685577392578 	 0.14318466186523438 	 0.08286046981811523 	 0.036624908447265625 	 combined
2025-07-29 23:50:43.870091 test begin: paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.0058460235595703125 	 0.004428863525390625 	 5.316734313964844e-05 	 2.6702880859375e-05 	 0.14699912071228027 	 0.1385481357574463 	 0.07494544982910156 	 0.04128527641296387 	 
2025-07-29 23:50:44.764639 test begin: paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), ) 	 25401744 	 1000 	 0.0034914016723632812 	 0.004381656646728516 	 7.62939453125e-06 	 1.7642974853515625e-05 	 0.1472945213317871 	 0.13852787017822266 	 0.07516837120056152 	 0.06620430946350098 	 
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 205, in <module>
    __bootstrap__()
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 197, in __bootstrap__
    core.init_devices()
KeyboardInterrupt
2025-07-29 23:50:41.927592 test begin: paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), )
W0729 23:50:42.590682 113742 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), ) 	 25443936 	 1000 	 0.003837108612060547 	 0.004701852798461914 	 1.0967254638671875e-05 	 2.4080276489257812e-05 	 0.15048933029174805 	 0.13989853858947754 	 0.07662510871887207 	 0.039299726486206055 	 
2025-07-29 23:50:43.473812 test begin: paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), ) 	 25443936 	 1000 	 0.008002996444702148 	 0.0075871944427490234 	 3.147125244140625e-05 	 2.1696090698242188e-05 	 0.15120697021484375 	 0.1397850513458252 	 0.0772092342376709 	 0.059235334396362305 	 
2025-07-29 23:50:44.302474 test begin: paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), ) 	 25443936 	 1000 	 0.0037584304809570312 	 0.004387855529785156 	 1.0728836059570312e-05 	 1.6927719116210938e-05 	 0.15073680877685547 	 0.14006686210632324 	 0.0769658088684082 	 0.06753802299499512 	 
2025-07-29 23:50:45.162617 test begin: paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.004019260406494141 	 0.004644870758056641 	 6.67572021484375e-06 	 2.4557113647460938e-05 	 0.15371298789978027 	 0.14253926277160645 	 0.07851934432983398 	 0.06946516036987305 	 
2025-07-29 23:50:45.975709 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), ) 	 25443936 	 1000 	 0.003765583038330078 	 0.004415988922119141 	 2.4318695068359375e-05 	 1.6927719116210938e-05 	 0.1507110595703125 	 0.1401679515838623 	 0.07695293426513672 	 0.06746578216552734 	 
2025-07-29 23:50:46.814393 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), ) 	 25443936 	 1000 	 0.003781557083129883 	 0.004398345947265625 	 7.62939453125e-06 	 1.71661376953125e-05 	 0.1508181095123291 	 0.1402273178100586 	 0.07704901695251465 	 0.06711506843566895 	 
2025-07-29 23:50:47.639618 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.004023313522338867 	 0.004614591598510742 	 6.4373016357421875e-06 	 1.811981201171875e-05 	 0.16538143157958984 	 0.15448880195617676 	 0.08445930480957031 	 0.07886672019958496 	 
Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/base/libpaddle.so
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 9, in <module>
    from tester import (APIConfig, APITestAccuracy, APITestCINNVSDygraph,
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/__init__.py", line 74, in __getattr__
    from .api_config import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/__init__.py", line 22, in __getattr__
    from .config_analyzer import APIConfig
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py", line 8, in <module>
    import paddle
  File "/usr/local/lib/python3.10/dist-packages/paddle/__init__.py", line 38, in <module>
    from .base import core  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/__init__.py", line 38, in <module>
    from . import (  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/backward.py", line 28, in <module>
    from . import core, framework, log_helper, unique_name
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/core.py", line 388, in <module>
    raise e
  File "/usr/local/lib/python3.10/dist-packages/paddle/base/core.py", line 267, in <module>
    from . import libpaddle
ImportError: initialization failed
2025-07-29 23:50:42.330508 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), )
W0729 23:50:43.072510 113762 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), ) 	 25443936 	 1000 	 0.0037870407104492188 	 0.004534482955932617 	 3.361701965332031e-05 	 2.765655517578125e-05 	 0.14951634407043457 	 0.13960695266723633 	 0.07615876197814941 	 0.04025554656982422 	 
2025-07-29 23:50:43.868537 test begin: paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, ) 	 25528608 	 1000 	 0.06591248512268066 	 0.048026084899902344 	 1.9311904907226562e-05 	 6.937980651855469e-05 	 0.17186450958251953 	 0.16529321670532227 	 0.021970510482788086 	 0.00011301040649414062 	 
2025-07-29 23:50:44.903448 test begin: paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, ) 	 25528608 	 1000 	 0.06916475296020508 	 0.037299394607543945 	 1.7881393432617188e-05 	 5.817413330078125e-05 	 0.17084670066833496 	 0.1527268886566162 	 0.0218353271484375 	 0.0029556751251220703 	 
2025-07-29 23:50:45.859888 test begin: paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), ) 	 25465104 	 1000 	 0.09132957458496094 	 0.060196638107299805 	 3.981590270996094e-05 	 5.7220458984375e-05 	 0.16804122924804688 	 0.19657492637634277 	 0.0213925838470459 	 0.00011682510375976562 	 
2025-07-29 23:50:46.923723 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, ) 	 25443143 	 1000 	 0.027723073959350586 	 0.037439584732055664 	 1.9788742065429688e-05 	 4.267692565917969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:50:47.656481 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, ) 	 25443143 	 1000 	 0.028209447860717773 	 0.028400897979736328 	 3.910064697265625e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-29 23:50:48.369025 test begin: paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 25486272 	 1000 	 0.006017923355102539 	 0.2084505558013916 	 2.1219253540039062e-05 	 7.367134094238281e-05 	 0.14998817443847656 	 0.25044798851013184 	 0.07650518417358398 	 0.00932002067565918 	 combined
