2025-07-25 17:48:41.720554 test begin: paddle.Tensor.__abs__(Tensor([10, 5080321],"float32"), )
W0725 17:48:42.781646 96620 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.3027801513671875 	 0.2992281913757324 	 0.2869839668273926 	 0.2847003936767578 	 0.45037841796875 	 0.7440316677093506 	 0.3916759490966797 	 0.37950611114501953 	 
2025-07-25 17:48:45.872369 test begin: paddle.Tensor.__abs__(Tensor([49613, 1024],"float32"), )
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([49613, 1024],"float32"), ) 	 50803712 	 1000 	 0.29694700241088867 	 0.2979240417480469 	 0.27968502044677734 	 0.2773439884185791 	 0.45032787322998047 	 0.7427871227264404 	 0.3860342502593994 	 0.37949681282043457 	 
2025-07-25 17:48:49.404576 test begin: paddle.Tensor.__abs__(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.29622793197631836 	 0.2978091239929199 	 0.2796616554260254 	 0.2786860466003418 	 0.45046114921569824 	 0.7427182197570801 	 0.3861076831817627 	 0.37947678565979004 	 
2025-07-25 17:48:52.877615 test begin: paddle.Tensor.__add__(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 1, 388, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 1, 388, 4096],"float32"), ) 	 52445184 	 1000 	 0.33681797981262207 	 0.32410240173339844 	 0.3261265754699707 	 0.31172680854797363 	 0.47671031951904297 	 0.15510940551757812 	 0.2435011863708496 	 0.08320736885070801 	 
2025-07-25 17:48:56.022334 test begin: paddle.Tensor.__add__(Tensor([1, 32, 4096, 388],"float32"), Tensor([1, 1, 4096, 388],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 4096, 388],"float32"), Tensor([1, 1, 4096, 388],"float32"), ) 	 52445184 	 1000 	 0.3359200954437256 	 0.3241124153137207 	 0.32045912742614746 	 0.3107943534851074 	 0.4768075942993164 	 0.15372323989868164 	 0.24361205101013184 	 0.08226132392883301 	 
2025-07-25 17:48:59.066754 test begin: paddle.Tensor.__add__(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), ) 	 553648128 	 1000 	 4.693557500839233 	 4.625305891036987 	 4.682663440704346 	 4.612349271774292 	 4.965959310531616 	 1.5599777698516846 	 1.6901049613952637 	 1.4879169464111328 	 
2025-07-25 17:49:33.549110 test begin: paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), ) 	 83886080 	 1000 	 0.5929806232452393 	 1.0286402702331543 	 0.582573413848877 	 0.5706338882446289 	 0.6633884906768799 	 0.24405622482299805 	 0.3389394283294678 	 0.1749882698059082 	 
2025-07-25 17:49:40.079247 test begin: paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 4096],"float32"), ) 	 134217728 	 1000 	 0.5934953689575195 	 0.5882754325866699 	 0.5767111778259277 	 0.5768239498138428 	 0.636481761932373 	 0.0610051155090332 	 0.5760667324066162 	 6.031990051269531e-05 	 
2025-07-25 17:49:45.402455 test begin: paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float16"), Tensor([2, 256, 336, 336],"float32"), )
W0725 17:49:47.350169 97693 dygraph_functions.cc:87088] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float16"), Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.7835800647735596 	 0.4666116237640381 	 0.400407075881958 	 0.4544961452484131 	 0.8027613162994385 	 0.2603597640991211 	 0.41010355949401855 	 0.17885851860046387 	 
2025-07-25 17:49:50.800249 test begin: paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float32"), Tensor([2, 256, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float32"), Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.5117859840393066 	 0.507758617401123 	 0.49499011039733887 	 0.48958373069763184 	 0.5487122535705566 	 0.05424165725708008 	 0.4794623851776123 	 7.176399230957031e-05 	 
2025-07-25 17:49:55.375382 test begin: paddle.Tensor.__add__(Tensor([4, 256, 336, 336],"float16"), Tensor([4, 256, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([4, 256, 336, 336],"float16"), Tensor([4, 256, 336, 336],"float32"), ) 	 231211008 	 1000 	 1.5620458126068115 	 0.926607608795166 	 0.798229455947876 	 0.9145815372467041 	 1.6007575988769531 	 0.5154545307159424 	 0.817889928817749 	 0.44655585289001465 	 
2025-07-25 17:50:06.118129 test begin: paddle.Tensor.__add__(Tensor([8, 113, 336, 336],"float16"), Tensor([8, 113, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 113, 336, 336],"float16"), Tensor([8, 113, 336, 336],"float32"), ) 	 204115968 	 1000 	 1.3795087337493896 	 0.818845272064209 	 0.7049751281738281 	 0.8068075180053711 	 1.4153985977172852 	 0.4557640552520752 	 0.7231299877166748 	 0.38676881790161133 	 
2025-07-25 17:50:15.584107 test begin: paddle.Tensor.__add__(Tensor([8, 256, 336, 74],"float32"), Tensor([8, 256, 336, 74],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 256, 336, 74],"float32"), Tensor([8, 256, 336, 74],"float32"), ) 	 101842944 	 1000 	 0.45143556594848633 	 0.4476914405822754 	 0.4417572021484375 	 0.4330456256866455 	 0.48398256301879883 	 0.05364060401916504 	 0.42338132858276367 	 6.532669067382812e-05 	 
2025-07-25 17:50:19.683467 test begin: paddle.Tensor.__add__(Tensor([8, 256, 74, 336],"float32"), Tensor([8, 256, 74, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 256, 74, 336],"float32"), Tensor([8, 256, 74, 336],"float32"), ) 	 101842944 	 1000 	 0.45147252082824707 	 0.4476511478424072 	 0.4418797492980957 	 0.4357872009277344 	 0.483994722366333 	 0.05725574493408203 	 0.4240570068359375 	 6.651878356933594e-05 	 
2025-07-25 17:50:23.637369 test begin: paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float16"), Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float16"), Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.6988143920898438 	 0.41634273529052734 	 0.3570699691772461 	 0.4042067527770996 	 0.716477632522583 	 0.23243212699890137 	 0.3660874366760254 	 0.15986919403076172 	 
2025-07-25 17:50:28.449868 test begin: paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float32"), Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float32"), Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.45638084411621094 	 0.45550084114074707 	 0.4469001293182373 	 0.44066286087036133 	 0.4892458915710449 	 0.053807973861694336 	 0.4288923740386963 	 3.0517578125e-05 	 
2025-07-25 17:50:32.515689 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.16091299057006836 	 0.22655701637268066 	 0.1514582633972168 	 0.2135448455810547 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:33.728328 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.1608734130859375 	 0.22655391693115234 	 0.15108537673950195 	 0.21368002891540527 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:34.931300 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 24807],"bool"), Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 24807],"bool"), Tensor([1, 1, 2048, 24807],"bool"), ) 	 101609472 	 1000 	 0.11777830123901367 	 0.12442779541015625 	 0.1092996597290039 	 0.09544563293457031 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:37.169127 test begin: paddle.Tensor.__and__(Tensor([1, 1, 24807, 2048],"bool"), Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 24807, 2048],"bool"), Tensor([1, 1, 24807, 2048],"bool"), ) 	 101609472 	 1000 	 0.11777234077453613 	 0.12163472175598145 	 0.10936546325683594 	 0.10339856147766113 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:41.393548 test begin: paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.18027186393737793 	 0.23008155822753906 	 0.1704239845275879 	 0.20646238327026367 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:42.640253 test begin: paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), ) 	 109051904 	 1000 	 0.1256406307220459 	 0.13327431678771973 	 0.11732602119445801 	 0.11175274848937988 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:45.095546 test begin: paddle.Tensor.__and__(Tensor([13, 1, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), ) 	 65913185 	 1000 	 0.18442559242248535 	 0.2489306926727295 	 0.17493963241577148 	 0.22513413429260254 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:47.858156 test begin: paddle.Tensor.__and__(Tensor([13, 1, 1007, 3881],"bool"), Tensor([13, 1, 1007, 3881],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 1007, 3881],"bool"), Tensor([13, 1, 1007, 3881],"bool"), ) 	 101612342 	 1000 	 0.11806344985961914 	 0.11668801307678223 	 0.10234546661376953 	 0.10279393196105957 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:49.566066 test begin: paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.18025612831115723 	 0.22643613815307617 	 0.17076468467712402 	 0.21314549446105957 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:50.794509 test begin: paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), ) 	 109051904 	 1000 	 0.1256544589996338 	 0.12341046333312988 	 0.10959768295288086 	 0.10502481460571289 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:52.646320 test begin: paddle.Tensor.__and__(Tensor([13, 1, 3881, 1007],"bool"), Tensor([13, 1, 3881, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 3881, 1007],"bool"), Tensor([13, 1, 3881, 1007],"bool"), ) 	 101612342 	 1000 	 0.11805081367492676 	 0.11816668510437012 	 0.10969924926757812 	 0.10387492179870605 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:54.328687 test begin: paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 1, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 1, 1007, 1007],"bool"), ) 	 65913185 	 1000 	 0.1976182460784912 	 0.23857498168945312 	 0.18613481521606445 	 0.22553563117980957 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:55.686639 test begin: paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), ) 	 105461096 	 1000 	 0.12285494804382324 	 0.12069106101989746 	 0.11434555053710938 	 0.10843467712402344 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:57.402933 test begin: paddle.Tensor.__and__(Tensor([194, 1, 512, 512],"bool"), Tensor([194, 1, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([194, 1, 512, 512],"bool"), Tensor([194, 1, 512, 512],"bool"), ) 	 101711872 	 1000 	 0.1177973747253418 	 0.1179654598236084 	 0.10936522483825684 	 0.10349154472351074 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:59.051242 test begin: paddle.Tensor.__and__(Tensor([51, 1, 1007, 1007],"bool"), Tensor([51, 1, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([51, 1, 1007, 1007],"bool"), Tensor([51, 1, 1007, 1007],"bool"), ) 	 103432998 	 1000 	 0.11950349807739258 	 0.11788034439086914 	 0.11103296279907227 	 0.10622239112854004 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:00.765612 test begin: paddle.Tensor.__and__(Tensor([8, 1, 12404, 512],"bool"), Tensor([8, 1, 12404, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 12404, 512],"bool"), Tensor([8, 1, 12404, 512],"bool"), ) 	 101613568 	 1000 	 0.11776185035705566 	 0.11546087265014648 	 0.10936307907104492 	 0.10340642929077148 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:02.475465 test begin: paddle.Tensor.__and__(Tensor([8, 1, 512, 12404],"bool"), Tensor([8, 1, 512, 12404],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 512, 12404],"bool"), Tensor([8, 1, 512, 12404],"bool"), ) 	 101613568 	 1000 	 0.11775684356689453 	 0.11686992645263672 	 0.1093134880065918 	 0.10347962379455566 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:04.143012 test begin: paddle.Tensor.__and__(Tensor([8, 1, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), ) 	 54525952 	 1000 	 0.18310832977294922 	 0.23543000221252441 	 0.17357373237609863 	 0.22153425216674805 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:05.327509 test begin: paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 1, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 1, 512, 512],"bool"), ) 	 54525952 	 1000 	 0.19318103790283203 	 0.23993802070617676 	 0.183729887008667 	 0.22213482856750488 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:07.985601 test begin: paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), ) 	 104857600 	 1000 	 0.12098407745361328 	 0.12619376182556152 	 0.11255669593811035 	 0.1067507266998291 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:10.414945 test begin: paddle.Tensor.__div__(Tensor([8, 16, 396901],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([8, 16, 396901],"float32"), 2, ) 	 50803328 	 1000 	 0.29567790031433105 	 0.2979726791381836 	 0.2867562770843506 	 0.283949613571167 	 0.29571533203125 	 0.29773449897766113 	 0.24233651161193848 	 0.23374080657958984 	 
2025-07-25 17:51:13.272191 test begin: paddle.Tensor.__div__(Tensor([8, 198451, 32],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([8, 198451, 32],"float32"), 2, ) 	 50803456 	 1000 	 0.29584741592407227 	 0.29879117012023926 	 0.2867095470428467 	 0.2839806079864502 	 0.2959902286529541 	 0.2977762222290039 	 0.22207331657409668 	 0.23372530937194824 	 
2025-07-25 17:51:16.169839 test begin: paddle.Tensor.__div__(Tensor([99226, 16, 32],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([99226, 16, 32],"float32"), 2, ) 	 50803712 	 1000 	 0.29581642150878906 	 0.29790592193603516 	 0.2869408130645752 	 0.2817575931549072 	 0.2958049774169922 	 0.29772448539733887 	 0.24245214462280273 	 0.23636174201965332 	 
2025-07-25 17:51:19.033179 test begin: paddle.Tensor.__eq__(Tensor([138, 369303],"float32"), Tensor([138, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([138, 369303],"float32"), Tensor([138, 1],"float32"), ) 	 50963952 	 1000 	 0.19208693504333496 	 0.24202513694763184 	 0.18239045143127441 	 0.22958588600158691 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:20.345228 test begin: paddle.Tensor.__eq__(Tensor([146, 349866],"float32"), Tensor([146, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([146, 349866],"float32"), Tensor([146, 1],"float32"), ) 	 51080582 	 1000 	 0.19242334365844727 	 0.242570161819458 	 0.18262815475463867 	 0.22443222999572754 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:21.643531 test begin: paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1036801],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1036801],"float32"), ) 	 101606498 	 1000 	 0.3268768787384033 	 0.3278779983520508 	 0.3178999423980713 	 0.31500673294067383 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:24.047128 test begin: paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1],"float32"), ) 	 50803298 	 1000 	 0.1917436122894287 	 0.24132966995239258 	 0.18192720413208008 	 0.22900915145874023 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:25.321004 test begin: paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 1],"float32"), ) 	 50803256 	 1000 	 0.19179654121398926 	 0.24582290649414062 	 0.1818993091583252 	 0.22887158393859863 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:26.593919 test begin: paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 958551],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 958551],"float32"), ) 	 101606406 	 1000 	 0.3268544673919678 	 0.32787346839904785 	 0.3178091049194336 	 0.3163595199584961 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:28.935344 test begin: paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 1],"float32"), ) 	 50803280 	 1000 	 0.19175124168395996 	 0.24131035804748535 	 0.18193817138671875 	 0.22895503044128418 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:30.213238 test begin: paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 923695],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 923695],"float32"), ) 	 101606450 	 1000 	 0.32686924934387207 	 0.32787179946899414 	 0.31772804260253906 	 0.31633973121643066 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:32.560286 test begin: paddle.Tensor.__floordiv__(Tensor([10, 10160641],"float32"), Tensor([10, 10160641],"float16"), )
W0725 17:51:36.021271 98839 dygraph_functions.cc:89596] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 10160641],"float32"), Tensor([10, 10160641],"float16"), ) 	 203212820 	 1000 	 1.3720431327819824 	 2.8153796195983887 	 0.7009122371673584 	 1.1637909412384033 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:40.988124 test begin: paddle.Tensor.__floordiv__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4475998878479004 	 0.44772887229919434 	 0.4388234615325928 	 0.4304080009460449 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:42.740569 test begin: paddle.Tensor.__floordiv__(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float16"), ) 	 101606420 	 1000 	 0.6893775463104248 	 0.5994665622711182 	 0.35220861434936523 	 0.581740140914917 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:45.894084 test begin: paddle.Tensor.__floordiv__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4480886459350586 	 0.4477229118347168 	 0.4391820430755615 	 0.4303722381591797 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:47.639386 test begin: paddle.Tensor.__floordiv__(Tensor([4, 6350401],"int64"), 4, )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([4, 6350401],"int64"), 4, ) 	 25401604 	 1000 	 0.3046729564666748 	 0.316112756729126 	 0.1556558609008789 	 0.28453803062438965 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:50.378819 test begin: paddle.Tensor.__floordiv__(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float16"), ) 	 101607424 	 1000 	 0.6903493404388428 	 0.6126110553741455 	 0.35269808769226074 	 0.5781402587890625 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:53.592975 test begin: paddle.Tensor.__floordiv__(Tensor([84673, 300],"int64"), 4, )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([84673, 300],"int64"), 4, ) 	 25401900 	 1000 	 0.30479907989501953 	 0.3086860179901123 	 0.15574336051940918 	 0.28431272506713867 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:54.664726 test begin: paddle.Tensor.__floordiv__(Tensor([99226, 1024],"float32"), Tensor([99226, 1024],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([99226, 1024],"float32"), Tensor([99226, 1024],"float16"), ) 	 203214848 	 1000 	 1.3739757537841797 	 1.190507411956787 	 0.7020797729492188 	 1.1730399131774902 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:00.880148 test begin: paddle.Tensor.__ge__(Tensor([50803201],"int32"), 0, )
[Prof] paddle.Tensor.__ge__ 	 paddle.Tensor.__ge__(Tensor([50803201],"int32"), 0, ) 	 50803201 	 1000 	 0.4690392017364502 	 0.18731427192687988 	 0.23966598510742188 	 0.16487789154052734 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:02.196970 test begin: paddle.Tensor.__getitem__(Tensor([1, 7576, 12800],"bfloat16"), slice(None,-3,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 7576, 12800],"bfloat16"), slice(None,-3,None), ) 	 96972800 	 1000 	 0.005324602127075195 	 0.0052607059478759766 	 8.821487426757812e-06 	 2.1457672119140625e-05 	 0.27457547187805176 	 0.1280372142791748 	 0.14040684700012207 	 0.051329612731933594 	 
2025-07-25 17:52:04.203629 test begin: paddle.Tensor.__getitem__(Tensor([1, 7576, 16770],"bfloat16"), slice(None,-3,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 7576, 16770],"bfloat16"), slice(None,-3,None), ) 	 127049520 	 1000 	 0.005432844161987305 	 0.005777120590209961 	 3.147125244140625e-05 	 5.14984130859375e-05 	 0.3592555522918701 	 0.16684913635253906 	 0.1835026741027832 	 0.09091496467590332 	 
2025-07-25 17:52:06.869517 test begin: paddle.Tensor.__getitem__(Tensor([1, 7712, 12800],"bfloat16"), slice(None,-2,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 7712, 12800],"bfloat16"), slice(None,-2,None), ) 	 98713600 	 1000 	 0.0051958560943603516 	 0.005378007888793945 	 8.58306884765625e-06 	 2.0265579223632812e-05 	 0.28294873237609863 	 0.13041973114013672 	 0.14446759223937988 	 0.05536961555480957 	 
2025-07-25 17:52:08.982185 test begin: paddle.Tensor.__getitem__(Tensor([1, 7712, 16470],"bfloat16"), slice(None,-2,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 7712, 16470],"bfloat16"), slice(None,-2,None), ) 	 127016640 	 1000 	 0.005276203155517578 	 0.005343437194824219 	 2.1696090698242188e-05 	 2.1219253540039062e-05 	 0.3676133155822754 	 0.16673493385314941 	 0.18774700164794922 	 0.09021854400634766 	 
2025-07-25 17:52:11.599537 test begin: paddle.Tensor.__getitem__(Tensor([1, 8168, 12800],"bfloat16"), slice(None,-6,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 8168, 12800],"bfloat16"), slice(None,-6,None), ) 	 104550400 	 1000 	 0.005213499069213867 	 0.005360126495361328 	 9.298324584960938e-06 	 2.4318695068359375e-05 	 0.2964365482330322 	 0.13843488693237305 	 0.15154504776000977 	 0.0629115104675293 	 
2025-07-25 17:52:13.756527 test begin: paddle.Tensor.__getitem__(Tensor([1, 8168, 15550],"bfloat16"), slice(None,-6,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 8168, 15550],"bfloat16"), slice(None,-6,None), ) 	 127012400 	 1000 	 0.005228519439697266 	 0.005298614501953125 	 1.1920928955078125e-05 	 2.09808349609375e-05 	 0.35989880561828613 	 0.16664743423461914 	 0.18386340141296387 	 0.09016060829162598 	 
2025-07-25 17:52:16.452832 test begin: paddle.Tensor.__getitem__(Tensor([1, 9923, 12800],"bfloat16"), slice(None,-2,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 9923, 12800],"bfloat16"), slice(None,-2,None), ) 	 127014400 	 1000 	 0.005211591720581055 	 0.005341291427612305 	 8.58306884765625e-06 	 2.1219253540039062e-05 	 0.3584766387939453 	 0.16679859161376953 	 0.18305683135986328 	 0.08923220634460449 	 
2025-07-25 17:52:19.036116 test begin: paddle.Tensor.__getitem__(Tensor([1, 9923, 12800],"bfloat16"), slice(None,-3,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 9923, 12800],"bfloat16"), slice(None,-3,None), ) 	 127014400 	 1000 	 0.00519108772277832 	 0.005280494689941406 	 2.5987625122070312e-05 	 2.4318695068359375e-05 	 0.35869646072387695 	 0.16678857803344727 	 0.18309569358825684 	 0.09105563163757324 	 
2025-07-25 17:52:21.644888 test begin: paddle.Tensor.__getitem__(Tensor([1, 9923, 12800],"bfloat16"), slice(None,-6,None), )
[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([1, 9923, 12800],"bfloat16"), slice(None,-6,None), ) 	 127014400 	 1000 	 0.005198001861572266 	 0.006313800811767578 	 1.33514404296875e-05 	 6.580352783203125e-05 	 0.35847020149230957 	 0.16671133041381836 	 0.18314433097839355 	 0.0881645679473877 	 
2025-07-25 17:52:24.321565 test begin: paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 0, ) 	 50803600 	 1000 	 0.4688849449157715 	 0.1860356330871582 	 0.2395787239074707 	 0.17176556587219238 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:25.806146 test begin: paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 1e-09, ) 	 50803600 	 1000 	 0.4688701629638672 	 0.18605661392211914 	 0.23728466033935547 	 0.17150640487670898 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:27.334218 test begin: paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 0, ) 	 50840832 	 1000 	 0.4693140983581543 	 0.1862490177154541 	 0.239793062210083 	 0.17183208465576172 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:28.826182 test begin: paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 1e-09, ) 	 50840832 	 1000 	 0.46948933601379395 	 0.18982243537902832 	 0.2399148941040039 	 0.17180633544921875 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:30.338881 test begin: paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 0, ) 	 52684800 	 1000 	 0.486163854598999 	 0.19258737564086914 	 0.248368501663208 	 0.1781315803527832 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:31.905790 test begin: paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 1e-09, ) 	 52684800 	 1000 	 0.4861259460449219 	 0.19257569313049316 	 0.24840116500854492 	 0.17805719375610352 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:33.495872 test begin: paddle.Tensor.__gt__(Tensor([324000, 157],"float32"), 0.0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([324000, 157],"float32"), 0.0, ) 	 50868000 	 1000 	 0.4693174362182617 	 0.18624067306518555 	 0.23982596397399902 	 0.1717698574066162 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:35.002522 test begin: paddle.Tensor.__gt__(Tensor([635041, 80],"float32"), 0.0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([635041, 80],"float32"), 0.0, ) 	 50803280 	 1000 	 0.468902587890625 	 0.19366979598999023 	 0.23959970474243164 	 0.16991448402404785 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:38.656635 test begin: paddle.Tensor.__le__(Tensor([243360, 209],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([243360, 209],"float32"), 0.0, ) 	 50862240 	 1000 	 0.4697573184967041 	 0.19321775436401367 	 0.24010372161865234 	 0.17131996154785156 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:40.147403 test begin: paddle.Tensor.__le__(Tensor([282240, 181],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([282240, 181],"float32"), 0.0, ) 	 51085440 	 1000 	 0.4713747501373291 	 0.18708586692810059 	 0.24084877967834473 	 0.17266178131103516 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:41.678236 test begin: paddle.Tensor.__le__(Tensor([324000, 157],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([324000, 157],"float32"), 0.0, ) 	 50868000 	 1000 	 0.46950721740722656 	 0.18937158584594727 	 0.2400221824645996 	 0.1716170310974121 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:43.174650 test begin: paddle.Tensor.__le__(Tensor([635041, 80],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([635041, 80],"float32"), 0.0, ) 	 50803280 	 1000 	 0.46899890899658203 	 0.18607282638549805 	 0.23966407775878906 	 0.17165350914001465 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:44.700616 test begin: paddle.Tensor.__len__(Tensor([100, 1352, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([100, 1352, 376],"float32"), ) 	 50835200 	 1000 	 0.0046558380126953125 	 0.0050470829010009766 	 5.7220458984375e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:45.540369 test begin: paddle.Tensor.__len__(Tensor([100, 376, 1352],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([100, 376, 1352],"float32"), ) 	 50835200 	 1000 	 0.00471806526184082 	 0.006571531295776367 	 7.3909759521484375e-06 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:46.380740 test begin: paddle.Tensor.__len__(Tensor([100000, 509],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([100000, 509],"float32"), ) 	 50900000 	 1000 	 0.0064678192138671875 	 0.006456613540649414 	 8.344650268554688e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:47.306306 test begin: paddle.Tensor.__len__(Tensor([23, 1501, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([23, 1501, 1501],"float32"), ) 	 51819023 	 1000 	 0.006511211395263672 	 0.006595134735107422 	 7.62939453125e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:48.252539 test begin: paddle.Tensor.__len__(Tensor([360, 376, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([360, 376, 376],"float32"), ) 	 50895360 	 1000 	 0.0047168731689453125 	 0.004936695098876953 	 5.9604644775390625e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:49.103862 test begin: paddle.Tensor.__len__(Tensor([50, 1501, 677],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([50, 1501, 677],"float32"), ) 	 50808850 	 1000 	 0.006888151168823242 	 0.006829261779785156 	 3.123283386230469e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:49.954931 test begin: paddle.Tensor.__len__(Tensor([50, 677, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([50, 677, 1501],"float32"), ) 	 50808850 	 1000 	 0.004648447036743164 	 0.0050275325775146484 	 5.7220458984375e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:50.795853 test begin: paddle.Tensor.__len__(Tensor([508033, 100],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([508033, 100],"float32"), ) 	 50803300 	 1000 	 0.004590749740600586 	 0.004881381988525391 	 6.4373016357421875e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:51.637506 test begin: paddle.Tensor.__lshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.45030927658081055 	 0.886214017868042 	 0.44112277030944824 	 0.43409061431884766 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:55.786575 test begin: paddle.Tensor.__lshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.4505479335784912 	 0.46024179458618164 	 0.44148707389831543 	 0.43422555923461914 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:58.705544 test begin: paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4477884769439697 	 0.45319485664367676 	 0.4378845691680908 	 0.437450647354126 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:01.648971 test begin: paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.4477872848510742 	 0.4501912593841553 	 0.43863940238952637 	 0.43788671493530273 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:04.578852 test begin: paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.44769763946533203 	 0.45421528816223145 	 0.43844056129455566 	 0.43766307830810547 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:07.529966 test begin: paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.44768691062927246 	 0.4519484043121338 	 0.4385385513305664 	 0.4377481937408447 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:10.511921 test begin: paddle.Tensor.__lt__(Tensor([1034, 3, 64, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([1034, 3, 64, 128],"float64"), 1, ) 	 25411584 	 1000 	 0.4522709846496582 	 0.16838383674621582 	 0.23111510276794434 	 0.15075206756591797 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:11.684535 test begin: paddle.Tensor.__lt__(Tensor([256, 13, 64, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 13, 64, 128],"float64"), 1, ) 	 27262976 	 1000 	 0.48416614532470703 	 0.18010592460632324 	 0.24738502502441406 	 0.16597580909729004 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:12.930275 test begin: paddle.Tensor.__lt__(Tensor([256, 3, 259, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 3, 259, 128],"float64"), 1, ) 	 25460736 	 1000 	 0.4534790515899658 	 0.17987298965454102 	 0.23183488845825195 	 0.1538865566253662 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:14.120691 test begin: paddle.Tensor.__lt__(Tensor([256, 3, 64, 517],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 3, 64, 517],"float64"), 1, ) 	 25411584 	 1000 	 0.45232343673706055 	 0.1684408187866211 	 0.23111462593078613 	 0.14939475059509277 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:15.277120 test begin: paddle.Tensor.__lt__(Tensor([4, 157920, 81],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([4, 157920, 81],"float32"), 0.1111111111111111, ) 	 51166080 	 1000 	 0.47230029106140137 	 0.18727707862854004 	 0.24134349822998047 	 0.17261028289794922 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:16.785432 test begin: paddle.Tensor.__lt__(Tensor([4, 1814401, 7],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([4, 1814401, 7],"float32"), 0.1111111111111111, ) 	 50803228 	 1000 	 0.4690728187561035 	 0.18919777870178223 	 0.23969459533691406 	 0.1712639331817627 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:18.285199 test begin: paddle.Tensor.__lt__(Tensor([46, 157920, 7],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([46, 157920, 7],"float32"), 0.1111111111111111, ) 	 50850240 	 1000 	 0.46902990341186523 	 0.1862325668334961 	 0.23959088325500488 	 0.17140412330627441 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:19.813670 test begin: paddle.Tensor.__lt__(Tensor([50803201],"float32"), 0.7, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([50803201],"float32"), 0.7, ) 	 50803201 	 1000 	 0.4689967632293701 	 0.18610739707946777 	 0.23966050148010254 	 0.1645984649658203 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:21.381605 test begin: paddle.Tensor.__matmul__(Tensor([10, 2304, 2304],"float32"), Tensor([10, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([10, 2304, 2304],"float32"), Tensor([10, 2304, 64],"float32"), ) 	 54558720 	 1000 	 0.9287135601043701 	 0.929133415222168 	 0.9129483699798584 	 0.9056041240692139 	 1.3739237785339355 	 1.3736798763275146 	 0.7020037174224854 	 0.7017970085144043 	 
2025-07-25 17:53:27.026928 test begin: paddle.Tensor.__matmul__(Tensor([111, 3, 392, 392],"float32"), Tensor([111, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([111, 3, 392, 392],"float32"), Tensor([111, 3, 392, 32],"float32"), ) 	 55347264 	 1000 	 1.033050775527954 	 1.0333006381988525 	 1.020582914352417 	 1.0097856521606445 	 1.4490242004394531 	 1.4485278129577637 	 0.7403919696807861 	 0.7400765419006348 	 
2025-07-25 17:53:32.975094 test begin: paddle.Tensor.__matmul__(Tensor([1351, 3, 392, 392],"float32"), Tensor([1351, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([1351, 3, 392, 392],"float32"), Tensor([1351, 3, 392, 32],"float32"), ) 	 673641024 	 1000 	 11.825428485870361 	 11.825985670089722 	 11.812784671783447 	 11.801308870315552 	 16.76865315437317 	 16.8281409740448 	 8.568787813186646 	 8.608712673187256 	 
2025-07-25 17:54:42.571496 test begin: paddle.Tensor.__matmul__(Tensor([176, 2, 392, 392],"float32"), Tensor([176, 2, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 2, 392, 392],"float32"), Tensor([176, 2, 392, 32],"float32"), ) 	 58505216 	 1000 	 1.1021735668182373 	 1.111072063446045 	 1.0896022319793701 	 1.08681058883667 	 1.5476126670837402 	 1.5500013828277588 	 0.7921769618988037 	 0.791867733001709 	 
2025-07-25 17:54:48.953407 test begin: paddle.Tensor.__matmul__(Tensor([176, 24, 392, 392],"float32"), Tensor([176, 24, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 24, 392, 392],"float32"), Tensor([176, 24, 392, 32],"float32"), ) 	 702062592 	 1000 	 12.374122381210327 	 12.374903202056885 	 12.360916376113892 	 12.347465753555298 	 17.531649351119995 	 17.530237913131714 	 8.958960056304932 	 8.957760334014893 	 
2025-07-25 17:56:02.000637 test begin: paddle.Tensor.__matmul__(Tensor([176, 3, 246, 392],"float32"), Tensor([176, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 3, 246, 392],"float32"), Tensor([176, 3, 392, 32],"float32"), ) 	 57539328 	 1000 	 0.7987751960754395 	 0.7986893653869629 	 0.7860558032989502 	 0.7713866233825684 	 1.3481523990631104 	 1.348116397857666 	 0.6888227462768555 	 0.688758373260498 	 
2025-07-25 17:56:07.401341 test begin: paddle.Tensor.__matmul__(Tensor([176, 3, 392, 392],"float32"), Tensor([176, 3, 392, 246],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 3, 392, 392],"float32"), Tensor([176, 3, 392, 246],"float32"), ) 	 132050688 	 1000 	 3.164133071899414 	 3.1652519702911377 	 3.1393580436706543 	 3.127507448196411 	 7.156742811203003 	 7.15773344039917 	 3.657414436340332 	 3.657594680786133 	 
2025-07-25 17:56:33.382954 test begin: paddle.Tensor.__matmul__(Tensor([345, 2304, 2304],"float32"), Tensor([345, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([345, 2304, 2304],"float32"), Tensor([345, 2304, 64],"float32"), ) 	 1882275840 	 1000 	 26.61942172050476 	 26.61966633796692 	 26.606611728668213 	 26.595630645751953 	 41.710700273513794 	 41.711705684661865 	 21.315284490585327 	 21.31430149078369 	 
2025-07-25 17:59:23.746321 test begin: paddle.Tensor.__matmul__(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 64],"float32"), ) 	 54591488 	 1000 	 0.8284187316894531 	 1.05047607421875 	 0.8157978057861328 	 0.8042581081390381 	 1.260368824005127 	 1.2609429359436035 	 0.6439745426177979 	 0.6442294120788574 	 
2025-07-25 17:59:31.389245 test begin: paddle.Tensor.__matmul__(Tensor([60, 2304, 2304],"float32"), Tensor([60, 2304, 368],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([60, 2304, 2304],"float32"), Tensor([60, 2304, 368],"float32"), ) 	 369377280 	 1000 	 13.775537490844727 	 13.775340557098389 	 13.75510025024414 	 13.748268842697144 	 27.200613975524902 	 27.210432291030884 	 13.899218320846558 	 13.904512166976929 	 
2025-07-25 18:01:01.142253 test begin: paddle.Tensor.__matmul__(Tensor([60, 368, 2304],"float32"), Tensor([60, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([60, 368, 2304],"float32"), Tensor([60, 2304, 64],"float32"), ) 	 59719680 	 1000 	 0.9283742904663086 	 0.9283795356750488 	 0.9078505039215088 	 0.8957726955413818 	 1.1963553428649902 	 1.1966667175292969 	 0.6112661361694336 	 0.6114020347595215 	 
2025-07-25 18:01:07.644884 test begin: paddle.Tensor.__matmul__(Tensor([776, 1024, 1024],"float32"), Tensor([776, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([776, 1024, 1024],"float32"), Tensor([776, 1024, 64],"float32"), ) 	 864550912 	 1000 	 11.867001056671143 	 11.867078065872192 	 11.846399545669556 	 11.843671560287476 	 18.528663158416748 	 18.51943874359131 	 9.468067169189453 	 9.463239669799805 	 
2025-07-25 18:02:24.821543 test begin: paddle.Tensor.__matmul__(Tensor([96, 1024, 1024],"float32"), Tensor([96, 1024, 517],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([96, 1024, 1024],"float32"), Tensor([96, 1024, 517],"float32"), ) 	 151486464 	 1000 	 7.372026681900024 	 7.375377178192139 	 7.351368188858032 	 7.34559178352356 	 13.34486436843872 	 13.350818872451782 	 6.8191046714782715 	 6.822167158126831 	 
2025-07-25 18:03:10.580077 test begin: paddle.Tensor.__matmul__(Tensor([96, 517, 1024],"float32"), Tensor([96, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([96, 517, 1024],"float32"), Tensor([96, 1024, 64],"float32"), ) 	 57114624 	 1000 	 1.031940221786499 	 1.0356416702270508 	 1.010436773300171 	 0.9983720779418945 	 1.3707258701324463 	 1.3707280158996582 	 0.7003419399261475 	 0.7002863883972168 	 
2025-07-25 18:03:16.432927 test begin: paddle.Tensor.__mod__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4472627639770508 	 0.450944185256958 	 0.4380686283111572 	 0.43558788299560547 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:19.392529 test begin: paddle.Tensor.__mod__(Tensor([13, 2, 976985],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([13, 2, 976985],"int64"), 16, ) 	 25401610 	 1000 	 0.5828087329864502 	 0.29927945137023926 	 0.297762393951416 	 0.2778658866882324 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:21.501201 test begin: paddle.Tensor.__mod__(Tensor([13, 30531, 64],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([13, 30531, 64],"int64"), 16, ) 	 25401792 	 1000 	 0.582594633102417 	 0.29918766021728516 	 0.29766249656677246 	 0.285139799118042 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:23.515685 test begin: paddle.Tensor.__mod__(Tensor([198451, 2, 64],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([198451, 2, 64],"int64"), 16, ) 	 25401728 	 1000 	 0.5828158855438232 	 0.29917144775390625 	 0.2978074550628662 	 0.28503942489624023 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:25.529698 test begin: paddle.Tensor.__mod__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4478590488433838 	 0.44864845275878906 	 0.4364333152770996 	 0.4357290267944336 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:28.428607 test begin: paddle.Tensor.__mod__(Tensor([26, 976985],"int64"), 64, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([26, 976985],"int64"), 64, ) 	 25401610 	 1000 	 0.5828146934509277 	 0.2991619110107422 	 0.29778146743774414 	 0.2851095199584961 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:30.447481 test begin: paddle.Tensor.__mod__(Tensor([396901, 64],"int64"), 64, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([396901, 64],"int64"), 64, ) 	 25401664 	 1000 	 0.582507848739624 	 0.29923152923583984 	 0.2976248264312744 	 0.28516316413879395 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:03:32.515602 test begin: paddle.Tensor.__mul__(Tensor([1, 1, 32768, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([1, 1, 32768, 32768],"float16"), 10000.0, ) 	 1073741824 	 1000 	 3.104710340499878 	 3.0921432971954346 	 3.0939724445343018 	 3.072150468826294 	 3.104987621307373 	 3.0912868976593018 	 3.0522050857543945 	 3.023548126220703 	 
2025-07-25 18:04:26.045220 test begin: paddle.Tensor.__mul__(Tensor([108544, 469],"float32"), Tensor([108544, 469],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([108544, 469],"float32"), Tensor([108544, 469],"float32"), ) 	 101814272 	 1000 	 0.4508981704711914 	 0.45264291763305664 	 0.44150424003601074 	 0.4334115982055664 	 1.10695481300354 	 0.8949520587921143 	 1.0443942546844482 	 0.4572560787200928 	 
2025-07-25 18:04:31.527573 test begin: paddle.Tensor.__mul__(Tensor([111616, 456],"float32"), Tensor([111616, 456],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([111616, 456],"float32"), Tensor([111616, 456],"float32"), ) 	 101793792 	 1000 	 0.4509305953979492 	 0.675856351852417 	 0.44156837463378906 	 0.43366146087646484 	 1.2167766094207764 	 0.8948206901550293 	 1.1532597541809082 	 0.457150936126709 	 
2025-07-25 18:04:40.178250 test begin: paddle.Tensor.__mul__(Tensor([14176, 3584],"float32"), Tensor([14176, 3584],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([14176, 3584],"float32"), Tensor([14176, 3584],"float32"), ) 	 101613568 	 1000 	 0.4500002861022949 	 0.4467635154724121 	 0.4407644271850586 	 0.43303775787353516 	 1.106370449066162 	 0.8931107521057129 	 1.0430774688720703 	 0.4563465118408203 	 
2025-07-25 18:04:45.574300 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 1551, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 1551, 32768],"float16"), 10000.0, ) 	 101646336 	 1000 	 0.2983052730560303 	 0.2971820831298828 	 0.28959226608276367 	 0.28226637840270996 	 0.29833030700683594 	 0.29620909690856934 	 0.2387101650238037 	 0.2242264747619629 	 
2025-07-25 18:04:50.594229 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 32768, 1551],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 32768, 1551],"float16"), 10000.0, ) 	 101646336 	 1000 	 0.29830336570739746 	 0.3014187812805176 	 0.2896251678466797 	 0.28234195709228516 	 0.2983078956604004 	 0.29620957374572754 	 0.2424027919769287 	 0.2265620231628418 	 
2025-07-25 18:04:55.592765 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 32768, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 32768, 32768],"float16"), 10000.0, ) 	 2147483648 	 1000 	 7.3909385204315186 	 6.185213565826416 	 6.196685791015625 	 3.15954327583313 	 6.206323623657227 	 6.183078050613403 	 6.153219223022461 	 3.1594929695129395 	 
2025-07-25 18:06:48.549582 test begin: paddle.Tensor.__ne__(Tensor([144, 392, 901],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([144, 392, 901],"float32"), 0, ) 	 50859648 	 1000 	 0.471449613571167 	 0.19098758697509766 	 0.24094796180725098 	 0.17166900634765625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:50.126460 test begin: paddle.Tensor.__ne__(Tensor([144, 901, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([144, 901, 392],"float32"), 0, ) 	 50859648 	 1000 	 0.4714992046356201 	 0.18636441230773926 	 0.24088358879089355 	 0.1655106544494629 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:51.642526 test begin: paddle.Tensor.__ne__(Tensor([160, 392, 811],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([160, 392, 811],"float32"), 0, ) 	 50865920 	 1000 	 0.4718797206878662 	 0.18837237358093262 	 0.24112534523010254 	 0.17220258712768555 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:53.155406 test begin: paddle.Tensor.__ne__(Tensor([160, 811, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([160, 811, 392],"float32"), 0, ) 	 50865920 	 1000 	 0.47176027297973633 	 0.18630242347717285 	 0.24102473258972168 	 0.1722860336303711 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:54.685337 test begin: paddle.Tensor.__ne__(Tensor([176, 392, 737],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([176, 392, 737],"float32"), 0, ) 	 50847104 	 1000 	 0.47159862518310547 	 0.18622612953186035 	 0.24097132682800293 	 0.17209839820861816 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:56.197066 test begin: paddle.Tensor.__ne__(Tensor([176, 737, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([176, 737, 392],"float32"), 0, ) 	 50847104 	 1000 	 0.47159433364868164 	 0.18626952171325684 	 0.24098539352416992 	 0.16467595100402832 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:57.769517 test begin: paddle.Tensor.__ne__(Tensor([331, 392, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([331, 392, 392],"float32"), 0, ) 	 50862784 	 1000 	 0.4717884063720703 	 0.19754886627197266 	 0.24112200736999512 	 0.17208623886108398 	 None 	 None 	 None 	 None 	 
2025-07-25 18:06:59.307304 test begin: paddle.Tensor.__neg__(Tensor([128, 396901],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2955026626586914 	 0.30066442489624023 	 0.2863445281982422 	 0.2873530387878418 	 0.2956678867340088 	 0.29775285720825195 	 0.24246501922607422 	 0.23113584518432617 	 
2025-07-25 18:07:02.184312 test begin: paddle.Tensor.__neg__(Tensor([128, 793801],"float16"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([128, 793801],"float16"), ) 	 101606528 	 1000 	 0.29850149154663086 	 0.2963738441467285 	 0.28980112075805664 	 0.28621840476989746 	 0.29858970642089844 	 0.2961256504058838 	 0.23727893829345703 	 0.22974467277526855 	 
2025-07-25 18:07:07.247824 test begin: paddle.Tensor.__neg__(Tensor([22, 81, 94, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([22, 81, 94, 311],"float32"), ) 	 52094988 	 1000 	 0.3031771183013916 	 0.32801294326782227 	 0.29430103302001953 	 0.2947211265563965 	 0.3030540943145752 	 0.30515432357788086 	 0.249985933303833 	 0.23795485496520996 	 
2025-07-25 18:07:12.967336 test begin: paddle.Tensor.__neg__(Tensor([264, 192612],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([264, 192612],"float32"), ) 	 50849568 	 1000 	 0.2960166931152344 	 0.2982027530670166 	 0.28728437423706055 	 0.2877967357635498 	 0.29605603218078613 	 0.29794740676879883 	 0.24161171913146973 	 0.23340678215026855 	 
2025-07-25 18:07:15.857048 test begin: paddle.Tensor.__neg__(Tensor([4, 435, 94, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 435, 94, 311],"float32"), ) 	 50867160 	 1000 	 0.29608702659606934 	 0.3023650646209717 	 0.287172794342041 	 0.28752970695495605 	 0.2961912155151367 	 0.29816746711730957 	 0.24291205406188965 	 0.23147106170654297 	 
2025-07-25 18:07:18.738730 test begin: paddle.Tensor.__neg__(Tensor([4, 81, 505, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 81, 505, 311],"float32"), ) 	 50885820 	 1000 	 0.2961239814758301 	 0.2992706298828125 	 0.28728413581848145 	 0.28769397735595703 	 0.29636073112487793 	 0.29822468757629395 	 0.24249577522277832 	 0.22947382926940918 	 
2025-07-25 18:07:21.678839 test begin: paddle.Tensor.__neg__(Tensor([4, 81, 94, 1669],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 81, 94, 1669],"float32"), ) 	 50831064 	 1000 	 0.29598331451416016 	 0.29985713958740234 	 0.27968406677246094 	 0.28099608421325684 	 0.2960999011993408 	 0.297957181930542 	 0.23409247398376465 	 0.22865843772888184 	 
2025-07-25 18:07:24.565061 test begin: paddle.Tensor.__neg__(Tensor([528, 192612],"float16"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([528, 192612],"float16"), ) 	 101699136 	 1000 	 0.29883813858032227 	 0.2965736389160156 	 0.2900214195251465 	 0.2861149311065674 	 0.29885315895080566 	 0.29636383056640625 	 0.24509286880493164 	 0.22588348388671875 	 
2025-07-25 18:07:29.624816 test begin: paddle.Tensor.__or__(Tensor([1, 210, 241921],"bool"), Tensor([1, 210, 241921],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 210, 241921],"bool"), Tensor([1, 210, 241921],"bool"), ) 	 101606820 	 1000 	 0.11780667304992676 	 0.11665701866149902 	 0.10943961143493652 	 0.10449528694152832 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:31.355154 test begin: paddle.Tensor.__or__(Tensor([1, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), ) 	 79380000 	 1000 	 0.16166472434997559 	 0.2780721187591553 	 0.15214109420776367 	 0.2649965286254883 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:32.986257 test begin: paddle.Tensor.__or__(Tensor([1, 218, 233043],"bool"), Tensor([1, 218, 233043],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 218, 233043],"bool"), Tensor([1, 218, 233043],"bool"), ) 	 101606748 	 1000 	 0.11782145500183105 	 0.11746072769165039 	 0.1094350814819336 	 0.1046304702758789 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:34.649148 test begin: paddle.Tensor.__or__(Tensor([1, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), ) 	 77001960 	 1000 	 0.15714383125305176 	 0.28406405448913574 	 0.14693665504455566 	 0.256075382232666 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:39.961229 test begin: paddle.Tensor.__or__(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"bool"), ) 	 101607200 	 1000 	 0.1170811653137207 	 0.12265300750732422 	 0.10863828659057617 	 0.10466361045837402 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:41.853025 test begin: paddle.Tensor.__or__(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), ) 	 79027200 	 1000 	 0.1347501277923584 	 0.23183369636535645 	 0.12521672248840332 	 0.2187516689300537 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:43.325639 test begin: paddle.Tensor.__or__(Tensor([1, 673, 75600],"bool"), Tensor([1, 673, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 673, 75600],"bool"), Tensor([1, 673, 75600],"bool"), ) 	 101757600 	 1000 	 0.11737680435180664 	 0.11632561683654785 	 0.10891962051391602 	 0.10228824615478516 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:44.998164 test begin: paddle.Tensor.__or__(Tensor([1, 720, 70644],"bool"), Tensor([1, 720, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 720, 70644],"bool"), Tensor([1, 720, 70644],"bool"), ) 	 101727360 	 1000 	 0.1178286075592041 	 0.1161339282989502 	 0.10930037498474121 	 0.10402274131774902 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:46.680423 test begin: paddle.Tensor.__or__(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"bool"), ) 	 101681664 	 1000 	 0.11797738075256348 	 0.11511349678039551 	 0.10236883163452148 	 0.09632182121276855 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:48.358889 test begin: paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"bool"), ) 	 79027200 	 1000 	 0.17508554458618164 	 0.23182225227355957 	 0.1647803783416748 	 0.21874475479125977 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:49.915527 test begin: paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), ) 	 105369600 	 1000 	 0.1211540699005127 	 0.11899685859680176 	 0.11243081092834473 	 0.10700607299804688 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:51.646141 test begin: paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([1, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([1, 210, 75600],"bool"), ) 	 79380000 	 1000 	 0.21141314506530762 	 0.2781062126159668 	 0.2019948959350586 	 0.26497530937194824 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:53.268767 test begin: paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), ) 	 127008000 	 1000 	 0.1458117961883545 	 0.1435389518737793 	 0.1373612880706787 	 0.13138055801391602 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:55.320415 test begin: paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([1, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([1, 218, 70644],"bool"), ) 	 77001960 	 1000 	 0.2046506404876709 	 0.27352356910705566 	 0.19515681266784668 	 0.2560238838195801 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:56.878581 test begin: paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), ) 	 123203136 	 1000 	 0.14067411422729492 	 0.14890074729919434 	 0.13219690322875977 	 0.12776565551757812 	 None 	 None 	 None 	 None 	 
2025-07-25 18:07:58.948096 test begin: paddle.Tensor.__pow__(Tensor([23, 17, 256, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([23, 17, 256, 256],"float64"), 2, ) 	 25624576 	 1000 	 0.5771591663360596 	 0.30106568336486816 	 0.5685813426971436 	 0.2838132381439209 	 0.6094303131103516 	 1.0603079795837402 	 0.5532965660095215 	 0.36119604110717773 	 
2025-07-25 18:08:02.656246 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 244, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 244, 256],"float64"), 2, ) 	 25485312 	 1000 	 0.574282169342041 	 0.3016226291656494 	 0.5655252933502197 	 0.2817826271057129 	 0.6068408489227295 	 1.0544371604919434 	 0.551624059677124 	 0.3592112064361572 	 
2025-07-25 18:08:06.330467 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 256, 244],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 256, 244],"float64"), 2, ) 	 25485312 	 1000 	 0.5742993354797363 	 0.2994565963745117 	 0.5655641555786133 	 0.28175783157348633 	 0.6070029735565186 	 1.0546367168426514 	 0.5451533794403076 	 0.3592875003814697 	 
2025-07-25 18:08:09.955304 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 256, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 256, 256],"float64"), 2, ) 	 26738688 	 1000 	 0.6022140979766846 	 0.31372737884521484 	 0.5934646129608154 	 0.29644298553466797 	 0.6364049911499023 	 1.1058964729309082 	 0.581031084060669 	 0.3767364025115967 	 
2025-07-25 18:08:16.172179 test begin: paddle.Tensor.__pow__(Tensor([259, 3, 256, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([259, 3, 256, 256],"float32"), 2, ) 	 50921472 	 1000 	 0.36922621726989746 	 0.31401753425598145 	 0.360271692276001 	 0.2736845016479492 	 0.4532949924468994 	 1.0548217296600342 	 0.39641642570495605 	 0.3593330383300781 	 
2025-07-25 18:08:21.206541 test begin: paddle.Tensor.__pow__(Tensor([28, 32, 241, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([28, 32, 241, 241],"float32"), 2, ) 	 52040576 	 1000 	 0.37748098373413086 	 0.305006742477417 	 0.368593692779541 	 0.2872581481933594 	 0.46249866485595703 	 1.0808358192443848 	 0.4072127342224121 	 0.2763478755950928 	 
2025-07-25 18:08:25.192497 test begin: paddle.Tensor.__pow__(Tensor([64, 13, 256, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 13, 256, 256],"float32"), 2, ) 	 54525952 	 1000 	 0.39512038230895996 	 0.32681822776794434 	 0.3858001232147217 	 0.3018827438354492 	 0.48483967781066895 	 1.12925386428833 	 0.42809414863586426 	 0.38466835021972656 	 
2025-07-25 18:08:29.357815 test begin: paddle.Tensor.__pow__(Tensor([64, 3, 1034, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 3, 1034, 256],"float32"), 2, ) 	 50823168 	 1000 	 0.3686826229095459 	 0.29809117317199707 	 0.35988783836364746 	 0.2807183265686035 	 0.4524872303009033 	 1.052891731262207 	 0.3961315155029297 	 0.35870885848999023 	 
2025-07-25 18:08:33.288023 test begin: paddle.Tensor.__pow__(Tensor([64, 3, 256, 1034],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 3, 256, 1034],"float32"), 2, ) 	 50823168 	 1000 	 0.3686232566833496 	 1.0806150436401367 	 0.3597679138183594 	 0.28102827072143555 	 0.45247316360473633 	 1.0530529022216797 	 0.3943140506744385 	 0.3586752414703369 	 
2025-07-25 18:08:40.999364 test begin: paddle.Tensor.__pow__(Tensor([8, 110, 241, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 110, 241, 241],"float32"), 2, ) 	 51111280 	 1000 	 0.37067341804504395 	 0.2997136116027832 	 0.3618032932281494 	 0.28183507919311523 	 0.45430874824523926 	 1.0616297721862793 	 0.3983802795410156 	 0.2714223861694336 	 
2025-07-25 18:08:44.985566 test begin: paddle.Tensor.__pow__(Tensor([8, 32, 241, 824],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 32, 241, 824],"float32"), 2, ) 	 50837504 	 1000 	 0.36870455741882324 	 0.2981140613555908 	 0.3599236011505127 	 0.2810389995574951 	 0.45261144638061523 	 1.0532708168029785 	 0.39658641815185547 	 0.35881733894348145 	 
2025-07-25 18:08:48.936924 test begin: paddle.Tensor.__pow__(Tensor([8, 32, 824, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 32, 824, 241],"float32"), 2, ) 	 50837504 	 1000 	 0.36865234375 	 0.3011157512664795 	 0.35971736907958984 	 0.2810239791870117 	 0.45258378982543945 	 1.053297996520996 	 0.396838903427124 	 0.35884976387023926 	 
2025-07-25 18:08:52.870348 test begin: paddle.Tensor.__radd__(Tensor([192, 104, 32, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 104, 32, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.30008625984191895 	 0.2981142997741699 	 0.29110288619995117 	 0.28318285942077637 	 0.30002832412719727 	 0.052704572677612305 	 0.24681663513183594 	 4.673004150390625e-05 	 
2025-07-25 18:08:57.681678 test begin: paddle.Tensor.__radd__(Tensor([192, 128, 16, 259],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 128, 16, 259],"float16"), 0, ) 	 101842944 	 1000 	 0.2988569736480713 	 0.29697322845458984 	 0.29013729095458984 	 0.2824680805206299 	 0.2989335060119629 	 0.05274558067321777 	 0.24588513374328613 	 4.076957702636719e-05 	 
2025-07-25 18:09:02.529042 test begin: paddle.Tensor.__radd__(Tensor([192, 128, 26, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 128, 26, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.30006885528564453 	 0.29809045791625977 	 0.29134535789489746 	 0.2838423252105713 	 0.3000342845916748 	 0.05288338661193848 	 0.24692654609680176 	 4.5299530029296875e-05 	 
2025-07-25 18:09:07.492858 test begin: paddle.Tensor.__radd__(Tensor([192, 207, 16, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 207, 16, 160],"float16"), 0, ) 	 101744640 	 1000 	 0.29865193367004395 	 0.29903697967529297 	 0.29003071784973145 	 0.2797205448150635 	 0.29857683181762695 	 0.05313897132873535 	 0.24495720863342285 	 5.9604644775390625e-05 	 
2025-07-25 18:09:12.317620 test begin: paddle.Tensor.__radd__(Tensor([192, 240, 16, 138],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 240, 16, 138],"float16"), 0, ) 	 101744640 	 1000 	 0.2986173629760742 	 0.29673337936401367 	 0.2898702621459961 	 0.2817227840423584 	 0.29859137535095215 	 0.05267071723937988 	 0.24531245231628418 	 5.340576171875e-05 	 
2025-07-25 18:09:17.236018 test begin: paddle.Tensor.__radd__(Tensor([192, 240, 28, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 240, 28, 80],"float16"), 0, ) 	 103219200 	 1000 	 0.3027925491333008 	 0.31435227394104004 	 0.29404139518737793 	 0.28638172149658203 	 0.30299878120422363 	 0.05276226997375488 	 0.24922657012939453 	 4.76837158203125e-05 	 
2025-07-25 18:09:23.274153 test begin: paddle.Tensor.__radd__(Tensor([192, 414, 16, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 414, 16, 80],"float16"), 0, ) 	 101744640 	 1000 	 0.29863762855529785 	 0.29671287536621094 	 0.28997087478637695 	 0.28227758407592773 	 0.2985818386077881 	 0.054769277572631836 	 0.24491238594055176 	 4.3392181396484375e-05 	 
2025-07-25 18:09:28.187230 test begin: paddle.Tensor.__radd__(Tensor([192, 64, 32, 259],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 64, 32, 259],"float16"), 0, ) 	 101842944 	 1000 	 0.29889655113220215 	 0.2969551086425781 	 0.29023075103759766 	 0.2823493480682373 	 0.29894399642944336 	 0.05262637138366699 	 0.2388148307800293 	 3.647804260253906e-05 	 
2025-07-25 18:09:32.995478 test begin: paddle.Tensor.__radd__(Tensor([192, 64, 52, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 64, 52, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.30008840560913086 	 0.3040454387664795 	 0.29143571853637695 	 0.28157806396484375 	 0.30003976821899414 	 0.0533599853515625 	 0.24636602401733398 	 2.9087066650390625e-05 	 
2025-07-25 18:09:39.933727 test begin: paddle.Tensor.__radd__(Tensor([311, 128, 16, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([311, 128, 16, 160],"float16"), 0, ) 	 101908480 	 1000 	 0.2990543842315674 	 0.29924988746643066 	 0.29019999504089355 	 0.2826113700866699 	 0.29921627044677734 	 0.053292274475097656 	 0.24581408500671387 	 4.863739013671875e-05 	 
2025-07-25 18:09:45.329890 test begin: paddle.Tensor.__radd__(Tensor([311, 64, 32, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([311, 64, 32, 160],"float16"), 0, ) 	 101908480 	 1000 	 0.2990429401397705 	 0.2970879077911377 	 0.29032254219055176 	 0.28200292587280273 	 0.2992208003997803 	 0.053191184997558594 	 0.2450580596923828 	 6.222724914550781e-05 	 
2025-07-25 18:09:50.205834 test begin: paddle.Tensor.__radd__(Tensor([331, 240, 16, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([331, 240, 16, 80],"float16"), 0, ) 	 101683200 	 1000 	 0.2984278202056885 	 0.29651522636413574 	 0.28972554206848145 	 0.2820310592651367 	 0.2983858585357666 	 0.053733110427856445 	 0.24537253379821777 	 7.271766662597656e-05 	 
2025-07-25 18:09:54.994550 test begin: paddle.Tensor.__rlshift__(Tensor([169345, 300],"int32"), -223, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([169345, 300],"int32"), -223, ) 	 50803500 	 1000 	 0.2983095645904541 	 0.2989504337310791 	 0.15236449241638184 	 0.27751636505126953 	 None 	 None 	 None 	 None 	 
2025-07-25 18:09:56.195644 test begin: paddle.Tensor.__rlshift__(Tensor([200, 254017],"int32"), -223, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 254017],"int32"), -223, ) 	 50803400 	 1000 	 0.2984354496002197 	 0.29793477058410645 	 0.15244746208190918 	 0.27614331245422363 	 None 	 None 	 None 	 None 	 
2025-07-25 18:09:57.383925 test begin: paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), -212, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), -212, ) 	 101606600 	 1000 	 0.33452796936035156 	 0.295133113861084 	 0.0003056526184082031 	 0.2757382392883301 	 None 	 None 	 None 	 None 	 
2025-07-25 18:09:59.010589 test begin: paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), 63, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), 63, ) 	 101606600 	 1000 	 0.3358438014984131 	 0.2999000549316406 	 0.0002989768981933594 	 0.2751798629760742 	 None 	 None 	 None 	 None 	 
2025-07-25 18:10:00.644556 test begin: paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), -212, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), -212, ) 	 101606700 	 1000 	 0.33696579933166504 	 0.2950742244720459 	 0.00030422210693359375 	 0.2754356861114502 	 None 	 None 	 None 	 None 	 
2025-07-25 18:10:02.287957 test begin: paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), 63, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), 63, ) 	 101606700 	 1000 	 0.3380305767059326 	 0.2951653003692627 	 0.0003063678741455078 	 0.26885175704956055 	 None 	 None 	 None 	 None 	 
2025-07-25 18:10:03.976419 test begin: paddle.Tensor.__rmatmul__(Tensor([10160641, 5],"float32"), Tensor([2, 10160641],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([10160641, 5],"float32"), Tensor([2, 10160641],"float32"), ) 	 71124487 	 1000 	 1.3851394653320312 	 1.3847217559814453 	 0.7077391147613525 	 0.7075011730194092 	 2.0924108028411865 	 2.0919713973999023 	 0.10686993598937988 	 0.1068418025970459 	 
2025-07-25 18:10:12.150159 test begin: paddle.Tensor.__rmatmul__(Tensor([25401601, 5],"float32"), Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([25401601, 5],"float32"), Tensor([2, 25401601],"float32"), ) 	 177811207 	 1000 	 3.3993523120880127 	 3.395991802215576 	 1.7370021343231201 	 1.7353239059448242 	 5.229841232299805 	 5.230636835098267 	 0.10688471794128418 	 0.10685610771179199 	 
2025-07-25 18:10:34.025383 test begin: paddle.Tensor.__rmatmul__(Tensor([3, 16934401],"float32"), Tensor([2, 3],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([3, 16934401],"float32"), Tensor([2, 3],"float32"), ) 	 50803209 	 1000 	 0.7624735832214355 	 0.7758605480194092 	 0.04580545425415039 	 0.04598093032836914 	 4.098223686218262 	 4.094212293624878 	 0.21866655349731445 	 0.22061491012573242 	 
2025-07-25 18:10:45.258734 test begin: paddle.Tensor.__rmatmul__(Tensor([3, 5],"float32"), Tensor([16934401, 3],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([3, 5],"float32"), Tensor([16934401, 3],"float32"), ) 	 50803218 	 1000 	 1.7829947471618652 	 1.7833561897277832 	 0.1071004867553711 	 0.10714530944824219 	 4.185732364654541 	 4.185431480407715 	 0.22561097145080566 	 0.22338104248046875 	 
2025-07-25 18:10:59.554107 test begin: paddle.Tensor.__rmod__(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), ) 	 101606412 	 1000 	 0.45035552978515625 	 0.44931602478027344 	 0.440767765045166 	 0.43309760093688965 	 1.1084210872650146 	 1.1970024108886719 	 1.0455124378204346 	 0.4077160358428955 	 
2025-07-25 18:11:05.257821 test begin: paddle.Tensor.__rmod__(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), ) 	 101606416 	 1000 	 0.4502532482147217 	 0.46485328674316406 	 0.4386296272277832 	 0.4330904483795166 	 1.1085224151611328 	 1.1969497203826904 	 1.0461921691894531 	 0.4076242446899414 	 
2025-07-25 18:11:12.170793 test begin: paddle.Tensor.__rmod__(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), ) 	 101606424 	 1000 	 0.4502589702606201 	 0.4493274688720703 	 0.44072389602661133 	 0.43340396881103516 	 1.1087779998779297 	 1.1968185901641846 	 1.0460569858551025 	 0.4075901508331299 	 
2025-07-25 18:11:17.901355 test begin: paddle.Tensor.__rmul__(Tensor([176, 392, 737],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([176, 392, 737],"float32"), -100.0, ) 	 50847104 	 1000 	 0.295788049697876 	 0.2981705665588379 	 0.2795836925506592 	 0.2768590450286865 	 0.29603004455566406 	 0.2979717254638672 	 0.2107686996459961 	 0.22698068618774414 	 
2025-07-25 18:11:20.919322 test begin: paddle.Tensor.__rmul__(Tensor([176, 737, 392],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([176, 737, 392],"float32"), -100.0, ) 	 50847104 	 1000 	 0.29575681686401367 	 0.2981879711151123 	 0.2856454849243164 	 0.283954381942749 	 0.2959630489349365 	 0.2979755401611328 	 0.24289727210998535 	 0.2313401699066162 	 
2025-07-25 18:11:23.758203 test begin: paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 0.75, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 0.75, ) 	 50868000 	 1000 	 0.2960548400878906 	 0.3019578456878662 	 0.2799193859100342 	 0.27701377868652344 	 0.29624032974243164 	 0.298203706741333 	 0.23432374000549316 	 0.2235853672027588 	 
2025-07-25 18:11:26.722151 test begin: paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 1.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 1.0, ) 	 50868000 	 1000 	 0.29607295989990234 	 0.2983403205871582 	 0.2796027660369873 	 0.27710676193237305 	 0.2962369918823242 	 0.2982509136199951 	 0.23379945755004883 	 0.22472143173217773 	 
2025-07-25 18:11:29.616228 test begin: paddle.Tensor.__rmul__(Tensor([331, 392, 392],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([331, 392, 392],"float32"), -100.0, ) 	 50862784 	 1000 	 0.296032190322876 	 0.2983133792877197 	 0.2867574691772461 	 0.2839343547821045 	 0.29630494117736816 	 0.29818153381347656 	 0.24308204650878906 	 0.23020172119140625 	 
2025-07-25 18:11:32.874271 test begin: paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 0.75, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 0.75, ) 	 50803280 	 1000 	 0.29549312591552734 	 0.31906676292419434 	 0.28299546241760254 	 0.2834053039550781 	 0.29567813873291016 	 0.29775190353393555 	 0.24262213706970215 	 0.2311410903930664 	 
2025-07-25 18:11:37.990966 test begin: paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 1.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 1.0, ) 	 50803280 	 1000 	 0.29544615745544434 	 0.31424856185913086 	 0.28682518005371094 	 0.2838156223297119 	 0.2957274913787842 	 0.2977263927459717 	 0.24254369735717773 	 0.22834563255310059 	 
2025-07-25 18:11:42.879118 test begin: paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), 5, ) 	 50803206 	 1000 	 0.298520565032959 	 0.3217284679412842 	 0.15247058868408203 	 0.28310465812683105 	 None 	 None 	 None 	 None 	 
2025-07-25 18:11:44.128006 test begin: paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), True, ) 	 50803206 	 1000 	 0.2985661029815674 	 0.3059513568878174 	 0.1525118350982666 	 0.2827637195587158 	 None 	 None 	 None 	 None 	 
2025-07-25 18:11:45.299621 test begin: paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), 5, ) 	 50803210 	 1000 	 0.2985377311706543 	 0.2979464530944824 	 0.1524662971496582 	 0.27570414543151855 	 None 	 None 	 None 	 None 	 
2025-07-25 18:11:46.491412 test begin: paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), True, ) 	 50803210 	 1000 	 0.2985198497772217 	 0.2979466915130615 	 0.15245604515075684 	 0.2832043170928955 	 None 	 None 	 None 	 None 	 
2025-07-25 18:11:47.678019 test begin: paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), 5, ) 	 50803215 	 1000 	 0.2985110282897949 	 0.29795312881469727 	 0.152479887008667 	 0.28288841247558594 	 None 	 None 	 None 	 None 	 
2025-07-25 18:11:48.865394 test begin: paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), True, ) 	 50803215 	 1000 	 0.29849934577941895 	 0.2979304790496826 	 0.15246176719665527 	 0.2832362651824951 	 None 	 None 	 None 	 None 	 
2025-07-25 18:11:50.063949 test begin: paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000, )
[Prof] paddle.Tensor.__rpow__ 	 paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000, ) 	 50803201 	 1000 	 0.584200382232666 	 0.6368405818939209 	 0.29848718643188477 	 0.3219602108001709 	 0.7022979259490967 	 0.7430126667022705 	 0.6474747657775879 	 0.37960195541381836 	 
2025-07-25 18:11:54.521078 test begin: paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000.0, )
[Prof] paddle.Tensor.__rpow__ 	 paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000.0, ) 	 50803201 	 1000 	 0.5842580795288086 	 0.644355058670044 	 0.2985868453979492 	 0.32912540435791016 	 0.7025306224822998 	 0.7430510520935059 	 0.6477656364440918 	 0.37961840629577637 	 
2025-07-25 18:11:59.004500 test begin: paddle.Tensor.__rrshift__(Tensor([169345, 300],"int32"), 232, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([169345, 300],"int32"), 232, ) 	 50803500 	 1000 	 0.2983982563018799 	 0.29961180686950684 	 0.1523892879486084 	 0.27086567878723145 	 None 	 None 	 None 	 None 	 
2025-07-25 18:12:00.207073 test begin: paddle.Tensor.__rrshift__(Tensor([200, 254017],"int32"), 232, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 254017],"int32"), 232, ) 	 50803400 	 1000 	 0.2983589172363281 	 0.29801297187805176 	 0.152388334274292 	 0.2708089351654053 	 None 	 None 	 None 	 None 	 
2025-07-25 18:12:01.455457 test begin: paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), -255, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), -255, ) 	 101606600 	 1000 	 0.3421206474304199 	 0.29624128341674805 	 0.00030231475830078125 	 0.2771615982055664 	 None 	 None 	 None 	 None 	 
2025-07-25 18:12:03.107701 test begin: paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), 11, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), 11, ) 	 101606600 	 1000 	 0.3417186737060547 	 0.2961258888244629 	 0.0003037452697753906 	 0.27683424949645996 	 None 	 None 	 None 	 None 	 
2025-07-25 18:12:04.784384 test begin: paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), -255, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), -255, ) 	 101606700 	 1000 	 0.3425719738006592 	 0.29612040519714355 	 0.0003132820129394531 	 0.276292085647583 	 None 	 None 	 None 	 None 	 
2025-07-25 18:12:06.469476 test begin: paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), 11, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), 11, ) 	 101606700 	 1000 	 0.33828258514404297 	 0.2969784736633301 	 0.00030994415283203125 	 0.2766849994659424 	 None 	 None 	 None 	 None 	 
2025-07-25 18:12:08.138673 test begin: paddle.Tensor.__rshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.449723482131958 	 0.44678330421447754 	 0.4405193328857422 	 0.43495655059814453 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:12:10.208737 test begin: paddle.Tensor.__rshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.4501044750213623 	 0.4467008113861084 	 0.4409935474395752 	 0.4324367046356201 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:12:12.314730 test begin: paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.44719386100769043 	 0.45378756523132324 	 0.43804359436035156 	 0.43787479400634766 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:12:15.342583 test begin: paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.44791197776794434 	 3.112375259399414 	 0.428957462310791 	 0.353529691696167 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:12:20.983725 test begin: paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.44707798957824707 	 0.45006227493286133 	 0.4379093647003174 	 0.4380300045013428 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:12:23.893768 test begin: paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.44754958152770996 	 3.1123650074005127 	 0.4383394718170166 	 0.35355663299560547 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:12:29.447363 test begin: paddle.Tensor.__rsub__(Tensor([2, 1, 12404, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 1, 12404, 4096],"float16"), 1, ) 	 101613568 	 1000 	 0.29819464683532715 	 0.299297571182251 	 0.2891979217529297 	 0.2767801284790039 	 0.2982137203216553 	 0.29610180854797363 	 0.24491071701049805 	 0.22650384902954102 	 
2025-07-25 18:12:34.542212 test begin: paddle.Tensor.__rsub__(Tensor([2, 1, 4096, 12404],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 1, 4096, 12404],"float16"), 1, ) 	 101613568 	 1000 	 0.2981855869293213 	 0.5207328796386719 	 0.2894885540008545 	 0.2770693302154541 	 0.2981724739074707 	 0.2961435317993164 	 0.24469995498657227 	 0.22951531410217285 	 
2025-07-25 18:12:40.954655 test begin: paddle.Tensor.__rsub__(Tensor([2, 4, 4096, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 4, 4096, 4096],"float16"), 1, ) 	 134217728 	 1000 	 0.3924417495727539 	 0.4003565311431885 	 0.3760254383087158 	 0.3701016902923584 	 0.39226698875427246 	 0.3899574279785156 	 0.33797287940979004 	 0.3170163631439209 	 
2025-07-25 18:12:47.697316 test begin: paddle.Tensor.__rsub__(Tensor([2944, 17257],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2944, 17257],"float32"), 1, ) 	 50804608 	 1000 	 0.29549288749694824 	 0.3002908229827881 	 0.2792048454284668 	 0.2711904048919678 	 0.29567909240722656 	 0.2977583408355713 	 0.23174047470092773 	 0.22447752952575684 	 
2025-07-25 18:12:50.607539 test begin: paddle.Tensor.__rsub__(Tensor([4224, 12028],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([4224, 12028],"float32"), 1, ) 	 50806272 	 1000 	 0.29576778411865234 	 0.298020601272583 	 0.27944397926330566 	 0.2712893486022949 	 0.2959272861480713 	 0.29778194427490234 	 0.23369431495666504 	 0.2310028076171875 	 
2025-07-25 18:12:53.474832 test begin: paddle.Tensor.__rsub__(Tensor([7, 1, 4096, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([7, 1, 4096, 4096],"float16"), 1, ) 	 117440512 	 1000 	 0.34417200088500977 	 0.34203624725341797 	 0.3278312683105469 	 0.31504154205322266 	 0.3440365791320801 	 0.3415710926055908 	 0.2819516658782959 	 0.27290797233581543 	 
2025-07-25 18:12:59.281778 test begin: paddle.Tensor.__rsub__(Tensor([7664, 6629],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([7664, 6629],"float32"), 1, ) 	 50804656 	 1000 	 0.295698881149292 	 0.2979457378387451 	 0.2845330238342285 	 0.27906346321105957 	 0.2958791255950928 	 0.2977879047393799 	 0.23801398277282715 	 0.23157739639282227 	 
2025-07-25 18:13:02.235727 test begin: paddle.Tensor.__rtruediv__(Tensor([15548, 3268],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([15548, 3268],"float32"), 1.0, ) 	 50810864 	 1000 	 0.5841329097747803 	 0.5961530208587646 	 0.29841113090515137 	 0.30446338653564453 	 0.5856969356536865 	 1.3381164073944092 	 0.49567294120788574 	 0.3419177532196045 	 
2025-07-25 18:13:07.030165 test begin: paddle.Tensor.__rtruediv__(Tensor([16773, 3029],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([16773, 3029],"float32"), 1.0, ) 	 50805417 	 1000 	 0.5842790603637695 	 0.5959947109222412 	 0.2985377311706543 	 0.3044309616088867 	 0.5855593681335449 	 1.3380382061004639 	 0.5113410949707031 	 0.34187841415405273 	 
2025-07-25 18:13:11.858615 test begin: paddle.Tensor.__rtruediv__(Tensor([26736, 1901],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([26736, 1901],"float32"), 1.0, ) 	 50825136 	 1000 	 0.5843226909637451 	 0.5963239669799805 	 0.2985837459564209 	 0.30460429191589355 	 0.5856788158416748 	 1.338585615158081 	 0.5271050930023193 	 0.34203362464904785 	 
2025-07-25 18:13:16.644511 test begin: paddle.Tensor.__rtruediv__(Tensor([37411, 1358],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([37411, 1358],"float32"), 1.0, ) 	 50804138 	 1000 	 0.5840139389038086 	 0.6015772819519043 	 0.2984592914581299 	 0.30442380905151367 	 0.5853245258331299 	 1.338064193725586 	 0.5267660617828369 	 0.34186768531799316 	 
2025-07-25 18:13:21.459962 test begin: paddle.Tensor.__rtruediv__(Tensor([6684, 7601],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([6684, 7601],"float32"), 1.0, ) 	 50805084 	 1000 	 0.5837528705596924 	 0.6014039516448975 	 0.2982785701751709 	 0.3044424057006836 	 0.5854935646057129 	 1.338059902191162 	 0.5269875526428223 	 0.3418886661529541 	 
2025-07-25 18:13:26.252188 test begin: paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), 5, ) 	 50803206 	 1000 	 0.2985358238220215 	 0.2979860305786133 	 0.15246915817260742 	 0.28215551376342773 	 None 	 None 	 None 	 None 	 
2025-07-25 18:13:27.443177 test begin: paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), True, ) 	 50803206 	 1000 	 0.29843664169311523 	 0.2978971004486084 	 0.15242981910705566 	 0.28313422203063965 	 None 	 None 	 None 	 None 	 
2025-07-25 18:13:28.637015 test begin: paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), 5, ) 	 50803210 	 1000 	 0.29846739768981934 	 0.29790186882019043 	 0.15249395370483398 	 0.2831122875213623 	 None 	 None 	 None 	 None 	 
2025-07-25 18:13:29.821373 test begin: paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), True, ) 	 50803210 	 1000 	 0.29851865768432617 	 0.29799652099609375 	 0.15247631072998047 	 0.2761104106903076 	 None 	 None 	 None 	 None 	 
2025-07-25 18:13:31.063119 test begin: paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), 5, ) 	 50803215 	 1000 	 0.2984485626220703 	 0.30566835403442383 	 0.15244722366333008 	 0.2832634449005127 	 None 	 None 	 None 	 None 	 
2025-07-25 18:13:32.257565 test begin: paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), True, ) 	 50803215 	 1000 	 0.2984580993652344 	 0.2979261875152588 	 0.1524655818939209 	 0.28308987617492676 	 None 	 None 	 None 	 None 	 
2025-07-25 18:13:33.449178 test begin: paddle.Tensor.__sub__(Tensor([1, 1, 32768, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([1, 1, 32768, 32768],"float16"), 1, ) 	 1073741824 	 1000 	 3.1047167778015137 	 3.094130516052246 	 3.088099241256714 	 3.067692995071411 	 3.1050446033477783 	 0.058873891830444336 	 3.023181200027466 	 4.887580871582031e-05 	 
2025-07-25 18:14:23.755105 test begin: paddle.Tensor.__sub__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), ) 	 52174848 	 1000 	 0.30408287048339844 	 0.31589221954345703 	 0.29347848892211914 	 0.3035109043121338 	 0.5345180034637451 	 0.45529794692993164 	 0.27301716804504395 	 0.2326056957244873 	 
2025-07-25 18:14:27.124908 test begin: paddle.Tensor.__sub__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), ) 	 52174848 	 1000 	 0.30409741401672363 	 0.31592392921447754 	 0.2933483123779297 	 0.30194878578186035 	 0.5344505310058594 	 0.4553062915802002 	 0.27301812171936035 	 0.23261642456054688 	 
2025-07-25 18:14:30.449142 test begin: paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), ) 	 53084160 	 1000 	 0.3060624599456787 	 0.319307804107666 	 0.2879917621612549 	 0.300260066986084 	 0.4860727787017822 	 0.46218276023864746 	 0.2482924461364746 	 0.23606014251708984 	 
2025-07-25 18:14:33.910646 test begin: paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), ) 	 103809024 	 1000 	 0.4595634937286377 	 1.1808714866638184 	 0.44270896911621094 	 0.4379875659942627 	 0.48416996002197266 	 0.3040006160736084 	 0.4149816036224365 	 0.22829318046569824 	 
2025-07-25 18:14:39.973948 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 1551, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 1551, 32768],"float16"), 1, ) 	 101646336 	 1000 	 0.29831695556640625 	 0.29651498794555664 	 0.2890002727508545 	 0.2821223735809326 	 0.2983074188232422 	 0.05797529220581055 	 0.24445462226867676 	 5.936622619628906e-05 	 
2025-07-25 18:14:44.840699 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 32768, 1551],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 32768, 1551],"float16"), 1, ) 	 101646336 	 1000 	 0.2982950210571289 	 0.29644250869750977 	 0.28954482078552246 	 0.28093647956848145 	 0.2983121871948242 	 0.060097455978393555 	 0.24100232124328613 	 5.91278076171875e-05 	 
2025-07-25 18:14:49.755810 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 32768, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 32768, 32768],"float16"), 1, ) 	 2147483648 	 1000 	 6.214772462844849 	 6.1834328174591064 	 6.205424785614014 	 3.1593587398529053 	 6.206542015075684 	 0.05554461479187012 	 6.146681070327759 	 5.8650970458984375e-05 	 
2025-07-25 18:16:31.184584 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 1],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 1],"float32"), ) 	 161966688 	 1000 	 0.714702844619751 	 1.9664442539215088 	 0.7049684524536133 	 0.6964092254638672 	 0.758371114730835 	 0.47130656242370605 	 0.6982238292694092 	 0.3837575912475586 	 
2025-07-25 18:16:39.898323 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 2],"float32"), ) 	 242950032 	 1000 	 1.1742117404937744 	 1.205601453781128 	 1.1634068489074707 	 1.1844003200531006 	 2.388115167617798 	 2.4666574001312256 	 1.2203845977783203 	 1.2603917121887207 	 
2025-07-25 18:16:53.798238 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 2],"float32"), Tensor([26736, 3029, 1],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 2],"float32"), Tensor([26736, 3029, 1],"float32"), ) 	 242950032 	 1000 	 1.173384189605713 	 1.202803611755371 	 1.1622436046600342 	 1.1829123497009277 	 2.22666597366333 	 2.4669339656829834 	 0.7582247257232666 	 1.2604994773864746 	 
2025-07-25 18:17:10.193508 test begin: paddle.Tensor.__sub__(Tensor([26736, 951, 2],"float32"), Tensor([26736, 951, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 951, 2],"float32"), Tensor([26736, 951, 2],"float32"), ) 	 101703744 	 1000 	 0.4501008987426758 	 0.44716620445251465 	 0.4405324459075928 	 0.43567919731140137 	 0.4758744239807129 	 0.2979414463043213 	 0.4154484272003174 	 0.22603821754455566 	 
2025-07-25 18:17:14.431366 test begin: paddle.Tensor.__sub__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), ) 	 51581952 	 1000 	 0.30011987686157227 	 0.3121781349182129 	 0.2895166873931885 	 0.299635648727417 	 0.4792640209197998 	 0.45038318634033203 	 0.24483561515808105 	 0.2300701141357422 	 
2025-07-25 18:17:17.639628 test begin: paddle.Tensor.__sub__(Tensor([8387, 3029, 2],"float32"), Tensor([8387, 3029, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([8387, 3029, 2],"float32"), Tensor([8387, 3029, 2],"float32"), ) 	 101616892 	 1000 	 0.44997477531433105 	 0.44678258895874023 	 0.4397866725921631 	 0.43518710136413574 	 0.4753437042236328 	 0.2977006435394287 	 0.41530418395996094 	 0.22513866424560547 	 
2025-07-25 18:17:21.958342 test begin: paddle.Tensor.__truediv__(Tensor([124, 128, 34, 96],"float32"), Tensor([124, 1, 34, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 128, 34, 96],"float32"), Tensor([124, 1, 34, 96],"float32"), ) 	 52210944 	 1000 	 0.30414485931396484 	 0.32499146461486816 	 0.2933526039123535 	 0.31154465675354004 	 0.8177802562713623 	 1.8868567943572998 	 0.41782474517822266 	 0.3212625980377197 	 
2025-07-25 18:17:26.982530 test begin: paddle.Tensor.__truediv__(Tensor([124, 128, 96, 34],"float32"), Tensor([124, 1, 96, 34],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 128, 96, 34],"float32"), Tensor([124, 1, 96, 34],"float32"), ) 	 52210944 	 1000 	 0.3041691780090332 	 0.3241863250732422 	 0.2934608459472656 	 0.31194043159484863 	 0.8177766799926758 	 1.886817216873169 	 0.41788697242736816 	 0.3212120532989502 	 
2025-07-25 18:17:32.060385 test begin: paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 1, 96, 96],"float32"), ) 	 52568064 	 1000 	 0.3037874698638916 	 0.3239626884460449 	 0.28752994537353516 	 0.31149935722351074 	 0.7707703113555908 	 1.8861839771270752 	 0.3938267230987549 	 0.32108545303344727 	 
2025-07-25 18:17:38.404066 test begin: paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 45, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 45, 96, 96],"float32"), ) 	 102850560 	 1000 	 0.45565271377563477 	 0.4550900459289551 	 0.44589948654174805 	 0.43706822395324707 	 1.116722583770752 	 2.1151890754699707 	 1.053635835647583 	 0.43233275413513184 	 
2025-07-25 18:17:45.122935 test begin: paddle.Tensor.__truediv__(Tensor([128, 128, 33, 96],"float32"), Tensor([128, 1, 33, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 128, 33, 96],"float32"), Tensor([128, 1, 33, 96],"float32"), ) 	 52310016 	 1000 	 0.3046293258666992 	 0.3308854103088379 	 0.2893819808959961 	 0.312361478805542 	 0.8110206127166748 	 1.8908500671386719 	 0.414414644241333 	 0.3219125270843506 	 
2025-07-25 18:17:50.201687 test begin: paddle.Tensor.__truediv__(Tensor([128, 128, 96, 33],"float32"), Tensor([128, 1, 96, 33],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 128, 96, 33],"float32"), Tensor([128, 1, 96, 33],"float32"), ) 	 52310016 	 1000 	 0.3046295642852783 	 0.32477498054504395 	 0.29360508918762207 	 0.30925440788269043 	 0.8110437393188477 	 1.8909530639648438 	 0.4144272804260254 	 0.3219153881072998 	 
2025-07-25 18:17:55.231972 test begin: paddle.Tensor.__truediv__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), ) 	 52174848 	 1000 	 0.3045947551727295 	 0.32818031311035156 	 0.29378771781921387 	 0.3118929862976074 	 0.8234875202178955 	 1.8874680995941162 	 0.4207754135131836 	 0.321336030960083 	 
2025-07-25 18:18:00.255213 test begin: paddle.Tensor.__truediv__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), ) 	 52174848 	 1000 	 0.30473756790161133 	 0.32503437995910645 	 0.28630876541137695 	 0.3053619861602783 	 0.8235208988189697 	 1.8874332904815674 	 0.4207594394683838 	 0.3213536739349365 	 
2025-07-25 18:18:05.386225 test begin: paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), ) 	 53084160 	 1000 	 0.3064079284667969 	 0.32718753814697266 	 0.28795647621154785 	 0.30788445472717285 	 0.7781257629394531 	 1.9013187885284424 	 0.397566556930542 	 0.32372426986694336 	 
2025-07-25 18:18:11.875135 test begin: paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), ) 	 103809024 	 1000 	 0.4595959186553955 	 0.4602537155151367 	 0.4426712989807129 	 0.4415566921234131 	 1.1313042640686035 	 2.1346688270568848 	 1.0482606887817383 	 0.43633246421813965 	 
2025-07-25 18:18:18.669876 test begin: paddle.Tensor.__truediv__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), ) 	 51581952 	 1000 	 0.3002002239227295 	 0.32049036026000977 	 0.281874418258667 	 0.30113720893859863 	 0.7653412818908691 	 1.8655927181243896 	 0.391035795211792 	 0.3175842761993408 	 
2025-07-25 18:18:23.617253 test begin: paddle.Tensor.__truediv__(Tensor([44, 128, 96, 96],"float32"), Tensor([44, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([44, 128, 96, 96],"float32"), Tensor([44, 1, 96, 96],"float32"), ) 	 52310016 	 1000 	 0.3039424419403076 	 0.32459402084350586 	 0.28214097023010254 	 0.3056623935699463 	 0.7756130695343018 	 1.8889403343200684 	 0.39623284339904785 	 0.32160162925720215 	 
2025-07-25 18:18:28.675083 test begin: paddle.Tensor.__xor__(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4479403495788574 	 0.4503340721130371 	 0.4323282241821289 	 0.4316871166229248 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:31.593414 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44821953773498535 	 0.45574307441711426 	 0.4326460361480713 	 0.4313817024230957 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:34.621599 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4481816291809082 	 0.470508337020874 	 0.4397547245025635 	 0.4379458427429199 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:40.229809 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.448108434677124 	 0.4502677917480469 	 0.4325070381164551 	 0.43163013458251953 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:43.196922 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.1170651912689209 	 0.11749792098999023 	 0.1083226203918457 	 0.10506701469421387 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:44.871381 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.4497992992401123 	 0.44684576988220215 	 0.4341402053833008 	 0.4280400276184082 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:47.005230 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.44811534881591797 	 0.45026350021362305 	 0.4396495819091797 	 0.4381103515625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:49.954896 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.16872310638427734 	 0.22742629051208496 	 0.1585218906402588 	 0.20695924758911133 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:51.070762 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3143153190612793 	 0.47948741912841797 	 0.3048882484436035 	 0.46591973304748535 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:52.856302 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2962954044342041 	 0.3081338405609131 	 0.2867007255554199 	 0.29470396041870117 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:54.057319 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11779475212097168 	 0.11707305908203125 	 0.10912728309631348 	 0.10395479202270508 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:55.716800 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.449878454208374 	 0.44672203063964844 	 0.441253662109375 	 0.4345223903656006 	 None 	 None 	 None 	 None 	 
2025-07-25 18:18:57.844523 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.4480271339416504 	 0.4515225887298584 	 0.43914198875427246 	 0.43766021728515625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:00.813054 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.17721772193908691 	 0.23050260543823242 	 0.16730880737304688 	 0.21391034126281738 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:01.956078 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11782503128051758 	 0.11631941795349121 	 0.10176873207092285 	 0.09688711166381836 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:03.665565 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2955460548400879 	 0.3080627918243408 	 0.2859337329864502 	 0.2947964668273926 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:04.864822 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.4499988555908203 	 0.4467017650604248 	 0.44147682189941406 	 0.434675931930542 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:06.949901 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.34545421600341797 	 0.47821474075317383 	 0.336061954498291 	 0.4645411968231201 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:08.781359 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.4479219913482666 	 0.45036816596984863 	 0.43944239616394043 	 0.4381377696990967 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:11.744710 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11780095100402832 	 0.1153419017791748 	 0.10904145240783691 	 0.10317134857177734 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:13.466886 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.44983839988708496 	 0.4654505252838135 	 0.4412810802459717 	 0.4337775707244873 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:17.616778 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11779236793518066 	 0.12148618698120117 	 0.10906028747558594 	 0.10314178466796875 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:20.102800 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45015907287597656 	 0.4468965530395508 	 0.4415767192840576 	 0.434614896774292 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:22.240877 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11780953407287598 	 0.1153714656829834 	 0.1091458797454834 	 0.103118896484375 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:23.915969 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45009827613830566 	 0.4467017650604248 	 0.43439745903015137 	 0.422405481338501 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:26.067289 test begin: paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11779308319091797 	 0.11542606353759766 	 0.10908865928649902 	 0.10003137588500977 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:27.738243 test begin: paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4501931667327881 	 0.4467747211456299 	 0.44150876998901367 	 0.43461036682128906 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:29.813469 test begin: paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.1178584098815918 	 0.11624383926391602 	 0.10701322555541992 	 0.10419130325317383 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:31.515444 test begin: paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.4498910903930664 	 0.4467353820800781 	 0.4413340091705322 	 0.4346625804901123 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:33.689219 test begin: paddle.Tensor.__xor__(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.4479532241821289 	 0.4672367572784424 	 0.4394710063934326 	 0.42814159393310547 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:38.037576 test begin: paddle.Tensor.abs(Tensor([243360, 209],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([243360, 209],"float32"), ) 	 50862240 	 1000 	 0.29611682891845703 	 0.30550146102905273 	 0.2870323657989502 	 0.2853739261627197 	 0.45026683807373047 	 0.743870735168457 	 0.3953549861907959 	 0.38009142875671387 	 
2025-07-25 18:19:41.516352 test begin: paddle.Tensor.abs(Tensor([282240, 181],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([282240, 181],"float32"), ) 	 51085440 	 1000 	 0.2972264289855957 	 0.30811619758605957 	 0.28820323944091797 	 0.2864096164703369 	 0.45210695266723633 	 0.7469089031219482 	 0.39737963676452637 	 0.3815762996673584 	 
2025-07-25 18:19:45.068974 test begin: paddle.Tensor.abs(Tensor([324000, 157],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([324000, 157],"float32"), ) 	 50868000 	 1000 	 0.2960836887359619 	 0.3072013854980469 	 0.2870657444000244 	 0.28547096252441406 	 0.4506103992462158 	 0.7439584732055664 	 0.3934922218322754 	 0.38008832931518555 	 
2025-07-25 18:19:48.622448 test begin: paddle.Tensor.abs(Tensor([635041, 80],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([635041, 80],"float32"), ) 	 50803280 	 1000 	 0.29552555084228516 	 0.311051607131958 	 0.2865931987762451 	 0.28533506393432617 	 0.44969964027404785 	 0.7429103851318359 	 0.3945431709289551 	 0.37958455085754395 	 
2025-07-25 18:19:52.103159 test begin: paddle.Tensor.add(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.add 	 paddle.Tensor.add(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.44997215270996094 	 0.44672656059265137 	 0.4404866695404053 	 0.4354398250579834 	 0.48259687423706055 	 0.06193995475769043 	 0.42136406898498535 	 6.341934204101562e-05 	 
2025-07-25 18:19:56.132360 test begin: paddle.Tensor.all(Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1, 1, 2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.052057504653930664 	 0.061324357986450195 	 0.026547908782958984 	 0.03129768371582031 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:56.988419 test begin: paddle.Tensor.all(Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1, 1, 24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.05199074745178223 	 0.061333417892456055 	 0.026541471481323242 	 0.03133845329284668 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:57.820021 test begin: paddle.Tensor.all(Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1, 13, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.05540180206298828 	 0.06508111953735352 	 0.028201818466186523 	 0.033329010009765625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:58.726290 test begin: paddle.Tensor.all(Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([13, 1, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.05518960952758789 	 0.06465697288513184 	 0.028178930282592773 	 0.03301548957824707 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:59.662359 test begin: paddle.Tensor.all(Tensor([159, 10, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([159, 10, 32000],"bool"), ) 	 50880000 	 1000 	 0.05258631706237793 	 0.06136655807495117 	 0.02685546875 	 0.031324148178100586 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:00.504499 test begin: paddle.Tensor.all(Tensor([2, 10, 2540161],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([2, 10, 2540161],"bool"), ) 	 50803220 	 1000 	 0.05220460891723633 	 0.061311960220336914 	 0.026657819747924805 	 0.03130841255187988 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:01.376233 test begin: paddle.Tensor.all(Tensor([2, 100, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([2, 100, 256000],"bool"), ) 	 51200000 	 1000 	 0.05230450630187988 	 0.06189537048339844 	 0.02671337127685547 	 0.031615495681762695 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:02.216578 test begin: paddle.Tensor.all(Tensor([2, 794, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([2, 794, 32000],"bool"), ) 	 50816000 	 1000 	 0.05242013931274414 	 0.06132984161376953 	 0.026758909225463867 	 0.03130602836608887 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:03.057580 test begin: paddle.Tensor.all(Tensor([20, 10, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 10, 256000],"bool"), ) 	 51200000 	 1000 	 0.05231761932373047 	 0.06193685531616211 	 0.02672100067138672 	 0.031632423400878906 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:03.885801 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803240 	 1000 	 0.45352673530578613 	 0.47161364555358887 	 0.43355250358581543 	 0.44936680793762207 	 1.3160672187805176 	 1.6163561344146729 	 0.3361845016479492 	 0.33017683029174805 	 
2025-07-25 18:20:08.785896 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803240 	 1000 	 0.5134708881378174 	 0.18377041816711426 	 0.50063157081604 	 0.1690680980682373 	 1.387247085571289 	 1.5295190811157227 	 0.35434579849243164 	 0.3125181198120117 	 
2025-07-25 18:20:13.455588 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803240 	 1000 	 0.15192770957946777 	 0.15296268463134766 	 0.07761263847351074 	 0.07812976837158203 	 1.0446770191192627 	 1.2480409145355225 	 0.21367287635803223 	 0.21242856979370117 	 
2025-07-25 18:20:16.888780 test begin: paddle.Tensor.amax(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, ) 	 50803230 	 1000 	 0.45352721214294434 	 0.4715235233306885 	 0.44010281562805176 	 0.456972599029541 	 1.3160436153411865 	 1.616513967514038 	 0.33617639541625977 	 0.33016324043273926 	 
2025-07-25 18:20:22.530033 test begin: paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, ) 	 50803224 	 1000 	 6.293964862823486 	 0.17212414741516113 	 3.216233253479004 	 0.08791041374206543 	 5.72378134727478 	 1.3408958911895752 	 1.168138027191162 	 0.2281968593597412 	 
2025-07-25 18:20:40.101189 test begin: paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, ) 	 50803224 	 1000 	 0.1519782543182373 	 0.15299320220947266 	 0.0776205062866211 	 0.07814407348632812 	 1.0446674823760986 	 1.248734951019287 	 0.21371245384216309 	 0.21262216567993164 	 
2025-07-25 18:20:43.609058 test begin: paddle.Tensor.amax(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, ) 	 50803224 	 1000 	 0.16951799392700195 	 0.15507149696350098 	 0.08662796020507812 	 0.07915186882019043 	 1.065758228302002 	 1.274843454360962 	 0.21796894073486328 	 0.2169952392578125 	 
2025-07-25 18:20:47.235554 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, ) 	 50803230 	 1000 	 0.20840692520141602 	 0.21844124794006348 	 0.18890690803527832 	 0.20353913307189941 	 1.2629263401031494 	 1.527254343032837 	 0.32266998291015625 	 0.3120553493499756 	 
2025-07-25 18:20:51.457713 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, ) 	 50803230 	 1000 	 0.15196442604064941 	 0.15295004844665527 	 0.07763814926147461 	 0.07813644409179688 	 1.044755458831787 	 1.2486443519592285 	 0.21370744705200195 	 0.21252846717834473 	 
2025-07-25 18:20:54.917386 test begin: paddle.Tensor.amax(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803260 	 1000 	 0.4534933567047119 	 0.4715597629547119 	 0.4418606758117676 	 0.45682215690612793 	 1.3164870738983154 	 1.6167864799499512 	 0.3363630771636963 	 0.3304719924926758 	 
2025-07-25 18:20:59.883796 test begin: paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803260 	 1000 	 0.5134592056274414 	 0.1837308406829834 	 0.5006508827209473 	 0.16918540000915527 	 1.387894868850708 	 1.529496192932129 	 0.3544046878814697 	 0.3124818801879883 	 
2025-07-25 18:21:04.507254 test begin: paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803260 	 1000 	 0.15193843841552734 	 0.1531810760498047 	 0.07761526107788086 	 0.07830524444580078 	 1.0446958541870117 	 1.2484304904937744 	 0.21367335319519043 	 0.21246838569641113 	 
2025-07-25 18:21:10.647632 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803240 	 1000 	 0.45354413986206055 	 0.4716053009033203 	 0.43126535415649414 	 0.4500608444213867 	 1.316410779953003 	 1.6165530681610107 	 0.33632326126098633 	 0.33025169372558594 	 
2025-07-25 18:21:15.633791 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803240 	 1000 	 0.5134897232055664 	 0.18372058868408203 	 0.500176191329956 	 0.16943001747131348 	 1.3872616291046143 	 1.529486894607544 	 0.35436153411865234 	 0.3124983310699463 	 
2025-07-25 18:21:20.299625 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803240 	 1000 	 0.15193915367126465 	 0.15322041511535645 	 0.07762432098388672 	 0.07831454277038574 	 1.0447266101837158 	 1.248661756515503 	 0.2137010097503662 	 0.2126779556274414 	 
2025-07-25 18:21:23.736145 test begin: paddle.Tensor.amin(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, ) 	 50803230 	 1000 	 0.45348644256591797 	 0.7083208560943604 	 0.44138121604919434 	 0.456998348236084 	 1.3165392875671387 	 1.61643385887146 	 0.33634328842163086 	 0.33019256591796875 	 
2025-07-25 18:21:30.277155 test begin: paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, ) 	 50803224 	 1000 	 6.293854236602783 	 0.1723041534423828 	 3.2160584926605225 	 0.08813261985778809 	 5.723668813705444 	 1.3411009311676025 	 1.1681971549987793 	 0.2282428741455078 	 
2025-07-25 18:21:44.708552 test begin: paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, ) 	 50803224 	 1000 	 0.15191364288330078 	 0.15313148498535156 	 0.07758784294128418 	 0.07816052436828613 	 1.0446999073028564 	 1.2480435371398926 	 0.21365976333618164 	 0.2124783992767334 	 
2025-07-25 18:21:48.215136 test begin: paddle.Tensor.amin(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, ) 	 50803224 	 1000 	 0.16948652267456055 	 0.154754638671875 	 0.08659052848815918 	 0.07892441749572754 	 1.0656428337097168 	 1.2748737335205078 	 0.21793365478515625 	 0.21715092658996582 	 
2025-07-25 18:21:51.739734 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, ) 	 50803230 	 1000 	 0.2084183692932129 	 0.2202134132385254 	 0.18854928016662598 	 0.19685864448547363 	 1.2629010677337646 	 1.5267341136932373 	 0.3227536678314209 	 0.3118314743041992 	 
2025-07-25 18:21:56.043320 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, ) 	 50803230 	 1000 	 0.15196633338928223 	 0.15315937995910645 	 0.07762765884399414 	 0.07830619812011719 	 1.044646978378296 	 1.2485220432281494 	 0.21364808082580566 	 0.2125999927520752 	 
2025-07-25 18:21:59.509114 test begin: paddle.Tensor.amin(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803260 	 1000 	 0.45350146293640137 	 0.473862886428833 	 0.43136000633239746 	 0.4487180709838867 	 1.3164191246032715 	 1.6163818836212158 	 0.3363480567932129 	 0.33017587661743164 	 
2025-07-25 18:22:04.438914 test begin: paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803260 	 1000 	 0.5134701728820801 	 0.18377399444580078 	 0.49216771125793457 	 0.16234993934631348 	 1.387669324874878 	 1.5301411151885986 	 0.3545100688934326 	 0.31260108947753906 	 
2025-07-25 18:22:09.100888 test begin: paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803260 	 1000 	 0.15195059776306152 	 0.15317893028259277 	 0.07761240005493164 	 0.07817959785461426 	 1.0446512699127197 	 1.2481505870819092 	 0.21365118026733398 	 0.2124626636505127 	 
2025-07-25 18:22:12.557924 test begin: paddle.Tensor.any(Tensor([1, 1379, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([1, 1379, 192, 192],"bool"), axis=list[2,3,], ) 	 50835456 	 1000 	 0.06489253044128418 	 0.06703805923461914 	 0.0331418514251709 	 0.0454556941986084 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:13.456134 test begin: paddle.Tensor.any(Tensor([1, 1501, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([1, 1501, 184, 184],"bool"), axis=list[2,3,], ) 	 50817856 	 1000 	 0.06392407417297363 	 0.06735467910766602 	 0.032647132873535156 	 0.04551267623901367 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:14.299748 test begin: paddle.Tensor.any(Tensor([1, 300, 184, 921],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([1, 300, 184, 921],"bool"), axis=list[2,3,], ) 	 50839200 	 1000 	 0.08715248107910156 	 0.07853174209594727 	 0.04453134536743164 	 0.04010343551635742 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:15.196198 test begin: paddle.Tensor.any(Tensor([1, 300, 192, 883],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([1, 300, 192, 883],"bool"), axis=list[2,3,], ) 	 50860800 	 1000 	 0.08775734901428223 	 0.07850384712219238 	 0.04481863975524902 	 0.040087223052978516 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:16.091550 test begin: paddle.Tensor.any(Tensor([1, 300, 883, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([1, 300, 883, 192],"bool"), axis=list[2,3,], ) 	 50860800 	 1000 	 0.08783602714538574 	 0.07846951484680176 	 0.04486441612243652 	 0.040064334869384766 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:17.005124 test begin: paddle.Tensor.any(Tensor([1, 300, 921, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([1, 300, 921, 184],"bool"), axis=list[2,3,], ) 	 50839200 	 1000 	 0.08718538284301758 	 0.07860302925109863 	 0.04454660415649414 	 0.040190696716308594 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:17.904724 test begin: paddle.Tensor.any(Tensor([10, 300, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 136, 136],"bool"), axis=list[2,3,], ) 	 55488000 	 1000 	 0.06423497200012207 	 0.07993316650390625 	 0.04483461380004883 	 0.05830121040344238 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:18.872397 test begin: paddle.Tensor.any(Tensor([2, 1374, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([2, 1374, 136, 136],"bool"), axis=list[2,3,], ) 	 50827008 	 1000 	 0.06183743476867676 	 0.07446074485778809 	 0.049920082092285156 	 0.04334902763366699 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:19.720643 test begin: paddle.Tensor.any(Tensor([2, 300, 136, 623],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([2, 300, 136, 623],"bool"), axis=list[2,3,], ) 	 50836800 	 1000 	 0.08587121963500977 	 0.0717003345489502 	 0.04384660720825195 	 0.04983949661254883 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:20.586683 test begin: paddle.Tensor.any(Tensor([2, 300, 623, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([2, 300, 623, 136],"bool"), axis=list[2,3,], ) 	 50836800 	 1000 	 0.0859212875366211 	 0.07171344757080078 	 0.04388785362243652 	 0.05728888511657715 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:21.450247 test begin: paddle.Tensor.any(Tensor([5, 300, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([5, 300, 192, 192],"bool"), axis=list[2,3,], ) 	 55296000 	 1000 	 0.06770181655883789 	 0.07079625129699707 	 0.03457760810852051 	 0.056148529052734375 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:22.394109 test begin: paddle.Tensor.any(Tensor([6, 300, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([6, 300, 184, 184],"bool"), axis=list[2,3,], ) 	 60940800 	 1000 	 0.08251047134399414 	 0.0793602466583252 	 0.04213595390319824 	 0.06499147415161133 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:23.453867 test begin: paddle.Tensor.argmax(Tensor([13, 498, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([13, 498, 8000],"float32"), axis=2, ) 	 51792000 	 1000 	 0.278414249420166 	 0.1676933765411377 	 0.2663421630859375 	 0.1537768840789795 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:24.753801 test begin: paddle.Tensor.argmax(Tensor([14, 457, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([14, 457, 8000],"float32"), axis=2, ) 	 51184000 	 1000 	 0.27530789375305176 	 0.16741299629211426 	 0.26511549949645996 	 0.15222477912902832 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:26.084839 test begin: paddle.Tensor.argmax(Tensor([14, 477, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([14, 477, 8000],"float32"), axis=2, ) 	 53424000 	 1000 	 0.2870810031890869 	 0.1712477207183838 	 0.2767906188964844 	 0.15724802017211914 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:27.416190 test begin: paddle.Tensor.argmax(Tensor([30, 212, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 212, 8000],"float32"), axis=2, ) 	 50880000 	 1000 	 0.2739412784576416 	 0.16666364669799805 	 0.26244282722473145 	 0.15267419815063477 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:28.683890 test begin: paddle.Tensor.argmax(Tensor([30, 457, 3706],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 457, 3706],"float32"), axis=2, ) 	 50809260 	 1000 	 0.3482816219329834 	 0.1624312400817871 	 0.33808207511901855 	 0.14839863777160645 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:30.091261 test begin: paddle.Tensor.argmax(Tensor([30, 477, 3551],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 477, 3551],"float32"), axis=2, ) 	 50814810 	 1000 	 0.35855746269226074 	 0.167633056640625 	 0.3483617305755615 	 0.15360116958618164 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:32.489362 test begin: paddle.Tensor.argmax(Tensor([30, 498, 3401],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 498, 3401],"float32"), axis=2, ) 	 50810940 	 1000 	 0.3700382709503174 	 0.16524076461791992 	 0.3598349094390869 	 0.15114665031433105 	 None 	 None 	 None 	 None 	 
2025-07-25 18:22:34.869624 test begin: paddle.Tensor.astype(Tensor([1, 32, 388, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1, 32, 388, 4096],"float32"), "float32", ) 	 50855936 	 1000 	 0.0032339096069335938 	 0.002156972885131836 	 1.1444091796875e-05 	 1.6450881958007812e-05 	 0.03160452842712402 	 0.05532574653625488 	 2.8371810913085938e-05 	 6.151199340820312e-05 	 
2025-07-25 18:22:37.619204 test begin: paddle.Tensor.astype(Tensor([1, 32, 4096, 388],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1, 32, 4096, 388],"float32"), "float32", ) 	 50855936 	 1000 	 0.00477290153503418 	 0.0070018768310546875 	 1.0728836059570312e-05 	 6.532669067382812e-05 	 0.034552574157714844 	 0.057076215744018555 	 3.600120544433594e-05 	 7.772445678710938e-05 	 
2025-07-25 18:22:39.741544 test begin: paddle.Tensor.astype(Tensor([1, 32, 4096, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1, 32, 4096, 4096],"float32"), "float32", ) 	 536870912 	 1000 	 0.0031843185424804688 	 0.0022084712982177734 	 8.821487426757812e-06 	 1.621246337890625e-05 	 0.03954577445983887 	 0.047394514083862305 	 5.841255187988281e-05 	 5.53131103515625e-05 	 
2025-07-25 18:22:57.452500 test begin: paddle.Tensor.astype(Tensor([1, 4, 4096, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1, 4, 4096, 4096],"float32"), "float32", ) 	 67108864 	 1000 	 0.0032269954681396484 	 0.0022051334381103516 	 1.049041748046875e-05 	 1.5735626220703125e-05 	 0.03053593635559082 	 0.04694008827209473 	 2.193450927734375e-05 	 4.2438507080078125e-05 	 
2025-07-25 18:22:59.804893 test begin: paddle.Tensor.astype(Tensor([100352, 1013],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([100352, 1013],"bfloat16"), "float32", ) 	 101656576 	 1000 	 0.47983717918395996 	 0.5596730709075928 	 0.4507100582122803 	 0.5395376682281494 	 0.4501960277557373 	 0.4538605213165283 	 0.3826477527618408 	 0.3768951892852783 	 
2025-07-25 18:23:05.131955 test begin: paddle.Tensor.astype(Tensor([1013, 100352],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1013, 100352],"bfloat16"), "float32", ) 	 101656576 	 1000 	 0.48001551628112793 	 0.5592174530029297 	 0.46627020835876465 	 0.5458824634552002 	 0.45024657249450684 	 0.45386195182800293 	 0.3925755023956299 	 0.38284850120544434 	 
2025-07-25 18:23:10.600395 test begin: paddle.Tensor.astype(Tensor([12404, 8192],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([12404, 8192],"bfloat16"), "float32", ) 	 101613568 	 1000 	 0.47997593879699707 	 0.5609769821166992 	 0.4663431644439697 	 0.5450551509857178 	 0.45076537132263184 	 0.45363426208496094 	 0.39139246940612793 	 0.38634705543518066 	 
2025-07-25 18:23:16.012533 test begin: paddle.Tensor.astype(Tensor([8192, 12404],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([8192, 12404],"bfloat16"), "float32", ) 	 101613568 	 1000 	 0.4800419807434082 	 0.5591897964477539 	 0.46633362770080566 	 0.5458259582519531 	 0.45078492164611816 	 0.4536261558532715 	 0.387545108795166 	 0.37769246101379395 	 
2025-07-25 18:23:21.330862 test begin: paddle.Tensor.atanh(Tensor([1, 16934401, 3],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2972753047943115 	 0.2982513904571533 	 0.28853702545166016 	 0.2877054214477539 	 0.4499225616455078 	 1.6227128505706787 	 0.3950185775756836 	 0.3317227363586426 	 
2025-07-25 18:23:25.737838 test begin: paddle.Tensor.atanh(Tensor([1, 2, 12700801],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.44330763816833496 	 0.40764904022216797 	 0.43478822708129883 	 0.392547607421875 	 0.44748592376708984 	 1.620779037475586 	 0.3930375576019287 	 0.3313627243041992 	 
2025-07-25 18:23:29.763874 test begin: paddle.Tensor.atanh(Tensor([1, 2, 25401601],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29729342460632324 	 0.29825735092163086 	 0.2886652946472168 	 0.2876732349395752 	 0.4498288631439209 	 1.6228938102722168 	 0.39490246772766113 	 0.33178019523620605 	 
2025-07-25 18:23:34.196451 test begin: paddle.Tensor.atanh(Tensor([1, 8467201, 3],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.4436345100402832 	 0.4232478141784668 	 0.4346921443939209 	 0.3967156410217285 	 0.4474794864654541 	 1.6214711666107178 	 0.39329075813293457 	 0.33168864250183105 	 
2025-07-25 18:23:43.106223 test begin: paddle.Tensor.atanh(Tensor([2, 12700801],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.44362664222717285 	 0.42038464546203613 	 0.4351029396057129 	 0.396728515625 	 0.4474153518676758 	 1.620783805847168 	 0.3930065631866455 	 0.3313331604003906 	 
2025-07-25 18:23:48.191837 test begin: paddle.Tensor.atanh(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.4436147212982178 	 0.408566951751709 	 0.43514156341552734 	 0.3960897922515869 	 0.4475438594818115 	 1.6207778453826904 	 0.391923189163208 	 0.3313748836517334 	 
2025-07-25 18:23:52.252678 test begin: paddle.Tensor.atanh(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.44362831115722656 	 0.407503604888916 	 0.43508219718933105 	 0.3967719078063965 	 0.447298526763916 	 1.6206121444702148 	 0.3868727684020996 	 0.3313145637512207 	 
2025-07-25 18:23:56.294178 test begin: paddle.Tensor.atanh(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2972402572631836 	 0.298276424407959 	 0.28865718841552734 	 0.28777575492858887 	 0.4499175548553467 	 1.622812271118164 	 0.392317533493042 	 0.33174657821655273 	 
2025-07-25 18:24:00.719199 test begin: paddle.Tensor.bmm(Tensor([1, 16934401, 3],"float32"), Tensor([1, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 16934401, 3],"float32"), Tensor([1, 3, 2],"float32"), ) 	 50803209 	 1000 	 1.778177261352539 	 1.7800707817077637 	 0.10682511329650879 	 0.10683965682983398 	 4.137913942337036 	 4.137558698654175 	 0.22295832633972168 	 0.22080397605895996 	 
2025-07-25 18:24:14.018084 test begin: paddle.Tensor.bmm(Tensor([1, 170476, 299],"float32"), Tensor([1, 299, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 170476, 299],"float32"), Tensor([1, 299, 2],"float32"), ) 	 50972922 	 1000 	 0.23964190483093262 	 0.23927640914916992 	 0.2254951000213623 	 0.22124361991882324 	 0.41747498512268066 	 0.423689603805542 	 0.1421194076538086 	 0.14429616928100586 	 
2025-07-25 18:24:16.198534 test begin: paddle.Tensor.bmm(Tensor([1, 179876, 283],"float32"), Tensor([1, 283, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 179876, 283],"float32"), Tensor([1, 283, 2],"float32"), ) 	 50905474 	 1000 	 0.24132490158081055 	 0.24113965034484863 	 0.2258296012878418 	 0.22172760963439941 	 0.4120779037475586 	 0.41603827476501465 	 0.14029431343078613 	 0.14161419868469238 	 
2025-07-25 18:24:18.367679 test begin: paddle.Tensor.bmm(Tensor([1, 191277, 266],"float32"), Tensor([1, 266, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 191277, 266],"float32"), Tensor([1, 266, 2],"float32"), ) 	 50880214 	 1000 	 0.23407292366027832 	 0.23408246040344238 	 0.21732735633850098 	 0.21059966087341309 	 0.41910552978515625 	 0.4209566116333008 	 0.14267754554748535 	 0.14318490028381348 	 
2025-07-25 18:24:20.530386 test begin: paddle.Tensor.bmm(Tensor([100, 170476, 3],"float32"), Tensor([100, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([100, 170476, 3],"float32"), Tensor([100, 3, 2],"float32"), ) 	 51143400 	 1000 	 4.850163221359253 	 4.851017236709595 	 4.837865591049194 	 4.833844423294067 	 38.526273250579834 	 38.526220083236694 	 19.68682336807251 	 19.686806678771973 	 
2025-07-25 18:25:48.869303 test begin: paddle.Tensor.bmm(Tensor([89, 191277, 3],"float32"), Tensor([89, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([89, 191277, 3],"float32"), Tensor([89, 3, 2],"float32"), ) 	 51071493 	 1000 	 4.842008352279663 	 6.240814924240112 	 4.829824924468994 	 4.819368600845337 	 42.629435777664185 	 42.629242181777954 	 21.783534049987793 	 21.783414602279663 	 
2025-07-25 18:27:27.291570 test begin: paddle.Tensor.bmm(Tensor([95, 179876, 3],"float32"), Tensor([95, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([95, 179876, 3],"float32"), Tensor([95, 3, 2],"float32"), ) 	 51265230 	 1000 	 4.863652467727661 	 4.8738720417022705 	 4.851064205169678 	 4.847220420837402 	 40.39806032180786 	 40.39832067489624 	 20.642723560333252 	 20.642855882644653 	 
2025-07-25 18:28:59.393195 test begin: paddle.Tensor.cast(Tensor([128256, 793],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([128256, 793],"float16"), Dtype(float16), ) 	 101707008 	 1000 	 0.3074791431427002 	 0.0019218921661376953 	 0.15713214874267578 	 1.5974044799804688e-05 	 0.3081979751586914 	 0.0522763729095459 	 0.1574406623840332 	 3.838539123535156e-05 	 combined
2025-07-25 18:29:03.907821 test begin: paddle.Tensor.cast(Tensor([152064, 669],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([152064, 669],"float16"), Dtype(float16), ) 	 101730816 	 1000 	 0.31508731842041016 	 0.001954793930053711 	 0.16100811958312988 	 1.621246337890625e-05 	 0.3149068355560303 	 0.04808306694030762 	 0.16086745262145996 	 6.532669067382812e-05 	 combined
2025-07-25 18:29:10.117110 test begin: paddle.Tensor.cast(Tensor([24807, 4096],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([24807, 4096],"float16"), Dtype(float16), ) 	 101609472 	 1000 	 0.3102552890777588 	 0.002913236618041992 	 0.29956746101379395 	 1.811981201171875e-05 	 0.3105792999267578 	 0.046018362045288086 	 0.2433769702911377 	 4.38690185546875e-05 	 combined
2025-07-25 18:29:14.806837 test begin: paddle.Tensor.cast(Tensor([28351, 3584],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([28351, 3584],"float16"), Dtype(float16), ) 	 101609984 	 1000 	 0.31471943855285645 	 0.001961946487426758 	 0.16080760955810547 	 1.621246337890625e-05 	 0.3146481513977051 	 0.04581642150878906 	 0.16072821617126465 	 4.315376281738281e-05 	 combined
2025-07-25 18:29:19.210912 test begin: paddle.Tensor.cast(Tensor([3584, 28351],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([3584, 28351],"float16"), Dtype(float16), ) 	 101609984 	 1000 	 0.3147428035736084 	 0.0019474029541015625 	 0.16082429885864258 	 1.5497207641601562e-05 	 0.31466150283813477 	 0.045664310455322266 	 0.16072583198547363 	 2.8133392333984375e-05 	 combined
2025-07-25 18:29:23.665230 test begin: paddle.Tensor.cast(Tensor([669, 152064],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([669, 152064],"float16"), Dtype(float16), ) 	 101730816 	 1000 	 0.31508851051330566 	 0.0019636154174804688 	 0.16100096702575684 	 1.8358230590820312e-05 	 0.3148679733276367 	 0.04526090621948242 	 0.1608412265777588 	 3.0279159545898438e-05 	 combined
2025-07-25 18:29:28.092587 test begin: paddle.Tensor.ceil(Tensor([1, 50803201],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([1, 50803201],"float32"), ) 	 50803201 	 1000 	 0.29564833641052246 	 0.2978942394256592 	 0.28703999519348145 	 0.28542065620422363 	 0.13396453857421875 	 0.13422751426696777 	 0.08177757263183594 	 0.06000018119812012 	 
2025-07-25 18:29:30.652650 test begin: paddle.Tensor.ceil(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29561758041381836 	 0.29790663719177246 	 0.2799072265625 	 0.28126072883605957 	 0.1338670253753662 	 0.13428330421447754 	 0.07295703887939453 	 0.05760788917541504 	 
2025-07-25 18:29:33.225129 test begin: paddle.Tensor.ceil(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2955641746520996 	 1.3134396076202393 	 0.2869589328765869 	 0.28069329261779785 	 0.13454699516296387 	 0.1351945400238037 	 0.07990002632141113 	 0.04405951499938965 	 
2025-07-25 18:29:39.187106 test begin: paddle.Tensor.ceil(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29566454887390137 	 0.2979147434234619 	 0.28696656227111816 	 0.2862508296966553 	 0.13402652740478516 	 0.13440847396850586 	 0.08080625534057617 	 0.06803464889526367 	 
2025-07-25 18:29:41.707997 test begin: paddle.Tensor.ceil(Tensor([25401601, 2],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([25401601, 2],"float32"), ) 	 50803202 	 1000 	 0.29555678367614746 	 0.2979283332824707 	 0.2870147228240967 	 0.28749895095825195 	 0.13396549224853516 	 0.13423681259155273 	 0.08159756660461426 	 0.06644988059997559 	 
2025-07-25 18:29:44.226214 test begin: paddle.Tensor.ceil(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2956256866455078 	 0.2979097366333008 	 0.2799530029296875 	 0.2813136577606201 	 0.13392424583435059 	 0.13425874710083008 	 0.07278752326965332 	 0.06194186210632324 	 
2025-07-25 18:29:46.871331 test begin: paddle.Tensor.ceil(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2955610752105713 	 0.29972219467163086 	 0.2866544723510742 	 0.28749966621398926 	 0.13408422470092773 	 0.134202241897583 	 0.0821077823638916 	 0.06849336624145508 	 
2025-07-25 18:29:49.422203 test begin: paddle.Tensor.chunk(Tensor([1034, 32, 64, 48],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([1034, 32, 64, 48],"float16"), 2, axis=1, ) 	 101646336 	 1000 	 0.46082234382629395 	 0.006522655487060547 	 0.4461236000061035 	 2.0742416381835938e-05 	 0.3091154098510742 	 0.45220160484313965 	 0.25046873092651367 	 0.36725521087646484 	 
2025-07-25 18:29:54.516290 test begin: paddle.Tensor.chunk(Tensor([128, 2068, 192],"float32"), 3, axis=-1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([128, 2068, 192],"float32"), 3, axis=-1, ) 	 50823168 	 1000 	 0.3451974391937256 	 0.007505893707275391 	 0.329392671585083 	 1.8835067749023438e-05 	 0.3099939823150635 	 0.30866122245788574 	 0.2499549388885498 	 0.19760394096374512 	 
2025-07-25 18:29:57.146426 test begin: paddle.Tensor.chunk(Tensor([512, 32, 130, 48],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 130, 48],"float16"), 2, axis=1, ) 	 102236160 	 1000 	 0.4581911563873291 	 0.0064830780029296875 	 0.44414663314819336 	 2.193450927734375e-05 	 0.31633734703063965 	 0.4545555114746094 	 0.25776219367980957 	 0.37070655822753906 	 
2025-07-25 18:30:02.182619 test begin: paddle.Tensor.chunk(Tensor([512, 32, 64, 49],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 64, 49],"float32"), 2, axis=1, ) 	 51380224 	 1000 	 0.3536043167114258 	 0.006557464599609375 	 0.3397057056427002 	 2.0265579223632812e-05 	 0.31734704971313477 	 0.3133847713470459 	 0.2599904537200928 	 0.22948479652404785 	 
2025-07-25 18:30:04.842845 test begin: paddle.Tensor.chunk(Tensor([512, 32, 64, 97],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 64, 97],"float16"), 2, axis=1, ) 	 101711872 	 1000 	 0.4575798511505127 	 0.006597757339477539 	 0.4434676170349121 	 2.6702880859375e-05 	 0.3151543140411377 	 0.45200467109680176 	 0.25742173194885254 	 0.3561849594116211 	 
2025-07-25 18:30:09.842748 test begin: paddle.Tensor.chunk(Tensor([512, 32, 65, 48],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 65, 48],"float32"), 2, axis=1, ) 	 51118080 	 1000 	 0.3523690700531006 	 0.007992744445800781 	 0.33826589584350586 	 5.14984130859375e-05 	 0.31634044647216797 	 0.3122396469116211 	 0.25852203369140625 	 0.22823500633239746 	 
2025-07-25 18:30:12.503684 test begin: paddle.Tensor.chunk(Tensor([517, 32, 64, 48],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([517, 32, 64, 48],"float32"), 2, axis=1, ) 	 50823168 	 1000 	 0.3510410785675049 	 0.011526823043823242 	 0.33696460723876953 	 2.6702880859375e-05 	 0.30923962593078613 	 0.31172704696655273 	 0.25055861473083496 	 0.22269558906555176 	 
2025-07-25 18:30:17.202806 test begin: paddle.Tensor.chunk(Tensor([85, 3136, 192],"float32"), 3, axis=-1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([85, 3136, 192],"float32"), 3, axis=-1, ) 	 51179520 	 1000 	 0.3468799591064453 	 0.007467508316040039 	 0.3313753604888916 	 1.9788742065429688e-05 	 0.3121190071105957 	 0.31105518341064453 	 0.24244356155395508 	 0.17439842224121094 	 
2025-07-25 18:30:20.652765 test begin: paddle.Tensor.clip(Tensor([1, 386, 65856, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 386, 65856, 2],"float32"), 0, ) 	 50840832 	 1000 	 0.29558444023132324 	 0.29976773262023926 	 0.2785947322845459 	 0.2851524353027344 	 0.4503214359283447 	 0.596064567565918 	 0.39301538467407227 	 0.20316123962402344 	 
2025-07-25 18:30:24.014803 test begin: paddle.Tensor.clip(Tensor([1, 400, 63505, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 400, 63505, 2],"float32"), 0, ) 	 50804000 	 1000 	 0.29522228240966797 	 0.2979288101196289 	 0.2787303924560547 	 0.2850055694580078 	 0.44986414909362793 	 0.5956525802612305 	 0.39536452293395996 	 0.20307016372680664 	 
2025-07-25 18:30:27.409062 test begin: paddle.Tensor.clip(Tensor([1, 400, 65856, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 400, 65856, 2],"float32"), 0, ) 	 52684800 	 1000 	 0.3063547611236572 	 0.3087120056152344 	 0.28970789909362793 	 0.2954742908477783 	 0.4663965702056885 	 0.6167941093444824 	 0.40903520584106445 	 0.21026372909545898 	 
2025-07-25 18:30:30.886218 test begin: paddle.Tensor.clip(Tensor([2100, 12096, 3],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2100, 12096, 3],"float32"), 0, ) 	 76204800 	 1000 	 0.4409627914428711 	 0.4442257881164551 	 0.4152076244354248 	 0.4235970973968506 	 0.6726462841033936 	 0.8851642608642578 	 0.6089818477630615 	 0.3017873764038086 	 
2025-07-25 18:30:37.726846 test begin: paddle.Tensor.clip(Tensor([2100, 12097, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2100, 12097, 2],"float32"), 0, ) 	 50807400 	 1000 	 0.2951996326446533 	 0.3096771240234375 	 0.2783219814300537 	 0.2848241329193115 	 0.4495809078216553 	 0.5957705974578857 	 0.3945450782775879 	 0.20309782028198242 	 
2025-07-25 18:30:41.640554 test begin: paddle.Tensor.clip(Tensor([2101, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2101, 12096, 2],"float32"), 0, ) 	 50827392 	 1000 	 0.2953948974609375 	 0.3079073429107666 	 0.26995325088500977 	 0.2783946990966797 	 0.4498140811920166 	 0.595858097076416 	 0.3862488269805908 	 0.20313811302185059 	 
2025-07-25 18:30:45.013901 test begin: paddle.Tensor.clip(Tensor([4, 525, 12096, 3],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 525, 12096, 3],"float32"), 0, ) 	 76204800 	 1000 	 0.44086503982543945 	 0.4441545009613037 	 0.4153456687927246 	 0.424083948135376 	 0.6727256774902344 	 0.885075569152832 	 0.6047928333282471 	 0.30175018310546875 	 
2025-07-25 18:30:50.097614 test begin: paddle.Tensor.clip(Tensor([4, 525, 12097, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 525, 12097, 2],"float32"), 0, ) 	 50807400 	 1000 	 0.2951533794403076 	 0.3038454055786133 	 0.26937270164489746 	 0.27828288078308105 	 0.44959092140197754 	 0.595740795135498 	 0.3861517906188965 	 0.20308780670166016 	 
2025-07-25 18:30:53.487011 test begin: paddle.Tensor.clip(Tensor([4, 526, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 526, 12096, 2],"float32"), 0, ) 	 50899968 	 1000 	 0.29592013359069824 	 0.2985215187072754 	 0.27045512199401855 	 0.278531551361084 	 0.4509894847869873 	 0.5966126918792725 	 0.3729062080383301 	 0.20337915420532227 	 
2025-07-25 18:30:56.913893 test begin: paddle.Tensor.clip(Tensor([5, 525, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([5, 525, 12096, 2],"float32"), 0, ) 	 63504000 	 1000 	 0.36771178245544434 	 0.37104153633117676 	 0.34245753288269043 	 0.34865379333496094 	 0.5609033107757568 	 0.7397348880767822 	 0.4974522590637207 	 0.2522108554840088 	 
2025-07-25 18:31:01.073147 test begin: paddle.Tensor.clone(Tensor([3544, 32, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([3544, 32, 896],"bfloat16"), ) 	 101613568 	 1000 	 0.31040120124816895 	 0.3142557144165039 	 0.29523754119873047 	 0.2972683906555176 	 0.6155450344085693 	 0.4536104202270508 	 0.5477509498596191 	 0.3709127902984619 	 
2025-07-25 18:31:07.628672 test begin: paddle.Tensor.clone(Tensor([6017, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6017, 19, 896],"bfloat16"), ) 	 102433408 	 1000 	 0.3169257640838623 	 0.315321683883667 	 0.16194605827331543 	 0.1610546112060547 	 0.627671480178833 	 0.457242488861084 	 0.3206338882446289 	 0.3687324523925781 	 
2025-07-25 18:31:12.665693 test begin: paddle.Tensor.clone(Tensor([6017, 32, 528],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6017, 32, 528],"bfloat16"), ) 	 101663232 	 1000 	 0.31507205963134766 	 0.31307220458984375 	 0.16097497940063477 	 0.15986061096191406 	 0.6218838691711426 	 0.453845739364624 	 0.3177156448364258 	 0.36527562141418457 	 
2025-07-25 18:31:17.726958 test begin: paddle.Tensor.clone(Tensor([6036, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6036, 19, 896],"bfloat16"), ) 	 102756864 	 1000 	 0.31800270080566406 	 0.32274532318115234 	 0.16249752044677734 	 0.16140007972717285 	 0.6285438537597656 	 0.4586620330810547 	 0.32112979888916016 	 0.379565954208374 	 
2025-07-25 18:31:26.508938 test begin: paddle.Tensor.clone(Tensor([6036, 32, 527],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6036, 32, 527],"bfloat16"), ) 	 101791104 	 1000 	 0.3151414394378662 	 0.3135049343109131 	 0.16105365753173828 	 0.1600944995880127 	 0.6231462955474854 	 0.454500675201416 	 0.31838369369506836 	 0.3655736446380615 	 
2025-07-25 18:31:31.690925 test begin: paddle.Tensor.clone(Tensor([6078, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6078, 19, 896],"bfloat16"), ) 	 103471872 	 1000 	 0.31360697746276855 	 0.5452110767364502 	 0.16025233268737793 	 0.16277575492858887 	 0.6178624629974365 	 0.46145033836364746 	 0.3156442642211914 	 0.3827247619628906 	 
2025-07-25 18:31:40.392630 test begin: paddle.Tensor.clone(Tensor([6078, 32, 523],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6078, 32, 523],"bfloat16"), ) 	 101721408 	 1000 	 0.31420373916625977 	 0.3156857490539551 	 0.1605520248413086 	 0.15996742248535156 	 0.6238527297973633 	 0.4542241096496582 	 0.3187265396118164 	 0.36521339416503906 	 
2025-07-25 18:31:45.548342 test begin: paddle.Tensor.conj(Tensor([10, 2540161],"float64"), )
[Prof] paddle.Tensor.conj 	 paddle.Tensor.conj(Tensor([10, 2540161],"float64"), ) 	 25401610 	 1000 	 0.2977473735809326 	 0.0015864372253417969 	 0.2896609306335449 	 1.430511474609375e-05 	 0.2975633144378662 	 0.0467374324798584 	 0.24682831764221191 	 3.4332275390625e-05 	 
2025-07-25 18:31:47.305008 test begin: paddle.Tensor.conj(Tensor([1270081, 20],"float64"), )
[Prof] paddle.Tensor.conj 	 paddle.Tensor.conj(Tensor([1270081, 20],"float64"), ) 	 25401620 	 1000 	 0.2977571487426758 	 0.0015947818756103516 	 0.28972911834716797 	 1.4781951904296875e-05 	 0.29751157760620117 	 0.045395612716674805 	 0.24648237228393555 	 2.9802322387695312e-05 	 
2025-07-25 18:31:49.032514 test begin: paddle.Tensor.cos(Tensor([131072, 388],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([131072, 388],"float32"), ) 	 50855936 	 1000 	 0.2957289218902588 	 0.29848289489746094 	 0.28714609146118164 	 0.28788256645202637 	 0.4505641460418701 	 1.0420053005218506 	 0.3941802978515625 	 0.3549830913543701 	 
2025-07-25 18:31:52.804309 test begin: paddle.Tensor.cos(Tensor([3175201, 16],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([3175201, 16],"float32"), ) 	 50803216 	 1000 	 0.2954988479614258 	 0.2982039451599121 	 0.2868833541870117 	 0.28789544105529785 	 0.4499680995941162 	 1.041001558303833 	 0.39523839950561523 	 0.3546755313873291 	 
2025-07-25 18:31:56.534004 test begin: paddle.Tensor.cos(Tensor([32768, 1551],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.2954678535461426 	 0.299252986907959 	 0.2868032455444336 	 0.2878866195678711 	 0.4502887725830078 	 1.0445349216461182 	 0.3950366973876953 	 0.3547384738922119 	 
2025-07-25 18:32:00.307085 test begin: paddle.Tensor.cos(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29533910751342773 	 0.29814910888671875 	 0.2867898941040039 	 0.2879011631011963 	 0.4499695301055908 	 1.0410959720611572 	 0.3818016052246094 	 0.35466504096984863 	 
2025-07-25 18:32:04.077524 test begin: paddle.Tensor.cumprod(Tensor([25401601],"float64"), -1, )
[Prof] paddle.Tensor.cumprod 	 paddle.Tensor.cumprod(Tensor([25401601],"float64"), -1, ) 	 25401601 	 1000 	 0.32645654678344727 	 0.32874584197998047 	 0.166795015335083 	 0.16786909103393555 	 2.798956871032715 	 2.061218500137329 	 0.00031638145446777344 	 0.0013065338134765625 	 
2025-07-25 18:32:10.752542 test begin: paddle.Tensor.cumprod(Tensor([50803201],"float32"), -1, )
[Prof] paddle.Tensor.cumprod 	 paddle.Tensor.cumprod(Tensor([50803201],"float32"), -1, ) 	 50803201 	 1000 	 0.32688117027282715 	 0.33071231842041016 	 0.16704392433166504 	 0.16900324821472168 	 3.1402053833007812 	 2.1244075298309326 	 0.00030422210693359375 	 0.0013089179992675781 	 
2025-07-25 18:32:18.417387 test begin: paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 1, ) 	 50803344 	 1000 	 1.2543997764587402 	 0.3658170700073242 	 0.42739295959472656 	 0.3429994583129883 	 6.395296335220337 	 0.9771754741668701 	 1.3075041770935059 	 0.3328397274017334 	 
2025-07-25 18:32:31.874020 test begin: paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 2, ) 	 50803344 	 1000 	 0.8934972286224365 	 1.2909448146820068 	 0.8840024471282959 	 1.0429959297180176 	 1.6926779747009277 	 1.6414999961853027 	 0.5767831802368164 	 0.559281587600708 	 
2025-07-25 18:32:42.147553 test begin: paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 1, ) 	 50803400 	 1000 	 1.4268393516540527 	 124.24298477172852 	 0.4861929416656494 	 124.23198652267456 	 2.1592493057250977 	 122.22074341773987 	 0.44141626358032227 	 41.677199840545654 	 
2025-07-25 18:36:55.038662 test begin: paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 2, ) 	 50803400 	 1000 	 0.40464282035827637 	 2.8177490234375 	 0.38794922828674316 	 2.800259828567505 	 4.1544249057769775 	 3.440821409225464 	 1.4147765636444092 	 1.1729145050048828 	 
2025-07-25 18:37:07.600005 test begin: paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 1, ) 	 50832000 	 1000 	 1.285438060760498 	 0.36539459228515625 	 0.4379563331604004 	 0.3513047695159912 	 6.432002544403076 	 0.9931879043579102 	 1.3151330947875977 	 0.3383464813232422 	 
2025-07-25 18:37:18.421793 test begin: paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 2, ) 	 50832000 	 1000 	 0.405026912689209 	 2.8191959857940674 	 0.3882462978363037 	 2.808157205581665 	 4.1543402671813965 	 3.4429433345794678 	 1.4147312641143799 	 1.1737174987792969 	 
2025-07-25 18:37:30.978818 test begin: paddle.Tensor.cumsum(Tensor([211681, 120],"int64"), )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([211681, 120],"int64"), ) 	 25401720 	 1000 	 0.35612034797668457 	 0.327528715133667 	 4.315376281738281e-05 	 0.1672196388244629 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:32.916338 test begin: paddle.Tensor.cumsum(Tensor([300, 84673],"int64"), )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([300, 84673],"int64"), ) 	 25401900 	 1000 	 0.3540811538696289 	 0.3432796001434326 	 2.6464462280273438e-05 	 0.16730809211730957 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:34.872699 test begin: paddle.Tensor.detach(Tensor([100352, 1013],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([100352, 1013],"bfloat16"), ) 	 101656576 	 1000 	 0.0009598731994628906 	 0.002984285354614258 	 8.106231689453125e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:39.555072 test begin: paddle.Tensor.detach(Tensor([1013, 100352],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([1013, 100352],"bfloat16"), ) 	 101656576 	 1000 	 0.0009903907775878906 	 0.005150318145751953 	 1.5497207641601562e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:42.932852 test begin: paddle.Tensor.detach(Tensor([12404, 8192],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([12404, 8192],"bfloat16"), ) 	 101613568 	 1000 	 0.0007593631744384766 	 0.002954721450805664 	 1.0251998901367188e-05 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:46.394347 test begin: paddle.Tensor.detach(Tensor([1772, 57344],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([1772, 57344],"bfloat16"), ) 	 101613568 	 1000 	 0.0007534027099609375 	 0.0029680728912353516 	 6.9141387939453125e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:49.689766 test begin: paddle.Tensor.detach(Tensor([8192, 12404],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([8192, 12404],"bfloat16"), ) 	 101613568 	 1000 	 0.0007510185241699219 	 0.002938985824584961 	 1.0251998901367188e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:37:53.058047 test begin: paddle.Tensor.diag_embed(Tensor([1, 25401601, 2],"float32"), )
[Prof] paddle.Tensor.diag_embed 	 paddle.Tensor.diag_embed(Tensor([1, 25401601, 2],"float32"), ) 	 50803202 	 1000 	 1.7745146751403809 	 1.0135219097137451 	 4.1484832763671875e-05 	 0.5177364349365234 	 None 	 None 	 None 	 None 	 
2025-07-25 18:37:56.661904 test begin: paddle.Tensor.diag_embed(Tensor([25401601, 1, 2],"float32"), )
[Prof] paddle.Tensor.diag_embed 	 paddle.Tensor.diag_embed(Tensor([25401601, 1, 2],"float32"), ) 	 50803202 	 1000 	 1.7765142917633057 	 1.028304100036621 	 6.437301635742188e-05 	 0.5179595947265625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:02.309723 test begin: paddle.Tensor.diagonal(Tensor([2, 25401601],"float32"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([2, 25401601],"float32"), axis1=-2, axis2=-1, ) 	 50803202 	 1000 	 0.0038154125213623047 	 0.0046482086181640625 	 1.2636184692382812e-05 	 2.09808349609375e-05 	 0.14950823783874512 	 0.13816332817077637 	 0.07632732391357422 	 0.037770986557006836 	 
2025-07-25 18:38:03.487166 test begin: paddle.Tensor.diagonal(Tensor([25401601, 2],"float32"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([25401601, 2],"float32"), axis1=-2, axis2=-1, ) 	 50803202 	 1000 	 0.0037517547607421875 	 0.0046503543853759766 	 1.0967254638671875e-05 	 1.71661376953125e-05 	 0.14930415153503418 	 0.1384906768798828 	 0.07626771926879883 	 0.06442427635192871 	 
2025-07-25 18:38:04.625894 test begin: paddle.Tensor.diagonal(Tensor([3, 8467201],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([3, 8467201],"float64"), axis1=-2, axis2=-1, ) 	 25401603 	 1000 	 0.003751993179321289 	 0.0046999454498291016 	 1.0967254638671875e-05 	 1.7404556274414062e-05 	 0.14676666259765625 	 0.138352632522583 	 0.07503986358642578 	 0.06420326232910156 	 
2025-07-25 18:38:05.476237 test begin: paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, ) 	 25401603 	 1000 	 0.003745555877685547 	 0.004710197448730469 	 7.152557373046875e-06 	 1.6450881958007812e-05 	 0.14669442176818848 	 0.13831353187561035 	 0.07489252090454102 	 0.06311774253845215 	 
2025-07-25 18:38:06.295180 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.9445269107818604 	 0.2616145610809326 	 0.321972131729126 	 0.2351093292236328 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:08.097365 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.9439582824707031 	 0.261594295501709 	 0.3215909004211426 	 0.24242043495178223 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:09.829021 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.9448165893554688 	 0.261594295501709 	 0.32207679748535156 	 0.23410248756408691 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:11.602811 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.8707964420318604 	 0.261566162109375 	 0.29667067527770996 	 0.24339914321899414 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:13.268661 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8707277774810791 	 0.26517820358276367 	 0.29662442207336426 	 0.24256110191345215 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:14.951240 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8707382678985596 	 0.2617321014404297 	 0.29665517807006836 	 0.2384035587310791 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:16.638729 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.8706488609313965 	 0.2615985870361328 	 0.2966313362121582 	 0.24323177337646484 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:18.294374 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 1.0701148509979248 	 0.3009376525878906 	 0.3646581172943115 	 0.28028202056884766 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:20.194299 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 1.0701067447662354 	 0.29947328567504883 	 0.36457014083862305 	 0.28041791915893555 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:22.103219 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 1.0700147151947021 	 0.2994539737701416 	 0.3645310401916504 	 0.28118324279785156 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:24.001130 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8072502613067627 	 0.2629392147064209 	 0.27503204345703125 	 0.24382948875427246 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:25.619850 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8072032928466797 	 0.26312851905822754 	 0.27501749992370605 	 0.24379801750183105 	 None 	 None 	 None 	 None 	 
2025-07-25 18:38:27.256505 test begin: paddle.Tensor.digamma(Tensor([4, 6350401],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 1.1690356731414795 	 1.1640872955322266 	 1.1607859134674072 	 1.1309301853179932 	 8.883338689804077 	 1.0845682621002197 	 8.830580949783325 	 0.5541276931762695 	 
2025-07-25 18:38:41.896399 test begin: paddle.Tensor.digamma(Tensor([453601, 7, 8],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([453601, 7, 8],"float64"), ) 	 25401656 	 1000 	 1.1688013076782227 	 1.1420161724090576 	 1.160445213317871 	 1.1321790218353271 	 8.560603618621826 	 1.0844855308532715 	 8.501682043075562 	 0.554100751876831 	 
2025-07-25 18:38:55.024390 test begin: paddle.Tensor.digamma(Tensor([45361, 7, 8, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([45361, 7, 8, 10],"float64"), ) 	 25402160 	 1000 	 1.1688158512115479 	 1.360107660293579 	 1.1604373455047607 	 1.3466241359710693 	 8.560997486114502 	 1.0845422744750977 	 8.49108362197876 	 0.5540874004364014 	 
2025-07-25 18:39:09.304047 test begin: paddle.Tensor.digamma(Tensor([5, 635041, 8],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 635041, 8],"float64"), ) 	 25401640 	 1000 	 1.1687486171722412 	 1.1419448852539062 	 1.1603467464447021 	 1.1260478496551514 	 8.560572147369385 	 1.084348440170288 	 8.506864786148071 	 0.5540502071380615 	 
2025-07-25 18:39:22.422784 test begin: paddle.Tensor.digamma(Tensor([5, 63505, 8, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 63505, 8, 10],"float64"), ) 	 25402000 	 1000 	 1.1687572002410889 	 1.1418275833129883 	 1.1602928638458252 	 1.1319966316223145 	 8.559410095214844 	 1.0843172073364258 	 8.506635665893555 	 0.5540275573730469 	 
2025-07-25 18:39:37.369689 test begin: paddle.Tensor.digamma(Tensor([5, 7, 725761],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 725761],"float64"), ) 	 25401635 	 1000 	 1.1686174869537354 	 1.1419029235839844 	 1.160285234451294 	 1.132028341293335 	 8.560120105743408 	 1.084367275238037 	 8.506759881973267 	 0.5540344715118408 	 
2025-07-25 18:39:50.475851 test begin: paddle.Tensor.digamma(Tensor([5, 7, 72577, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 72577, 10],"float64"), ) 	 25401950 	 1000 	 1.168576955795288 	 1.1417016983032227 	 1.1603138446807861 	 1.1318600177764893 	 8.56024694442749 	 1.0851702690124512 	 8.507530689239502 	 0.5548498630523682 	 
2025-07-25 18:40:03.575232 test begin: paddle.Tensor.digamma(Tensor([5, 7, 8, 90721],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 8, 90721],"float64"), ) 	 25401880 	 1000 	 1.1685030460357666 	 1.1454463005065918 	 1.160301923751831 	 1.1250510215759277 	 8.562355518341064 	 1.0864343643188477 	 8.503664255142212 	 0.5552124977111816 	 
2025-07-25 18:40:17.002820 test begin: paddle.Tensor.digamma(Tensor([5080321, 5],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5080321, 5],"float64"), ) 	 25401605 	 1000 	 1.1684234142303467 	 1.1417338848114014 	 1.16005539894104 	 1.1259937286376953 	 8.560838460922241 	 1.0861754417419434 	 8.49399447441101 	 0.55513596534729 	 
2025-07-25 18:40:30.129836 test begin: paddle.Tensor.dim(Tensor([111616, 911],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([111616, 911],"bfloat16"), ) 	 101682176 	 1000 	 0.0007088184356689453 	 0.0015025138854980469 	 9.298324584960938e-06 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:31.813971 test begin: paddle.Tensor.dim(Tensor([12404, 8192],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([12404, 8192],"bfloat16"), ) 	 101613568 	 1000 	 0.0006930828094482422 	 0.0014910697937011719 	 6.67572021484375e-06 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:33.431561 test begin: paddle.Tensor.dim(Tensor([14176, 7168],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([14176, 7168],"bfloat16"), ) 	 101613568 	 1000 	 0.0011496543884277344 	 0.001535654067993164 	 2.3603439331054688e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:35.072643 test begin: paddle.Tensor.dim(Tensor([7168, 14176],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([7168, 14176],"bfloat16"), ) 	 101613568 	 1000 	 0.0007159709930419922 	 0.0028963088989257812 	 6.9141387939453125e-06 	 0.00011110305786132812 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:37.136955 test begin: paddle.Tensor.dim(Tensor([911, 111616],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([911, 111616],"bfloat16"), ) 	 101682176 	 1000 	 0.0006976127624511719 	 0.0014965534210205078 	 9.059906005859375e-06 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:39.278929 test begin: paddle.Tensor.dim(Tensor([95872, 1060],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([95872, 1060],"bfloat16"), ) 	 101624320 	 1000 	 0.0007021427154541016 	 0.0015192031860351562 	 1.33514404296875e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:40.965763 test begin: paddle.Tensor.dot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
Warning: The core code of paddle.Tensor.dot is too complex.
[Prof] paddle.Tensor.dot 	 paddle.Tensor.dot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.2960643768310547 	 0.2932887077331543 	 0.28725385665893555 	 0.1498429775238037 	 0.7104361057281494 	 0.6040332317352295 	 0.3630375862121582 	 0.3085958957672119 	 
2025-07-25 18:40:44.608884 test begin: paddle.Tensor.equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), ) 	 50803456 	 1000 	 0.30882906913757324 	 0.3201756477355957 	 0.298506498336792 	 0.30190348625183105 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:46.053534 test begin: paddle.Tensor.equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), ) 	 50803456 	 1000 	 0.3088541030883789 	 0.31426501274108887 	 0.2911524772644043 	 0.29563093185424805 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:47.546134 test begin: paddle.Tensor.equal(Tensor([2, 12700801],"int64"), 3, )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([2, 12700801],"int64"), 3, ) 	 25401602 	 1000 	 0.1779797077178955 	 0.18277740478515625 	 0.09092974662780762 	 0.1537787914276123 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:48.326902 test begin: paddle.Tensor.equal(Tensor([2540161, 10],"int64"), 3, )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([2540161, 10],"int64"), 3, ) 	 25401610 	 1000 	 0.1779181957244873 	 0.16821789741516113 	 0.0908820629119873 	 0.14693069458007812 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:49.139972 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 0.3430156707763672 	 0.3821845054626465 	 0.11667609214782715 	 7.581710815429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:50.734082 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([8],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([8],"int64"), ) 	 25401609 	 1000 	 0.017000675201416016 	 0.0026586055755615234 	 1.9311904907226562e-05 	 1.52587890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:51.165977 test begin: paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3175201],"int64"), ) 	 50803216 	 1000 	 0.3429841995239258 	 0.3814077377319336 	 0.1166536808013916 	 7.009506225585938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:52.717909 test begin: paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3],"int64"), ) 	 25401632 	 1000 	 0.01699662208557129 	 0.0028908252716064453 	 8.821487426757812e-06 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:53.148607 test begin: paddle.Tensor.equal_all(Tensor([8, 3],"int64"), Tensor([8, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8, 3],"int64"), Tensor([8, 3175201],"int64"), ) 	 25401632 	 1000 	 0.016831159591674805 	 0.0027053356170654297 	 1.3113021850585938e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:53.585544 test begin: paddle.Tensor.equal_all(Tensor([8, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 25401627 	 1000 	 0.016927719116210938 	 0.0026259422302246094 	 9.298324584960938e-06 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:54.026791 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8, 3],"int64"), ) 	 25401627 	 1000 	 0.02049541473388672 	 0.0026221275329589844 	 2.6941299438476562e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:54.469769 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 50803206 	 1000 	 0.3429901599884033 	 0.378450870513916 	 0.11665153503417969 	 7.033348083496094e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:56.026624 test begin: paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([25401601],"int64"), ) 	 25401609 	 1000 	 0.017167091369628906 	 0.0038106441497802734 	 8.821487426757812e-06 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:40:56.471459 test begin: paddle.Tensor.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.3316771984100342 	 0.3089773654937744 	 0.3232908248901367 	 0.29761743545532227 	 0.44802141189575195 	 1.642716646194458 	 0.39345860481262207 	 0.3358135223388672 	 
2025-07-25 18:41:00.304984 test begin: paddle.Tensor.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3326852321624756 	 0.31277012825012207 	 0.32434535026550293 	 0.29900574684143066 	 0.4480299949645996 	 1.6427204608917236 	 0.39206814765930176 	 0.3358590602874756 	 
2025-07-25 18:41:04.162498 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.33443236351013184 	 1.3446283340454102 	 0.32588744163513184 	 0.2969858646392822 	 0.44743800163269043 	 1.642773151397705 	 0.3927140235900879 	 0.33589720726013184 	 
2025-07-25 18:41:12.161448 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.334303617477417 	 0.3215367794036865 	 0.32594823837280273 	 0.2991490364074707 	 0.4474031925201416 	 1.6427514553070068 	 0.3933374881744385 	 0.3359510898590088 	 
2025-07-25 18:41:17.572576 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.3345670700073242 	 0.3399693965911865 	 0.31898021697998047 	 0.2969777584075928 	 0.4473075866699219 	 1.6426827907562256 	 0.3841371536254883 	 0.33586668968200684 	 
2025-07-25 18:41:22.386344 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.3347434997558594 	 0.3105902671813965 	 0.31896519660949707 	 0.2945582866668701 	 0.44808316230773926 	 1.6426727771759033 	 0.3844573497772217 	 0.33585643768310547 	 
2025-07-25 18:41:26.291068 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3175201],"float64"), ) 	 25401608 	 1000 	 0.33434462547302246 	 0.31296277046203613 	 0.32605409622192383 	 0.30145692825317383 	 0.447420597076416 	 1.6426455974578857 	 0.3920257091522217 	 0.33583736419677734 	 
2025-07-25 18:41:30.137182 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3343539237976074 	 0.3119626045227051 	 0.3260459899902344 	 0.3016624450683594 	 0.447420597076416 	 1.6428618431091309 	 0.39309072494506836 	 0.3358139991760254 	 
2025-07-25 18:41:34.032208 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2116801, 3],"float64"), ) 	 25401612 	 1000 	 0.334625244140625 	 0.32585692405700684 	 0.326246976852417 	 0.2998795509338379 	 0.44733238220214844 	 1.6428680419921875 	 0.39011383056640625 	 0.3358733654022217 	 
2025-07-25 18:41:42.014225 test begin: paddle.Tensor.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.33443450927734375 	 0.31183552742004395 	 0.3262021541595459 	 0.3019583225250244 	 0.44739603996276855 	 1.6427128314971924 	 0.3880879878997803 	 0.3358738422393799 	 
2025-07-25 18:41:45.798527 test begin: paddle.Tensor.erfinv(x=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.3345305919647217 	 0.3165576457977295 	 0.32610058784484863 	 0.3016972541809082 	 0.4474067687988281 	 1.642836332321167 	 0.39266252517700195 	 0.33579277992248535 	 
2025-07-25 18:41:49.582891 test begin: paddle.Tensor.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.33441781997680664 	 0.31208157539367676 	 0.326047420501709 	 0.3020765781402588 	 0.44744873046875 	 1.642754316329956 	 0.37474679946899414 	 0.3358626365661621 	 
2025-07-25 18:41:53.393955 test begin: paddle.Tensor.exp(Tensor([1000000, 26],"float64"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([1000000, 26],"float64"), ) 	 26000000 	 1000 	 0.30573034286499023 	 0.30750346183776855 	 0.2977287769317627 	 0.29655981063842773 	 0.4589989185333252 	 0.45493531227111816 	 0.4043545722961426 	 0.3890068531036377 	 
2025-07-25 18:41:55.995964 test begin: paddle.Tensor.exp(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2954442501068115 	 0.29782986640930176 	 0.2872798442840576 	 0.2838883399963379 	 0.4492156505584717 	 0.44667840003967285 	 0.3941171169281006 	 0.3767271041870117 	 
2025-07-25 18:41:59.142134 test begin: paddle.Tensor.exp(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2953798770904541 	 0.29781651496887207 	 0.2871522903442383 	 0.2874150276184082 	 0.4492015838623047 	 0.44666266441345215 	 0.3941986560821533 	 0.3809645175933838 	 
2025-07-25 18:42:02.320004 test begin: paddle.Tensor.exp(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.2993340492248535 	 0.30298900604248047 	 0.29135584831237793 	 0.2897367477416992 	 0.4474916458129883 	 0.4444739818572998 	 0.3929414749145508 	 0.37804412841796875 	 
2025-07-25 18:42:04.875454 test begin: paddle.Tensor.exp(Tensor([64, 793801],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([64, 793801],"float32"), ) 	 50803264 	 1000 	 0.2954566478729248 	 0.29787564277648926 	 0.28000783920288086 	 0.2783846855163574 	 0.44917893409729004 	 0.44665050506591797 	 0.38474488258361816 	 0.37184715270996094 	 
2025-07-25 18:42:08.072718 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 266, 477, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 266, 477, 401],"float32"), ) 	 50879683 	 1000 	 0.1350083351135254 	 0.00396728515625 	 0.12352633476257324 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:10.064808 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 283, 466, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 283, 466, 386],"float32"), ) 	 50904909 	 1000 	 0.13507294654846191 	 0.004015207290649414 	 0.12383151054382324 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:12.026193 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 299, 391, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 299, 391, 436],"float32"), ) 	 50972325 	 1000 	 0.13528871536254883 	 0.004029750823974609 	 0.12413597106933594 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:13.960624 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 38841, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 38841, 436],"float32"), ) 	 50804029 	 1000 	 0.13469719886779785 	 0.0040357112884521484 	 0.1235344409942627 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:15.905748 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 391, 43311],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 391, 43311],"float32"), ) 	 50803804 	 1000 	 0.1347663402557373 	 0.0076749324798583984 	 0.11574196815490723 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:17.861997 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 42231, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 42231, 401],"float32"), ) 	 50803894 	 1000 	 0.1347217559814453 	 0.007734775543212891 	 0.11572885513305664 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:19.794979 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 43872, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 43872, 386],"float32"), ) 	 50803777 	 1000 	 0.13512063026428223 	 0.004067420959472656 	 0.11618232727050781 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:22.987438 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 466, 36340],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 466, 36340],"float32"), ) 	 50803321 	 1000 	 0.1347494125366211 	 0.007662057876586914 	 0.11563539505004883 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:26.339833 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 477, 35502],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 477, 35502],"float32"), ) 	 50803363 	 1000 	 0.1347050666809082 	 0.004108905792236328 	 0.11513781547546387 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:28.343285 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([100, 3, 391, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([100, 3, 391, 436],"float32"), ) 	 51142801 	 1000 	 0.13571906089782715 	 0.004003286361694336 	 0.12449812889099121 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:30.291312 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([89, 3, 477, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([89, 3, 477, 401],"float32"), ) 	 51070960 	 1000 	 0.13558340072631836 	 0.004010438919067383 	 0.12438797950744629 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:32.223706 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([95, 3, 466, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([95, 3, 466, 386],"float32"), ) 	 51264661 	 1000 	 0.13623404502868652 	 0.004043102264404297 	 0.12509655952453613 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:42:34.175442 test begin: paddle.Tensor.fill_(Tensor([50803201],"float32"), 0, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([50803201],"float32"), 0, ) 	 50803201 	 1000 	 0.14606404304504395 	 0.13423609733581543 	 0.13028430938720703 	 0.1254441738128662 	 None 	 None 	 None 	 None 	 
2025-07-25 18:42:38.505747 test begin: paddle.Tensor.fill_(Tensor([659782, 77],"float32"), value=-math.inf, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([659782, 77],"float32"), value=-math.inf, ) 	 50803214 	 1000 	 0.14577078819274902 	 0.13430380821228027 	 0.13010168075561523 	 0.1259288787841797 	 None 	 None 	 None 	 None 	 
2025-07-25 18:42:40.894442 test begin: paddle.Tensor.fill_(Tensor([77, 659782],"float32"), value=-math.inf, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([77, 659782],"float32"), value=-math.inf, ) 	 50803214 	 1000 	 0.14595365524291992 	 0.13430476188659668 	 0.12380266189575195 	 0.12026524543762207 	 None 	 None 	 None 	 None 	 
2025-07-25 18:42:42.930428 test begin: paddle.Tensor.fill_(x=Tensor([10, 158761, 16],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([10, 158761, 16],"float64"), value=41.2, ) 	 25401760 	 1000 	 0.147233247756958 	 0.13467669486999512 	 0.13178110122680664 	 0.1261274814605713 	 None 	 None 	 None 	 None 	 
2025-07-25 18:42:44.316101 test begin: paddle.Tensor.fill_(x=Tensor([10, 16, 158761],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([10, 16, 158761],"float64"), value=41.2, ) 	 25401760 	 1000 	 0.14706182479858398 	 0.13450241088867188 	 0.13146042823791504 	 0.12592482566833496 	 None 	 None 	 None 	 None 	 
2025-07-25 18:42:45.688623 test begin: paddle.Tensor.fill_(x=Tensor([99226, 16, 16],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([99226, 16, 16],"float64"), value=41.2, ) 	 25401856 	 1000 	 0.14557814598083496 	 0.13472580909729004 	 0.13004636764526367 	 0.12616753578186035 	 None 	 None 	 None 	 None 	 
2025-07-25 18:42:47.057739 test begin: paddle.Tensor.fill_diagonal_(Tensor([128, 396901],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([128, 396901],"float32"), 0, wrap=False, ) 	 50803328 	 1000 	 0.02291131019592285 	 0.010722875595092773 	 1.8358230590820312e-05 	 2.5987625122070312e-05 	 0.03387284278869629 	 0.04522562026977539 	 2.002716064453125e-05 	 3.337860107421875e-05 	 combined
2025-07-25 18:42:48.815671 test begin: paddle.Tensor.fill_diagonal_(Tensor([396901, 128],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([396901, 128],"float32"), 0, wrap=False, ) 	 50803328 	 1000 	 0.022562503814697266 	 0.010704994201660156 	 1.4543533325195312e-05 	 2.4318695068359375e-05 	 0.03369760513305664 	 0.04546642303466797 	 3.743171691894531e-05 	 4.935264587402344e-05 	 combined
2025-07-25 18:42:50.557396 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([12700801, 4, 7],"int32"), Tensor([12700801, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([12700801, 4, 7],"int32"), Tensor([12700801, 4],"int32"), 0, 1, 2, ) 	 406425632 	 1000 	 78.14661955833435 	 4.578920125961304 	 0.0038819313049316406 	 1.4834709167480469 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:41.628073 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([1814401, 4, 7],"int32"), Tensor([1814401, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([1814401, 4, 7],"int32"), Tensor([1814401, 4],"int32"), 0, 1, 2, ) 	 58060832 	 1000 	 3.238657236099243 	 0.6301474571228027 	 0.0015254020690917969 	 0.21472454071044922 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:50.295242 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 3175201],"int64"), Tensor([2, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 3175201],"int64"), Tensor([2, 4],"int64"), 0, 1, 2, ) 	 25401616 	 1000 	 0.3210127353668213 	 0.3158550262451172 	 0.08188629150390625 	 0.10739707946777344 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:52.092547 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 6350401],"int32"), Tensor([2, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 6350401],"int32"), Tensor([2, 4],"int32"), 0, 1, 2, ) 	 50803216 	 1000 	 0.3209826946258545 	 0.3187522888183594 	 0.08188033103942871 	 0.10611295700073242 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:54.289097 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4233601, 3, 2],"int32"), Tensor([2, 2, 3],"int32"), offset=0, dim1=1, dim2=2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4233601, 3, 2],"int32"), Tensor([2, 2, 3],"int32"), offset=0, dim1=1, dim2=2, ) 	 50803224 	 1000 	 0.3210639953613281 	 0.31588006019592285 	 0.0818631649017334 	 0.10742783546447754 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:56.509906 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([6350401, 4, 7],"int64"), Tensor([6350401, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([6350401, 4, 7],"int64"), Tensor([6350401, 4],"int64"), 0, 1, 2, ) 	 203212832 	 1000 	 43.719868421554565 	 3.6034862995147705 	 0.0018677711486816406 	 1.2267236709594727 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:47:34.049462 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([907201, 4, 7],"int64"), Tensor([907201, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([907201, 4, 7],"int64"), Tensor([907201, 4],"int64"), 0, 1, 2, ) 	 29030432 	 1000 	 2.3148000240325928 	 0.518366813659668 	 0.0008141994476318359 	 0.17625784873962402 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:47:40.386691 test begin: paddle.Tensor.flatten(Tensor([1, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 168448000 	 1000 	 0.006027698516845703 	 0.008286476135253906 	 1.33514404296875e-05 	 3.24249267578125e-05 	 0.05135083198547363 	 0.06457328796386719 	 4.982948303222656e-05 	 5.412101745605469e-05 	 
2025-07-25 18:47:46.222962 test begin: paddle.Tensor.flatten(Tensor([128, 127, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([128, 127, 56, 56],"float32"), 2, ) 	 50978816 	 1000 	 0.005423545837402344 	 0.004526376724243164 	 1.3828277587890625e-05 	 1.6450881958007812e-05 	 0.043226003646850586 	 0.05634784698486328 	 4.100799560546875e-05 	 3.743171691894531e-05 	 
2025-07-25 18:47:48.031420 test begin: paddle.Tensor.flatten(Tensor([128, 254, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([128, 254, 56, 56],"float16"), 2, ) 	 101957632 	 1000 	 0.010434150695800781 	 0.007920026779174805 	 1.33514404296875e-05 	 2.384185791015625e-05 	 0.050050973892211914 	 0.06325197219848633 	 2.9325485229492188e-05 	 4.38690185546875e-05 	 
2025-07-25 18:47:52.769258 test begin: paddle.Tensor.flatten(Tensor([128, 512, 14, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([128, 512, 14, 56],"float32"), 2, ) 	 51380224 	 1000 	 0.005524396896362305 	 0.00447845458984375 	 1.0728836059570312e-05 	 1.8358230590820312e-05 	 0.043613433837890625 	 0.0572361946105957 	 3.528594970703125e-05 	 6.222724914550781e-05 	 
2025-07-25 18:47:55.977788 test begin: paddle.Tensor.flatten(Tensor([128, 512, 28, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([128, 512, 28, 56],"float16"), 2, ) 	 102760448 	 1000 	 0.005489826202392578 	 0.007957935333251953 	 8.58306884765625e-06 	 2.0503997802734375e-05 	 0.051004886627197266 	 0.06347322463989258 	 4.3392181396484375e-05 	 6.222724914550781e-05 	 
2025-07-25 18:47:59.940974 test begin: paddle.Tensor.flatten(Tensor([128, 512, 56, 14],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([128, 512, 56, 14],"float32"), 2, ) 	 51380224 	 1000 	 0.010487556457519531 	 0.007969141006469727 	 1.9073486328125e-05 	 1.9311904907226562e-05 	 0.05069899559020996 	 0.06380724906921387 	 4.553794860839844e-05 	 5.53131103515625e-05 	 
2025-07-25 18:48:01.783791 test begin: paddle.Tensor.flatten(Tensor([128, 512, 56, 28],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([128, 512, 56, 28],"float16"), 2, ) 	 102760448 	 1000 	 0.01045083999633789 	 0.00785684585571289 	 1.2159347534179688e-05 	 2.2172927856445312e-05 	 0.051444292068481445 	 0.06582045555114746 	 6.866455078125e-05 	 7.963180541992188e-05 	 
2025-07-25 18:48:06.224078 test begin: paddle.Tensor.flatten(Tensor([32, 512, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([32, 512, 56, 56],"float32"), 2, ) 	 51380224 	 1000 	 0.005452632904052734 	 0.004470109939575195 	 7.3909759521484375e-06 	 1.7404556274414062e-05 	 0.042887210845947266 	 0.056748151779174805 	 3.361701965332031e-05 	 7.557868957519531e-05 	 
2025-07-25 18:48:07.989250 test begin: paddle.Tensor.flatten(Tensor([4, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([4, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 52640000 	 1000 	 0.005819082260131836 	 0.004651546478271484 	 1.0251998901367188e-05 	 1.6927719116210938e-05 	 0.04325985908508301 	 0.05730271339416504 	 2.7418136596679688e-05 	 5.555152893066406e-05 	 
2025-07-25 18:48:09.781266 test begin: paddle.Tensor.flatten(Tensor([4, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([4, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 53903360 	 1000 	 0.005789041519165039 	 0.004611492156982422 	 7.3909759521484375e-06 	 1.7404556274414062e-05 	 0.04300117492675781 	 0.05693697929382324 	 2.3365020751953125e-05 	 3.933906555175781e-05 	 
2025-07-25 18:48:11.620383 test begin: paddle.Tensor.flatten(Tensor([4, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([4, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, ) 	 51968000 	 1000 	 0.005835056304931641 	 0.008125782012939453 	 1.6927719116210938e-05 	 2.0265579223632812e-05 	 0.0505828857421875 	 0.06358671188354492 	 4.220008850097656e-05 	 4.553794860839844e-05 	 
2025-07-25 18:48:13.486396 test begin: paddle.Tensor.flatten(Tensor([4, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([4, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, ) 	 52940800 	 1000 	 0.005807399749755859 	 0.004624605178833008 	 6.9141387939453125e-06 	 1.811981201171875e-05 	 0.04321432113647461 	 0.05734443664550781 	 3.0279159545898438e-05 	 6.461143493652344e-05 	 
2025-07-25 18:48:15.290879 test begin: paddle.Tensor.flatten(Tensor([64, 512, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([64, 512, 56, 56],"float16"), 2, ) 	 102760448 	 1000 	 0.005445241928100586 	 0.004456281661987305 	 1.0251998901367188e-05 	 1.8596649169921875e-05 	 0.04284834861755371 	 0.05670619010925293 	 3.0040740966796875e-05 	 5.507469177246094e-05 	 
2025-07-25 18:48:19.252094 test begin: paddle.Tensor.flip(Tensor([16, 3, 224, 4726],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 3, 224, 4726],"float32"), 0, ) 	 50813952 	 1000 	 0.9613733291625977 	 0.31131792068481445 	 0.9451520442962646 	 0.28931546211242676 	 0.9616479873657227 	 0.31118297576904297 	 0.9005212783813477 	 0.21270251274108887 	 
2025-07-25 18:48:23.511631 test begin: paddle.Tensor.flip(Tensor([16, 3, 4726, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 3, 4726, 224],"float32"), 0, ) 	 50813952 	 1000 	 0.9617488384246826 	 0.3112773895263672 	 0.9530384540557861 	 0.2965888977050781 	 0.9617767333984375 	 0.31119751930236816 	 0.90962815284729 	 0.2412569522857666 	 
2025-07-25 18:48:27.695795 test begin: paddle.Tensor.flip(Tensor([16, 64, 224, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 64, 224, 224],"float32"), 0, ) 	 51380224 	 1000 	 0.9716544151306152 	 0.3150978088378906 	 0.9555933475494385 	 0.3001675605773926 	 0.9714803695678711 	 0.31504034996032715 	 0.9101524353027344 	 0.21486878395080566 	 
2025-07-25 18:48:32.158226 test begin: paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-1,], ) 	 50804400 	 1000 	 0.8902955055236816 	 0.547511100769043 	 0.881310224533081 	 0.28896188735961914 	 0.8902311325073242 	 0.31264829635620117 	 0.8372635841369629 	 0.22818446159362793 	 
2025-07-25 18:48:40.012125 test begin: paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-2,], ) 	 50804400 	 1000 	 0.8904130458831787 	 0.3160061836242676 	 0.8740389347076416 	 0.29442405700683594 	 0.8904101848602295 	 0.31583476066589355 	 0.8292543888092041 	 0.2388160228729248 	 
2025-07-25 18:48:44.154723 test begin: paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-1,], ) 	 50804100 	 1000 	 0.8903830051422119 	 0.3126842975616455 	 0.8739070892333984 	 0.29082226753234863 	 0.8906285762786865 	 0.3126227855682373 	 0.8297443389892578 	 0.21657299995422363 	 
2025-07-25 18:48:48.286382 test begin: paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-2,], ) 	 50804100 	 1000 	 0.8904228210449219 	 0.325817346572876 	 0.8742208480834961 	 0.29387855529785156 	 0.8905332088470459 	 0.3155558109283447 	 0.8295962810516357 	 0.23911428451538086 	 
2025-07-25 18:48:52.352510 test begin: paddle.Tensor.flip(Tensor([338, 3, 224, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([338, 3, 224, 224],"float32"), 0, ) 	 50878464 	 1000 	 0.962799072265625 	 0.3147096633911133 	 0.9467778205871582 	 0.29713010787963867 	 0.9627904891967773 	 0.31188535690307617 	 0.9016985893249512 	 0.24110126495361328 	 
2025-07-25 18:48:56.592801 test begin: paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-1,], ) 	 50880000 	 1000 	 0.8929529190063477 	 0.7891013622283936 	 0.8841042518615723 	 0.2981412410736084 	 0.8923203945159912 	 0.3128945827484131 	 0.8400790691375732 	 0.23721671104431152 	 
2025-07-25 18:49:01.745688 test begin: paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-2,], ) 	 50880000 	 1000 	 0.8930466175079346 	 0.3164396286010742 	 0.8842127323150635 	 0.30136966705322266 	 0.8925149440765381 	 0.3163158893585205 	 0.8402936458587646 	 0.24737095832824707 	 
2025-07-25 18:49:05.882883 test begin: paddle.Tensor.floor(Tensor([12700801, 4],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([12700801, 4],"float32"), ) 	 50803204 	 1000 	 0.2956359386444092 	 0.30151987075805664 	 0.28699159622192383 	 0.2875220775604248 	 0.13398051261901855 	 0.13437247276306152 	 0.08164501190185547 	 0.06764411926269531 	 
2025-07-25 18:49:08.430432 test begin: paddle.Tensor.floor(Tensor([1857, 27358],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1857, 27358],"float32"), ) 	 50803806 	 1000 	 0.2954137325286865 	 0.2978987693786621 	 0.286989688873291 	 0.2876880168914795 	 0.13388872146606445 	 0.13437962532043457 	 0.07941842079162598 	 0.0630500316619873 	 
2025-07-25 18:49:10.964165 test begin: paddle.Tensor.floor(Tensor([1872, 27139],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1872, 27139],"float32"), ) 	 50804208 	 1000 	 0.2957172393798828 	 0.29796481132507324 	 0.28716397285461426 	 0.286679744720459 	 0.13393020629882812 	 0.13438868522644043 	 0.0813605785369873 	 0.06842231750488281 	 
2025-07-25 18:49:13.466946 test begin: paddle.Tensor.floor(Tensor([1915, 26530],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1915, 26530],"float32"), ) 	 50804950 	 1000 	 0.2959020137786865 	 0.29782915115356445 	 0.2873547077178955 	 0.2876420021057129 	 0.1339282989501953 	 0.13428592681884766 	 0.08162760734558105 	 0.06795620918273926 	 
2025-07-25 18:49:16.013959 test begin: paddle.Tensor.gather(Tensor([4, 12700801],"float32"), Tensor([4, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([4, 12700801],"float32"), Tensor([4, 1],"int64"), 1, ) 	 50803208 	 1000 	 0.009561777114868164 	 0.17394757270812988 	 2.3365020751953125e-05 	 7.05718994140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:49:17.175567 test begin: paddle.Tensor.gather(Tensor([40, 1270080],"float32"), Tensor([40, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([40, 1270080],"float32"), Tensor([40, 1],"int64"), 1, ) 	 50803240 	 1000 	 0.017348766326904297 	 1.8654639720916748 	 2.0265579223632812e-05 	 0.00022745132446289062 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:49:20.065655 test begin: paddle.Tensor.gather(Tensor([400, 127008],"float32"), Tensor([400, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([400, 127008],"float32"), Tensor([400, 1],"int64"), 1, ) 	 50803600 	 1000 	 0.018313169479370117 	 17.536662578582764 	 3.933906555175781e-05 	 0.0002665519714355469 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:49:39.464471 test begin: paddle.Tensor.gather_nd(Tensor([119, 53568, 8],"float32"), Tensor([119, 500, 2],"int64"), )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7effb39668c0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-25 18:59:44.644613 test begin: paddle.Tensor.gather_nd(Tensor([119, 53568, 8],"float32"), Tensor([4, 500, 2],"int64"), )
W0725 18:59:45.678220 144158 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([119, 53568, 8],"float32"), Tensor([4, 500, 2],"int64"), ) 	 51000736 	 1000 	 0.018570899963378906 	 161.82677602767944 	 1.621246337890625e-05 	 0.0002613067626953125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:02:28.489160 test begin: paddle.Tensor.gather_nd(Tensor([119, 53568, 8],"float32"), Tensor([60, 500, 2],"int64"), )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7ff325a06c80>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-25 19:12:33.338276 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 156, 80, 85],"float32"), Tensor([516, 4],"int64"), )
W0725 19:12:34.494232 152940 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 156, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 50920464 	 1000 	 0.010624885559082031 	 79.33807015419006 	 1.2874603271484375e-05 	 0.0002562999725341797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:13:54.564323 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), ) 	 50920464 	 1000 	 0.010267972946166992 	 76.39742922782898 	 1.2159347534179688e-05 	 0.00023126602172851562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:15:12.039700 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), ) 	 50997264 	 1000 	 0.010521411895751953 	 76.50880217552185 	 1.239776611328125e-05 	 0.00022530555725097656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:16:29.623297 test begin: paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.01031041145324707 	 76.62918496131897 	 1.2636184692382812e-05 	 0.0002162456512451172 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:48.177389 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.010374069213867188 	 57.10293364524841 	 1.71661376953125e-05 	 0.0002281665802001953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:18:46.414080 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.010353803634643555 	 76.38690042495728 	 1.2159347534179688e-05 	 0.0002238750457763672 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:20:03.957106 test begin: paddle.Tensor.gather_nd(Tensor([4, 1587601, 8],"float32"), Tensor([4, 500, 2],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([4, 1587601, 8],"float32"), Tensor([4, 500, 2],"int64"), ) 	 50807232 	 1000 	 0.010642051696777344 	 155.14974927902222 	 1.1920928955078125e-05 	 0.00012874603271484375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:22:41.102905 test begin: paddle.Tensor.gather_nd(Tensor([4, 53568, 238],"float32"), Tensor([4, 500, 2],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([4, 53568, 238],"float32"), Tensor([4, 500, 2],"int64"), ) 	 51000736 	 1000 	 0.011487483978271484 	 154.52126812934875 	 0.0007622241973876953 	 0.00022077560424804688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:25:16.841820 test begin: paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.010428905487060547 	 56.94142413139343 	 1.6450881958007812e-05 	 0.00021600723266601562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:26:14.870602 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.010654926300048828 	 56.78736186027527 	 1.7881393432617188e-05 	 0.00022840499877929688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:27:12.909848 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.010608673095703125 	 57.21939301490784 	 1.4066696166992188e-05 	 0.00021529197692871094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:28:11.219528 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), ) 	 50843140 	 1000 	 0.010602951049804688 	 57.02779674530029 	 1.3828277587890625e-05 	 0.0002181529998779297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:29:09.297956 test begin: paddle.Tensor.gcd(x=Tensor([127008, 2, 4, 5],"int32"), y=Tensor([127008, 2, 4, 5],"int32"), )
W0725 19:29:21.545882 25380 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([127008, 2, 4, 5],"int32"), y=Tensor([127008, 2, 4, 5],"int32"), ) 	 10160640 	 1000 	 11.93825101852417 	 0.16017723083496094 	 2.86102294921875e-05 	 0.14720463752746582 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:21.752035 test begin: paddle.Tensor.gcd(x=Tensor([2, 4, 635040],"int32"), y=Tensor([2, 4, 635040],"int32"), )
W0725 19:29:33.906066 28071 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([2, 4, 635040],"int32"), y=Tensor([2, 4, 635040],"int32"), ) 	 10160640 	 1000 	 11.919634342193604 	 0.1636967658996582 	 5.030632019042969e-05 	 0.14780735969543457 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:34.725646 test begin: paddle.Tensor.gcd(x=Tensor([2, 508032, 5],"int32"), y=Tensor([2, 508032, 5],"int32"), )
W0725 19:29:47.480551 30872 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([2, 508032, 5],"int32"), y=Tensor([2, 508032, 5],"int32"), ) 	 10160640 	 1000 	 12.540367841720581 	 0.16143393516540527 	 2.574920654296875e-05 	 0.14946579933166504 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:47.760225 test begin: paddle.Tensor.gcd(x=Tensor([254016, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0725 19:30:09.829413 31114 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([254016, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 5080330 	 1000 	 21.889323472976685 	 0.4286618232727051 	 4.76837158203125e-05 	 0.412830114364624 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:30:10.293003 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([130],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([130],"int64"), ) 	 50803354 	 1000 	 0.009000062942504883 	 0.012946367263793945 	 1.8358230590820312e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:11.594989 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([182],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([182],"int64"), ) 	 50803406 	 1000 	 0.008715152740478516 	 0.01703357696533203 	 1.3113021850585938e-05 	 5.698204040527344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:12.589111 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([91],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([91],"int64"), ) 	 50803315 	 1000 	 0.00876307487487793 	 0.012930154800415039 	 1.1444091796875e-05 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:13.574761 test begin: paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([182],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([182],"int64"), ) 	 50806938 	 1000 	 0.03556513786315918 	 0.029374361038208008 	 0.02187657356262207 	 0.013389348983764648 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:14.689391 test begin: paddle.Tensor.index_select(Tensor([4004, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), ) 	 25497697 	 1000 	 8.14524531364441 	 8.608971118927002 	 8.13422679901123 	 8.59105134010315 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:46.814777 test begin: paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([130],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([130],"int64"), ) 	 50803638 	 1000 	 0.18921661376953125 	 0.17058825492858887 	 0.17953991889953613 	 0.15699458122253418 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:48.538919 test begin: paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([91],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([91],"int64"), ) 	 50803599 	 1000 	 0.1337902545928955 	 0.12521719932556152 	 0.12424421310424805 	 0.10497283935546875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:30:50.059040 test begin: paddle.Tensor.index_select(Tensor([454, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), ) 	 25412497 	 1000 	 7.628399610519409 	 7.150916337966919 	 7.6167778968811035 	 7.130946159362793 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:31:21.143218 test begin: paddle.Tensor.inner(x=Tensor([2, 1058401, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:824: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:181.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 1058401, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401744 	 1000 	 1.9537124633789062 	 1.954369306564331 	 0.28505611419677734 	 0.2850496768951416 	 3.3641278743743896 	 3.240063190460205 	 0.3820528984069824 	 0.36740899085998535 	 
2025-07-25 19:31:37.423245 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), ) 	 25401744 	 1000 	 1.9130709171295166 	 1.4586923122406006 	 0.21295595169067383 	 0.2127671241760254 	 4.072326421737671 	 4.073646306991577 	 0.46181583404541016 	 0.4624507427215576 	 
2025-07-25 19:31:54.663719 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), ) 	 25401780 	 1000 	 1.825709581375122 	 1.8105103969573975 	 0.26647186279296875 	 0.26400136947631836 	 3.4098660945892334 	 3.6540441513061523 	 0.38654327392578125 	 0.41608381271362305 	 
2025-07-25 19:32:09.997757 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), ) 	 25401760 	 1000 	 1.6936872005462646 	 1.4563586711883545 	 0.2129204273223877 	 0.212660551071167 	 4.070836544036865 	 4.071150302886963 	 0.461681604385376 	 0.4623146057128906 	 
2025-07-25 19:32:28.576336 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), ) 	 50803260 	 1000 	 0.3385491371154785 	 0.33566808700561523 	 0.17293405532836914 	 0.1715106964111328 	 0.7139530181884766 	 0.7665317058563232 	 0.364668607711792 	 0.39151787757873535 	 
2025-07-25 19:32:31.797513 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 635041, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 635041, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401760 	 1000 	 1.9508395195007324 	 1.9526722431182861 	 0.2845168113708496 	 0.2850337028503418 	 3.3703534603118896 	 3.245880365371704 	 0.38263392448425293 	 0.3678410053253174 	 
2025-07-25 19:32:47.490275 test begin: paddle.Tensor.inner(x=Tensor([2116801, 3, 4],"float64"), y=Tensor([2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2116801, 3, 4],"float64"), y=Tensor([2, 5, 4],"float64"), ) 	 25401652 	 1000 	 1.865746259689331 	 1.879119873046875 	 0.2724754810333252 	 0.27031946182250977 	 3.1045260429382324 	 2.3274056911468506 	 0.35234904289245605 	 0.26399683952331543 	 
2025-07-25 19:32:58.616544 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), ) 	 25401636 	 1000 	 1.3619647026062012 	 1.3681809902191162 	 0.1983942985534668 	 0.19954824447631836 	 2.652644395828247 	 2.633870840072632 	 0.3021426200866699 	 0.2989540100097656 	 
2025-07-25 19:33:07.645281 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), ) 	 25401672 	 1000 	 1.3786497116088867 	 1.3875744342803955 	 0.20107245445251465 	 0.20256638526916504 	 2.3674418926239014 	 2.4516780376434326 	 0.2695796489715576 	 0.2781813144683838 	 
2025-07-25 19:33:17.947666 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), ) 	 25401652 	 1000 	 1.37290620803833 	 1.37796950340271 	 0.19933223724365234 	 0.2006511688232422 	 2.650726795196533 	 2.633610248565674 	 0.3006105422973633 	 0.29878664016723633 	 
2025-07-25 19:33:26.978616 test begin: paddle.Tensor.inner(x=Tensor([3, 8467201],"float64"), y=Tensor([3, 2, 5, 8467201],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 8467201],"float64"), y=Tensor([3, 2, 5, 8467201],"float64"), ) 	 279417633 	 1000 	 1.7756505012512207 	 1.783076524734497 	 0.9065954685211182 	 0.909940242767334 	 4.02012300491333 	 4.22223687171936 	 0.22816920280456543 	 0.23936676979064941 	 
2025-07-25 19:33:46.253389 test begin: paddle.Tensor.inner(x=Tensor([3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), ) 	 27941793 	 1000 	 0.19297027587890625 	 0.1904911994934082 	 0.09852337837219238 	 0.09728121757507324 	 0.4127388000488281 	 0.4272470474243164 	 0.2108018398284912 	 0.21818852424621582 	 
2025-07-25 19:33:48.093307 test begin: paddle.Tensor.inner(x=Tensor([423361, 5, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([423361, 5, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401780 	 1000 	 1.955878496170044 	 1.959115982055664 	 0.28613996505737305 	 0.28705525398254395 	 3.3650763034820557 	 3.243269681930542 	 0.381908655166626 	 0.3677327632904053 	 
2025-07-25 19:34:03.202607 test begin: paddle.Tensor.inner(x=Tensor([5, 1270081, 4],"float64"), y=Tensor([2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 1270081, 4],"float64"), y=Tensor([2, 5, 4],"float64"), ) 	 25401660 	 1000 	 1.869283676147461 	 1.8498659133911133 	 0.27222752571105957 	 0.27007341384887695 	 2.330604314804077 	 2.3290576934814453 	 0.2643580436706543 	 0.2639040946960449 	 
2025-07-25 19:34:13.508039 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 1693441],"float64"), y=Tensor([2, 5, 1693441],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 1693441],"float64"), y=Tensor([2, 5, 1693441],"float64"), ) 	 42336025 	 1000 	 0.29805469512939453 	 0.28965306282043457 	 0.15222477912902832 	 0.14800691604614258 	 0.8183469772338867 	 0.8680088520050049 	 0.2089405059814453 	 0.22133135795593262 	 
2025-07-25 19:34:16.665569 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 2540161],"float64"), y=Tensor([2, 5, 2540161],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 2540161],"float64"), y=Tensor([2, 5, 2540161],"float64"), ) 	 63504025 	 1000 	 0.43419361114501953 	 0.42877697944641113 	 0.22179174423217773 	 0.21909689903259277 	 1.240546464920044 	 1.3296635150909424 	 0.21118402481079102 	 0.22716307640075684 	 
2025-07-25 19:34:24.967298 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([1270081, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([1270081, 5, 4],"float64"), ) 	 25401680 	 1000 	 1.5580995082855225 	 1.5406365394592285 	 0.22742795944213867 	 0.22493553161621094 	 2.4742419719696045 	 2.6768929958343506 	 0.28055524826049805 	 0.303647518157959 	 
2025-07-25 19:34:37.889890 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 3175201, 4],"float64"), ) 	 25401668 	 1000 	 1.557267427444458 	 1.5517830848693848 	 0.22799968719482422 	 0.22433805465698242 	 2.7935755252838135 	 2.791839599609375 	 0.3168461322784424 	 0.3167576789855957 	 
2025-07-25 19:34:50.808605 test begin: paddle.Tensor.inner(x=Tensor([6350401, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([6350401, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401724 	 1000 	 1.947453498840332 	 1.9597678184509277 	 0.2841520309448242 	 0.28603529930114746 	 3.3609166145324707 	 3.239504814147949 	 0.38280344009399414 	 0.3670382499694824 	 
2025-07-25 19:35:05.775807 test begin: paddle.Tensor.inverse(Tensor([4, 39690, 4, 4],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([4, 39690, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.605529069900513 	 0.3444521427154541 	 0.00010728836059570312 	 8.177757263183594e-05 	 3.901921510696411 	 1.9653022289276123 	 0.33473706245422363 	 0.2869088649749756 	 
2025-07-25 19:35:19.780074 test begin: paddle.Tensor.inverse(Tensor([70560, 6, 6],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([70560, 6, 6],"float64"), ) 	 2540160 	 1000 	 3.555540084838867 	 0.39875268936157227 	 5.340576171875e-05 	 8.749961853027344e-05 	 2.1958134174346924 	 1.6712219715118408 	 0.5617575645446777 	 0.3409757614135742 	 
2025-07-25 19:35:28.669385 test begin: paddle.Tensor.inverse(Tensor([79380, 2, 4, 4],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([79380, 2, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.539903163909912 	 0.3430206775665283 	 0.0001087188720703125 	 8.225440979003906e-05 	 4.420659065246582 	 1.9653606414794922 	 0.3347904682159424 	 0.2869091033935547 	 
2025-07-25 19:35:43.072206 test begin: paddle.Tensor.is_complex(Tensor([2, 3, 100, 42337],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2, 3, 100, 42337],"float64"), ) 	 25402200 	 1000 	 0.003736257553100586 	 0.00167083740234375 	 1.0251998901367188e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:43.605444 test begin: paddle.Tensor.is_complex(Tensor([2, 3, 105841, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2, 3, 105841, 40],"float64"), ) 	 25401840 	 1000 	 0.0038101673126220703 	 0.0016276836395263672 	 1.0251998901367188e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:44.174302 test begin: paddle.Tensor.is_complex(Tensor([2, 3, 40, 105841],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2, 3, 40, 105841],"float64"), ) 	 25401840 	 1000 	 0.003744363784790039 	 0.0016279220581054688 	 5.9604644775390625e-06 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:44.712271 test begin: paddle.Tensor.is_complex(Tensor([2, 3, 42337, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2, 3, 42337, 100],"float64"), ) 	 25402200 	 1000 	 0.003701925277709961 	 0.001611948013305664 	 6.198883056640625e-06 	 1.52587890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:45.239047 test begin: paddle.Tensor.is_complex(Tensor([2, 3176, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2, 3176, 100, 40],"float64"), ) 	 25408000 	 1000 	 0.0036797523498535156 	 0.0016283988952636719 	 1.0967254638671875e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:45.765985 test begin: paddle.Tensor.is_complex(Tensor([2, 3176, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2, 3176, 40, 100],"float64"), ) 	 25408000 	 1000 	 0.0037031173706054688 	 0.0016336441040039062 	 9.5367431640625e-06 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:46.316044 test begin: paddle.Tensor.is_complex(Tensor([2117, 3, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2117, 3, 100, 40],"float64"), ) 	 25404000 	 1000 	 0.003740549087524414 	 0.0016522407531738281 	 9.298324584960938e-06 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:46.824185 test begin: paddle.Tensor.is_complex(Tensor([2117, 3, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([2117, 3, 40, 100],"float64"), ) 	 25404000 	 1000 	 0.0037353038787841797 	 0.0016198158264160156 	 5.9604644775390625e-06 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:47.349252 test begin: paddle.Tensor.is_complex(Tensor([3, 100, 84673],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([3, 100, 84673],"float64"), ) 	 25401900 	 1000 	 0.0037610530853271484 	 0.001634359359741211 	 5.7220458984375e-06 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:47.872628 test begin: paddle.Tensor.is_complex(Tensor([3, 211681, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([3, 211681, 40],"float64"), ) 	 25401720 	 1000 	 0.0037813186645507812 	 0.00160980224609375 	 6.67572021484375e-06 	 1.52587890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:48.464716 test begin: paddle.Tensor.is_complex(Tensor([6351, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([6351, 100, 40],"float64"), ) 	 25404000 	 1000 	 0.003745555877685547 	 0.0016398429870605469 	 1.7404556274414062e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:49.035956 test begin: paddle.Tensor.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), ) 	 50803240 	 1000 	 0.36214518547058105 	 3.0811092853546143 	 0.34810519218444824 	 0.24173331260681152 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:53.610936 test begin: paddle.Tensor.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 0.3633596897125244 	 3.0813305377960205 	 0.34819722175598145 	 0.2417771816253662 	 None 	 None 	 None 	 None 	 
2025-07-25 19:35:58.180525 test begin: paddle.Tensor.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), ) 	 50803230 	 1000 	 0.3606858253479004 	 3.0815353393554688 	 0.3486020565032959 	 0.2417595386505127 	 None 	 None 	 None 	 None 	 
2025-07-25 19:36:02.703422 test begin: paddle.Tensor.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), ) 	 50803224 	 1000 	 0.3601832389831543 	 3.0813260078430176 	 0.348111629486084 	 0.24174833297729492 	 None 	 None 	 None 	 None 	 
2025-07-25 19:36:07.212315 test begin: paddle.Tensor.isclose(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.4224870204925537 	 3.313366651535034 	 0.41025257110595703 	 0.26102542877197266 	 None 	 None 	 None 	 None 	 
2025-07-25 19:36:12.578153 test begin: paddle.Tensor.isnan(Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.isnan 	 paddle.Tensor.isnan(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.18218159675598145 	 0.1688542366027832 	 0.17389655113220215 	 0.15791010856628418 	 None 	 None 	 None 	 None 	 
2025-07-25 19:36:13.455398 test begin: paddle.Tensor.isnan(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.isnan 	 paddle.Tensor.isnan(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.23282432556152344 	 0.18610548973083496 	 0.22550559043884277 	 0.1752157211303711 	 None 	 None 	 None 	 None 	 
2025-07-25 19:36:14.689878 test begin: paddle.Tensor.item(Tensor([16934401, 3],"float32"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([16934401, 3],"float32"), 0, ) 	 50803203 	 1000 	 0.01972031593322754 	 0.027748823165893555 	 1.9073486328125e-05 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:15.588404 test begin: paddle.Tensor.item(Tensor([2, 1, 12700801],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2, 1, 12700801],"int64"), 0, ) 	 25401602 	 1000 	 0.0191495418548584 	 0.028256654739379883 	 1.2159347534179688e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:16.044905 test begin: paddle.Tensor.item(Tensor([2, 1, 25401601],"int32"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2, 1, 25401601],"int32"), 0, ) 	 50803202 	 1000 	 0.019254446029663086 	 0.02762460708618164 	 1.0728836059570312e-05 	 4.2438507080078125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:16.678473 test begin: paddle.Tensor.item(Tensor([2, 12700801, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2, 12700801, 1],"int64"), 0, ) 	 25401602 	 1000 	 0.019280672073364258 	 0.027901887893676758 	 1.0013580322265625e-05 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:17.136954 test begin: paddle.Tensor.item(Tensor([2, 25401601, 1],"int32"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2, 25401601, 1],"int32"), 0, ) 	 50803202 	 1000 	 0.019120454788208008 	 0.027790069580078125 	 8.58306884765625e-06 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:17.771393 test begin: paddle.Tensor.item(Tensor([25401601, 1, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([25401601, 1, 1],"int64"), 0, ) 	 25401601 	 1000 	 0.019840240478515625 	 0.027516841888427734 	 3.9577484130859375e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:18.226844 test begin: paddle.Tensor.item(Tensor([3, 16934401],"float32"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([3, 16934401],"float32"), 0, ) 	 50803203 	 1000 	 0.019176959991455078 	 0.02741861343383789 	 2.0265579223632812e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:19.085852 test begin: paddle.Tensor.item(Tensor([50803201, 1, 1],"int32"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([50803201, 1, 1],"int32"), 0, ) 	 50803201 	 1000 	 0.019329309463500977 	 0.027533292770385742 	 1.0251998901367188e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:19.710993 test begin: paddle.Tensor.kthvalue(Tensor([2, 200, 127009],"float32"), k=200, axis=1, )
[Prof] paddle.Tensor.kthvalue 	 paddle.Tensor.kthvalue(Tensor([2, 200, 127009],"float32"), k=200, axis=1, ) 	 50803600 	 1000 	 6.805760860443115 	 11.61249566078186 	 1.7352380752563477 	 11.583249807357788 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:36:42.945428 test begin: paddle.Tensor.kthvalue(Tensor([2, 2540161, 10],"float32"), k=200, axis=1, )
[Prof] paddle.Tensor.kthvalue 	 paddle.Tensor.kthvalue(Tensor([2, 2540161, 10],"float32"), k=200, axis=1, ) 	 50803220 	 1000 	 37.60561394691467 	 33.38141965866089 	 9.591815710067749 	 33.36232948303223 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:37:59.203017 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.0, ) 	 50803360 	 1000 	 0.45171523094177246 	 0.45715928077697754 	 0.23071813583374023 	 0.4317026138305664 	 0.48255467414855957 	 0.5966048240661621 	 0.4213676452636719 	 0.3048233985900879 	 
2025-07-25 19:38:02.810522 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.5, ) 	 50803360 	 1000 	 0.4518303871154785 	 0.4449448585510254 	 0.2308330535888672 	 0.4321150779724121 	 0.4826188087463379 	 0.5979080200195312 	 0.4188401699066162 	 0.3047657012939453 	 
2025-07-25 19:38:06.389462 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=1.0, ) 	 50803360 	 1000 	 0.45284533500671387 	 0.4449131488800049 	 0.23189091682434082 	 0.43198513984680176 	 0.48250532150268555 	 0.5967042446136475 	 0.41535329818725586 	 0.3048696517944336 	 
2025-07-25 19:38:09.969873 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.0, ) 	 50803320 	 1000 	 0.4517395496368408 	 0.4467008113861084 	 0.23068475723266602 	 0.43317389488220215 	 0.48390984535217285 	 0.5966804027557373 	 0.4237096309661865 	 0.30484843254089355 	 
2025-07-25 19:38:13.572925 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.5, ) 	 50803320 	 1000 	 0.45151734352111816 	 0.44497179985046387 	 0.23062348365783691 	 0.4321248531341553 	 0.48264098167419434 	 0.5977725982666016 	 0.42222094535827637 	 0.305941104888916 	 
2025-07-25 19:38:17.202274 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=1.0, ) 	 50803320 	 1000 	 0.45166754722595215 	 0.45976829528808594 	 0.2306830883026123 	 0.4320805072784424 	 0.48259902000427246 	 0.5966393947601318 	 0.4223754405975342 	 0.3048217296600342 	 
2025-07-25 19:38:20.905806 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.0, ) 	 50803296 	 1000 	 0.45197057723999023 	 0.444929838180542 	 0.23063111305236816 	 0.43212175369262695 	 0.4826846122741699 	 0.5977873802185059 	 0.4076497554779053 	 0.3048379421234131 	 
2025-07-25 19:38:24.587374 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.5, ) 	 50803296 	 1000 	 0.45161962509155273 	 0.44486522674560547 	 0.23067259788513184 	 0.43171000480651855 	 0.4826838970184326 	 0.5966148376464844 	 0.42280030250549316 	 0.3048222064971924 	 
2025-07-25 19:38:28.208058 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=1.0, ) 	 50803296 	 1000 	 0.45157599449157715 	 0.45778322219848633 	 0.23065400123596191 	 0.43199944496154785 	 0.48264026641845703 	 0.5966508388519287 	 0.4218883514404297 	 0.3048369884490967 	 
2025-07-25 19:38:31.886117 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.0, ) 	 50803320 	 1000 	 0.4560561180114746 	 0.4581449031829834 	 0.23068666458129883 	 0.43163466453552246 	 0.48254895210266113 	 0.5966625213623047 	 0.39391565322875977 	 0.3048365116119385 	 
2025-07-25 19:38:39.870826 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.5, ) 	 50803320 	 1000 	 0.45276331901550293 	 0.44492483139038086 	 0.23065185546875 	 0.4319617748260498 	 0.4826984405517578 	 0.5966520309448242 	 0.4191243648529053 	 0.3048107624053955 	 
2025-07-25 19:38:43.554235 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=1.0, ) 	 50803320 	 1000 	 0.4552946090698242 	 0.45372962951660156 	 0.23073363304138184 	 0.42949485778808594 	 0.48285651206970215 	 0.5965824127197266 	 0.4220430850982666 	 0.3048384189605713 	 
2025-07-25 19:38:50.260975 test begin: paddle.Tensor.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.less 	 paddle.Tensor.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.32775163650512695 	 0.32776331901550293 	 0.3181478977203369 	 0.31660962104797363 	 None 	 None 	 None 	 None 	 
2025-07-25 19:38:52.731713 test begin: paddle.Tensor.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), )
[Prof] paddle.Tensor.less 	 paddle.Tensor.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), ) 	 101607424 	 1000 	 0.3279001712799072 	 0.3310587406158447 	 0.31797027587890625 	 0.31528210639953613 	 None 	 None 	 None 	 None 	 
2025-07-25 19:38:55.128361 test begin: paddle.Tensor.lgamma(Tensor([100, 100, 2541],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([100, 100, 2541],"float64"), ) 	 25410000 	 1000 	 0.7172973155975342 	 0.6910183429718018 	 0.7052133083343506 	 0.6813192367553711 	 1.376103401184082 	 1.5855352878570557 	 1.3212134838104248 	 0.8101515769958496 	 
2025-07-25 19:39:00.630810 test begin: paddle.Tensor.lgamma(Tensor([100, 2541, 100],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([100, 2541, 100],"float64"), ) 	 25410000 	 1000 	 0.7159736156463623 	 0.6896946430206299 	 0.7048935890197754 	 0.6798954010009766 	 1.3792202472686768 	 1.5881848335266113 	 1.3228540420532227 	 0.8114235401153564 	 
2025-07-25 19:39:06.098070 test begin: paddle.Tensor.lgamma(Tensor([2541, 100, 100],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([2541, 100, 100],"float64"), ) 	 25410000 	 1000 	 0.717186689376831 	 0.6909101009368896 	 0.7037646770477295 	 0.6811347007751465 	 1.377981185913086 	 1.5868494510650635 	 1.3271782398223877 	 0.8101553916931152 	 
2025-07-25 19:39:11.628562 test begin: paddle.Tensor.lgamma(Tensor([453601, 7, 8],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([453601, 7, 8],"float64"), ) 	 25401656 	 1000 	 0.7139801979064941 	 0.693192720413208 	 0.7048802375793457 	 0.6806151866912842 	 1.3786985874176025 	 1.5865085124969482 	 1.327155351638794 	 0.8112576007843018 	 
2025-07-25 19:39:17.170554 test begin: paddle.Tensor.lgamma(Tensor([45361, 7, 8, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([45361, 7, 8, 10],"float64"), ) 	 25402160 	 1000 	 0.7121150493621826 	 0.6896765232086182 	 0.703596830368042 	 0.679893970489502 	 1.3843932151794434 	 1.5867319107055664 	 1.3331873416900635 	 0.8101258277893066 	 
2025-07-25 19:39:22.661012 test begin: paddle.Tensor.lgamma(Tensor([5, 635041, 8],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 635041, 8],"float64"), ) 	 25401640 	 1000 	 0.7133586406707764 	 0.6896896362304688 	 0.7047474384307861 	 0.67991042137146 	 1.3787336349487305 	 1.5866620540618896 	 1.3279902935028076 	 0.8113200664520264 	 
2025-07-25 19:39:28.112803 test begin: paddle.Tensor.lgamma(Tensor([5, 63505, 8, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 63505, 8, 10],"float64"), ) 	 25402000 	 1000 	 0.7159113883972168 	 0.6896677017211914 	 0.7050707340240479 	 0.6799392700195312 	 1.3838818073272705 	 1.587930679321289 	 1.331618070602417 	 0.8113112449645996 	 
2025-07-25 19:39:33.616404 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 725761],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 725761],"float64"), ) 	 25401635 	 1000 	 0.7142167091369629 	 0.696500301361084 	 0.7049920558929443 	 0.6793994903564453 	 1.377575159072876 	 1.5854921340942383 	 1.3244059085845947 	 0.810157060623169 	 
2025-07-25 19:39:39.872172 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 72577, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 72577, 10],"float64"), ) 	 25401950 	 1000 	 0.7201430797576904 	 0.6896405220031738 	 0.7063689231872559 	 0.6799261569976807 	 1.3792405128479004 	 1.58652663230896 	 1.327345848083496 	 0.8112466335296631 	 
2025-07-25 19:39:45.515335 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 8, 90721],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 8, 90721],"float64"), ) 	 25401880 	 1000 	 0.712144136428833 	 0.6952526569366455 	 0.70365309715271 	 0.6805381774902344 	 1.3799490928649902 	 1.585362195968628 	 1.327561378479004 	 0.8100297451019287 	 
2025-07-25 19:39:51.632690 test begin: paddle.Tensor.log(Tensor([100, 200, 1271],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([100, 200, 1271],"float64"), ) 	 25420000 	 1000 	 0.3155653476715088 	 0.31891584396362305 	 0.296489953994751 	 0.2959446907043457 	 0.4489774703979492 	 0.44910311698913574 	 0.39542150497436523 	 0.3793935775756836 	 
2025-07-25 19:39:56.765722 test begin: paddle.Tensor.log(Tensor([100, 2541, 100],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([100, 2541, 100],"float64"), ) 	 25410000 	 1000 	 0.30454373359680176 	 0.31296753883361816 	 0.2957496643066406 	 0.2972109317779541 	 0.44913148880004883 	 0.4488863945007324 	 0.3961210250854492 	 0.3812539577484131 	 
2025-07-25 19:39:59.392832 test begin: paddle.Tensor.log(Tensor([10000, 5, 509],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([10000, 5, 509],"float64"), ) 	 25450000 	 1000 	 0.3069150447845459 	 0.3100903034210205 	 0.2967660427093506 	 0.2971198558807373 	 0.4489753246307373 	 0.44962620735168457 	 0.39685964584350586 	 0.3737208843231201 	 
2025-07-25 19:40:01.991072 test begin: paddle.Tensor.log(Tensor([10000, 847, 3],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([10000, 847, 3],"float64"), ) 	 25410000 	 1000 	 0.30524110794067383 	 0.30624914169311523 	 0.29669833183288574 	 0.2958502769470215 	 0.4471774101257324 	 0.4489567279815674 	 0.3916633129119873 	 0.3815124034881592 	 
2025-07-25 19:40:04.602092 test begin: paddle.Tensor.log(Tensor([1271, 200, 100],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([1271, 200, 100],"float64"), ) 	 25420000 	 1000 	 0.3052093982696533 	 0.3065023422241211 	 0.2966172695159912 	 0.29602646827697754 	 0.4475576877593994 	 0.4491252899169922 	 0.3894667625427246 	 0.3828165531158447 	 
2025-07-25 19:40:07.170670 test begin: paddle.Tensor.log(Tensor([1693441, 5, 3],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([1693441, 5, 3],"float64"), ) 	 25401615 	 1000 	 0.3042447566986084 	 0.3162996768951416 	 0.29537439346313477 	 0.29575467109680176 	 0.4471004009246826 	 0.450042724609375 	 0.39481425285339355 	 0.3824329376220703 	 
2025-07-25 17:48:41.927098 test begin: paddle.Tensor.log(Tensor([4800, 10585],"float32"), )
W0725 17:48:43.003041 96630 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([4800, 10585],"float32"), ) 	 50808000 	 1000 	 0.2962942123413086 	 0.29893922805786133 	 0.28647422790527344 	 0.28003644943237305 	 0.45052027702331543 	 0.451204776763916 	 0.38474202156066895 	 0.3432960510253906 	 
2025-07-25 17:48:45.794863 test begin: paddle.Tensor.log(Tensor([503002, 101],"float32"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([503002, 101],"float32"), ) 	 50803202 	 1000 	 0.2959613800048828 	 0.29778242111206055 	 0.28714513778686523 	 0.2805204391479492 	 0.4507255554199219 	 0.44994044303894043 	 0.3834645748138428 	 0.35814857482910156 	 
2025-07-25 17:48:49.012716 test begin: paddle.Tensor.log10(Tensor([101811, 499],"float32"), )
[Prof] paddle.Tensor.log10 	 paddle.Tensor.log10(Tensor([101811, 499],"float32"), ) 	 50803689 	 1000 	 0.2976992130279541 	 0.29761767387390137 	 0.28762269020080566 	 0.2872648239135742 	 0.45052194595336914 	 0.7458374500274658 	 0.39396047592163086 	 0.38105201721191406 	 
2025-07-25 17:48:52.481526 test begin: paddle.Tensor.log10(Tensor([80, 635041],"float32"), )
[Prof] paddle.Tensor.log10 	 paddle.Tensor.log10(Tensor([80, 635041],"float32"), ) 	 50803280 	 1000 	 0.2959775924682617 	 0.29761362075805664 	 0.2877182960510254 	 0.28730249404907227 	 0.45034122467041016 	 0.7458338737487793 	 0.39517712593078613 	 0.38102293014526367 	 
2025-07-25 17:48:56.005633 test begin: paddle.Tensor.log1p(Tensor([16934401, 3],"float32"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.295790433883667 	 0.2989013195037842 	 0.287412166595459 	 0.28859734535217285 	 0.4503209590911865 	 0.7457761764526367 	 0.3951442241668701 	 0.38100385665893555 	 
2025-07-25 17:48:59.456951 test begin: paddle.Tensor.log1p(Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29581785202026367 	 0.29891037940979004 	 0.2873547077178955 	 0.2885727882385254 	 0.4501807689666748 	 0.7458059787750244 	 0.3912379741668701 	 0.3810544013977051 	 
2025-07-25 17:49:02.929919 test begin: paddle.Tensor.log1p(Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 3, 4233601],"float64"), ) 	 25401606 	 1000 	 0.30514073371887207 	 0.3360779285430908 	 0.29549717903137207 	 0.3257331848144531 	 0.44851064682006836 	 0.7448019981384277 	 0.3940601348876953 	 0.38049745559692383 	 
2025-07-25 17:49:05.809142 test begin: paddle.Tensor.log1p(Tensor([2, 6350401, 2],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 6350401, 2],"float64"), ) 	 25401604 	 1000 	 0.305128812789917 	 0.336153507232666 	 0.2964468002319336 	 0.3258519172668457 	 0.448103666305542 	 0.7448790073394775 	 0.39352846145629883 	 0.3805210590362549 	 
2025-07-25 17:49:08.712452 test begin: paddle.Tensor.log1p(Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.30515074729919434 	 0.33638429641723633 	 0.29645681381225586 	 0.3259768486022949 	 0.44864869117736816 	 0.7448263168334961 	 0.3943471908569336 	 0.3805551528930664 	 
2025-07-25 17:49:11.636865 test begin: paddle.Tensor.log1p(Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([4233601, 3, 2],"float64"), ) 	 25401606 	 1000 	 0.30520033836364746 	 0.33600783348083496 	 0.29674720764160156 	 0.32579946517944336 	 0.4483931064605713 	 0.7449185848236084 	 0.38370180130004883 	 0.38051581382751465 	 
2025-07-25 17:49:14.588284 test begin: paddle.Tensor.logical_and(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_and 	 paddle.Tensor.logical_and(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11843204498291016 	 0.11649775505065918 	 0.10911059379577637 	 0.10327935218811035 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:16.255566 test begin: paddle.Tensor.logical_not(Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_not 	 paddle.Tensor.logical_not(Tensor([50803201],"bool"), ) 	 50803201 	 1000 	 0.08176374435424805 	 0.0799705982208252 	 0.07341432571411133 	 0.06788277626037598 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:17.133192 test begin: paddle.Tensor.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_or 	 paddle.Tensor.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11789560317993164 	 0.11621403694152832 	 0.10878849029541016 	 0.10279965400695801 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:18.784726 test begin: paddle.Tensor.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, ) 	 25401660 	 1000 	 0.3249702453613281 	 0.30279994010925293 	 0.3124401569366455 	 0.2905292510986328 	 0.44362974166870117 	 0.448840856552124 	 0.38954639434814453 	 0.3866579532623291 	 
2025-07-25 17:49:21.360553 test begin: paddle.Tensor.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, ) 	 25401640 	 1000 	 0.32497644424438477 	 0.3025851249694824 	 0.3157072067260742 	 0.29024481773376465 	 0.4436213970184326 	 0.44887757301330566 	 0.3898749351501465 	 0.3869030475616455 	 
2025-07-25 17:49:23.929428 test begin: paddle.Tensor.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, ) 	 25401630 	 1000 	 0.3250713348388672 	 0.30281996726989746 	 0.3159313201904297 	 0.290513277053833 	 0.4433877468109131 	 0.4489319324493408 	 0.3893747329711914 	 0.3869659900665283 	 
2025-07-25 17:49:26.510106 test begin: paddle.Tensor.lu(Tensor([1693, 3],"float32"), )
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:924: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  LU, pivots, infos = torch._lu_with_info(
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([1693, 3],"float32"), ) 	 5079 	 1000 	 0.05472874641418457 	 0.17605805397033691 	 1.6689300537109375e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:27.288435 test begin: paddle.Tensor.lu(Tensor([216, 3, 2, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([216, 3, 2, 2],"float64"), ) 	 2592 	 1000 	 13.12576699256897 	 0.03753995895385742 	 0.00012946128845214844 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:45.457632 test begin: paddle.Tensor.lu(Tensor([3, 1193],"float32"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([3, 1193],"float32"), ) 	 3579 	 1000 	 0.05763435363769531 	 0.12940216064453125 	 1.8358230590820312e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:46.004330 test begin: paddle.Tensor.lu(Tensor([3, 3, 422],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([3, 3, 422],"float64"), ) 	 3798 	 1000 	 0.14312267303466797 	 0.13260316848754883 	 3.4809112548828125e-05 	 6.127357482910156e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:46.665529 test begin: paddle.Tensor.lu(Tensor([3, 422, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([3, 422, 3],"float64"), ) 	 3798 	 1000 	 0.09658026695251465 	 0.10962414741516113 	 3.838539123535156e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:47.251298 test begin: paddle.Tensor.lu(Tensor([4, 187, 2, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 187, 2, 2],"float64"), ) 	 2992 	 1000 	 15.341968059539795 	 0.03752017021179199 	 0.00010848045349121094 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:50:08.379924 test begin: paddle.Tensor.lu(Tensor([4, 3, 158, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 3, 158, 2],"float64"), ) 	 3792 	 1000 	 0.28844428062438965 	 0.10669779777526855 	 4.267692565917969e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:50:09.221335 test begin: paddle.Tensor.lu(Tensor([4, 3, 2, 158],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 3, 2, 158],"float64"), ) 	 3792 	 1000 	 0.38741540908813477 	 0.14161968231201172 	 4.267692565917969e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:50:10.191859 test begin: paddle.Tensor.lu(Tensor([522, 3, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([522, 3, 3],"float64"), ) 	 4698 	 1000 	 12.399216413497925 	 0.037200927734375 	 0.00011277198791503906 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:50:26.720793 test begin: paddle.Tensor.masked_fill(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 1],"bool"), 0.0, ) 	 51001907 	 1000 	 0.1442720890045166 	 0.6225800514221191 	 0.04907345771789551 	 0.2106773853302002 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:29.628733 test begin: paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1380],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1380],"bool"), 0.0, ) 	 101645280 	 1000 	 0.37726664543151855 	 0.6510510444641113 	 0.0963900089263916 	 0.22160911560058594 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:33.267679 test begin: paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, ) 	 50859468 	 1000 	 0.14270544052124023 	 0.8509914875030518 	 0.04848337173461914 	 0.21123623847961426 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:39.416567 test begin: paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1325],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1325],"bool"), 0.0, ) 	 101672550 	 1000 	 0.3934650421142578 	 1.1032288074493408 	 0.09634995460510254 	 0.2220308780670166 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:47.641019 test begin: paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, ) 	 50874642 	 1000 	 0.24638915061950684 	 0.6210639476776123 	 0.0838935375213623 	 0.21135711669921875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:50.337300 test begin: paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, ) 	 50812650 	 1000 	 0.1418149471282959 	 0.6163392066955566 	 0.048217058181762695 	 0.2097785472869873 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:52.923893 test begin: paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 5942],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 5942],"bool"), 0.0, ) 	 101608200 	 1000 	 0.39319467544555664 	 0.6534533500671387 	 0.09631705284118652 	 0.2215256690979004 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:56.676166 test begin: paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, ) 	 52539750 	 1000 	 0.45861101150512695 	 0.6377391815185547 	 0.11697220802307129 	 0.3258180618286133 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:59.932842 test begin: paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([24, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([24, 8550, 1],"bool"), 0.0, ) 	 52736400 	 1000 	 0.14776349067687988 	 0.6367063522338867 	 0.05027484893798828 	 0.325244665145874 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:02.736988 test begin: paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, ) 	 56604636 	 1000 	 0.49214625358581543 	 0.6880791187286377 	 0.12556242942810059 	 0.35152673721313477 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:07.763776 test begin: paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([6, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([6, 36828, 1],"bool"), 0.0, ) 	 56788776 	 1000 	 0.46532487869262695 	 0.6961121559143066 	 0.05396389961242676 	 0.34990763664245605 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:11.401153 test begin: paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, ) 	 58970079 	 1000 	 0.5133059024810791 	 0.7239603996276855 	 0.13093972206115723 	 0.24474048614501953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:15.141404 test begin: paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([6, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([6, 38367, 1],"bool"), 0.0, ) 	 59161914 	 1000 	 0.1668086051940918 	 0.7154965400695801 	 0.05623292922973633 	 0.24356508255004883 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:18.131868 test begin: paddle.Tensor.masked_select(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"bool"), ) 	 101606500 	 1000 	 2.6206884384155273 	 2.4482979774475098 	 0.0016531944274902344 	 0.0023458003997802734 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:28.292675 test begin: paddle.Tensor.masked_select(Tensor([15000, 3387],"float32"), Tensor([15000, 3387],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([15000, 3387],"float32"), Tensor([15000, 3387],"bool"), ) 	 101610000 	 1000 	 1.372837781906128 	 2.450932502746582 	 0.0008556842803955078 	 0.002335071563720703 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:37.524621 test begin: paddle.Tensor.masked_select(Tensor([50803201],"float32"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([50803201],"float32"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 4.821571111679077 	 1.140732765197754 	 0.002941608428955078 	 0.001033782958984375 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:52.937883 test begin: paddle.Tensor.masked_select(Tensor([60000, 847],"float32"), Tensor([60000, 847],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([60000, 847],"float32"), Tensor([60000, 847],"bool"), ) 	 101640000 	 1000 	 1.377155065536499 	 2.4394302368164062 	 0.0008585453033447266 	 0.002334117889404297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:52:00.571714 test begin: paddle.Tensor.matmul(Tensor([110, 12, 197, 197],"float32"), Tensor([110, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([110, 12, 197, 197],"float32"), Tensor([110, 12, 197, 64],"float32"), ) 	 67870440 	 1000 	 1.0278244018554688 	 1.02748703956604 	 1.014503002166748 	 1.0038588047027588 	 1.7513971328735352 	 1.751410961151123 	 0.894874095916748 	 0.8948795795440674 	 
2025-07-25 17:52:07.621428 test begin: paddle.Tensor.matmul(Tensor([124, 16, 100, 257],"float32"), Tensor([124, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 16, 100, 257],"float32"), Tensor([124, 16, 257, 64],"float32"), ) 	 83621632 	 1000 	 1.0279450416564941 	 1.0304374694824219 	 1.012932538986206 	 1.0005805492401123 	 2.0477843284606934 	 2.047877311706543 	 1.0465269088745117 	 1.0462772846221924 	 
2025-07-25 17:52:15.374245 test begin: paddle.Tensor.matmul(Tensor([124, 16, 257, 257],"float32"), Tensor([124, 16, 257, 100],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 16, 257, 257],"float32"), Tensor([124, 16, 257, 100],"float32"), ) 	 182030016 	 1000 	 2.982090950012207 	 2.9786243438720703 	 2.9689972400665283 	 2.9531378746032715 	 6.655327081680298 	 6.659642934799194 	 3.3983778953552246 	 3.4032397270202637 	 
2025-07-25 17:52:39.802228 test begin: paddle.Tensor.matmul(Tensor([124, 25, 257, 257],"float32"), Tensor([124, 25, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 25, 257, 257],"float32"), Tensor([124, 25, 257, 64],"float32"), ) 	 255740700 	 1000 	 4.61839747428894 	 4.623056650161743 	 4.597652196884155 	 4.576009511947632 	 8.402248859405518 	 8.401296854019165 	 4.293479919433594 	 4.293075084686279 	 
2025-07-25 17:53:11.836490 test begin: paddle.Tensor.matmul(Tensor([124, 7, 257, 257],"float32"), Tensor([124, 7, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 7, 257, 257],"float32"), Tensor([124, 7, 257, 64],"float32"), ) 	 71607396 	 1000 	 1.3342695236206055 	 1.3343453407287598 	 1.3134584426879883 	 1.300337553024292 	 2.4023797512054443 	 2.4036383628845215 	 1.2269845008850098 	 1.2282540798187256 	 
2025-07-25 17:53:20.814502 test begin: paddle.Tensor.matmul(Tensor([128, 11, 197, 197],"float32"), Tensor([128, 11, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 11, 197, 197],"float32"), Tensor([128, 11, 197, 64],"float32"), ) 	 72395136 	 1000 	 1.1000471115112305 	 1.1001238822937012 	 1.0785655975341797 	 1.0663824081420898 	 1.8717617988586426 	 1.8717896938323975 	 0.9563877582550049 	 0.9564683437347412 	 
2025-07-25 17:53:28.321350 test begin: paddle.Tensor.matmul(Tensor([128, 12, 168, 197],"float32"), Tensor([128, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 12, 168, 197],"float32"), Tensor([128, 12, 197, 64],"float32"), ) 	 70201344 	 1000 	 1.189342975616455 	 1.1891460418701172 	 1.1686019897460938 	 1.1552610397338867 	 1.8490164279937744 	 1.850020408630371 	 0.9447617530822754 	 0.9452667236328125 	 
2025-07-25 17:53:37.551647 test begin: paddle.Tensor.matmul(Tensor([128, 12, 197, 197],"float32"), Tensor([128, 12, 197, 168],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 12, 197, 197],"float32"), Tensor([128, 12, 197, 168],"float32"), ) 	 110446080 	 1000 	 2.6451475620269775 	 2.3314642906188965 	 2.31693696975708 	 2.3038899898529053 	 4.30346417427063 	 4.302919626235962 	 2.198807716369629 	 2.198655128479004 	 
2025-07-25 17:53:53.943720 test begin: paddle.Tensor.matmul(Tensor([128, 16, 257, 257],"float32"), Tensor([128, 16, 257, 97],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 16, 257, 257],"float32"), Tensor([128, 16, 257, 97],"float32"), ) 	 186322944 	 1000 	 3.058241605758667 	 3.057839870452881 	 3.0450031757354736 	 3.033782958984375 	 6.854139089584351 	 6.853408098220825 	 3.502192974090576 	 3.5019912719726562 	 
2025-07-25 17:54:17.899431 test begin: paddle.Tensor.matmul(Tensor([128, 16, 97, 257],"float32"), Tensor([128, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 16, 97, 257],"float32"), Tensor([128, 16, 257, 64],"float32"), ) 	 84740096 	 1000 	 1.0265512466430664 	 1.026393175125122 	 1.0136632919311523 	 1.0024828910827637 	 2.1042773723602295 	 2.1049046516418457 	 1.0751714706420898 	 1.075469970703125 	 
2025-07-25 17:54:25.836681 test begin: paddle.Tensor.matmul(Tensor([128, 25, 257, 257],"float32"), Tensor([128, 25, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 25, 257, 257],"float32"), Tensor([128, 25, 257, 64],"float32"), ) 	 263990400 	 1000 	 4.763064622879028 	 4.762008428573608 	 4.749096393585205 	 4.737853765487671 	 8.66877031326294 	 8.668254137039185 	 4.429402589797974 	 4.429426670074463 	 
2025-07-25 17:54:59.253140 test begin: paddle.Tensor.matmul(Tensor([128, 32, 197, 197],"float32"), Tensor([128, 32, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 32, 197, 197],"float32"), Tensor([128, 32, 197, 64],"float32"), ) 	 210604032 	 1000 	 3.1022233963012695 	 3.102073907852173 	 3.089076519012451 	 3.078549385070801 	 5.324115991592407 	 5.3234899044036865 	 2.7203030586242676 	 2.7201623916625977 	 
2025-07-25 17:55:20.726487 test begin: paddle.Tensor.matmul(Tensor([128, 7, 257, 257],"float32"), Tensor([128, 7, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 7, 257, 257],"float32"), Tensor([128, 7, 257, 64],"float32"), ) 	 73917312 	 1000 	 1.3451509475708008 	 1.345273733139038 	 1.3321506977081299 	 1.3212199211120605 	 2.448457956314087 	 2.4482600688934326 	 1.251082181930542 	 1.2509617805480957 	 
2025-07-25 17:55:29.795799 test begin: paddle.Tensor.matmul(Tensor([194, 16, 257, 257],"float32"), Tensor([194, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([194, 16, 257, 257],"float32"), Tensor([194, 16, 257, 64],"float32"), ) 	 256070688 	 1000 	 4.653126239776611 	 4.6538825035095215 	 4.6377809047698975 	 4.624722480773926 	 8.440850973129272 	 8.440317630767822 	 4.3131103515625 	 4.3128626346588135 	 
2025-07-25 17:56:01.961876 test begin: paddle.Tensor.matmul(Tensor([336, 12, 197, 197],"float32"), Tensor([336, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([336, 12, 197, 197],"float32"), Tensor([336, 12, 197, 64],"float32"), ) 	 207313344 	 1000 	 3.0604400634765625 	 3.065843105316162 	 3.047196865081787 	 3.0366272926330566 	 5.246865272521973 	 5.2470786571502686 	 2.6810874938964844 	 2.6811118125915527 	 
2025-07-25 17:56:23.088941 test begin: paddle.Tensor.matmul(Tensor([49, 16, 257, 257],"float32"), Tensor([49, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([49, 16, 257, 257],"float32"), Tensor([49, 16, 257, 64],"float32"), ) 	 64677648 	 1000 	 1.1846272945404053 	 1.184800148010254 	 1.1716718673706055 	 1.1609914302825928 	 2.151146173477173 	 2.1513710021972656 	 1.099217176437378 	 1.099259376525879 	 
2025-07-25 17:56:31.044358 test begin: paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), -2, ) 	 50803600 	 1000 	 0.260847806930542 	 0.19374537467956543 	 0.24928665161132812 	 0.1761467456817627 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:33.515150 test begin: paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), axis=-1, keepdim=True, ) 	 50803600 	 1000 	 0.18066024780273438 	 0.16025757789611816 	 0.09226346015930176 	 0.1371593475341797 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:37.318146 test begin: paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), -2, ) 	 50840832 	 1000 	 0.30864596366882324 	 0.1627054214477539 	 0.15765047073364258 	 0.14265871047973633 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:39.833076 test begin: paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), axis=-1, keepdim=True, ) 	 50840832 	 1000 	 0.1627669334411621 	 0.15789532661437988 	 0.08316516876220703 	 0.1424252986907959 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:42.067953 test begin: paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), -2, ) 	 52684800 	 1000 	 0.2582881450653076 	 0.16745901107788086 	 0.24704456329345703 	 0.1505138874053955 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:44.544711 test begin: paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), axis=-1, keepdim=True, ) 	 52684800 	 1000 	 0.16693496704101562 	 0.16234922409057617 	 0.08529877662658691 	 0.13943958282470703 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:46.828513 test begin: paddle.Tensor.max(Tensor([324000, 157],"float32"), axis=1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([324000, 157],"float32"), axis=1, keepdim=True, ) 	 50868000 	 1000 	 0.5778622627258301 	 0.41138172149658203 	 0.5656864643096924 	 0.39557957649230957 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:49.933543 test begin: paddle.Tensor.max(Tensor([635041, 80],"float32"), axis=1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([635041, 80],"float32"), axis=1, keepdim=True, ) 	 50803280 	 1000 	 0.5386576652526855 	 0.5394954681396484 	 0.5264313220977783 	 0.516625165939331 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:56:53.123396 test begin: paddle.Tensor.mean(Tensor([124, 128, 34, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 128, 34, 96],"float32"), 1, keepdim=True, ) 	 51806208 	 1000 	 0.21217608451843262 	 0.1594994068145752 	 0.19608187675476074 	 0.13756227493286133 	 0.14324617385864258 	 0.19711017608642578 	 0.08647775650024414 	 0.0870978832244873 	 
2025-07-25 17:56:54.700109 test begin: paddle.Tensor.mean(Tensor([124, 128, 96, 34],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 128, 96, 34],"float32"), 1, keepdim=True, ) 	 51806208 	 1000 	 0.21213150024414062 	 0.15371203422546387 	 0.20049238204956055 	 0.13755440711975098 	 0.14370369911193848 	 0.1970505714416504 	 0.08722448348999023 	 0.12450838088989258 	 
2025-07-25 17:56:56.267957 test begin: paddle.Tensor.mean(Tensor([124, 45, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 45, 96, 96],"float32"), 1, keepdim=True, ) 	 51425280 	 1000 	 0.16550493240356445 	 0.15741467475891113 	 0.15399789810180664 	 0.14224481582641602 	 0.14645838737487793 	 0.2123725414276123 	 0.08931827545166016 	 0.13935256004333496 	 
2025-07-25 17:56:57.815084 test begin: paddle.Tensor.mean(Tensor([128, 128, 33, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 128, 33, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.20457839965820312 	 0.1525099277496338 	 0.19298148155212402 	 0.1311817169189453 	 0.14402294158935547 	 0.1981208324432373 	 0.07765436172485352 	 0.11447715759277344 	 
2025-07-25 17:56:59.372368 test begin: paddle.Tensor.mean(Tensor([128, 128, 96, 33],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 128, 96, 33],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.20456457138061523 	 0.1524796485900879 	 0.19286894798278809 	 0.1381969451904297 	 0.14382696151733398 	 0.19811058044433594 	 0.08665752410888672 	 0.12615609169006348 	 
2025-07-25 17:57:00.930172 test begin: paddle.Tensor.mean(Tensor([128, 192, 22, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 192, 22, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.21903038024902344 	 0.15059328079223633 	 0.19904494285583496 	 0.12950921058654785 	 0.14419865608215332 	 0.19684529304504395 	 0.07771944999694824 	 0.1169278621673584 	 
2025-07-25 17:57:02.489786 test begin: paddle.Tensor.mean(Tensor([128, 192, 96, 22],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 192, 96, 22],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.21896576881408691 	 0.15060687065124512 	 0.20727062225341797 	 0.13670563697814941 	 0.14341521263122559 	 0.19698858261108398 	 0.08655190467834473 	 0.12421441078186035 	 
2025-07-25 17:57:04.078926 test begin: paddle.Tensor.mean(Tensor([128, 44, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 44, 96, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.16772675514221191 	 0.15754365921020508 	 0.15600323677062988 	 0.14337754249572754 	 0.14778757095336914 	 0.2152707576751709 	 0.08894801139831543 	 0.14275193214416504 	 
2025-07-25 17:57:05.659528 test begin: paddle.Tensor.mean(Tensor([29, 192, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([29, 192, 96, 96],"float32"), 1, keepdim=True, ) 	 51314688 	 1000 	 0.16467761993408203 	 0.14816498756408691 	 0.15311074256896973 	 0.13451671600341797 	 0.14063191413879395 	 0.19205093383789062 	 0.0829782485961914 	 0.11979484558105469 	 
2025-07-25 17:57:07.170216 test begin: paddle.Tensor.mean(Tensor([44, 128, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([44, 128, 96, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.16583037376403809 	 0.15080857276916504 	 0.15419840812683105 	 0.13672208786010742 	 0.14209461212158203 	 0.20195531845092773 	 0.0832822322845459 	 0.12986993789672852 	 
2025-07-25 17:57:08.722959 test begin: paddle.Tensor.min(Tensor([1, 193, 65856, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 193, 65856, 4],"float32"), axis=-1, ) 	 50840832 	 1000 	 0.5388152599334717 	 0.8674509525299072 	 0.5266580581665039 	 0.8493950366973877 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:12.618938 test begin: paddle.Tensor.min(Tensor([1, 400, 31753, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 31753, 4],"float32"), axis=-1, ) 	 50804800 	 1000 	 0.5384302139282227 	 0.8831071853637695 	 0.5254330635070801 	 0.8415358066558838 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:20.151516 test begin: paddle.Tensor.min(Tensor([1, 400, 65856, 2],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 65856, 2],"float32"), axis=-1, ) 	 52684800 	 1000 	 0.5175197124481201 	 0.8217577934265137 	 0.4976160526275635 	 0.7957861423492432 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:24.658204 test begin: paddle.Tensor.min(Tensor([1, 400, 65856, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 65856, 4],"float32"), axis=-1, ) 	 105369600 	 1000 	 1.111412763595581 	 1.7949137687683105 	 1.0915234088897705 	 1.7729120254516602 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:32.753379 test begin: paddle.Tensor.min(Tensor([15661, 4, 811],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([15661, 4, 811],"float32"), axis=1, ) 	 50804284 	 1000 	 0.21975994110107422 	 1.543881893157959 	 0.2081010341644287 	 0.2810380458831787 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:40.373932 test begin: paddle.Tensor.min(Tensor([24565, 3, 811],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([24565, 3, 811],"float32"), axis=1, ) 	 59766645 	 1000 	 0.30507874488830566 	 0.40712761878967285 	 0.2933485507965088 	 0.38976502418518066 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:44.002552 test begin: paddle.Tensor.min(Tensor([24565, 4, 518],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([24565, 4, 518],"float32"), axis=1, ) 	 50898680 	 1000 	 0.22642993927001953 	 0.26600098609924316 	 0.21471595764160156 	 0.2484126091003418 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:46.787073 test begin: paddle.Tensor.min(Tensor([3, 525, 12096, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([3, 525, 12096, 4],"float32"), axis=-1, ) 	 76204800 	 1000 	 0.805168628692627 	 1.2972290515899658 	 0.7933394908905029 	 1.279212474822998 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:52.533839 test begin: paddle.Tensor.min(Tensor([4, 263, 12096, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 263, 12096, 4],"float32"), axis=-1, ) 	 50899968 	 1000 	 0.539294958114624 	 0.8689286708831787 	 0.5274193286895752 	 0.8502440452575684 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:57:56.425413 test begin: paddle.Tensor.min(Tensor([4, 525, 12096, 3],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 525, 12096, 3],"float32"), axis=-1, ) 	 76204800 	 1000 	 0.5272746086120605 	 0.8906185626983643 	 0.5153350830078125 	 0.8698651790618896 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:58:01.503687 test begin: paddle.Tensor.min(Tensor([4, 525, 6049, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 525, 6049, 4],"float32"), axis=-1, ) 	 50811600 	 1000 	 0.5383028984069824 	 0.867095947265625 	 0.5262360572814941 	 0.8488764762878418 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-25 17:58:05.341726 test begin: paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.mm 	 paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 5080321],"float32"), ) 	 50803310 	 1000 	 0.6534411907196045 	 0.655019998550415 	 0.13341784477233887 	 0.13341140747070312 	 1.4465701580047607 	 1.4427144527435303 	 0.21107268333435059 	 0.21057629585266113 	 
2025-07-25 17:58:11.263875 test begin: paddle.Tensor.mm(Tensor([5080321, 10],"float32"), Tensor([10, 10],"float32"), )
[Prof] paddle.Tensor.mm 	 paddle.Tensor.mm(Tensor([5080321, 10],"float32"), Tensor([10, 10],"float32"), ) 	 50803310 	 1000 	 0.6513757705688477 	 0.651247501373291 	 0.13303589820861816 	 0.1329810619354248 	 1.4156420230865479 	 1.4124085903167725 	 0.20655441284179688 	 0.20616769790649414 	 
2025-07-25 17:58:17.087543 test begin: paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), ) 	 25401606 	 1000 	 54.01658511161804 	 9.497162342071533 	 0.00010919570922851562 	 0.0002434253692626953 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:59:23.406203 test begin: paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), axis=2, keepdim=True, ) 	 25401606 	 1000 	 54.12603807449341 	 9.49305510520935 	 0.00010395050048828125 	 0.00024628639221191406 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:00:29.818791 test begin: paddle.Tensor.mode(Tensor([3, 2822401, 3],"float64"), axis=1, keepdim=False, )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2822401, 3],"float64"), axis=1, keepdim=False, ) 	 25401609 	 1000 	 78.35399770736694 	 10.872016906738281 	 9.989738464355469e-05 	 0.00024437904357910156 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:02:03.950504 test begin: paddle.Tensor.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 25401810 	 1000 	 0.00780487060546875 	 0.004998445510864258 	 1.3113021850585938e-05 	 2.002716064453125e-05 	 0.04075217247009277 	 0.05758261680603027 	 3.337860107421875e-05 	 3.695487976074219e-05 	 
2025-07-25 18:02:05.118901 test begin: paddle.Tensor.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401810 	 1000 	 0.007606983184814453 	 0.006098270416259766 	 8.58306884765625e-06 	 2.4080276489257812e-05 	 0.04104018211364746 	 0.05771970748901367 	 2.3603439331054688e-05 	 4.792213439941406e-05 	 
2025-07-25 18:02:06.289116 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 1058401],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 1058401],"float64"), source=0, destination=2, ) 	 25401624 	 1000 	 0.006894350051879883 	 0.004841327667236328 	 8.821487426757812e-06 	 1.9073486328125e-05 	 0.04101753234863281 	 0.0626680850982666 	 2.193450927734375e-05 	 5.364418029785156e-05 	 
2025-07-25 18:02:07.464371 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 25401768 	 1000 	 0.007054328918457031 	 0.004953622817993164 	 7.3909759521484375e-06 	 1.8358230590820312e-05 	 0.041005611419677734 	 0.05737185478210449 	 3.266334533691406e-05 	 3.337860107421875e-05 	 
2025-07-25 18:02:08.635637 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401768 	 1000 	 0.007566928863525391 	 0.0059833526611328125 	 8.58306884765625e-06 	 1.8596649169921875e-05 	 0.04116415977478027 	 0.06450533866882324 	 2.956390380859375e-05 	 4.57763671875e-05 	 
2025-07-25 18:02:09.826272 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 25401720 	 1000 	 0.007016181945800781 	 0.004945993423461914 	 8.58306884765625e-06 	 1.7881393432617188e-05 	 0.04111003875732422 	 0.05826902389526367 	 2.1457672119140625e-05 	 3.933906555175781e-05 	 
2025-07-25 18:02:11.008201 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401720 	 1000 	 0.007467031478881836 	 0.0059092044830322266 	 2.002716064453125e-05 	 1.8835067749023438e-05 	 0.040886640548706055 	 0.05798053741455078 	 1.8596649169921875e-05 	 4.744529724121094e-05 	 
2025-07-25 18:02:12.186760 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 635041, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 635041, 5],"float64"), source=0, destination=2, ) 	 25401640 	 1000 	 0.0068056583404541016 	 0.0048885345458984375 	 8.344650268554688e-06 	 1.8835067749023438e-05 	 0.040906429290771484 	 0.06025409698486328 	 1.811981201171875e-05 	 5.3882598876953125e-05 	 
2025-07-25 18:02:13.353561 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 25401880 	 1000 	 0.0070612430572509766 	 0.004987001419067383 	 8.344650268554688e-06 	 2.384185791015625e-05 	 0.04090428352355957 	 0.058619022369384766 	 2.9087066650390625e-05 	 7.295608520507812e-05 	 
2025-07-25 18:02:14.538023 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401880 	 1000 	 0.007541179656982422 	 0.005868673324584961 	 8.106231689453125e-06 	 1.7881393432617188e-05 	 0.04093599319458008 	 0.05812644958496094 	 1.8358230590820312e-05 	 4.363059997558594e-05 	 
2025-07-25 18:02:15.718780 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 423361, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 423361, 3, 5],"float64"), source=0, destination=2, ) 	 25401660 	 1000 	 0.006783723831176758 	 0.004893064498901367 	 8.106231689453125e-06 	 1.7881393432617188e-05 	 0.04091763496398926 	 0.057154178619384766 	 3.0994415283203125e-05 	 3.4332275390625e-05 	 
2025-07-25 18:02:16.899532 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 25402020 	 1000 	 0.007052898406982422 	 0.005001544952392578 	 8.58306884765625e-06 	 1.8835067749023438e-05 	 0.04171633720397949 	 0.05756688117980957 	 3.981590270996094e-05 	 3.123283386230469e-05 	 
2025-07-25 18:02:18.086476 test begin: paddle.Tensor.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25402020 	 1000 	 0.0077037811279296875 	 0.005957841873168945 	 1.0013580322265625e-05 	 1.9550323486328125e-05 	 0.041190385818481445 	 0.05771994590759277 	 2.193450927734375e-05 	 4.1484832763671875e-05 	 
2025-07-25 18:02:19.261276 test begin: paddle.Tensor.moveaxis(x=Tensor([846721, 2, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([846721, 2, 3, 5],"float64"), source=0, destination=2, ) 	 25401630 	 1000 	 0.0067446231842041016 	 0.004792451858520508 	 8.58306884765625e-06 	 1.8596649169921875e-05 	 0.040877342224121094 	 0.06481003761291504 	 2.2172927856445312e-05 	 6.866455078125e-05 	 
2025-07-25 18:02:20.450775 test begin: paddle.Tensor.multiply(Tensor([132301, 768],"float16"), Tensor([132301, 1],"float32"), )
W0725 18:02:22.292379 106198 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([132301, 768],"float16"), Tensor([132301, 1],"float32"), ) 	 101739469 	 1000 	 1.0731546878814697 	 0.7279596328735352 	 0.5462920665740967 	 0.7086532115936279 	 1.9102153778076172 	 2.126840353012085 	 0.6501343250274658 	 0.5430591106414795 	 
2025-07-25 18:02:30.068857 test begin: paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 1],"float32"), ) 	 50803520 	 1000 	 0.2965548038482666 	 0.3034040927886963 	 0.2862081527709961 	 0.29110288619995117 	 0.7714743614196777 	 0.922480583190918 	 0.262420654296875 	 0.23539090156555176 	 
2025-07-25 18:02:34.039633 test begin: paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 317521],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 317521],"float32"), ) 	 101606720 	 1000 	 0.44985294342041016 	 0.4541313648223877 	 0.44030141830444336 	 0.43145179748535156 	 1.1624395847320557 	 0.8933041095733643 	 1.0996143817901611 	 0.4563770294189453 	 
2025-07-25 18:02:41.296204 test begin: paddle.Tensor.multiply(Tensor([160, 635041],"float16"), Tensor([160, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 635041],"float16"), Tensor([160, 1],"float32"), ) 	 101606720 	 1000 	 1.071218490600586 	 0.7043471336364746 	 0.5472776889801025 	 0.6810588836669922 	 1.9224953651428223 	 2.137671947479248 	 0.4906160831451416 	 0.43646812438964844 	 
2025-07-25 18:02:53.814241 test begin: paddle.Tensor.multiply(Tensor([16538, 3072],"float32"), Tensor([16538, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([16538, 3072],"float32"), Tensor([16538, 1],"float32"), ) 	 50821274 	 1000 	 0.29547858238220215 	 0.307722806930542 	 0.28503894805908203 	 0.29530858993530273 	 0.7365319728851318 	 0.9000358581542969 	 0.3762679100036621 	 0.3064768314361572 	 
2025-07-25 18:02:57.737399 test begin: paddle.Tensor.multiply(Tensor([33076, 3072],"float16"), Tensor([33076, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([33076, 3072],"float16"), Tensor([33076, 1],"float32"), ) 	 101642548 	 1000 	 1.0668630599975586 	 0.7231144905090332 	 0.545060396194458 	 0.7100694179534912 	 1.904236078262329 	 2.130463123321533 	 0.6480793952941895 	 0.5439410209655762 	 
2025-07-25 18:03:07.213893 test begin: paddle.Tensor.multiply(Tensor([512, 198451],"float16"), Tensor([512, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([512, 198451],"float16"), Tensor([512, 1],"float32"), ) 	 101607424 	 1000 	 1.0684630870819092 	 0.698258638381958 	 0.5458664894104004 	 0.681955099105835 	 1.9464538097381592 	 2.1547300815582275 	 0.4967184066772461 	 0.550206184387207 	 
2025-07-25 18:03:16.676242 test begin: paddle.Tensor.nansum(Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0640814304351807 	 0.19130468368530273 	 0.2720978260040283 	 0.17394185066223145 	 0.5298187732696533 	 0.4416921138763428 	 0.2707366943359375 	 0.15036845207214355 	 
2025-07-25 18:03:19.609428 test begin: paddle.Tensor.nansum(Tensor([2822401, 3, 3],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([2822401, 3, 3],"float64"), ) 	 25401609 	 1000 	 0.9354784488677979 	 0.15015769004821777 	 0.1909775733947754 	 0.07671427726745605 	 0.46474575996398926 	 0.4131588935852051 	 0.2374100685119629 	 0.1406254768371582 	 
2025-07-25 18:03:22.110541 test begin: paddle.Tensor.nansum(Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0641438961029053 	 0.18958115577697754 	 0.27208518981933594 	 0.17403411865234375 	 0.5297393798828125 	 0.44168543815612793 	 0.2706136703491211 	 0.1503753662109375 	 
2025-07-25 18:03:25.005800 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401780 	 1000 	 5.656517028808594 	 0.1735527515411377 	 1.1588022708892822 	 0.08866715431213379 	 0.4659152030944824 	 0.4174659252166748 	 0.23800015449523926 	 0.14214277267456055 	 
2025-07-25 18:03:32.264997 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401744 	 1000 	 0.974402666091919 	 0.19632458686828613 	 0.24906516075134277 	 0.17392206192016602 	 0.5134308338165283 	 0.4436051845550537 	 0.2623271942138672 	 0.15104937553405762 	 
2025-07-25 18:03:35.077272 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 0.9744374752044678 	 0.19725990295410156 	 0.2490530014038086 	 0.17490911483764648 	 0.5135860443115234 	 0.4440619945526123 	 0.26238393783569336 	 0.15116286277770996 	 
2025-07-25 18:03:39.578627 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, ) 	 25402320 	 1000 	 0.9742677211761475 	 0.1901078224182129 	 0.24908089637756348 	 0.17450332641601562 	 0.5133168697357178 	 0.4452831745147705 	 0.2622849941253662 	 0.15159034729003906 	 
2025-07-25 18:03:42.382828 test begin: paddle.Tensor.nansum(Tensor([3, 2822401, 3],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2822401, 3],"float64"), ) 	 25401609 	 1000 	 0.9354739189147949 	 0.15015697479248047 	 0.19101953506469727 	 0.07672929763793945 	 0.4647560119628906 	 0.41315412521362305 	 0.23740172386169434 	 0.14066100120544434 	 
2025-07-25 18:03:44.899504 test begin: paddle.Tensor.nansum(Tensor([3, 3, 2822401],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 3, 2822401],"float64"), ) 	 25401609 	 1000 	 0.9354281425476074 	 0.15025925636291504 	 0.19100236892700195 	 0.07678008079528809 	 0.46480607986450195 	 0.41318583488464355 	 0.23743271827697754 	 0.14064764976501465 	 
2025-07-25 18:03:47.552244 test begin: paddle.Tensor.nansum(Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 1.009847640991211 	 0.15285229682922363 	 0.20615172386169434 	 0.07809805870056152 	 0.5567853450775146 	 0.5897023677825928 	 0.284437894821167 	 0.20091795921325684 	 
2025-07-25 18:03:50.728275 test begin: paddle.Tensor.nansum(Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 1.0099334716796875 	 0.15287184715270996 	 0.20615172386169434 	 0.07809686660766602 	 0.5567057132720947 	 0.5896914005279541 	 0.2844245433807373 	 0.2008683681488037 	 
2025-07-25 18:03:57.541939 test begin: paddle.Tensor.nansum(Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 1.063807487487793 	 0.18958497047424316 	 0.27202439308166504 	 0.16647982597351074 	 0.5309569835662842 	 0.44194912910461426 	 0.27123498916625977 	 0.15050816535949707 	 
2025-07-25 18:04:00.449628 test begin: paddle.Tensor.nansum(Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 1.0098073482513428 	 0.15291070938110352 	 0.20611906051635742 	 0.07810854911804199 	 0.5566990375518799 	 0.5896487236022949 	 0.2844243049621582 	 0.2008213996887207 	 
2025-07-25 18:04:03.665575 test begin: paddle.Tensor.neg(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.neg 	 paddle.Tensor.neg(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.29586362838745117 	 0.3012857437133789 	 0.2790052890777588 	 0.2807760238647461 	 0.295853853225708 	 0.29773616790771484 	 0.234818696975708 	 0.22631287574768066 	 
2025-07-25 18:04:06.574219 test begin: paddle.Tensor.nonzero(Tensor([3628801, 14],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([3628801, 14],"bool"), ) 	 50803214 	 1000 	 5.889880180358887 	 1.4172635078430176 	 0.003990650177001953 	 0.0013167858123779297 	 None 	 None 	 None 	 None 	 
2025-07-25 18:04:14.624623 test begin: paddle.Tensor.nonzero(Tensor([3907939, 13],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([3907939, 13],"bool"), ) 	 50803207 	 1000 	 5.886811971664429 	 1.4164910316467285 	 0.004009723663330078 	 0.0013148784637451172 	 None 	 None 	 None 	 None 	 
2025-07-25 18:04:22.667381 test begin: paddle.Tensor.nonzero(Tensor([4233601, 12],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([4233601, 12],"bool"), ) 	 50803212 	 1000 	 5.884610414505005 	 1.4167907238006592 	 0.004012346267700195 	 0.001317739486694336 	 None 	 None 	 None 	 None 	 
2025-07-25 18:04:30.699776 test begin: paddle.Tensor.nonzero(Tensor([52640, 966],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([52640, 966],"bool"), ) 	 50850240 	 1000 	 5.888718605041504 	 1.4250335693359375 	 0.004001140594482422 	 0.0013217926025390625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:04:40.168061 test begin: paddle.Tensor.norm(Tensor([100352, 507],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.1527411937713623 	 0.15256786346435547 	 0.0519101619720459 	 0.07790279388427734 	 0.9970910549163818 	 0.9116823673248291 	 0.9410519599914551 	 0.23303532600402832 	 
2025-07-25 18:04:43.267515 test begin: paddle.Tensor.norm(Tensor([507, 100352],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.1527094841003418 	 0.15257477760314941 	 0.051912546157836914 	 0.07793021202087402 	 0.9970622062683105 	 0.9116029739379883 	 0.9410309791564941 	 0.2330305576324463 	 
2025-07-25 18:04:46.427650 test begin: paddle.Tensor.norm(Tensor([6202, 8192],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.1527087688446045 	 0.1523146629333496 	 0.05190110206604004 	 0.07776141166687012 	 0.9961040019989014 	 0.9102263450622559 	 0.9307327270507812 	 0.23267006874084473 	 
2025-07-25 18:04:49.497722 test begin: paddle.Tensor.norm(Tensor([8192, 6202],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.15268397331237793 	 0.15234947204589844 	 0.05192446708679199 	 0.07783198356628418 	 0.9959969520568848 	 0.9101405143737793 	 0.9399106502532959 	 0.23264241218566895 	 
2025-07-25 18:04:52.553344 test begin: paddle.Tensor.norm(Tensor([886, 57344],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.15263772010803223 	 0.1524660587310791 	 0.05187726020812988 	 0.07782602310180664 	 0.9959053993225098 	 0.9102928638458252 	 0.941472053527832 	 0.2326796054840088 	 
2025-07-25 18:04:55.607681 test begin: paddle.Tensor.not_equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), ) 	 50803456 	 1000 	 0.31047749519348145 	 0.31324315071105957 	 0.3017754554748535 	 0.3007168769836426 	 None 	 None 	 None 	 None 	 
2025-07-25 18:04:57.085731 test begin: paddle.Tensor.not_equal(Tensor([13, 1953970],"int64"), Tensor([1],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([13, 1953970],"int64"), Tensor([1],"int64"), ) 	 25401611 	 1000 	 0.1761784553527832 	 0.18103384971618652 	 0.16669154167175293 	 0.16785025596618652 	 None 	 None 	 None 	 None 	 
2025-07-25 18:04:59.814042 test begin: paddle.Tensor.not_equal(Tensor([13, 3907939],"bool"), Tensor([1],"bool"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([13, 3907939],"bool"), Tensor([1],"bool"), ) 	 50803208 	 1000 	 0.1376957893371582 	 0.43843626976013184 	 0.12844562530517578 	 0.18576526641845703 	 None 	 None 	 None 	 None 	 
2025-07-25 18:05:02.650588 test begin: paddle.Tensor.not_equal(Tensor([1814401, 14],"int64"), Tensor([1],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([1814401, 14],"int64"), Tensor([1],"int64"), ) 	 25401615 	 1000 	 0.17619729042053223 	 0.18016719818115234 	 0.16642093658447266 	 0.16783666610717773 	 None 	 None 	 None 	 None 	 
2025-07-25 18:05:03.430160 test begin: paddle.Tensor.not_equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), ) 	 50803456 	 1000 	 0.3103315830230713 	 0.3131873607635498 	 0.3017256259918213 	 0.3018178939819336 	 None 	 None 	 None 	 None 	 
2025-07-25 18:05:04.891072 test begin: paddle.Tensor.not_equal(Tensor([3628801, 14],"bool"), Tensor([1],"bool"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([3628801, 14],"bool"), Tensor([1],"bool"), ) 	 50803215 	 1000 	 0.13767313957214355 	 0.19824481010437012 	 0.12840652465820312 	 0.18601226806640625 	 None 	 None 	 None 	 None 	 
2025-07-25 18:05:05.938398 test begin: paddle.Tensor.outer(x=Tensor([12700801, 2],"float64"), y=Tensor([2, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([12700801, 2],"float64"), y=Tensor([2, 3, 4],"float64"), ) 	 25401626 	 1000 	 3.8787834644317627 	 3.8188745975494385 	 0.15853166580200195 	 0.9751391410827637 	 7.481673002243042 	 22.864240646362305 	 2.5470831394195557 	 1.1669235229492188 	 
2025-07-25 18:06:00.445445 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3175201],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3175201],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401632 	 1000 	 3.8814618587493896 	 3.8278112411499023 	 0.1584937572479248 	 0.9777803421020508 	 7.480934143066406 	 22.806562900543213 	 2.547254800796509 	 1.1639440059661865 	 
2025-07-25 18:06:52.068243 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3175201],"float64"), ) 	 25401632 	 1000 	 4.043606758117676 	 7.110292196273804 	 0.16522789001464844 	 1.8164236545562744 	 7.437750577926636 	 25.531858444213867 	 2.5326507091522217 	 1.3044095039367676 	 
2025-07-25 18:07:51.506241 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2116801, 3],"float64"), ) 	 25401636 	 1000 	 4.032367467880249 	 7.081664562225342 	 0.16486382484436035 	 1.8086960315704346 	 7.440213918685913 	 25.50652003288269 	 2.533679723739624 	 1.3031785488128662 	 
2025-07-25 18:08:51.730592 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4233601, 2, 3],"float64"), ) 	 25401630 	 1000 	 4.175830125808716 	 7.132349729537964 	 0.17064237594604492 	 1.820143461227417 	 7.4472315311431885 	 25.54426884651184 	 2.535982847213745 	 1.3050601482391357 	 
2025-07-25 18:09:52.750726 test begin: paddle.Tensor.outer(x=Tensor([4, 2116801, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2116801, 3],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401636 	 1000 	 3.879727840423584 	 3.8326964378356934 	 0.15855002403259277 	 0.9787287712097168 	 7.479918718338013 	 22.80603790283203 	 2.546551465988159 	 1.1639986038208008 	 
2025-07-25 18:10:44.232429 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4233601],"float64"), ) 	 25401614 	 1000 	 1.5172843933105469 	 2.368889570236206 	 0.061887502670288086 	 2.3514764308929443 	 2.7476754188537598 	 8.337654113769531 	 0.9355075359344482 	 1.7031805515289307 	 
2025-07-25 18:11:04.125817 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3175201, 4],"float64"), ) 	 25401616 	 1000 	 1.5101687908172607 	 2.3598618507385254 	 0.061724185943603516 	 2.3440489768981934 	 2.7430946826934814 	 8.33575987815857 	 0.93398118019104 	 1.7029058933258057 	 
2025-07-25 18:11:24.059794 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2116801, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2116801, 3, 4],"float64"), ) 	 25401620 	 1000 	 1.5050663948059082 	 3.3611438274383545 	 0.06141352653503418 	 2.336073398590088 	 2.743608236312866 	 8.329977035522461 	 0.9341392517089844 	 1.7017054557800293 	 
2025-07-25 18:11:46.647880 test begin: paddle.Tensor.outer(x=Tensor([4, 6350401],"float64"), y=Tensor([2, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 6350401],"float64"), y=Tensor([2, 3, 4],"float64"), ) 	 25401628 	 1000 	 3.878934860229492 	 3.831605911254883 	 0.15857601165771484 	 0.9787290096282959 	 7.48021125793457 	 22.763884782791138 	 2.546689510345459 	 1.1616661548614502 	 
2025-07-25 18:12:40.558859 test begin: paddle.Tensor.outer(x=Tensor([4233601, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4233601, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401630 	 1000 	 3.8826708793640137 	 3.828622579574585 	 0.15863728523254395 	 0.9763228893280029 	 7.48098087310791 	 22.785301208496094 	 2.5472002029418945 	 1.1629092693328857 	 
2025-07-25 18:13:32.873755 test begin: paddle.Tensor.pow(Tensor([124, 128, 34, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 128, 34, 96],"float32"), 2, ) 	 51806208 	 1000 	 0.37905001640319824 	 0.4946863651275635 	 0.3624565601348877 	 0.283846378326416 	 0.4600067138671875 	 1.0732598304748535 	 0.40544867515563965 	 0.3656282424926758 	 
2025-07-25 18:13:40.752544 test begin: paddle.Tensor.pow(Tensor([124, 128, 96, 34],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 128, 96, 34],"float32"), 2, ) 	 51806208 	 1000 	 0.37812113761901855 	 0.30368542671203613 	 0.36154937744140625 	 0.28357529640197754 	 0.4601781368255615 	 1.0731487274169922 	 0.3962736129760742 	 0.3656129837036133 	 
2025-07-25 18:13:44.739880 test begin: paddle.Tensor.pow(Tensor([124, 45, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 45, 96, 96],"float32"), 2, ) 	 51425280 	 1000 	 0.3754119873046875 	 0.3214449882507324 	 0.358875036239624 	 0.28818631172180176 	 0.4566621780395508 	 1.066683292388916 	 0.39098644256591797 	 0.36423254013061523 	 
2025-07-25 18:13:51.857355 test begin: paddle.Tensor.pow(Tensor([128, 128, 33, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 128, 33, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.3775746822357178 	 0.32358288764953613 	 0.36104917526245117 	 0.28349733352661133 	 0.46109700202941895 	 1.075141191482544 	 0.3974118232727051 	 0.36632704734802246 	 
2025-07-25 18:13:55.859500 test begin: paddle.Tensor.pow(Tensor([128, 128, 96, 33],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 128, 96, 33],"float32"), 2, ) 	 51904512 	 1000 	 0.37821078300476074 	 0.3051443099975586 	 0.361530065536499 	 0.28401947021484375 	 0.4613935947418213 	 1.0751605033874512 	 0.3970949649810791 	 0.36623501777648926 	 
2025-07-25 18:13:59.855700 test begin: paddle.Tensor.pow(Tensor([128, 192, 22, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 192, 22, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.37772178649902344 	 0.30417871475219727 	 0.36847352981567383 	 0.2913937568664551 	 0.4611527919769287 	 1.0750751495361328 	 0.40600109100341797 	 0.3662405014038086 	 
2025-07-25 18:14:03.825424 test begin: paddle.Tensor.pow(Tensor([128, 192, 96, 22],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 192, 96, 22],"float32"), 2, ) 	 51904512 	 1000 	 0.3781614303588867 	 0.3041725158691406 	 0.368729829788208 	 0.2911996841430664 	 0.4612545967102051 	 1.0751242637634277 	 0.4061594009399414 	 0.36626625061035156 	 
2025-07-25 18:14:07.813033 test begin: paddle.Tensor.pow(Tensor([128, 44, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 44, 96, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.37757277488708496 	 0.3059518337249756 	 0.36794161796569824 	 0.2840895652770996 	 0.46133923530578613 	 1.075141429901123 	 0.3974742889404297 	 0.36626410484313965 	 
2025-07-25 18:14:12.026558 test begin: paddle.Tensor.pow(Tensor([29, 192, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([29, 192, 96, 96],"float32"), 2, ) 	 51314688 	 1000 	 0.37253761291503906 	 0.30093955993652344 	 0.36319780349731445 	 0.28084301948547363 	 0.45606231689453125 	 1.063295841217041 	 0.39008498191833496 	 0.36218857765197754 	 
2025-07-25 18:14:16.049018 test begin: paddle.Tensor.pow(Tensor([44, 128, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([44, 128, 96, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.3762385845184326 	 0.3041510581970215 	 0.3669159412384033 	 0.28922247886657715 	 0.4613182544708252 	 1.075202226638794 	 0.40396714210510254 	 0.36629271507263184 	 
2025-07-25 18:14:20.034357 test begin: paddle.Tensor.prod(Tensor([1, 386, 65856, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 386, 65856, 2],"float32"), -1, ) 	 50840832 	 1000 	 0.3880469799041748 	 0.47665977478027344 	 0.37170982360839844 	 0.45291757583618164 	 1.6771132946014404 	 2.0611352920532227 	 1.6200833320617676 	 0.0007164478302001953 	 
2025-07-25 18:14:25.907336 test begin: paddle.Tensor.prod(Tensor([1, 400, 63505, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 400, 63505, 2],"float32"), -1, ) 	 50804000 	 1000 	 0.3889167308807373 	 0.4673614501953125 	 0.3729090690612793 	 0.4531705379486084 	 1.6765251159667969 	 2.0593760013580322 	 1.619948148727417 	 0.0007138252258300781 	 
2025-07-25 18:14:31.747690 test begin: paddle.Tensor.prod(Tensor([1, 400, 65856, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 400, 65856, 2],"float32"), -1, ) 	 52684800 	 1000 	 0.40201640129089355 	 1.4355802536010742 	 0.3862636089324951 	 0.4632587432861328 	 1.737976312637329 	 2.1272034645080566 	 1.680786371231079 	 0.000743865966796875 	 
2025-07-25 18:14:40.533802 test begin: paddle.Tensor.prod(Tensor([2100, 12096, 3],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2100, 12096, 3],"float32"), -1, ) 	 76204800 	 1000 	 0.4137706756591797 	 0.5191049575805664 	 0.39786458015441895 	 0.4977080821990967 	 1.8898797035217285 	 2.7184054851531982 	 1.8328845500946045 	 0.0010077953338623047 	 
2025-07-25 18:14:47.784190 test begin: paddle.Tensor.prod(Tensor([2100, 12097, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2100, 12097, 2],"float32"), -1, ) 	 50807400 	 1000 	 0.38778066635131836 	 0.467348575592041 	 0.37200212478637695 	 0.4531724452972412 	 1.266509771347046 	 2.056171417236328 	 1.2094807624816895 	 0.0007174015045166016 	 
2025-07-25 18:14:54.491899 test begin: paddle.Tensor.prod(Tensor([2101, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2101, 12096, 2],"float32"), -1, ) 	 50827392 	 1000 	 0.3879096508026123 	 0.4729294776916504 	 0.3721659183502197 	 0.45276522636413574 	 1.2665455341339111 	 2.056973695755005 	 1.2100353240966797 	 0.0007078647613525391 	 
2025-07-25 18:14:59.987561 test begin: paddle.Tensor.prod(Tensor([4, 525, 12096, 3],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 525, 12096, 3],"float32"), -1, ) 	 76204800 	 1000 	 0.4137117862701416 	 0.5120031833648682 	 0.3894927501678467 	 0.49070048332214355 	 2.505378007888794 	 2.723335027694702 	 2.4392638206481934 	 0.0010151863098144531 	 
2025-07-25 18:15:07.852817 test begin: paddle.Tensor.prod(Tensor([4, 525, 12097, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 525, 12097, 2],"float32"), -1, ) 	 50807400 	 1000 	 0.38784337043762207 	 0.4674506187438965 	 0.36331939697265625 	 0.44591259956359863 	 1.6765148639678955 	 2.0536692142486572 	 1.6107888221740723 	 0.0007195472717285156 	 
2025-07-25 18:15:13.792918 test begin: paddle.Tensor.prod(Tensor([4, 526, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 526, 12096, 2],"float32"), -1, ) 	 50899968 	 1000 	 0.38846755027770996 	 0.4682488441467285 	 0.3638932704925537 	 0.44668078422546387 	 1.679534673690796 	 2.0586447715759277 	 1.6123409271240234 	 0.0007178783416748047 	 
2025-07-25 18:15:19.660832 test begin: paddle.Tensor.prod(Tensor([5, 525, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([5, 525, 12096, 2],"float32"), -1, ) 	 63504000 	 1000 	 0.48322248458862305 	 0.5824463367462158 	 0.45922040939331055 	 0.561384916305542 	 2.0932507514953613 	 2.550328493118286 	 2.026628017425537 	 0.0009012222290039062 	 
2025-07-25 18:15:26.984402 test begin: paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 145800 	 1000 	 16.363585948944092 	 0.31153321266174316 	 0.4251677989959717 	 0.0005757808685302734 	 0.2622501850128174 	 0.2708709239959717 	 3.719329833984375e-05 	 9.870529174804688e-05 	 
2025-07-25 18:15:44.319071 test begin: paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 145800 	 1000 	 13.118130207061768 	 1.619187355041504 	 0.36860132217407227 	 0.00021386146545410156 	 0.18909454345703125 	 0.2175905704498291 	 3.838539123535156e-05 	 8.511543273925781e-05 	 
2025-07-25 18:15:59.715691 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=3, keepdim=True, ) 	 124416 	 1000 	 13.97873568534851 	 0.21049785614013672 	 0.36316919326782227 	 6.985664367675781e-05 	 0.19472432136535645 	 0.23277902603149414 	 3.814697265625e-05 	 5.650520324707031e-05 	 
2025-07-25 18:16:14.369542 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=5, ) 	 124416 	 1000 	 0.49492359161376953 	 0.1936664581298828 	 6.651878356933594e-05 	 6.175041198730469e-05 	 0.18052935600280762 	 0.20848727226257324 	 2.47955322265625e-05 	 6.437301635742188e-05 	 
2025-07-25 18:16:15.458290 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253800 	 1000 	 28.350358724594116 	 0.23038434982299805 	 0.7371084690093994 	 6.914138793945312e-05 	 0.19616460800170898 	 0.23384380340576172 	 5.1975250244140625e-05 	 5.650520324707031e-05 	 
2025-07-25 18:16:44.526642 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=5, ) 	 253800 	 1000 	 22.719799995422363 	 0.27954626083374023 	 0.6383323669433594 	 0.00010538101196289062 	 0.23388314247131348 	 0.24626970291137695 	 3.7670135498046875e-05 	 8.726119995117188e-05 	 
2025-07-25 18:17:09.540162 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253800 	 1000 	 0.5659945011138916 	 0.20963501930236816 	 0.014644384384155273 	 7.867813110351562e-05 	 0.20061588287353516 	 0.23533058166503906 	 3.886222839355469e-05 	 7.200241088867188e-05 	 
2025-07-25 18:17:10.763781 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=5, ) 	 253800 	 1000 	 22.718677520751953 	 0.20379400253295898 	 0.6380388736724854 	 5.364418029785156e-05 	 0.17978286743164062 	 0.20906949043273926 	 4.172325134277344e-05 	 4.2438507080078125e-05 	 
2025-07-25 18:17:34.119590 test begin: paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253440 	 1000 	 28.31876301765442 	 0.21703028678894043 	 0.7362501621246338 	 5.888938903808594e-05 	 0.1917262077331543 	 0.23392224311828613 	 4.887580871582031e-05 	 6.532669067382812e-05 	 
2025-07-25 18:18:03.122997 test begin: paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 253440 	 1000 	 22.685219764709473 	 0.20194339752197266 	 0.6372354030609131 	 7.772445678710938e-05 	 0.17569327354431152 	 0.21146011352539062 	 4.220008850097656e-05 	 7.62939453125e-05 	 
2025-07-25 18:18:26.436141 test begin: paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253440 	 1000 	 28.317779779434204 	 0.2119753360748291 	 0.7363150119781494 	 8.320808410644531e-05 	 0.19270825386047363 	 0.24654889106750488 	 5.078315734863281e-05 	 8.0108642578125e-05 	 
2025-07-25 18:18:55.447589 test begin: paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 253440 	 1000 	 22.679314851760864 	 0.28208065032958984 	 0.6374943256378174 	 9.512901306152344e-05 	 0.17970013618469238 	 0.2302231788635254 	 4.220008850097656e-05 	 6.985664367675781e-05 	 
2025-07-25 18:19:20.466506 test begin: paddle.Tensor.rad2deg(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.29824280738830566 	 0.3007786273956299 	 0.28348779678344727 	 0.2846972942352295 	 0.29777073860168457 	 0.29836368560791016 	 0.24540948867797852 	 0.23011350631713867 	 
2025-07-25 18:19:22.728978 test begin: paddle.Tensor.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2978684902191162 	 0.29857444763183594 	 0.28296732902526855 	 0.2840399742126465 	 0.29720497131347656 	 0.29842257499694824 	 0.2449038028717041 	 0.22716808319091797 	 
2025-07-25 18:19:24.993272 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 1587601, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 1587601, 4],"float64"), ) 	 25401616 	 1000 	 0.2982184886932373 	 0.2985851764678955 	 0.2833092212677002 	 0.28470492362976074 	 0.2977738380432129 	 0.2982962131500244 	 0.24544000625610352 	 0.23009681701660156 	 
2025-07-25 18:19:27.255737 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2978653907775879 	 0.2986946105957031 	 0.28310632705688477 	 0.28450608253479004 	 0.2971646785736084 	 0.2983851432800293 	 0.24449753761291504 	 0.22891592979431152 	 
2025-07-25 18:19:29.512514 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 1587601],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 1587601],"float64"), ) 	 25401616 	 1000 	 0.2981729507446289 	 0.2985670566558838 	 0.28327465057373047 	 0.2845470905303955 	 0.2977933883666992 	 0.2983541488647461 	 0.24524736404418945 	 0.230668306350708 	 
2025-07-25 18:19:31.773798 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.29782700538635254 	 0.29856157302856445 	 0.28308939933776855 	 0.28464651107788086 	 0.2971813678741455 	 0.29831433296203613 	 0.2444906234741211 	 0.22967910766601562 	 
2025-07-25 18:19:34.035403 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.2978665828704834 	 0.3091163635253906 	 0.28290843963623047 	 0.2770876884460449 	 0.2972071170806885 	 0.2983989715576172 	 0.24476981163024902 	 0.22206997871398926 	 
2025-07-25 18:19:38.040450 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 6350401],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 0.2981736660003662 	 0.31120848655700684 	 0.2832918167114258 	 0.2843630313873291 	 0.2977724075317383 	 0.2983968257904053 	 0.24404621124267578 	 0.22933340072631836 	 
2025-07-25 18:19:40.345985 test begin: paddle.Tensor.rad2deg(x=Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.29818201065063477 	 0.2985999584197998 	 0.2820737361907959 	 0.2848703861236572 	 0.29773569107055664 	 0.2983403205871582 	 0.24543404579162598 	 0.22992277145385742 	 
2025-07-25 18:19:42.636601 test begin: paddle.Tensor.rank(Tensor([256, 1536, 3, 44],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 1536, 3, 44],"float32"), ) 	 51904512 	 1000 	 0.042194366455078125 	 0.029967069625854492 	 2.002716064453125e-05 	 5.054473876953125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:43.611733 test begin: paddle.Tensor.rank(Tensor([256, 1536, 44, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 1536, 44, 3],"float32"), ) 	 51904512 	 1000 	 0.04165935516357422 	 0.030054807662963867 	 2.9087066650390625e-05 	 5.269050598144531e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:44.560602 test begin: paddle.Tensor.rank(Tensor([256, 2048, 3, 33],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 2048, 3, 33],"float32"), ) 	 51904512 	 1000 	 0.04173088073730469 	 0.02959299087524414 	 1.8596649169921875e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:45.516867 test begin: paddle.Tensor.rank(Tensor([256, 2048, 33, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 2048, 33, 3],"float32"), ) 	 51904512 	 1000 	 0.04147601127624512 	 0.02966451644897461 	 2.6941299438476562e-05 	 5.745887756347656e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:46.465690 test begin: paddle.Tensor.rank(Tensor([256, 22051, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 22051, 3, 3],"float32"), ) 	 50805504 	 1000 	 0.04182124137878418 	 0.030396699905395508 	 1.6927719116210938e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:47.408484 test begin: paddle.Tensor.rank(Tensor([256, 768, 3, 87],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 768, 3, 87],"float32"), ) 	 51314688 	 1000 	 0.04174995422363281 	 0.029690027236938477 	 1.6450881958007812e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:48.346735 test begin: paddle.Tensor.rank(Tensor([256, 768, 87, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([256, 768, 87, 3],"float32"), ) 	 51314688 	 1000 	 0.04414105415344238 	 0.02987837791442871 	 2.9802322387695312e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:49.308224 test begin: paddle.Tensor.rank(Tensor([2757, 2048, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2757, 2048, 3, 3],"float32"), ) 	 50817024 	 1000 	 0.04191255569458008 	 0.029848575592041016 	 1.7404556274414062e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:50.255663 test begin: paddle.Tensor.rank(Tensor([3676, 1536, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([3676, 1536, 3, 3],"float32"), ) 	 50817024 	 1000 	 0.041683197021484375 	 0.030059337615966797 	 2.5510787963867188e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:51.200143 test begin: paddle.Tensor.rank(Tensor([7351, 768, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([7351, 768, 3, 3],"float32"), ) 	 50810112 	 1000 	 0.04420018196105957 	 0.02974224090576172 	 2.9325485229492188e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:19:52.140693 test begin: paddle.Tensor.reciprocal(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.295562744140625 	 0.29830002784729004 	 0.2869377136230469 	 0.2878599166870117 	 0.44949984550476074 	 1.0407953262329102 	 0.39519238471984863 	 0.3545675277709961 	 
2025-07-25 18:19:55.953097 test begin: paddle.Tensor.reciprocal(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2956984043121338 	 0.29831862449645996 	 0.2800419330596924 	 0.2814514636993408 	 0.44969797134399414 	 1.0407161712646484 	 0.38579416275024414 	 0.35459041595458984 	 
2025-07-25 18:19:59.796273 test begin: paddle.Tensor.reciprocal(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.295640230178833 	 0.2983126640319824 	 0.28711438179016113 	 0.287905216217041 	 0.44967222213745117 	 1.040679931640625 	 0.39273643493652344 	 0.3545341491699219 	 
2025-07-25 18:20:03.577974 test begin: paddle.Tensor.reciprocal(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2957327365875244 	 0.29834532737731934 	 0.28014111518859863 	 0.28131675720214844 	 0.4496433734893799 	 1.040705680847168 	 0.38624072074890137 	 0.3545572757720947 	 
2025-07-25 18:20:07.395038 test begin: paddle.Tensor.reciprocal(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2956256866455078 	 0.29839110374450684 	 0.28716492652893066 	 0.2869381904602051 	 0.4496786594390869 	 1.0407202243804932 	 0.39474987983703613 	 0.3545219898223877 	 
2025-07-25 18:20:11.217159 test begin: paddle.Tensor.reciprocal(Tensor([4233601, 12],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([4233601, 12],"float32"), ) 	 50803212 	 1000 	 0.29564857482910156 	 0.2982602119445801 	 0.28691887855529785 	 0.28775477409362793 	 0.4496746063232422 	 1.0407438278198242 	 0.3952171802520752 	 0.35452795028686523 	 
2025-07-25 18:20:15.000160 test begin: paddle.Tensor.remainder(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), ) 	 101606412 	 1000 	 0.4504415988922119 	 0.4494609832763672 	 0.44071292877197266 	 0.4377250671386719 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:17.624713 test begin: paddle.Tensor.remainder(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), ) 	 101606416 	 1000 	 0.45049428939819336 	 0.44936633110046387 	 0.433117151260376 	 0.4310336112976074 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:20.252974 test begin: paddle.Tensor.remainder(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), ) 	 101606424 	 1000 	 0.4504380226135254 	 0.45395469665527344 	 0.43306875228881836 	 0.43095946311950684 	 None 	 None 	 None 	 None 	 
2025-07-25 18:20:23.115914 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 1, 198451, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 1, 198451, 128],"float64"), 3, axis=1, ) 	 25401728 	 1000 	 1.3519306182861328 	 0.8909151554107666 	 0.45937037467956543 	 0.85666823387146 	 1.4866347312927246 	 0.5880095958709717 	 0.5067570209503174 	 0.4384286403656006 	 
2025-07-25 18:20:29.922572 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 1, 64, 396901],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 1, 64, 396901],"float64"), 3, axis=1, ) 	 25401664 	 1000 	 0.8998031616210938 	 0.8830037117004395 	 0.4588634967803955 	 0.8504505157470703 	 1.485344409942627 	 0.587864875793457 	 0.5063717365264893 	 0.4851996898651123 	 
2025-07-25 18:20:37.830237 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 3101, 64, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 3101, 64, 128],"float64"), 3, axis=1, ) 	 25403392 	 1000 	 1.177530288696289 	 0.640451192855835 	 0.07437539100646973 	 0.6142358779907227 	 0.9203290939331055 	 0.5947790145874023 	 0.09461259841918945 	 0.4934258460998535 	 
2025-07-25 18:20:43.362863 test begin: paddle.Tensor.repeat_interleave(Tensor([3101, 1, 64, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([3101, 1, 64, 128],"float64"), 3, axis=1, ) 	 25403392 	 1000 	 0.6242213249206543 	 0.6393499374389648 	 0.3185238838195801 	 0.6144847869873047 	 0.9146409034729004 	 0.5949032306671143 	 0.31168484687805176 	 0.5010669231414795 	 
2025-07-25 18:20:48.347147 test begin: paddle.Tensor.repeat_interleave(x=Tensor([158761, 2, 4, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([158761, 2, 4, 4, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 219.6435580253601 	 0.47145891189575195 	 0.00011301040649414062 	 0.44229936599731445 	 247.66433548927307 	 0.5450661182403564 	 9.989738464355469e-05 	 0.44513869285583496 	 
2025-07-25 18:28:39.983206 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 158761, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 158761, 4, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 198.7691068649292 	 0.46634554862976074 	 0.000152587890625 	 0.44274353981018066 	 226.30185294151306 	 0.5451157093048096 	 0.00019741058349609375 	 0.4184551239013672 	 
2025-07-25 18:35:48.747106 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 158761, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 158761, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 197.61307907104492 	 0.4663853645324707 	 0.00011396408081054688 	 0.44340085983276367 	 225.32039260864258 	 0.5452356338500977 	 0.00018930435180664062 	 0.4417424201965332 	 
2025-07-25 18:42:54.864024 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 198451],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 198451],"float64"), repeats=2, ) 	 25401728 	 1000 	 197.37551927566528 	 0.46637940406799316 	 0.00014066696166992188 	 0.44293642044067383 	 223.00967073440552 	 0.5451006889343262 	 0.00018310546875 	 0.42134833335876465 	 
2025-07-25 18:49:58.319649 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 79381, 4, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 79381, 4, 4, 5],"float64"), repeats=2, ) 	 25401920 	 1000 	 193.52958941459656 	 0.466261625289917 	 0.00012731552124023438 	 0.4429607391357422 	 221.55263781547546 	 0.5451054573059082 	 0.00017642974853515625 	 0.44412946701049805 	 
2025-07-25 18:56:56.451153 test begin: paddle.Tensor.reshape(Tensor([12404, 8192],"bfloat16"), list[-1,8192,], )
[Prof] paddle.Tensor.reshape 	 paddle.Tensor.reshape(Tensor([12404, 8192],"bfloat16"), list[-1,8192,], ) 	 101613568 	 1000 	 0.005297660827636719 	 0.004210472106933594 	 1.1682510375976562e-05 	 2.3365020751953125e-05 	 0.048270463943481445 	 0.4538075923919678 	 5.221366882324219e-05 	 0.3488643169403076 	 
2025-07-25 18:57:00.062968 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5123350620269775 	 0.3035309314727783 	 0.48743224143981934 	 0.28029918670654297 	 0.8217556476593018 	 0.3040592670440674 	 0.4198334217071533 	 0.22098088264465332 	 
2025-07-25 18:57:03.122045 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8163156509399414 	 0.3035249710083008 	 0.4170668125152588 	 0.2785053253173828 	 0.5116651058197021 	 0.3034780025482178 	 0.440932035446167 	 0.2279677391052246 	 
2025-07-25 18:57:06.151600 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8124105930328369 	 0.3036789894104004 	 0.4150352478027344 	 0.2785351276397705 	 0.5117537975311279 	 0.3031759262084961 	 0.43027329444885254 	 0.22674012184143066 	 
2025-07-25 18:57:09.193473 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5131368637084961 	 0.30431437492370605 	 0.4884607791900635 	 0.280576229095459 	 0.8230407238006592 	 0.3027615547180176 	 0.4204838275909424 	 0.20911335945129395 	 
2025-07-25 18:57:12.239459 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.9464054107666016 	 0.30456113815307617 	 0.4835793972015381 	 0.27904272079467773 	 0.5138859748840332 	 0.30435681343078613 	 0.44124913215637207 	 0.22400522232055664 	 
2025-07-25 18:57:15.391831 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8123412132263184 	 0.3035850524902344 	 0.41507697105407715 	 0.27826976776123047 	 0.5116443634033203 	 0.30312347412109375 	 0.4401431083679199 	 0.2290186882019043 	 
2025-07-25 18:57:18.449783 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.5140764713287354 	 0.30435729026794434 	 0.47805070877075195 	 0.28115034103393555 	 0.8221631050109863 	 0.30403685569763184 	 0.42002439498901367 	 0.230377197265625 	 
2025-07-25 18:57:21.471960 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8273332118988037 	 0.30443382263183594 	 0.4227163791656494 	 0.27927112579345703 	 0.5115911960601807 	 0.30351853370666504 	 0.4405374526977539 	 0.23113346099853516 	 
2025-07-25 18:57:24.498312 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8147802352905273 	 0.3045003414154053 	 0.4163053035736084 	 0.27903056144714355 	 0.5135529041290283 	 0.30583834648132324 	 0.44258618354797363 	 0.2043166160583496 	 
2025-07-25 18:57:27.483318 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.5140466690063477 	 0.3043184280395508 	 0.47795772552490234 	 0.2809445858001709 	 0.8221564292907715 	 0.30406832695007324 	 0.41997694969177246 	 0.22588062286376953 	 
2025-07-25 18:57:30.518483 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8237283229827881 	 0.3076646327972412 	 0.4208662509918213 	 0.2777881622314453 	 0.5137171745300293 	 0.3062872886657715 	 0.4406735897064209 	 0.22655892372131348 	 
2025-07-25 18:57:33.554705 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8075668811798096 	 0.324110746383667 	 0.4126453399658203 	 0.2869608402252197 	 0.5115950107574463 	 0.3032948970794678 	 0.4407310485839844 	 0.2319633960723877 	 
2025-07-25 18:57:39.427501 test begin: paddle.Tensor.round(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2956888675689697 	 0.30457568168640137 	 0.2865285873413086 	 0.28624439239501953 	 0.13412785530090332 	 0.13428044319152832 	 0.08195829391479492 	 0.04517793655395508 	 
2025-07-25 18:57:41.856370 test begin: paddle.Tensor.round(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.295701265335083 	 0.30101919174194336 	 0.2869105339050293 	 0.2865939140319824 	 0.13410472869873047 	 0.1342453956604004 	 0.08142304420471191 	 0.06688880920410156 	 
2025-07-25 18:57:44.437832 test begin: paddle.Tensor.round(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2958028316497803 	 0.29808712005615234 	 0.27999329566955566 	 0.2800757884979248 	 0.13410234451293945 	 0.134368896484375 	 0.06809139251708984 	 0.06333136558532715 	 
2025-07-25 18:57:47.014932 test begin: paddle.Tensor.round(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2958240509033203 	 0.3088560104370117 	 0.2868950366973877 	 0.2867426872253418 	 0.13416600227355957 	 0.13429880142211914 	 0.08229184150695801 	 0.061628103256225586 	 
2025-07-25 18:57:49.606479 test begin: paddle.Tensor.round(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29578351974487305 	 0.298004150390625 	 0.28696250915527344 	 0.2866384983062744 	 0.13408398628234863 	 0.1344749927520752 	 0.08187031745910645 	 0.06818079948425293 	 
2025-07-25 18:57:52.140390 test begin: paddle.Tensor.rsqrt(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2958800792694092 	 0.30420398712158203 	 0.2870912551879883 	 0.2874414920806885 	 0.4495840072631836 	 1.0405595302581787 	 0.394425630569458 	 0.35437655448913574 	 
2025-07-25 18:57:58.703538 test begin: paddle.Tensor.rsqrt(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29585957527160645 	 0.29810047149658203 	 0.2785353660583496 	 0.2812483310699463 	 0.4496338367462158 	 1.0405607223510742 	 0.3855416774749756 	 0.3544952869415283 	 
2025-07-25 18:58:02.550545 test begin: paddle.Tensor.rsqrt(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29581212997436523 	 0.29816365242004395 	 0.2800743579864502 	 0.2812654972076416 	 0.4497354030609131 	 1.0405387878417969 	 0.3853278160095215 	 0.3545095920562744 	 
2025-07-25 18:58:06.368585 test begin: paddle.Tensor.rsqrt(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29582667350769043 	 0.29801368713378906 	 0.2801201343536377 	 0.2812461853027344 	 0.44962430000305176 	 1.0405850410461426 	 0.38517284393310547 	 0.354494571685791 	 
2025-07-25 18:58:10.208576 test begin: paddle.Tensor.rsqrt(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29585742950439453 	 0.2979907989501953 	 0.28009653091430664 	 0.2812817096710205 	 0.44969701766967773 	 1.0404973030090332 	 0.3852694034576416 	 0.3544783592224121 	 
2025-07-25 18:58:14.041674 test begin: paddle.Tensor.scale(Tensor([100352, 1013],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([100352, 1013],"bfloat16"), 0.006378560586546936, ) 	 101656576 	 1000 	 0.2983095645904541 	 0.5977330207824707 	 0.2812631130218506 	 0.3028080463409424 	 0.5875594615936279 	 0.7499961853027344 	 0.5207648277282715 	 0.3832097053527832 	 combined
2025-07-25 18:58:19.709959 test begin: paddle.Tensor.scale(Tensor([1013, 100352],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([1013, 100352],"bfloat16"), 0.006378560586546936, ) 	 101656576 	 1000 	 0.29828786849975586 	 0.5941061973571777 	 0.2814066410064697 	 0.3027641773223877 	 0.5875341892242432 	 0.7499294281005859 	 0.5164716243743896 	 0.3831441402435303 	 combined
2025-07-25 18:58:25.316581 test begin: paddle.Tensor.scale(Tensor([12404, 8192],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([12404, 8192],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.29816508293151855 	 0.592327356338501 	 0.28101634979248047 	 0.30264973640441895 	 0.5873012542724609 	 0.7496170997619629 	 0.5201835632324219 	 0.38297414779663086 	 combined
2025-07-25 18:58:30.971250 test begin: paddle.Tensor.scale(Tensor([1772, 57344],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([1772, 57344],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.2981138229370117 	 0.5923986434936523 	 0.2811746597290039 	 0.3026714324951172 	 0.5873310565948486 	 0.7496154308319092 	 0.5204648971557617 	 0.3829984664916992 	 combined
2025-07-25 18:58:37.594845 test begin: paddle.Tensor.scale(Tensor([8192, 12404],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([8192, 12404],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.29810452461242676 	 0.5922746658325195 	 0.28849339485168457 	 0.30259060859680176 	 0.5872452259063721 	 0.7496242523193359 	 0.5294394493103027 	 0.3830103874206543 	 combined
2025-07-25 18:58:43.224189 test begin: paddle.Tensor.set_(Tensor([20],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([20],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, ) 	 50803235 	 1000 	 0.09243583679199219 	 0.0022253990173339844 	 3.123283386230469e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:58:44.072861 test begin: paddle.Tensor.set_(Tensor([20],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([20],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, ) 	 50803223 	 1000 	 0.03660416603088379 	 0.002269744873046875 	 2.0742416381835938e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:58:44.872835 test begin: paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([15, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([15, 3],"bool"), list[20,], list[2,], 0, ) 	 50803246 	 1000 	 0.036270856857299805 	 0.0022695064544677734 	 1.621246337890625e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:58:45.689131 test begin: paddle.Tensor.sigmoid(Tensor([1, 1100, 46185],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 1100, 46185],"float32"), ) 	 50803500 	 1000 	 0.29488372802734375 	 0.2984769344329834 	 0.28586745262145996 	 0.2880704402923584 	 0.44963741302490234 	 0.4467470645904541 	 0.394791841506958 	 0.37834620475769043 	 
2025-07-25 18:58:48.837485 test begin: paddle.Tensor.sigmoid(Tensor([1, 12700801, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 12700801, 4],"float32"), ) 	 50803204 	 1000 	 0.2949097156524658 	 0.2985560894012451 	 0.2859921455383301 	 0.28797268867492676 	 0.44965600967407227 	 0.44671058654785156 	 0.39453935623168945 	 0.38058972358703613 	 
2025-07-25 18:58:52.021335 test begin: paddle.Tensor.sigmoid(Tensor([1, 6380, 7963],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 6380, 7963],"float32"), ) 	 50803940 	 1000 	 0.2948272228240967 	 0.29918670654296875 	 0.2859361171722412 	 0.28808093070983887 	 0.4494781494140625 	 0.44675731658935547 	 0.39394330978393555 	 0.37540507316589355 	 
2025-07-25 18:58:55.249249 test begin: paddle.Tensor.sigmoid(Tensor([1, 8550, 5942],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 8550, 5942],"float32"), ) 	 50804100 	 1000 	 0.29489612579345703 	 0.29848337173461914 	 0.28594112396240234 	 0.2880439758300781 	 0.4497084617614746 	 0.44671130180358887 	 0.39483165740966797 	 0.37851428985595703 	 
2025-07-25 18:58:58.396271 test begin: paddle.Tensor.sigmoid(Tensor([11547, 1100, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([11547, 1100, 4],"float32"), ) 	 50806800 	 1000 	 0.29483938217163086 	 0.5345444679260254 	 0.28562188148498535 	 0.28786325454711914 	 0.4497196674346924 	 0.4468233585357666 	 0.39407944679260254 	 0.3775949478149414 	 
2025-07-25 18:59:03.860530 test begin: paddle.Tensor.sigmoid(Tensor([1486, 8550, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1486, 8550, 4],"float32"), ) 	 50821200 	 1000 	 0.29492998123168945 	 0.29859185218811035 	 0.28597426414489746 	 0.2882049083709717 	 0.4497659206390381 	 0.4468696117401123 	 0.39490509033203125 	 0.38066768646240234 	 
2025-07-25 18:59:07.067990 test begin: paddle.Tensor.sigmoid(Tensor([1991, 6380, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1991, 6380, 4],"float32"), ) 	 50810320 	 1000 	 0.2948880195617676 	 0.29857516288757324 	 0.2857518196105957 	 0.2880442142486572 	 0.4495246410369873 	 0.44682812690734863 	 0.39359617233276367 	 0.3804337978363037 	 
2025-07-25 18:59:10.220076 test begin: paddle.Tensor.sign(Tensor([1016065, 5, 5],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1016065, 5, 5],"float64"), ) 	 25401625 	 1000 	 0.30871129035949707 	 0.3017411231994629 	 0.29677438735961914 	 0.28737711906433105 	 0.2978041172027588 	 0.13472938537597656 	 0.245269775390625 	 0.06849241256713867 	 
2025-07-25 18:59:12.365302 test begin: paddle.Tensor.sign(Tensor([1124, 45199],"float32"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1124, 45199],"float32"), ) 	 50803676 	 1000 	 0.3447880744934082 	 0.2979583740234375 	 0.33668994903564453 	 0.2876708507537842 	 0.29575419425964355 	 0.13429617881774902 	 0.24284839630126953 	 0.06381344795227051 	 
2025-07-25 18:59:15.136406 test begin: paddle.Tensor.sign(Tensor([12700801, 2],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.3087010383605957 	 0.29842162132263184 	 0.30039405822753906 	 0.28795528411865234 	 0.2977893352508545 	 0.13481998443603516 	 0.24441194534301758 	 0.05145096778869629 	 
2025-07-25 18:59:17.255824 test begin: paddle.Tensor.sign(Tensor([1587601, 32],"float32"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 0.34526920318603516 	 0.2982485294342041 	 0.3371453285217285 	 0.28765869140625 	 0.2958800792694092 	 0.13443684577941895 	 0.24323606491088867 	 0.042859554290771484 	 
2025-07-25 18:59:19.994038 test begin: paddle.Tensor.sign(Tensor([50000, 102, 5],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 102, 5],"float64"), ) 	 25500000 	 1000 	 0.30960607528686523 	 0.2996680736541748 	 0.3013443946838379 	 0.28905415534973145 	 0.29903364181518555 	 0.13530492782592773 	 0.24660205841064453 	 0.0465238094329834 	 
2025-07-25 18:59:22.116609 test begin: paddle.Tensor.sign(Tensor([50000, 5, 102],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 5, 102],"float64"), ) 	 25500000 	 1000 	 0.30964159965515137 	 0.2996644973754883 	 0.30135512351989746 	 0.2889831066131592 	 0.2989964485168457 	 0.13506102561950684 	 0.2463216781616211 	 0.03616833686828613 	 
2025-07-25 18:59:24.234319 test begin: paddle.Tensor.sign(Tensor([50000, 509],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 509],"float64"), ) 	 25450000 	 1000 	 0.30933380126953125 	 0.3010115623474121 	 0.30123353004455566 	 0.28846287727355957 	 0.29843950271606445 	 0.1348872184753418 	 0.24602174758911133 	 0.03742170333862305 	 
2025-07-25 18:59:26.413121 test begin: paddle.Tensor.signbit(Tensor([12, 10584, 2],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 10584, 2],"float64"), ) 	 254016 	 1000 	 10.109373092651367 	 0.01638627052307129 	 6.937980651855469e-05 	 8.153915405273438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:59:37.199981 test begin: paddle.Tensor.signbit(Tensor([12, 20, 1058],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 1058],"float64"), ) 	 253920 	 1000 	 10.228199005126953 	 0.009966135025024414 	 5.316734313964844e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:59:47.491362 test begin: paddle.Tensor.signbit(Tensor([12, 20, 2116],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 2116],"float32"), ) 	 507840 	 1000 	 20.12245225906372 	 0.009795904159545898 	 5.340576171875e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:00:07.690600 test begin: paddle.Tensor.signbit(Tensor([12, 20, 4233],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 4233],"int16"), ) 	 1015920 	 1000 	 39.90091872215271 	 0.010511159896850586 	 5.817413330078125e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:00:47.692975 test begin: paddle.Tensor.signbit(Tensor([12, 21168, 2],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 21168, 2],"float32"), ) 	 508032 	 1000 	 20.19819164276123 	 0.016839981079101562 	 5.91278076171875e-05 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:01:08.872263 test begin: paddle.Tensor.signbit(Tensor([12, 42336, 2],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 42336, 2],"int16"), ) 	 1016064 	 1000 	 40.09716773033142 	 0.010514497756958008 	 5.4836273193359375e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:01:49.070820 test begin: paddle.Tensor.signbit(Tensor([12700, 20, 2],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12700, 20, 2],"float32"), ) 	 508000 	 1000 	 20.724255800247192 	 0.016153573989868164 	 5.7220458984375e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:02:09.884774 test begin: paddle.Tensor.signbit(Tensor([25401, 20, 2],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([25401, 20, 2],"int16"), ) 	 1016040 	 1000 	 40.9081974029541 	 0.018711090087890625 	 5.364418029785156e-05 	 6.556510925292969e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:02:50.934315 test begin: paddle.Tensor.signbit(Tensor([6350, 20, 2],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([6350, 20, 2],"float64"), ) 	 254000 	 1000 	 10.424936771392822 	 0.010140180587768555 	 3.814697265625e-05 	 3.266334533691406e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:03:01.417825 test begin: paddle.Tensor.sin(Tensor([131072, 388],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([131072, 388],"float32"), ) 	 50855936 	 1000 	 0.2957634925842285 	 0.30118608474731445 	 0.28632283210754395 	 0.28791165351867676 	 0.45052313804626465 	 0.7445187568664551 	 0.3946821689605713 	 0.3803834915161133 	 
2025-07-25 19:03:04.949239 test begin: paddle.Tensor.sin(Tensor([3175201, 16],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([3175201, 16],"float32"), ) 	 50803216 	 1000 	 0.29556727409362793 	 0.298297643661499 	 0.28627705574035645 	 0.28761792182922363 	 0.4501187801361084 	 0.7437353134155273 	 0.3948826789855957 	 0.3800086975097656 	 
2025-07-25 19:03:08.427849 test begin: paddle.Tensor.sin(Tensor([32768, 1551],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.2954831123352051 	 0.2984039783477783 	 0.286268949508667 	 0.2877683639526367 	 0.45024728775024414 	 0.7439641952514648 	 0.3921627998352051 	 0.3800806999206543 	 
2025-07-25 19:03:11.907395 test begin: paddle.Tensor.sin(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29543304443359375 	 0.29825353622436523 	 0.28616905212402344 	 0.2875669002532959 	 0.45003771781921387 	 0.7436599731445312 	 0.3955247402191162 	 0.3799247741699219 	 
2025-07-25 19:03:15.372311 test begin: paddle.Tensor.slice(Tensor([12700801, 4],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([12700801, 4],"float32"), list[1,], list[0,], list[1,], ) 	 50803204 	 1000 	 0.0076749324798583984 	 0.01364445686340332 	 1.3589859008789062e-05 	 2.574920654296875e-05 	 0.4915907382965088 	 0.4794783592224121 	 0.2511756420135498 	 0.24494123458862305 	 combined
2025-07-25 19:03:17.403842 test begin: paddle.Tensor.slice(Tensor([4, 12700801],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([4, 12700801],"float32"), list[1,], list[0,], list[1,], ) 	 50803204 	 1000 	 0.007138967514038086 	 0.013327598571777344 	 8.106231689453125e-06 	 2.1696090698242188e-05 	 0.1490001678466797 	 0.1379251480102539 	 0.07622361183166504 	 0.06181931495666504 	 combined
2025-07-25 19:03:18.536911 test begin: paddle.Tensor.slice_scatter(Tensor([4233601, 6],"float64"), Tensor([4233601, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([4233601, 6],"float64"), Tensor([4233601, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 38102409 	 1000 	 0.3763277530670166 	 0.6918182373046875 	 0.36152124404907227 	 0.23436331748962402 	 1.0703465938568115 	 0.7657339572906494 	 0.18224811553955078 	 0.19559836387634277 	 
2025-07-25 19:03:25.459951 test begin: paddle.Tensor.slice_scatter(Tensor([8, 3175201],"float64"), Tensor([8, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([8, 3175201],"float64"), Tensor([8, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 25401632 	 1000 	 0.014589548110961914 	 0.316417932510376 	 1.049041748046875e-05 	 0.10750555992126465 	 0.32517194747924805 	 0.31836557388305664 	 0.05524396896362305 	 0.08114457130432129 	 
2025-07-25 19:03:27.494241 test begin: paddle.Tensor.slice_scatter(Tensor([8467201, 6],"float64"), Tensor([8467201, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([8467201, 6],"float64"), Tensor([8467201, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 76204809 	 1000 	 0.7474124431610107 	 1.3653929233551025 	 0.7323722839355469 	 0.46416473388671875 	 2.1001226902008057 	 1.5059869289398193 	 0.35750675201416016 	 0.3848438262939453 	 
2025-07-25 19:03:37.632720 test begin: paddle.Tensor.sqrt(Tensor([276, 80, 48, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([276, 80, 48, 48],"float32"), ) 	 50872320 	 1000 	 0.2949860095977783 	 0.31514930725097656 	 0.27889347076416016 	 0.27875280380249023 	 0.45107531547546387 	 0.7483913898468018 	 0.3868567943572998 	 0.3823215961456299 	 
2025-07-25 19:03:41.137251 test begin: paddle.Tensor.sqrt(Tensor([329, 80, 44, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([329, 80, 44, 44],"float32"), ) 	 50955520 	 1000 	 0.295424222946167 	 0.29994630813598633 	 0.2796351909637451 	 0.282787561416626 	 0.451582670211792 	 0.7496364116668701 	 0.38804149627685547 	 0.3830223083496094 	 
2025-07-25 19:03:44.630357 test begin: paddle.Tensor.sqrt(Tensor([397, 80, 40, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([397, 80, 40, 40],"float32"), ) 	 50816000 	 1000 	 0.29475998878479004 	 0.29918527603149414 	 0.2788228988647461 	 0.28162217140197754 	 0.45052123069763184 	 0.7475523948669434 	 0.38678789138793945 	 0.38194894790649414 	 
2025-07-25 19:03:48.138630 test begin: paddle.Tensor.sqrt(Tensor([64, 345, 48, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 345, 48, 48],"float32"), ) 	 50872320 	 1000 	 0.29494452476501465 	 0.2994837760925293 	 0.2790334224700928 	 0.2823359966278076 	 0.45108842849731445 	 0.7483932971954346 	 0.38741111755371094 	 0.382371187210083 	 
2025-07-25 19:03:51.660999 test begin: paddle.Tensor.sqrt(Tensor([64, 411, 44, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 411, 44, 44],"float32"), ) 	 50924544 	 1000 	 0.29534101486206055 	 0.30370664596557617 	 0.27849745750427246 	 0.2824981212615967 	 0.45145392417907715 	 0.7493867874145508 	 0.3875420093536377 	 0.38285160064697266 	 
2025-07-25 19:03:55.199699 test begin: paddle.Tensor.sqrt(Tensor([64, 497, 40, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 497, 40, 40],"float32"), ) 	 50892800 	 1000 	 0.2950625419616699 	 0.29955363273620605 	 0.27927255630493164 	 0.28241729736328125 	 0.45125365257263184 	 0.7487359046936035 	 0.3867335319519043 	 0.3824944496154785 	 
2025-07-25 19:03:58.707681 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 207, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 207, 48],"float32"), ) 	 50872320 	 1000 	 0.29496121406555176 	 0.2995302677154541 	 0.27919960021972656 	 0.28653979301452637 	 0.45105433464050293 	 0.748375654220581 	 0.3831291198730469 	 0.3823990821838379 	 
2025-07-25 19:04:02.252376 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 226, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 226, 44],"float32"), ) 	 50913280 	 1000 	 0.2952234745025635 	 0.29973554611206055 	 0.27844953536987305 	 0.2815535068511963 	 0.45139002799987793 	 0.7490222454071045 	 0.387315034866333 	 0.3826775550842285 	 
2025-07-25 19:04:05.794132 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 249, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 249, 40],"float32"), ) 	 50995200 	 1000 	 0.2954378128051758 	 0.30011773109436035 	 0.2796001434326172 	 0.2827115058898926 	 0.4520549774169922 	 0.7501575946807861 	 0.3875443935394287 	 0.3832840919494629 	 
2025-07-25 19:04:09.319370 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 40, 249],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 40, 249],"float32"), ) 	 50995200 	 1000 	 0.29541563987731934 	 0.30583882331848145 	 0.27966809272766113 	 0.2828865051269531 	 0.4520232677459717 	 0.7502524852752686 	 0.3850882053375244 	 0.3833281993865967 	 
2025-07-25 19:04:12.883815 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 44, 226],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 44, 226],"float32"), ) 	 50913280 	 1000 	 0.2951796054840088 	 0.299727201461792 	 0.2793300151824951 	 0.2826533317565918 	 0.45147061347961426 	 0.7490832805633545 	 0.37738633155822754 	 0.3827214241027832 	 
2025-07-25 19:04:16.438304 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 48, 207],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 48, 207],"float32"), ) 	 50872320 	 1000 	 0.29500675201416016 	 0.2995145320892334 	 0.27916574478149414 	 0.2823166847229004 	 0.4509921073913574 	 0.7484142780303955 	 0.3856675624847412 	 0.38234734535217285 	 
2025-07-25 19:04:19.978438 test begin: paddle.Tensor.square(Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29593658447265625 	 0.29798364639282227 	 0.28025293350219727 	 0.28644609451293945 	 0.44970202445983887 	 1.055833101272583 	 0.39528656005859375 	 0.2699611186981201 	 
2025-07-25 19:04:23.851104 test begin: paddle.Tensor.square(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29604530334472656 	 0.30854010581970215 	 0.28034257888793945 	 0.2860126495361328 	 0.4496755599975586 	 1.0560338497161865 	 0.38639259338378906 	 0.26999735832214355 	 
2025-07-25 19:04:30.794405 test begin: paddle.Tensor.square(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.295926570892334 	 0.29811954498291016 	 0.2868309020996094 	 0.2839658260345459 	 0.44974780082702637 	 1.0558838844299316 	 0.39532995223999023 	 0.2699589729309082 	 
2025-07-25 19:04:34.617310 test begin: paddle.Tensor.square(Tensor([8, 6350401],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([8, 6350401],"float32"), ) 	 50803208 	 1000 	 0.29588842391967773 	 0.2998836040496826 	 0.2872328758239746 	 0.2799382209777832 	 0.4496736526489258 	 1.0560057163238525 	 0.39298176765441895 	 0.2699596881866455 	 
2025-07-25 19:04:39.759508 test begin: paddle.Tensor.squeeze(Tensor([1, 2, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([1, 2, 3840, 10240],"float32"), 0, ) 	 78643200 	 1000 	 0.004357576370239258 	 0.0048999786376953125 	 9.5367431640625e-06 	 5.5789947509765625e-05 	 0.04724001884460449 	 0.05705094337463379 	 4.458427429199219e-05 	 3.552436828613281e-05 	 
2025-07-25 19:04:42.501234 test begin: paddle.Tensor.squeeze(Tensor([1, 3, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([1, 3, 1654, 10240],"float32"), 0, ) 	 50810880 	 1000 	 0.004454374313354492 	 0.004422664642333984 	 1.4066696166992188e-05 	 1.811981201171875e-05 	 0.04307818412780762 	 0.05887866020202637 	 2.193450927734375e-05 	 6.318092346191406e-05 	 
2025-07-25 19:04:44.291274 test begin: paddle.Tensor.squeeze(Tensor([1, 3, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([1, 3, 3840, 10240],"float32"), 0, ) 	 117964800 	 1000 	 0.004430055618286133 	 0.004469156265258789 	 1.3589859008789062e-05 	 1.9550323486328125e-05 	 0.04271197319030762 	 0.06064152717590332 	 2.6464462280273438e-05 	 5.6743621826171875e-05 	 
2025-07-25 19:04:48.457071 test begin: paddle.Tensor.squeeze(Tensor([1, 3, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([1, 3, 3840, 4411],"float32"), 0, ) 	 50814720 	 1000 	 0.004530429840087891 	 0.004486083984375 	 1.6450881958007812e-05 	 1.811981201171875e-05 	 0.04659724235534668 	 0.05663871765136719 	 5.1975250244140625e-05 	 5.435943603515625e-05 	 
2025-07-25 19:04:50.382842 test begin: paddle.Tensor.squeeze(Tensor([16, 1, 125, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([16, 1, 125, 25500],"float32"), 1, ) 	 51000000 	 1000 	 0.004538774490356445 	 0.008003950119018555 	 7.867813110351562e-06 	 2.0265579223632812e-05 	 0.04737210273742676 	 0.06212949752807617 	 3.62396240234375e-05 	 6.127357482910156e-05 	 
2025-07-25 19:04:52.195268 test begin: paddle.Tensor.squeeze(Tensor([16, 1, 80, 39691],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([16, 1, 80, 39691],"float32"), 1, ) 	 50804480 	 1000 	 0.00455164909362793 	 0.004439353942871094 	 9.298324584960938e-06 	 1.7642974853515625e-05 	 0.04284071922302246 	 0.06253957748413086 	 4.506111145019531e-05 	 6.175041198730469e-05 	 
2025-07-25 19:04:53.990854 test begin: paddle.Tensor.squeeze(Tensor([16, 2, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([16, 2, 80, 25500],"float32"), 1, ) 	 65280000 	 1000 	 0.004348039627075195 	 0.004367351531982422 	 1.4066696166992188e-05 	 5.5789947509765625e-05 	 0.0430302619934082 	 0.05323481559753418 	 2.9087066650390625e-05 	 5.793571472167969e-05 	 
2025-07-25 19:04:56.212591 test begin: paddle.Tensor.squeeze(Tensor([200, 1, 127009, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([200, 1, 127009, 2],"float32"), 1, ) 	 50803600 	 1000 	 0.004487514495849609 	 0.00487828254699707 	 1.5020370483398438e-05 	 6.508827209472656e-05 	 0.042720794677734375 	 0.06194591522216797 	 1.9788742065429688e-05 	 5.316734313964844e-05 	 
2025-07-25 19:04:57.998150 test begin: paddle.Tensor.squeeze(Tensor([200, 1, 37632, 7],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([200, 1, 37632, 7],"float32"), 1, ) 	 52684800 	 1000 	 0.004497528076171875 	 0.005079030990600586 	 6.9141387939453125e-06 	 6.508827209472656e-05 	 0.04349017143249512 	 0.05939078330993652 	 5.0067901611328125e-05 	 5.030632019042969e-05 	 
2025-07-25 19:04:59.860514 test begin: paddle.Tensor.squeeze(Tensor([200, 4, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([200, 4, 37632, 2],"float32"), 1, ) 	 60211200 	 1000 	 0.004385232925415039 	 0.004280567169189453 	 8.106231689453125e-06 	 1.8596649169921875e-05 	 0.042781829833984375 	 0.052936553955078125 	 1.9550323486328125e-05 	 4.220008850097656e-05 	 
2025-07-25 19:05:01.976244 test begin: paddle.Tensor.squeeze(Tensor([25, 1, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([25, 1, 80, 25500],"float32"), 1, ) 	 51000000 	 1000 	 0.0044994354248046875 	 0.004375934600830078 	 7.867813110351562e-06 	 1.811981201171875e-05 	 0.04606032371520996 	 0.059352874755859375 	 3.337860107421875e-05 	 7.033348083496094e-05 	 
2025-07-25 19:05:03.761824 test begin: paddle.Tensor.squeeze(Tensor([676, 1, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([676, 1, 37632, 2],"float32"), 1, ) 	 50878464 	 1000 	 0.0045070648193359375 	 0.0043659210205078125 	 8.106231689453125e-06 	 1.8596649169921875e-05 	 0.059354305267333984 	 0.056668996810913086 	 4.887580871582031e-05 	 3.1948089599609375e-05 	 
2025-07-25 19:05:05.611830 test begin: paddle.Tensor.std(Tensor([1024, 1024, 25],"float64"), )
W0725 19:05:06.101202 147906 dygraph_functions.cc:88394] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 1024, 25],"float64"), ) 	 26214400 	 1000 	 1.3512959480285645 	 0.18459868431091309 	 2.1457672119140625e-05 	 0.0942697525024414 	 1.5290091037750244 	 0.7919683456420898 	 0.19570016860961914 	 0.0901937484741211 	 
2025-07-25 19:05:10.076033 test begin: paddle.Tensor.std(Tensor([1024, 1024, 49],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 1024, 49],"float32"), ) 	 51380224 	 1000 	 1.119703769683838 	 0.1684269905090332 	 3.4332275390625e-05 	 0.0860447883605957 	 1.354161262512207 	 0.7843735218048096 	 0.17330479621887207 	 0.08933353424072266 	 
2025-07-25 19:05:14.382663 test begin: paddle.Tensor.std(Tensor([1024, 3101, 8],"float64"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 3101, 8],"float64"), ) 	 25403392 	 1000 	 1.3222358226776123 	 0.17952513694763184 	 2.1219253540039062e-05 	 0.09173297882080078 	 1.483139991760254 	 0.7694096565246582 	 0.18979573249816895 	 0.08765220642089844 	 
2025-07-25 19:05:18.701479 test begin: paddle.Tensor.std(Tensor([1024, 6202, 8],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 6202, 8],"float32"), ) 	 50806784 	 1000 	 1.1041803359985352 	 0.16671538352966309 	 2.9087066650390625e-05 	 0.08515024185180664 	 1.3383879661560059 	 0.7779009342193604 	 0.1712813377380371 	 0.08860611915588379 	 
2025-07-25 19:05:22.967672 test begin: paddle.Tensor.std(Tensor([1444, 35183],"float32"), axis=1, )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1444, 35183],"float32"), axis=1, ) 	 50804252 	 1000 	 1.132866382598877 	 0.1768970489501953 	 2.288818359375e-05 	 0.16082358360290527 	 1.362626314163208 	 0.7815496921539307 	 0.17440056800842285 	 0.09998297691345215 	 
2025-07-25 19:05:27.266705 test begin: paddle.Tensor.std(Tensor([3101, 1024, 8],"float64"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([3101, 1024, 8],"float64"), ) 	 25403392 	 1000 	 1.313443899154663 	 0.17936253547668457 	 2.1219253540039062e-05 	 0.09163498878479004 	 1.4823112487792969 	 0.7691988945007324 	 0.18968844413757324 	 0.0876162052154541 	 
2025-07-25 19:05:33.508879 test begin: paddle.Tensor.std(Tensor([49613, 1024],"float32"), axis=1, )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([49613, 1024],"float32"), axis=1, ) 	 50803712 	 1000 	 1.2376887798309326 	 0.16785001754760742 	 2.1457672119140625e-05 	 0.15184593200683594 	 1.3474183082580566 	 0.7813491821289062 	 0.19672250747680664 	 0.09996318817138672 	 
2025-07-25 19:05:39.578452 test begin: paddle.Tensor.std(Tensor([6202, 1024, 8],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([6202, 1024, 8],"float32"), ) 	 50806784 	 1000 	 1.5094616413116455 	 0.16667914390563965 	 3.743171691894531e-05 	 0.08516359329223633 	 1.3385663032531738 	 0.7774009704589844 	 0.17124700546264648 	 0.088592529296875 	 
2025-07-25 19:05:44.247796 test begin: paddle.Tensor.subtract(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.subtract 	 paddle.Tensor.subtract(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.44983911514282227 	 0.4468576908111572 	 0.4400486946105957 	 0.43527817726135254 	 0.4693872928619385 	 0.2979109287261963 	 0.41019678115844727 	 0.227308988571167 	 
2025-07-25 19:05:48.421972 test begin: paddle.Tensor.sum(Tensor([106496, 478],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([106496, 478],"float32"), axis=-1, ) 	 50905088 	 1000 	 0.15001559257507324 	 0.1552135944366455 	 0.13797593116760254 	 0.14069318771362305 	 0.1385042667388916 	 0.05658125877380371 	 0.08083844184875488 	 3.6716461181640625e-05 	 
2025-07-25 19:05:49.774144 test begin: paddle.Tensor.sum(Tensor([108544, 469],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([108544, 469],"float32"), axis=-1, ) 	 50907136 	 1000 	 0.15006494522094727 	 0.15504789352416992 	 0.13834667205810547 	 0.14035701751708984 	 0.13840031623840332 	 0.05713796615600586 	 0.07815909385681152 	 6.318092346191406e-05 	 
2025-07-25 19:05:51.175476 test begin: paddle.Tensor.sum(Tensor([111616, 456],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([111616, 456],"float32"), axis=-1, ) 	 50896896 	 1000 	 0.15032100677490234 	 0.15278148651123047 	 0.13835787773132324 	 0.13645076751708984 	 0.1383976936340332 	 0.056334495544433594 	 0.08014869689941406 	 3.218650817871094e-05 	 
2025-07-25 19:05:52.515491 test begin: paddle.Tensor.sum(Tensor([14176, 3584],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([14176, 3584],"float32"), axis=-1, ) 	 50806784 	 1000 	 0.14618539810180664 	 0.15572500228881836 	 0.13432526588439941 	 0.14107990264892578 	 0.13735723495483398 	 0.05639195442199707 	 0.07957887649536133 	 2.956390380859375e-05 	 
2025-07-25 19:05:53.900056 test begin: paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, ) 	 50931328 	 1000 	 0.7758498191833496 	 0.4742579460144043 	 0.2642824649810791 	 0.45198726654052734 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:06.539267 test begin: paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, ) 	 50803456 	 1000 	 0.30375218391418457 	 0.018019676208496094 	 0.10357189178466797 	 4.76837158203125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:08.165896 test begin: paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, ) 	 101606656 	 1000 	 1.4006898403167725 	 0.7370102405548096 	 0.47722792625427246 	 0.7191617488861084 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:17.415138 test begin: paddle.Tensor.take_along_axis(Tensor([50804, 1000],"float32"), indices=Tensor([50804, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([50804, 1000],"float32"), indices=Tensor([50804, 1],"int32"), axis=-1, ) 	 50854804 	 1000 	 0.3085343837738037 	 0.017175912857055664 	 0.10518598556518555 	 3.5762786865234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:19.070951 test begin: paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, ) 	 50883280 	 1000 	 0.7633261680603027 	 0.475445032119751 	 0.25997424125671387 	 0.45232129096984863 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:32.079319 test begin: paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, ) 	 50803360 	 1000 	 0.3036634922027588 	 0.017245054244995117 	 0.10350894927978516 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:33.781036 test begin: paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, ) 	 101606560 	 1000 	 2.151914596557617 	 0.7524003982543945 	 0.47771668434143066 	 0.726142406463623 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:45.987284 test begin: paddle.Tensor.tanh(Tensor([1, 16934401, 3],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.29564380645751953 	 0.29822874069213867 	 0.2797205448150635 	 0.281139612197876 	 0.4496653079986572 	 0.44662928581237793 	 0.3818652629852295 	 0.3725547790527344 	 
2025-07-25 19:06:49.187846 test begin: paddle.Tensor.tanh(Tensor([1, 2, 12700801],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.29930853843688965 	 0.30043578147888184 	 0.29054737091064453 	 0.28987932205200195 	 0.44771528244018555 	 0.44466257095336914 	 0.39295196533203125 	 0.37298059463500977 	 
2025-07-25 19:06:51.779131 test begin: paddle.Tensor.tanh(Tensor([1, 2, 25401601],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.2955591678619385 	 0.304257869720459 	 0.28682827949523926 	 0.28765058517456055 	 0.4496943950653076 	 0.446688175201416 	 0.39446163177490234 	 0.37920689582824707 	 
2025-07-25 19:06:54.961850 test begin: paddle.Tensor.tanh(Tensor([1, 8467201, 3],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.29926037788391113 	 0.30041980743408203 	 0.2906341552734375 	 0.2898378372192383 	 0.4479854106903076 	 0.44472837448120117 	 0.39364123344421387 	 0.3766756057739258 	 
2025-07-25 19:06:57.520750 test begin: paddle.Tensor.tanh(Tensor([2, 12700801],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.29929208755493164 	 0.3005337715148926 	 0.2906067371368408 	 0.28878259658813477 	 0.44775986671447754 	 0.44466376304626465 	 0.3931910991668701 	 0.3781261444091797 	 
2025-07-25 19:07:00.144584 test begin: paddle.Tensor.tanh(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.2992851734161377 	 0.3012075424194336 	 0.29058384895324707 	 0.28998756408691406 	 0.4479410648345947 	 0.44471049308776855 	 0.38425779342651367 	 0.3770260810852051 	 
2025-07-25 19:07:02.711236 test begin: paddle.Tensor.tanh(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.2992701530456543 	 0.30046916007995605 	 0.2905697822570801 	 0.29001617431640625 	 0.44763708114624023 	 0.44464659690856934 	 0.39285707473754883 	 0.37639379501342773 	 
2025-07-25 19:07:05.308355 test begin: paddle.Tensor.tanh(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2956414222717285 	 0.2983238697052002 	 0.28676772117614746 	 0.28437304496765137 	 0.449737548828125 	 0.44660043716430664 	 0.3927597999572754 	 0.3787391185760498 	 
2025-07-25 19:07:08.502169 test begin: paddle.Tensor.tile(Tensor([198451, 1, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([198451, 1, 256],"float32"), tuple(1,1,1,), ) 	 50803456 	 1000 	 0.2962222099304199 	 0.31334686279296875 	 0.2845458984375 	 0.16002225875854492 	 0.30705761909484863 	 0.06261181831359863 	 0.1568753719329834 	 7.891654968261719e-05 	 
2025-07-25 19:07:11.214342 test begin: paddle.Tensor.tile(Tensor([36858, 1, 1379],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([36858, 1, 1379],"float32"), tuple(1,1,1,), ) 	 50827182 	 1000 	 0.29632067680358887 	 0.31343746185302734 	 0.2850942611694336 	 0.16005301475524902 	 0.31531763076782227 	 0.05268979072570801 	 0.16107439994812012 	 3.647804260253906e-05 	 
2025-07-25 19:07:13.912878 test begin: paddle.Tensor.tile(Tensor([36858, 6, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([36858, 6, 256],"float32"), tuple(1,1,1,), ) 	 56613888 	 1000 	 0.3294713497161865 	 0.34784746170043945 	 0.318190336227417 	 0.31798648834228516 	 0.3390064239501953 	 0.05719947814941406 	 0.27689075469970703 	 4.8160552978515625e-05 	 
2025-07-25 19:07:16.852980 test begin: paddle.Tensor.tile(Tensor([38402, 1, 1323],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([38402, 1, 1323],"float32"), tuple(1,1,1,), ) 	 50805846 	 1000 	 0.2964761257171631 	 0.31308984756469727 	 0.2851235866546631 	 0.1598966121673584 	 0.3140246868133545 	 0.055237770080566406 	 0.160400390625 	 6.151199340820312e-05 	 
2025-07-25 19:07:19.550751 test begin: paddle.Tensor.tile(Tensor([38402, 6, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([38402, 6, 256],"float32"), tuple(1,1,1,), ) 	 58985472 	 1000 	 0.3430020809173584 	 0.35939502716064453 	 0.33148789405822754 	 0.3392980098724365 	 0.3530733585357666 	 0.053928375244140625 	 0.2948894500732422 	 4.649162292480469e-05 	 
2025-07-25 19:07:22.676559 test begin: paddle.Tensor.tolist(Tensor([11, 16, 32, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 16, 32, 43],"int64"), ) 	 242176 	 1000 	 13.855605125427246 	 17.316410779953003 	 9.298324584960938e-05 	 0.00013947486877441406 	 None 	 None 	 None 	 None 	 
2025-07-25 19:07:53.885665 test begin: paddle.Tensor.tolist(Tensor([11, 25, 21, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 25, 21, 43],"int64"), ) 	 248325 	 1000 	 14.045485973358154 	 18.117758750915527 	 0.00010085105895996094 	 0.00013184547424316406 	 None 	 None 	 None 	 None 	 
2025-07-25 19:08:26.084018 test begin: paddle.Tensor.tolist(Tensor([11, 25, 32, 28],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 25, 32, 28],"int64"), ) 	 246400 	 1000 	 14.635205030441284 	 21.348276376724243 	 9.250640869140625e-05 	 0.00013780593872070312 	 None 	 None 	 None 	 None 	 
2025-07-25 19:09:02.100656 test begin: paddle.Tensor.tolist(Tensor([7, 25, 32, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([7, 25, 32, 43],"int64"), ) 	 240800 	 1000 	 13.269707679748535 	 17.15876317024231 	 0.00010037422180175781 	 0.00013566017150878906 	 None 	 None 	 None 	 None 	 
2025-07-25 19:09:32.561170 test begin: paddle.Tensor.topk(Tensor([1, 50803201],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1, 50803201],"float32"), 5, 1, True, True, ) 	 50803201 	 1000 	 178.35220170021057 	 5.994051933288574 	 178.34202098846436 	 0.3415093421936035 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:13:07.900786 test begin: paddle.Tensor.topk(Tensor([1024, 1034, 48],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1024, 1034, 48],"float32"), 2, axis=-1, ) 	 50823168 	 1000 	 2.6633973121643066 	 11.155412673950195 	 2.653139352798462 	 5.698409795761108 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:13:27.306325 test begin: paddle.Tensor.topk(Tensor([1024, 8, 6202],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1024, 8, 6202],"float32"), 2, axis=-1, ) 	 50806784 	 1000 	 0.38179612159729004 	 1.5396103858947754 	 0.3715195655822754 	 0.0875709056854248 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:13:34.541223 test begin: paddle.Tensor.topk(Tensor([128, 396901],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([128, 396901],"float32"), 5, 1, True, True, ) 	 50803328 	 1000 	 1.48435640335083 	 1.4841985702514648 	 1.4743072986602783 	 0.08439302444458008 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:13:42.754170 test begin: paddle.Tensor.topk(Tensor([132301, 8, 48],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([132301, 8, 48],"float32"), 2, axis=-1, ) 	 50803584 	 1000 	 2.663254737854004 	 11.156490802764893 	 2.6530544757843018 	 5.700812339782715 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:14:02.260967 test begin: paddle.Tensor.topk(Tensor([50804, 1000],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([50804, 1000],"float32"), 5, 1, True, True, ) 	 50804000 	 1000 	 0.652259111404419 	 2.4205610752105713 	 0.6423494815826416 	 0.13747715950012207 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:14:10.546898 test begin: paddle.Tensor.transpose(Tensor([106496, 955],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([106496, 955],"bfloat16"), list[1,0,], ) 	 101703680 	 1000 	 0.0034132003784179688 	 0.004724979400634766 	 8.821487426757812e-06 	 1.9073486328125e-05 	 0.04474616050720215 	 0.45405125617980957 	 4.8160552978515625e-05 	 0.37185096740722656 	 
2025-07-25 19:14:14.526490 test begin: paddle.Tensor.transpose(Tensor([108544, 937],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([108544, 937],"bfloat16"), list[1,0,], ) 	 101705728 	 1000 	 0.0034127235412597656 	 0.004635334014892578 	 7.3909759521484375e-06 	 1.9311904907226562e-05 	 0.04460501670837402 	 0.4541664123535156 	 2.5987625122070312e-05 	 0.3720579147338867 	 
2025-07-25 19:14:18.550033 test begin: paddle.Tensor.transpose(Tensor([111616, 911],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([111616, 911],"bfloat16"), list[1,0,], ) 	 101682176 	 1000 	 0.005380153656005859 	 0.004637479782104492 	 3.266334533691406e-05 	 1.9073486328125e-05 	 0.045389652252197266 	 0.4540879726409912 	 3.1948089599609375e-05 	 0.3718404769897461 	 
2025-07-25 19:14:22.392289 test begin: paddle.Tensor.transpose(Tensor([14176, 7168],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([14176, 7168],"bfloat16"), list[1,0,], ) 	 101613568 	 1000 	 0.003484010696411133 	 0.009481191635131836 	 1.1920928955078125e-05 	 5.2928924560546875e-05 	 0.05575108528137207 	 0.45377373695373535 	 4.935264587402344e-05 	 0.3612394332885742 	 
2025-07-25 19:14:27.872721 test begin: paddle.Tensor.tril(Tensor([1, 2, 25401601],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([1, 2, 25401601],"float32"), -1, ) 	 50803202 	 1000 	 0.30020594596862793 	 0.2731475830078125 	 0.2919731140136719 	 0.25565028190612793 	 0.2995758056640625 	 0.2667672634124756 	 0.2417614459991455 	 0.20205354690551758 	 
2025-07-25 19:14:30.716502 test begin: paddle.Tensor.tril(Tensor([1, 25401601, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([1, 25401601, 2],"float32"), -1, ) 	 50803202 	 1000 	 0.4200000762939453 	 0.321505069732666 	 0.4119703769683838 	 0.31029534339904785 	 0.41938066482543945 	 0.32175588607788086 	 0.36789965629577637 	 0.25647568702697754 	 
2025-07-25 19:14:33.923190 test begin: paddle.Tensor.tril(Tensor([12700801, 2, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([12700801, 2, 2],"float32"), -1, ) 	 50803204 	 1000 	 0.4207491874694824 	 0.340054988861084 	 0.4125947952270508 	 0.31276631355285645 	 0.4201061725616455 	 0.3242757320404053 	 0.3689601421356201 	 0.2592594623565674 	 
2025-07-25 19:14:38.818994 test begin: paddle.Tensor.tril(Tensor([2, 12700801, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 12700801, 2],"float32"), -1, ) 	 50803204 	 1000 	 0.4199526309967041 	 0.32362961769104004 	 0.4119858741760254 	 0.30794358253479004 	 0.4193859100341797 	 0.32177233695983887 	 0.36807966232299805 	 0.25687575340270996 	 
2025-07-25 19:14:41.970689 test begin: paddle.Tensor.tril(Tensor([2, 2, 12700801],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 2, 12700801],"float32"), -1, ) 	 50803204 	 1000 	 0.3002283573150635 	 0.2669565677642822 	 0.29203033447265625 	 0.2556722164154053 	 0.29962992668151855 	 0.26683855056762695 	 0.22989702224731445 	 0.2018263339996338 	 
2025-07-25 19:14:44.818678 test begin: paddle.Tensor.tril(Tensor([2, 25401601],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 25401601],"float32"), -1, ) 	 50803202 	 1000 	 0.3001995086669922 	 0.18296384811401367 	 0.29216861724853516 	 0.17194104194641113 	 0.29954004287719727 	 0.18278241157531738 	 0.24791812896728516 	 0.11802983283996582 	 
2025-07-25 19:14:47.499192 test begin: paddle.Tensor.tril(Tensor([25401601, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([25401601, 2],"float32"), -1, ) 	 50803202 	 1000 	 0.41997694969177246 	 0.30635833740234375 	 0.4118649959564209 	 0.2953507900238037 	 0.4193592071533203 	 0.30637598037719727 	 0.36795473098754883 	 0.2421274185180664 	 
2025-07-25 19:14:50.687563 test begin: paddle.Tensor.trunc(Tensor([1814401, 28],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([1814401, 28],"float32"), ) 	 50803228 	 1000 	 0.009289741516113281 	 0.297959566116333 	 2.9802322387695312e-05 	 0.28746843338012695 	 0.051444053649902344 	 0.13429975509643555 	 2.002716064453125e-05 	 0.06569862365722656 	 
2025-07-25 19:14:53.127735 test begin: paddle.Tensor.trunc(Tensor([2, 3175201, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([2, 3175201, 8],"float32"), ) 	 50803216 	 1000 	 0.009249448776245117 	 0.2979271411895752 	 3.266334533691406e-05 	 0.2873411178588867 	 0.05190157890319824 	 0.13425254821777344 	 4.029273986816406e-05 	 0.06723237037658691 	 
2025-07-25 19:14:55.495919 test begin: paddle.Tensor.trunc(Tensor([2, 8, 3175201],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([2, 8, 3175201],"float32"), ) 	 50803216 	 1000 	 0.008220434188842773 	 0.2979252338409424 	 1.049041748046875e-05 	 0.28736257553100586 	 0.05105400085449219 	 0.13425540924072266 	 3.5762786865234375e-05 	 0.06791448593139648 	 
2025-07-25 19:14:57.857044 test begin: paddle.Tensor.trunc(Tensor([28, 1814401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([28, 1814401],"float32"), ) 	 50803228 	 1000 	 0.00821995735168457 	 0.2979896068572998 	 2.8133392333984375e-05 	 0.2872028350830078 	 0.0512845516204834 	 0.13428163528442383 	 3.528594970703125e-05 	 0.06283855438232422 	 
2025-07-25 19:15:00.253362 test begin: paddle.Tensor.trunc(Tensor([6350401, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([6350401, 8],"float32"), ) 	 50803208 	 1000 	 0.008143424987792969 	 0.29796433448791504 	 9.5367431640625e-06 	 0.28730225563049316 	 0.05612492561340332 	 0.13423681259155273 	 4.0531158447265625e-05 	 0.06818652153015137 	 
2025-07-25 19:15:02.690331 test begin: paddle.Tensor.trunc(Tensor([793801, 8, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([793801, 8, 8],"float32"), ) 	 50803264 	 1000 	 0.008271932601928711 	 0.2979898452758789 	 8.344650268554688e-06 	 0.28737640380859375 	 0.05240440368652344 	 0.13422393798828125 	 3.528594970703125e-05 	 0.06801605224609375 	 
2025-07-25 19:15:05.088870 test begin: paddle.Tensor.trunc(Tensor([8, 6350401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([8, 6350401],"float32"), ) 	 50803208 	 1000 	 0.008634328842163086 	 0.2979605197906494 	 3.123283386230469e-05 	 0.28735947608947754 	 0.051030874252319336 	 0.13425230979919434 	 2.4318695068359375e-05 	 0.062430381774902344 	 
2025-07-25 19:15:07.500590 test begin: paddle.Tensor.unbind(Tensor([3, 115, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 115, 2304, 64],"float32"), 0, ) 	 50872320 	 1000 	 0.008213520050048828 	 0.006665468215942383 	 9.059906005859375e-06 	 2.1219253540039062e-05 	 0.3466358184814453 	 0.30445146560668945 	 0.2885403633117676 	 0.2030181884765625 	 
2025-07-25 19:15:09.916440 test begin: paddle.Tensor.unbind(Tensor([3, 1351, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 1351, 196, 64],"float32"), 0, ) 	 50840832 	 1000 	 0.008512258529663086 	 0.006730079650878906 	 3.147125244140625e-05 	 1.9550323486328125e-05 	 0.3466053009033203 	 0.3042259216308594 	 0.286297082901001 	 0.21149826049804688 	 
2025-07-25 19:15:12.291504 test begin: paddle.Tensor.unbind(Tensor([3, 60, 2304, 123],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 60, 2304, 123],"float32"), 0, ) 	 51010560 	 1000 	 0.008036375045776367 	 0.006708621978759766 	 8.58306884765625e-06 	 1.9311904907226562e-05 	 0.34669065475463867 	 0.3051912784576416 	 0.2881183624267578 	 0.20875310897827148 	 
2025-07-25 19:15:14.719449 test begin: paddle.Tensor.unbind(Tensor([3, 60, 4411, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 60, 4411, 64],"float32"), 0, ) 	 50814720 	 1000 	 0.008106708526611328 	 0.007911443710327148 	 7.62939453125e-06 	 9.512901306152344e-05 	 0.3460807800292969 	 0.3041832447052002 	 0.2843506336212158 	 0.21133637428283691 	 
2025-07-25 19:15:17.116129 test begin: paddle.Tensor.unbind(Tensor([3, 864, 196, 101],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 864, 196, 101],"float32"), 0, ) 	 51311232 	 1000 	 0.013628959655761719 	 0.011181116104125977 	 1.71661376953125e-05 	 2.0503997802734375e-05 	 0.3500826358795166 	 0.3070557117462158 	 0.2575409412384033 	 0.21321392059326172 	 
2025-07-25 19:15:19.635974 test begin: paddle.Tensor.unbind(Tensor([3, 864, 307, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 864, 307, 64],"float32"), 0, ) 	 50927616 	 1000 	 0.013751983642578125 	 0.013860702514648438 	 1.0251998901367188e-05 	 6.961822509765625e-05 	 0.34700560569763184 	 0.3047165870666504 	 0.2774312496185303 	 0.21027684211730957 	 
2025-07-25 19:15:22.044680 test begin: paddle.Tensor.unbind(Tensor([3, 960, 196, 91],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 960, 196, 91],"float32"), 0, ) 	 51367680 	 1000 	 0.013742923736572266 	 0.011201620101928711 	 1.0728836059570312e-05 	 2.193450927734375e-05 	 0.3495323657989502 	 0.3073103427886963 	 0.27883028984069824 	 0.21094489097595215 	 
2025-07-25 19:15:24.478463 test begin: paddle.Tensor.unbind(Tensor([3, 960, 276, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([3, 960, 276, 64],"float32"), 0, ) 	 50872320 	 1000 	 0.013615131378173828 	 0.011698007583618164 	 1.5974044799804688e-05 	 6.389617919921875e-05 	 0.34670329093933105 	 0.3044588565826416 	 0.2758002281188965 	 0.20264124870300293 	 
2025-07-25 19:15:26.851844 test begin: paddle.Tensor.unbind(Tensor([5, 864, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([5, 864, 196, 64],"float32"), 0, ) 	 54190080 	 1000 	 0.0103302001953125 	 0.009122133255004883 	 1.3113021850585938e-05 	 6.365776062011719e-05 	 0.36899471282958984 	 0.3220643997192383 	 0.307725191116333 	 0.2013711929321289 	 
2025-07-25 19:15:31.410307 test begin: paddle.Tensor.unbind(Tensor([5, 960, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([5, 960, 196, 64],"float32"), 0, ) 	 60211200 	 1000 	 0.015961647033691406 	 0.008445978164672852 	 2.3126602172851562e-05 	 2.002716064453125e-05 	 0.4098529815673828 	 0.35739612579345703 	 0.34619903564453125 	 0.2483656406402588 	 
2025-07-25 19:15:34.546389 test begin: paddle.Tensor.unbind(Tensor([6, 60, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([6, 60, 2304, 64],"float32"), 0, ) 	 53084160 	 1000 	 0.016840696334838867 	 0.014576911926269531 	 1.049041748046875e-05 	 5.316734313964844e-05 	 0.36179685592651367 	 0.3152620792388916 	 0.28931689262390137 	 0.18803763389587402 	 
2025-07-25 19:15:40.131204 test begin: paddle.Tensor.unique(Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.unique 	 paddle.Tensor.unique(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 6.747193813323975 	 3.256037473678589 	 9.655952453613281e-05 	 0.00021958351135253906 	 None 	 None 	 None 	 None 	 
2025-07-25 19:15:50.659392 test begin: paddle.Tensor.unsqueeze(Tensor([172, 544, 544],"float32"), 0, )
Warning: The core code of paddle.Tensor.unsqueeze is too complex.
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([172, 544, 544],"float32"), 0, ) 	 50900992 	 1000 	 0.004416704177856445 	 0.004275083541870117 	 1.4781951904296875e-05 	 3.790855407714844e-05 	 0.04430127143859863 	 0.06957149505615234 	 2.384185791015625e-05 	 4.553794860839844e-05 	 
2025-07-25 19:15:52.443122 test begin: paddle.Tensor.unsqueeze(Tensor([172, 544, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([172, 544, 544],"float32"), 1, ) 	 50900992 	 1000 	 0.0042934417724609375 	 0.0040435791015625 	 1.6927719116210938e-05 	 1.621246337890625e-05 	 0.043511152267456055 	 0.05843329429626465 	 3.2901763916015625e-05 	 5.9604644775390625e-05 	 
2025-07-25 19:15:54.249686 test begin: paddle.Tensor.unsqueeze(Tensor([2, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2, 3840, 10240],"float32"), 0, ) 	 78643200 	 1000 	 0.00419163703918457 	 0.003915548324584961 	 2.384185791015625e-05 	 1.7404556274414062e-05 	 0.04382038116455078 	 0.05945920944213867 	 4.315376281738281e-05 	 6.771087646484375e-05 	 
2025-07-25 19:15:56.946617 test begin: paddle.Tensor.unsqueeze(Tensor([200, 467, 544],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([200, 467, 544],"float32"), 0, ) 	 50809600 	 1000 	 0.004277944564819336 	 0.003935098648071289 	 9.059906005859375e-06 	 1.811981201171875e-05 	 0.0465090274810791 	 0.05989980697631836 	 2.2172927856445312e-05 	 4.8160552978515625e-05 	 
2025-07-25 19:15:58.722154 test begin: paddle.Tensor.unsqueeze(Tensor([200, 467, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([200, 467, 544],"float32"), 1, ) 	 50809600 	 1000 	 0.004246950149536133 	 0.003930568695068359 	 7.3909759521484375e-06 	 1.7642974853515625e-05 	 0.05075383186340332 	 0.05704545974731445 	 5.14984130859375e-05 	 4.172325134277344e-05 	 
2025-07-25 19:16:00.552500 test begin: paddle.Tensor.unsqueeze(Tensor([200, 544, 467],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([200, 544, 467],"float32"), 0, ) 	 50809600 	 1000 	 0.004259586334228516 	 0.004544973373413086 	 6.9141387939453125e-06 	 6.651878356933594e-05 	 0.049884796142578125 	 0.06078529357910156 	 5.269050598144531e-05 	 4.482269287109375e-05 	 
2025-07-25 19:16:02.428019 test begin: paddle.Tensor.unsqueeze(Tensor([200, 544, 467],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([200, 544, 467],"float32"), 1, ) 	 50809600 	 1000 	 0.004364967346191406 	 0.005078554153442383 	 6.67572021484375e-06 	 5.3882598876953125e-05 	 0.046293020248413086 	 0.05768013000488281 	 2.8371810913085938e-05 	 5.745887756347656e-05 	 
2025-07-25 19:16:04.233790 test begin: paddle.Tensor.unsqueeze(Tensor([3, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([3, 1654, 10240],"float32"), 0, ) 	 50810880 	 1000 	 0.004297733306884766 	 0.003961801528930664 	 1.6927719116210938e-05 	 1.7642974853515625e-05 	 0.04408526420593262 	 0.05711627006530762 	 3.0994415283203125e-05 	 3.647804260253906e-05 	 
2025-07-25 19:16:06.055004 test begin: paddle.Tensor.unsqueeze(Tensor([3, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([3, 3840, 4411],"float32"), 0, ) 	 50814720 	 1000 	 0.004222393035888672 	 0.003936767578125 	 7.62939453125e-06 	 1.7404556274414062e-05 	 0.04489278793334961 	 0.0566563606262207 	 2.9325485229492188e-05 	 3.910064697265625e-05 	 
2025-07-25 19:16:07.844170 test begin: paddle.Tensor.var(Tensor([1000, 50804],"float32"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([1000, 50804],"float32"), axis=0, ) 	 50804000 	 1000 	 1.2770662307739258 	 0.17369341850280762 	 2.6702880859375e-05 	 0.15749621391296387 	 1.4322619438171387 	 0.7668287754058838 	 0.2091059684753418 	 0.1958165168762207 	 
2025-07-25 19:16:12.338415 test begin: paddle.Tensor.var(Tensor([100000, 255],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([100000, 255],"float64"), axis=0, ) 	 25500000 	 1000 	 1.759251594543457 	 0.19454383850097656 	 4.935264587402344e-05 	 0.09938263893127441 	 1.7096624374389648 	 0.7634084224700928 	 0.24958014488220215 	 0.1559910774230957 	 
2025-07-25 19:16:17.364322 test begin: paddle.Tensor.var(Tensor([1000000, 26],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([1000000, 26],"float64"), axis=0, ) 	 26000000 	 1000 	 6.170569658279419 	 0.18922090530395508 	 3.886222839355469e-05 	 0.09664273262023926 	 3.9224343299865723 	 0.7853724956512451 	 0.5726001262664795 	 0.16048955917358398 	 
2025-07-25 19:16:29.061821 test begin: paddle.Tensor.var(Tensor([6350401, 4],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([6350401, 4],"float64"), axis=0, ) 	 25401604 	 1000 	 11.529069185256958 	 0.2502307891845703 	 5.054473876953125e-05 	 0.12781047821044922 	 6.573026895523071 	 0.7661337852478027 	 0.9596767425537109 	 0.15656447410583496 	 
2025-07-25 19:16:48.794795 test begin: paddle.Tensor.var(Tensor([64801, 784],"float32"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([64801, 784],"float32"), axis=0, ) 	 50803984 	 1000 	 1.417257308959961 	 0.2599153518676758 	 3.170967102050781e-05 	 0.13292288780212402 	 1.4988126754760742 	 0.8004779815673828 	 0.21879172325134277 	 0.16348743438720703 	 
2025-07-25 19:16:53.614279 test begin: paddle.Tensor.zero_(Tensor([100352, 507],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.14542865753173828 	 0.13438177108764648 	 0.13196969032287598 	 0.12723445892333984 	 None 	 None 	 None 	 None 	 
2025-07-25 19:16:55.631615 test begin: paddle.Tensor.zero_(Tensor([507, 100352],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.14568161964416504 	 0.1343398094177246 	 0.13206911087036133 	 0.12737464904785156 	 None 	 None 	 None 	 None 	 
2025-07-25 19:16:57.616800 test begin: paddle.Tensor.zero_(Tensor([6202, 8192],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.14529871940612793 	 0.13410592079162598 	 0.1308455467224121 	 0.12609076499938965 	 None 	 None 	 None 	 None 	 
2025-07-25 19:16:59.605789 test begin: paddle.Tensor.zero_(Tensor([8192, 6202],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.1454145908355713 	 0.1341254711151123 	 0.13176727294921875 	 0.12369585037231445 	 None 	 None 	 None 	 None 	 
2025-07-25 19:17:01.620964 test begin: paddle.Tensor.zero_(Tensor([886, 57344],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.14539480209350586 	 0.13409876823425293 	 0.12312841415405273 	 0.12695574760437012 	 None 	 None 	 None 	 None 	 
2025-07-25 19:17:03.610611 test begin: paddle.abs(Tensor([13, 64, 256, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([13, 64, 256, 256],"float32"), ) 	 54525952 	 1000 	 0.3170614242553711 	 0.31934189796447754 	 0.3071000576019287 	 0.3065216541290283 	 0.4825727939605713 	 0.7969663143157959 	 0.42815470695495605 	 0.40717148780822754 	 
2025-07-25 19:17:07.324492 test begin: paddle.abs(Tensor([16, 128, 128, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 128, 128, 194],"float32"), ) 	 50855936 	 1000 	 0.29593372344970703 	 0.2982008457183838 	 0.28673839569091797 	 0.28497862815856934 	 0.4502129554748535 	 0.7439007759094238 	 0.39351582527160645 	 0.3800792694091797 	 
2025-07-25 19:17:10.910352 test begin: paddle.abs(Tensor([16, 128, 194, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 128, 194, 128],"float32"), ) 	 50855936 	 1000 	 0.29599547386169434 	 0.2982053756713867 	 0.28674864768981934 	 0.2853665351867676 	 0.4502081871032715 	 0.7439272403717041 	 0.39533329010009766 	 0.38010644912719727 	 
2025-07-25 19:17:14.482356 test begin: paddle.abs(Tensor([16, 194, 128, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 194, 128, 128],"float32"), ) 	 50855936 	 1000 	 0.295931339263916 	 0.2990376949310303 	 0.28609418869018555 	 0.28479647636413574 	 0.4504666328430176 	 0.7439148426055908 	 0.38790345191955566 	 0.380108118057251 	 
2025-07-25 19:17:17.962119 test begin: paddle.abs(Tensor([16, 256, 194, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 256, 194, 64],"float32"), ) 	 50855936 	 1000 	 0.2960238456726074 	 0.29818201065063477 	 0.28685736656188965 	 0.2840306758880615 	 0.45029211044311523 	 0.7439203262329102 	 0.3946864604949951 	 0.38008832931518555 	 
2025-07-25 19:17:21.440368 test begin: paddle.abs(Tensor([16, 256, 64, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 256, 64, 194],"float32"), ) 	 50855936 	 1000 	 0.29598164558410645 	 0.2981603145599365 	 0.2867438793182373 	 0.2853217124938965 	 0.45025134086608887 	 0.7439155578613281 	 0.39447689056396484 	 0.3800771236419678 	 
2025-07-25 19:17:24.915978 test begin: paddle.abs(Tensor([16, 49, 256, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 49, 256, 256],"float32"), ) 	 51380224 	 1000 	 0.29895663261413574 	 0.30121588706970215 	 0.28983211517333984 	 0.2879676818847656 	 0.45484352111816406 	 0.7514240741729736 	 0.4002189636230469 	 0.38390159606933594 	 
2025-07-25 19:17:28.426023 test begin: paddle.abs(Tensor([16, 64, 194, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 64, 194, 256],"float32"), ) 	 50855936 	 1000 	 0.2959582805633545 	 0.30141401290893555 	 0.28683018684387207 	 0.28491687774658203 	 0.4502866268157959 	 0.7438900470733643 	 0.39438295364379883 	 0.38005614280700684 	 
2025-07-25 19:17:31.983709 test begin: paddle.abs(Tensor([16, 64, 256, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 64, 256, 194],"float32"), ) 	 50855936 	 1000 	 0.2959606647491455 	 0.3019394874572754 	 0.2867097854614258 	 0.2852213382720947 	 0.45027709007263184 	 0.7439849376678467 	 0.39510440826416016 	 0.3801252841949463 	 
2025-07-25 19:17:37.638322 test begin: paddle.abs(Tensor([16, 776, 64, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 776, 64, 64],"float32"), ) 	 50855936 	 1000 	 0.29596424102783203 	 0.30242204666137695 	 0.28680920600891113 	 0.28516077995300293 	 0.45023322105407715 	 0.743889570236206 	 0.3952670097351074 	 0.38007497787475586 	 
2025-07-25 19:17:41.308103 test begin: paddle.abs(Tensor([25, 128, 128, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([25, 128, 128, 128],"float32"), ) 	 52428800 	 1000 	 0.3049921989440918 	 0.3257291316986084 	 0.28850555419921875 	 0.2878148555755615 	 0.4641094207763672 	 0.7666685581207275 	 0.39974284172058105 	 0.39173388481140137 	 
2025-07-25 19:17:48.191215 test begin: paddle.abs(Tensor([49, 256, 64, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([49, 256, 64, 64],"float32"), ) 	 51380224 	 1000 	 0.29891276359558105 	 0.30125999450683594 	 0.2897050380706787 	 0.2885258197784424 	 0.4549863338470459 	 0.7514767646789551 	 0.3999443054199219 	 0.38396716117858887 	 
2025-07-25 19:17:51.725483 test begin: paddle.acos(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29553842544555664 	 0.3031613826751709 	 0.2866547107696533 	 0.2870199680328369 	 0.44986438751220703 	 2.081249952316284 	 0.39460158348083496 	 0.3544914722442627 	 
2025-07-25 19:17:56.578259 test begin: paddle.acos(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29584693908691406 	 0.2978203296661377 	 0.28710460662841797 	 0.28678369522094727 	 0.4501228332519531 	 2.081270456314087 	 0.3898298740386963 	 0.3545517921447754 	 
2025-07-25 19:18:01.440746 test begin: paddle.acos(Tensor([10, 5080321],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29582810401916504 	 0.30135464668273926 	 0.2851266860961914 	 0.28212428092956543 	 0.45006322860717773 	 2.081200122833252 	 0.39400148391723633 	 0.354473352432251 	 
2025-07-25 19:18:06.299002 test begin: paddle.acos(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29579854011535645 	 0.2978241443634033 	 0.28693246841430664 	 0.2854158878326416 	 0.45004963874816895 	 2.08125638961792 	 0.39252305030822754 	 0.35451626777648926 	 
2025-07-25 19:18:11.183037 test begin: paddle.acos(Tensor([5080321, 10],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([5080321, 10],"float32"), ) 	 50803210 	 1000 	 0.2958359718322754 	 0.2978942394256592 	 0.2872169017791748 	 0.28356409072875977 	 0.4500620365142822 	 2.0813190937042236 	 0.3924083709716797 	 0.35454630851745605 	 
2025-07-25 19:18:16.105296 test begin: paddle.acos(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.2957954406738281 	 0.2978358268737793 	 0.28478074073791504 	 0.28687572479248047 	 0.4499988555908203 	 2.0812764167785645 	 0.3948683738708496 	 0.3545839786529541 	 
2025-07-25 19:18:20.962642 test begin: paddle.acos(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.2957456111907959 	 0.29792308807373047 	 0.28670740127563477 	 0.2860279083251953 	 0.45000147819519043 	 2.081294298171997 	 0.3727226257324219 	 0.35454344749450684 	 
2025-07-25 19:18:25.750111 test begin: paddle.acos(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.2958228588104248 	 0.29786133766174316 	 0.2868003845214844 	 0.28669118881225586 	 0.4501197338104248 	 2.081357717514038 	 0.3917663097381592 	 0.3545873165130615 	 
2025-07-25 19:18:30.580519 test begin: paddle.acosh(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29527711868286133 	 0.2991023063659668 	 0.28221702575683594 	 0.28807568550109863 	 0.45146656036376953 	 1.3386008739471436 	 0.39649105072021484 	 0.3420686721801758 	 
2025-07-25 19:18:34.724619 test begin: paddle.acosh(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2953472137451172 	 0.3171820640563965 	 0.2864649295806885 	 0.2881968021392822 	 0.45165038108825684 	 1.3386969566345215 	 0.3969612121582031 	 0.3420236110687256 	 
2025-07-25 19:18:41.629536 test begin: paddle.acosh(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2953164577484131 	 0.29924798011779785 	 0.28646087646484375 	 0.2783017158508301 	 0.45166563987731934 	 1.3385663032531738 	 0.3779716491699219 	 0.3420848846435547 	 
2025-07-25 19:18:45.927309 test begin: paddle.add(x=Tensor([2, 256, 320, 352],"float32"), y=Tensor([2, 256, 320, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 320, 352],"float32"), y=Tensor([2, 256, 320, 352],"float32"), ) 	 115343360 	 1000 	 0.5223639011383057 	 0.5208284854888916 	 0.500389814376831 	 0.4946479797363281 	 0.5481107234954834 	 0.06841373443603516 	 0.4777696132659912 	 7.62939453125e-05 	 
2025-07-25 19:18:54.120900 test begin: paddle.add(x=Tensor([2, 256, 336, 336],"float32"), y=Tensor([2, 256, 336, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 336, 336],"float32"), y=Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.5140001773834229 	 0.5101637840270996 	 0.501225471496582 	 0.4953498840332031 	 0.5492017269134521 	 0.06030869483947754 	 0.4885985851287842 	 5.173683166503906e-05 	 
2025-07-25 19:18:58.627165 test begin: paddle.add(x=Tensor([2, 256, 352, 352],"float32"), y=Tensor([2, 256, 352, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 352, 352],"float32"), y=Tensor([2, 256, 352, 352],"float32"), ) 	 126877696 	 1000 	 0.5612409114837646 	 0.5567359924316406 	 0.5509679317474365 	 0.5450029373168945 	 0.6025528907775879 	 0.07083773612976074 	 0.541898250579834 	 7.200241088867188e-05 	 
2025-07-25 19:19:03.723341 test begin: paddle.add(x=Tensor([8, 256, 320, 78],"float32"), y=Tensor([8, 256, 320, 78],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 320, 78],"float32"), y=Tensor([8, 256, 320, 78],"float32"), ) 	 102236160 	 1000 	 0.4524979591369629 	 0.4495382308959961 	 0.44208669662475586 	 0.4371490478515625 	 0.4857175350189209 	 0.06634044647216797 	 0.42519211769104004 	 4.315376281738281e-05 	 
2025-07-25 19:19:07.716658 test begin: paddle.add(x=Tensor([8, 256, 336, 74],"float32"), y=Tensor([8, 256, 336, 74],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 336, 74],"float32"), y=Tensor([8, 256, 336, 74],"float32"), ) 	 101842944 	 1000 	 0.45085763931274414 	 0.4478168487548828 	 0.44068050384521484 	 0.4355347156524658 	 0.4837610721588135 	 0.060080528259277344 	 0.42263007164001465 	 4.458427429199219e-05 	 
2025-07-25 19:19:11.791727 test begin: paddle.add(x=Tensor([8, 256, 352, 71],"float32"), y=Tensor([8, 256, 352, 71],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 352, 71],"float32"), y=Tensor([8, 256, 352, 71],"float32"), ) 	 102367232 	 1000 	 0.4530761241912842 	 0.45022034645080566 	 0.4430878162384033 	 0.4380035400390625 	 0.48616552352905273 	 0.06112360954284668 	 0.4233255386352539 	 6.175041198730469e-05 	 
2025-07-25 19:19:15.831474 test begin: paddle.add(x=Tensor([8, 256, 71, 352],"float32"), y=Tensor([8, 256, 71, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 71, 352],"float32"), y=Tensor([8, 256, 71, 352],"float32"), ) 	 102367232 	 1000 	 0.4543495178222656 	 0.45021581649780273 	 0.44448065757751465 	 0.4381265640258789 	 0.48616695404052734 	 0.0620265007019043 	 0.42499828338623047 	 7.200241088867188e-05 	 
2025-07-25 19:19:19.855777 test begin: paddle.add(x=Tensor([8, 256, 74, 336],"float32"), y=Tensor([8, 256, 74, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 74, 336],"float32"), y=Tensor([8, 256, 74, 336],"float32"), ) 	 101842944 	 1000 	 0.45081663131713867 	 0.4478187561035156 	 0.4408137798309326 	 0.4350771903991699 	 0.483823299407959 	 0.05992937088012695 	 0.42296695709228516 	 4.6253204345703125e-05 	 
2025-07-25 19:19:23.855122 test begin: paddle.add(x=Tensor([8, 52, 352, 352],"float32"), y=Tensor([8, 52, 352, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 52, 352, 352],"float32"), y=Tensor([8, 52, 352, 352],"float32"), ) 	 103088128 	 1000 	 0.45629048347473145 	 0.453289270401001 	 0.4463765621185303 	 0.44105982780456543 	 0.48963165283203125 	 0.06070113182067871 	 0.4290471076965332 	 5.1975250244140625e-05 	 
2025-07-25 19:19:27.887204 test begin: paddle.add(x=Tensor([8, 57, 320, 352],"float32"), y=Tensor([8, 57, 320, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 57, 320, 352],"float32"), y=Tensor([8, 57, 320, 352],"float32"), ) 	 102727680 	 1000 	 0.45473647117614746 	 0.4517083168029785 	 0.4447615146636963 	 0.4398040771484375 	 0.4892282485961914 	 0.0626370906829834 	 0.4275662899017334 	 5.7697296142578125e-05 	 
2025-07-25 19:19:31.958888 test begin: paddle.add(x=Tensor([8, 57, 336, 336],"float32"), y=Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 57, 336, 336],"float32"), y=Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.45577192306518555 	 1.6279411315917969 	 0.4457075595855713 	 0.44028472900390625 	 0.4891657829284668 	 0.060414791107177734 	 0.4284031391143799 	 3.910064697265625e-05 	 
2025-07-25 19:19:40.387883 test begin: paddle.add_n(list[Tensor([194, 128, 64, 64],"float16"),Tensor([194, 128, 64, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([194, 128, 64, 64],"float16"),Tensor([194, 128, 64, 64],"float16"),], ) 	 203423744 	 1000 	 0.5768918991088867 	 1.520052194595337 	 0.5671186447143555 	 0.7751548290252686 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:19:46.437547 test begin: paddle.add_n(list[Tensor([388, 256, 32, 32],"float16"),Tensor([388, 256, 32, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([388, 256, 32, 32],"float16"),Tensor([388, 256, 32, 32],"float16"),], ) 	 203423744 	 1000 	 0.5755176544189453 	 1.5176243782043457 	 0.5656678676605225 	 0.7754526138305664 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:19:52.443298 test begin: paddle.add_n(list[Tensor([64, 128, 194, 64],"float16"),Tensor([64, 128, 194, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 194, 64],"float16"),Tensor([64, 128, 194, 64],"float16"),], ) 	 203423744 	 1000 	 0.5754444599151611 	 1.5310142040252686 	 0.5656816959381104 	 0.775160551071167 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:19:59.771306 test begin: paddle.add_n(list[Tensor([64, 128, 64, 194],"float16"),Tensor([64, 128, 64, 194],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 64, 194],"float16"),Tensor([64, 128, 64, 194],"float16"),], ) 	 203423744 	 1000 	 0.5754129886627197 	 1.517836570739746 	 0.5585458278656006 	 0.7748627662658691 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:05.823515 test begin: paddle.add_n(list[Tensor([64, 128, 64, 97],"float32"),Tensor([64, 128, 64, 97],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 64, 97],"float32"),Tensor([64, 128, 64, 97],"float32"),], ) 	 101711872 	 1000 	 0.4724855422973633 	 1.0607929229736328 	 0.4628026485443115 	 0.5411713123321533 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:09.170273 test begin: paddle.add_n(list[Tensor([64, 128, 97, 64],"float32"),Tensor([64, 128, 97, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 97, 64],"float32"),Tensor([64, 128, 97, 64],"float32"),], ) 	 101711872 	 1000 	 0.472487211227417 	 1.0591585636138916 	 0.45560669898986816 	 0.5412478446960449 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:12.426364 test begin: paddle.add_n(list[Tensor([64, 1551, 32, 32],"float16"),Tensor([64, 1551, 32, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 1551, 32, 32],"float16"),Tensor([64, 1551, 32, 32],"float16"),], ) 	 203292672 	 1000 	 0.5741956233978271 	 1.5160033702850342 	 0.5642604827880859 	 0.7745752334594727 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:18.547350 test begin: paddle.add_n(list[Tensor([64, 194, 64, 64],"float32"),Tensor([64, 194, 64, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 194, 64, 64],"float32"),Tensor([64, 194, 64, 64],"float32"),], ) 	 101711872 	 1000 	 0.4725193977355957 	 1.0591926574707031 	 0.45383381843566895 	 0.5412046909332275 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:21.744577 test begin: paddle.add_n(list[Tensor([64, 256, 194, 32],"float16"),Tensor([64, 256, 194, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 256, 194, 32],"float16"),Tensor([64, 256, 194, 32],"float16"),], ) 	 203423744 	 1000 	 0.5754666328430176 	 1.517310380935669 	 0.5658864974975586 	 0.7751438617706299 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:27.716135 test begin: paddle.add_n(list[Tensor([64, 256, 32, 194],"float16"),Tensor([64, 256, 32, 194],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 256, 32, 194],"float16"),Tensor([64, 256, 32, 194],"float16"),], ) 	 203423744 	 1000 	 0.5754063129425049 	 1.5201361179351807 	 0.5585694313049316 	 0.7746422290802002 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:33.983169 test begin: paddle.add_n(list[Tensor([64, 388, 64, 64],"float16"),Tensor([64, 388, 64, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 388, 64, 64],"float16"),Tensor([64, 388, 64, 64],"float16"),], ) 	 203423744 	 1000 	 0.5754990577697754 	 1.5334904193878174 	 0.5658478736877441 	 0.7762162685394287 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:41.771266 test begin: paddle.add_n(list[Tensor([97, 128, 64, 64],"float32"),Tensor([97, 128, 64, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([97, 128, 64, 64],"float32"),Tensor([97, 128, 64, 64],"float32"),], ) 	 101711872 	 1000 	 0.47255516052246094 	 1.0589873790740967 	 0.46286940574645996 	 0.5411791801452637 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:20:45.080236 test begin: paddle.addmm(Tensor([1016065, 50],"float32"), Tensor([1016065, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([1016065, 50],"float32"), Tensor([1016065, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, ) 	 132092450 	 1000 	 1.0208570957183838 	 0.9874820709228516 	 0.5212810039520264 	 0.33636045455932617 	 2.678569793701172 	 1.873223066329956 	 0.390841007232666 	 0.47792935371398926 	 
2025-07-25 19:20:54.749504 test begin: paddle.addmm(Tensor([30, 1693441],"float32"), Tensor([30, 80],"float32"), Tensor([80, 1693441],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 1693441],"float32"), Tensor([30, 80],"float32"), Tensor([80, 1693441],"float32"), alpha=1.0, beta=2.0, ) 	 186280910 	 1000 	 1.1805505752563477 	 1.1295676231384277 	 0.4021120071411133 	 0.28788185119628906 	 3.2154459953308105 	 2.0948381423950195 	 0.41074109077453613 	 0.4275791645050049 	 
2025-07-25 19:21:07.932098 test begin: paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1016065],"float32"), Tensor([1016065, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1016065],"float32"), Tensor([1016065, 50],"float32"), alpha=1.0, beta=2.0, ) 	 81286700 	 1000 	 0.3139793872833252 	 0.3131852149963379 	 0.1071312427520752 	 0.10679292678833008 	 1.100482702255249 	 0.6198616027832031 	 0.18766498565673828 	 0.2116379737854004 	 
2025-07-25 19:21:14.739277 test begin: paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1693441],"float32"), Tensor([1693441, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1693441],"float32"), Tensor([1693441, 50],"float32"), alpha=1.0, beta=2.0, ) 	 135476780 	 1000 	 0.49986720085144043 	 0.49924731254577637 	 0.17050933837890625 	 0.17020559310913086 	 1.828052282333374 	 1.0510809421539307 	 0.2339489459991455 	 0.2133045196533203 	 
2025-07-25 19:21:20.857628 test begin: paddle.addmm(Tensor([30, 635041],"float32"), Tensor([30, 80],"float32"), Tensor([80, 635041],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 635041],"float32"), Tensor([30, 80],"float32"), Tensor([80, 635041],"float32"), alpha=1.0, beta=2.0, ) 	 69856910 	 1000 	 0.42423224449157715 	 0.41924476623535156 	 0.21674418449401855 	 0.14213156700134277 	 1.2206075191497803 	 0.7928695678710938 	 0.1781919002532959 	 0.20227336883544922 	 
2025-07-25 19:21:25.195040 test begin: paddle.addmm(Tensor([635041, 50],"float32"), Tensor([635041, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([635041, 50],"float32"), Tensor([635041, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, ) 	 82559330 	 1000 	 0.6480209827423096 	 0.6299772262573242 	 0.3311343193054199 	 0.2145540714263916 	 1.6954991817474365 	 1.1824212074279785 	 0.2473316192626953 	 0.30165529251098633 	 
2025-07-25 19:21:31.319621 test begin: paddle.addmm(input=Tensor([5, 5],"float64"), x=Tensor([5, 5080321],"float64"), y=Tensor([5080321, 5],"float64"), )
[Prof] paddle.addmm 	 paddle.addmm(input=Tensor([5, 5],"float64"), x=Tensor([5, 5080321],"float64"), y=Tensor([5080321, 5],"float64"), ) 	 50803235 	 1000 	 0.6193079948425293 	 0.6219625473022461 	 0.21114850044250488 	 0.21205592155456543 	 3.0063092708587646 	 2.538085460662842 	 0.21935677528381348 	 0.2592592239379883 	 
2025-07-25 19:21:43.729173 test begin: paddle.all(Tensor([423361, 6, 10],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([423361, 6, 10],"float64"), None, False, None, ) 	 25401660 	 1000 	 0.20157170295715332 	 0.15046906471252441 	 0.0685579776763916 	 0.07685375213623047 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:44.621098 test begin: paddle.all(Tensor([5, 1016065, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 1016065, 10],"bool"), None, False, None, ) 	 50803250 	 1000 	 0.052298545837402344 	 0.06100153923034668 	 0.026705503463745117 	 0.031155109405517578 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:45.441756 test begin: paddle.all(Tensor([5, 508033, 10],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 508033, 10],"float64"), None, False, None, ) 	 25401650 	 1000 	 0.20153284072875977 	 0.15046930313110352 	 0.06854438781738281 	 0.07684803009033203 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:46.361557 test begin: paddle.all(Tensor([5, 6, 1693441],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 6, 1693441],"bool"), None, False, None, ) 	 50803230 	 1000 	 0.052260398864746094 	 0.06102275848388672 	 0.026686668395996094 	 0.031162500381469727 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:47.184588 test begin: paddle.all(Tensor([5, 6, 846721],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 6, 846721],"float64"), None, False, None, ) 	 25401630 	 1000 	 0.20341062545776367 	 0.1504683494567871 	 0.06920504570007324 	 0.07686853408813477 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:48.096242 test begin: paddle.all(Tensor([50803201],"bool"), )
[Prof] paddle.all 	 paddle.all(Tensor([50803201],"bool"), ) 	 50803201 	 1000 	 0.05228781700134277 	 0.0610201358795166 	 0.02669692039489746 	 0.03116774559020996 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:48.924559 test begin: paddle.all(Tensor([846721, 6, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([846721, 6, 10],"bool"), None, False, None, ) 	 50803260 	 1000 	 0.052306175231933594 	 0.06100177764892578 	 0.02670574188232422 	 0.03115105628967285 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:49.774127 test begin: paddle.allclose(Tensor([1124, 45199],"float32"), Tensor([1124, 45199],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([1124, 45199],"float32"), Tensor([1124, 45199],"float32"), ) 	 101607352 	 1000 	 1.0212759971618652 	 3.4163448810577393 	 1.0095455646514893 	 7.2479248046875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:56.149196 test begin: paddle.allclose(Tensor([13, 32, 122124],"float32"), Tensor([13, 32, 122124],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([13, 32, 122124],"float32"), Tensor([13, 32, 122124],"float32"), rtol=0.0001, atol=0.0001, ) 	 101607168 	 1000 	 1.053076982498169 	 3.4160985946655273 	 1.0412626266479492 	 0.0002307891845703125 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:02.290595 test begin: paddle.allclose(Tensor([13, 61062, 64],"float32"), Tensor([13, 61062, 64],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([13, 61062, 64],"float32"), Tensor([13, 61062, 64],"float32"), rtol=0.0001, atol=0.0001, ) 	 101607168 	 1000 	 1.053248405456543 	 3.4174060821533203 	 1.0412073135375977 	 8.440017700195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:09.365084 test begin: paddle.allclose(Tensor([1587601, 32],"float32"), Tensor([1587601, 32],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([1587601, 32],"float32"), Tensor([1587601, 32],"float32"), ) 	 101606464 	 1000 	 1.2132353782653809 	 3.416616201400757 	 1.2013862133026123 	 0.00011086463928222656 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:15.952990 test begin: paddle.allclose(Tensor([24807, 32, 64],"float32"), Tensor([24807, 32, 64],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([24807, 32, 64],"float32"), Tensor([24807, 32, 64],"float32"), rtol=0.0001, atol=0.0001, ) 	 101609472 	 1000 	 1.0387988090515137 	 3.4129204750061035 	 1.0268373489379883 	 9.703636169433594e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:22.160196 test begin: paddle.allclose(Tensor([30522, 1665],"float32"), Tensor([30522, 1665],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([30522, 1665],"float32"), Tensor([30522, 1665],"float32"), ) 	 101638260 	 1000 	 1.0585975646972656 	 3.4185445308685303 	 1.0471086502075195 	 0.00010704994201660156 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:28.340580 test begin: paddle.allclose(Tensor([6350401, 8],"float32"), Tensor([6350401, 8],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([6350401, 8],"float32"), Tensor([6350401, 8],"float32"), ) 	 101606416 	 1000 	 1.056004524230957 	 3.4109790325164795 	 1.0370221138000488 	 0.00010323524475097656 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:34.550328 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22185444831848145 	 0.17833185195922852 	 0.11334609985351562 	 0.09111189842224121 	 1.1024394035339355 	 1.3139991760253906 	 0.22550249099731445 	 0.22363734245300293 	 
2025-07-25 19:22:41.109554 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.23673009872436523 	 0.20020246505737305 	 0.12095832824707031 	 0.10226678848266602 	 1.115281105041504 	 1.3575210571289062 	 0.22810006141662598 	 0.23118972778320312 	 
2025-07-25 19:22:44.897090 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 0.19815874099731445 	 0.16226720809936523 	 0.18463921546936035 	 0.1453261375427246 	 1.0941963195800781 	 1.289609670639038 	 0.27934980392456055 	 0.26338839530944824 	 
2025-07-25 19:22:48.522191 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22191858291625977 	 0.17838072776794434 	 0.11338329315185547 	 0.09116268157958984 	 1.1023833751678467 	 1.3157272338867188 	 0.22540545463562012 	 0.22365498542785645 	 
2025-07-25 19:22:52.217477 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.5712566375732422 	 0.45574283599853516 	 0.5579590797424316 	 0.43782973289489746 	 1.310889482498169 	 1.4622814655303955 	 0.3348405361175537 	 0.29834985733032227 	 
2025-07-25 19:22:56.865126 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.9354846477508545 	 0.16587018966674805 	 3.0324041843414307 	 0.08474516868591309 	 5.868646144866943 	 1.2948191165924072 	 1.1986351013183594 	 0.22035598754882812 	 
2025-07-25 19:23:11.027224 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.4402632713317871 	 1.1474676132202148 	 0.42806458473205566 	 0.26567554473876953 	 1.1776432991027832 	 1.3139863014221191 	 0.30086565017700195 	 0.2681412696838379 	 
2025-07-25 19:23:18.493523 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.2560455799102783 	 0.21554040908813477 	 0.13084959983825684 	 0.11019349098205566 	 1.131561517715454 	 1.4265398979187012 	 0.23138213157653809 	 0.24257278442382812 	 
2025-07-25 19:23:22.405452 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.935325622558594 	 0.1658766269683838 	 3.032353639602661 	 0.08472752571105957 	 5.8686134815216064 	 1.2949118614196777 	 1.1985735893249512 	 0.22039413452148438 	 
2025-07-25 19:23:39.928059 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.2218616008758545 	 0.1783146858215332 	 0.11333036422729492 	 0.0910792350769043 	 1.103689193725586 	 1.3144786357879639 	 0.22542381286621094 	 0.22379136085510254 	 
2025-07-25 19:23:43.607956 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.23667097091674805 	 0.20170903205871582 	 0.12092328071594238 	 0.10230469703674316 	 1.1153039932250977 	 1.357248306274414 	 0.22807908058166504 	 0.23114776611328125 	 
2025-07-25 19:23:47.383347 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 0.19818377494812012 	 0.16046404838562012 	 0.17808008193969727 	 0.1383075714111328 	 1.0927517414093018 	 1.2909231185913086 	 0.2790870666503906 	 0.2634272575378418 	 
2025-07-25 19:23:51.035256 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22182250022888184 	 0.1782846450805664 	 0.11331462860107422 	 0.0910806655883789 	 1.1023802757263184 	 1.3157799243927002 	 0.22547054290771484 	 0.22519612312316895 	 
2025-07-25 19:23:54.734350 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.5714526176452637 	 0.45276856422424316 	 0.5582699775695801 	 0.43789029121398926 	 1.3106162548065186 	 1.4614410400390625 	 0.3348047733306885 	 0.2996068000793457 	 
2025-07-25 19:23:59.411671 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.935521125793457 	 0.1658482551574707 	 3.0336434841156006 	 0.0847330093383789 	 5.867367506027222 	 1.2961077690124512 	 1.1972568035125732 	 0.22044706344604492 	 
2025-07-25 19:24:13.570038 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.4400827884674072 	 0.28817129135131836 	 0.42820096015930176 	 0.273390531539917 	 1.1778945922851562 	 1.3142178058624268 	 0.30092811584472656 	 0.2681269645690918 	 
2025-07-25 19:24:17.705046 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.25614047050476074 	 0.21560120582580566 	 0.13082194328308105 	 0.11016702651977539 	 1.1316792964935303 	 1.425140380859375 	 0.23103857040405273 	 0.24255013465881348 	 
2025-07-25 19:24:24.920809 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.935548305511475 	 0.16589617729187012 	 3.0336217880249023 	 0.08473420143127441 	 5.867459297180176 	 1.2951939105987549 	 1.1972906589508057 	 0.22047686576843262 	 
2025-07-25 19:24:40.888217 test begin: paddle.any(Tensor([1, 12404, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([1, 12404, 4096],"bool"), ) 	 50806784 	 1000 	 0.053955078125 	 0.06445074081420898 	 0.026926517486572266 	 0.0329129695892334 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:41.748758 test begin: paddle.any(Tensor([1, 300, 169345],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([1, 300, 169345],"bool"), ) 	 50803500 	 1000 	 0.05256342887878418 	 0.06439661979675293 	 0.026837587356567383 	 0.0328831672668457 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:42.595424 test begin: paddle.any(Tensor([1124, 45199],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([1124, 45199],"bool"), ) 	 50803676 	 1000 	 0.05256462097167969 	 0.06445193290710449 	 0.026839017868041992 	 0.03293490409851074 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:43.427535 test begin: paddle.any(Tensor([1587601, 32],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([1587601, 32],"bool"), ) 	 50803232 	 1000 	 0.05243349075317383 	 0.06443619728088379 	 0.02677297592163086 	 0.032919883728027344 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:44.286739 test begin: paddle.any(Tensor([42, 300, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([42, 300, 4096],"bool"), ) 	 51609600 	 1000 	 0.05359911918640137 	 0.06526303291320801 	 0.027378320693969727 	 0.03334164619445801 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:45.193405 test begin: paddle.any(Tensor([512, 99226],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([512, 99226],"bool"), ) 	 50803712 	 1000 	 0.05257129669189453 	 0.06441640853881836 	 0.02685379981994629 	 0.03289222717285156 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:46.051818 test begin: paddle.argmax(Tensor([15877, 100, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([15877, 100, 32],"float32"), axis=1, ) 	 50806400 	 1000 	 0.7615480422973633 	 0.18320202827453613 	 0.7509806156158447 	 0.1688070297241211 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:47.851178 test begin: paddle.argmax(Tensor([29151, 100, 18],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 100, 18],"float32"), axis=1, ) 	 52471800 	 1000 	 0.6401383876800537 	 0.17469477653503418 	 0.6289842128753662 	 0.15730762481689453 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:49.550453 test begin: paddle.argmax(Tensor([29151, 28, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 28, 64],"float32"), axis=1, ) 	 52238592 	 1000 	 1.5050368309020996 	 0.1807558536529541 	 1.4945735931396484 	 0.16200947761535645 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:52.121788 test begin: paddle.argmax(Tensor([29151, 55, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 55, 32],"float32"), axis=1, ) 	 51305760 	 1000 	 0.7550606727600098 	 0.16915321350097656 	 0.7444193363189697 	 0.1550579071044922 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:53.980097 test begin: paddle.argmax(Tensor([39691, 20, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([39691, 20, 64],"float32"), axis=1, ) 	 50804480 	 1000 	 2.0465142726898193 	 0.17626476287841797 	 2.0359911918640137 	 0.16225433349609375 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:57.047759 test begin: paddle.argmax(Tensor([7939, 100, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([7939, 100, 64],"float32"), axis=1, ) 	 50809600 	 1000 	 0.7439839839935303 	 0.18058133125305176 	 0.733525276184082 	 0.16652965545654297 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:58.808604 test begin: paddle.argmax(Tensor([80239, 10, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([80239, 10, 64],"float32"), axis=1, ) 	 51352960 	 1000 	 4.131396532058716 	 0.19652771949768066 	 4.121004104614258 	 0.18260812759399414 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:03.992001 test begin: paddle.argmax(Tensor([80239, 20, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([80239, 20, 32],"float32"), axis=1, ) 	 51352960 	 1000 	 2.067237615585327 	 0.18156194686889648 	 2.0566112995147705 	 0.16340875625610352 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:07.110884 test begin: paddle.argmin(Tensor([104534, 3, 3, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([104534, 3, 3, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 0.4781808853149414 	 0.1607809066772461 	 0.46730804443359375 	 0.08209586143493652 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:08.306876 test begin: paddle.argmin(Tensor([203213, 5, 5, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([203213, 5, 5, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 0.49009037017822266 	 0.16275572776794434 	 0.47939038276672363 	 0.08315443992614746 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:09.496985 test begin: paddle.argmin(Tensor([3, 104534, 3, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 104534, 3, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.808398246765137 	 0.20537686347961426 	 6.7975804805755615 	 0.18813085556030273 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:17.108131 test begin: paddle.argmin(Tensor([3, 3, 104534, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 104534, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.808170795440674 	 0.20352411270141602 	 6.797423839569092 	 0.18645358085632324 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:24.726097 test begin: paddle.argmin(Tensor([3, 3, 3, 104534, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 104534, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.808072090148926 	 0.20340561866760254 	 6.7972047328948975 	 0.18637609481811523 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:32.296047 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 104534, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 3, 104534, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.871318817138672 	 0.2107234001159668 	 6.860409498214722 	 0.18816924095153809 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:40.019857 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 3, 104534],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 3, 3, 104534],"float64"), axis=0, ) 	 25401762 	 1000 	 6.807793378829956 	 0.20341825485229492 	 6.796921014785767 	 0.1878376007080078 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:47.582132 test begin: paddle.argmin(Tensor([4, 4, 4, 4, 99226],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 4, 4, 99226],"float64"), axis=0, ) 	 25401856 	 1000 	 5.107261896133423 	 0.1923048496246338 	 5.095946788787842 	 0.1768801212310791 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:53.446075 test begin: paddle.argmin(Tensor([4, 4, 4, 99226, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 4, 99226, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.108790636062622 	 0.19136953353881836 	 5.097890615463257 	 0.17666053771972656 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:59.287996 test begin: paddle.argmin(Tensor([4, 4, 99226, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 99226, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.10735821723938 	 0.19303226470947266 	 5.096506357192993 	 0.17696833610534668 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:05.137884 test begin: paddle.argmin(Tensor([4, 99226, 4, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 99226, 4, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.107370615005493 	 0.19133782386779785 	 5.0958263874053955 	 0.17708802223205566 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:11.034770 test begin: paddle.argmin(Tensor([5, 203213, 5, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 203213, 5, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 4.08660101890564 	 0.1993403434753418 	 4.075837850570679 	 0.1816110610961914 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:15.872873 test begin: paddle.argmin(Tensor([5, 5, 203213, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 5, 203213, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 4.086758852005005 	 0.19592881202697754 	 4.075838088989258 	 0.18124008178710938 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:20.695610 test begin: paddle.argmin(Tensor([5, 5, 5, 203213],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 5, 5, 203213],"float64"), axis=0, ) 	 25401625 	 1000 	 4.0868239402771 	 0.19609475135803223 	 4.075998544692993 	 0.18136215209960938 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:25.539675 test begin: paddle.argmin(Tensor([99226, 4, 4, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([99226, 4, 4, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 0.43373799324035645 	 0.32213401794433594 	 0.4229245185852051 	 0.16448974609375 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:26.847098 test begin: paddle.argsort(Tensor([25401601],"float64"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([25401601],"float64"), stable=True, ) 	 25401601 	 1000 	 18.265748023986816 	 7.495190143585205 	 9.870529174804688e-05 	 0.33395957946777344 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:26:58.186571 test begin: paddle.argsort(Tensor([50803201],"float32"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([50803201],"float32"), stable=True, ) 	 50803201 	 1000 	 16.26843786239624 	 7.874655246734619 	 0.00010347366333007812 	 0.5369820594787598 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:27:32.708640 test begin: paddle.argsort(Tensor([50803201],"int32"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([50803201],"int32"), stable=True, ) 	 50803201 	 1000 	 24.515060901641846 	 7.221301078796387 	 0.00010991096496582031 	 0.49218249320983887 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:28:14.671965 test begin: paddle.as_complex(Tensor([32, 15, 207, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([32, 15, 207, 8, 32, 2],"float32"), ) 	 50872320 	 1000 	 0.003113985061645508 	 0.004438877105712891 	 1.0728836059570312e-05 	 1.7642974853515625e-05 	 0.04001665115356445 	 0.058133840560913086 	 3.337860107421875e-05 	 4.220008850097656e-05 	 
2025-07-25 19:28:16.127878 test begin: paddle.as_complex(Tensor([32, 15, 8, 207, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([32, 15, 8, 207, 32, 2],"float32"), ) 	 50872320 	 1000 	 0.004548788070678711 	 0.004426479339599609 	 3.170967102050781e-05 	 1.6927719116210938e-05 	 0.04010796546936035 	 0.05871772766113281 	 5.316734313964844e-05 	 6.604194641113281e-05 	 
2025-07-25 19:28:17.604574 test begin: paddle.as_complex(Tensor([32, 15, 8, 8, 827, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([32, 15, 8, 8, 827, 2],"float32"), ) 	 50810880 	 1000 	 0.003084421157836914 	 0.004400968551635742 	 6.9141387939453125e-06 	 1.811981201171875e-05 	 0.042374372482299805 	 0.05814480781555176 	 4.291534423828125e-05 	 3.647804260253906e-05 	 
2025-07-25 19:28:19.089282 test begin: paddle.as_complex(Tensor([32, 388, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([32, 388, 8, 8, 32, 2],"float32"), ) 	 50855936 	 1000 	 0.0030395984649658203 	 0.004434347152709961 	 7.867813110351562e-06 	 1.71661376953125e-05 	 0.04011106491088867 	 0.05885815620422363 	 5.316734313964844e-05 	 5.626678466796875e-05 	 
2025-07-25 19:28:20.548603 test begin: paddle.as_complex(Tensor([827, 15, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([827, 15, 8, 8, 32, 2],"float32"), ) 	 50810880 	 1000 	 0.003040313720703125 	 0.008720159530639648 	 7.152557373046875e-06 	 4.315376281738281e-05 	 0.046898603439331055 	 0.06576657295227051 	 4.410743713378906e-05 	 6.461143493652344e-05 	 
2025-07-25 19:28:22.089414 test begin: paddle.as_strided(Tensor([1587601, 32],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([1587601, 32],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 50803232 	 1000 	 0.01716327667236328 	 0.004583597183227539 	 2.1457672119140625e-05 	 1.7642974853515625e-05 	 0.14902925491333008 	 0.13723993301391602 	 0.07607030868530273 	 0.0477910041809082 	 
2025-07-25 19:28:23.246703 test begin: paddle.as_strided(Tensor([3175201, 32],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([3175201, 32],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 101606432 	 1000 	 0.01707291603088379 	 0.004549980163574219 	 1.9788742065429688e-05 	 1.8358230590820312e-05 	 0.1475679874420166 	 0.13690996170043945 	 0.07532405853271484 	 0.05633282661437988 	 
2025-07-25 19:28:25.469500 test begin: paddle.as_strided(Tensor([3175201, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([3175201, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 101606432 	 1000 	 0.017236709594726562 	 0.0046672821044921875 	 1.2874603271484375e-05 	 1.7881393432617188e-05 	 0.14739489555358887 	 0.13784503936767578 	 0.0751497745513916 	 0.056673288345336914 	 
2025-07-25 19:28:27.697397 test begin: paddle.as_strided(Tensor([32, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([32, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 50803232 	 1000 	 0.016984224319458008 	 0.004793405532836914 	 1.3589859008789062e-05 	 2.2411346435546875e-05 	 0.1486520767211914 	 0.13706350326538086 	 0.07579517364501953 	 0.05647134780883789 	 
2025-07-25 19:28:28.830547 test begin: paddle.as_strided(Tensor([32, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([32, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 101606432 	 1000 	 0.016849517822265625 	 0.00730586051940918 	 1.33514404296875e-05 	 8.678436279296875e-05 	 0.14741086959838867 	 0.13701963424682617 	 0.07529544830322266 	 0.04670238494873047 	 
2025-07-25 19:28:31.041956 test begin: paddle.as_strided(Tensor([32, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([32, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 101606432 	 1000 	 0.017298460006713867 	 0.007512807846069336 	 1.2159347534179688e-05 	 6.628036499023438e-05 	 0.14748907089233398 	 0.13784527778625488 	 0.07519817352294922 	 0.047250986099243164 	 
2025-07-25 19:28:33.295080 test begin: paddle.asin(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29554080963134766 	 0.5282509326934814 	 0.2869877815246582 	 0.27445530891418457 	 0.4500129222869873 	 1.7851910591125488 	 0.3916609287261963 	 0.3658733367919922 	 
2025-07-25 19:28:41.478242 test begin: paddle.asin(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29541516304016113 	 0.2977135181427002 	 0.286639928817749 	 0.2858262062072754 	 0.44992518424987793 	 1.7835984230041504 	 0.37581324577331543 	 0.3645753860473633 	 
2025-07-25 19:28:46.116552 test begin: paddle.asin(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29541754722595215 	 0.31589722633361816 	 0.2866840362548828 	 0.2865488529205322 	 0.449709415435791 	 1.7838199138641357 	 0.39443397521972656 	 0.364579439163208 	 
2025-07-25 19:28:53.117000 test begin: paddle.asinh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.3025944232940674 	 0.3005821704864502 	 0.28691768646240234 	 0.28301334381103516 	 0.45018815994262695 	 1.338411808013916 	 0.3859896659851074 	 0.341963529586792 	 
2025-07-25 19:28:57.286814 test begin: paddle.asinh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.3010697364807129 	 0.3005363941192627 	 0.2920987606048584 	 0.28917908668518066 	 0.44988369941711426 	 1.3384854793548584 	 0.39525890350341797 	 0.3420450687408447 	 
2025-07-25 19:29:01.341939 test begin: paddle.asinh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.3008995056152344 	 0.30057311058044434 	 0.2848656177520752 	 0.28314948081970215 	 0.45006465911865234 	 1.3385810852050781 	 0.3944740295410156 	 0.34211111068725586 	 
2025-07-25 19:29:05.493374 test begin: paddle.atan(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2976396083831787 	 0.2989320755004883 	 0.2818117141723633 	 0.28024768829345703 	 0.449981689453125 	 1.0435166358947754 	 0.3653135299682617 	 0.35548877716064453 	 
2025-07-25 19:29:09.301808 test begin: paddle.atan(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29758167266845703 	 0.3031895160675049 	 0.2887859344482422 	 0.28125 	 0.44976806640625 	 1.0435106754302979 	 0.3943197727203369 	 0.35550904273986816 	 
2025-07-25 19:29:13.112776 test begin: paddle.atan(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2975137233734131 	 0.2976996898651123 	 0.288482666015625 	 0.2868947982788086 	 0.4495699405670166 	 1.0448522567749023 	 0.3948097229003906 	 0.3554980754852295 	 
2025-07-25 19:29:16.927121 test begin: paddle.atan2(Tensor([100],"float64"), Tensor([254017, 100],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([100],"float64"), Tensor([254017, 100],"float64"), ) 	 25401800 	 1000 	 0.8820016384124756 	 0.31456732749938965 	 0.3004181385040283 	 0.2956569194793701 	 1.6821939945220947 	 2.7448766231536865 	 0.34339022636413574 	 0.25490593910217285 	 
2025-07-25 19:29:23.682624 test begin: paddle.atan2(Tensor([111, 222, 1031],"float64"), Tensor([222, 1031],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([111, 222, 1031],"float64"), Tensor([222, 1031],"float64"), ) 	 25634784 	 1000 	 0.882742166519165 	 0.31783223152160645 	 0.30052828788757324 	 0.3056011199951172 	 1.2319107055664062 	 2.9890363216400146 	 0.3142979145050049 	 0.3053097724914551 	 
2025-07-25 19:29:30.208864 test begin: paddle.atan2(Tensor([111, 688, 333],"float64"), Tensor([688, 333],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([111, 688, 333],"float64"), Tensor([688, 333],"float64"), ) 	 25659648 	 1000 	 0.8834536075592041 	 0.31883931159973145 	 0.3006711006164551 	 0.3062131404876709 	 1.2336666584014893 	 2.9972331523895264 	 0.3148365020751953 	 0.3062148094177246 	 
2025-07-25 19:29:38.138450 test begin: paddle.atan2(Tensor([344, 222, 333],"float64"), Tensor([222, 333],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([344, 222, 333],"float64"), Tensor([222, 333],"float64"), ) 	 25504470 	 1000 	 2.864851713180542 	 0.3247809410095215 	 0.299929141998291 	 0.30364990234375 	 1.312459945678711 	 2.98618745803833 	 0.3345658779144287 	 0.3052082061767578 	 
2025-07-25 19:29:46.820774 test begin: paddle.atan2(x=Tensor([19601, 6, 6, 6, 6],"float64"), y=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([19601, 6, 6, 6, 6],"float64"), y=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 50805792 	 1000 	 0.4458322525024414 	 0.4563121795654297 	 0.4282417297363281 	 0.4418962001800537 	 0.732832670211792 	 3.4104793071746826 	 0.6741831302642822 	 0.3872644901275635 	 
2025-07-25 19:29:56.454975 test begin: paddle.atan2(x=Tensor([3, 39201, 6, 6, 6],"float64"), y=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 39201, 6, 6, 6],"float64"), y=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 50804496 	 1000 	 0.44576168060302734 	 0.4789390563964844 	 0.43540287017822266 	 0.44194793701171875 	 0.732816219329834 	 3.4091153144836426 	 0.672929048538208 	 0.38729262351989746 	 
2025-07-25 19:30:05.333246 test begin: paddle.atan2(x=Tensor([3, 6, 39201, 6, 6],"float64"), y=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 39201, 6, 6],"float64"), y=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 50804496 	 1000 	 0.4472322463989258 	 0.46506738662719727 	 0.4369471073150635 	 0.4419710636138916 	 0.7326407432556152 	 3.4103806018829346 	 0.6738450527191162 	 0.38724660873413086 	 
2025-07-25 19:30:12.015073 test begin: paddle.atan2(x=Tensor([3, 6, 6, 39201, 6],"float64"), y=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 6, 39201, 6],"float64"), y=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 50804496 	 1000 	 0.44577717781066895 	 0.4537694454193115 	 0.4353599548339844 	 0.44226789474487305 	 0.732703685760498 	 3.4102582931518555 	 0.673992395401001 	 0.3872530460357666 	 
2025-07-25 19:30:18.763654 test begin: paddle.atan2(x=Tensor([3, 6, 6, 6, 39201],"float64"), y=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 6, 6, 39201],"float64"), y=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 50804496 	 1000 	 0.4458174705505371 	 0.45679736137390137 	 0.43352389335632324 	 0.4420647621154785 	 0.7327089309692383 	 3.4104464054107666 	 0.6737926006317139 	 0.38727450370788574 	 
2025-07-25 19:30:25.434697 test begin: paddle.atanh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2969546318054199 	 0.30136895179748535 	 0.28795456886291504 	 0.28728175163269043 	 0.44988250732421875 	 1.624474048614502 	 0.3949394226074219 	 0.33188462257385254 	 
2025-07-25 19:30:29.860131 test begin: paddle.atanh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2967567443847656 	 0.29833173751831055 	 0.28778696060180664 	 0.28731822967529297 	 0.44965529441833496 	 1.624586582183838 	 0.3950495719909668 	 0.33188366889953613 	 
2025-07-25 19:30:34.265168 test begin: paddle.atanh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2967402935028076 	 0.31933069229125977 	 0.2877795696258545 	 0.28735780715942383 	 0.4496448040008545 	 1.6245112419128418 	 0.3952927589416504 	 0.33304429054260254 	 
2025-07-25 19:30:41.375991 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 1058401],"float64"), ) 	 25401624 	 1000 	 0.0016436576843261719 	 0.006315946578979492 	 1.2159347534179688e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:41.918918 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), ) 	 76204872 	 1000 	 0.005303382873535156 	 0.007316112518310547 	 2.4080276489257812e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:43.588568 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401864 	 1000 	 0.004896640777587891 	 0.008109569549560547 	 3.4809112548828125e-05 	 4.887580871582031e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:44.138533 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401864 	 1000 	 0.0028791427612304688 	 0.007378816604614258 	 1.049041748046875e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:44.685108 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), ) 	 25401864 	 1000 	 0.0028100013732910156 	 0.013090372085571289 	 6.198883056640625e-06 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:45.242947 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), ) 	 25401900 	 1000 	 0.002810955047607422 	 0.007470846176147461 	 7.152557373046875e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:46.000801 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.002855062484741211 	 0.007441997528076172 	 7.152557373046875e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:46.552534 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.0028171539306640625 	 0.007227659225463867 	 6.9141387939453125e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:47.127900 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401900 	 1000 	 0.0029535293579101562 	 0.007315158843994141 	 6.198883056640625e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:47.691356 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.0028209686279296875 	 0.007265806198120117 	 5.9604644775390625e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:48.247967 test begin: paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.002850770950317383 	 0.00728607177734375 	 6.198883056640625e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:48.795213 test begin: paddle.atleast_1d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), ) 	 76204836 	 1000 	 0.00284576416015625 	 0.00744938850402832 	 2.0265579223632812e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:50.475301 test begin: paddle.atleast_1d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401660 	 1000 	 0.0028123855590820312 	 0.007221221923828125 	 7.3909759521484375e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:51.030051 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401660 	 1000 	 0.002828359603881836 	 0.007318258285522461 	 6.4373016357421875e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:51.590873 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), ) 	 25401660 	 1000 	 0.002933025360107422 	 0.014529228210449219 	 8.344650268554688e-06 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:52.162423 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), ) 	 25401654 	 1000 	 0.0028052330017089844 	 0.010382652282714844 	 9.059906005859375e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:52.734593 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.002862691879272461 	 0.010771751403808594 	 1.7642974853515625e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:53.293668 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401654 	 1000 	 0.002808094024658203 	 0.010709524154663086 	 7.867813110351562e-06 	 0.00011420249938964844 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:53.869319 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.002922534942626953 	 0.007415771484375 	 2.3603439331054688e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:54.423999 test begin: paddle.atleast_1d(Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 423361, 5],"float64"), ) 	 25401660 	 1000 	 0.00159454345703125 	 0.006192684173583984 	 6.67572021484375e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:54.976047 test begin: paddle.atleast_1d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401900 	 1000 	 0.0028214454650878906 	 0.007328987121582031 	 1.2159347534179688e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:55.538024 test begin: paddle.atleast_1d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), ) 	 76204980 	 1000 	 0.002880573272705078 	 0.007462024688720703 	 7.867813110351562e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:57.155569 test begin: paddle.atleast_1d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401654 	 1000 	 0.0027844905853271484 	 0.007348775863647461 	 6.9141387939453125e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:57.701693 test begin: paddle.atleast_1d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), ) 	 76204818 	 1000 	 0.0028312206268310547 	 0.007211923599243164 	 6.198883056640625e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:59.325128 test begin: paddle.atleast_1d(Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 846721, 2, 5],"float64"), ) 	 25401630 	 1000 	 0.0015728473663330078 	 0.006183147430419922 	 6.9141387939453125e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:30:59.874237 test begin: paddle.atleast_1d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.002850055694580078 	 0.009540796279907227 	 6.4373016357421875e-06 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:00.424647 test begin: paddle.atleast_1d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), ) 	 76204890 	 1000 	 0.0029027462005615234 	 0.0073773860931396484 	 1.3113021850585938e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:03.483065 test begin: paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.004252910614013672 	 0.007440328598022461 	 2.9802322387695312e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:04.687392 test begin: paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 76204824 	 1000 	 0.0029366016387939453 	 0.00745844841003418 	 1.2874603271484375e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:06.647682 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), ) 	 25401640 	 1000 	 0.0015697479248046875 	 0.006215095520019531 	 5.9604644775390625e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:07.185335 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.002863645553588867 	 0.007493019104003906 	 6.198883056640625e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:07.723570 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 76204920 	 1000 	 0.002887725830078125 	 0.010258674621582031 	 1.049041748046875e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:10.176892 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 1058401],"float64"), ) 	 25401624 	 1000 	 0.0019638538360595703 	 0.00843191146850586 	 1.239776611328125e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:11.875257 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), ) 	 76204872 	 1000 	 0.0039479732513427734 	 0.007313966751098633 	 8.344650268554688e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:13.480392 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401864 	 1000 	 0.0037469863891601562 	 0.007397651672363281 	 7.152557373046875e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:14.027859 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401864 	 1000 	 0.0037393569946289062 	 0.007329225540161133 	 6.4373016357421875e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:14.578661 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), ) 	 25401864 	 1000 	 0.003833293914794922 	 0.0073626041412353516 	 1.0013580322265625e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:15.129896 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), ) 	 25401900 	 1000 	 0.0037469863891601562 	 0.007478952407836914 	 7.152557373046875e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:15.678050 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.003789186477661133 	 0.007295846939086914 	 6.9141387939453125e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:16.224626 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.003742694854736328 	 0.007432699203491211 	 8.106231689453125e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:16.771576 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401900 	 1000 	 0.003742218017578125 	 0.007258892059326172 	 7.152557373046875e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:17.329070 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.00392460823059082 	 0.0073833465576171875 	 6.198883056640625e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:17.880356 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.0037915706634521484 	 0.007353067398071289 	 9.5367431640625e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:18.427639 test begin: paddle.atleast_2d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), ) 	 76204836 	 1000 	 0.003760099411010742 	 0.01052999496459961 	 8.821487426757812e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:20.069083 test begin: paddle.atleast_2d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401660 	 1000 	 0.0037679672241210938 	 0.007477760314941406 	 6.67572021484375e-06 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:20.627549 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401660 	 1000 	 0.0036890506744384766 	 0.0075244903564453125 	 7.62939453125e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:21.179325 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), ) 	 25401660 	 1000 	 0.0037131309509277344 	 0.007249355316162109 	 6.4373016357421875e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:21.735757 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), ) 	 25401654 	 1000 	 0.0037314891815185547 	 0.007399797439575195 	 6.4373016357421875e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:22.365053 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.0036971569061279297 	 0.011195182800292969 	 6.4373016357421875e-06 	 5.3882598876953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:22.918220 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401654 	 1000 	 0.0037131309509277344 	 0.007508277893066406 	 7.152557373046875e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:23.467528 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.0037827491760253906 	 0.007265806198120117 	 6.67572021484375e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:24.013653 test begin: paddle.atleast_2d(Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 423361, 5],"float64"), ) 	 25401660 	 1000 	 0.0018932819366455078 	 0.006163597106933594 	 5.9604644775390625e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:24.581575 test begin: paddle.atleast_2d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401900 	 1000 	 0.0037946701049804688 	 0.010243654251098633 	 7.152557373046875e-06 	 6.175041198730469e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:25.138236 test begin: paddle.atleast_2d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), ) 	 76204980 	 1000 	 0.0042877197265625 	 0.007332801818847656 	 2.5033950805664062e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:26.807283 test begin: paddle.atleast_2d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401654 	 1000 	 0.0056095123291015625 	 0.007405996322631836 	 2.5272369384765625e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:27.362243 test begin: paddle.atleast_2d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), ) 	 76204818 	 1000 	 0.0037965774536132812 	 0.007343292236328125 	 1.1682510375976562e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:28.989885 test begin: paddle.atleast_2d(Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 846721, 2, 5],"float64"), ) 	 25401630 	 1000 	 0.0018947124481201172 	 0.006195783615112305 	 7.3909759521484375e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:29.534025 test begin: paddle.atleast_2d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.003807544708251953 	 0.007474660873413086 	 7.152557373046875e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:30.073320 test begin: paddle.atleast_2d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), ) 	 76204890 	 1000 	 0.003778696060180664 	 0.007558345794677734 	 9.5367431640625e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:31.710943 test begin: paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.003811359405517578 	 0.009301900863647461 	 7.152557373046875e-06 	 4.673004150390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:32.250797 test begin: paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 76204824 	 1000 	 0.003747701644897461 	 0.010387897491455078 	 8.106231689453125e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:34.036455 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), ) 	 25401640 	 1000 	 0.002018451690673828 	 0.008815765380859375 	 9.298324584960938e-06 	 5.0067901611328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:34.706273 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.003821849822998047 	 0.007851600646972656 	 1.6450881958007812e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:37.313525 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 76204920 	 1000 	 0.0037970542907714844 	 0.01049494743347168 	 9.5367431640625e-06 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:39.595813 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 1058401],"float64"), ) 	 25401624 	 1000 	 0.004602193832397461 	 0.008499622344970703 	 1.430511474609375e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:40.252600 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 1058401],"float64"), ) 	 76204872 	 1000 	 0.0047991275787353516 	 0.010083436965942383 	 8.821487426757812e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:41.911651 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401864 	 1000 	 0.004673480987548828 	 0.007463693618774414 	 1.1205673217773438e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:42.455311 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401864 	 1000 	 0.00471043586730957 	 0.007347583770751953 	 6.9141387939453125e-06 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:43.007861 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 1058401],"float64"), ) 	 25401864 	 1000 	 0.00886392593383789 	 0.011933565139770508 	 8.344650268554688e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:43.571846 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), ) 	 25401900 	 1000 	 0.004689216613769531 	 0.007316112518310547 	 6.67572021484375e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:44.123399 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.004744768142700195 	 0.007300853729248047 	 7.152557373046875e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:44.760701 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.004719972610473633 	 0.007260560989379883 	 6.9141387939453125e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:45.305129 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401900 	 1000 	 0.0046727657318115234 	 0.007485866546630859 	 5.7220458984375e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:45.851099 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.004724025726318359 	 0.012662172317504883 	 7.3909759521484375e-06 	 5.364418029785156e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:46.410519 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.0046541690826416016 	 0.007242918014526367 	 8.344650268554688e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:46.971781 test begin: paddle.atleast_3d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), ) 	 76204836 	 1000 	 0.004819154739379883 	 0.007288217544555664 	 8.58306884765625e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:48.643224 test begin: paddle.atleast_3d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401660 	 1000 	 0.004676342010498047 	 0.008162975311279297 	 9.298324584960938e-06 	 3.719329833984375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:49.323822 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401660 	 1000 	 0.0046346187591552734 	 0.007472515106201172 	 1.5735626220703125e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:49.883034 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2116801],"float64"), ) 	 25401660 	 1000 	 0.004604816436767578 	 0.007362842559814453 	 6.67572021484375e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:50.432649 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), ) 	 25401654 	 1000 	 0.005221128463745117 	 0.007266998291015625 	 2.4318695068359375e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:50.985943 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.004605531692504883 	 0.007348775863647461 	 6.67572021484375e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:51.533641 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401654 	 1000 	 0.004618644714355469 	 0.0072286128997802734 	 5.9604644775390625e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:52.079233 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.0046503543853759766 	 0.007422685623168945 	 5.9604644775390625e-06 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:52.625365 test begin: paddle.atleast_3d(Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 423361, 5],"float64"), ) 	 25401660 	 1000 	 0.0022072792053222656 	 0.006174802780151367 	 5.9604644775390625e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:53.167886 test begin: paddle.atleast_3d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401900 	 1000 	 0.004688739776611328 	 0.007437467575073242 	 6.67572021484375e-06 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:53.919063 test begin: paddle.atleast_3d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), Tensor([3, 4, 423361, 5],"float64"), ) 	 76204980 	 1000 	 0.0047550201416015625 	 0.007434368133544922 	 1.1444091796875e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:55.546291 test begin: paddle.atleast_3d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401654 	 1000 	 0.004631996154785156 	 0.00818324089050293 	 1.3828277587890625e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:56.091241 test begin: paddle.atleast_3d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), Tensor([3, 4233601, 2],"float64"), ) 	 76204818 	 1000 	 0.004629611968994141 	 0.007204294204711914 	 5.4836273193359375e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:57.773005 test begin: paddle.atleast_3d(Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 846721, 2, 5],"float64"), ) 	 25401630 	 1000 	 0.002215862274169922 	 0.006476163864135742 	 7.152557373046875e-06 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:58.430214 test begin: paddle.atleast_3d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401870 	 1000 	 0.004723548889160156 	 0.007525920867919922 	 1.71661376953125e-05 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:31:58.986612 test begin: paddle.atleast_3d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), Tensor([3, 846721, 2, 5],"float64"), ) 	 76204890 	 1000 	 0.004723072052001953 	 0.007338762283325195 	 1.52587890625e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:00.656757 test begin: paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 25401656 	 1000 	 0.0045964717864990234 	 0.007447242736816406 	 1.5020370483398438e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:01.207508 test begin: paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 76204824 	 1000 	 0.006078243255615234 	 0.0074138641357421875 	 3.4332275390625e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:02.857025 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), ) 	 25401640 	 1000 	 0.0022001266479492188 	 0.008165121078491211 	 5.9604644775390625e-06 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:03.408964 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 25401880 	 1000 	 0.004704713821411133 	 0.00741887092590332 	 6.4373016357421875e-06 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:03.960272 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 76204920 	 1000 	 0.004771232604980469 	 0.0072574615478515625 	 7.867813110351562e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:05.596065 test begin: paddle.bincount(Tensor([25401601],"int64"), minlength=Tensor([1],"int32"), )
[Prof] paddle.bincount 	 paddle.bincount(Tensor([25401601],"int64"), minlength=Tensor([1],"int32"), ) 	 25401602 	 1000 	 1.0001161098480225 	 0.829153299331665 	 0.0005106925964355469 	 0.00047278404235839844 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:09.026703 test begin: paddle.bincount(Tensor([50803201],"int32"), weights=Tensor([50803201],"float32"), )
[Prof] paddle.bincount 	 paddle.bincount(Tensor([50803201],"int32"), weights=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 1.9757776260375977 	 1.4437580108642578 	 0.001226663589477539 	 0.0010805130004882812 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:14.162864 test begin: paddle.bincount(x=Tensor([50803201],"int32"), weights=Tensor([50803201],"int32"), )
[Prof] paddle.bincount 	 paddle.bincount(x=Tensor([50803201],"int32"), weights=Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.7705368995666504 	 1.8119194507598877 	 0.0010273456573486328 	 0.0009622573852539062 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:18.977577 test begin: paddle.bitwise_and(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4480764865875244 	 0.4505431652069092 	 0.439450740814209 	 0.43611621856689453 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:21.910920 test begin: paddle.bitwise_and(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4484388828277588 	 0.4504528045654297 	 0.4398012161254883 	 0.4386763572692871 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:24.812889 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4483978748321533 	 0.45044994354248047 	 0.439831018447876 	 0.43833374977111816 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:27.741376 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.448474645614624 	 0.4504125118255615 	 0.43997693061828613 	 0.43846893310546875 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:30.668015 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11798763275146484 	 0.11709094047546387 	 0.10951948165893555 	 0.10496711730957031 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:32.367267 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.449840784072876 	 0.4579505920410156 	 0.4411036968231201 	 0.43445920944213867 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:34.592996 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.4480593204498291 	 0.4528229236602783 	 0.4394218921661377 	 0.4382920265197754 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:39.534391 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1780261993408203 	 0.2349262237548828 	 0.16128087043762207 	 0.2090134620666504 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:40.700946 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.31473422050476074 	 0.4792978763580322 	 0.3053252696990967 	 0.46596693992614746 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:43.004588 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
W0725 17:48:43.690384 96679 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2967367172241211 	 0.30947256088256836 	 0.2868335247039795 	 0.2911710739135742 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:44.565670 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11823272705078125 	 0.11633777618408203 	 0.10938119888305664 	 0.10399293899536133 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:46.242540 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.4514808654785156 	 0.44670557975769043 	 0.4417548179626465 	 0.4347541332244873 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:48.323045 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.4487743377685547 	 0.4503178596496582 	 0.44014644622802734 	 0.4384040832519531 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:51.264912 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.18457937240600586 	 0.22727346420288086 	 0.17493581771850586 	 0.21371746063232422 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:52.381107 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.12148261070251465 	 0.12190651893615723 	 0.10992550849914551 	 0.10404276847839355 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:54.102304 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2967946529388428 	 0.30770206451416016 	 0.28617167472839355 	 0.294353723526001 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:55.321145 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.45075297355651855 	 0.44829392433166504 	 0.44189953804016113 	 0.43454670906066895 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:57.450188 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.34597301483154297 	 0.4789271354675293 	 0.33617281913757324 	 0.46565723419189453 	 None 	 None 	 None 	 None 	 
2025-07-25 17:48:59.312479 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.44902610778808594 	 0.45025205612182617 	 0.440227746963501 	 0.4384191036224365 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:02.185185 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.1183011531829834 	 0.11538410186767578 	 0.10966348648071289 	 0.10327887535095215 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:03.843090 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.4519834518432617 	 0.44669175148010254 	 0.44078826904296875 	 0.4335496425628662 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:05.919644 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11844468116760254 	 0.11537718772888184 	 0.10962319374084473 	 0.1032552719116211 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:07.598852 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45070362091064453 	 0.44671082496643066 	 0.4418776035308838 	 0.4346616268157959 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:09.721239 test begin: paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11812806129455566 	 0.11548399925231934 	 0.10963225364685059 	 0.10135912895202637 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:11.387512 test begin: paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45073676109313965 	 0.4479398727416992 	 0.4419870376586914 	 0.43446993827819824 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:13.506098 test begin: paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1181344985961914 	 0.1197364330291748 	 0.10970854759216309 	 0.1033933162689209 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:15.175956 test begin: paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45067811012268066 	 0.44671058654785156 	 0.4418497085571289 	 0.4348161220550537 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:17.252853 test begin: paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11843729019165039 	 0.1161811351776123 	 0.10966229438781738 	 0.10300016403198242 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:18.956235 test begin: paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.45737338066101074 	 0.4466845989227295 	 0.4418010711669922 	 0.4347512722015381 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:21.089129 test begin: paddle.bitwise_and(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.4507408142089844 	 0.45026183128356934 	 0.4402341842651367 	 0.43839073181152344 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:24.081516 test begin: paddle.bitwise_invert(Tensor([12700801, 4, 1],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([12700801, 4, 1],"int32"), ) 	 50803204 	 1000 	 0.2966923713684082 	 0.2979776859283447 	 0.2879214286804199 	 0.2866811752319336 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:25.302358 test begin: paddle.bitwise_invert(Tensor([2, 1270081, 4, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 1270081, 4, 5],"int32"), ) 	 50803240 	 1000 	 0.29603004455566406 	 0.2978823184967041 	 0.28778886795043945 	 0.2862985134124756 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:26.474473 test begin: paddle.bitwise_invert(Tensor([2, 3, 1693441, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 3, 1693441, 5],"int32"), ) 	 50803230 	 1000 	 0.2960178852081299 	 0.29790353775024414 	 0.2876927852630615 	 0.2866783142089844 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:27.651868 test begin: paddle.bitwise_invert(Tensor([2, 3, 4, 2116801],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 3, 4, 2116801],"int32"), ) 	 50803224 	 1000 	 0.29600977897644043 	 0.29785847663879395 	 0.28779053688049316 	 0.2866044044494629 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:28.827361 test begin: paddle.bitwise_invert(Tensor([3, 16934401, 1],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([3, 16934401, 1],"int32"), ) 	 50803203 	 1000 	 0.2960085868835449 	 0.29794955253601074 	 0.28774094581604004 	 0.2816751003265381 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:30.006598 test begin: paddle.bitwise_invert(Tensor([3, 4, 4233601],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([3, 4, 4233601],"int32"), ) 	 50803212 	 1000 	 0.2960999011993408 	 0.2979006767272949 	 0.2856431007385254 	 0.28592467308044434 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:31.186710 test begin: paddle.bitwise_invert(Tensor([846721, 3, 4, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([846721, 3, 4, 5],"int32"), ) 	 50803260 	 1000 	 0.29603075981140137 	 0.29904794692993164 	 0.2877817153930664 	 0.28652191162109375 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:32.385493 test begin: paddle.bitwise_left_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.45078325271606445 	 0.45997166633605957 	 0.44169092178344727 	 0.4346621036529541 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:35.983157 test begin: paddle.bitwise_left_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.45255470275878906 	 0.6908383369445801 	 0.4412877559661865 	 0.4347233772277832 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:42.477681 test begin: paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4478902816772461 	 0.4520857334136963 	 0.4386260509490967 	 0.4385101795196533 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:45.509299 test begin: paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.4481675624847412 	 0.45002198219299316 	 0.4390597343444824 	 0.4383206367492676 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:48.445205 test begin: paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.4472064971923828 	 0.4500608444213867 	 0.43805551528930664 	 0.4384443759918213 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:51.409203 test begin: paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.4486522674560547 	 0.4584224224090576 	 0.4396486282348633 	 0.4381837844848633 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:54.463132 test begin: paddle.bitwise_not(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.2987818717956543 	 0.2962186336517334 	 0.2903130054473877 	 0.2846548557281494 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:56.139983 test begin: paddle.bitwise_not(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.29795122146606445 	 0.2962915897369385 	 0.2899038791656494 	 0.28470349311828613 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:57.752137 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.2979440689086914 	 0.2962777614593506 	 0.28995227813720703 	 0.2847926616668701 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:59.334742 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 101606940 	 1000 	 0.2983722686767578 	 0.29634833335876465 	 0.2902677059173584 	 0.2846348285675049 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:00.937819 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 50803632 	 1000 	 0.08955264091491699 	 0.08075094223022461 	 0.08139681816101074 	 0.0689399242401123 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:01.834666 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 50803632 	 1000 	 0.2968406677246094 	 0.2978706359863281 	 0.288210391998291 	 0.2861659526824951 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:03.046949 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 101606832 	 1000 	 0.29845190048217773 	 0.29630255699157715 	 0.28695011138916016 	 0.28479957580566406 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:04.647818 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 50804280 	 1000 	 0.08851861953735352 	 0.07982516288757324 	 0.08003568649291992 	 0.06798076629638672 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:05.583551 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 50804280 	 1000 	 0.29686713218688965 	 0.29791808128356934 	 0.2881286144256592 	 0.2864232063293457 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:06.760701 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 101607480 	 1000 	 0.29778170585632324 	 0.2963080406188965 	 0.2896864414215088 	 0.285053014755249 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:08.372440 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50805360 	 1000 	 0.0897824764251709 	 0.07995343208312988 	 0.08150529861450195 	 0.06818866729736328 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:09.250295 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50805360 	 1000 	 0.29680442810058594 	 0.29789233207702637 	 0.28812575340270996 	 0.2864229679107666 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:10.432160 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101608560 	 1000 	 0.2984297275543213 	 0.2962982654571533 	 0.2903265953063965 	 0.2848389148712158 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:12.033586 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 50803740 	 1000 	 0.08947205543518066 	 0.07918953895568848 	 0.08123135566711426 	 0.06733512878417969 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:12.910348 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 50803740 	 1000 	 0.295987606048584 	 0.30275988578796387 	 0.28783655166625977 	 0.2861654758453369 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:14.101196 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 50803920 	 1000 	 0.08967423439025879 	 0.08024072647094727 	 0.08138179779052734 	 0.06728363037109375 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:14.995912 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.29578423500061035 	 0.29955554008483887 	 0.28769755363464355 	 0.2862882614135742 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:16.172011 test begin: paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 50803920 	 1000 	 0.08966183662414551 	 0.07921981811523438 	 0.08148384094238281 	 0.0672905445098877 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:17.042732 test begin: paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2957615852355957 	 0.30107665061950684 	 0.28764986991882324 	 0.28616833686828613 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:18.230677 test begin: paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50803920 	 1000 	 0.08966350555419922 	 0.07919049263000488 	 0.08141922950744629 	 0.06734871864318848 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:19.100021 test begin: paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2958400249481201 	 0.29790830612182617 	 0.2876007556915283 	 0.2863485813140869 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:20.289137 test begin: paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50804280 	 1000 	 0.08958196640014648 	 0.07983636856079102 	 0.08128929138183594 	 0.06808042526245117 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:21.174721 test begin: paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50804280 	 1000 	 0.29592442512512207 	 0.29789113998413086 	 0.28760814666748047 	 0.2863466739654541 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:22.348511 test begin: paddle.bitwise_not(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101607480 	 1000 	 0.2983565330505371 	 0.2962913513183594 	 0.290299654006958 	 0.28475499153137207 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:23.942306 test begin: paddle.bitwise_or(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.45037078857421875 	 0.4501807689666748 	 0.4405796527862549 	 0.43752384185791016 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:26.873140 test begin: paddle.bitwise_or(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4487607479095459 	 0.4502243995666504 	 0.44003725051879883 	 0.4384036064147949 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:29.809281 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44893312454223633 	 0.45026564598083496 	 0.44033384323120117 	 0.4381287097930908 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:32.737462 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.4485468864440918 	 0.8912291526794434 	 0.43982672691345215 	 0.43798375129699707 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:39.410356 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.6385338306427002 	 0.13761019706726074 	 0.10747909545898438 	 0.1047677993774414 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:41.809744 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.8674917221069336 	 0.4608314037322998 	 0.4418501853942871 	 0.4344799518585205 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:45.507428 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.4500894546508789 	 0.45023155212402344 	 0.4400181770324707 	 0.43822169303894043 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:48.670676 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.155426025390625 	 0.22740769386291504 	 0.14573884010314941 	 0.21423554420471191 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:49.839256 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3172471523284912 	 0.4803428649902344 	 0.30516695976257324 	 0.4672231674194336 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:51.623239 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29669857025146484 	 0.3079979419708252 	 0.2871706485748291 	 0.29495930671691895 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:52.848664 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.12046432495117188 	 0.12157917022705078 	 0.10952520370483398 	 0.10364508628845215 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:54.525499 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.45072460174560547 	 0.4466679096221924 	 0.44197607040405273 	 0.43467068672180176 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:56.645018 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.4491281509399414 	 0.4503142833709717 	 0.44049954414367676 	 0.4384880065917969 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:59.539595 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1739182472229004 	 0.22765350341796875 	 0.16428065299987793 	 0.21364068984985352 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:00.659994 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11828994750976562 	 0.11586999893188477 	 0.10944271087646484 	 0.10384583473205566 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:02.327553 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2968578338623047 	 0.3077223300933838 	 0.28673720359802246 	 0.29473185539245605 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:03.537335 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.45067286491394043 	 0.4467182159423828 	 0.4421412944793701 	 0.43500185012817383 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:07.737528 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.6546366214752197 	 0.4853363037109375 	 0.33290982246398926 	 0.4644598960876465 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:10.807058 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.4489736557006836 	 0.4502391815185547 	 0.440352201461792 	 0.43851518630981445 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:13.725805 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11778926849365234 	 0.11495804786682129 	 0.10920095443725586 	 0.10302400588989258 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:15.407998 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.4506363868713379 	 0.4466993808746338 	 0.442030668258667 	 0.4349846839904785 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:17.544858 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1180117130279541 	 0.1150200366973877 	 0.1091761589050293 	 0.10289788246154785 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:19.231651 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4506869316101074 	 0.4466531276702881 	 0.44179677963256836 	 0.43456029891967773 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:21.335367 test begin: paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11768031120300293 	 0.1150217056274414 	 0.10916352272033691 	 0.10291433334350586 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:22.999950 test begin: paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4528017044067383 	 0.44663214683532715 	 0.4421074390411377 	 0.4350006580352783 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:25.084709 test begin: paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11765575408935547 	 0.11506366729736328 	 0.10919904708862305 	 0.10188055038452148 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:26.748320 test begin: paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4517943859100342 	 0.44670629501342773 	 0.44147276878356934 	 0.43487071990966797 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:28.915754 test begin: paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11822056770324707 	 0.11578512191772461 	 0.10490798950195312 	 0.10368537902832031 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:30.654823 test begin: paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.45067834854125977 	 0.4466850757598877 	 0.442061185836792 	 0.4349510669708252 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:32.760168 test begin: paddle.bitwise_or(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.4488096237182617 	 0.4519822597503662 	 0.44019341468811035 	 0.43816471099853516 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:37.507488 test begin: paddle.bitwise_right_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.4560708999633789 	 0.45149707794189453 	 0.44174981117248535 	 0.4344348907470703 	 None 	 None 	 None 	 None 	 combined
2025-07-25 17:51:40.915212 test begin: paddle.bitwise_right_shift(Tensor([200, 127009],"int64"), Tensor([200, 127009],"int64"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 127009],"int64"), Tensor([200, 127009],"int64"), ) 	 50803600 	 1000 	 0.4518153667449951 	 0.4553072452545166 	 0.43991684913635254 	 0.43367671966552734 	 None 	 None 	 None 	 None 	 combined
2025-07-25 17:51:42.686796 test begin: paddle.bitwise_right_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.45059633255004883 	 0.44666099548339844 	 0.441605806350708 	 0.43465304374694824 	 None 	 None 	 None 	 None 	 combined
2025-07-25 17:51:44.825197 test begin: paddle.bitwise_right_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4496462345123291 	 0.45012378692626953 	 0.4383995532989502 	 0.4381124973297119 	 None 	 None 	 None 	 None 	 combined
2025-07-25 17:51:47.757372 test begin: paddle.bitwise_right_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.4544970989227295 	 0.45159292221069336 	 0.43881845474243164 	 0.43778204917907715 	 None 	 None 	 None 	 None 	 combined
2025-07-25 17:51:52.918698 test begin: paddle.bitwise_right_shift(Tensor([84673, 300],"int64"), Tensor([84673, 300],"int64"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([84673, 300],"int64"), Tensor([84673, 300],"int64"), ) 	 50803800 	 1000 	 0.45108461380004883 	 0.45163893699645996 	 0.4397773742675781 	 0.43379759788513184 	 None 	 None 	 None 	 None 	 combined
2025-07-25 17:51:54.694064 test begin: paddle.bitwise_xor(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44913148880004883 	 0.45026683807373047 	 0.43643689155578613 	 0.4380204677581787 	 None 	 None 	 None 	 None 	 
2025-07-25 17:51:57.643725 test begin: paddle.bitwise_xor(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4490480422973633 	 0.45020222663879395 	 0.44026780128479004 	 0.4379909038543701 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:00.594368 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44913649559020996 	 0.4501819610595703 	 0.4402580261230469 	 0.4380500316619873 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:03.553376 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.44885683059692383 	 0.45017528533935547 	 0.4399745464324951 	 0.4381725788116455 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:06.479380 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.1196584701538086 	 0.12129878997802734 	 0.10915970802307129 	 0.10501980781555176 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:08.158792 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.45122694969177246 	 0.4467432498931885 	 0.4382493495941162 	 0.4349048137664795 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:10.246330 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.45014238357543945 	 0.4502432346343994 	 0.44008731842041016 	 0.43820667266845703 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:13.256872 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.16845202445983887 	 0.23015141487121582 	 0.1587662696838379 	 0.21373963356018066 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:14.410104 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.31519389152526855 	 0.48025989532470703 	 0.3054063320159912 	 0.46709537506103516 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:16.228486 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29683566093444824 	 0.30802297592163086 	 0.2870481014251709 	 0.294891357421875 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:17.442789 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.1197209358215332 	 0.11704206466674805 	 0.10928177833557129 	 0.10390543937683105 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:19.168604 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.45067882537841797 	 0.44666266441345215 	 0.441845178604126 	 0.43491673469543457 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:21.263473 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.44892048835754395 	 0.45023274421691895 	 0.4400315284729004 	 0.4383251667022705 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:24.226786 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.17713475227355957 	 0.2270970344543457 	 0.16753411293029785 	 0.21366167068481445 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:25.343916 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11823844909667969 	 0.11722159385681152 	 0.10927677154541016 	 0.10409021377563477 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:27.030097 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29968953132629395 	 0.31124258041381836 	 0.28643012046813965 	 0.2939791679382324 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:28.248352 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.45066022872924805 	 0.44846534729003906 	 0.4418327808380127 	 0.43352174758911133 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:30.401438 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3468663692474365 	 0.4787132740020752 	 0.33574819564819336 	 0.4655876159667969 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:32.241922 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.44898200035095215 	 0.45032286643981934 	 0.43947672843933105 	 0.437666654586792 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:35.231770 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11773347854614258 	 0.12277054786682129 	 0.1088409423828125 	 0.10293078422546387 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:39.282413 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.45389771461486816 	 0.44979071617126465 	 0.44129014015197754 	 0.4344305992126465 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:41.390211 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.12310314178466797 	 0.11737966537475586 	 0.10903716087341309 	 0.10321307182312012 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:43.075117 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45369410514831543 	 0.44672393798828125 	 0.4418911933898926 	 0.4346351623535156 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:45.248213 test begin: paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1176767349243164 	 0.11548018455505371 	 0.10913300514221191 	 0.10338306427001953 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:46.945604 test begin: paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45061540603637695 	 0.44663023948669434 	 0.44173407554626465 	 0.4347496032714844 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:49.087788 test begin: paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11763882637023926 	 0.1155092716217041 	 0.10903501510620117 	 0.1027679443359375 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:50.763118 test begin: paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4522252082824707 	 0.44667482376098633 	 0.4416227340698242 	 0.43484067916870117 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:52.884070 test begin: paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.5459651947021484 	 0.1190178394317627 	 0.10901331901550293 	 0.10401558876037598 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:55.622033 test begin: paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.45424556732177734 	 0.446850061416626 	 0.44173765182495117 	 0.43277835845947266 	 None 	 None 	 None 	 None 	 
2025-07-25 17:52:59.328886 test begin: paddle.bitwise_xor(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44964146614074707 	 0.4502067565917969 	 0.44004201889038086 	 0.4380612373352051 	 None 	 None 	 None 	 None 	 
2025-07-25 17:53:02.258686 test begin: paddle.bmm(Tensor([112, 1043, 435],"float32"), Tensor([112, 435, 64],"float32"), )
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:824: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:181.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[Prof] paddle.bmm 	 paddle.bmm(Tensor([112, 1043, 435],"float32"), Tensor([112, 435, 64],"float32"), ) 	 53933040 	 1000 	 0.8949835300445557 	 0.8962645530700684 	 0.882434606552124 	 0.8783202171325684 	 1.6087558269500732 	 1.610400915145874 	 0.821953535079956 	 0.8226358890533447 	 
2025-07-25 17:53:08.695894 test begin: paddle.bmm(Tensor([112, 435, 435],"float32"), Tensor([112, 435, 1043],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([112, 435, 435],"float32"), Tensor([112, 435, 1043],"float32"), ) 	 72008160 	 1000 	 3.368417263031006 	 3.368422746658325 	 3.355844497680664 	 3.352121114730835 	 6.94806981086731 	 6.9480438232421875 	 3.5501983165740967 	 3.5504674911499023 	 
2025-07-25 17:53:31.465113 test begin: paddle.bmm(Tensor([14, 81, 7332],"float32"), Tensor([14, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([14, 81, 7332],"float32"), Tensor([14, 7332, 512],"float32"), ) 	 60870264 	 1000 	 1.4690971374511719 	 1.9234275817871094 	 1.4568407535552979 	 1.459657907485962 	 1.4226717948913574 	 1.4225406646728516 	 0.7267875671386719 	 0.7265586853027344 	 
2025-07-25 17:53:41.216971 test begin: paddle.bmm(Tensor([1825, 435, 435],"float32"), Tensor([1825, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([1825, 435, 435],"float32"), Tensor([1825, 435, 64],"float32"), ) 	 396143625 	 1000 	 6.021304368972778 	 6.019291877746582 	 6.007511615753174 	 6.003002166748047 	 9.950348377227783 	 9.948532342910767 	 5.084131479263306 	 5.083595275878906 	 
2025-07-25 17:54:20.827396 test begin: paddle.bmm(Tensor([26, 1024, 1024],"float32"), Tensor([26, 1024, 1909],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([26, 1024, 1024],"float32"), Tensor([26, 1024, 1909],"float32"), ) 	 78088192 	 1000 	 5.944522380828857 	 5.944648742675781 	 5.932227373123169 	 5.9285194873809814 	 12.069784164428711 	 12.069471836090088 	 6.167621850967407 	 6.167353868484497 	 
2025-07-25 17:54:59.193829 test begin: paddle.bmm(Tensor([26, 1909, 1024],"float32"), Tensor([26, 1024, 12],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([26, 1909, 1024],"float32"), Tensor([26, 1024, 12],"float32"), ) 	 51144704 	 1000 	 0.8321597576141357 	 0.8322482109069824 	 0.8188455104827881 	 0.8162503242492676 	 0.9405057430267334 	 0.9399487972259521 	 0.4807708263397217 	 0.48076891899108887 	 
2025-07-25 17:55:03.604217 test begin: paddle.bmm(Tensor([269, 435, 435],"float32"), Tensor([269, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([269, 435, 435],"float32"), Tensor([269, 435, 64],"float32"), ) 	 58390485 	 1000 	 0.9019660949707031 	 0.8978722095489502 	 0.8879659175872803 	 0.8812565803527832 	 1.4870414733886719 	 1.4873569011688232 	 0.7590563297271729 	 0.7595047950744629 	 
2025-07-25 17:55:12.686774 test begin: paddle.bmm(Tensor([4, 1733, 7332],"float32"), Tensor([4, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 1733, 7332],"float32"), Tensor([4, 7332, 512],"float32"), ) 	 65841360 	 1000 	 4.386166334152222 	 4.385911703109741 	 4.372509956359863 	 4.369757652282715 	 6.311038017272949 	 6.311105728149414 	 3.225045919418335 	 3.2255780696868896 	 
2025-07-25 17:55:37.572129 test begin: paddle.bmm(Tensor([4, 81, 156801],"float32"), Tensor([4, 156801, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 156801],"float32"), Tensor([4, 156801, 512],"float32"), ) 	 371931972 	 1000 	 31.362619400024414 	 31.293610334396362 	 31.350444793701172 	 31.277962923049927 	 8.19941234588623 	 8.200196981430054 	 4.189723253250122 	 4.190015554428101 	 
2025-07-25 17:57:03.243369 test begin: paddle.bmm(Tensor([4, 81, 24807],"float32"), Tensor([4, 24807, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 24807],"float32"), Tensor([4, 24807, 512],"float32"), ) 	 58842204 	 1000 	 4.944533824920654 	 4.945556879043579 	 4.932193040847778 	 4.929872512817383 	 1.390904188156128 	 1.3907294273376465 	 0.7106738090515137 	 0.7105100154876709 	 
2025-07-25 17:57:20.129826 test begin: paddle.bmm(Tensor([4, 81, 7332],"float32"), Tensor([4, 7332, 1733],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 7332],"float32"), Tensor([4, 7332, 1733],"float32"), ) 	 53200992 	 1000 	 1.4684126377105713 	 1.4702751636505127 	 1.4560184478759766 	 1.4454944133758545 	 1.6405940055847168 	 1.6405243873596191 	 0.8382570743560791 	 0.8381330966949463 	 
2025-07-25 17:57:27.557991 test begin: paddle.bmm(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 12],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 12],"float32"), ) 	 51982336 	 1000 	 0.829240083694458 	 0.8280038833618164 	 0.8158094882965088 	 0.8121809959411621 	 0.9916164875030518 	 0.9912614822387695 	 0.5066695213317871 	 0.5064074993133545 	 
2025-07-25 17:57:32.076578 test begin: paddle.bmm(Tensor([86, 81, 7332],"float32"), Tensor([86, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([86, 81, 7332],"float32"), Tensor([86, 7332, 512],"float32"), ) 	 373917336 	 1000 	 6.8872904777526855 	 5.839347839355469 	 5.826710939407349 	 5.823239088058472 	 8.361342191696167 	 8.360611200332642 	 4.272552013397217 	 4.272188186645508 	 
2025-07-25 17:58:08.827130 test begin: paddle.broadcast_tensors(list[Tensor([127009, 200],"float64"),Tensor([127009, 200],"float64"),], )
[Prof] paddle.broadcast_tensors 	 paddle.broadcast_tensors(list[Tensor([127009, 200],"float64"),Tensor([127009, 200],"float64"),], ) 	 50803600 	 1000 	 0.614342212677002 	 0.007247447967529297 	 0.31378912925720215 	 2.5272369384765625e-05 	 0.6258366107940674 	 0.062236785888671875 	 0.15985989570617676 	 3.981590270996094e-05 	 
2025-07-25 17:58:12.367040 test begin: paddle.broadcast_tensors(list[Tensor([200, 127009],"float64"),Tensor([200, 127009],"float64"),], )
[Prof] paddle.broadcast_tensors 	 paddle.broadcast_tensors(list[Tensor([200, 127009],"float64"),Tensor([200, 127009],"float64"),], ) 	 50803600 	 1000 	 0.6148314476013184 	 0.008502483367919922 	 0.31402039527893066 	 8.034706115722656e-05 	 0.6258368492126465 	 0.07365536689758301 	 0.1598529815673828 	 3.933906555175781e-05 	 
2025-07-25 17:58:15.811589 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), ) 	 38102403 	 1000 	 1.3409337997436523 	 1.0374057292938232 	 1.3300409317016602 	 1.0261516571044922 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:19.073938 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), out_int32=True, ) 	 38102403 	 1000 	 1.3356094360351562 	 1.237828254699707 	 1.3246040344238281 	 1.2189412117004395 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:26.185984 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), right=True, ) 	 38102403 	 1000 	 1.3459720611572266 	 1.0421252250671387 	 1.3327276706695557 	 1.0303778648376465 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:29.418382 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), ) 	 25401606 	 1000 	 0.3182716369628906 	 0.3212604522705078 	 0.30677175521850586 	 0.3035585880279541 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:30.584306 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), out_int32=True, ) 	 25401606 	 1000 	 0.2864084243774414 	 0.24772000312805176 	 0.2740051746368408 	 0.23310399055480957 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:31.654283 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), right=True, ) 	 25401606 	 1000 	 0.3175497055053711 	 0.3173389434814453 	 0.30649352073669434 	 0.3036460876464844 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:32.811874 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 76204803 	 1000 	 2.7753617763519287 	 3.4531807899475098 	 2.7646052837371826 	 2.13131046295166 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:41.744354 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 76204803 	 1000 	 2.7678346633911133 	 2.136206865310669 	 2.7550361156463623 	 2.1247570514678955 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:48.282102 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), right=True, ) 	 76204803 	 1000 	 2.781843900680542 	 2.155217170715332 	 2.7708303928375244 	 2.143852710723877 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:54.878295 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([25401601],"float64"), ) 	 25401609 	 1000 	 0.010761737823486328 	 0.012917518615722656 	 1.52587890625e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:55.443397 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 25401609 	 1000 	 0.011142253875732422 	 0.011173725128173828 	 1.3828277587890625e-05 	 2.6941299438476562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:56.000820 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([25401601],"float64"), right=True, ) 	 25401609 	 1000 	 0.011160135269165039 	 0.011136293411254883 	 1.2636184692382812e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:56.587687 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), ) 	 25401608 	 1000 	 0.3194904327392578 	 0.3142211437225342 	 0.30558323860168457 	 0.3030111789703369 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:57.760664 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), out_int32=True, ) 	 25401608 	 1000 	 0.28369855880737305 	 0.24501991271972656 	 0.2727210521697998 	 0.23321247100830078 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:58.823280 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), right=True, ) 	 25401608 	 1000 	 0.31635117530822754 	 0.3150758743286133 	 0.30533719062805176 	 0.30365443229675293 	 None 	 None 	 None 	 None 	 
2025-07-25 17:58:59.995551 test begin: paddle.cartesian_prod(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5080],"complex128"),], ) 	 5088 	 1000 	 0.06067943572998047 	 0.06998062133789062 	 1.71661376953125e-05 	 4.363059997558594e-05 	 8.611960649490356 	 0.17362022399902344 	 2.1985042095184326 	 5.507469177246094e-05 	 
2025-07-25 17:59:08.985284 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([40],"int32"),Tensor([508],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([40],"int32"),Tensor([508],"int32"),], ) 	 588 	 1000 	 0.0630488395690918 	 0.07219290733337402 	 0.0040187835693359375 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:59:16.518021 test begin: paddle.cartesian_prod(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([50803],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([50803],"int32"),], ) 	 50811 	 1000 	 0.06910347938537598 	 0.07114982604980469 	 0.00477290153503418 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:00:13.544757 test begin: paddle.cast(Tensor([1, 1, 32768, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([1, 1, 32768, 32768],"float16"), dtype=Dtype(float16), ) 	 1073741824 	 1000 	 3.2413127422332764 	 0.0020761489868164062 	 1.653136968612671 	 1.71661376953125e-05 	 3.235372543334961 	 0.04794788360595703 	 1.6532034873962402 	 6.008148193359375e-05 	 combined
2025-07-25 18:01:01.659706 test begin: paddle.cast(Tensor([128256, 793],"bfloat16"), Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([128256, 793],"bfloat16"), Dtype(float16), ) 	 101707008 	 1000 	 0.29828596115112305 	 0.5223886966705322 	 0.2889702320098877 	 0.4971587657928467 	 0.298022985458374 	 0.5070850849151611 	 0.2420051097869873 	 0.44438648223876953 	 combined
2025-07-25 18:01:10.162722 test begin: paddle.cast(Tensor([2, 1, 1551, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 1551, 32768],"float16"), dtype=Dtype(float16), ) 	 101646336 	 1000 	 0.3100593090057373 	 0.002031087875366211 	 0.2992570400238037 	 1.6450881958007812e-05 	 0.3101480007171631 	 0.04502415657043457 	 0.255462646484375 	 5.936622619628906e-05 	 combined
2025-07-25 18:01:14.739553 test begin: paddle.cast(Tensor([2, 1, 32768, 1551],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 32768, 1551],"float16"), dtype=Dtype(float16), ) 	 101646336 	 1000 	 0.310075044631958 	 0.002020120620727539 	 0.2992701530456543 	 1.71661376953125e-05 	 0.3101232051849365 	 0.043856143951416016 	 0.25422024726867676 	 4.029273986816406e-05 	 combined
2025-07-25 18:01:19.315405 test begin: paddle.cast(Tensor([2, 1, 32768, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 32768, 32768],"float16"), dtype=Dtype(float16), ) 	 2147483648 	 1000 	 6.471521377563477 	 0.0020530223846435547 	 3.30537486076355 	 2.288818359375e-05 	 6.732742071151733 	 0.043822526931762695 	 3.5674946308135986 	 4.982948303222656e-05 	 combined
2025-07-25 18:02:55.689530 test begin: paddle.cast(Tensor([2, 1024, 50304],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1024, 50304],"float16"), dtype="float32", ) 	 103022592 	 1000 	 0.4884004592895508 	 0.5567104816436768 	 0.4767594337463379 	 0.5435914993286133 	 0.4571256637573242 	 0.4598367214202881 	 0.4030461311340332 	 0.3884570598602295 	 combined
2025-07-25 18:03:01.353076 test begin: paddle.cast(Tensor([33076, 3072],"bfloat16"), Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([33076, 3072],"bfloat16"), Dtype(float16), ) 	 101609472 	 1000 	 0.29747891426086426 	 0.5100400447845459 	 0.28446006774902344 	 0.49691176414489746 	 0.29758119583129883 	 0.5066750049591064 	 0.24148178100585938 	 0.4439868927001953 	 combined
2025-07-25 18:03:06.543805 test begin: paddle.cast(Tensor([8, 1024, 12404],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([8, 1024, 12404],"float16"), dtype="float32", ) 	 101613568 	 1000 	 0.4818286895751953 	 0.5490772724151611 	 0.4705352783203125 	 0.5357513427734375 	 0.4509119987487793 	 0.4536168575286865 	 0.3984701633453369 	 0.39024901390075684 	 combined
2025-07-25 18:03:12.147076 test begin: paddle.cast(Tensor([8, 253, 50304],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([8, 253, 50304],"float16"), dtype="float32", ) 	 101815296 	 1000 	 0.48238158226013184 	 0.550142765045166 	 0.47108983993530273 	 0.5366711616516113 	 0.4512636661529541 	 0.45451974868774414 	 0.3990359306335449 	 0.38865137100219727 	 combined
2025-07-25 18:03:17.641154 test begin: paddle.cdist(Tensor([12700801, 4],"float32"), Tensor([1, 4],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([12700801, 4],"float32"), Tensor([1, 4],"float32"), p=1, ) 	 50803208 	 1000 	 0.6933517456054688 	 26.98014235496521 	 0.35428881645202637 	 26.950212001800537 	 8.360218524932861 	 14.188350915908813 	 2.8489303588867188 	 2.894505262374878 	 
2025-07-25 18:04:09.106472 test begin: paddle.cdist(Tensor([6380, 7963],"float32"), Tensor([1, 7963],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([6380, 7963],"float32"), Tensor([1, 7963],"float32"), p=1, ) 	 50811903 	 1000 	 0.44960856437683105 	 0.19415664672851562 	 0.22974514961242676 	 0.17259693145751953 	 2.184262752532959 	 1.1751558780670166 	 0.7425582408905029 	 0.23987984657287598 	 
2025-07-25 18:04:14.001112 test begin: paddle.cdist(Tensor([8550, 5942],"float32"), Tensor([1, 5942],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([8550, 5942],"float32"), Tensor([1, 5942],"float32"), p=1, ) 	 50810042 	 1000 	 0.4504101276397705 	 0.193742036819458 	 0.2301194667816162 	 0.17226123809814453 	 2.1907308101654053 	 1.1611812114715576 	 0.7448282241821289 	 0.23702502250671387 	 
2025-07-25 18:04:18.848252 test begin: paddle.cdist(Tensor([900, 56449],"float32"), Tensor([1, 56449],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([900, 56449],"float32"), Tensor([1, 56449],"float32"), p=1, ) 	 50860549 	 1000 	 0.48183655738830566 	 0.2902843952178955 	 0.1640172004699707 	 0.26850342750549316 	 2.157785654067993 	 1.228208303451538 	 0.7334744930267334 	 0.31369972229003906 	 
2025-07-25 18:04:23.845910 test begin: paddle.ceil(Tensor([12404, 32, 128],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([12404, 32, 128],"float32"), ) 	 50806784 	 1000 	 0.2960641384124756 	 0.30208897590637207 	 0.28720593452453613 	 0.2853825092315674 	 0.13414525985717773 	 0.13428711891174316 	 0.08355331420898438 	 0.07326555252075195 	 
2025-07-25 18:04:26.433523 test begin: paddle.ceil(Tensor([141121, 6, 3, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([141121, 6, 3, 1, 2, 5],"float64"), ) 	 25401780 	 1000 	 0.2978813648223877 	 0.3036794662475586 	 0.2891969680786133 	 0.2870001792907715 	 0.13388848304748535 	 0.13450217247009277 	 0.08372926712036133 	 0.07117223739624023 	 
2025-07-25 18:04:28.362746 test begin: paddle.ceil(Tensor([3, 141121, 3, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 141121, 3, 4, 1, 5],"float64"), ) 	 25401780 	 1000 	 0.29784154891967773 	 0.2983419895172119 	 0.28929638862609863 	 0.2869429588317871 	 0.1338820457458496 	 0.1345689296722412 	 0.08279633522033691 	 0.060697078704833984 	 
2025-07-25 18:04:30.305119 test begin: paddle.ceil(Tensor([3, 282241, 3, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 282241, 3, 1, 2, 5],"float64"), ) 	 25401690 	 1000 	 0.2979245185852051 	 0.29837608337402344 	 0.28939199447631836 	 0.28690624237060547 	 0.13393259048461914 	 0.13447904586791992 	 0.08312582969665527 	 0.07033395767211914 	 
2025-07-25 18:04:32.256625 test begin: paddle.ceil(Tensor([3, 6, 141121, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 141121, 1, 2, 5],"float64"), ) 	 25401780 	 1000 	 0.29782867431640625 	 0.3006739616394043 	 0.2892873287200928 	 0.28700804710388184 	 0.13391876220703125 	 0.1345212459564209 	 0.08402872085571289 	 0.07064223289489746 	 
2025-07-25 18:04:34.250258 test begin: paddle.ceil(Tensor([3, 6, 3, 1, 2, 235201],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 1, 2, 235201],"float64"), ) 	 25401708 	 1000 	 0.2975955009460449 	 1.4315869808197021 	 0.2890584468841553 	 0.28673720359802246 	 0.13385891914367676 	 0.13452410697937012 	 0.08408641815185547 	 0.0708770751953125 	 
2025-07-25 18:04:39.633038 test begin: paddle.ceil(Tensor([3, 6, 3, 1, 94081, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 1, 94081, 5],"float64"), ) 	 25401870 	 1000 	 0.2980027198791504 	 0.3022928237915039 	 0.289478063583374 	 0.2853255271911621 	 0.13417339324951172 	 0.13453888893127441 	 0.08424520492553711 	 0.07052278518676758 	 
2025-07-25 18:04:41.622545 test begin: paddle.ceil(Tensor([3, 6, 3, 4, 1, 117601],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 4, 1, 117601],"float64"), ) 	 25401816 	 1000 	 0.29799795150756836 	 0.3084442615509033 	 0.2894575595855713 	 0.2870478630065918 	 0.13393855094909668 	 0.13451051712036133 	 0.08416271209716797 	 0.07164621353149414 	 
2025-07-25 18:04:43.572406 test begin: paddle.ceil(Tensor([3, 6, 3, 4, 23521, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 4, 23521, 5],"float64"), ) 	 25402680 	 1000 	 0.2978222370147705 	 0.29836606979370117 	 0.2892482280731201 	 0.2869746685028076 	 0.13396048545837402 	 0.13467812538146973 	 0.08425760269165039 	 0.0714113712310791 	 
2025-07-25 18:04:45.494295 test begin: paddle.ceil(Tensor([3, 6, 3, 47041, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 47041, 2, 5],"float64"), ) 	 25402140 	 1000 	 0.29795360565185547 	 0.30126190185546875 	 0.28922319412231445 	 0.286973237991333 	 0.13388729095458984 	 0.13451647758483887 	 0.08386945724487305 	 0.06993341445922852 	 
2025-07-25 18:04:47.431817 test begin: paddle.ceil(Tensor([3, 6, 3, 94081, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 94081, 1, 5],"float64"), ) 	 25401870 	 1000 	 0.2980070114135742 	 0.3071928024291992 	 0.289290189743042 	 0.2870142459869385 	 0.13402843475341797 	 0.13446617126464844 	 0.05994820594787598 	 0.06617546081542969 	 
2025-07-25 18:04:49.393160 test begin: paddle.ceil(Tensor([3, 6, 70561, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 70561, 4, 1, 5],"float64"), ) 	 25401960 	 1000 	 0.2975795269012451 	 0.30164074897766113 	 0.28891515731811523 	 0.28427815437316895 	 0.13385939598083496 	 0.1346902847290039 	 0.0841681957244873 	 0.0702362060546875 	 
2025-07-25 18:04:51.378340 test begin: paddle.ceil(Tensor([32, 12404, 128],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([32, 12404, 128],"float32"), ) 	 50806784 	 1000 	 0.29603147506713867 	 0.2978997230529785 	 0.2872450351715088 	 0.28679513931274414 	 0.13402366638183594 	 0.13420939445495605 	 0.0840449333190918 	 0.0442347526550293 	 
2025-07-25 18:04:53.930870 test begin: paddle.ceil(Tensor([32, 32, 49613],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([32, 32, 49613],"float32"), ) 	 50803712 	 1000 	 0.2957448959350586 	 0.29784560203552246 	 0.2870609760284424 	 0.28672337532043457 	 0.13405942916870117 	 0.13416814804077148 	 0.08373832702636719 	 0.07258725166320801 	 
2025-07-25 18:04:56.485561 test begin: paddle.ceil(Tensor([70561, 6, 3, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([70561, 6, 3, 4, 1, 5],"float64"), ) 	 25401960 	 1000 	 0.29758405685424805 	 0.7436730861663818 	 0.2889668941497803 	 0.2869565486907959 	 0.1339247226715088 	 0.13460755348205566 	 0.0840005874633789 	 0.06993246078491211 	 
2025-07-25 18:05:00.321383 test begin: paddle.chunk(Tensor([115, 216, 64, 64],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([115, 216, 64, 64],"float16"), 3, axis=1, ) 	 101744640 	 1000 	 0.4322776794433594 	 0.0077667236328125 	 0.41706371307373047 	 2.384185791015625e-05 	 0.30860400199890137 	 0.5046522617340088 	 0.2499675750732422 	 0.41237974166870117 	 
2025-07-25 18:05:05.422311 test begin: paddle.chunk(Tensor([16, 128, 24807],"float32"), 2, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([16, 128, 24807],"float32"), 2, axis=1, ) 	 50804736 	 1000 	 0.3380136489868164 	 0.00669407844543457 	 0.32405877113342285 	 3.0994415283203125e-05 	 0.3123936653137207 	 0.3073756694793701 	 0.25426578521728516 	 0.23153901100158691 	 
2025-07-25 18:05:08.025732 test begin: paddle.chunk(Tensor([16, 128, 25500],"float32"), 2, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([16, 128, 25500],"float32"), 2, axis=1, ) 	 52224000 	 1000 	 0.35420775413513184 	 0.006568431854248047 	 0.3401806354522705 	 2.2172927856445312e-05 	 0.3196542263031006 	 0.31491947174072266 	 0.26461291313171387 	 0.2374897003173828 	 
2025-07-25 18:05:10.773239 test begin: paddle.chunk(Tensor([4, 216, 1838, 64],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 1838, 64],"float16"), 3, axis=1, ) 	 101634048 	 1000 	 0.42957520484924316 	 0.0078125 	 0.41453123092651367 	 2.4080276489257812e-05 	 0.308452844619751 	 0.5031795501708984 	 0.24960851669311523 	 0.4159576892852783 	 
2025-07-25 18:05:15.817195 test begin: paddle.chunk(Tensor([4, 216, 64, 1838],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 64, 1838],"float16"), 3, axis=1, ) 	 101634048 	 1000 	 0.4296119213104248 	 0.00780034065246582 	 0.41453003883361816 	 4.172325134277344e-05 	 0.30846071243286133 	 0.502981424331665 	 0.25034189224243164 	 0.40285706520080566 	 
2025-07-25 18:05:20.914966 test begin: paddle.chunk(Tensor([4, 216, 64, 919],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 64, 919],"float32"), 3, axis=1, ) 	 50817024 	 1000 	 0.33685994148254395 	 0.014441251754760742 	 0.3217813968658447 	 6.222724914550781e-05 	 0.30852508544921875 	 0.3048262596130371 	 0.2502100467681885 	 0.21743392944335938 	 
2025-07-25 18:05:23.572789 test begin: paddle.chunk(Tensor([4, 216, 919, 64],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 919, 64],"float32"), 3, axis=1, ) 	 50817024 	 1000 	 0.3368191719055176 	 0.007842302322387695 	 0.3217964172363281 	 1.9550323486328125e-05 	 0.3084697723388672 	 0.3048090934753418 	 0.24979352951049805 	 0.21448707580566406 	 
2025-07-25 18:05:26.215429 test begin: paddle.chunk(Tensor([58, 216, 64, 64],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([58, 216, 64, 64],"float32"), 3, axis=1, ) 	 51314688 	 1000 	 0.34569740295410156 	 0.0077915191650390625 	 0.3307328224182129 	 2.6226043701171875e-05 	 0.31121826171875 	 0.3078451156616211 	 0.2527298927307129 	 0.22069239616394043 	 
2025-07-25 18:05:28.854579 test begin: paddle.clip(Tensor([1408, 36082],"float32"), min=-2, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([1408, 36082],"float32"), min=-2, max=2, ) 	 50803456 	 1000 	 0.2955362796783447 	 0.2980372905731201 	 0.2785460948944092 	 0.2849898338317871 	 0.45040273666381836 	 0.7343180179595947 	 0.3981497287750244 	 0.15012621879577637 	 
2025-07-25 18:05:32.403436 test begin: paddle.clip(Tensor([2, 3840, 10240],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([2, 3840, 10240],"float32"), 0, 255, ) 	 78643200 	 1000 	 0.45574498176574707 	 0.47349047660827637 	 0.43957972526550293 	 0.4450516700744629 	 0.6943602561950684 	 1.1192002296447754 	 0.639028787612915 	 0.22667741775512695 	 
2025-07-25 18:05:41.019597 test begin: paddle.clip(Tensor([23, 17, 256, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([23, 17, 256, 256],"float64"), min=0, max=2, ) 	 25624576 	 1000 	 0.30065488815307617 	 0.30534839630126953 	 0.28398609161376953 	 0.2880239486694336 	 0.45185017585754395 	 0.7251851558685303 	 0.3950536251068115 	 0.1482844352722168 	 
2025-07-25 18:05:43.964052 test begin: paddle.clip(Tensor([24, 17, 244, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 244, 256],"float64"), min=0, max=2, ) 	 25485312 	 1000 	 0.29915571212768555 	 0.2994718551635742 	 0.28247523307800293 	 0.28621578216552734 	 0.44982314109802246 	 0.7213306427001953 	 0.39797115325927734 	 0.1474902629852295 	 
2025-07-25 18:05:46.818139 test begin: paddle.clip(Tensor([24, 17, 256, 244],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 256, 244],"float64"), min=0, max=2, ) 	 25485312 	 1000 	 0.29912853240966797 	 0.299419641494751 	 0.28257083892822266 	 0.2860748767852783 	 0.4496164321899414 	 0.721320629119873 	 0.39749813079833984 	 0.14747953414916992 	 
2025-07-25 18:05:49.693363 test begin: paddle.clip(Tensor([24, 17, 256, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 256, 256],"float64"), min=0, max=2, ) 	 26738688 	 1000 	 0.3137483596801758 	 0.31584763526916504 	 0.2971644401550293 	 0.30069804191589355 	 0.471815824508667 	 0.75541090965271 	 0.4199256896972656 	 0.15445923805236816 	 
2025-07-25 18:05:52.705150 test begin: paddle.clip(Tensor([3, 1654, 10240],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([3, 1654, 10240],"float32"), 0, 255, ) 	 50810880 	 1000 	 0.2957906723022461 	 0.30435729026794434 	 0.27924537658691406 	 0.28504467010498047 	 0.4503796100616455 	 0.7329723834991455 	 0.39763689041137695 	 0.149855375289917 	 
2025-07-25 18:05:56.199825 test begin: paddle.clip(Tensor([3, 3840, 4411],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([3, 3840, 4411],"float32"), 0, 255, ) 	 50814720 	 1000 	 0.29566121101379395 	 0.29795074462890625 	 0.2791759967803955 	 0.2850778102874756 	 0.4504358768463135 	 0.7340617179870605 	 0.3981282711029053 	 0.15009260177612305 	 
2025-07-25 18:05:59.716323 test begin: paddle.clip(Tensor([8269, 6144],"float32"), min=-2, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([8269, 6144],"float32"), min=-2, max=2, ) 	 50804736 	 1000 	 0.2958815097808838 	 0.2981126308441162 	 0.27825093269348145 	 0.2850837707519531 	 0.45030689239501953 	 0.7328860759735107 	 0.3965449333190918 	 0.14983558654785156 	 
2025-07-25 18:06:03.208923 test begin: paddle.clone(Tensor([145, 12, 112, 261],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 12, 112, 261],"float32"), ) 	 50863680 	 1000 	 0.31504106521606445 	 0.31810879707336426 	 0.16098999977111816 	 0.16008543968200684 	 0.31621718406677246 	 0.04877805709838867 	 0.16153764724731445 	 4.9591064453125e-05 	 
2025-07-25 18:06:06.167888 test begin: paddle.clone(Tensor([145, 12, 261, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 12, 261, 112],"float32"), ) 	 50863680 	 1000 	 0.31499671936035156 	 0.31354522705078125 	 0.16094708442687988 	 0.1601262092590332 	 0.31621718406677246 	 0.051642417907714844 	 0.1615440845489502 	 6.890296936035156e-05 	 
2025-07-25 18:06:08.823864 test begin: paddle.clone(Tensor([145, 28, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 28, 112, 112],"float32"), ) 	 50928640 	 1000 	 0.31075358390808105 	 0.31099653244018555 	 0.30181407928466797 	 0.29755282402038574 	 0.3108253479003906 	 0.049279212951660156 	 0.2577083110809326 	 6.318092346191406e-05 	 
2025-07-25 18:06:11.469214 test begin: paddle.clone(Tensor([22, 185, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 185, 112, 112],"float32"), ) 	 51054080 	 1000 	 0.3143603801727295 	 0.3144974708557129 	 0.1606454849243164 	 0.1605994701385498 	 0.3145737648010254 	 0.048712730407714844 	 0.16069293022155762 	 3.6716461181640625e-05 	 
2025-07-25 18:06:14.152117 test begin: paddle.clone(Tensor([22, 64, 112, 323],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 64, 112, 323],"float32"), ) 	 50935808 	 1000 	 0.31078052520751953 	 0.311018705368042 	 0.30184245109558105 	 0.29751086235046387 	 0.3108334541320801 	 0.048500776290893555 	 0.25795769691467285 	 5.650520324707031e-05 	 
2025-07-25 18:06:16.787636 test begin: paddle.clone(Tensor([22, 64, 323, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 64, 323, 112],"float32"), ) 	 50935808 	 1000 	 0.31075000762939453 	 0.31101512908935547 	 0.3018374443054199 	 0.2975313663482666 	 0.3108084201812744 	 0.048184871673583984 	 0.25618791580200195 	 5.1975250244140625e-05 	 
2025-07-25 18:06:19.469810 test begin: paddle.clone(Tensor([338, 12, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([338, 12, 112, 112],"float32"), ) 	 50878464 	 1000 	 0.3103601932525635 	 0.31061840057373047 	 0.3014090061187744 	 0.297222375869751 	 0.31053733825683594 	 0.047910213470458984 	 0.2577340602874756 	 4.1961669921875e-05 	 
2025-07-25 18:06:22.096498 test begin: paddle.clone(Tensor([43, 256, 56, 83],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 256, 56, 83],"float32"), ) 	 51165184 	 1000 	 0.31214046478271484 	 0.3124704360961914 	 0.3032243251800537 	 0.29917359352111816 	 0.312183141708374 	 0.04804801940917969 	 0.2602076530456543 	 6.628036499023438e-05 	 
2025-07-25 18:06:24.745664 test begin: paddle.clone(Tensor([43, 256, 83, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 256, 83, 56],"float32"), ) 	 51165184 	 1000 	 0.31212449073791504 	 0.3158457279205322 	 0.30319786071777344 	 0.2991173267364502 	 0.312225341796875 	 0.05072832107543945 	 0.2600381374359131 	 6.580352783203125e-05 	 
2025-07-25 18:06:27.442151 test begin: paddle.clone(Tensor([43, 377, 56, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 377, 56, 56],"float32"), ) 	 50837696 	 1000 	 0.3154022693634033 	 0.3128502368927002 	 0.1611616611480713 	 0.15975379943847656 	 0.31512928009033203 	 0.04805564880371094 	 0.16097092628479004 	 4.935264587402344e-05 	 
2025-07-25 18:06:30.104498 test begin: paddle.clone(Tensor([64, 256, 56, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([64, 256, 56, 56],"float32"), ) 	 51380224 	 1000 	 0.31342196464538574 	 0.3136708736419678 	 0.30445170402526855 	 0.3005523681640625 	 0.3134932518005371 	 0.04806256294250488 	 0.26160717010498047 	 4.291534423828125e-05 	 
2025-07-25 18:06:32.789233 test begin: paddle.clone(Tensor([64, 64, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([64, 64, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.3134167194366455 	 0.32662391662597656 	 0.3044755458831787 	 0.3003530502319336 	 0.3134763240814209 	 0.04790520668029785 	 0.26150941848754883 	 4.673004150390625e-05 	 
2025-07-25 18:06:38.065533 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9274613857269287 	 0.9313442707061768 	 0.9117457866668701 	 0.9073355197906494 	 0.9278504848480225 	 0.06907916069030762 	 0.8600127696990967 	 4.9114227294921875e-05 	 
2025-07-25 18:06:44.175403 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.31495141983032227 	 0.31312108039855957 	 0.30178046226501465 	 0.15986394882202148 	 0.3110158443450928 	 0.0677938461303711 	 0.2519247531890869 	 0.0001125335693359375 	 
2025-07-25 18:06:46.245569 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31681132316589355 	 0.3229951858520508 	 0.30113935470581055 	 0.3062136173248291 	 0.31261682510375977 	 0.07012605667114258 	 0.244154691696167 	 8.153915405273438e-05 	 
2025-07-25 18:06:48.345685 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31618332862854004 	 0.32387876510620117 	 0.30060410499572754 	 0.30573320388793945 	 0.3131673336029053 	 0.0708014965057373 	 0.24476933479309082 	 5.5789947509765625e-05 	 
2025-07-25 18:06:50.465307 test begin: paddle.column_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9246580600738525 	 0.9224109649658203 	 0.9090101718902588 	 0.9050626754760742 	 0.9295663833618164 	 0.07031965255737305 	 0.861609935760498 	 6.341934204101562e-05 	 
2025-07-25 18:06:56.571671 test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 25401654 	 1000 	 0.31702470779418945 	 0.3180997371673584 	 0.3014857769012451 	 0.30359816551208496 	 0.31269145011901855 	 0.07201409339904785 	 0.24241137504577637 	 6.961822509765625e-05 	 
2025-07-25 18:06:58.685927 test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.31613612174987793 	 0.3216259479522705 	 0.300342321395874 	 0.2990248203277588 	 0.3125286102294922 	 0.07017850875854492 	 0.24482154846191406 	 0.00011372566223144531 	 
2025-07-25 18:07:00.767930 test begin: paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9249064922332764 	 0.9282138347625732 	 0.9092342853546143 	 0.9132301807403564 	 0.9299633502960205 	 0.06869196891784668 	 0.8625259399414062 	 5.888938903808594e-05 	 
2025-07-25 18:07:06.839527 test begin: paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3140385150909424 	 1.0941622257232666 	 0.30120038986206055 	 0.15986418724060059 	 0.31127476692199707 	 0.05361604690551758 	 0.254457950592041 	 5.125999450683594e-05 	 
2025-07-25 18:07:10.815234 test begin: paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.31627964973449707 	 0.31926536560058594 	 0.3008146286010742 	 0.29712796211242676 	 0.31251096725463867 	 0.06881380081176758 	 0.24494481086730957 	 5.841255187988281e-05 	 
2025-07-25 18:07:13.651271 test begin: paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9302887916564941 	 0.9288289546966553 	 0.9147374629974365 	 0.9116075038909912 	 0.9439408779144287 	 0.07053399085998535 	 0.8758294582366943 	 5.936622619628906e-05 	 
2025-07-25 18:07:19.710778 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3162860870361328 	 0.3152577877044678 	 0.3005709648132324 	 0.30042409896850586 	 0.3124675750732422 	 0.08158564567565918 	 0.24511075019836426 	 7.033348083496094e-05 	 
2025-07-25 18:07:21.831713 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9316718578338623 	 0.9375450611114502 	 0.9160201549530029 	 0.9222919940948486 	 0.9409494400024414 	 0.06873011589050293 	 0.8735218048095703 	 3.647804260253906e-05 	 
2025-07-25 18:07:27.928075 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.31588077545166016 	 0.32224225997924805 	 0.30311155319213867 	 0.15989208221435547 	 0.31250858306884766 	 0.05582785606384277 	 0.257108211517334 	 4.267692565917969e-05 	 
2025-07-25 18:07:30.020674 test begin: paddle.column_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.977025032043457 	 1.4005913734436035 	 0.9613299369812012 	 1.379028558731079 	 0.9600052833557129 	 0.07308673858642578 	 0.8857278823852539 	 8.273124694824219e-05 	 
2025-07-25 18:07:38.104300 test begin: paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9254257678985596 	 1.0322046279907227 	 0.9099295139312744 	 1.0151770114898682 	 0.9379549026489258 	 0.07526326179504395 	 0.8545727729797363 	 6.961822509765625e-05 	 
2025-07-25 18:07:44.308807 test begin: paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3077511787414551 	 0.31313109397888184 	 0.2948577404022217 	 0.15987849235534668 	 0.3261439800262451 	 0.05373549461364746 	 0.27086424827575684 	 4.863739013671875e-05 	 
2025-07-25 18:07:46.443042 test begin: paddle.combinations(Tensor([25401601],"int64"), 0, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([25401601],"int64"), 0, True, ) 	 25401601 	 1000 	 0.01242208480834961 	 0.0043294429779052734 	 7.62939453125e-06 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:07:46.900143 test begin: paddle.combinations(Tensor([50803201],"int32"), 1, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([50803201],"int32"), 1, True, ) 	 50803201 	 1000 	 5.485877752304077 	 2.121053695678711 	 0.003219127655029297 	 0.0013134479522705078 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:08:00.916262 test begin: paddle.complex(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), ) 	 101606528 	 1000 	 0.5920116901397705 	 0.5879931449890137 	 0.5829379558563232 	 0.5748984813690186 	 0.5913686752319336 	 0.06765270233154297 	 0.5329663753509521 	 5.14984130859375e-05 	 
2025-07-25 18:08:05.450703 test begin: paddle.complex(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), ) 	 101613568 	 1000 	 0.5909438133239746 	 0.5879595279693604 	 0.5817992687225342 	 0.5748729705810547 	 0.5896551609039307 	 0.0687408447265625 	 0.5318286418914795 	 6.818771362304688e-05 	 
2025-07-25 18:08:09.985271 test begin: paddle.complex(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 51380224 	 1000 	 0.4906182289123535 	 0.47657132148742676 	 0.4807765483856201 	 0.4626471996307373 	 0.516608715057373 	 0.28749775886535645 	 0.45650267601013184 	 0.20246601104736328 	 
2025-07-25 18:08:15.738612 test begin: paddle.complex(Tensor([20, 2417, 1051],"float32"), Tensor([20, 2417, 1051],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 2417, 1051],"float32"), Tensor([20, 2417, 1051],"float32"), ) 	 101610680 	 1000 	 0.5913474559783936 	 0.5973355770111084 	 0.582200288772583 	 0.5745196342468262 	 0.5909910202026367 	 0.06897878646850586 	 0.5331127643585205 	 6.437301635742188e-05 	 
2025-07-25 18:08:20.560179 test begin: paddle.complex(Tensor([20, 2538, 1001],"float32"), Tensor([20, 2538, 1001],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 2538, 1001],"float32"), Tensor([20, 2538, 1001],"float32"), ) 	 101621520 	 1000 	 0.5924980640411377 	 0.5880796909332275 	 0.5830478668212891 	 0.5749173164367676 	 0.5904195308685303 	 0.06707096099853516 	 0.5328054428100586 	 3.7670135498046875e-05 	 
2025-07-25 18:08:25.114297 test begin: paddle.complex(Tensor([20, 64, 39691],"float32"), Tensor([20, 64, 39691],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 64, 39691],"float32"), Tensor([20, 64, 39691],"float32"), ) 	 101608960 	 1000 	 0.5909144878387451 	 0.5879058837890625 	 0.581859827041626 	 0.5746681690216064 	 0.5903947353363037 	 0.06766486167907715 	 0.5312647819519043 	 6.413459777832031e-05 	 
2025-07-25 18:08:29.629190 test begin: paddle.complex(Tensor([756, 64, 1051],"float32"), Tensor([756, 64, 1051],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([756, 64, 1051],"float32"), Tensor([756, 64, 1051],"float32"), ) 	 101703168 	 1000 	 0.5915422439575195 	 0.5885260105133057 	 0.5823640823364258 	 0.5752882957458496 	 0.5909950733184814 	 0.07160258293151855 	 0.5338020324707031 	 6.771087646484375e-05 	 
2025-07-25 18:08:34.162649 test begin: paddle.complex(Tensor([794, 64, 1001],"float32"), Tensor([794, 64, 1001],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([794, 64, 1001],"float32"), Tensor([794, 64, 1001],"float32"), ) 	 101733632 	 1000 	 0.5924022197723389 	 0.5970523357391357 	 0.5831000804901123 	 0.5746521949768066 	 0.5908832550048828 	 0.06782126426696777 	 0.5334360599517822 	 4.744529724121094e-05 	 
2025-07-25 18:08:40.859369 test begin: paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), ) 	 51380224 	 1000 	 0.482715368270874 	 0.4730699062347412 	 0.47299909591674805 	 0.4591531753540039 	 0.5132269859313965 	 0.28750038146972656 	 0.4533390998840332 	 0.20318007469177246 	 
2025-07-25 18:08:44.509867 test begin: paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 101711872 	 1000 	 0.5915777683258057 	 0.5885975360870361 	 0.5825064182281494 	 0.5746324062347412 	 0.5902197360992432 	 0.06703376770019531 	 0.5329716205596924 	 6.222724914550781e-05 	 
2025-07-25 18:08:49.031524 test begin: paddle.concat(list[Tensor([101606401],"bfloat16"),], )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([101606401],"bfloat16"),], ) 	 101606401 	 1000 	 0.3080160617828369 	 0.31325197219848633 	 0.1573936939239502 	 0.15995264053344727 	 0.6243960857391357 	 0.45356273651123047 	 0.3190031051635742 	 0.3772904872894287 	 
2025-07-25 18:08:54.132403 test begin: paddle.concat(list[Tensor([254, 32, 112, 112],"float16"),Tensor([254, 32, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([254, 32, 112, 112],"float16"),Tensor([254, 32, 112, 112],"float16"),], axis=1, ) 	 203915264 	 1000 	 0.6100418567657471 	 0.9066290855407715 	 0.5970828533172607 	 0.8908302783966064 	 0.9353435039520264 	 0.06256413459777832 	 0.8749220371246338 	 4.3392181396484375e-05 	 
2025-07-25 18:09:04.260351 test begin: paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6133449077606201 	 0.9143722057342529 	 0.6004939079284668 	 0.9000453948974609 	 0.9345126152038574 	 0.062099456787109375 	 0.8733725547790527 	 5.841255187988281e-05 	 
2025-07-25 18:09:14.509690 test begin: paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 32, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 32, 112, 112],"float16"),], axis=1, ) 	 308281344 	 1000 	 0.9236726760864258 	 1.6096129417419434 	 0.9102537631988525 	 1.595231294631958 	 1.420896053314209 	 0.06146359443664551 	 1.3599977493286133 	 3.409385681152344e-05 	 
2025-07-25 18:09:30.096051 test begin: paddle.concat(list[Tensor([512, 32, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, ) 	 308281344 	 1000 	 0.9227240085601807 	 1.5403707027435303 	 0.9098207950592041 	 1.5259368419647217 	 1.421694278717041 	 0.06174111366271973 	 1.361084222793579 	 4.601478576660156e-05 	 
2025-07-25 18:09:45.603046 test begin: paddle.concat(list[Tensor([512, 32, 112, 56],"float16"),Tensor([512, 32, 112, 56],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 112, 56],"float16"),Tensor([512, 32, 112, 56],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6132252216339111 	 0.9205725193023682 	 0.6003904342651367 	 0.8889367580413818 	 0.9345593452453613 	 0.06173992156982422 	 0.8713140487670898 	 5.3882598876953125e-05 	 
2025-07-25 18:09:56.087827 test begin: paddle.concat(list[Tensor([512, 32, 56, 112],"float16"),Tensor([512, 32, 56, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 56, 112],"float16"),Tensor([512, 32, 56, 112],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6135504245758057 	 0.9143691062927246 	 0.6005551815032959 	 0.8962254524230957 	 0.934394359588623 	 0.06281375885009766 	 0.8737473487854004 	 5.6743621826171875e-05 	 
2025-07-25 18:10:06.326906 test begin: paddle.conj(Tensor([2, 20, 2, 635041],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 20, 2, 635041],"float32"), ) 	 50803280 	 1000 	 0.3072774410247803 	 0.001878976821899414 	 0.2992541790008545 	 1.5497207641601562e-05 	 0.3074324131011963 	 0.04376697540283203 	 0.2582075595855713 	 4.1484832763671875e-05 	 
2025-07-25 18:10:08.696123 test begin: paddle.conj(Tensor([2, 20, 423361, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 20, 423361, 3],"float32"), ) 	 50803320 	 1000 	 0.3072624206542969 	 0.0018680095672607422 	 0.2993125915527344 	 1.621246337890625e-05 	 0.30747556686401367 	 0.04385209083557129 	 0.2582876682281494 	 4.744529724121094e-05 	 
2025-07-25 18:10:11.010651 test begin: paddle.conj(Tensor([2, 4233601, 2, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 4233601, 2, 3],"float32"), ) 	 50803212 	 1000 	 0.30922532081604004 	 0.0018432140350341797 	 0.30114102363586426 	 1.5735626220703125e-05 	 0.3088498115539551 	 0.045249223709106445 	 0.2596158981323242 	 4.1484832763671875e-05 	 
2025-07-25 18:10:13.368183 test begin: paddle.conj(Tensor([423361, 20, 2, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([423361, 20, 2, 3],"float32"), ) 	 50803320 	 1000 	 0.30724096298217773 	 0.0018591880798339844 	 0.29915809631347656 	 1.5974044799804688e-05 	 0.30748987197875977 	 0.043782711029052734 	 0.2502710819244385 	 5.817413330078125e-05 	 
2025-07-25 18:10:15.674962 test begin: paddle.copysign(Tensor([12, 1058401, 2],"float64"), Tensor([12, 1058401, 2],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 1058401, 2],"float64"), Tensor([12, 1058401, 2],"float64"), ) 	 50803248 	 1000 	 0.4485290050506592 	 0.443007230758667 	 0.43582725524902344 	 0.43172240257263184 	 0.7426128387451172 	 1.5150001049041748 	 0.68412184715271 	 0.30975866317749023 	 
2025-07-25 18:10:20.846447 test begin: paddle.copysign(Tensor([12, 20, 105841],"float64"), Tensor([12, 20, 105841],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 20, 105841],"float64"), Tensor([12, 20, 105841],"float64"), ) 	 50803680 	 1000 	 0.44808483123779297 	 0.44293737411499023 	 0.43566298484802246 	 0.4315493106842041 	 0.7423195838928223 	 1.5149588584899902 	 0.6837306022644043 	 0.3097405433654785 	 
2025-07-25 18:10:25.610166 test begin: paddle.copysign(Tensor([12, 20, 211681],"float32"), Tensor([12, 20, 211681],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 20, 211681],"float32"), Tensor([12, 20, 211681],"float32"), ) 	 101606880 	 1000 	 0.4505035877227783 	 1.4925026893615723 	 0.437755823135376 	 0.43514275550842285 	 1.1859982013702393 	 1.5520949363708496 	 1.1271255016326904 	 0.317396879196167 	 
2025-07-25 18:10:34.023316 test begin: paddle.copysign(Tensor([12, 2116801, 2],"float32"), Tensor([12, 2116801, 2],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 2116801, 2],"float32"), Tensor([12, 2116801, 2],"float32"), ) 	 101606448 	 1000 	 0.4502403736114502 	 0.6831281185150146 	 0.43757104873657227 	 0.4349956512451172 	 1.2853341102600098 	 1.5519373416900635 	 1.2261264324188232 	 0.31732940673828125 	 
2025-07-25 18:10:42.254781 test begin: paddle.copysign(Tensor([1270081, 20, 2],"float32"), Tensor([1270081, 20, 2],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([1270081, 20, 2],"float32"), Tensor([1270081, 20, 2],"float32"), ) 	 101606480 	 1000 	 0.45029115676879883 	 0.44664430618286133 	 0.43222928047180176 	 0.4354214668273926 	 1.1887249946594238 	 1.551734209060669 	 1.1128113269805908 	 0.3173065185546875 	 
2025-07-25 18:10:48.416268 test begin: paddle.copysign(Tensor([635041, 20, 2],"float64"), Tensor([635041, 20, 2],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([635041, 20, 2],"float64"), Tensor([635041, 20, 2],"float64"), ) 	 50803280 	 1000 	 0.44876933097839355 	 0.44849729537963867 	 0.43643617630004883 	 0.43158960342407227 	 0.7423031330108643 	 1.5149226188659668 	 0.6837866306304932 	 0.30974841117858887 	 
2025-07-25 18:10:53.259761 test begin: paddle.cos(Tensor([1587601, 32],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 0.2954874038696289 	 0.29820990562438965 	 0.28693222999572754 	 0.28728222846984863 	 0.4505486488342285 	 1.0409345626831055 	 0.39737629890441895 	 0.35457777976989746 	 
2025-07-25 18:10:57.039497 test begin: paddle.cos(Tensor([198451, 256],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([198451, 256],"float32"), ) 	 50803456 	 1000 	 0.2954366207122803 	 0.29821085929870605 	 0.28676486015319824 	 0.2874438762664795 	 0.4505150318145752 	 1.0408859252929688 	 0.3979926109313965 	 0.35457491874694824 	 
2025-07-25 18:11:00.807878 test begin: paddle.cos(Tensor([32768, 1551],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.29542112350463867 	 0.29986000061035156 	 0.28687357902526855 	 0.2874641418457031 	 0.4506077766418457 	 1.0413532257080078 	 0.39648008346557617 	 0.3547790050506592 	 
2025-07-25 18:11:04.543168 test begin: paddle.cos(Tensor([396901, 128],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29530954360961914 	 0.3007688522338867 	 0.2866983413696289 	 0.2872748374938965 	 0.45037221908569336 	 1.040893793106079 	 0.3981952667236328 	 0.35462164878845215 	 
2025-07-25 18:11:10.434803 test begin: paddle.cos(Tensor([5000, 10161],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([5000, 10161],"float32"), ) 	 50805000 	 1000 	 0.29543232917785645 	 0.2983214855194092 	 0.28684401512145996 	 0.28745508193969727 	 0.4505457878112793 	 1.0408682823181152 	 0.3978235721588135 	 0.35463452339172363 	 
2025-07-25 18:11:14.224947 test begin: paddle.cos(Tensor([8192, 6202],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.2953214645385742 	 0.2982168197631836 	 0.28682923316955566 	 0.28753662109375 	 0.4504251480102539 	 1.0409631729125977 	 0.3974025249481201 	 0.35463666915893555 	 
2025-07-25 18:11:18.005010 test begin: paddle.cosh(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29476428031921387 	 0.2987182140350342 	 0.28585219383239746 	 0.2868988513946533 	 0.4506521224975586 	 0.7432088851928711 	 0.3979802131652832 	 0.3797152042388916 	 
2025-07-25 18:11:21.445107 test begin: paddle.cosh(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2947652339935303 	 0.2987062931060791 	 0.2858591079711914 	 0.2876565456390381 	 0.45037341117858887 	 0.743213415145874 	 0.39743733406066895 	 0.3797311782836914 	 
2025-07-25 18:11:24.917898 test begin: paddle.cosh(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2947218418121338 	 0.30208444595336914 	 0.2858772277832031 	 0.28761935234069824 	 0.45040011405944824 	 0.7432451248168945 	 0.37808871269226074 	 0.3797781467437744 	 
2025-07-25 18:11:28.413332 test begin: paddle.cosh(Tensor([28, 32, 241, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([28, 32, 241, 241],"float32"), ) 	 52040576 	 1000 	 0.30142784118652344 	 0.3136720657348633 	 0.29270267486572266 	 0.29447436332702637 	 0.46102452278137207 	 0.7610576152801514 	 0.40762829780578613 	 0.38884425163269043 	 
2025-07-25 18:11:32.007976 test begin: paddle.cosh(Tensor([8, 110, 241, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 110, 241, 241],"float32"), ) 	 51111280 	 1000 	 0.29639768600463867 	 0.3117060661315918 	 0.28757190704345703 	 0.2891058921813965 	 0.45273804664611816 	 0.7477447986602783 	 0.4002103805541992 	 0.3820362091064453 	 
2025-07-25 18:11:37.992945 test begin: paddle.cosh(Tensor([8, 32, 241, 824],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 32, 241, 824],"float32"), ) 	 50837504 	 1000 	 0.2952253818511963 	 2.6144328117370605 	 0.28636717796325684 	 0.2876908779144287 	 0.4506092071533203 	 0.7436590194702148 	 0.3979682922363281 	 0.3799116611480713 	 
2025-07-25 18:11:44.481690 test begin: paddle.cosh(Tensor([8, 32, 824, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 32, 824, 241],"float32"), ) 	 50837504 	 1000 	 0.2951962947845459 	 0.2989201545715332 	 0.27913689613342285 	 0.28125643730163574 	 0.4507017135620117 	 0.7437994480133057 	 0.3887827396392822 	 0.380051851272583 	 
2025-07-25 18:11:47.857624 test begin: paddle.cosh(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.29482483863830566 	 0.298769474029541 	 0.27824950218200684 	 0.28110790252685547 	 0.4503657817840576 	 0.7432448863983154 	 0.38680243492126465 	 0.3797149658203125 	 
2025-07-25 18:11:51.290138 test begin: paddle.cosh(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.29477858543395996 	 0.29873061180114746 	 0.2783637046813965 	 0.2810940742492676 	 0.45026612281799316 	 0.7432162761688232 	 0.3882300853729248 	 0.37972354888916016 	 
2025-07-25 18:11:54.640076 test begin: paddle.cosh(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.294827938079834 	 0.3015003204345703 	 0.2783381938934326 	 0.28721094131469727 	 0.45056581497192383 	 0.7432265281677246 	 0.3974020481109619 	 0.3796985149383545 	 
2025-07-25 18:11:58.126348 test begin: paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401796 	 1000 	 0.5987997055053711 	 0.5262227058410645 	 0.20398926734924316 	 0.17933082580566406 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:00.292658 test begin: paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401796 	 1000 	 0.5987887382507324 	 0.5261640548706055 	 0.20405983924865723 	 0.17929983139038086 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 129601, 1]) and output[0] has a shape of torch.Size([1, 129601]).
2025-07-25 18:12:02.464281 test begin: paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401670 	 1000 	 0.6130552291870117 	 0.5434231758117676 	 0.15666794776916504 	 0.13870930671691895 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:04.657986 test begin: paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401670 	 1000 	 0.613008975982666 	 0.5436034202575684 	 0.15659546852111816 	 0.13872194290161133 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 5, 1]) and output[0] has a shape of torch.Size([1, 5]).
2025-07-25 18:12:06.836332 test begin: paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401670 	 1000 	 0.6074891090393066 	 0.552060604095459 	 0.15528154373168945 	 0.14094185829162598 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:09.013906 test begin: paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401670 	 1000 	 0.6075372695922852 	 0.5521743297576904 	 0.15520668029785156 	 0.1409769058227539 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 5, 1]) and output[0] has a shape of torch.Size([1, 5]).
2025-07-25 18:12:11.216608 test begin: paddle.count_nonzero(Tensor([2, 1270081, 4, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 1270081, 4, 5],"float32"), axis=-1, keepdim=False, ) 	 50803240 	 1000 	 0.9746458530426025 	 1.0620708465576172 	 0.3321378231048584 	 0.36194586753845215 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:15.176795 test begin: paddle.count_nonzero(Tensor([2, 3, 1693441, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 3, 1693441, 5],"float32"), axis=-1, keepdim=False, ) 	 50803230 	 1000 	 0.9743897914886475 	 1.0629982948303223 	 0.33208417892456055 	 0.36194276809692383 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:19.169230 test begin: paddle.count_nonzero(Tensor([2, 3, 4, 2116801],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 3, 4, 2116801],"float32"), axis=-1, keepdim=False, ) 	 50803224 	 1000 	 0.8749499320983887 	 0.8666448593139648 	 0.22347331047058105 	 0.2212812900543213 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:22.555961 test begin: paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25402580 	 1000 	 0.5929820537567139 	 0.5278160572052002 	 0.2020263671875 	 0.1798090934753418 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:24.727638 test begin: paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25402580 	 1000 	 0.5929172039031982 	 0.5279607772827148 	 0.20204520225524902 	 0.17986488342285156 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([25921, 1, 5, 1]) and output[0] has a shape of torch.Size([25921, 5]).
2025-07-25 18:12:26.943084 test begin: paddle.count_nonzero(Tensor([846721, 3, 4, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([846721, 3, 4, 5],"float32"), axis=-1, keepdim=False, ) 	 50803260 	 1000 	 0.974600076675415 	 1.0620498657226562 	 0.33214783668518066 	 0.36197948455810547 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:12:30.907671 test begin: paddle.crop(x=Tensor([16934401, 3],"float32"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([16934401, 3],"float32"), shape=list[2,2,], ) 	 50803203 	 1000 	 0.01923060417175293 	 0.014322996139526367 	 1.5974044799804688e-05 	 7.367134094238281e-05 	 0.1530773639678955 	 0.14271855354309082 	 0.10186147689819336 	 0.036437034606933594 	 combined
2025-07-25 18:12:32.082060 test begin: paddle.crop(x=Tensor([2, 1411201, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([2, 1411201, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25401618 	 1000 	 0.01813530921936035 	 0.018366336822509766 	 1.1920928955078125e-05 	 2.193450927734375e-05 	 0.1638641357421875 	 0.14903569221496582 	 0.11258888244628906 	 0.02538323402404785 	 combined
2025-07-25 18:12:32.959238 test begin: paddle.crop(x=Tensor([2, 3, 1411201, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([2, 3, 1411201, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25401618 	 1000 	 0.09162640571594238 	 0.018428564071655273 	 0.07341217994689941 	 2.4080276489257812e-05 	 0.2266392707824707 	 0.5867273807525635 	 0.17162799835205078 	 0.09992480278015137 	 combined
2025-07-25 18:12:34.570653 test begin: paddle.crop(x=Tensor([2, 3, 3, 1411201],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([2, 3, 3, 1411201],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25401618 	 1000 	 0.01816391944885254 	 0.018607139587402344 	 1.5974044799804688e-05 	 2.9802322387695312e-05 	 0.19939112663269043 	 0.39896702766418457 	 0.14311647415161133 	 0.06786894798278809 	 combined
2025-07-25 18:12:40.272665 test begin: paddle.crop(x=Tensor([3, 16934401],"float32"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([3, 16934401],"float32"), shape=list[2,2,], ) 	 50803203 	 1000 	 0.01887202262878418 	 0.013937950134277344 	 1.3589859008789062e-05 	 2.5033950805664062e-05 	 0.1840054988861084 	 0.43929147720336914 	 0.13286828994750977 	 0.08978796005249023 	 combined
2025-07-25 18:12:43.708049 test begin: paddle.crop(x=Tensor([3, 8467201],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([3, 8467201],"float64"), shape=list[2,2,], ) 	 25401603 	 1000 	 0.01884150505065918 	 0.013902902603149414 	 1.2874603271484375e-05 	 2.7894973754882812e-05 	 0.15066003799438477 	 0.4397275447845459 	 0.09860610961914062 	 0.08986663818359375 	 combined
2025-07-25 18:12:46.344418 test begin: paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], ) 	 25401603 	 1000 	 0.01889967918395996 	 0.013587713241577148 	 1.4066696166992188e-05 	 2.2411346435546875e-05 	 0.14997196197509766 	 0.1431264877319336 	 0.09862494468688965 	 0.03655195236206055 	 combined
2025-07-25 18:12:47.208215 test begin: paddle.crop(x=Tensor([940801, 3, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([940801, 3, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25401627 	 1000 	 0.018347978591918945 	 0.019983291625976562 	 1.4781951904296875e-05 	 4.3392181396484375e-05 	 0.1501176357269287 	 0.15436887741088867 	 0.09868359565734863 	 0.013254404067993164 	 combined
2025-07-25 18:12:48.107796 test begin: paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=1, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=1, ) 	 50803218 	 1000 	 0.45018863677978516 	 0.44967126846313477 	 0.4397251605987549 	 0.4355297088623047 	 0.7488934993743896 	 0.8988349437713623 	 0.6900198459625244 	 0.4592745304107666 	 
2025-07-25 18:12:52.251474 test begin: paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=2, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=2, ) 	 50803218 	 1000 	 0.4505324363708496 	 0.4530363082885742 	 0.44046545028686523 	 0.43636274337768555 	 0.7559225559234619 	 0.9013454914093018 	 0.6972177028656006 	 0.4605133533477783 	 
2025-07-25 18:12:56.426427 test begin: paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=0, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=0, ) 	 50803218 	 1000 	 0.4473600387573242 	 0.4488346576690674 	 0.43726658821105957 	 0.4341282844543457 	 0.7413597106933594 	 0.8972434997558594 	 0.6818833351135254 	 0.4583895206451416 	 
2025-07-25 18:13:00.626020 test begin: paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=2, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=2, ) 	 50803218 	 1000 	 0.45050668716430664 	 0.4508388042449951 	 0.44048190116882324 	 0.4366886615753174 	 0.7559413909912109 	 0.9012305736541748 	 0.6976621150970459 	 0.46048545837402344 	 
2025-07-25 18:13:04.773742 test begin: paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=0, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=0, ) 	 50803218 	 1000 	 0.44750452041625977 	 0.4488098621368408 	 0.437441349029541 	 0.43462586402893066 	 0.7413802146911621 	 0.8973348140716553 	 0.6802525520324707 	 0.45842647552490234 	 
2025-07-25 18:13:08.973842 test begin: paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=1, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=1, ) 	 50803218 	 1000 	 0.44802093505859375 	 0.4478185176849365 	 0.43743276596069336 	 0.43345189094543457 	 0.7407741546630859 	 0.8959832191467285 	 0.6816797256469727 	 0.45777440071105957 	 
2025-07-25 18:13:13.106153 test begin: paddle.cummax(Tensor([100, 2080],"float32"), )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), ) 	 208000 	 1000 	 11.345654010772705 	 0.8115167617797852 	 11.326336145401001 	 0.7960803508758545 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:25.648156 test begin: paddle.cummax(Tensor([100, 2080],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), axis=-1, ) 	 208000 	 1000 	 0.17580294609069824 	 0.035057783126831055 	 0.1632084846496582 	 0.018290281295776367 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:25.934109 test begin: paddle.cummax(Tensor([100, 2080],"float32"), axis=-2, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), axis=-2, ) 	 208000 	 1000 	 0.025161266326904297 	 0.02437448501586914 	 0.012686729431152344 	 0.009488344192504883 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:26.056856 test begin: paddle.cummax(Tensor([2080, 100],"float32"), )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), ) 	 208000 	 1000 	 11.3452730178833 	 2.0844192504882812 	 11.32642674446106 	 0.7958414554595947 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:40.474393 test begin: paddle.cummax(Tensor([2080, 100],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), axis=-1, ) 	 208000 	 1000 	 0.013641595840454102 	 0.023282527923583984 	 0.0009555816650390625 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:40.593658 test begin: paddle.cummax(Tensor([2080, 100],"float32"), axis=-2, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), axis=-2, ) 	 208000 	 1000 	 0.4334719181060791 	 0.415114164352417 	 0.4209249019622803 	 0.39723753929138184 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:41.518186 test begin: paddle.cummin(Tensor([100, 508033],"float32"), axis=-1, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([100, 508033],"float32"), axis=-1, ) 	 50803300 	 1000 	 59.13575077056885 	 2.539926052093506 	 59.11846971511841 	 2.524744987487793 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:15:47.426760 test begin: paddle.cummin(Tensor([100, 508033],"float32"), axis=-2, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([100, 508033],"float32"), axis=-2, ) 	 50803300 	 1000 	 0.794959306716919 	 0.789456844329834 	 0.782686710357666 	 0.7739927768707275 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:15:57.630551 test begin: paddle.cummin(Tensor([508033, 100],"float32"), axis=-1, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([508033, 100],"float32"), axis=-1, ) 	 50803300 	 1000 	 1.3334791660308838 	 8.54465913772583 	 1.321197748184204 	 8.52929401397705 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:16:11.923647 test begin: paddle.cummin(Tensor([508033, 100],"float32"), axis=-2, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([508033, 100],"float32"), axis=-2, ) 	 50803300 	 1000 	 251.05702781677246 	 250.56467819213867 	 251.0443458557129 	 250.54928874969482 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:24:40.233364 test begin: paddle.cumprod(Tensor([2, 127009, 10, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 127009, 10, 10],"float64"), 1, ) 	 25401800 	 1000 	 66.10978674888611 	 64.24765944480896 	 66.10152411460876 	 64.23495364189148 	 258.17393946647644 	 65.98025369644165 	 0.06595778465270996 	 0.06519365310668945 	 
2025-07-25 18:32:16.493403 test begin: paddle.cumprod(Tensor([2, 3, 10, 423361],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 10, 423361],"float64"), 1, ) 	 25401660 	 1000 	 0.3028852939605713 	 0.3029470443725586 	 0.2946169376373291 	 0.2916276454925537 	 2.8461344242095947 	 2.036428213119507 	 0.00034737586975097656 	 0.0012776851654052734 	 
2025-07-25 18:32:23.151584 test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=0, ) 	 50803272 	 1000 	 0.3293893337249756 	 0.324953556060791 	 0.32087206840515137 	 0.30040860176086426 	 3.398393154144287 	 2.1172447204589844 	 0.0004787445068359375 	 0.0013279914855957031 	 
2025-07-25 18:32:33.030379 test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=1, ) 	 50803272 	 1000 	 0.3220179080963135 	 1.4816067218780518 	 0.31362032890319824 	 0.3081996440887451 	 3.253007411956787 	 2.1282317638397217 	 0.00043201446533203125 	 0.0013387203216552734 	 
2025-07-25 18:32:43.031722 test begin: paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=0, ) 	 50803290 	 1000 	 0.32938385009765625 	 0.3230855464935303 	 0.32076191902160645 	 0.2999422550201416 	 3.398815393447876 	 2.1128127574920654 	 0.0004818439483642578 	 0.0013282299041748047 	 
2025-07-25 18:32:50.882515 test begin: paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=1, ) 	 50803290 	 1000 	 0.3223268985748291 	 0.32065796852111816 	 0.3138010501861572 	 0.3093874454498291 	 3.2561020851135254 	 2.1281354427337646 	 0.00043201446533203125 	 0.0013434886932373047 	 
2025-07-25 18:32:58.597425 test begin: paddle.cumprod(Tensor([2, 3, 423361, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 10],"float64"), 1, ) 	 25401660 	 1000 	 0.3028433322906494 	 0.3029212951660156 	 0.29460763931274414 	 0.291670560836792 	 2.8491082191467285 	 2.03725004196167 	 0.00033855438232421875 	 0.0013003349304199219 	 
2025-07-25 18:33:05.217482 test begin: paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=0, ) 	 50803320 	 1000 	 0.3293919563293457 	 0.3118855953216553 	 0.3209714889526367 	 0.300586462020874 	 3.4009602069854736 	 2.120443820953369 	 0.0004820823669433594 	 0.0013203620910644531 	 
2025-07-25 18:33:13.065194 test begin: paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=1, ) 	 50803320 	 1000 	 0.32219791412353516 	 0.32010531425476074 	 0.313718318939209 	 0.30890536308288574 	 3.2566909790039062 	 2.133265733718872 	 0.0004184246063232422 	 0.0013382434844970703 	 
2025-07-25 18:33:20.841496 test begin: paddle.cumprod(Tensor([2, 423361, 3, 4, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 423361, 3, 4, 5],"float32"), dim=0, ) 	 50803320 	 1000 	 0.32938623428344727 	 0.3118903636932373 	 0.3207356929779053 	 0.30060458183288574 	 3.4022068977355957 	 2.1166906356811523 	 0.0004780292510986328 	 0.0013287067413330078 	 
2025-07-25 18:33:28.690388 test begin: paddle.cumprod(Tensor([282241, 3, 3, 4, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([282241, 3, 3, 4, 5],"float32"), dim=1, ) 	 50803380 	 1000 	 0.3274967670440674 	 0.566077470779419 	 0.3191187381744385 	 0.3112313747406006 	 3.2683324813842773 	 2.1375885009765625 	 0.00042819976806640625 	 0.001300811767578125 	 
2025-07-25 18:33:40.422229 test begin: paddle.cumprod(Tensor([84673, 3, 10, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([84673, 3, 10, 10],"float64"), 1, ) 	 25401900 	 1000 	 0.3035163879394531 	 0.30407166481018066 	 0.295360803604126 	 0.2915077209472656 	 2.845188617706299 	 2.041184663772583 	 0.0003554821014404297 	 0.0013053417205810547 	 
2025-07-25 18:33:47.084382 test begin: paddle.cumsum(Tensor([50803201],"float32"), axis=0, )
[Prof] paddle.cumsum 	 paddle.cumsum(Tensor([50803201],"float32"), axis=0, ) 	 50803201 	 1000 	 0.3506889343261719 	 0.33112120628356934 	 5.340576171875e-05 	 0.16797590255737305 	 0.4121854305267334 	 0.945338249206543 	 5.412101745605469e-05 	 0.24163079261779785 	 
2025-07-25 18:33:50.844654 test begin: paddle.deg2rad(Tensor([25401601],"int64"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 0.3784620761871338 	 0.23267745971679688 	 0.1933460235595703 	 0.21790385246276855 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:52.753259 test begin: paddle.deg2rad(Tensor([50803201],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2958362102508545 	 0.30121588706970215 	 0.28130078315734863 	 0.28347206115722656 	 0.2958061695098877 	 0.29766416549682617 	 0.2442154884338379 	 0.23219084739685059 	 
2025-07-25 18:33:55.600442 test begin: paddle.deg2rad(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2956359386444092 	 0.2978842258453369 	 0.278841495513916 	 0.2829427719116211 	 0.2957630157470703 	 0.29762792587280273 	 0.2434864044189453 	 0.23395109176635742 	 
2025-07-25 18:33:58.455091 test begin: paddle.deg2rad(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2958214282989502 	 0.2978641986846924 	 0.28092384338378906 	 0.2833240032196045 	 0.2959606647491455 	 0.2976369857788086 	 0.2388441562652588 	 0.22206544876098633 	 
2025-07-25 18:34:01.363402 test begin: paddle.deg2rad(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2958078384399414 	 0.29789113998413086 	 0.273012638092041 	 0.28322505950927734 	 0.29573726654052734 	 0.2976515293121338 	 0.24341368675231934 	 0.23346948623657227 	 
2025-07-25 18:34:04.234173 test begin: paddle.diag(Tensor([2000, 25402],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([2000, 25402],"float32"), ) 	 50804000 	 1000 	 0.008654594421386719 	 0.018070459365844727 	 1.1444091796875e-05 	 9.703636169433594e-05 	 0.1544203758239746 	 0.14037108421325684 	 0.07890200614929199 	 0.07072234153747559 	 
2025-07-25 18:34:05.397594 test begin: paddle.diag(Tensor([2000, 25402],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([2000, 25402],"float32"), offset=-1, ) 	 50804000 	 1000 	 0.008844852447509766 	 0.021014690399169922 	 1.5497207641601562e-05 	 5.984306335449219e-05 	 0.15416455268859863 	 0.14047503471374512 	 0.0787053108215332 	 0.0694284439086914 	 
2025-07-25 18:34:06.546635 test begin: paddle.diag(Tensor([2000, 25402],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([2000, 25402],"float32"), offset=1, ) 	 50804000 	 1000 	 0.008857011795043945 	 0.018023252487182617 	 2.5272369384765625e-05 	 4.76837158203125e-05 	 0.15422272682189941 	 0.14034581184387207 	 0.07875752449035645 	 0.06858611106872559 	 
2025-07-25 18:34:07.696437 test begin: paddle.diag(Tensor([25402, 2000],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([25402, 2000],"float32"), ) 	 50804000 	 1000 	 0.008619546890258789 	 0.017344951629638672 	 1.2874603271484375e-05 	 3.266334533691406e-05 	 0.15411019325256348 	 0.13889360427856445 	 0.07861328125 	 0.06895971298217773 	 
2025-07-25 18:34:08.846351 test begin: paddle.diag(Tensor([25402, 2000],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([25402, 2000],"float32"), offset=-1, ) 	 50804000 	 1000 	 0.008718013763427734 	 0.030774831771850586 	 1.0013580322265625e-05 	 8.320808410644531e-05 	 0.15385103225708008 	 0.13902783393859863 	 0.07850861549377441 	 0.06378412246704102 	 
2025-07-25 18:34:10.023011 test begin: paddle.diag(Tensor([25402, 2000],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([25402, 2000],"float32"), offset=1, ) 	 50804000 	 1000 	 0.008708953857421875 	 0.017449378967285156 	 1.0728836059570312e-05 	 3.3855438232421875e-05 	 0.15389370918273926 	 0.13895750045776367 	 0.07846665382385254 	 0.06754159927368164 	 
2025-07-25 18:34:11.212827 test begin: paddle.diag_embed(Tensor([1058401, 3, 8],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([1058401, 3, 8],"float64"), ) 	 25401624 	 1000 	 2.589763641357422 	 2.6382222175598145 	 7.104873657226562e-05 	 1.333853006362915 	 None 	 None 	 None 	 None 	 
2025-07-25 18:34:17.010175 test begin: paddle.diag_embed(Tensor([1411201, 3, 6],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([1411201, 3, 6],"float64"), ) 	 25401618 	 1000 	 2.219766855239868 	 2.2058730125427246 	 4.0531158447265625e-05 	 1.1213963031768799 	 None 	 None 	 None 	 None 	 
2025-07-25 18:34:21.993317 test begin: paddle.diag_embed(Tensor([2, 1058401, 12],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 1058401, 12],"float64"), ) 	 25401624 	 1000 	 3.8377773761749268 	 3.8302183151245117 	 6.0558319091796875e-05 	 0.9788713455200195 	 None 	 None 	 None 	 None 	 
2025-07-25 18:34:30.266623 test begin: paddle.diag_embed(Tensor([2, 1587601, 8],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 1587601, 8],"float64"), ) 	 25401616 	 1000 	 2.57656192779541 	 2.666639566421509 	 4.029273986816406e-05 	 1.389206886291504 	 None 	 None 	 None 	 None 	 
2025-07-25 18:34:36.769409 test begin: paddle.diag_embed(Tensor([2, 2116801, 6],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 2116801, 6],"float64"), ) 	 25401612 	 1000 	 2.219897747039795 	 2.198301076889038 	 5.5789947509765625e-05 	 1.121375322341919 	 None 	 None 	 None 	 None 	 
2025-07-25 18:34:41.905179 test begin: paddle.diag_embed(Tensor([705601, 3, 12],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([705601, 3, 12],"float64"), ) 	 25401636 	 1000 	 3.8286895751953125 	 3.8413569927215576 	 5.888938903808594e-05 	 0.978945255279541 	 None 	 None 	 None 	 None 	 
2025-07-25 18:34:51.815655 test begin: paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.0035958290100097656 	 0.006016969680786133 	 9.059906005859375e-06 	 5.507469177246094e-05 	 0.14852404594421387 	 0.13881707191467285 	 0.07574009895324707 	 0.0667121410369873 	 
2025-07-25 18:34:52.700302 test begin: paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), ) 	 25401744 	 1000 	 0.0035130977630615234 	 0.0045964717864990234 	 7.867813110351562e-06 	 4.6253204345703125e-05 	 0.14671039581298828 	 0.13843154907226562 	 0.0749354362487793 	 0.06729960441589355 	 
2025-07-25 18:34:53.520122 test begin: paddle.diagonal(x=Tensor([6, 117601, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 117601, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.003537893295288086 	 0.00440526008605957 	 6.9141387939453125e-06 	 1.6689300537109375e-05 	 0.14842438697814941 	 0.13855361938476562 	 0.07564902305603027 	 0.06676673889160156 	 
2025-07-25 18:34:54.350986 test begin: paddle.diagonal(x=Tensor([6, 176401, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 176401, 6, 2, 2],"float64"), ) 	 25401744 	 1000 	 0.003537893295288086 	 0.00449061393737793 	 2.002716064453125e-05 	 1.71661376953125e-05 	 0.14684247970581055 	 0.1384873390197754 	 0.07498025894165039 	 0.067230224609375 	 
2025-07-25 18:34:55.173999 test begin: paddle.diagonal(x=Tensor([6, 176401, 6, 2, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 176401, 6, 2, 2],"float64"), axis1=-1, axis2=2, ) 	 25401744 	 1000 	 0.003791332244873047 	 0.004716396331787109 	 6.198883056640625e-06 	 1.6927719116210938e-05 	 0.31397175788879395 	 0.2991654872894287 	 0.16041254997253418 	 0.15286803245544434 	 
2025-07-25 18:34:56.412822 test begin: paddle.diagonal(x=Tensor([6, 6, 117601, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 117601, 6],"float64"), ) 	 25401816 	 1000 	 0.0035986900329589844 	 0.0044901371002197266 	 9.059906005859375e-06 	 1.811981201171875e-05 	 0.19611620903015137 	 0.2943291664123535 	 0.10014891624450684 	 0.15035462379455566 	 
2025-07-25 18:34:57.587539 test begin: paddle.diagonal(x=Tensor([6, 6, 176401, 2, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 176401, 2, 2],"float64"), axis1=-1, axis2=2, ) 	 25401744 	 1000 	 0.003771543502807617 	 0.0048046112060546875 	 8.58306884765625e-06 	 3.218650817871094e-05 	 0.14709258079528809 	 0.13901591300964355 	 0.07506418228149414 	 0.06285285949707031 	 
2025-07-25 18:34:58.422156 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 117601],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 6, 117601],"float64"), ) 	 25401816 	 1000 	 0.003517627716064453 	 0.004476308822631836 	 7.152557373046875e-06 	 1.9550323486328125e-05 	 0.19615864753723145 	 0.29445457458496094 	 0.10020947456359863 	 0.15033578872680664 	 
2025-07-25 18:34:59.546012 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 58801],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 6, 2, 58801],"float64"), ) 	 25402032 	 1000 	 0.0035300254821777344 	 0.004601478576660156 	 1.6689300537109375e-05 	 5.14984130859375e-05 	 0.1964578628540039 	 0.2930643558502197 	 0.10033273696899414 	 0.14973855018615723 	 
2025-07-25 18:35:00.681402 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 58801],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 6, 2, 58801],"float64"), axis1=-1, axis2=2, ) 	 25402032 	 1000 	 0.0037899017333984375 	 0.004658222198486328 	 8.821487426757812e-06 	 1.8358230590820312e-05 	 0.15307140350341797 	 0.13991475105285645 	 0.07812333106994629 	 0.06818509101867676 	 
2025-07-25 18:35:01.553550 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 58801, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 6, 58801, 2],"float64"), ) 	 25402032 	 1000 	 0.0035552978515625 	 0.004465818405151367 	 7.62939453125e-06 	 3.1948089599609375e-05 	 0.19633150100708008 	 0.2928786277770996 	 0.10031008720397949 	 0.14960002899169922 	 
2025-07-25 18:35:02.667761 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 58801, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([6, 6, 6, 58801, 2],"float64"), axis1=-1, axis2=2, ) 	 25402032 	 1000 	 0.0037620067596435547 	 0.0046346187591552734 	 1.621246337890625e-05 	 1.71661376953125e-05 	 0.27728915214538574 	 0.27248358726501465 	 0.14165663719177246 	 0.13918352127075195 	 
2025-07-25 18:35:03.873325 test begin: paddle.diagonal_scatter(Tensor([10, 10160641],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 10160641],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 	 101606420 	 1000 	 0.32074546813964844 	 0.31604838371276855 	 0.08176016807556152 	 0.10739398002624512 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:35:06.836998 test begin: paddle.diagonal_scatter(Tensor([10, 5080321],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 5080321],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.08974862098693848 	 0.08690547943115234 	 0.02287006378173828 	 0.0294649600982666 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:35:08.527755 test begin: paddle.diagonal_scatter(Tensor([10, 5080321],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 5080321],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.32073473930358887 	 0.3159902095794678 	 0.08177733421325684 	 0.10738611221313477 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:35:10.696362 test begin: paddle.diagonal_scatter(Tensor([10160641, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10160641, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 	 101606420 	 1000 	 0.32063770294189453 	 0.31652307510375977 	 0.0817570686340332 	 0.10737419128417969 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:35:13.711034 test begin: paddle.diagonal_scatter(Tensor([5080321, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([5080321, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.08970952033996582 	 0.08679866790771484 	 0.022871732711791992 	 0.029419660568237305 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:35:15.423253 test begin: paddle.diagonal_scatter(Tensor([5080321, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([5080321, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.3206934928894043 	 0.3160068988800049 	 0.08177971839904785 	 0.10738825798034668 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:35:17.559434 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.9449594020843506 	 0.26476168632507324 	 0.3218879699707031 	 0.24263930320739746 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:19.329240 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.944878339767456 	 0.2614445686340332 	 0.32189369201660156 	 0.24230480194091797 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:21.109134 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.9447958469390869 	 0.261476993560791 	 0.3218569755554199 	 0.242445707321167 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:22.885372 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.87064528465271 	 0.26155829429626465 	 0.29659485816955566 	 0.24187445640563965 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:24.560253 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8706300258636475 	 0.2614736557006836 	 0.2965881824493408 	 0.24254369735717773 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:26.240397 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8706564903259277 	 0.2623412609100342 	 0.2966313362121582 	 0.24238967895507812 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:27.917657 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.8706040382385254 	 0.26149559020996094 	 0.2965726852416992 	 0.23908233642578125 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:29.593449 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 1.069899320602417 	 0.29958510398864746 	 0.3645057678222656 	 0.28055262565612793 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:31.493562 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 1.0699687004089355 	 0.2995564937591553 	 0.36452293395996094 	 0.28069448471069336 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:33.418310 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 1.0697133541107178 	 0.3038620948791504 	 0.36440205574035645 	 0.2806878089904785 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:37.133937 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8069772720336914 	 0.5134239196777344 	 0.2749156951904297 	 0.24366402626037598 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:40.348863 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8070452213287354 	 0.2628662586212158 	 0.2749979496002197 	 0.24399852752685547 	 None 	 None 	 None 	 None 	 
2025-07-25 18:35:41.956972 test begin: paddle.digamma(Tensor([16538, 3, 32, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([16538, 3, 32, 32],"float32"), ) 	 50804736 	 1000 	 0.9600822925567627 	 1.2848267555236816 	 0.9519555568695068 	 1.0520601272583008 	 4.489599704742432 	 1.0747969150543213 	 4.438551187515259 	 0.5490834712982178 	 
2025-07-25 18:35:53.021407 test begin: paddle.digamma(Tensor([8, 3, 32, 33076],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 32, 33076],"float64"), ) 	 25402368 	 1000 	 1.1693432331085205 	 1.1436142921447754 	 1.1612160205841064 	 1.1333444118499756 	 8.555455923080444 	 1.0874130725860596 	 8.50356149673462 	 0.5556001663208008 	 
2025-07-25 18:36:06.162392 test begin: paddle.digamma(Tensor([8, 3, 32, 66151],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 32, 66151],"float32"), ) 	 50803968 	 1000 	 0.9640612602233887 	 1.0645813941955566 	 0.9559023380279541 	 1.053980827331543 	 4.4962239265441895 	 1.0749366283416748 	 4.444481372833252 	 0.5492339134216309 	 
2025-07-25 18:36:15.521393 test begin: paddle.digamma(Tensor([8, 3, 33076, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 33076, 32],"float64"), ) 	 25402368 	 1000 	 1.1696100234985352 	 1.1434111595153809 	 1.1614410877227783 	 1.1328229904174805 	 8.555294036865234 	 1.0872416496276855 	 8.504240989685059 	 0.5555646419525146 	 
2025-07-25 18:36:28.647508 test begin: paddle.digamma(Tensor([8, 3, 66151, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 66151, 32],"float32"), ) 	 50803968 	 1000 	 0.9629490375518799 	 1.3215551376342773 	 0.9546852111816406 	 1.0735173225402832 	 4.4952332973480225 	 1.0750184059143066 	 4.443069934844971 	 0.549307107925415 	 
2025-07-25 18:36:39.680672 test begin: paddle.digamma(Tensor([8, 3101, 32, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3101, 32, 32],"float64"), ) 	 25403392 	 1000 	 1.170541524887085 	 1.1423556804656982 	 1.1622710227966309 	 1.131565809249878 	 8.554161071777344 	 1.0872294902801514 	 8.502966165542603 	 0.5555622577667236 	 
2025-07-25 18:36:52.807794 test begin: paddle.digamma(Tensor([8, 6202, 32, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 6202, 32, 32],"float32"), ) 	 50806784 	 1000 	 0.96346116065979 	 1.0656776428222656 	 0.9554460048675537 	 1.052095890045166 	 4.498740911483765 	 1.0747780799865723 	 4.4467926025390625 	 0.5491776466369629 	 
2025-07-25 18:37:02.163193 test begin: paddle.digamma(Tensor([8269, 3, 32, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8269, 3, 32, 32],"float64"), ) 	 25402368 	 1000 	 1.1739399433135986 	 1.1443893909454346 	 1.1658146381378174 	 1.1309723854064941 	 8.555365324020386 	 1.087209701538086 	 8.50406002998352 	 0.5554928779602051 	 
2025-07-25 18:37:15.295958 test begin: paddle.digamma(x=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 25402896 	 1000 	 1.1729295253753662 	 1.142756462097168 	 1.1644084453582764 	 1.1320483684539795 	 8.563068389892578 	 1.0872173309326172 	 8.510124206542969 	 0.5554871559143066 	 
2025-07-25 18:37:28.415975 test begin: paddle.digamma(x=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 25402248 	 1000 	 1.1695594787597656 	 1.1488237380981445 	 1.1611628532409668 	 1.1317007541656494 	 8.560441017150879 	 1.0873394012451172 	 8.509772300720215 	 0.5555706024169922 	 
2025-07-25 18:37:41.971807 test begin: paddle.digamma(x=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 25402248 	 1000 	 1.173125982284546 	 1.1430244445800781 	 1.1647851467132568 	 1.132453203201294 	 8.561546802520752 	 1.0871553421020508 	 8.510175228118896 	 0.5554215908050537 	 
2025-07-25 18:37:55.107278 test begin: paddle.digamma(x=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 25402248 	 1000 	 1.1700143814086914 	 1.147773265838623 	 1.1616756916046143 	 1.1345930099487305 	 8.560206890106201 	 1.0872302055358887 	 8.508506774902344 	 0.5554697513580322 	 
2025-07-25 18:38:08.234733 test begin: paddle.digamma(x=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 25402248 	 1000 	 1.1741139888763428 	 1.1465084552764893 	 1.1657004356384277 	 1.1358704566955566 	 8.560145378112793 	 1.0871899127960205 	 8.507845640182495 	 0.5554826259613037 	 
2025-07-25 18:38:21.367077 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([2540161, 10],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([10],"float64"), y=Tensor([2540161, 10],"float64"), ) 	 25401620 	 1000 	 0.4538586139678955 	 0.4543311595916748 	 0.11573338508605957 	 0.154585599899292 	 6.7491655349731445 	 2.8729469776153564 	 1.3815999031066895 	 0.2257862091064453 	 
2025-07-25 18:38:32.515698 test begin: paddle.dist(x=Tensor([113401, 1, 1, 4, 4],"float64"), y=Tensor([113401, 8, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([113401, 1, 1, 4, 4],"float64"), y=Tensor([113401, 8, 7, 1, 4],"float64"), ) 	 27216240 	 1000 	 1.3795692920684814 	 1.4035873413085938 	 0.35171079635620117 	 0.47777581214904785 	 8.537856578826904 	 11.310421228408813 	 1.744014024734497 	 0.8890786170959473 	 
2025-07-25 18:38:55.786860 test begin: paddle.dist(x=Tensor([1587601, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([1587601, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 	 25401644 	 1000 	 2.2125113010406494 	 2.2981879711151123 	 0.56429123878479 	 0.7823140621185303 	 15.25257921218872 	 19.251097440719604 	 2.5947508811950684 	 1.405292272567749 	 
2025-07-25 18:39:37.389001 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 453601, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 453601, 7, 1, 4],"float64"), ) 	 25401688 	 1000 	 1.3676695823669434 	 1.3938703536987305 	 0.34871840476989746 	 0.4745163917541504 	 9.951504230499268 	 11.316678524017334 	 1.6940653324127197 	 0.8260934352874756 	 
2025-07-25 18:40:02.029101 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 396901, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 396901, 1, 4],"float64"), ) 	 25401696 	 1000 	 1.3678147792816162 	 1.3945324420928955 	 0.3487675189971924 	 0.47468090057373047 	 9.962097406387329 	 11.31548023223877 	 1.6960585117340088 	 0.8259763717651367 	 
2025-07-25 18:40:27.393361 test begin: paddle.dist(x=Tensor([2, 1, 3175201, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 3175201, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 	 25401636 	 1000 	 3.0420730113983154 	 3.066678524017334 	 0.7757575511932373 	 1.043715238571167 	 16.22671413421631 	 20.83635950088501 	 2.761711597442627 	 1.5210041999816895 	 
2025-07-25 18:41:12.144145 test begin: paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([6350401, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([6350401, 1, 4],"float64"), ) 	 25401636 	 1000 	 2.696542263031006 	 2.7528128623962402 	 0.6876232624053955 	 0.9371678829193115 	 17.626600980758667 	 22.357996940612793 	 3.000603199005127 	 1.6320621967315674 	 
2025-07-25 18:42:00.021753 test begin: paddle.dist(x=Tensor([2, 1, 793801, 4, 4],"float64"), y=Tensor([2, 8, 793801, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 793801, 4, 4],"float64"), y=Tensor([2, 8, 793801, 1, 4],"float64"), ) 	 76204896 	 1000 	 3.7548489570617676 	 3.7487175464630127 	 0.9574699401855469 	 1.2756993770599365 	 18.17219305038452 	 24.64292335510254 	 3.7106876373291016 	 1.9369533061981201 	 
2025-07-25 18:42:53.931564 test begin: paddle.dist(x=Tensor([2, 793801, 1, 4, 4],"float64"), y=Tensor([2, 793801, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 793801, 1, 4, 4],"float64"), y=Tensor([2, 793801, 7, 1, 4],"float64"), ) 	 69854488 	 1000 	 2.5210485458374023 	 2.554438591003418 	 0.6430294513702393 	 0.8695557117462158 	 15.27657961845398 	 20.172715425491333 	 3.1199347972869873 	 1.668419599533081 	 
2025-07-25 18:43:38.045055 test begin: paddle.dist(x=Tensor([25401601],"float64"), y=Tensor([4, 25401601],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([25401601],"float64"), y=Tensor([4, 25401601],"float64"), ) 	 127008005 	 1000 	 2.3449745178222656 	 2.353533983230591 	 0.5979578495025635 	 0.8007669448852539 	 8.492080688476562 	 12.603779077529907 	 2.1673972606658936 	 1.0732035636901855 	 
2025-07-25 18:44:06.751825 test begin: paddle.dist(x=Tensor([6350401],"float64"), y=Tensor([4, 6350401],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([6350401],"float64"), y=Tensor([4, 6350401],"float64"), ) 	 31752005 	 1000 	 0.6014974117279053 	 0.5986778736114502 	 0.1534116268157959 	 0.20373821258544922 	 2.145944118499756 	 3.1897387504577637 	 0.5476932525634766 	 0.2716491222381592 	 
2025-07-25 18:44:14.022821 test begin: paddle.divide(Tensor([128, 396901],"float32"), Tensor([1, 396901],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([128, 396901],"float32"), Tensor([1, 396901],"float32"), ) 	 51200229 	 1000 	 0.29970240592956543 	 0.311464786529541 	 0.28914332389831543 	 0.2992894649505615 	 0.8012306690216064 	 1.8374948501586914 	 0.40934300422668457 	 0.3128056526184082 	 
2025-07-25 18:44:18.969057 test begin: paddle.divide(Tensor([51059, 995],"float32"), Tensor([1, 995],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([51059, 995],"float32"), Tensor([1, 995],"float32"), ) 	 50804700 	 1000 	 0.2970714569091797 	 0.309781551361084 	 0.2865285873413086 	 0.2975194454193115 	 0.9018914699554443 	 1.8610775470733643 	 0.3069477081298828 	 0.271681547164917 	 
2025-07-25 18:44:24.004618 test begin: paddle.divide(Tensor([51059, 995],"float32"), Tensor([51059, 995],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([51059, 995],"float32"), Tensor([51059, 995],"float32"), ) 	 101607410 	 1000 	 0.4503622055053711 	 0.4519636631011963 	 0.44046831130981445 	 0.4376804828643799 	 1.1560320854187012 	 2.0917043685913086 	 1.0952317714691162 	 0.4275703430175781 	 
2025-07-25 18:44:30.640267 test begin: paddle.divide(Tensor([512, 99226],"float32"), Tensor([1, 99226],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([512, 99226],"float32"), Tensor([1, 99226],"float32"), ) 	 50902938 	 1000 	 0.29549455642700195 	 1.1984100341796875 	 0.28499484062194824 	 0.2929515838623047 	 0.8428020477294922 	 1.8332936763763428 	 0.2867622375488281 	 0.3121035099029541 	 
2025-07-25 18:44:38.084051 test begin: paddle.divide(Tensor([544, 93431],"float32"), Tensor([1, 93431],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([544, 93431],"float32"), Tensor([1, 93431],"float32"), ) 	 50919895 	 1000 	 0.29562902450561523 	 1.516019344329834 	 0.2850766181945801 	 0.2981438636779785 	 0.8933982849121094 	 1.8388891220092773 	 0.3040025234222412 	 0.31305861473083496 	 
2025-07-25 18:44:44.872674 test begin: paddle.divide(Tensor([544, 93431],"float32"), Tensor([544, 93431],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([544, 93431],"float32"), Tensor([544, 93431],"float32"), ) 	 101652928 	 1000 	 0.45081043243408203 	 0.45160484313964844 	 0.4410684108734131 	 0.43816304206848145 	 1.155557632446289 	 2.0927093029022217 	 1.0928549766540527 	 0.4277763366699219 	 
2025-07-25 18:44:51.553391 test begin: paddle.divide(x=Tensor([16934401, 3],"float32"), y=Tensor([3],"float32"), )
[Prof] paddle.divide 	 paddle.divide(x=Tensor([16934401, 3],"float32"), y=Tensor([3],"float32"), ) 	 50803206 	 1000 	 0.29658079147338867 	 0.3096902370452881 	 0.28577518463134766 	 0.29753637313842773 	 5.666629076004028 	 1.8553287982940674 	 1.93165922164917 	 0.27079272270202637 	 
2025-07-25 18:45:01.395543 test begin: paddle.divide(x=Tensor([187679, 271],"float32"), y=Tensor([271],"float32"), )
[Prof] paddle.divide 	 paddle.divide(x=Tensor([187679, 271],"float32"), y=Tensor([271],"float32"), ) 	 50861280 	 1000 	 0.2972595691680908 	 0.31006526947021484 	 0.28630995750427246 	 0.2975647449493408 	 1.0054938793182373 	 1.8374183177947998 	 0.3423192501068115 	 0.2682833671569824 	 
2025-07-25 18:45:06.517334 test begin: paddle.dot(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
Warning: The core code of paddle.dot is too complex.
[Prof] paddle.dot 	 paddle.dot(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 6.7540364265441895 	 0.2934706211090088 	 6.7448577880859375 	 0.1499340534210205 	 0.6253929138183594 	 0.6002998352050781 	 0.31953859329223633 	 0.3067007064819336 	 
2025-07-25 18:45:15.942570 test begin: paddle.dot(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), )
[Prof] paddle.dot 	 paddle.dot(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.2960648536682129 	 0.2932729721069336 	 0.28694844245910645 	 0.14981508255004883 	 0.7109708786010742 	 0.6037299633026123 	 0.3632833957672119 	 0.3084566593170166 	 
2025-07-25 18:45:19.502524 test begin: paddle.dot(x=Tensor([5080320],"int32"), y=Tensor([5080320],"int32"), )
[Prof] paddle.dot 	 paddle.dot(x=Tensor([5080320],"int32"), y=Tensor([5080320],"int32"), ) 	 10160640 	 1000 	 208.75139832496643 	 0.03884696960449219 	 208.74227142333984 	 0.016324996948242188 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:48.705790 test begin: paddle.dsplit(Tensor([1411201, 3, 6],"int64"), list[-1,1,3,], )
W0725 18:48:49.726305 137284 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([1411201, 3, 6],"int64"), list[-1,1,3,], ) 	 25401618 	 1000 	 0.031917572021484375 	 0.00978231430053711 	 2.4080276489257812e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:49.908973 test begin: paddle.dsplit(Tensor([1411201, 3, 6],"int64"), list[-1,], )
W0725 18:48:50.639569 137302 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([1411201, 3, 6],"int64"), list[-1,], ) 	 25401618 	 1000 	 0.018094301223754883 	 0.011365890502929688 	 2.8133392333984375e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:50.772576 test begin: paddle.dsplit(Tensor([1411201, 3, 6],"int64"), list[2,4,], )
W0725 18:48:51.514168 137313 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([1411201, 3, 6],"int64"), list[2,4,], ) 	 25401618 	 1000 	 0.025467395782470703 	 0.008308172225952148 	 2.2411346435546875e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:51.659610 test begin: paddle.dsplit(Tensor([4, 1058401, 6],"int64"), list[-1,1,3,], )
W0725 18:48:52.653551 137314 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([4, 1058401, 6],"int64"), list[-1,1,3,], ) 	 25401624 	 1000 	 0.031010150909423828 	 0.009602546691894531 	 2.5987625122070312e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:52.871128 test begin: paddle.dsplit(Tensor([4, 1058401, 6],"int64"), list[-1,], )
W0725 18:48:53.604514 137325 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([4, 1058401, 6],"int64"), list[-1,], ) 	 25401624 	 1000 	 0.01683497428894043 	 0.007190227508544922 	 1.0728836059570312e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:53.729566 test begin: paddle.dsplit(Tensor([4, 1058401, 6],"int64"), list[2,4,], )
W0725 18:48:54.484215 137329 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([4, 1058401, 6],"int64"), list[2,4,], ) 	 25401624 	 1000 	 0.02353978157043457 	 0.008339405059814453 	 1.2159347534179688e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:54.621583 test begin: paddle.dsplit(Tensor([4, 3, 2116801],"int64"), list[-1,1,3,], )
W0725 18:48:55.719305 137336 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([4, 3, 2116801],"int64"), list[-1,1,3,], ) 	 25401612 	 1000 	 0.030815839767456055 	 0.009472131729125977 	 1.811981201171875e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:55.915293 test begin: paddle.dsplit(Tensor([4, 3, 2116801],"int64"), list[-1,], )
W0725 18:48:56.652570 137363 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([4, 3, 2116801],"int64"), list[-1,], ) 	 25401612 	 1000 	 0.017241477966308594 	 0.00718998908996582 	 2.8848648071289062e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:56.775702 test begin: paddle.dsplit(Tensor([4, 3, 2116801],"int64"), list[2,4,], )
W0725 18:48:57.512467 137367 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([4, 3, 2116801],"int64"), list[2,4,], ) 	 25401612 	 1000 	 0.02353668212890625 	 0.008300065994262695 	 1.5974044799804688e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:48:57.636212 test begin: paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9421982765197754 	 0.9415810108184814 	 0.9227707386016846 	 0.923851490020752 	 0.955498456954956 	 0.07682681083679199 	 0.8873562812805176 	 5.078315734863281e-05 	 
2025-07-25 18:49:05.533913 test begin: paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.32054924964904785 	 0.3130357265472412 	 0.3057525157928467 	 0.1598520278930664 	 0.3185451030731201 	 0.06013655662536621 	 0.22823309898376465 	 3.981590270996094e-05 	 
2025-07-25 18:49:07.635910 test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401900 	 1000 	 0.3224771022796631 	 0.32244396209716797 	 0.3033154010772705 	 0.30796360969543457 	 0.32304930686950684 	 0.0794978141784668 	 0.24837899208068848 	 4.792213439941406e-05 	 
2025-07-25 18:49:09.742281 test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401900 	 1000 	 0.3224329948425293 	 0.3289332389831543 	 0.3018686771392822 	 0.3145167827606201 	 0.32308030128479004 	 0.07705545425415039 	 0.2542226314544678 	 3.62396240234375e-05 	 
2025-07-25 18:49:11.854644 test begin: paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9702997207641602 	 0.94162917137146 	 0.9512588977813721 	 0.9237477779388428 	 0.9692776203155518 	 0.07735610008239746 	 0.8899257183074951 	 4.410743713378906e-05 	 
2025-07-25 18:49:18.138841 test begin: paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401660 	 1000 	 0.32225894927978516 	 0.316300630569458 	 0.3028683662414551 	 0.3004639148712158 	 0.3221583366394043 	 0.07840514183044434 	 0.253201961517334 	 6.246566772460938e-05 	 
2025-07-25 18:49:20.261167 test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401660 	 1000 	 0.32219839096069336 	 0.32593441009521484 	 0.3033714294433594 	 0.308551549911499 	 0.322537899017334 	 0.08068728446960449 	 0.2534148693084717 	 0.00018024444580078125 	 
2025-07-25 18:49:22.369766 test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 25401660 	 1000 	 0.3222177028656006 	 0.3201296329498291 	 0.3030271530151367 	 0.30606627464294434 	 0.32230281829833984 	 0.07750821113586426 	 0.2329115867614746 	 4.220008850097656e-05 	 
2025-07-25 18:49:24.458328 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401900 	 1000 	 0.3224925994873047 	 0.3187899589538574 	 0.3035271167755127 	 0.30010056495666504 	 0.3224222660064697 	 0.07870149612426758 	 0.23327183723449707 	 4.363059997558594e-05 	 
2025-07-25 18:49:26.592632 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9682881832122803 	 0.9465045928955078 	 0.9490060806274414 	 0.9316139221191406 	 0.9676473140716553 	 0.07860374450683594 	 0.8986983299255371 	 5.054473876953125e-05 	 
2025-07-25 18:49:32.733880 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.322070837020874 	 0.3183283805847168 	 0.3067002296447754 	 0.15990376472473145 	 0.32195091247558594 	 0.06068062782287598 	 0.2664170265197754 	 5.888938903808594e-05 	 
2025-07-25 18:49:34.842186 test begin: paddle.dstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 1.5554721355438232 	 2.4161856174468994 	 1.5359253883361816 	 2.3858377933502197 	 2.6080660820007324 	 0.09326410293579102 	 2.539637804031372 	 6.508827209472656e-05 	 
2025-07-25 18:49:45.013362 test begin: paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9624245166778564 	 2.523165464401245 	 0.9431393146514893 	 2.5068864822387695 	 1.070265769958496 	 0.08109378814697266 	 0.9951932430267334 	 5.936622619628906e-05 	 
2025-07-25 18:49:52.907289 test begin: paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3902902603149414 	 0.3131113052368164 	 0.37546610832214355 	 0.159898042678833 	 0.3961961269378662 	 0.058753013610839844 	 0.3397328853607178 	 4.267692565917969e-05 	 
2025-07-25 18:49:55.125959 test begin: paddle.dstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 1.555220127105713 	 2.402482032775879 	 1.5361065864562988 	 2.3879878520965576 	 2.6066083908081055 	 0.0759437084197998 	 2.533220052719116 	 3.981590270996094e-05 	 
2025-07-25 18:50:07.083024 test begin: paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9624254703521729 	 2.53363037109375 	 0.9433431625366211 	 2.506049871444702 	 1.0659403800964355 	 0.0964362621307373 	 0.997460126876831 	 6.699562072753906e-05 	 
2025-07-25 18:50:14.979216 test begin: paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3895905017852783 	 0.3130817413330078 	 0.37468433380126953 	 0.15991449356079102 	 0.3969290256500244 	 0.05996537208557129 	 0.33881282806396484 	 4.57763671875e-05 	 
2025-07-25 18:50:17.279266 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([200, 8, 498, 498],"float32"), Tensor([200, 8, 498, 64],"float32"), )
Warning: The core code of paddle.einsum is too complex.
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([200, 8, 498, 498],"float32"), Tensor([200, 8, 498, 64],"float32"), ) 	 447801600 	 1000 	 6.078718423843384 	 6.0824220180511475 	 6.019547700881958 	 6.026900053024292 	 12.346080780029297 	 9.511657238006592 	 2.524862766265869 	 4.860010862350464 	 
2025-07-25 18:50:59.957096 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([209, 8, 477, 477],"float32"), Tensor([209, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([209, 8, 477, 477],"float32"), Tensor([209, 8, 477, 64],"float32"), ) 	 431471304 	 1000 	 6.0843305587768555 	 6.016400575637817 	 6.025452375411987 	 5.9605467319488525 	 12.34928011894226 	 9.601407289505005 	 2.5238871574401855 	 4.905444383621216 	 
2025-07-25 18:51:42.725506 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([218, 8, 457, 457],"float32"), Tensor([218, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([218, 8, 457, 457],"float32"), Tensor([218, 8, 457, 64],"float32"), ) 	 415241168 	 1000 	 6.07674503326416 	 6.074416160583496 	 6.019757986068726 	 6.02101469039917 	 12.427703380584717 	 9.829699754714966 	 2.541508436203003 	 5.022588729858398 	 
2025-07-25 18:52:25.219950 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([26, 8, 498, 498],"float32"), Tensor([26, 8, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([26, 8, 498, 498],"float32"), Tensor([26, 8, 498, 64],"float32"), ) 	 58214208 	 1000 	 0.8229458332061768 	 0.8230206966400146 	 0.7605247497558594 	 0.7709295749664307 	 1.6565742492675781 	 1.2795498371124268 	 0.3387582302093506 	 0.6536662578582764 	 
2025-07-25 18:52:30.911951 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([28, 8, 477, 477],"float32"), Tensor([28, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([28, 8, 477, 477],"float32"), Tensor([28, 8, 477, 64],"float32"), ) 	 57804768 	 1000 	 0.8788418769836426 	 0.8840079307556152 	 0.8230559825897217 	 0.8245315551757812 	 1.7486605644226074 	 1.370593547821045 	 0.3576076030731201 	 0.7001702785491943 	 
2025-07-25 18:52:37.947870 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 54, 498, 498],"float32"), Tensor([30, 54, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 54, 498, 498],"float32"), Tensor([30, 54, 498, 64],"float32"), ) 	 453399120 	 1000 	 6.0975916385650635 	 6.097568511962891 	 6.040484666824341 	 6.042155027389526 	 12.433228492736816 	 9.561539888381958 	 2.5431458950042725 	 4.885133504867554 	 
2025-07-25 18:53:20.768801 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 56, 477, 477],"float32"), Tensor([30, 56, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 56, 477, 477],"float32"), Tensor([30, 56, 477, 64],"float32"), ) 	 433535760 	 1000 	 6.079946756362915 	 6.080198764801025 	 6.022234916687012 	 6.027971506118774 	 12.435389041900635 	 9.680049180984497 	 2.5430428981781006 	 4.946203231811523 	 
2025-07-25 18:54:03.363067 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 58, 457, 457],"float32"), Tensor([30, 58, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 58, 457, 457],"float32"), Tensor([30, 58, 457, 64],"float32"), ) 	 414288780 	 1000 	 6.067786693572998 	 6.068892002105713 	 6.007970571517944 	 6.011586427688599 	 12.403462886810303 	 9.81470799446106 	 2.5366015434265137 	 5.01510214805603 	 
2025-07-25 18:54:46.441585 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 7, 498, 498],"float32"), Tensor([30, 7, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 7, 498, 498],"float32"), Tensor([30, 7, 498, 64],"float32"), ) 	 58773960 	 1000 	 0.8231444358825684 	 0.829301118850708 	 0.7671318054199219 	 0.7673087120056152 	 1.669506311416626 	 1.2844669818878174 	 0.34137582778930664 	 0.6562421321868896 	 
2025-07-25 18:54:52.204715 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 426, 498],"float32"), Tensor([30, 8, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 426, 498],"float32"), Tensor([30, 8, 498, 64],"float32"), ) 	 58564800 	 1000 	 0.9243268966674805 	 0.9268279075622559 	 0.8684051036834717 	 0.8687913417816162 	 1.6961431503295898 	 1.323108434677124 	 0.3468482494354248 	 0.6759068965911865 	 
2025-07-25 18:54:58.185408 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 444, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 444, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), ) 	 58155840 	 1000 	 0.881873607635498 	 0.8830163478851318 	 0.8170478343963623 	 0.828599214553833 	 1.7250893115997314 	 1.3520655632019043 	 0.35273194313049316 	 0.6907715797424316 	 
2025-07-25 18:55:04.129732 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 457, 457],"float32"), Tensor([30, 8, 457, 464],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 457, 457],"float32"), Tensor([30, 8, 457, 464],"float32"), ) 	 101015280 	 1000 	 3.371079206466675 	 3.371615171432495 	 3.315187454223633 	 3.3174896240234375 	 7.6325178146362305 	 6.75800895690918 	 1.5606276988983154 	 3.4531285762786865 	 
2025-07-25 18:55:27.940828 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 464, 457],"float32"), Tensor([30, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 464, 457],"float32"), Tensor([30, 8, 457, 64],"float32"), ) 	 57911040 	 1000 	 0.8530411720275879 	 0.853205680847168 	 0.7801163196563721 	 0.8007416725158691 	 1.7485053539276123 	 1.379870891571045 	 0.35750293731689453 	 0.7049672603607178 	 
2025-07-25 18:55:33.847572 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 444],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 444],"float32"), ) 	 105436080 	 1000 	 3.4885599613189697 	 3.502253293991089 	 3.4178073406219482 	 3.4304304122924805 	 7.6692962646484375 	 6.758409023284912 	 1.5681822299957275 	 3.4533345699310303 	 
2025-07-25 18:55:58.018170 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), ) 	 61933680 	 1000 	 0.8820698261260986 	 0.8835330009460449 	 0.8224320411682129 	 0.8198199272155762 	 1.8088948726654053 	 1.4076721668243408 	 0.36990952491760254 	 0.7191281318664551 	 
2025-07-25 18:56:04.194920 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 498, 498],"float32"), Tensor([30, 8, 498, 426],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 498, 498],"float32"), Tensor([30, 8, 498, 426],"float32"), ) 	 110436480 	 1000 	 3.6607606410980225 	 3.662709951400757 	 3.6049108505249023 	 3.6067001819610596 	 7.753893852233887 	 6.816995859146118 	 1.5857689380645752 	 3.482935667037964 	 
2025-07-25 18:56:28.964106 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 9, 457, 457],"float32"), Tensor([30, 9, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 9, 457, 457],"float32"), Tensor([30, 9, 457, 64],"float32"), ) 	 64286190 	 1000 	 0.9462554454803467 	 0.9525086879730225 	 0.8905515670776367 	 0.8872373104095459 	 1.9486496448516846 	 1.5385587215423584 	 0.3984696865081787 	 0.7860851287841797 	 
2025-07-25 18:56:37.319199 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([31, 8, 457, 457],"float32"), Tensor([31, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([31, 8, 457, 457],"float32"), Tensor([31, 8, 457, 64],"float32"), ) 	 59048056 	 1000 	 0.942467451095581 	 0.9427199363708496 	 0.8855786323547363 	 0.8895082473754883 	 1.865386962890625 	 1.4880874156951904 	 0.3814690113067627 	 0.7601828575134277 	 
2025-07-25 18:56:43.643742 test begin: paddle.empty_like(Tensor([101606401],"uint8"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([101606401],"uint8"), ) 	 101606401 	 1000 	 0.011943340301513672 	 0.017782926559448242 	 8.106231689453125e-06 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:44.607673 test begin: paddle.empty_like(Tensor([4096, 12404],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([4096, 12404],"bool"), ) 	 50806784 	 1000 	 0.01184701919555664 	 0.0055980682373046875 	 7.62939453125e-06 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:45.340563 test begin: paddle.empty_like(Tensor([4096, 12404],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([4096, 12404],"float32"), ) 	 50806784 	 1000 	 0.012124300003051758 	 0.005549430847167969 	 1.7642974853515625e-05 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:46.185433 test begin: paddle.empty_like(Tensor([793801, 64],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([793801, 64],"bool"), ) 	 50803264 	 1000 	 0.011925220489501953 	 0.007757663726806641 	 9.298324584960938e-06 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:46.934087 test begin: paddle.empty_like(Tensor([793801, 64],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([793801, 64],"float32"), ) 	 50803264 	 1000 	 0.011837244033813477 	 0.577509880065918 	 9.5367431640625e-06 	 6.794929504394531e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:49.469003 test begin: paddle.equal(Tensor([4148, 6124],"int64"), Tensor([4148, 6124],"int64"), )
[Prof] paddle.equal 	 paddle.equal(Tensor([4148, 6124],"int64"), Tensor([4148, 6124],"int64"), ) 	 50804704 	 1000 	 0.30924558639526367 	 0.33353471755981445 	 0.29837536811828613 	 0.30150794982910156 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:52.361642 test begin: paddle.equal(Tensor([416, 61062],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([416, 61062],"int64"), 0, ) 	 25401792 	 1000 	 0.1778421401977539 	 0.17108416557312012 	 0.09084796905517578 	 0.1533372402191162 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:53.130293 test begin: paddle.equal(Tensor([512, 49613],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([512, 49613],"int64"), 0, ) 	 25401856 	 1000 	 0.17707157135009766 	 0.1681818962097168 	 0.09046053886413574 	 0.15393853187561035 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:53.897961 test begin: paddle.equal(Tensor([846721, 30],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([846721, 30],"int64"), 0, ) 	 25401630 	 1000 	 0.17790579795837402 	 0.1681673526763916 	 0.09086847305297852 	 0.1537473201751709 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:54.662147 test begin: paddle.equal(Tensor([846721, 30],"int64"), Tensor([846721, 30],"int64"), )
[Prof] paddle.equal 	 paddle.equal(Tensor([846721, 30],"int64"), Tensor([846721, 30],"int64"), ) 	 50803260 	 1000 	 0.3105924129486084 	 0.3130323886871338 	 0.2994976043701172 	 0.3018205165863037 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:56.111776 test begin: paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([1, 2, 10, 2540161],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([1, 2, 10, 2540161],"bool"), ) 	 50803540 	 1000 	 0.017191171646118164 	 0.0025835037231445312 	 1.3113021850585938e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:56.837864 test begin: paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), ) 	 50803552 	 1000 	 0.017144203186035156 	 0.0026047229766845703 	 1.52587890625e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:57.574890 test begin: paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), ) 	 50803680 	 1000 	 0.01733994483947754 	 0.0025594234466552734 	 2.1219253540039062e-05 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:58.328165 test begin: paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 50803840 	 1000 	 0.017215490341186523 	 0.0026090145111083984 	 1.7404556274414062e-05 	 1.430511474609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:59.065043 test begin: paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 16],"bool"), ) 	 50803540 	 1000 	 0.017146587371826172 	 0.002595663070678711 	 8.344650268554688e-06 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:56:59.813795 test begin: paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 2540161],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 2540161],"bool"), ) 	 101606440 	 1000 	 0.16932320594787598 	 0.20386004447937012 	 0.05762457847595215 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:01.653976 test begin: paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 10, 16],"bool"), ) 	 50803552 	 1000 	 0.017316102981567383 	 0.0025963783264160156 	 2.1696090698242188e-05 	 1.430511474609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:02.403407 test begin: paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), ) 	 101606464 	 1000 	 0.1693134307861328 	 0.20489192008972168 	 0.05762529373168945 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:04.227936 test begin: paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 2, 10, 16],"bool"), ) 	 50803680 	 1000 	 0.01701188087463379 	 0.002604961395263672 	 7.3909759521484375e-06 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:04.988808 test begin: paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), ) 	 101606720 	 1000 	 0.16928458213806152 	 0.2047414779663086 	 0.05761575698852539 	 7.152557373046875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:06.787827 test begin: paddle.equal_all(Tensor([128],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([128],"float32"), Tensor([50803201],"float32"), ) 	 50803329 	 1000 	 0.0232696533203125 	 0.002617359161376953 	 2.1219253540039062e-05 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:07.677196 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([1, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([1, 2, 10, 16],"bool"), ) 	 50803840 	 1000 	 0.018233537673950195 	 0.0026161670684814453 	 2.3365020751953125e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:08.402209 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 101607040 	 1000 	 0.16896414756774902 	 0.20518803596496582 	 0.05749940872192383 	 6.365776062011719e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:10.206084 test begin: paddle.equal_all(Tensor([16, 16],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 16],"float32"), Tensor([16, 3175201],"float32"), ) 	 50803472 	 1000 	 0.01709723472595215 	 0.0026688575744628906 	 8.344650268554688e-06 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:11.062199 test begin: paddle.equal_all(Tensor([16, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 50803472 	 1000 	 0.02280449867248535 	 0.0026504993438720703 	 3.0040740966796875e-05 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:11.935719 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 16],"float32"), ) 	 50803472 	 1000 	 0.017034530639648438 	 0.002614736557006836 	 1.5497207641601562e-05 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:12.789128 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 3175201],"float32"), ) 	 101606432 	 1000 	 0.3797919750213623 	 0.41798973083496094 	 0.12920236587524414 	 7.05718994140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:15.333941 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([16, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([16, 16],"float32"), ) 	 50803472 	 1000 	 0.017002344131469727 	 0.002637147903442383 	 8.821487426757812e-06 	 1.430511474609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:16.178904 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 101606432 	 1000 	 0.37973570823669434 	 0.41766929626464844 	 0.12916016578674316 	 8.96453857421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:18.670378 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([128],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([128],"float32"), ) 	 50803329 	 1000 	 0.017207860946655273 	 0.002609729766845703 	 3.0517578125e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:19.541456 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.3797590732574463 	 0.4176812171936035 	 0.12916326522827148 	 6.794929504394531e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:57:22.029681 test begin: paddle.erf(Tensor([11, 2309237],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([11, 2309237],"float64"), ) 	 25401607 	 1000 	 0.33739566802978516 	 0.30875515937805176 	 0.328702449798584 	 0.29225921630859375 	 0.44774365425109863 	 1.6377367973327637 	 0.3934617042541504 	 0.3347916603088379 	 
2025-07-25 18:57:25.935099 test begin: paddle.erf(Tensor([1494212, 17],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([1494212, 17],"float64"), ) 	 25401604 	 1000 	 0.3373849391937256 	 0.3036928176879883 	 0.3286857604980469 	 0.2922980785369873 	 0.4477059841156006 	 1.637571096420288 	 0.39530181884765625 	 0.33481931686401367 	 
2025-07-25 18:57:29.738555 test begin: paddle.erf(Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.3380894660949707 	 0.3036668300628662 	 0.32681703567504883 	 0.29210400581359863 	 0.4482605457305908 	 1.6375646591186523 	 0.39302635192871094 	 0.3347971439361572 	 
2025-07-25 18:57:33.551633 test begin: paddle.erf(Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3380148410797119 	 0.5456056594848633 	 0.3292722702026367 	 0.2914748191833496 	 0.448239803314209 	 1.6377365589141846 	 0.3961219787597656 	 0.334810733795166 	 
2025-07-25 18:57:41.701103 test begin: paddle.erf(Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.33772945404052734 	 0.3068253993988037 	 0.32906293869018555 	 0.29227614402770996 	 0.4477262496948242 	 1.637648582458496 	 0.3958418369293213 	 0.33481311798095703 	 
2025-07-25 18:57:45.498085 test begin: paddle.erf(Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.3372838497161865 	 0.3074004650115967 	 0.32853174209594727 	 0.29215097427368164 	 0.4476919174194336 	 1.6376240253448486 	 0.39076972007751465 	 0.3347780704498291 	 
2025-07-25 18:57:49.335351 test begin: paddle.erf(Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.3375980854034424 	 0.3048548698425293 	 0.32892847061157227 	 0.2892014980316162 	 0.4476163387298584 	 1.6376667022705078 	 0.39387941360473633 	 0.334794282913208 	 
2025-07-25 18:57:54.816422 test begin: paddle.erf(Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.33808279037475586 	 0.8916044235229492 	 0.32888245582580566 	 0.291964054107666 	 0.4482424259185791 	 1.6376502513885498 	 0.39619994163513184 	 0.33478689193725586 	 
2025-07-25 18:58:00.726876 test begin: paddle.erf(Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3374595642089844 	 0.30367255210876465 	 0.3287179470062256 	 0.2922801971435547 	 0.44765496253967285 	 1.6377496719360352 	 0.3953249454498291 	 0.33478307723999023 	 
2025-07-25 18:58:04.573968 test begin: paddle.erf(Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.3374309539794922 	 0.30367159843444824 	 0.32860469818115234 	 0.29221105575561523 	 0.4476754665374756 	 1.6376676559448242 	 0.3883821964263916 	 0.33478474617004395 	 
2025-07-25 18:58:08.377786 test begin: paddle.erf(Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.3373606204986572 	 0.3036658763885498 	 0.32866382598876953 	 0.29166746139526367 	 0.44768190383911133 	 1.637712001800537 	 0.3950507640838623 	 0.33484530448913574 	 
2025-07-25 18:58:12.183140 test begin: paddle.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.3315098285675049 	 0.3116171360015869 	 0.3227853775024414 	 0.298370361328125 	 0.44769978523254395 	 1.64247727394104 	 0.39582157135009766 	 0.33577966690063477 	 
2025-07-25 18:58:16.126397 test begin: paddle.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3319101333618164 	 0.31141185760498047 	 0.31992197036743164 	 0.29857540130615234 	 0.44778013229370117 	 1.6422464847564697 	 0.39458537101745605 	 0.33576035499572754 	 
2025-07-25 18:58:19.957323 test begin: paddle.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.33191442489624023 	 0.30922627449035645 	 0.32318711280822754 	 0.29866623878479004 	 0.44709348678588867 	 1.6423873901367188 	 0.3937051296234131 	 0.33571958541870117 	 
2025-07-25 18:58:23.747308 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.3320634365081787 	 0.30892515182495117 	 0.3233957290649414 	 0.29848265647888184 	 0.44708871841430664 	 1.6426303386688232 	 0.3953852653503418 	 0.3357834815979004 	 
2025-07-25 18:58:27.596825 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.33187174797058105 	 0.3094291687011719 	 0.32314205169677734 	 0.2988135814666748 	 0.44708251953125 	 1.6422502994537354 	 0.39308881759643555 	 0.33571934700012207 	 
2025-07-25 18:58:31.410021 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.3319852352142334 	 0.30917930603027344 	 0.3233029842376709 	 0.29845738410949707 	 0.4477226734161377 	 1.6426751613616943 	 0.3951096534729004 	 0.3358793258666992 	 
2025-07-25 18:58:35.290371 test begin: paddle.erfinv(x=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3175201],"float64"), ) 	 25401608 	 1000 	 0.3318753242492676 	 0.32275867462158203 	 0.3233065605163574 	 0.29804039001464844 	 0.4469797611236572 	 1.6424715518951416 	 0.39338016510009766 	 0.33579015731811523 	 
2025-07-25 18:58:41.324061 test begin: paddle.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3320634365081787 	 0.30911755561828613 	 0.32337045669555664 	 0.29854249954223633 	 0.4470181465148926 	 1.642651081085205 	 0.3947141170501709 	 0.3357853889465332 	 
2025-07-25 18:58:45.183963 test begin: paddle.erfinv(x=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2116801, 3],"float64"), ) 	 25401612 	 1000 	 0.33205580711364746 	 0.30953001976013184 	 0.3231666088104248 	 0.2984130382537842 	 0.447094202041626 	 1.6424243450164795 	 0.39309215545654297 	 0.33577823638916016 	 
2025-07-25 18:58:49.022962 test begin: paddle.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.33203887939453125 	 0.30971646308898926 	 0.3218975067138672 	 0.29918622970581055 	 0.44699859619140625 	 1.6423625946044922 	 0.3939857482910156 	 0.33571863174438477 	 
2025-07-25 18:58:52.853304 test begin: paddle.erfinv(x=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.332141637802124 	 0.3091742992401123 	 0.3235025405883789 	 0.2987029552459717 	 0.44703102111816406 	 1.6423969268798828 	 0.3943595886230469 	 0.33580756187438965 	 
2025-07-25 18:58:56.639575 test begin: paddle.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.33492588996887207 	 0.3092827796936035 	 0.325897216796875 	 0.2986443042755127 	 0.4471096992492676 	 1.6423625946044922 	 0.3947014808654785 	 0.33574604988098145 	 
2025-07-25 18:59:01.834369 test begin: paddle.exp(Tensor([125, 1, 640, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([125, 1, 640, 640],"float32"), ) 	 51200000 	 1000 	 0.29805541038513184 	 0.3008437156677246 	 0.28978943824768066 	 0.2891051769256592 	 0.4539978504180908 	 0.4500136375427246 	 0.40114402770996094 	 0.38002657890319824 	 
2025-07-25 18:59:05.299948 test begin: paddle.exp(Tensor([13, 243, 1007, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 243, 1007, 16],"float32"), ) 	 50897808 	 1000 	 0.29605865478515625 	 0.2984037399291992 	 0.2854490280151367 	 0.2869079113006592 	 0.45068907737731934 	 0.44731879234313965 	 0.39765453338623047 	 0.37751078605651855 	 
2025-07-25 18:59:08.480710 test begin: paddle.exp(Tensor([13, 64, 1007, 61],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 64, 1007, 61],"float32"), ) 	 51107264 	 1000 	 0.29732441902160645 	 0.30239272117614746 	 0.28879213333129883 	 0.2881627082824707 	 0.45244812965393066 	 0.44916439056396484 	 0.39404988288879395 	 0.3797914981842041 	 
2025-07-25 18:59:11.679223 test begin: paddle.exp(Tensor([13, 64, 3817, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 64, 3817, 16],"float32"), ) 	 50811904 	 1000 	 0.29560351371765137 	 0.3017096519470215 	 0.2872352600097656 	 0.28651857376098633 	 0.45049285888671875 	 0.44658923149108887 	 0.3967711925506592 	 0.3784303665161133 	 
2025-07-25 18:59:14.875165 test begin: paddle.exp(Tensor([16, 1, 4962, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 1, 4962, 640],"float32"), ) 	 50810880 	 1000 	 0.29587435722351074 	 0.2990989685058594 	 0.28766751289367676 	 0.286191463470459 	 0.45043277740478516 	 0.4465780258178711 	 0.39734339714050293 	 0.3761415481567383 	 
2025-07-25 18:59:18.046856 test begin: paddle.exp(Tensor([16, 1, 640, 4962],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 1, 640, 4962],"float32"), ) 	 50810880 	 1000 	 0.29578089714050293 	 0.2978498935699463 	 0.2874875068664551 	 0.2869100570678711 	 0.4505925178527832 	 0.4465513229370117 	 0.3970363140106201 	 0.37895846366882324 	 
2025-07-25 18:59:21.229083 test begin: paddle.exp(Tensor([16, 8, 640, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 8, 640, 640],"float32"), ) 	 52428800 	 1000 	 0.305131196975708 	 0.30706048011779785 	 0.2969539165496826 	 0.29596376419067383 	 0.4647040367126465 	 0.46067285537719727 	 0.4097893238067627 	 0.3917098045349121 	 
2025-07-25 18:59:24.535225 test begin: paddle.exp(Tensor([50, 64, 1007, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([50, 64, 1007, 16],"float32"), ) 	 51558400 	 1000 	 0.3000373840332031 	 0.30284714698791504 	 0.29174375534057617 	 0.29059791564941406 	 0.45711302757263184 	 0.4531104564666748 	 0.4037463665008545 	 0.38342881202697754 	 
2025-07-25 18:59:27.824102 test begin: paddle.exp(Tensor([56, 1, 960, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([56, 1, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3003654479980469 	 0.3024263381958008 	 0.29195737838745117 	 0.2910749912261963 	 0.45750880241394043 	 0.45357728004455566 	 0.3984994888305664 	 0.38546156883239746 	 
2025-07-25 18:59:31.042432 test begin: paddle.exp(Tensor([8, 1, 6616, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 1, 6616, 960],"float32"), ) 	 50810880 	 1000 	 0.2958667278289795 	 0.29779982566833496 	 0.28761816024780273 	 0.2866544723510742 	 0.4504728317260742 	 0.44648313522338867 	 0.39744043350219727 	 0.37947821617126465 	 
2025-07-25 18:59:34.265418 test begin: paddle.exp(Tensor([8, 1, 960, 6616],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 1, 960, 6616],"float32"), ) 	 50810880 	 1000 	 0.2958192825317383 	 0.30855631828308105 	 0.2875492572784424 	 0.28664112091064453 	 0.45050764083862305 	 0.4475998878479004 	 0.39473891258239746 	 0.3794739246368408 	 
2025-07-25 18:59:39.733834 test begin: paddle.exp(Tensor([8, 7, 960, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 7, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3003697395324707 	 0.3056142330169678 	 0.29200124740600586 	 0.29221057891845703 	 0.45746517181396484 	 0.45354509353637695 	 0.4044368267059326 	 0.38548994064331055 	 
2025-07-25 18:59:42.991345 test begin: paddle.expand_as(Tensor([1621, 80, 1, 1],"float32"), Tensor([1621, 80, 28, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([1621, 80, 1, 1],"float32"), Tensor([1621, 80, 28, 28],"float16"), ) 	 101798800 	 1000 	 0.2701117992401123 	 0.003650188446044922 	 0.2593705654144287 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:59:47.112561 test begin: paddle.expand_as(Tensor([511, 127, 1, 1],"float32"), Tensor([511, 127, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 127, 1, 1],"float32"), Tensor([511, 127, 28, 28],"float32"), ) 	 50944145 	 1000 	 0.13723015785217285 	 0.0037229061126708984 	 0.1264781951904297 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:59:49.088880 test begin: paddle.expand_as(Tensor([511, 80, 1, 1243],"float32"), Tensor([511, 80, 28, 1243],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1243],"float32"), Tensor([511, 80, 28, 1243],"float32"), ) 	 1473601360 	 1000 	 4.056102275848389 	 0.004693746566772461 	 4.045099258422852 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:00:45.825149 test begin: paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 28, 45],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 28, 45],"float32"), ) 	 51549680 	 1000 	 0.1404561996459961 	 0.0037527084350585938 	 0.12967252731323242 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:00:47.937277 test begin: paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 45, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 45, 28],"float32"), ) 	 51549680 	 1000 	 0.1391005516052246 	 0.0037314891815185547 	 0.12822437286376953 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:00:49.932613 test begin: paddle.expand_as(Tensor([511, 80, 1243, 1],"float32"), Tensor([511, 80, 1243, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1243, 1],"float32"), Tensor([511, 80, 1243, 28],"float32"), ) 	 1473601360 	 1000 	 4.32450270652771 	 0.003782987594604492 	 4.306103944778442 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:01:54.429770 test begin: paddle.expand_as(Tensor([512, 127, 1, 1],"float32"), Tensor([512, 127, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 127, 1, 1],"float32"), Tensor([512, 127, 28, 28],"float32"), ) 	 51043840 	 1000 	 0.13887500762939453 	 0.004288434982299805 	 0.12798452377319336 	 6.437301635742188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:01:56.460002 test begin: paddle.expand_as(Tensor([512, 254, 1, 1],"float32"), Tensor([512, 254, 28, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 254, 1, 1],"float32"), Tensor([512, 254, 28, 28],"float16"), ) 	 102087680 	 1000 	 0.27066612243652344 	 0.0036754608154296875 	 0.2599484920501709 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:02:00.616578 test begin: paddle.expand_as(Tensor([512, 80, 1, 1241],"float32"), Tensor([512, 80, 28, 1241],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1241],"float32"), Tensor([512, 80, 28, 1241],"float32"), ) 	 1474109440 	 1000 	 4.057894706726074 	 0.0036826133728027344 	 4.0468480587005615 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:02:57.569353 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 45],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 45],"float32"), ) 	 51650560 	 1000 	 0.1406385898590088 	 0.003735065460205078 	 0.1298508644104004 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:02:59.641093 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 89],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 89],"float16"), ) 	 102113280 	 1000 	 0.27092933654785156 	 0.003615856170654297 	 0.2601191997528076 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:03:03.759773 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 45, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 45, 28],"float32"), ) 	 51650560 	 1000 	 0.13933682441711426 	 0.003720998764038086 	 0.12860941886901855 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:03:05.731768 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 89, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 89, 28],"float16"), ) 	 102113280 	 1000 	 0.2709217071533203 	 0.005879402160644531 	 0.26009249687194824 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:03:09.888795 test begin: paddle.expand_as(Tensor([512, 80, 1241, 1],"float32"), Tensor([512, 80, 1241, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1241, 1],"float32"), Tensor([512, 80, 1241, 28],"float32"), ) 	 1474109440 	 1000 	 4.318436145782471 	 0.0037767887115478516 	 4.30735182762146 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:04:13.432251 test begin: paddle.expand_as(Tensor([811, 80, 1, 1],"float32"), Tensor([811, 80, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([811, 80, 1, 1],"float32"), Tensor([811, 80, 28, 28],"float32"), ) 	 50930800 	 1000 	 0.1386089324951172 	 0.0037055015563964844 	 0.12783265113830566 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:04:15.452467 test begin: paddle.expm1(Tensor([198451, 16, 32],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([198451, 16, 32],"float16"), ) 	 101606912 	 1000 	 0.3354640007019043 	 0.30393481254577637 	 0.32701754570007324 	 0.29318833351135254 	 0.4486062526702881 	 0.745671272277832 	 0.3960583209991455 	 0.38097405433654785 	 
2025-07-25 19:04:21.090865 test begin: paddle.expm1(Tensor([8, 16, 793801],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([8, 16, 793801],"float16"), ) 	 101606528 	 1000 	 0.33553504943847656 	 0.30527806282043457 	 0.32718586921691895 	 0.29278111457824707 	 0.4481832981109619 	 0.745786190032959 	 0.39405369758605957 	 0.38098883628845215 	 
2025-07-25 19:04:27.802564 test begin: paddle.expm1(Tensor([8, 396901, 32],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([8, 396901, 32],"float16"), ) 	 101606656 	 1000 	 0.33541202545166016 	 0.30869174003601074 	 0.3268420696258545 	 0.29256153106689453 	 0.44815802574157715 	 0.7456095218658447 	 0.396453857421875 	 0.3809518814086914 	 
2025-07-25 19:04:33.420444 test begin: paddle.fft.fftn(Tensor([226801, 7, 32],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([226801, 7, 32],"float32"), ) 	 50803424 	 1000 	 11.149574518203735 	 15.964178562164307 	 5.221366882324219e-05 	 1.8134281635284424 	 19.54349112510681 	 15.51558256149292 	 1.5359218120574951 	 1.981567621231079 	 
2025-07-25 19:05:39.600413 test begin: paddle.fft.fftn(Tensor([39, 40708, 32],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([39, 40708, 32],"float32"), ) 	 50803584 	 1000 	 9.374072790145874 	 10.602161169052124 	 5.507469177246094e-05 	 1.0845155715942383 	 11.9397451877594 	 10.027090549468994 	 1.015904188156128 	 1.1394143104553223 	 
2025-07-25 19:06:25.448494 test begin: paddle.fft.fftn(Tensor([39, 7, 186093],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([39, 7, 186093],"float32"), ) 	 50803389 	 1000 	 6.95377779006958 	 5.993094444274902 	 5.125999450683594e-05 	 0.7649779319763184 	 7.55270528793335 	 5.524346828460693 	 0.7713830471038818 	 0.8079242706298828 	 
2025-07-25 19:06:54.445312 test begin: paddle.fft.fftn(Tensor([7, 32, 481, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([7, 32, 481, 481],"float32"), axes=list[2,3,], ) 	 51824864 	 1000 	 5.976524591445923 	 4.348815679550171 	 4.696846008300781e-05 	 0.8914217948913574 	 5.521747589111328 	 3.9036872386932373 	 0.806096076965332 	 0.9995071887969971 	 
2025-07-25 19:07:16.214127 test begin: paddle.fft.fftn(Tensor([8, 28, 481, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 28, 481, 481],"float32"), axes=list[2,3,], ) 	 51824864 	 1000 	 5.973454713821411 	 4.331242084503174 	 1.8596649169921875e-05 	 0.885807991027832 	 5.521289587020874 	 3.8895812034606934 	 0.8061366081237793 	 0.9958059787750244 	 
2025-07-25 19:07:39.230483 test begin: paddle.fft.fftn(Tensor([8, 32, 413, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 32, 413, 481],"float32"), axes=list[2,3,], ) 	 50855168 	 1000 	 5.958215713500977 	 4.228135347366333 	 5.125999450683594e-05 	 0.8643941879272461 	 5.6062469482421875 	 3.7536914348602295 	 0.8185269832611084 	 0.9592726230621338 	 
2025-07-25 19:08:00.802405 test begin: paddle.fft.fftn(Tensor([8, 32, 481, 413],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 32, 481, 413],"float32"), axes=list[2,3,], ) 	 50855168 	 1000 	 5.948434352874756 	 4.225988149642944 	 2.002716064453125e-05 	 0.8631758689880371 	 5.620826721191406 	 3.7441327571868896 	 0.8205819129943848 	 0.9565002918243408 	 
2025-07-25 19:08:22.302840 test begin: paddle.fft.fftn(x=Tensor([50, 133, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 133, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50832600 	 1000 	 6.026770830154419 	 2.9737207889556885 	 5.269050598144531e-05 	 0.6079065799713135 	 4.378016710281372 	 2.492224931716919 	 0.6391725540161133 	 0.6366877555847168 	 
2025-07-25 19:08:40.131486 test begin: paddle.fft.fftn(x=Tensor([50, 8, 39, 14, 233],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 39, 14, 233],"float32"), axes=list[-3,-2,-1,], ) 	 50887200 	 1000 	 6.810463905334473 	 3.6954023838043213 	 4.8160552978515625e-05 	 0.7550303936004639 	 5.958475828170776 	 3.211399555206299 	 0.8699491024017334 	 0.8207719326019287 	 
2025-07-25 19:09:02.979927 test begin: paddle.fft.fftn(x=Tensor([50, 8, 39, 233, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 39, 233, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50887200 	 1000 	 7.204288482666016 	 4.127264022827148 	 3.910064697265625e-05 	 0.8443188667297363 	 6.529407739639282 	 3.6446454524993896 	 0.9533700942993164 	 0.9317324161529541 	 
2025-07-25 19:09:26.430929 test begin: paddle.fft.fftn(x=Tensor([50, 8, 649, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 649, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50881600 	 1000 	 6.356911897659302 	 3.560359239578247 	 2.3603439331054688e-05 	 0.726611852645874 	 4.962001323699951 	 3.073173761367798 	 0.7244656085968018 	 0.7847826480865479 	 
2025-07-25 19:09:46.901582 test begin: paddle.fft.fftn(x=Tensor([831, 8, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([831, 8, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50817312 	 1000 	 6.021800994873047 	 3.19759202003479 	 1.9788742065429688e-05 	 0.607710599899292 	 4.3754377365112305 	 2.4917805194854736 	 0.6388006210327148 	 0.6366276741027832 	 
2025-07-25 19:10:06.510167 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 6, 264601],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 4, 6, 264601],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401696 	 1000 	 3.0063819885253906 	 1.3908071517944336 	 1.9550323486328125e-05 	 0.35527896881103516 	 2.8657407760620117 	 1.901444673538208 	 0.3661768436431885 	 0.38886427879333496 	 
2025-07-25 19:10:16.601860 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 793801, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 4, 793801, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401632 	 1000 	 2.8359153270721436 	 1.3926360607147217 	 5.4836273193359375e-05 	 0.3551764488220215 	 2.598140001296997 	 1.9014160633087158 	 0.33182644844055176 	 0.3888885974884033 	 
2025-07-25 19:10:26.279711 test begin: paddle.fft.ifftn(x=Tensor([4, 529201, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 529201, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401648 	 1000 	 0.24778413772583008 	 0.49295830726623535 	 1.33514404296875e-05 	 0.1256718635559082 	 0.16714835166931152 	 0.7268321514129639 	 0.021354198455810547 	 0.09302878379821777 	 
2025-07-25 19:10:28.454041 test begin: paddle.fft.ifftn(x=Tensor([529201, 4, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([529201, 4, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401648 	 1000 	 0.23427391052246094 	 0.49261927604675293 	 1.5974044799804688e-05 	 0.1256117820739746 	 0.16672372817993164 	 0.27945852279663086 	 0.021291255950927734 	 0.05717754364013672 	 
2025-07-25 19:10:30.153772 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), ) 	 25401618 	 1000 	 1.8628108501434326 	 0.7675776481628418 	 0.38088560104370117 	 0.38783788681030273 	 3.4308910369873047 	 2.625009536743164 	 0.5843327045440674 	 0.5364668369293213 	 
2025-07-25 19:10:42.065923 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, ) 	 25401618 	 1000 	 1.972825527191162 	 0.7674217224121094 	 0.3361930847167969 	 0.390289306640625 	 2.869579315185547 	 1.8297195434570312 	 0.36641740798950195 	 0.37383031845092773 	 
2025-07-25 19:10:50.612041 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, axis=1, ) 	 25401618 	 1000 	 0.06770658493041992 	 0.049538373947143555 	 1.8596649169921875e-05 	 5.14984130859375e-05 	 0.1658790111541748 	 0.1660757064819336 	 0.02118849754333496 	 0.00011134147644042969 	 
2025-07-25 19:10:51.594727 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), ) 	 25401624 	 1000 	 1.8627569675445557 	 0.7590837478637695 	 0.3807981014251709 	 0.38773155212402344 	 3.430469036102295 	 2.6244661808013916 	 0.5842463970184326 	 0.5364303588867188 	 
2025-07-25 19:11:01.367217 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, ) 	 25401624 	 1000 	 1.9726989269256592 	 0.7687218189239502 	 0.33613109588623047 	 0.3902263641357422 	 2.8695337772369385 	 1.8297011852264404 	 0.36638522148132324 	 0.3737926483154297 	 
2025-07-25 19:11:13.073242 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, axis=1, ) 	 25401624 	 1000 	 1.738525390625 	 0.6928374767303467 	 0.2962005138397217 	 0.2360539436340332 	 2.470571517944336 	 1.700861930847168 	 0.3151686191558838 	 0.28968000411987305 	 
2025-07-25 19:11:20.572832 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 6.972048759460449 	 6.109938859939575 	 0.5090322494506836 	 0.5678391456604004 	 13.031872034072876 	 11.80624532699585 	 1.0247013568878174 	 1.005303144454956 	 
2025-07-25 19:11:59.544826 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, ) 	 25401624 	 1000 	 0.06996846199035645 	 0.03822898864746094 	 1.3828277587890625e-05 	 5.555152893066406e-05 	 0.1651153564453125 	 0.15807533264160156 	 0.021091461181640625 	 0.00011301040649414062 	 
2025-07-25 19:12:00.510186 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, axis=1, ) 	 25401624 	 1000 	 1.8582215309143066 	 0.6960721015930176 	 0.3168461322784424 	 0.23592662811279297 	 2.453284978866577 	 1.7014150619506836 	 0.3133056163787842 	 0.2896854877471924 	 
2025-07-25 19:12:08.118448 test begin: paddle.fft.ihfft(x=Tensor([705601, 4, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([705601, 4, 3, 3],"float64"), ) 	 25401636 	 1000 	 1.8602898120880127 	 1.4768807888031006 	 0.3803269863128662 	 0.3877866268157959 	 3.432793140411377 	 2.625368118286133 	 0.5846905708312988 	 0.5365185737609863 	 
2025-07-25 19:12:19.789944 test begin: paddle.fft.ihfft2(x=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([1270081, 4, 5],"float64"), ) 	 25401620 	 1000 	 2.096942663192749 	 2.1298329830169678 	 0.3571610450744629 	 0.36278820037841797 	 3.9947309494018555 	 3.516258716583252 	 0.5831429958343506 	 0.44924497604370117 	 
2025-07-25 19:12:32.602831 test begin: paddle.fft.ihfft2(x=Tensor([2822401, 3, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([2822401, 3, 3],"float64"), s=tuple(1,2,), ) 	 25401609 	 1000 	 0.7723047733306885 	 0.6381990909576416 	 0.13159990310668945 	 0.16120314598083496 	 1.1490323543548584 	 1.161299705505371 	 0.14683270454406738 	 0.1484231948852539 	 
2025-07-25 19:12:39.551898 test begin: paddle.fft.ihfft2(x=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([3, 1693441, 5],"float64"), ) 	 25401615 	 1000 	 8.836689949035645 	 7.3711230754852295 	 0.6949286460876465 	 0.6851742267608643 	 15.51038146018982 	 8.769017696380615 	 1.1323003768920898 	 0.6885130405426025 	 
2025-07-25 19:13:22.144629 test begin: paddle.fft.ihfft2(x=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([3, 4, 2116801],"float64"), ) 	 25401612 	 1000 	 9.110108137130737 	 7.308588743209839 	 0.620018482208252 	 0.4976465702056885 	 13.635854244232178 	 13.136682987213135 	 0.995368480682373 	 0.8951568603515625 	 
2025-07-25 19:14:06.373413 test begin: paddle.fft.ihfft2(x=Tensor([4, 2116801, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 2116801, 3],"float64"), s=tuple(1,2,), ) 	 25401612 	 1000 	 0.10032987594604492 	 0.06283950805664062 	 1.52587890625e-05 	 4.291534423828125e-05 	 0.16433286666870117 	 0.1971757411956787 	 0.02096867561340332 	 0.0001125335693359375 	 
2025-07-25 19:14:07.450554 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 2116801],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 2116801],"float64"), s=tuple(1,2,), ) 	 25401612 	 1000 	 0.09253644943237305 	 0.06049919128417969 	 2.7179718017578125e-05 	 3.7670135498046875e-05 	 0.16447806358337402 	 0.3016343116760254 	 0.0210111141204834 	 0.038571834564208984 	 
2025-07-25 19:14:08.592073 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 3, 705601],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 3, 705601],"float64"), ) 	 25401636 	 1000 	 7.286461353302002 	 7.309180736541748 	 0.4960787296295166 	 0.4973268508911133 	 13.619534015655518 	 12.746284008026123 	 0.9942538738250732 	 0.8684368133544922 	 
2025-07-25 19:14:51.368860 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 705601, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 705601, 3],"float64"), ) 	 25401636 	 1000 	 9.466489791870117 	 9.006914854049683 	 0.7445619106292725 	 0.7090170383453369 	 15.11660647392273 	 10.502551794052124 	 1.1034657955169678 	 0.7155065536499023 	 
2025-07-25 19:15:37.620370 test begin: paddle.fft.ihfft2(x=Tensor([4, 705601, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 705601, 3, 3],"float64"), ) 	 25401636 	 1000 	 2.266371011734009 	 2.3820579051971436 	 0.38603997230529785 	 0.40576791763305664 	 4.037669658660889 	 3.8588318824768066 	 0.5895075798034668 	 0.4929797649383545 	 
2025-07-25 19:15:51.259197 test begin: paddle.fft.ihfft2(x=Tensor([940801, 3, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([940801, 3, 3, 3],"float64"), ) 	 25401627 	 1000 	 2.2679171562194824 	 2.3818135261535645 	 0.38634300231933594 	 0.4057638645172119 	 4.038439512252808 	 3.858698844909668 	 0.5896332263946533 	 0.49312448501586914 	 
2025-07-25 19:16:04.914476 test begin: paddle.fft.ihfftn(Tensor([1270081, 4, 5],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([1270081, 4, 5],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401620 	 1000 	 2.096970319747925 	 2.133535861968994 	 0.3572068214416504 	 0.36319899559020996 	 3.994601249694824 	 3.5182924270629883 	 0.5832252502441406 	 0.449465274810791 	 
2025-07-25 19:16:17.664907 test begin: paddle.fft.ihfftn(Tensor([3, 1693441, 5],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([3, 1693441, 5],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401615 	 1000 	 8.8360915184021 	 7.3931052684783936 	 0.6949682235717773 	 0.6863367557525635 	 15.509637355804443 	 8.7809579372406 	 1.1321816444396973 	 0.6895031929016113 	 
2025-07-25 19:16:59.297742 test begin: paddle.fft.ihfftn(Tensor([3, 4, 2116801],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([3, 4, 2116801],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401612 	 1000 	 9.109594345092773 	 7.3158769607543945 	 0.6201472282409668 	 0.4979519844055176 	 13.635418176651001 	 13.140032052993774 	 0.9955077171325684 	 0.8952763080596924 	 
2025-07-25 19:17:44.916531 test begin: paddle.fft.ihfftn(Tensor([4, 3, 3, 705601],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 3, 3, 705601],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 7.286191463470459 	 7.3045737743377686 	 0.4960317611694336 	 0.49729108810424805 	 13.61653757095337 	 12.745522260665894 	 0.9941751956939697 	 0.8685834407806396 	 
2025-07-25 19:18:26.885625 test begin: paddle.fft.ihfftn(Tensor([4, 3, 705601, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 3, 705601, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 9.465667247772217 	 9.016789197921753 	 0.7444806098937988 	 0.7089438438415527 	 15.118513584136963 	 10.505688428878784 	 1.1036503314971924 	 0.7153213024139404 	 
2025-07-25 19:19:13.811635 test begin: paddle.fft.ihfftn(Tensor([4, 705601, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 705601, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 2.2663774490356445 	 2.383129358291626 	 0.38607287406921387 	 0.4057314395904541 	 4.038707494735718 	 3.859917640686035 	 0.5894396305084229 	 0.4929680824279785 	 
2025-07-25 19:19:27.434465 test begin: paddle.fft.ihfftn(Tensor([940801, 3, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([940801, 3, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401627 	 1000 	 2.2679860591888428 	 2.381596565246582 	 0.3863646984100342 	 0.4057271480560303 	 4.0394439697265625 	 3.861011266708374 	 0.5895242691040039 	 0.4928312301635742 	 
2025-07-25 19:19:41.596544 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 1058401, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 3, 1058401, 2],"float64"), ) 	 25401624 	 1000 	 15.198294162750244 	 14.119374513626099 	 0.9129207134246826 	 1.0304021835327148 	 18.41781497001648 	 14.264627695083618 	 1.0462877750396729 	 1.042463779449463 	 
2025-07-25 19:20:46.920930 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 5, 423361],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 3, 5, 423361],"float64"), ) 	 25401660 	 1000 	 7.311604738235474 	 6.401555061340332 	 0.4392282962799072 	 0.46692490577697754 	 15.397278547286987 	 10.885890483856201 	 0.9830241203308105 	 0.795637845993042 	 
2025-07-25 19:21:29.283068 test begin: paddle.fft.ihfftn(x=Tensor([4, 635041, 5, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 635041, 5, 2],"float64"), ) 	 25401640 	 1000 	 16.857515335083008 	 15.650436401367188 	 1.0124976634979248 	 1.142165184020996 	 20.538744688034058 	 15.78928256034851 	 1.712538480758667 	 1.1524105072021484 	 
2025-07-25 19:22:41.158843 test begin: paddle.fft.ihfftn(x=Tensor([846721, 3, 5, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([846721, 3, 5, 2],"float64"), ) 	 25401630 	 1000 	 18.895907163619995 	 15.553933382034302 	 1.135713815689087 	 1.3227310180664062 	 17.128782510757446 	 15.675968885421753 	 0.9736490249633789 	 1.334322214126587 	 
2025-07-25 19:23:50.523695 test begin: paddle.fft.rfft(Tensor([20, 1210, 2101],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 1210, 2101],"float32"), ) 	 50844200 	 1000 	 2.6045444011688232 	 2.0153090953826904 	 0.531904935836792 	 0.6867585182189941 	 4.90661883354187 	 3.382326602935791 	 1.0018620491027832 	 1.152703046798706 	 
2025-07-25 19:24:04.880261 test begin: paddle.fft.rfft(Tensor([20, 1270, 2001],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 1270, 2001],"float32"), ) 	 50825400 	 1000 	 1.9830503463745117 	 1.3314642906188965 	 0.40511369705200195 	 0.4527583122253418 	 3.6905205249786377 	 2.0225894451141357 	 0.7529871463775635 	 0.6893506050109863 	 
2025-07-25 19:24:15.229226 test begin: paddle.fft.rfft(Tensor([20, 64, 39691],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 64, 39691],"float32"), ) 	 50804480 	 1000 	 4.73548698425293 	 4.108712911605835 	 0.48346972465515137 	 0.5246829986572266 	 9.09937834739685 	 7.5049052238464355 	 0.9291355609893799 	 0.9597485065460205 	 
2025-07-25 19:24:44.976707 test begin: paddle.fft.rfft(Tensor([378, 64, 2101],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([378, 64, 2101],"float32"), ) 	 50827392 	 1000 	 2.6040124893188477 	 2.009596347808838 	 0.5315549373626709 	 0.6856498718261719 	 4.884136438369751 	 3.3755455017089844 	 0.9971046447753906 	 1.1507503986358643 	 
2025-07-25 19:24:59.313086 test begin: paddle.fft.rfft(Tensor([397, 64, 2001],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([397, 64, 2001],"float32"), ) 	 50841408 	 1000 	 1.985360860824585 	 1.3304798603057861 	 0.40569567680358887 	 0.45374321937561035 	 3.655534029006958 	 2.0242106914520264 	 0.7464511394500732 	 0.6894161701202393 	 
2025-07-25 19:25:09.718863 test begin: paddle.fft.rfft(Tensor([4, 32, 32, 12404],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 32, 32, 12404],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 4.894656658172607 	 4.3208088874816895 	 0.4997873306274414 	 0.5516667366027832 	 10.12466049194336 	 8.72894024848938 	 0.940803050994873 	 0.993668794631958 	 
2025-07-25 19:25:40.716649 test begin: paddle.fft.rfft(Tensor([4, 32, 6202, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 32, 6202, 64],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 1.2784700393676758 	 0.6293482780456543 	 0.32660984992980957 	 0.3207714557647705 	 3.5167312622070312 	 1.837191104888916 	 0.5986692905426025 	 0.4696319103240967 	 
2025-07-25 19:25:49.569680 test begin: paddle.fft.rfft(Tensor([4, 6202, 32, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 6202, 32, 64],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 1.2784762382507324 	 0.627936601638794 	 0.32661986351013184 	 0.3208131790161133 	 3.517078161239624 	 1.8370978832244873 	 0.5987043380737305 	 0.46962976455688477 	 
2025-07-25 19:25:58.173042 test begin: paddle.fft.rfft(Tensor([776, 32, 32, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([776, 32, 32, 64],"float32"), axis=-1, norm="forward", ) 	 50855936 	 1000 	 1.2789523601531982 	 0.6283910274505615 	 0.3267488479614258 	 0.3210625648498535 	 3.516747236251831 	 1.8390579223632812 	 0.5986504554748535 	 0.4700131416320801 	 
2025-07-25 19:26:06.885805 test begin: paddle.fft.rfft2(Tensor([26, 32, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([26, 32, 250, 250],"float32"), ) 	 52000000 	 1000 	 1.4788095951080322 	 0.8324434757232666 	 0.3776819705963135 	 0.42638468742370605 	 3.5992140769958496 	 1.9251832962036133 	 0.6127722263336182 	 0.492229700088501 	 
2025-07-25 19:26:16.108014 test begin: paddle.fft.rfft2(Tensor([32, 26, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 26, 250, 250],"float32"), ) 	 52000000 	 1000 	 1.4788618087768555 	 0.8315339088439941 	 0.37774062156677246 	 0.4262714385986328 	 3.599309206008911 	 1.925180196762085 	 0.6127228736877441 	 0.4922149181365967 	 
2025-07-25 19:26:25.387749 test begin: paddle.fft.rfft2(Tensor([32, 32, 199, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 32, 199, 250],"float32"), ) 	 50944000 	 1000 	 2.696821689605713 	 1.493807077407837 	 0.6895315647125244 	 0.7609140872955322 	 6.036309003829956 	 3.2593839168548584 	 1.0907835960388184 	 0.8332476615905762 	 
2025-07-25 19:26:42.680473 test begin: paddle.fft.rfft2(Tensor([32, 32, 250, 199],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 32, 250, 199],"float32"), ) 	 50944000 	 1000 	 2.738384962081909 	 1.6373138427734375 	 0.46596455574035645 	 0.4177255630493164 	 5.239346265792847 	 2.708338499069214 	 0.8915841579437256 	 0.6923048496246338 	 
2025-07-25 19:26:56.433481 test begin: paddle.fft.rfft2(Tensor([8, 102, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 102, 250, 250],"float32"), ) 	 51000000 	 1000 	 1.4517316818237305 	 0.8073770999908447 	 0.3708305358886719 	 0.4131937026977539 	 3.528904438018799 	 1.8854005336761475 	 0.6010172367095947 	 0.4820709228515625 	 
2025-07-25 19:27:05.499352 test begin: paddle.fft.rfft2(Tensor([8, 32, 250, 794],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 32, 250, 794],"float32"), ) 	 50816000 	 1000 	 2.107285737991333 	 1.4728174209594727 	 0.43158435821533203 	 0.5012917518615723 	 4.391649961471558 	 2.7359766960144043 	 0.7487716674804688 	 0.7008540630340576 	 
2025-07-25 19:27:17.693840 test begin: paddle.fft.rfft2(Tensor([8, 32, 794, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 32, 794, 250],"float32"), ) 	 50816000 	 1000 	 2.3231678009033203 	 1.6281280517578125 	 0.5938377380371094 	 0.8318982124328613 	 5.251183271408081 	 3.51298451423645 	 0.8947393894195557 	 0.8982791900634766 	 
2025-07-25 19:27:31.862163 test begin: paddle.fft.rfft2(x=Tensor([32, 15, 15, 7057],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 15, 15, 7057],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50810400 	 1000 	 1.5988283157348633 	 1.6138629913330078 	 0.32675695419311523 	 0.40760183334350586 	 3.932701826095581 	 3.0481128692626953 	 0.6695914268493652 	 0.6233479976654053 	 
2025-07-25 19:27:46.373876 test begin: paddle.fft.rfft2(x=Tensor([32, 15, 414, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 15, 414, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50872320 	 1000 	 2.322889566421509 	 1.8551018238067627 	 0.33889198303222656 	 0.37880539894104004 	 4.269680976867676 	 3.1273093223571777 	 0.6232008934020996 	 0.5326123237609863 	 
2025-07-25 19:27:59.369377 test begin: paddle.fft.rfft2(x=Tensor([32, 414, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 414, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50872320 	 1000 	 1.6713366508483887 	 1.696993350982666 	 0.3412744998931885 	 0.4335453510284424 	 4.3025946617126465 	 3.433079957962036 	 0.6279990673065186 	 0.5845534801483154 	 
2025-07-25 19:28:11.995710 test begin: paddle.fft.rfft2(x=Tensor([883, 15, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([883, 15, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50860800 	 1000 	 1.5656483173370361 	 1.576664686203003 	 0.32000088691711426 	 0.4023153781890869 	 3.897918224334717 	 3.025221586227417 	 0.663733959197998 	 0.6187877655029297 	 
2025-07-25 19:28:23.439501 test begin: paddle.fft.rfftn(Tensor([26, 32, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([26, 32, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 52000000 	 1000 	 1.4794020652770996 	 0.8272721767425537 	 0.37787961959838867 	 0.4219059944152832 	 3.600447177886963 	 1.925269603729248 	 0.6128954887390137 	 0.49221038818359375 	 
2025-07-25 19:28:32.747474 test begin: paddle.fft.rfftn(Tensor([32, 15, 15, 7057],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 15, 15, 7057],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50810400 	 1000 	 1.5987894535064697 	 1.6173086166381836 	 0.32680273056030273 	 0.4076058864593506 	 3.9333455562591553 	 3.0485966205596924 	 0.6696741580963135 	 0.6235580444335938 	 
2025-07-25 19:28:44.774128 test begin: paddle.fft.rfftn(Tensor([32, 15, 414, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 15, 414, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50872320 	 1000 	 2.322551965713501 	 1.8676996231079102 	 0.3389122486114502 	 0.3787708282470703 	 4.2687764167785645 	 3.1258316040039062 	 0.6231269836425781 	 0.532604455947876 	 
2025-07-25 19:28:58.224770 test begin: paddle.fft.rfftn(Tensor([32, 26, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 26, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 52000000 	 1000 	 1.479327917098999 	 0.82993483543396 	 0.3778724670410156 	 0.4258575439453125 	 3.600273370742798 	 1.9264874458312988 	 0.6128358840942383 	 0.4936227798461914 	 
2025-07-25 19:29:07.431587 test begin: paddle.fft.rfftn(Tensor([32, 32, 199, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 32, 199, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50944000 	 1000 	 2.6991069316864014 	 1.4905540943145752 	 0.6901607513427734 	 0.7615954875946045 	 5.965256452560425 	 3.261387825012207 	 1.0160832405090332 	 0.8338828086853027 	 
2025-07-25 19:29:22.259583 test begin: paddle.fft.rfftn(Tensor([32, 32, 250, 199],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 32, 250, 199],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50944000 	 1000 	 2.739769220352173 	 1.6370325088500977 	 0.4674701690673828 	 0.4179372787475586 	 5.241535663604736 	 2.7096638679504395 	 0.8919861316680908 	 0.692650556564331 	 
2025-07-25 19:29:37.444998 test begin: paddle.fft.rfftn(Tensor([32, 414, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 414, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50872320 	 1000 	 1.6697938442230225 	 1.7015395164489746 	 0.34125852584838867 	 0.4334447383880615 	 4.301915645599365 	 3.4320859909057617 	 0.627830982208252 	 0.584223747253418 	 
2025-07-25 19:29:50.013325 test begin: paddle.fft.rfftn(Tensor([8, 102, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 102, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 51000000 	 1000 	 1.4520416259765625 	 0.8151829242706299 	 0.37096738815307617 	 0.4119696617126465 	 3.529484748840332 	 1.8860297203063965 	 0.6010644435882568 	 0.48247694969177246 	 
2025-07-25 19:30:00.732953 test begin: paddle.fft.rfftn(Tensor([8, 32, 250, 794],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 32, 250, 794],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50816000 	 1000 	 2.1082794666290283 	 1.4805779457092285 	 0.43041253089904785 	 0.5016319751739502 	 4.393719673156738 	 2.7374463081359863 	 0.747704029083252 	 0.6997425556182861 	 
2025-07-25 19:30:12.884929 test begin: paddle.fft.rfftn(Tensor([8, 32, 794, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 32, 794, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50816000 	 1000 	 2.3256676197052 	 1.6290109157562256 	 0.5956356525421143 	 0.8323194980621338 	 5.251943588256836 	 3.513969659805298 	 0.8936872482299805 	 0.8986363410949707 	 
2025-07-25 19:30:27.042550 test begin: paddle.fft.rfftn(Tensor([883, 15, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([883, 15, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50860800 	 1000 	 1.5670232772827148 	 1.5783958435058594 	 0.31999659538269043 	 0.4023921489715576 	 3.8995354175567627 	 3.0256881713867188 	 0.6651430130004883 	 0.6187431812286377 	 
2025-07-25 19:30:39.963973 test begin: paddle.flatten(Tensor([4051, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4051, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 50815744 	 1000 	 0.005713462829589844 	 0.00448298454284668 	 9.059906005859375e-06 	 2.3126602172851562e-05 	 0.04121685028076172 	 0.056382179260253906 	 2.3365020751953125e-05 	 5.340576171875e-05 	 
2025-07-25 19:30:41.703608 test begin: paddle.flatten(Tensor([4096, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4096, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 50978816 	 1000 	 0.005797147750854492 	 0.0043866634368896484 	 1.0251998901367188e-05 	 1.71661376953125e-05 	 0.04110240936279297 	 0.05613589286804199 	 2.3365020751953125e-05 	 3.457069396972656e-05 	 
2025-07-25 19:30:43.462305 test begin: paddle.flatten(Tensor([4096, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4096, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 51380224 	 1000 	 0.005810260772705078 	 0.004471778869628906 	 7.867813110351562e-06 	 3.8623809814453125e-05 	 0.04224419593811035 	 0.05724835395812988 	 3.4809112548828125e-05 	 6.031990051269531e-05 	 
2025-07-25 19:30:45.224453 test begin: paddle.flatten(Tensor([416, 50, 10, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([416, 50, 10, 256],"float32"), start_axis=2, ) 	 53248000 	 1000 	 0.005663156509399414 	 0.0042726993560791016 	 1.2159347534179688e-05 	 1.71661376953125e-05 	 0.04147696495056152 	 0.05621743202209473 	 3.62396240234375e-05 	 3.981590270996094e-05 	 
2025-07-25 19:30:47.066567 test begin: paddle.flatten(Tensor([416, 50, 7, 349],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([416, 50, 7, 349],"float32"), start_axis=2, ) 	 50814400 	 1000 	 0.005683422088623047 	 0.004215240478515625 	 8.106231689453125e-06 	 1.71661376953125e-05 	 0.04102206230163574 	 0.056671857833862305 	 3.0279159545898438e-05 	 3.9577484130859375e-05 	 
2025-07-25 19:30:48.811757 test begin: paddle.flatten(Tensor([416, 69, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([416, 69, 7, 256],"float32"), start_axis=2, ) 	 51437568 	 1000 	 0.005610942840576172 	 0.004281759262084961 	 7.867813110351562e-06 	 1.6927719116210938e-05 	 0.04715251922607422 	 0.056133270263671875 	 3.647804260253906e-05 	 2.9087066650390625e-05 	 
2025-07-25 19:30:50.588173 test begin: paddle.flatten(Tensor([512, 50, 7, 284],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([512, 50, 7, 284],"float32"), start_axis=2, ) 	 50892800 	 1000 	 0.0056798458099365234 	 0.0042629241943359375 	 6.9141387939453125e-06 	 1.7404556274414062e-05 	 0.0465092658996582 	 0.05611085891723633 	 2.6941299438476562e-05 	 3.0279159545898438e-05 	 
2025-07-25 19:30:52.331447 test begin: paddle.flatten(Tensor([512, 50, 8, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([512, 50, 8, 256],"float32"), start_axis=2, ) 	 52428800 	 1000 	 0.00569462776184082 	 0.004312276840209961 	 1.6927719116210938e-05 	 1.6450881958007812e-05 	 0.041486263275146484 	 0.05715179443359375 	 1.8358230590820312e-05 	 3.838539123535156e-05 	 
2025-07-25 19:30:54.144401 test begin: paddle.flatten(Tensor([512, 56, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([512, 56, 7, 256],"float32"), start_axis=2, ) 	 51380224 	 1000 	 0.005695819854736328 	 0.004210472106933594 	 8.821487426757812e-06 	 1.811981201171875e-05 	 0.04118704795837402 	 0.05669426918029785 	 2.956390380859375e-05 	 3.695487976074219e-05 	 
2025-07-25 19:30:56.113870 test begin: paddle.flatten(Tensor([568, 50, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([568, 50, 7, 256],"float32"), start_axis=2, ) 	 50892800 	 1000 	 0.0056378841400146484 	 0.004225492477416992 	 9.298324584960938e-06 	 1.6450881958007812e-05 	 0.041597604751586914 	 0.056465864181518555 	 3.3855438232421875e-05 	 3.218650817871094e-05 	 
2025-07-25 19:30:57.851637 test begin: paddle.flip(Tensor([127, 8, 224, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([127, 8, 224, 224],"float32"), axis=list[3,], ) 	 50978816 	 1000 	 0.968569278717041 	 1.0786640644073486 	 0.9593725204467773 	 0.29897212982177734 	 0.9673264026641846 	 0.3133544921875 	 0.9175817966461182 	 0.23825883865356445 	 
2025-07-25 19:31:06.241784 test begin: paddle.flip(Tensor([1351, 3, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([1351, 3, 112, 112],"float32"), axis=-1, ) 	 50840832 	 1000 	 0.967188835144043 	 0.32298803329467773 	 0.9580519199371338 	 0.298445463180542 	 0.9676480293273926 	 0.31309080123901367 	 0.9181623458862305 	 0.24254512786865234 	 
2025-07-25 19:31:12.188451 test begin: paddle.flip(Tensor([3, 338, 224, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 338, 224, 224],"float32"), axis=list[3,], ) 	 50878464 	 1000 	 0.9665522575378418 	 0.3142087459564209 	 0.957237720489502 	 0.29836368560791016 	 0.9652831554412842 	 0.3127777576446533 	 0.9152238368988037 	 0.229994535446167 	 
2025-07-25 19:31:16.422051 test begin: paddle.flip(Tensor([3, 8, 224, 9451],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 8, 224, 9451],"float32"), axis=list[3,], ) 	 50808576 	 1000 	 0.9658405780792236 	 0.31282877922058105 	 0.9566869735717773 	 0.29889392852783203 	 0.9646389484405518 	 0.31268930435180664 	 0.9152467250823975 	 0.22342610359191895 	 
2025-07-25 19:31:20.655227 test begin: paddle.flip(Tensor([3, 8, 9451, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 8, 9451, 224],"float32"), axis=list[3,], ) 	 50808576 	 1000 	 0.9653253555297852 	 0.3124685287475586 	 0.9561715126037598 	 0.2984442710876465 	 0.964221715927124 	 0.31241440773010254 	 0.9142489433288574 	 0.24355411529541016 	 
2025-07-25 19:31:24.901057 test begin: paddle.flip(Tensor([52, 3, 112, 2908],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 3, 112, 2908],"float32"), axis=-1, ) 	 50808576 	 1000 	 0.966132402420044 	 0.31285691261291504 	 0.9570121765136719 	 0.2972121238708496 	 0.9647600650787354 	 0.31269049644470215 	 0.9122860431671143 	 0.24406838417053223 	 
2025-07-25 19:31:29.090208 test begin: paddle.flip(Tensor([52, 3, 2908, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 3, 2908, 112],"float32"), axis=-1, ) 	 50808576 	 1000 	 0.966651201248169 	 0.312593936920166 	 0.957510232925415 	 0.2985663414001465 	 0.9665374755859375 	 0.3128693103790283 	 0.9168436527252197 	 0.24393081665039062 	 
2025-07-25 19:31:33.347817 test begin: paddle.flip(Tensor([52, 78, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 78, 112, 112],"float32"), axis=-1, ) 	 50878464 	 1000 	 0.9678127765655518 	 0.3261275291442871 	 0.9586946964263916 	 0.2989656925201416 	 0.9676008224487305 	 0.31316089630126953 	 0.917762041091919 	 0.24371623992919922 	 
2025-07-25 19:31:39.388849 test begin: paddle.flip(Tensor([64, 3, 112, 2363],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 3, 112, 2363],"float32"), axis=-1, ) 	 50813952 	 1000 	 0.9659709930419922 	 0.31656980514526367 	 0.9568424224853516 	 0.2986562252044678 	 0.9646542072296143 	 0.3127725124359131 	 0.914175271987915 	 0.24396324157714844 	 
2025-07-25 19:31:43.605584 test begin: paddle.flip(Tensor([64, 3, 2363, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 3, 2363, 112],"float32"), axis=-1, ) 	 50813952 	 1000 	 0.9677407741546631 	 0.3126533031463623 	 0.9586257934570312 	 0.2987251281738281 	 0.9663491249084473 	 0.312938928604126 	 0.904242992401123 	 0.24380707740783691 	 
2025-07-25 19:31:47.918606 test begin: paddle.flip(Tensor([64, 64, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 64, 112, 112],"float32"), axis=-1, ) 	 51380224 	 1000 	 0.9785904884338379 	 0.31644701957702637 	 0.9693942070007324 	 0.3022921085357666 	 0.9772229194641113 	 0.3161437511444092 	 0.9263148307800293 	 0.24701666831970215 	 
2025-07-25 19:31:52.167267 test begin: paddle.floor(Tensor([100000, 170, 3],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([100000, 170, 3],"float32"), ) 	 51000000 	 1000 	 0.2968268394470215 	 0.3041045665740967 	 0.2881591320037842 	 0.28755855560302734 	 0.13536739349365234 	 0.13459467887878418 	 0.08543968200683594 	 0.0670621395111084 	 
2025-07-25 19:31:54.671761 test begin: paddle.floor(Tensor([100000, 2, 255],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([100000, 2, 255],"float32"), ) 	 51000000 	 1000 	 0.29680657386779785 	 0.2989647388458252 	 0.2882235050201416 	 0.2755415439605713 	 0.13461661338806152 	 0.134627103805542 	 0.07390761375427246 	 0.03693699836730957 	 
2025-07-25 19:31:57.147582 test begin: paddle.floor(Tensor([322, 157920],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([322, 157920],"float32"), ) 	 50850240 	 1000 	 0.29608750343322754 	 0.29808568954467773 	 0.2875518798828125 	 0.28473997116088867 	 0.13409996032714844 	 0.13416814804077148 	 0.08444905281066895 	 0.06896471977233887 	 
2025-07-25 19:31:59.650296 test begin: paddle.floor(Tensor([4, 12700801],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([4, 12700801],"float32"), ) 	 50803204 	 1000 	 0.2957606315612793 	 0.29775261878967285 	 0.28719401359558105 	 0.2865254878997803 	 0.1340348720550537 	 0.1341094970703125 	 0.08385038375854492 	 0.0687098503112793 	 
2025-07-25 19:32:02.155073 test begin: paddle.floor(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2957310676574707 	 0.2977406978607178 	 0.28710365295410156 	 0.28687453269958496 	 0.13409161567687988 	 0.13408637046813965 	 0.08392763137817383 	 0.0678868293762207 	 
2025-07-25 19:32:04.637629 test begin: paddle.floor(x=Tensor([100, 352, 38, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 352, 38, 38],"float32"), ) 	 50828800 	 1000 	 0.2959935665130615 	 0.2978847026824951 	 0.2871975898742676 	 0.2870028018951416 	 0.1340956687927246 	 0.13422608375549316 	 0.08266711235046387 	 0.05853557586669922 	 
2025-07-25 19:32:09.036981 test begin: paddle.floor(x=Tensor([100, 4, 3343, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 4, 3343, 38],"float32"), ) 	 50813600 	 1000 	 0.295820951461792 	 0.5295629501342773 	 0.28687167167663574 	 0.2868387699127197 	 0.1340954303741455 	 0.13417696952819824 	 0.08350467681884766 	 0.05729794502258301 	 
2025-07-25 19:32:13.083575 test begin: paddle.floor(x=Tensor([100, 4, 38, 3343],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 4, 38, 3343],"float32"), ) 	 50813600 	 1000 	 0.29584383964538574 	 0.29791808128356934 	 0.287003755569458 	 0.28614091873168945 	 0.13413262367248535 	 0.13409733772277832 	 0.08373785018920898 	 0.06753110885620117 	 
2025-07-25 19:32:15.658401 test begin: paddle.floor(x=Tensor([8796, 4, 38, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([8796, 4, 38, 38],"float32"), ) 	 50805696 	 1000 	 0.29570674896240234 	 0.29776859283447266 	 0.2864358425140381 	 0.2864358425140381 	 0.13407158851623535 	 0.13409900665283203 	 0.08422708511352539 	 0.06342506408691406 	 
2025-07-25 19:32:18.142076 test begin: paddle.floor_divide(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.42798805236816406 	 0.5003714561462402 	 0.41793346405029297 	 0.4805643558502197 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:19.922213 test begin: paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.42741823196411133 	 0.4938066005706787 	 0.41753220558166504 	 0.4806551933288574 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:21.654257 test begin: paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.45251917839050293 	 0.4572305679321289 	 0.4431440830230713 	 0.4440879821777344 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:24.211727 test begin: paddle.floor_divide(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4471864700317383 	 0.44719982147216797 	 0.4381568431854248 	 0.43513059616088867 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:25.937623 test begin: paddle.floor_divide(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.4517500400543213 	 0.4605269432067871 	 0.442643404006958 	 0.44399285316467285 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:28.532274 test begin: paddle.floor_divide(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4480898380279541 	 0.4471762180328369 	 0.4391617774963379 	 0.4349987506866455 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:30.245169 test begin: paddle.floor_divide(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.4517965316772461 	 0.4549989700317383 	 0.4426703453063965 	 0.4428691864013672 	 None 	 None 	 None 	 None 	 
2025-07-25 19:32:32.877725 test begin: paddle.fmax(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 558835211 	 1000 	 4.452049493789673 	 4.424619197845459 	 4.435104131698608 	 4.392100095748901 	 45.21737623214722 	 27.21040940284729 	 45.15918326377869 	 1.986191987991333 	 
2025-07-25 19:34:13.152263 test begin: paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.4497642517089844 	 0.44609737396240234 	 0.4399731159210205 	 0.43471407890319824 	 0.7378082275390625 	 2.645118236541748 	 0.6802370548248291 	 0.20786786079406738 	 
2025-07-25 19:34:20.790955 test begin: paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), ) 	 55883531 	 1000 	 0.4502086639404297 	 0.4459190368652344 	 0.43944406509399414 	 0.4335176944732666 	 4.541020393371582 	 2.7512567043304443 	 4.48028826713562 	 0.20064401626586914 	 
2025-07-25 19:34:30.842540 test begin: paddle.fmax(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), ) 	 101616000 	 1000 	 0.4568746089935303 	 0.46172499656677246 	 0.447188138961792 	 0.43437719345092773 	 0.7365009784698486 	 2.6416351795196533 	 0.6793477535247803 	 0.20771074295043945 	 
2025-07-25 19:34:37.855661 test begin: paddle.fmax(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), ) 	 101608800 	 1000 	 0.4501054286956787 	 0.4532506465911865 	 0.44039058685302734 	 0.43833422660827637 	 0.7378237247467041 	 2.6456820964813232 	 0.6759603023529053 	 0.20801734924316406 	 
2025-07-25 19:34:44.647056 test begin: paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), ) 	 50803230 	 1000 	 0.29657936096191406 	 0.3039100170135498 	 0.2858095169067383 	 0.29131221771240234 	 8.394219875335693 	 2.4770402908325195 	 8.335139036178589 	 0.16849327087402344 	 
2025-07-25 19:34:57.867205 test begin: paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), ) 	 101606430 	 1000 	 0.4496607780456543 	 0.44709181785583496 	 0.4400818347930908 	 0.4344062805175781 	 0.7364709377288818 	 2.646312713623047 	 0.678544282913208 	 0.20911431312561035 	 
2025-07-25 19:35:04.606792 test begin: paddle.fmax(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), ) 	 101616000 	 1000 	 0.4502575397491455 	 0.44609713554382324 	 0.4404773712158203 	 0.43470311164855957 	 0.7377862930297852 	 2.642831325531006 	 0.6808052062988281 	 0.20772242546081543 	 
2025-07-25 19:35:11.345528 test begin: paddle.fmin(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 558835211 	 1000 	 4.445959091186523 	 4.4089415073394775 	 4.433175563812256 	 4.396187782287598 	 45.26875925064087 	 27.211381912231445 	 45.21110129356384 	 1.9869105815887451 	 
2025-07-25 19:36:50.658735 test begin: paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.4497668743133545 	 0.4523468017578125 	 0.44007110595703125 	 0.4346756935119629 	 0.7364559173583984 	 2.6451070308685303 	 0.679248571395874 	 0.2078537940979004 	 
2025-07-25 19:36:57.489196 test begin: paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), ) 	 55883531 	 1000 	 0.4512157440185547 	 0.46221470832824707 	 0.44060397148132324 	 0.43499064445495605 	 4.542113542556763 	 2.7491939067840576 	 4.483747959136963 	 0.20064425468444824 	 
2025-07-25 19:37:07.512664 test begin: paddle.fmin(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), ) 	 101616000 	 1000 	 0.45019102096557617 	 0.44780397415161133 	 0.4404599666595459 	 0.4346625804901123 	 0.7365050315856934 	 2.644383430480957 	 0.6790018081665039 	 0.20774078369140625 	 
2025-07-25 17:48:47.845341 test begin: paddle.fmin(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), )
W0725 17:48:49.543828 96901 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.fmin 	 paddle.fmin(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), ) 	 101608800 	 1000 	 0.4556748867034912 	 0.45100903511047363 	 0.4421684741973877 	 0.43488049507141113 	 0.7339553833007812 	 2.6463232040405273 	 0.6729025840759277 	 0.20807313919067383 	 
2025-07-25 17:48:56.020693 test begin: paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), ) 	 50803230 	 1000 	 0.29722046852111816 	 0.30353784561157227 	 0.2863733768463135 	 0.29163336753845215 	 8.338178157806396 	 2.48111629486084 	 8.278265714645386 	 0.16893362998962402 	 
2025-07-25 17:49:09.268248 test begin: paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), ) 	 101606430 	 1000 	 0.45060253143310547 	 0.446805477142334 	 0.44092464447021484 	 0.435563325881958 	 0.7349264621734619 	 2.6442813873291016 	 0.6767432689666748 	 0.2079312801361084 	 
2025-07-25 17:49:16.025653 test begin: paddle.fmin(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), ) 	 101616000 	 1000 	 0.4508044719696045 	 0.44678688049316406 	 0.4411137104034424 	 0.4354281425476074 	 0.7328059673309326 	 2.642256736755371 	 0.6743285655975342 	 0.2077789306640625 	 
2025-07-25 17:49:22.765312 test begin: paddle.frac(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.808211088180542 	 0.2980520725250244 	 0.7846226692199707 	 0.2874300479888916 	 1.1838603019714355 	 0.047617197036743164 	 0.604895830154419 	 4.1484832763671875e-05 	 
2025-07-25 17:49:26.815693 test begin: paddle.frac(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.8077957630157471 	 0.2980196475982666 	 0.7858924865722656 	 0.2874116897583008 	 1.1841058731079102 	 0.04956555366516113 	 0.6050324440002441 	 4.7206878662109375e-05 	 
2025-07-25 17:49:30.840519 test begin: paddle.frac(Tensor([16934401, 3],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.8076341152191162 	 0.969353437423706 	 0.7860369682312012 	 0.287461519241333 	 1.1840810775756836 	 0.04834294319152832 	 0.6050269603729248 	 6.961822509765625e-05 	 
2025-07-25 17:49:36.478281 test begin: paddle.frac(Tensor([2, 12700801],"float64"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 1.4160261154174805 	 0.5341064929962158 	 0.7256276607513428 	 0.28740739822387695 	 1.065631628036499 	 0.058775901794433594 	 0.544442892074585 	 8.106231689453125e-05 	 
2025-07-25 17:49:42.941571 test begin: paddle.frac(Tensor([2, 25401601],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.807744026184082 	 0.29798054695129395 	 0.7860331535339355 	 0.28732848167419434 	 1.1840763092041016 	 0.04781532287597656 	 0.6050622463226318 	 3.170967102050781e-05 	 
2025-07-25 17:49:46.962690 test begin: paddle.frac(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.8075902462005615 	 0.29798436164855957 	 0.785900354385376 	 0.2875995635986328 	 1.1839544773101807 	 0.04796314239501953 	 0.6049673557281494 	 3.719329833984375e-05 	 
2025-07-25 17:49:50.985401 test begin: paddle.frac(Tensor([8467201, 3],"float64"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.7483909130096436 	 0.29814815521240234 	 0.7262680530548096 	 0.2875375747680664 	 1.06571626663208 	 0.04866361618041992 	 0.5444724559783936 	 3.910064697265625e-05 	 
2025-07-25 17:49:54.251183 test begin: paddle.full_like(Tensor([1, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([1, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), ) 	 50804736 	 1000 	 0.06914114952087402 	 0.07257914543151855 	 0.05793881416320801 	 0.056270599365234375 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:55.107428 test begin: paddle.full_like(Tensor([1, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([1, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 50804736 	 1000 	 0.06889820098876953 	 0.06884098052978516 	 0.05799269676208496 	 0.056366682052612305 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:55.955911 test begin: paddle.full_like(Tensor([1, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([1, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 54525952 	 1000 	 0.07370781898498535 	 0.07363104820251465 	 0.06274032592773438 	 0.06123852729797363 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:56.858885 test begin: paddle.full_like(Tensor([1, 300, 169345],"float32"), 1, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([1, 300, 169345],"float32"), 1, ) 	 50803500 	 1000 	 0.13420724868774414 	 0.1345067024230957 	 0.1238243579864502 	 0.12227988243103027 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:57.951426 test begin: paddle.full_like(Tensor([13, 1, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([13, 1, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 54525952 	 1000 	 0.07386636734008789 	 0.07363510131835938 	 0.06271123886108398 	 0.06138134002685547 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:58.849317 test begin: paddle.full_like(Tensor([199, 256000],"float32"), 0.0, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([199, 256000],"float32"), 0.0, ) 	 50944000 	 1000 	 0.1352686882019043 	 0.13477349281311035 	 0.1241004467010498 	 0.12215328216552734 	 None 	 None 	 None 	 None 	 
2025-07-25 17:49:59.940477 test begin: paddle.full_like(Tensor([42, 300, 4096],"float32"), 1, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([42, 300, 4096],"float32"), 1, ) 	 51609600 	 1000 	 0.1370532512664795 	 0.14076495170593262 	 0.12583065032958984 	 0.12325549125671387 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:01.073549 test begin: paddle.full_like(Tensor([6, 8467201],"float32"), 0.0, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([6, 8467201],"float32"), 0.0, ) 	 50803206 	 1000 	 0.13428092002868652 	 0.13431453704833984 	 0.12398123741149902 	 0.1219942569732666 	 None 	 None 	 None 	 None 	 
2025-07-25 17:50:02.163947 test begin: paddle.gammainc(Tensor([1270081, 40],"float32"), y=Tensor([1270081, 40],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([1270081, 40],"float32"), y=Tensor([1270081, 40],"float32"), ) 	 101606480 	 1000 	 4.206756353378296 	 2.267019510269165 	 0.0030393600463867188 	 2.2556118965148926 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-25 17:50:12.762394 test begin: paddle.gammainc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 4.201763868331909 	 2.2669451236724854 	 0.0030417442321777344 	 2.2555036544799805 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-25 17:50:23.170802 test begin: paddle.gammainc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 4.226711273193359 	 2.2668519020080566 	 0.0030350685119628906 	 2.248847484588623 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-25 17:50:33.936844 test begin: paddle.gammainc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 4.201099872589111 	 2.721930503845215 	 0.003032684326171875 	 2.2532899379730225 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-25 17:50:47.722958 test begin: paddle.gammainc(Tensor([3, 16934401],"float32"), y=Tensor([3, 16934401],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([3, 16934401],"float32"), y=Tensor([3, 16934401],"float32"), ) 	 101606406 	 1000 	 4.212631940841675 	 2.2720327377319336 	 0.00304412841796875 	 2.2514379024505615 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-25 17:50:58.229474 test begin: paddle.gammainc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 4.207180976867676 	 2.2671091556549072 	 0.0030379295349121094 	 2.2480897903442383 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-25 17:51:10.344367 test begin: paddle.gammaincc(Tensor([1270081, 40],"float32"), Tensor([1270081, 40],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([1270081, 40],"float32"), Tensor([1270081, 40],"float32"), ) 	 101606480 	 1000 	 3.9199299812316895 	 7.098546028137207 	 0.002768993377685547 	 7.082711458206177 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-25 17:51:25.212019 test begin: paddle.gammaincc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 3.9111015796661377 	 7.097230672836304 	 0.0027632713317871094 	 7.085913181304932 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-25 17:51:40.191467 test begin: paddle.gammaincc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 3.9286062717437744 	 7.098621129989624 	 0.002764463424682617 	 7.083576679229736 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-25 17:51:55.196068 test begin: paddle.gammaincc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 3.9048068523406982 	 7.099117040634155 	 0.002770662307739258 	 7.085544586181641 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-25 17:52:09.992808 test begin: paddle.gammaincc(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), ) 	 101606406 	 1000 	 3.928161859512329 	 7.096406936645508 	 0.002765655517578125 	 7.078721761703491 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-25 17:52:24.866096 test begin: paddle.gammaincc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 3.9033749103546143 	 7.0968098640441895 	 0.0027573108673095703 	 7.085577011108398 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-25 17:52:39.890816 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.0890815258026123 	 15.543580055236816 	 0.07749772071838379 	 0.00020933151245117188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:52:58.192734 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.09014654159545898 	 16.077457666397095 	 0.08051848411560059 	 0.0002110004425048828 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:53:15.979078 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09378218650817871 	 16.335063457489014 	 0.08294272422790527 	 0.00010466575622558594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:53:34.119177 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08844995498657227 	 21.292822122573853 	 0.07848238945007324 	 0.00023651123046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:54:00.655967 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.6115832328796387 	 15.817904949188232 	 0.07791996002197266 	 0.00021982192993164062 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:54:20.163826 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09251260757446289 	 16.37974500656128 	 0.0829164981842041 	 0.00013303756713867188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:54:39.702561 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([482, 1],"int64"), ) 	 50878946 	 1000 	 0.11971473693847656 	 21.18728470802307 	 0.10849642753601074 	 0.00023651123046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:55:02.611630 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([496, 1],"int64"), ) 	 50878960 	 1000 	 0.12125754356384277 	 15.836918592453003 	 0.11136531829833984 	 0.0002124309539794922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:55:20.003000 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([512, 1],"int64"), ) 	 50878976 	 1000 	 0.12444877624511719 	 16.334731340408325 	 0.11502671241760254 	 0.00020551681518554688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:55:39.813618 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([482, 1],"int64"), ) 	 50878946 	 1000 	 0.284498929977417 	 15.405805349349976 	 0.273101806640625 	 0.00024509429931640625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:55:58.028215 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([496, 1],"int64"), ) 	 50878960 	 1000 	 0.2927405834197998 	 15.675278425216675 	 0.2831873893737793 	 0.00023436546325683594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:56:16.546908 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([512, 1],"int64"), ) 	 50878976 	 1000 	 0.29918909072875977 	 16.345500469207764 	 0.2895619869232178 	 0.0002422332763671875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:56:37.330921 test begin: paddle.gather_nd(Tensor([1, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), ) 	 1016128 	 1000 	 0.010877609252929688 	 59.72527837753296 	 1.2874603271484375e-05 	 0.00014925003051757812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:57:38.129316 test begin: paddle.gather_nd(Tensor([1, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), ) 	 1016204 	 1000 	 0.019727230072021484 	 71.18642473220825 	 2.4080276489257812e-05 	 0.00021576881408691406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:58:50.290207 test begin: paddle.gather_nd(Tensor([1, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), ) 	 1017116 	 1000 	 0.018552064895629883 	 70.11788821220398 	 1.5735626220703125e-05 	 0.00010609626770019531 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:00:00.631082 test begin: paddle.gather_nd(Tensor([1, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), ) 	 1017440 	 1000 	 0.023029088973999023 	 74.7854733467102 	 2.7894973754882812e-05 	 9.799003601074219e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:01:15.634973 test begin: paddle.gather_nd(Tensor([10, 413, 128],"float32"), index=Tensor([10, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([10, 413, 128],"float32"), index=Tensor([10, 50, 2],"int64"), ) 	 529640 	 1000 	 0.019109010696411133 	 45.54827570915222 	 1.8358230590820312e-05 	 0.0002319812774658203 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:02:01.345241 test begin: paddle.gather_nd(Tensor([10, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([10, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 530640 	 1000 	 0.010929584503173828 	 77.43166923522949 	 1.1920928955078125e-05 	 0.000213623046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:03:18.947963 test begin: paddle.gather_nd(Tensor([10, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([10, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), ) 	 529140 	 1000 	 0.011096477508544922 	 19.31952404975891 	 1.0728836059570312e-05 	 0.00021314620971679688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:03:39.567524 test begin: paddle.gather_nd(Tensor([2, 81, 7168],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([2, 81, 7168],"bfloat16"), Tensor([778, 2],"int64"), ) 	 1162772 	 1000 	 0.035280704498291016 	 59.88896203041077 	 0.02482771873474121 	 0.00021958351135253906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:04:40.211920 test begin: paddle.gather_nd(Tensor([2, 81, 7168],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([2, 81, 7168],"bfloat16"), Tensor([816, 2],"int64"), ) 	 1162848 	 1000 	 0.03611421585083008 	 62.81462740898132 	 0.02559375762939453 	 0.00021886825561523438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:05:43.332010 test begin: paddle.gather_nd(Tensor([20, 198, 128],"float32"), index=Tensor([20, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([20, 198, 128],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 508880 	 1000 	 0.011136531829833984 	 102.42586874961853 	 1.1444091796875e-05 	 0.000217437744140625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:07:25.963145 test begin: paddle.gather_nd(Tensor([20, 198, 128],"float32"), index=Tensor([20, 993, 2],"int64"), )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f85104daaa0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-25 18:17:30.700148 test begin: paddle.gather_nd(Tensor([20, 413, 128],"float32"), index=Tensor([20, 6350, 2],"int64"), )
W0725 18:17:31.003762 116275 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7fe2741a2f50>,)) (kwargs={}) timed out after 600.000000 seconds.

terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753439251 (unix time) try "date -d @1753439251" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c5cb) received by PID 116171 (TID 0x7fe26b6f8640) from PID 116171 ***]

2025-07-25 18:27:43.289217 test begin: paddle.gather_nd(Tensor([20, 413, 128],"float32"), index=Tensor([254, 500, 2],"int64"), )
W0725 18:27:43.595047 123168 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f8dc2c4ed70>,)) (kwargs={}) timed out after 600.000000 seconds.

terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753439863 (unix time) try "date -d @1753439863" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e08a) received by PID 123018 (TID 0x7f8dbe43f640) from PID 123018 ***]

2025-07-25 18:37:50.574221 test begin: paddle.gather_nd(Tensor([20, 413, 62],"float32"), index=Tensor([20, 50, 2],"int64"), )
W0725 18:37:50.952404 129953 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([20, 413, 62],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 514120 	 1000 	 0.01860523223876953 	 113.92129611968994 	 1.8835067749023438e-05 	 0.0003514289855957031 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:39:45.492955 test begin: paddle.gcd(Tensor([10, 50803],"int32"), Tensor([10, 50803],"int32"), )
W0725 18:39:51.832266 131206 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(Tensor([10, 50803],"int32"), Tensor([10, 50803],"int32"), ) 	 1016060 	 1000 	 6.178619623184204 	 0.026177644729614258 	 1.9550323486328125e-05 	 0.01553964614868164 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:39:51.867888 test begin: paddle.gcd(Tensor([25401, 20],"int32"), Tensor([25401, 20],"int32"), )
W0725 18:39:58.495324 131252 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(Tensor([25401, 20],"int32"), Tensor([25401, 20],"int32"), ) 	 1016040 	 1000 	 6.531646490097046 	 0.026489973068237305 	 7.677078247070312e-05 	 0.01627349853515625 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:39:58.534723 test begin: paddle.gcd(x=Tensor([12700, 2, 4, 5],"int32"), y=Tensor([12700, 2, 4, 5],"int32"), )
W0725 18:40:04.885272 131296 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([12700, 2, 4, 5],"int32"), y=Tensor([12700, 2, 4, 5],"int32"), ) 	 1016000 	 1000 	 6.318570137023926 	 0.02656102180480957 	 5.173683166503906e-05 	 0.016164779663085938 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:04.972865 test begin: paddle.gcd(x=Tensor([25401, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0725 18:40:13.530663 131351 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([25401, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 508030 	 1000 	 8.408910274505615 	 0.056565046310424805 	 4.76837158203125e-05 	 0.038870811462402344 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:14.797630 test begin: paddle.gcd(x=Tensor([6, 1, 16934, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0725 18:40:23.645757 131801 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 1, 16934, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 508030 	 1000 	 8.519455909729004 	 0.05626177787780762 	 5.078315734863281e-05 	 0.03867077827453613 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:23.745281 test begin: paddle.gcd(x=Tensor([6, 1, 4, 21168],"int32"), y=Tensor([2, 1, 21168],"int32"), )
W0725 18:40:30.059573 131863 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 1, 4, 21168],"int32"), y=Tensor([2, 1, 21168],"int32"), ) 	 550368 	 1000 	 6.2093024253845215 	 0.055924415588378906 	 4.696846008300781e-05 	 0.04473733901977539 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:30.133895 test begin: paddle.gcd(x=Tensor([6, 2, 4, 10584],"int32"), y=Tensor([6, 2, 4, 10584],"int32"), )
W0725 18:40:36.571564 131916 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 2, 4, 10584],"int32"), y=Tensor([6, 2, 4, 10584],"int32"), ) 	 1016064 	 1000 	 6.407205104827881 	 0.026218891143798828 	 4.482269287109375e-05 	 0.015816688537597656 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:39.208493 test begin: paddle.gcd(x=Tensor([6, 2, 8467, 5],"int32"), y=Tensor([6, 2, 8467, 5],"int32"), )
W0725 18:40:48.180436 131978 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 2, 8467, 5],"int32"), y=Tensor([6, 2, 8467, 5],"int32"), ) 	 1016040 	 1000 	 8.631523609161377 	 0.026365280151367188 	 4.9591064453125e-05 	 0.009719371795654297 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:48.236190 test begin: paddle.gcd(x=Tensor([6, 4233, 4, 5],"int32"), y=Tensor([6, 4233, 4, 5],"int32"), )
W0725 18:40:54.805022 132050 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 4233, 4, 5],"int32"), y=Tensor([6, 4233, 4, 5],"int32"), ) 	 1015920 	 1000 	 6.5376386642456055 	 0.02675318717956543 	 4.649162292480469e-05 	 0.01665806770324707 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:54.846390 test begin: paddle.geometric.segment_max(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.794827938079834 	 10.004422664642334 	 0.0007736682891845703 	 0.00033783912658691406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:41:08.492967 test begin: paddle.geometric.segment_max(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), ) 	 101606480 	 1000 	 1.999258041381836 	 11.406842470169067 	 0.0017371177673339844 	 0.00035190582275390625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:41:29.105324 test begin: paddle.geometric.segment_max(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.4697747230529785 	 9.530571699142456 	 0.0004458427429199219 	 0.00020456314086914062 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:41:40.642176 test begin: paddle.geometric.segment_mean(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), ) 	 26671701 	 1000 	 0.5997684001922607 	 1.2861449718475342 	 0.0005590915679931641 	 0.00024318695068359375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:41:47.282580 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 9.11363673210144 	 13.04629397392273 	 0.009075403213500977 	 0.0019614696502685547 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:43:00.953699 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 5.335798263549805 	 10.331362009048462 	 0.00531315803527832 	 0.0015265941619873047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:44:03.547405 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 10.520944595336914 	 23.11123490333557 	 0.010496377944946289 	 0.004550933837890625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:04.164610 test begin: paddle.geometric.segment_mean(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), ) 	 53343381 	 1000 	 0.4259767532348633 	 0.5903916358947754 	 0.00039124488830566406 	 7.05718994140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:07.067983 test begin: paddle.geometric.segment_mean(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.5777955055236816 	 1.5593576431274414 	 0.0005471706390380859 	 0.0003230571746826172 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:53:15.678647 test begin: paddle.geometric.segment_mean(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.5226664543151855 	 1.3652994632720947 	 0.0004913806915283203 	 0.0002872943878173828 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:56:45.034507 test begin: paddle.geometric.segment_mean(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), ) 	 106686741 	 1000 	 1.922196626663208 	 3.099072217941284 	 0.0018923282623291016 	 0.0005042552947998047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:57:03.821856 test begin: paddle.geometric.segment_min(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), ) 	 26671701 	 1000 	 0.5783836841583252 	 1.0791621208190918 	 0.0005571842193603516 	 8.320808410644531e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:57:06.886539 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 11.414262056350708 	 23.980687856674194 	 0.011355400085449219 	 0.0030553340911865234 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:09.300102 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 8.762460231781006 	 18.509037494659424 	 0.008724451065063477 	 0.0007996559143066406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:57.247042 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 12.119986295700073 	 21.18614172935486 	 0.012066841125488281 	 0.004346132278442383 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:07.750911 test begin: paddle.geometric.segment_min(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), ) 	 53343381 	 1000 	 1.3148221969604492 	 3.4110655784606934 	 0.001065969467163086 	 0.00021004676818847656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:15.632560 test begin: paddle.geometric.segment_min(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.6636307239532471 	 0.6550264358520508 	 0.0006396770477294922 	 7.62939453125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:18.633449 test begin: paddle.geometric.segment_min(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), ) 	 101606480 	 1000 	 1.8674674034118652 	 2.667555570602417 	 0.0018296241760253906 	 0.0005819797515869141 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:27.934550 test begin: paddle.geometric.segment_min(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.5204699039459229 	 0.7709472179412842 	 0.0005009174346923828 	 0.000156402587890625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:30.723611 test begin: paddle.geometric.segment_min(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), ) 	 106686741 	 1000 	 2.291733503341675 	 4.888956546783447 	 0.0022652149200439453 	 0.00058746337890625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:44.417091 test begin: paddle.geometric.segment_sum(Tensor([25401601, 15],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([25401601, 15],"float16"), Tensor([25401601],"int64"), ) 	 406425616 	 1000 	 6.154452562332153 	 4.411099672317505 	 0.006121158599853516 	 2.2531979084014893 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:09.626607 test begin: paddle.geometric.segment_sum(Tensor([25401601, 15],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([25401601, 15],"float32"), Tensor([25401601],"int64"), ) 	 406425616 	 1000 	 5.409541606903076 	 4.450340032577515 	 0.0053691864013671875 	 2.320127487182617 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:39.619353 test begin: paddle.geometric.segment_sum(Tensor([2540161, 20],"float32"), Tensor([2540161],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([2540161, 20],"float32"), Tensor([2540161],"int32"), ) 	 53343381 	 1000 	 0.5480597019195557 	 0.4190070629119873 	 0.0005242824554443359 	 0.21402812004089355 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:42.137602 test begin: paddle.geometric.segment_sum(Tensor([30, 1693441],"float32"), Tensor([30],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([30, 1693441],"float32"), Tensor([30],"int64"), ) 	 50803260 	 1000 	 0.49437808990478516 	 0.32915687561035156 	 0.0004546642303466797 	 0.1681063175201416 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:44.656536 test begin: paddle.geometric.segment_sum(Tensor([30, 3386881],"float16"), Tensor([30],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([30, 3386881],"float16"), Tensor([30],"int64"), ) 	 101606460 	 1000 	 1.3688724040985107 	 1.1044926643371582 	 0.0013484954833984375 	 0.564216136932373 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:51.202451 test begin: paddle.geometric.segment_sum(Tensor([3386881, 15],"float32"), Tensor([3386881],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([3386881, 15],"float32"), Tensor([3386881],"int64"), ) 	 54190096 	 1000 	 0.6851646900177002 	 0.5420072078704834 	 0.0006628036499023438 	 0.2768871784210205 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:54.709944 test begin: paddle.geometric.segment_sum(Tensor([40, 1270081],"float32"), Tensor([40],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([40, 1270081],"float32"), Tensor([40],"int32"), ) 	 50803280 	 1000 	 0.531686544418335 	 0.3958585262298584 	 0.0005135536193847656 	 0.20151591300964355 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:01:57.505644 test begin: paddle.geometric.segment_sum(Tensor([50803201, 20],"float32"), Tensor([50803201],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([50803201, 20],"float32"), Tensor([50803201],"int32"), ) 	 1066867221 	 1000 	 11.978508472442627 	 9.465453863143921 	 0.011903762817382812 	 2.42035174369812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:01.603180 test begin: paddle.geometric.segment_sum(Tensor([6773761, 15],"float16"), Tensor([6773761],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([6773761, 15],"float16"), Tensor([6773761],"int64"), ) 	 108380176 	 1000 	 1.615278959274292 	 1.272090196609497 	 0.0015900135040283203 	 0.6501486301422119 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:08.276248 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, ) 	 25401640 	 1000 	 1.0310277938842773 	 3.9098360538482666 	 0.35125064849853516 	 0.00045299530029296875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:15.657091 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, ) 	 25401640 	 1000 	 1.0788764953613281 	 4.430854558944702 	 0.2203199863433838 	 0.0002617835998535156 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:23.140023 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, ) 	 25401640 	 1000 	 1.0173511505126953 	 3.675848960876465 	 0.34400105476379395 	 0.0004527568817138672 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:32.011286 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, ) 	 25401650 	 1000 	 0.4495406150817871 	 2.2128636837005615 	 0.15303611755371094 	 0.0004642009735107422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:36.928705 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, ) 	 25401650 	 1000 	 0.36910390853881836 	 2.590961217880249 	 0.07389092445373535 	 0.0002086162567138672 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:42.262373 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, ) 	 25401650 	 1000 	 0.44966554641723633 	 2.234011173248291 	 0.15307974815368652 	 0.0004642009735107422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:46.256276 test begin: paddle.geometric.send_ue_recv(Tensor([10, 1693441],"float64"), Tensor([15, 1693441],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 1693441],"float64"), Tensor([15, 1693441],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 42336055 	 1000 	 0.8722426891326904 	 2.834918737411499 	 0.1780705451965332 	 0.00021409988403320312 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:03:52.383348 test begin: paddle.geometric.send_ue_recv(Tensor([10, 2540161],"float64"), Tensor([15, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 2540161],"float64"), Tensor([15, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 63504055 	 1000 	 1.2748212814331055 	 3.55623197555542 	 0.26023221015930176 	 0.0002560615539550781 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:04:00.800121 test begin: paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 33022175 	 1000 	 71.99581408500671 	 3.664320945739746 	 9.131431579589844e-05 	 0.0004949569702148438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:06:32.786876 test begin: paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 33022175 	 1000 	 79.52092266082764 	 2.5986859798431396 	 8.273124694824219e-05 	 0.00021123886108398438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:10:04.153207 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 25401830 	 1000 	 58.122724533081055 	 3.4304611682891846 	 8.58306884765625e-05 	 0.0005130767822265625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:14:06.245215 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 25401830 	 1000 	 64.4520616531372 	 2.407215118408203 	 8.916854858398438e-05 	 6.556510925292969e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:19:09.603678 test begin: paddle.geometric.send_ue_recv(Tensor([1270081, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([1270081, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 25401950 	 1000 	 0.36314964294433594 	 1.598816156387329 	 0.07362222671508789 	 0.00010132789611816406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:19:12.785902 test begin: paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 25401790 	 1000 	 1.2297990322113037 	 1.6812090873718262 	 5.3882598876953125e-05 	 0.0004642009735107422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:19:17.451046 test begin: paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 25401790 	 1000 	 0.4202406406402588 	 1.3856663703918457 	 3.9577484130859375e-05 	 8.58306884765625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:19:21.278667 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", ) 	 50805302 	 1000 	 9.229799032211304 	 6.06247091293335 	 8.487701416015625e-05 	 3.098238229751587 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:20:28.593546 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "mul", ) 	 50805302 	 1000 	 15.57461667060852 	 6.061128854751587 	 8.726119995117188e-05 	 3.0968782901763916 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:21:42.449711 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401830 	 1000 	 4.570020914077759 	 0.05031418800354004 	 8.797645568847656e-05 	 0.03875303268432617 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:21:49.403815 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 25401830 	 1000 	 5.106974124908447 	 0.05030226707458496 	 6.365776062011719e-05 	 0.038651227951049805 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:21:59.375466 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401750 	 1000 	 0.7919347286224365 	 0.011633634567260742 	 3.6716461181640625e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:22:00.911482 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 25401750 	 1000 	 0.33551740646362305 	 0.018158912658691406 	 2.3365020751953125e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:22:02.635345 test begin: paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([100, 1],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([100, 1],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", ) 	 50805302 	 1000 	 15.720657348632812 	 6.063262939453125 	 8.20159912109375e-05 	 3.098243236541748 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:04.084423 test begin: paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25403631 	 1000 	 0.49233126640319824 	 0.011114120483398438 	 4.2438507080078125e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:15.343058 test begin: paddle.geometric.send_uv(Tensor([100, 254017],"float64"), Tensor([100, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 254017],"float64"), Tensor([100, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401830 	 1000 	 6.815510511398315 	 0.05061149597167969 	 8.034706115722656e-05 	 0.03003835678100586 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:24.528219 test begin: paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 26671731 	 1000 	 0.33272767066955566 	 0.01110529899597168 	 3.24249267578125e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:25.973485 test begin: paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 26671731 	 1000 	 0.31783270835876465 	 0.011400222778320312 	 3.4332275390625e-05 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:27.872559 test begin: paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 26671731 	 1000 	 0.0899970531463623 	 0.011044025421142578 	 2.8848648071289062e-05 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:29.071822 test begin: paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 533433651 	 1000 	 0.09912776947021484 	 0.011197090148925781 	 3.719329833984375e-05 	 3.2901763916015625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:23:54.444288 test begin: paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 533433651 	 1000 	 0.09052753448486328 	 0.011325836181640625 	 2.6941299438476562e-05 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:24:16.715842 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 533433651 	 1000 	 0.10964345932006836 	 0.017874479293823242 	 2.9087066650390625e-05 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:24:40.175482 test begin: paddle.greater_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), ) 	 38103936 	 1000 	 0.5631628036499023 	 0.5069773197174072 	 0.5493032932281494 	 0.49142909049987793 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:42.007999 test begin: paddle.greater_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), ) 	 38102688 	 1000 	 0.5542144775390625 	 0.510725736618042 	 0.5448439121246338 	 0.49024152755737305 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:43.715185 test begin: paddle.greater_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), ) 	 31753280 	 1000 	 0.21325063705444336 	 0.21924853324890137 	 0.20384597778320312 	 0.20722103118896484 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:44.676483 test begin: paddle.greater_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), ) 	 25403456 	 1000 	 0.5660316944122314 	 0.44408631324768066 	 0.55670166015625 	 0.43180179595947266 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:46.239920 test begin: paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), ) 	 25405120 	 1000 	 1.0473499298095703 	 0.9120590686798096 	 1.0370118618011475 	 0.8957779407501221 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:48.625613 test begin: paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), ) 	 228616128 	 1000 	 1.7912662029266357 	 1.5714600086212158 	 1.774440050125122 	 1.550776720046997 	 None 	 None 	 None 	 None 	 
2025-07-25 19:24:56.696341 test begin: paddle.greater_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), ) 	 76205064 	 1000 	 1.1146800518035889 	 1.000563144683838 	 1.1053776741027832 	 0.9883990287780762 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:00.159805 test begin: paddle.greater_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), ) 	 76205376 	 1000 	 1.1030807495117188 	 0.9983184337615967 	 1.0938162803649902 	 0.9865901470184326 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:03.515629 test begin: paddle.greater_equal(Tensor([16935, 10, 15, 20],"float32"), Tensor([16935, 10, 15, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([16935, 10, 15, 20],"float32"), Tensor([16935, 10, 15, 20],"float32"), ) 	 101610000 	 1000 	 0.3270082473754883 	 0.3279531002044678 	 0.3177816867828369 	 0.3167698383331299 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:05.846715 test begin: paddle.greater_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), ) 	 76205184 	 1000 	 1.112938642501831 	 0.9997951984405518 	 1.1023917198181152 	 0.988239049911499 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:09.221247 test begin: paddle.greater_equal(Tensor([49613, 1024, 1, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([49613, 1024, 1, 1],"float32"), Tensor([1],"float32"), ) 	 50803713 	 1000 	 0.1900789737701416 	 0.2312946319580078 	 0.1787872314453125 	 0.21932125091552734 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:10.490069 test begin: paddle.greater_equal(Tensor([5, 10, 15, 67738],"float32"), Tensor([5, 10, 15, 67738],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 10, 15, 67738],"float32"), Tensor([5, 10, 15, 67738],"float32"), ) 	 101607000 	 1000 	 0.32727932929992676 	 0.32791757583618164 	 0.31693506240844727 	 0.31693553924560547 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:12.823467 test begin: paddle.greater_equal(Tensor([5, 10, 50804, 20],"float32"), Tensor([5, 10, 50804, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 10, 50804, 20],"float32"), Tensor([5, 10, 50804, 20],"float32"), ) 	 101608000 	 1000 	 0.3421757221221924 	 0.32805752754211426 	 0.3184225559234619 	 0.31435370445251465 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:15.152057 test begin: paddle.greater_equal(Tensor([5, 33869, 15, 20],"float32"), Tensor([5, 33869, 15, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 33869, 15, 20],"float32"), Tensor([5, 33869, 15, 20],"float32"), ) 	 101607000 	 1000 	 0.3279433250427246 	 0.3279762268066406 	 0.31832170486450195 	 0.3168504238128662 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:17.600834 test begin: paddle.greater_equal(Tensor([8, 1024, 1, 6202],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 1024, 1, 6202],"float32"), Tensor([1],"float32"), ) 	 50806785 	 1000 	 0.18844175338745117 	 0.23131799697875977 	 0.17801332473754883 	 0.21642589569091797 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:18.835812 test begin: paddle.greater_equal(Tensor([8, 1024, 6202, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 1024, 6202, 1],"float32"), Tensor([1],"float32"), ) 	 50806785 	 1000 	 0.18744349479675293 	 0.2313222885131836 	 0.17777538299560547 	 0.21950316429138184 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:20.066398 test begin: paddle.greater_equal(Tensor([8, 6350401, 1, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 6350401, 1, 1],"float32"), Tensor([1],"float32"), ) 	 50803209 	 1000 	 0.18819665908813477 	 0.23134827613830566 	 0.17846035957336426 	 0.21663880348205566 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:21.313563 test begin: paddle.greater_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), ) 	 38102784 	 1000 	 0.5689916610717773 	 0.5026702880859375 	 0.5453782081604004 	 0.4905993938446045 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:23.006286 test begin: paddle.greater_than(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19026517868041992 	 0.24908089637756348 	 0.18077373504638672 	 0.23738598823547363 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:24.297915 test begin: paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18802309036254883 	 1.2638325691223145 	 0.1786057949066162 	 0.23758459091186523 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:27.679281 test begin: paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3381845951080322 	 0.33246564865112305 	 0.3177924156188965 	 0.3116903305053711 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:31.165997 test begin: paddle.greater_than(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.32735133171081543 	 0.32796764373779297 	 0.31149864196777344 	 0.3095118999481201 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:33.798040 test begin: paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), )
W0725 19:25:38.603014  3545 dygraph_functions.cc:90428] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), ) 	 203212812 	 1000 	 1.1435675621032715 	 0.722135066986084 	 0.5789413452148438 	 0.7055990695953369 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:41.769219 test begin: paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float64"), ) 	 203212812 	 1000 	 2.028188943862915 	 0.9783592224121094 	 1.0363717079162598 	 0.9666316509246826 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:49.242319 test begin: paddle.greater_than(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.32739806175231934 	 0.3295772075653076 	 0.31857872009277344 	 0.3169267177581787 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:51.637700 test begin: paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), ) 	 203212816 	 1000 	 1.1318793296813965 	 0.7188475131988525 	 0.5777897834777832 	 0.7076983451843262 	 None 	 None 	 None 	 None 	 
2025-07-25 19:25:57.095041 test begin: paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float64"), ) 	 203212816 	 1000 	 2.029524326324463 	 0.9783978462219238 	 1.0379161834716797 	 0.9667086601257324 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:05.073450 test begin: paddle.greater_than(Tensor([4, 3, 2116801],"float16"), Tensor([4, 3, 2116801],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 2116801],"float16"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 0.5167782306671143 	 0.251070499420166 	 0.26404738426208496 	 0.23979663848876953 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:06.880285 test begin: paddle.greater_than(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 0.5698027610778809 	 0.3633537292480469 	 0.29117465019226074 	 0.3522450923919678 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:09.606012 test begin: paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), ) 	 203212824 	 1000 	 1.1306877136230469 	 0.7187998294830322 	 0.5777835845947266 	 0.7009704113006592 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:15.071452 test begin: paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float64"), ) 	 203212824 	 1000 	 2.0279030799865723 	 0.980851411819458 	 1.0363376140594482 	 0.9673502445220947 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:22.237504 test begin: paddle.greater_than(Tensor([4, 3175201, 2],"float16"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3175201, 2],"float16"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 0.5167324542999268 	 0.25105834007263184 	 0.2640717029571533 	 0.23981618881225586 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:24.030346 test begin: paddle.greater_than(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 0.5698196887969971 	 0.36338210105895996 	 0.29112863540649414 	 0.35230493545532227 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:26.899525 test begin: paddle.greater_than(Tensor([4233601, 3, 2],"float16"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4233601, 3, 2],"float16"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 0.5167131423950195 	 0.2511024475097656 	 0.2640256881713867 	 0.2398836612701416 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:28.710863 test begin: paddle.greater_than(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 0.5706567764282227 	 0.3752553462982178 	 0.29131627082824707 	 0.3453023433685303 	 None 	 None 	 None 	 None 	 
2025-07-25 19:26:33.131288 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([1],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([1],"float32"), ) 	 50804737 	 1000 	 0.2991344928741455 	 0.31817126274108887 	 0.2847607135772705 	 0.2908358573913574 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-25 19:27:12.267932 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([2048],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([2048],"float32"), ) 	 50806784 	 1000 	 0.2975287437438965 	 0.3060615062713623 	 0.2874336242675781 	 0.2872457504272461 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-25 19:27:15.882456 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([24807, 2048],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([24807, 2048],"float32"), ) 	 101609472 	 1000 	 0.45224881172180176 	 0.4468495845794678 	 0.4430849552154541 	 0.4355490207672119 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-25 19:27:19.869601 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([169345],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([169345],"float32"), ) 	 50972845 	 1000 	 0.2964656352996826 	 0.3060152530670166 	 0.2858395576477051 	 0.2939128875732422 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-25 19:27:22.790529 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([1],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([1],"float32"), ) 	 50803501 	 1000 	 0.2967264652252197 	 0.30309605598449707 	 0.28681373596191406 	 0.29106807708740234 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-25 19:27:59.785828 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), ) 	 101607000 	 1000 	 0.45142388343811035 	 0.4468495845794678 	 0.4415891170501709 	 0.4354729652404785 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-25 19:28:03.869847 test begin: paddle.histogram(input=Tensor([4, 6350401],"int64"), )
[Prof] paddle.histogram 	 paddle.histogram(input=Tensor([4, 6350401],"int64"), ) 	 25401604 	 1000 	 6.4264140129089355 	 0.7659697532653809 	 0.00037598609924316406 	 0.00041675567626953125 	 None 	 None 	 None 	 None 	 
2025-07-25 19:28:11.562936 test begin: paddle.histogram(input=Tensor([6350401, 4],"int64"), )
[Prof] paddle.histogram 	 paddle.histogram(input=Tensor([6350401, 4],"int64"), ) 	 25401604 	 1000 	 6.433071613311768 	 0.774273157119751 	 0.0003733634948730469 	 0.0004062652587890625 	 None 	 None 	 None 	 None 	 
2025-07-25 19:28:19.295970 test begin: paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0, max=1, ) 	 50803220 	 1000 	 0.1006169319152832 	 0.016018152236938477 	 1.430511474609375e-05 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:28:20.280897 test begin: paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0.2, max=0.9, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0.2, max=0.9, ) 	 50803220 	 1000 	 0.09784793853759766 	 0.01636815071105957 	 1.621246337890625e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:28:21.217566 test begin: paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=1, max=1, ) 	 50803220 	 1000 	 0.09815335273742676 	 0.016259431838989258 	 1.33514404296875e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:28:22.159754 test begin: paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=0, max=1, ) 	 50803205 	 1000 	 0.0990757942199707 	 0.016434192657470703 	 1.9788742065429688e-05 	 4.363059997558594e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:28:23.097358 test begin: paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=0.2, max=0.9, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=0.2, max=0.9, ) 	 50803205 	 1000 	 0.09721565246582031 	 0.016021251678466797 	 1.8835067749023438e-05 	 3.0994415283203125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:28:24.029061 test begin: paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=1, max=1, ) 	 50803205 	 1000 	 0.1029655933380127 	 0.0160677433013916 	 1.9550323486328125e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:28:24.977747 test begin: paddle.histogramdd(Tensor([1270, 2, 2],"float64"), bins=5, weights=Tensor([1270, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, )
/usr/local/lib/python3.10/dist-packages/paddle/tensor/linalg.py:5741: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  edge = paddle.to_tensor(edge)
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([1270, 2, 2],"float64"), bins=5, weights=Tensor([1270, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, ) 	 7620 	 1000 	 1.8324494361877441 	 0.07815957069396973 	 1.4781951904296875e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:28:26.958469 test begin: paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=False, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=False, ) 	 317520 	 1000 	 4.3977272510528564 	 1.2361319065093994 	 2.956390380859375e-05 	 0.000274658203125 	 None 	 None 	 None 	 None 	 
2025-07-25 19:28:32.614279 test begin: paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=True, ) 	 317520 	 1000 	 3.882704973220825 	 1.2863078117370605 	 2.0742416381835938e-05 	 0.0002994537353515625 	 None 	 None 	 None 	 None 	 
2025-07-25 19:28:37.803893 test begin: paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=False, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=False, ) 	 1270080 	 1000 	 20.539873123168945 	 4.351209878921509 	 3.743171691894531e-05 	 0.00024175643920898438 	 None 	 None 	 None 	 None 	 
2025-07-25 19:29:02.766115 test begin: paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=True, ) 	 1270080 	 1000 	 21.045572996139526 	 4.5754218101501465 	 3.0994415283203125e-05 	 0.0001983642578125 	 None 	 None 	 None 	 None 	 
2025-07-25 19:29:28.443609 test begin: paddle.histogramdd(Tensor([63504, 2, 2],"float64"), bins=5, weights=Tensor([63504, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([63504, 2, 2],"float64"), bins=5, weights=Tensor([63504, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, ) 	 381024 	 1000 	 3.2075607776641846 	 0.14113163948059082 	 0.0001690387725830078 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:29:31.812354 test begin: paddle.hsplit(Tensor([1411201, 6, 3],"int64"), list[-1,1,3,], )
W0725 19:29:32.811568 30783 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([1411201, 6, 3],"int64"), list[-1,1,3,], ) 	 25401618 	 1000 	 0.03222155570983887 	 0.009329795837402344 	 1.239776611328125e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:32.996280 test begin: paddle.hsplit(Tensor([1411201, 6, 3],"int64"), list[-1,], )
W0725 19:29:33.728055 30854 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([1411201, 6, 3],"int64"), list[-1,], ) 	 25401618 	 1000 	 0.017238616943359375 	 0.0069925785064697266 	 1.2636184692382812e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:33.916831 test begin: paddle.hsplit(Tensor([1411201, 6, 3],"int64"), list[2,4,], )
W0725 19:29:34.684582 30860 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([1411201, 6, 3],"int64"), list[2,4,], ) 	 25401618 	 1000 	 0.026787519454956055 	 0.008199930191040039 	 0.00011897087097167969 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:34.854525 test begin: paddle.hsplit(Tensor([4, 2116801, 3],"int64"), list[-1,1,3,], )
W0725 19:29:37.657156 30880 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([4, 2116801, 3],"int64"), list[-1,1,3,], ) 	 25401612 	 1000 	 0.05324149131774902 	 0.01538538932800293 	 4.029273986816406e-05 	 9.72747802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:41.258861 test begin: paddle.hsplit(Tensor([4, 2116801, 3],"int64"), list[-1,], )
W0725 19:29:42.026970 30982 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([4, 2116801, 3],"int64"), list[-1,], ) 	 25401612 	 1000 	 0.017560958862304688 	 0.006974458694458008 	 1.0013580322265625e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:42.182569 test begin: paddle.hsplit(Tensor([4, 2116801, 3],"int64"), list[2,4,], )
W0725 19:29:42.948809 30991 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([4, 2116801, 3],"int64"), list[2,4,], ) 	 25401612 	 1000 	 0.024750709533691406 	 0.011721134185791016 	 1.5735626220703125e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:43.124664 test begin: paddle.hsplit(Tensor([4, 6, 1058401],"int64"), list[-1,1,3,], )
W0725 19:29:44.101018 30995 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([4, 6, 1058401],"int64"), list[-1,1,3,], ) 	 25401624 	 1000 	 0.03149604797363281 	 0.009379386901855469 	 2.5272369384765625e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:44.322468 test begin: paddle.hsplit(Tensor([4, 6, 1058401],"int64"), list[-1,], )
W0725 19:29:45.051412 31003 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([4, 6, 1058401],"int64"), list[-1,], ) 	 25401624 	 1000 	 0.0184326171875 	 0.0070912837982177734 	 2.3603439331054688e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:45.159185 test begin: paddle.hsplit(Tensor([4, 6, 1058401],"int64"), list[2,4,], )
W0725 19:29:45.919430 31016 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([4, 6, 1058401],"int64"), list[2,4,], ) 	 25401624 	 1000 	 0.024195432662963867 	 0.008060455322265625 	 1.6927719116210938e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:29:46.086839 test begin: paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9459273815155029 	 0.9247493743896484 	 0.9135725498199463 	 0.9101510047912598 	 0.9285039901733398 	 0.08916211128234863 	 0.8588311672210693 	 4.553794860839844e-05 	 
2025-07-25 19:29:52.269551 test begin: paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3208506107330322 	 0.333498477935791 	 0.2999582290649414 	 0.16006064414978027 	 0.31121349334716797 	 0.07117795944213867 	 0.25722265243530273 	 8.559226989746094e-05 	 
2025-07-25 19:29:56.734229 test begin: paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31931233406066895 	 0.5749192237854004 	 0.29804062843322754 	 0.30664682388305664 	 0.3130929470062256 	 0.07146954536437988 	 0.2409679889678955 	 9.34600830078125e-05 	 
2025-07-25 19:30:01.204243 test begin: paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3234395980834961 	 0.32088637351989746 	 0.301105260848999 	 0.30660128593444824 	 0.31350183486938477 	 0.06783819198608398 	 0.24687957763671875 	 5.054473876953125e-05 	 
2025-07-25 19:30:03.304149 test begin: paddle.hstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9290060997009277 	 0.9357917308807373 	 0.911008358001709 	 0.9082658290863037 	 0.9307920932769775 	 0.06829071044921875 	 0.8643670082092285 	 7.081031799316406e-05 	 
2025-07-25 19:30:09.462468 test begin: paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 25401654 	 1000 	 0.3193652629852295 	 0.32408690452575684 	 0.29868340492248535 	 0.3037374019622803 	 0.3143806457519531 	 0.0692453384399414 	 0.2446885108947754 	 0.00014281272888183594 	 
2025-07-25 19:30:11.571097 test begin: paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.31693315505981445 	 0.3185298442840576 	 0.2990093231201172 	 0.3045945167541504 	 0.313060998916626 	 0.07035470008850098 	 0.2459735870361328 	 4.863739013671875e-05 	 
2025-07-25 19:30:13.644810 test begin: paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9306652545928955 	 0.9295051097869873 	 0.9112646579742432 	 0.9077386856079102 	 0.9312622547149658 	 0.09648799896240234 	 0.8645267486572266 	 7.939338684082031e-05 	 
2025-07-25 19:30:19.833019 test begin: paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.31618762016296387 	 0.31969571113586426 	 0.3007783889770508 	 0.15996384620666504 	 0.31153297424316406 	 0.05820584297180176 	 0.2558097839355469 	 4.982948303222656e-05 	 
2025-07-25 19:30:21.908127 test begin: paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.3173661231994629 	 0.3117959499359131 	 0.299267053604126 	 0.2978086471557617 	 0.3128397464752197 	 0.07809281349182129 	 0.2467963695526123 	 9.298324584960938e-05 	 
2025-07-25 19:30:23.997787 test begin: paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9319450855255127 	 0.928659200668335 	 0.9122552871704102 	 0.9140362739562988 	 0.9453468322753906 	 0.06728887557983398 	 0.8791685104370117 	 5.507469177246094e-05 	 
2025-07-25 19:30:30.190482 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3170289993286133 	 0.3191399574279785 	 0.2947835922241211 	 0.3009779453277588 	 0.3129281997680664 	 0.07253289222717285 	 0.2462475299835205 	 4.0531158447265625e-05 	 
2025-07-25 19:30:32.357047 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9356744289398193 	 0.9682784080505371 	 0.9160294532775879 	 0.9231913089752197 	 0.9422838687896729 	 0.06952166557312012 	 0.8760418891906738 	 7.104873657226562e-05 	 
2025-07-25 19:30:41.445060 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3215670585632324 	 0.31343555450439453 	 0.30014801025390625 	 0.16009140014648438 	 0.3126077651977539 	 0.06056928634643555 	 0.24895143508911133 	 3.361701965332031e-05 	 
2025-07-25 19:30:43.633978 test begin: paddle.hstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.9751238822937012 	 1.3960778713226318 	 0.9570796489715576 	 1.3816940784454346 	 0.9601325988769531 	 0.06844305992126465 	 0.8930923938751221 	 4.4345855712890625e-05 	 
2025-07-25 19:30:50.421043 test begin: paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9285497665405273 	 1.035642385482788 	 0.8985400199890137 	 1.0152676105499268 	 0.9390885829925537 	 0.0786733627319336 	 0.8724155426025391 	 6.008148193359375e-05 	 
2025-07-25 19:30:56.702303 test begin: paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3098759651184082 	 0.31356191635131836 	 0.2860989570617676 	 0.16002368927001953 	 0.3273162841796875 	 0.060494184494018555 	 0.263660192489624 	 3.266334533691406e-05 	 
2025-07-25 19:30:58.819285 test begin: paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 1],"float32"), ) 	 50803220 	 1000 	 0.9639983177185059 	 0.34009528160095215 	 0.24603724479675293 	 0.3095831871032715 	 1.1135945320129395 	 1.8324332237243652 	 0.2275841236114502 	 0.3116481304168701 	 
2025-07-25 19:31:06.506889 test begin: paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 1.4863786697387695 	 0.4511566162109375 	 0.3779110908508301 	 0.4368269443511963 	 1.667651653289795 	 1.7925124168395996 	 0.3408527374267578 	 0.4580550193786621 	 
2025-07-25 19:31:16.449717 test begin: paddle.hypot(Tensor([2540161, 20],"float32"), Tensor([2540161, 20],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([2540161, 20],"float32"), Tensor([2540161, 20],"float32"), ) 	 101606440 	 1000 	 1.4816207885742188 	 0.4529886245727539 	 0.3779006004333496 	 0.4376649856567383 	 1.6658508777618408 	 1.792414665222168 	 0.340695858001709 	 0.45796656608581543 	 
2025-07-25 19:31:24.412479 test begin: paddle.hypot(Tensor([50803201],"float32"), Tensor([1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([50803201],"float32"), Tensor([1],"float32"), ) 	 50803202 	 1000 	 0.962538480758667 	 0.317396879196167 	 0.24618101119995117 	 0.3027768135070801 	 1.0591955184936523 	 1.8043639659881592 	 0.2164914608001709 	 0.30686521530151367 	 
2025-07-25 19:31:30.251696 test begin: paddle.hypot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 1.4792160987854004 	 0.45845699310302734 	 0.3777904510498047 	 0.436908483505249 	 1.6661133766174316 	 1.7924830913543701 	 0.3407623767852783 	 0.45793771743774414 	 
2025-07-25 19:31:40.323309 test begin: paddle.hypot(Tensor([5080321, 10],"float32"), Tensor([5080321, 1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([5080321, 10],"float32"), Tensor([5080321, 1],"float32"), ) 	 55883531 	 1000 	 1.01389741897583 	 0.3353567123413086 	 0.2591216564178467 	 0.31465911865234375 	 1.2980053424835205 	 2.0962166786193848 	 0.3314509391784668 	 0.4284951686859131 	 
2025-07-25 19:31:46.859889 test begin: paddle.i0(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.46574926376342773 	 0.407132625579834 	 0.44892311096191406 	 0.3970921039581299 	 0.4489867687225342 	 0.8564963340759277 	 0.3972897529602051 	 0.43773460388183594 	 
2025-07-25 19:31:50.721959 test begin: paddle.i0(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.46722412109375 	 0.4070878028869629 	 0.45838022232055664 	 0.39702630043029785 	 0.44509434700012207 	 0.8575599193572998 	 0.3655402660369873 	 0.4378089904785156 	 
2025-07-25 19:31:54.695201 test begin: paddle.i0(Tensor([25401601],"float64"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.4945054054260254 	 0.4661273956298828 	 0.4860720634460449 	 0.45609426498413086 	 0.5090372562408447 	 0.9160201549530029 	 0.45705437660217285 	 0.46791601181030273 	 
2025-07-25 19:31:58.138101 test begin: paddle.i0(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.46782875061035156 	 0.4075939655303955 	 0.45835113525390625 	 0.39258527755737305 	 0.4452338218688965 	 0.8546130657196045 	 0.39359426498413086 	 0.43663763999938965 	 
2025-07-25 19:32:01.985467 test begin: paddle.i0(Tensor([50803201],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.4788696765899658 	 0.40712428092956543 	 0.45848536491394043 	 0.3970968723297119 	 0.44521594047546387 	 0.8559796810150146 	 0.39380502700805664 	 0.43769359588623047 	 
2025-07-25 19:32:05.875836 test begin: paddle.i0e(Tensor([25401601],"float64"), )
[Prof] paddle.i0e 	 paddle.i0e(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.39373159408569336 	 0.3718597888946533 	 0.3853874206542969 	 0.3479175567626953 	 0.5888230800628662 	 2.0043931007385254 	 0.5283834934234619 	 0.40976834297180176 	 
2025-07-25 19:32:12.632345 test begin: paddle.i0e(Tensor([50803201],"float32"), )
[Prof] paddle.i0e 	 paddle.i0e(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.43018102645874023 	 0.36759209632873535 	 0.4215543270111084 	 0.35773491859436035 	 0.586932897567749 	 1.9312763214111328 	 0.5242753028869629 	 0.39487361907958984 	 
2025-07-25 19:32:17.775549 test begin: paddle.i1(Tensor([25401601],"float64"), )
[Prof] paddle.i1 	 paddle.i1(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.5015292167663574 	 0.47400617599487305 	 0.4914591312408447 	 0.45816946029663086 	 0.6021168231964111 	 3.206000804901123 	 0.5482008457183838 	 0.29785585403442383 	 
2025-07-25 19:32:23.704936 test begin: paddle.i1(Tensor([50803201],"float32"), )
[Prof] paddle.i1 	 paddle.i1(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.3413083553314209 	 0.41028594970703125 	 0.33258056640625 	 0.40044641494750977 	 0.5893049240112305 	 3.3426613807678223 	 0.5383374691009521 	 0.31044435501098633 	 
2025-07-25 19:32:30.098843 test begin: paddle.i1e(Tensor([25401601],"float64"), )
[Prof] paddle.i1e 	 paddle.i1e(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.39493322372436523 	 0.37291932106018066 	 0.3862149715423584 	 0.3568844795227051 	 0.5907585620880127 	 3.8489341735839844 	 0.5391147136688232 	 0.30284976959228516 	 
2025-07-25 19:32:37.455660 test begin: paddle.i1e(Tensor([50803201],"float32"), )
[Prof] paddle.i1e 	 paddle.i1e(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.5470051765441895 	 0.3065328598022461 	 0.3006901741027832 	 0.2811751365661621 	 0.5872364044189453 	 4.044269561767578 	 0.5263051986694336 	 0.3182680606842041 	 
2025-07-25 19:32:44.779197 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([7576, 13412],"bfloat16"), Tensor([7576, 13412],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
/usr/local/lib/python3.10/dist-packages/paddle/incubate/nn/functional/fused_dropout_add.py:100: UserWarning: Currently, fused_dropout_add maybe has precision problem, so it falls back to dropout + add. 
  warnings.warn(
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([7576, 13412],"bfloat16"), Tensor([7576, 13412],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203218624 	 1000 	 0.44995617866516113 	 0.4500308036804199 	 0.4382822513580322 	 0.4275538921356201 	 0.9636650085449219 	 0.453352689743042 	 0.8921782970428467 	 0.3754549026489258 	 combined
2025-07-25 19:32:52.021149 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([7712, 13176],"bfloat16"), Tensor([7712, 13176],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([7712, 13176],"bfloat16"), Tensor([7712, 13176],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203226624 	 1000 	 0.450423002243042 	 0.452136754989624 	 0.4376091957092285 	 0.42760348320007324 	 0.9632489681243896 	 0.4534728527069092 	 0.8986403942108154 	 0.35302019119262695 	 combined
2025-07-25 19:33:00.147984 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([79381, 1280],"bfloat16"), Tensor([79381, 1280],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([79381, 1280],"bfloat16"), Tensor([79381, 1280],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203215360 	 1000 	 0.44966888427734375 	 0.4500446319580078 	 0.43065690994262695 	 0.4278280735015869 	 0.9626336097717285 	 0.4550609588623047 	 0.8890471458435059 	 0.37715888023376465 	 combined
2025-07-25 19:33:08.012013 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([8168, 12440],"bfloat16"), Tensor([8168, 12440],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([8168, 12440],"bfloat16"), Tensor([8168, 12440],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203219840 	 1000 	 0.4494447708129883 	 0.4553670883178711 	 0.4380056858062744 	 0.4274303913116455 	 0.9624416828155518 	 0.45342206954956055 	 0.8984532356262207 	 0.3745884895324707 	 combined
2025-07-25 19:33:17.988221 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 14176, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0725 19:33:34.768497 37073 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 14176, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 193376768 	 1000 	 10.572158336639404 	 10.575732946395874 	 10.55124545097351 	 10.518761157989502 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:34:10.034849 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 12404],"bfloat16"), Tensor([12404, 8192],"bfloat16"), None, False, None, )
W0725 19:34:18.268309 38987 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 12404],"bfloat16"), Tensor([12404, 8192],"bfloat16"), None, False, None, ) 	 152420352 	 1000 	 5.125734567642212 	 5.259881973266602 	 2.620875120162964 	 2.6849679946899414 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:34:37.870495 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 16384],"bfloat16"), Tensor([16384, 6202],"bfloat16"), None, False, None, )
W0725 19:34:46.593387 40364 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 16384],"bfloat16"), Tensor([16384, 6202],"bfloat16"), None, False, None, ) 	 168722432 	 1000 	 5.7861504554748535 	 5.788156747817993 	 2.953702449798584 	 2.956845283508301 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:35:04.747822 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 24807],"bfloat16"), Tensor([24807, 8192],"bfloat16"), None, False, None, )
W0725 19:35:28.688594 41374 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 24807],"bfloat16"), Tensor([24807, 8192],"bfloat16"), None, False, None, ) 	 304828416 	 1000 	 18.815139532089233 	 21.222583055496216 	 9.613324642181396 	 10.847481727600098 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:36:40.100537 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 8192],"bfloat16"), Tensor([8192, 12404],"bfloat16"), None, transpose_weight=False, )
W0725 19:36:48.514969 45245 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 8192],"bfloat16"), Tensor([8192, 12404],"bfloat16"), None, transpose_weight=False, ) 	 135168000 	 1000 	 5.571679353713989 	 5.607327222824097 	 5.554655075073242 	 5.578273296356201 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:37:06.344092 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 6202, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, )
W0725 19:37:17.611586 46192 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 6202, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, ) 	 235831296 	 1000 	 6.798603296279907 	 6.8160717487335205 	 6.783473253250122 	 6.7702226638793945 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:37:43.714720 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 12404],"bfloat16"), Tensor([12404, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0725 19:38:05.337350 47916 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 12404],"bfloat16"), Tensor([12404, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 260397568 	 1000 	 16.03411555290222 	 16.33987808227539 	 16.01376247406006 	 16.305427312850952 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:38:54.318221 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 7168],"bfloat16"), Tensor([7168, 14176],"bfloat16"), Tensor([14176],"bfloat16"), )
W0725 19:39:05.455752 51959 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 7168],"bfloat16"), Tensor([7168, 14176],"bfloat16"), Tensor([14176],"bfloat16"), ) 	 160348000 	 1000 	 6.873803615570068 	 6.880186557769775 	 6.855083227157593 	 6.8373517990112305 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:39:26.839841 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([2, 4096, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, )
W0725 19:39:40.620350 53844 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([2, 4096, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, ) 	 268435456 	 1000 	 8.624245166778564 	 8.638813018798828 	 8.609349727630615 	 8.604203462600708 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:40:09.119911 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([2, 8192, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0725 19:40:27.907925 55967 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([2, 8192, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 209203712 	 1000 	 12.128410816192627 	 12.127611875534058 	 12.10533618927002 	 12.091193437576294 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:41:07.557952 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([4, 4096, 8192],"bfloat16"), Tensor([8192, 100352],"bfloat16"), None, transpose_weight=False, )
W0725 19:43:40.377688 60822 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([4, 4096, 8192],"bfloat16"), Tensor([8192, 100352],"bfloat16"), None, transpose_weight=False, ) 	 956301312 	 1000 	 109.78634405136108 	 110.62699675559998 	 109.72747087478638 	 110.5530276298523 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:49:24.620358 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([40, 50],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([40, 50],"float32"), None, False, True, ) 	 50805250 	 1000 	 0.4722433090209961 	 0.48239731788635254 	 0.4573209285736084 	 0.4511568546295166 	 0.9013369083404541 	 0.9019665718078613 	 0.3067023754119873 	 0.30677366256713867 	 
2025-07-25 19:49:28.995891 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([50, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([50, 40],"float32"), None, False, False, ) 	 50805250 	 1000 	 0.4663825035095215 	 0.4696798324584961 	 0.4512972831726074 	 0.447437047958374 	 0.9062962532043457 	 0.9085602760314941 	 0.3085043430328369 	 0.3096015453338623 	 
2025-07-25 19:49:33.290886 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1270081, 30],"float32"), Tensor([40, 1270081],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1270081, 30],"float32"), Tensor([40, 1270081],"float32"), None, True, True, ) 	 88905670 	 1000 	 0.3985295295715332 	 0.3949604034423828 	 0.20429587364196777 	 0.20183658599853516 	 0.6887402534484863 	 0.6912655830383301 	 0.17591118812561035 	 0.17638039588928223 	 
2025-07-25 19:49:39.332249 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1693441, 30],"float32"), Tensor([40, 1693441],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1693441, 30],"float32"), Tensor([40, 1693441],"float32"), None, True, True, ) 	 118540870 	 1000 	 0.520909309387207 	 0.5188889503479004 	 0.26618361473083496 	 0.2651252746582031 	 0.9204964637756348 	 0.9210193157196045 	 0.23487234115600586 	 0.2356250286102295 	 
2025-07-25 19:49:45.607079 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([1270081, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([1270081, 40],"float32"), None, False, False, ) 	 88905670 	 1000 	 0.42282700538635254 	 0.4154384136199951 	 0.2159593105316162 	 0.21217799186706543 	 0.7240986824035645 	 0.7333922386169434 	 0.18502330780029297 	 0.18697237968444824 	 
2025-07-25 19:49:49.691785 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([40, 1270081],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([40, 1270081],"float32"), None, False, True, ) 	 88905670 	 1000 	 0.4056088924407959 	 0.40346431732177734 	 0.20723748207092285 	 0.20615077018737793 	 0.6829862594604492 	 0.6866598129272461 	 0.17506957054138184 	 0.17534470558166504 	 
2025-07-25 19:49:53.417833 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([1693441, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([1693441, 40],"float32"), None, False, False, ) 	 118540870 	 1000 	 0.542539119720459 	 0.5379784107208252 	 0.2772178649902344 	 0.27486467361450195 	 0.9568238258361816 	 0.9560019969940186 	 0.24376606941223145 	 0.2435169219970703 	 
2025-07-25 19:49:58.886694 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([40, 1693441],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([40, 1693441],"float32"), None, False, True, ) 	 118540870 	 1000 	 0.5322926044464111 	 0.5309405326843262 	 0.2719895839691162 	 0.27005958557128906 	 0.9127850532531738 	 0.9066162109375 	 0.2327897548675537 	 0.2313556671142578 	 
2025-07-25 19:50:03.731292 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([1016065, 50],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([1016065, 50],"float32"), None, False, True, ) 	 50804750 	 1000 	 0.30164337158203125 	 0.3055121898651123 	 0.28525352478027344 	 0.27901697158813477 	 0.6258101463317871 	 0.626220703125 	 0.21267914772033691 	 0.2131638526916504 	 
2025-07-25 19:50:06.959252 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([50, 1016065],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([50, 1016065],"float32"), None, False, False, ) 	 50804750 	 1000 	 0.29971981048583984 	 0.2961397171020508 	 0.2826120853424072 	 0.2737147808074951 	 0.6470592021942139 	 0.6466562747955322 	 0.21979737281799316 	 0.21970844268798828 	 
2025-07-25 19:50:10.188957 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 1016065],"float32"), Tensor([40, 50],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 1016065],"float32"), Tensor([40, 50],"float32"), None, True, True, ) 	 50805250 	 1000 	 0.46108579635620117 	 0.4746279716491699 	 0.44487547874450684 	 0.43392372131347656 	 0.8887612819671631 	 0.8824539184570312 	 0.3020191192626953 	 0.3003542423248291 	 
2025-07-25 19:50:14.487206 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 30],"float32"), Tensor([1016065, 50],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 30],"float32"), Tensor([1016065, 50],"float32"), None, True, True, ) 	 50804750 	 1000 	 0.30057525634765625 	 0.31685805320739746 	 0.2847716808319092 	 0.2734701633453369 	 0.6521313190460205 	 0.6499440670013428 	 0.22115015983581543 	 0.22122406959533691 	 
2025-07-25 19:50:17.805910 test begin: paddle.incubate.nn.functional.swiglu(Tensor([14176, 7168],"bfloat16"), )
W0725 19:50:20.629772 107149 backward.cc:462] While running Node (SwigluGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.swiglu 	 paddle.incubate.nn.functional.swiglu(Tensor([14176, 7168],"bfloat16"), ) 	 101613568 	 1000 	 0.2294139862060547 	 0.5305519104003906 	 0.22013044357299805 	 0.2687039375305176 	 None 	 None 	 None 	 None 	 combined
2025-07-25 19:50:22.807016 test begin: paddle.incubate.segment_max(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:129: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_max" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_max" instead.
    Reason: paddle.incubate.segment_max will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:147: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_max" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_max" instead.
    Reason: paddle.incubate.segment_max will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_max 	 paddle.incubate.segment_max(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 1.0325162410736084 	 1.0854096412658691 	 0.0010018348693847656 	 0.00021719932556152344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:50:27.195968 test begin: paddle.incubate.segment_mean(Tensor([3, 1693440],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:129: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:147: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_mean 	 paddle.incubate.segment_mean(Tensor([3, 1693440],"float32"), Tensor([3],"int32"), ) 	 5080323 	 1000 	 0.059072017669677734 	 0.2609131336212158 	 3.457069396972656e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:50:34.144668 test begin: paddle.incubate.segment_min(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:129: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_min" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_min" instead.
    Reason: paddle.incubate.segment_min will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:147: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_min" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_min" instead.
    Reason: paddle.incubate.segment_min will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_min 	 paddle.incubate.segment_min(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 0.6856188774108887 	 0.8631727695465088 	 0.0006508827209472656 	 0.00020742416381835938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:50:39.505163 test begin: paddle.incubate.segment_sum(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:129: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_sum" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_sum" instead.
    Reason: paddle.incubate.segment_sum will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:147: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_sum" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_sum" instead.
    Reason: paddle.incubate.segment_sum will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_sum 	 paddle.incubate.segment_sum(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 0.7060372829437256 	 0.5948762893676758 	 0.0006759166717529297 	 0.3039085865020752 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:50:43.081055 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([1013, 1, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([1013, 1, 224, 224],"float32"), ) 	 50828288 	 1000 	 0.26041603088378906 	 0.6209414005279541 	 0.24490737915039062 	 0.1560196876525879 	 0.3292965888977051 	 0.8939211368560791 	 0.2764585018157959 	 0.456740140914917 	 combined
2025-07-25 19:50:48.676790 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([145, 7, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([145, 7, 224, 224],"float32"), ) 	 50928640 	 1000 	 0.26281309127807617 	 0.6192662715911865 	 0.2460308074951172 	 0.15630674362182617 	 0.32706713676452637 	 0.8958020210266113 	 0.26813459396362305 	 0.4576992988586426 	 combined
2025-07-25 19:50:54.030149 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([3, 338, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([3, 338, 224, 224],"float32"), ) 	 50878464 	 1000 	 0.261685848236084 	 0.6150081157684326 	 0.2532999515533447 	 0.1574394702911377 	 0.3293147087097168 	 0.8964128494262695 	 0.2765936851501465 	 0.4572787284851074 	 combined
2025-07-25 19:50:57.964595 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([4511, 11, 32, 32],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([4511, 11, 32, 32],"float32"), ) 	 50811904 	 1000 	 0.7473649978637695 	 0.6799266338348389 	 0.7391068935394287 	 0.17435646057128906 	 0.4489612579345703 	 0.897202730178833 	 0.3979036808013916 	 0.4584488868713379 	 combined
2025-07-25 19:51:02.461102 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([5, 203, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([5, 203, 224, 224],"float32"), ) 	 50928640 	 1000 	 0.2619669437408447 	 0.6131691932678223 	 0.25365114212036133 	 0.15631866455078125 	 0.3284437656402588 	 0.8969635963439941 	 0.2786083221435547 	 0.4576740264892578 	 combined
2025-07-25 19:51:07.560524 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 7088, 32, 32],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 7088, 32, 32],"float32"), ) 	 50806784 	 1000 	 0.9713616371154785 	 0.6815083026885986 	 0.7305150032043457 	 0.1729438304901123 	 0.44754457473754883 	 0.8955576419830322 	 0.3852853775024414 	 0.4581716060638428 	 combined
2025-07-25 19:51:13.053232 test begin: paddle.index_add(Tensor([100, 100, 25402],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 25402],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 25402],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 25402],"float32"), ) 	 304824020 	 1000 	 2.007906436920166 	 3.4710195064544678 	 0.6840863227844238 	 5.9604644775390625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:51:29.967771 test begin: paddle.index_add(Tensor([100, 100, 25],"float32"), Tensor([5081],"int32"), 2, Tensor([100, 100, 5081],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 25],"float32"), Tensor([5081],"int32"), 2, Tensor([100, 100, 5081],"float32"), ) 	 51065081 	 1000 	 1.740067720413208 	 361.2802801132202 	 0.8886415958404541 	 0.0002181529998779297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:57:34.900651 test begin: paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5081],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5081],"float32"), ) 	 60972020 	 1000 	 0.41025638580322266 	 1.77994966506958 	 0.13866019248962402 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:57:41.503121 test begin: paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 2, Tensor([100, 100, 20],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 2, Tensor([100, 100, 20],"float32"), ) 	 51010020 	 1000 	 0.3413717746734619 	 1.7832181453704834 	 0.11583113670349121 	 0.00019240379333496094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:57:45.919653 test begin: paddle.index_add(Tensor([100, 101607, 5],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 101607, 5],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5],"float32"), ) 	 50813520 	 1000 	 0.31119656562805176 	 1.772024393081665 	 0.10576033592224121 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:57:50.024854 test begin: paddle.index_add(Tensor([100, 2540161],"float32"), Tensor([20],"int32"), 0, Tensor([20, 2540161],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 2540161],"float32"), Tensor([20],"int32"), 0, Tensor([20, 2540161],"float32"), ) 	 304819340 	 1000 	 2.0016074180603027 	 3.331038475036621 	 0.6800451278686523 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:58:06.888349 test begin: paddle.index_add(Tensor([100, 508033],"float32"), Tensor([20],"int32"), 0, Tensor([20, 508033],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 508033],"float32"), Tensor([20],"int32"), 0, Tensor([20, 508033],"float32"), ) 	 60963980 	 1000 	 0.40808820724487305 	 2.082808017730713 	 0.1396644115447998 	 0.0002002716064453125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:58:11.978944 test begin: paddle.index_add(Tensor([10160641, 5],"float32"), Tensor([20],"int32"), 0, Tensor([20, 5],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([10160641, 5],"float32"), Tensor([20],"int32"), 0, Tensor([20, 5],"float32"), ) 	 50803325 	 1000 	 0.31871819496154785 	 1.7733674049377441 	 0.10837101936340332 	 9.989738464355469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:58:16.071184 test begin: paddle.index_fill(Tensor([10, 1016065, 10],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 1016065, 10],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606505 	 1000 	 0.8216567039489746 	 1.272752046585083 	 0.0006921291351318359 	 0.10810327529907227 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:58:23.411482 test begin: paddle.index_fill(Tensor([10, 15, 169345],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 169345],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401755 	 1000 	 1.029430627822876 	 0.36965250968933105 	 0.06395626068115234 	 0.12563490867614746 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:58:27.099542 test begin: paddle.index_fill(Tensor([10, 15, 338689],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 338689],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803355 	 1000 	 0.9287805557250977 	 0.17071866989135742 	 0.0007350444793701172 	 0.05815267562866211 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:58:30.551674 test begin: paddle.index_fill(Tensor([10, 15, 677377],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 677377],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606555 	 1000 	 2.0450844764709473 	 0.49925875663757324 	 0.0018944740295410156 	 0.16500473022460938 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:58:39.931647 test begin: paddle.index_fill(Tensor([10, 254017, 10],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 254017, 10],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401705 	 1000 	 0.6649773120880127 	 0.3179302215576172 	 0.04503226280212402 	 0.10803914070129395 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:58:42.440503 test begin: paddle.index_fill(Tensor([10, 508033, 10],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 508033, 10],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803305 	 1000 	 0.347278356552124 	 0.0881044864654541 	 0.0001518726348876953 	 0.02995777130126953 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:58:44.677922 test begin: paddle.index_fill(Tensor([169345, 15, 10],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([169345, 15, 10],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401755 	 1000 	 1.1111595630645752 	 0.4379568099975586 	 0.0700075626373291 	 0.14898180961608887 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:58:48.144076 test begin: paddle.index_fill(Tensor([338689, 15, 10],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([338689, 15, 10],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803355 	 1000 	 1.093735694885254 	 0.16596746444702148 	 0.0009527206420898438 	 0.05651450157165527 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:58:51.909323 test begin: paddle.index_fill(Tensor([677377, 15, 10],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([677377, 15, 10],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606555 	 1000 	 2.463475465774536 	 0.531252384185791 	 0.0023126602172851562 	 0.18079519271850586 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:01.933713 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25628144 	 1000 	 0.3670661449432373 	 0.4654552936553955 	 0.022034883499145508 	 0.012505054473876953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:04.288836 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, ) 	 25628144 	 1000 	 0.3596532344818115 	 0.32950592041015625 	 0.0261533260345459 	 0.08397436141967773 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:06.406515 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25628144 	 1000 	 0.3584318161010742 	 0.45766258239746094 	 0.026165485382080078 	 0.01337742805480957 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:08.703822 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25541904 	 1000 	 0.36020636558532715 	 0.4607560634613037 	 0.021616220474243164 	 0.012423276901245117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:10.951463 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, ) 	 25541904 	 1000 	 0.3502845764160156 	 0.3299286365509033 	 0.02556324005126953 	 0.08515787124633789 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:13.078139 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25541904 	 1000 	 0.3497593402862549 	 0.4689326286315918 	 0.025527000427246094 	 0.013339519500732422 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:15.344883 test begin: paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25435280 	 1000 	 0.35681653022766113 	 0.4599335193634033 	 0.021411895751953125 	 0.012421131134033203 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:17.612925 test begin: paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25435280 	 1000 	 0.3491036891937256 	 0.45479488372802734 	 0.02547931671142578 	 0.013316869735717773 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:19.830973 test begin: paddle.index_sample(Tensor([1865664, 100],"float32"), Tensor([1865664, 14],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 100],"float32"), Tensor([1865664, 14],"int64"), ) 	 212685696 	 1000 	 0.7528965473175049 	 1.140014886856079 	 0.7420618534088135 	 0.38827037811279297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:28.584361 test begin: paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 14],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 14],"int64"), ) 	 78357888 	 1000 	 0.524799108505249 	 0.8109028339385986 	 0.516632080078125 	 0.2740750312805176 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:32.247947 test begin: paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 1],"int64"), ) 	 54104256 	 1000 	 0.41678786277770996 	 0.1539599895477295 	 0.40859341621398926 	 0.07864809036254883 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:59:34.213229 test begin: paddle.index_sample(Tensor([25401601, 100],"float32"), Tensor([25401601, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([25401601, 100],"float32"), Tensor([25401601, 1],"int64"), ) 	 2565561701 	 1000 	 4.54515266418457 	 2.926218032836914 	 4.536843299865723 	 1.2175395488739014 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:00:36.673793 test begin: paddle.index_sample(Tensor([25401601, 20],"float32"), Tensor([25401601, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([25401601, 20],"float32"), Tensor([25401601, 1],"int64"), ) 	 533433621 	 1000 	 4.338082790374756 	 1.7983734607696533 	 4.315895080566406 	 0.9194865226745605 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:00:59.010310 test begin: paddle.index_sample(Tensor([2540161, 20],"float32"), Tensor([2540161, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([2540161, 20],"float32"), Tensor([2540161, 1],"int64"), ) 	 53343381 	 1000 	 0.543102502822876 	 0.19802212715148926 	 0.5346438884735107 	 0.10117268562316895 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:01.224735 test begin: paddle.index_sample(Tensor([508033, 100],"float32"), Tensor([508033, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([508033, 100],"float32"), Tensor([508033, 1],"int64"), ) 	 51311333 	 1000 	 0.11959171295166016 	 0.06471037864685059 	 0.10424542427062988 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:02.596950 test begin: paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 1],"int64"), ) 	 56488256 	 1000 	 0.9619240760803223 	 0.3169090747833252 	 0.9537677764892578 	 0.16196870803833008 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:07.374395 test begin: paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 5],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 5],"int64"), ) 	 77029440 	 1000 	 1.0712759494781494 	 0.8612532615661621 	 1.0630970001220703 	 0.2935011386871338 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:12.203326 test begin: paddle.index_sample(Tensor([5135296, 20],"float32"), Tensor([5135296, 5],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 20],"float32"), Tensor([5135296, 5],"int64"), ) 	 128382400 	 1000 	 1.117734432220459 	 0.9892928600311279 	 1.109562635421753 	 0.33724355697631836 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:18.044412 test begin: paddle.index_sample(Tensor([932832, 100],"float32"), Tensor([932832, 28],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 100],"float32"), Tensor([932832, 28],"int64"), ) 	 119402496 	 1000 	 0.5080804824829102 	 0.8788421154022217 	 0.4999120235443115 	 0.2994344234466553 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:22.884208 test begin: paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 1],"int64"), ) 	 52238592 	 1000 	 0.21311616897583008 	 0.08722543716430664 	 0.20496773719787598 	 0.023123979568481445 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:24.498132 test begin: paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 28],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 28],"int64"), ) 	 77425056 	 1000 	 0.3897373676300049 	 0.7787408828735352 	 0.38156795501708984 	 0.26523852348327637 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:27.895327 test begin: paddle.index_select(Tensor([16, 11109, 286],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 11109, 286],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50834864 	 1000 	 0.20271992683410645 	 0.22359728813171387 	 0.19391298294067383 	 0.21034979820251465 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:29.978704 test begin: paddle.index_select(Tensor([16, 12096, 263],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 12096, 263],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50900048 	 1000 	 0.21300673484802246 	 0.23100590705871582 	 0.20412468910217285 	 0.2175614833831787 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:32.041194 test begin: paddle.index_select(Tensor([16, 39201, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 39201, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50804576 	 1000 	 0.6327879428863525 	 0.5571269989013672 	 0.6239774227142334 	 0.5420165061950684 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:37.113515 test begin: paddle.index_select(Tensor([205, 3060, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([205, 3060, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50811380 	 1000 	 0.6332643032073975 	 1.4662551879882812 	 0.6245687007904053 	 0.5430886745452881 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:45.337624 test begin: paddle.index_select(Tensor([52, 12096, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([52, 12096, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50948432 	 1000 	 0.6353271007537842 	 0.5599894523620605 	 0.6264996528625488 	 0.5463228225708008 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:48.950882 test begin: paddle.index_select(Tensor([57, 11109, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([57, 11109, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 51290333 	 1000 	 0.6401982307434082 	 0.570349931716919 	 0.6313977241516113 	 0.5521845817565918 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:52.654486 test begin: paddle.index_select(Tensor([64, 3060, 260],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([64, 3060, 260],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50918480 	 1000 	 0.21515250205993652 	 0.23335576057434082 	 0.20621061325073242 	 0.22002625465393066 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:54.764977 test begin: paddle.index_select(Tensor([64, 9801, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([64, 9801, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50808464 	 1000 	 0.6347095966339111 	 0.5593323707580566 	 0.6256449222564697 	 0.5457684993743896 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:01:58.393596 test begin: paddle.inner(Tensor([20, 1270081],"float64"), Tensor([1270081],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([20, 1270081],"float64"), Tensor([1270081],"float64"), ) 	 26671701 	 1000 	 0.16526317596435547 	 0.16544032096862793 	 0.08441615104675293 	 0.08443522453308105 	 0.3592827320098877 	 0.3605506420135498 	 0.12190580368041992 	 0.12262821197509766 	 
2025-07-25 20:02:00.041001 test begin: paddle.inner(Tensor([20, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([20, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 533433621 	 1000 	 3.0434601306915283 	 3.052659034729004 	 1.5551297664642334 	 1.5596907138824463 	 6.875041961669922 	 6.879920721054077 	 0.2719457149505615 	 0.2703261375427246 	 
2025-07-25 20:02:31.467733 test begin: paddle.inner(Tensor([508033, 50],"float64"), Tensor([50],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([508033, 50],"float64"), Tensor([50],"float64"), ) 	 25401700 	 1000 	 0.15651607513427734 	 0.15683436393737793 	 0.09833478927612305 	 0.13022851943969727 	 0.379392147064209 	 0.37678027153015137 	 0.12912464141845703 	 0.12813329696655273 	 
2025-07-25 20:02:33.077734 test begin: paddle.is_complex(Tensor([100352, 507],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.0036230087280273438 	 0.0017397403717041016 	 9.775161743164062e-06 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:33.950167 test begin: paddle.is_complex(Tensor([507, 100352],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.0036020278930664062 	 0.0017304420471191406 	 1.33514404296875e-05 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:34.784105 test begin: paddle.is_complex(Tensor([6202, 8192],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.0034699440002441406 	 0.0017900466918945312 	 5.7220458984375e-06 	 1.5020370483398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:35.614482 test begin: paddle.is_complex(Tensor([8192, 6202],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.003530263900756836 	 0.0017466545104980469 	 6.9141387939453125e-06 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:36.461268 test begin: paddle.is_complex(Tensor([886, 57344],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.0043561458587646484 	 0.0022423267364501953 	 8.344650268554688e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:37.283394 test begin: paddle.is_empty(Tensor([10160641, 5],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([10160641, 5],"float32"), ) 	 50803205 	 1000 	 0.0033926963806152344 	 0.0015382766723632812 	 7.62939453125e-06 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:38.116038 test begin: paddle.is_empty(Tensor([16934401, 3],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.003355264663696289 	 0.0015447139739990234 	 8.344650268554688e-06 	 1.430511474609375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:38.942695 test begin: paddle.is_empty(Tensor([2, 25401601],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.0033702850341796875 	 0.001538991928100586 	 5.9604644775390625e-06 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:39.811109 test begin: paddle.is_empty(Tensor([3, 16934401],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([3, 16934401],"float32"), ) 	 50803203 	 1000 	 0.0034437179565429688 	 0.0015604496002197266 	 7.867813110351562e-06 	 1.4066696166992188e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:40.645096 test begin: paddle.is_empty(x=Tensor([4, 32, 396901],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([4, 32, 396901],"float32"), ) 	 50803328 	 1000 	 0.00357818603515625 	 0.0015614032745361328 	 8.106231689453125e-06 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:41.467835 test begin: paddle.is_empty(x=Tensor([4, 396901, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([4, 396901, 32],"float32"), ) 	 50803328 	 1000 	 0.003529071807861328 	 0.0015349388122558594 	 7.867813110351562e-06 	 1.4066696166992188e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:42.305492 test begin: paddle.is_empty(x=Tensor([49613, 32, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([49613, 32, 32],"float32"), ) 	 50803712 	 1000 	 0.0035314559936523438 	 0.0015745162963867188 	 1.8835067749023438e-05 	 1.430511474609375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 20:02:43.115996 test begin: paddle.isclose(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), rtol=1e-05, atol=1e-08, )
[Prof] paddle.isclose 	 paddle.isclose(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), rtol=1e-05, atol=1e-08, ) 	 50803220 	 1000 	 0.3650977611541748 	 3.0855581760406494 	 0.35275959968566895 	 0.24182724952697754 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:48.941897 test begin: paddle.isclose(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), rtol=1e-05, atol=1e-08, )
[Prof] paddle.isclose 	 paddle.isclose(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), rtol=1e-05, atol=1e-08, ) 	 50803220 	 1000 	 0.36364316940307617 	 3.0868465900421143 	 0.351285457611084 	 0.24187040328979492 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:54.671543 test begin: paddle.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), ) 	 50803240 	 1000 	 0.36345958709716797 	 3.086725950241089 	 0.3511691093444824 	 0.2417922019958496 	 None 	 None 	 None 	 None 	 
2025-07-25 20:02:59.264859 test begin: paddle.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 0.3635265827178955 	 3.0866973400115967 	 0.3512568473815918 	 0.24190926551818848 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:03.778166 test begin: paddle.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), ) 	 50803230 	 1000 	 0.3636324405670166 	 3.0866222381591797 	 0.34381771087646484 	 0.24184203147888184 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:08.392079 test begin: paddle.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), ) 	 50803224 	 1000 	 0.36337900161743164 	 3.0867760181427 	 0.35107922554016113 	 0.2418050765991211 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:12.931483 test begin: paddle.isfinite(Tensor([1738, 94, 311],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([1738, 94, 311],"float32"), ) 	 50808692 	 1000 	 0.23340177536010742 	 0.7885475158691406 	 0.21959185600280762 	 0.20136451721191406 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:14.852207 test begin: paddle.isfinite(Tensor([28462, 17, 5, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([28462, 17, 5, 6, 7],"float16"), ) 	 101609340 	 1000 	 0.39806056022644043 	 0.9732062816619873 	 0.3907756805419922 	 0.24831652641296387 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:18.095872 test begin: paddle.isfinite(Tensor([4, 280, 376, 25, 5],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 376, 25, 5],"float32"), ) 	 52640000 	 1000 	 0.2421741485595703 	 0.8147323131561279 	 0.23215436935424805 	 0.2081894874572754 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:20.068511 test begin: paddle.isfinite(Tensor([4, 280, 376, 41, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 376, 41, 3],"float32"), ) 	 51797760 	 1000 	 0.23880290985107422 	 0.8053667545318604 	 0.2288050651550293 	 0.20505070686340332 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:22.004242 test begin: paddle.isfinite(Tensor([4, 280, 605, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 605, 25, 3],"float32"), ) 	 50820000 	 1000 	 0.23416399955749512 	 0.7887282371520996 	 0.2268059253692627 	 0.2014145851135254 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:23.844866 test begin: paddle.isfinite(Tensor([4, 40839, 311],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 40839, 311],"float32"), ) 	 50803716 	 1000 	 0.23476529121398926 	 0.7879793643951416 	 0.22751164436340332 	 0.20089459419250488 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:25.737167 test begin: paddle.isfinite(Tensor([4, 451, 376, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 451, 376, 25, 3],"float32"), ) 	 50872800 	 1000 	 0.2363123893737793 	 0.7884335517883301 	 0.22898650169372559 	 0.20134186744689941 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:27.587210 test begin: paddle.isfinite(Tensor([4, 94, 135115],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 94, 135115],"float32"), ) 	 50803240 	 1000 	 0.2339155673980713 	 0.7885274887084961 	 0.22650790214538574 	 0.2022724151611328 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:29.437173 test begin: paddle.isfinite(Tensor([7, 280, 376, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([7, 280, 376, 25, 3],"float32"), ) 	 55272000 	 1000 	 0.25514698028564453 	 0.8568074703216553 	 0.24770140647888184 	 0.21936750411987305 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:31.483197 test begin: paddle.isfinite(Tensor([8, 17, 17789, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 17789, 6, 7],"float16"), ) 	 101610768 	 1000 	 0.39508938789367676 	 0.9750850200653076 	 0.38138341903686523 	 0.24915838241577148 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:34.873479 test begin: paddle.isfinite(Tensor([8, 17, 5, 21346, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 5, 21346, 7],"float16"), ) 	 101606960 	 1000 	 0.39531946182250977 	 0.9951214790344238 	 0.3815593719482422 	 0.24947857856750488 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:40.200752 test begin: paddle.isfinite(Tensor([8, 17, 5, 6, 24904],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 5, 6, 24904],"float16"), ) 	 101608320 	 1000 	 0.39533495903015137 	 0.9719977378845215 	 0.3882482051849365 	 0.24839472770690918 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:43.441402 test begin: paddle.isfinite(Tensor([8, 60481, 5, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 60481, 5, 6, 7],"float16"), ) 	 101608080 	 1000 	 0.3939342498779297 	 0.9725513458251953 	 0.3868565559387207 	 0.2481670379638672 	 None 	 None 	 None 	 None 	 
2025-07-25 20:03:46.820989 test begin: paddle.isin(Tensor([396901, 64],"float64"), Tensor([4, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([396901, 64],"float64"), Tensor([4, 256],"float64"), False, False, ) 	 25402688 	 1000 	 2.730947971343994 	 21.315890550613403 	 0.002487659454345703 	 0.0008664131164550781 	 None 	 None 	 None 	 None 	 
2025-07-25 20:04:11.458995 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, False, ) 	 50804288 	 1000 	 4.453713655471802 	 25.345744132995605 	 0.004224538803100586 	 0.002029895782470703 	 None 	 None 	 None 	 None 	 
2025-07-25 20:04:42.127376 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, True, ) 	 50804288 	 1000 	 4.538924217224121 	 25.292711973190308 	 0.004279136657714844 	 0.0020363330841064453 	 None 	 None 	 None 	 None 	 
2025-07-25 20:05:12.847659 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, False, ) 	 254016320 	 1000 	 101.02462553977966 	 45.30616521835327 	 0.05265617370605469 	 0.002601146697998047 	 None 	 None 	 None 	 None 	 
2025-07-25 20:07:43.639055 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, True, ) 	 254016320 	 1000 	 101.90247440338135 	 45.267250776290894 	 0.05276846885681152 	 0.0026056766510009766 	 None 	 None 	 None 	 None 	 
2025-07-25 20:10:15.298994 test begin: paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 256],"float64"), False, False, ) 	 25402632 	 1000 	 2.7303571701049805 	 21.311138153076172 	 0.002500772476196289 	 0.0008416175842285156 	 None 	 None 	 None 	 None 	 
2025-07-25 20:10:39.931675 test begin: paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 3175201],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 3175201],"float64"), False, False, ) 	 38102412 	 1000 	 32.355340003967285 	 27.273906469345093 	 0.017521142959594727 	 0.0009748935699462891 	 None 	 None 	 None 	 None 	 
2025-07-25 20:11:40.715147 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, False, ) 	 50804232 	 1000 	 4.4628379344940186 	 25.325751781463623 	 0.0041658878326416016 	 0.002011537551879883 	 None 	 None 	 None 	 None 	 
2025-07-25 20:12:11.432522 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, True, ) 	 50804232 	 1000 	 4.531052112579346 	 25.29826283454895 	 0.004288673400878906 	 0.0020329952239990234 	 None 	 None 	 None 	 None 	 
2025-07-25 20:12:42.932576 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, False, ) 	 76204812 	 1000 	 47.36409139633179 	 30.01971197128296 	 0.03574776649475098 	 0.0021915435791015625 	 None 	 None 	 None 	 None 	 
2025-07-25 20:14:01.980078 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, True, ) 	 76204812 	 1000 	 58.71641755104065 	 30.047797918319702 	 0.03574347496032715 	 0.0021796226501464844 	 None 	 None 	 None 	 None 	 
2025-07-25 20:15:32.215657 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, False, ) 	 50803968 	 1000 	 26.357512712478638 	 8.308168411254883 	 4.9591064453125e-05 	 0.00028252601623535156 	 None 	 None 	 None 	 None 	 
2025-07-25 20:16:07.835578 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, True, ) 	 50803968 	 1000 	 16.80723214149475 	 8.323945760726929 	 4.76837158203125e-05 	 0.0002753734588623047 	 None 	 None 	 None 	 None 	 
2025-07-25 20:16:33.904226 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, False, ) 	 50803716 	 1000 	 21.453227043151855 	 8.315422058105469 	 5.4836273193359375e-05 	 0.0002903938293457031 	 None 	 None 	 None 	 None 	 
2025-07-25 20:17:04.611808 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, True, ) 	 50803716 	 1000 	 16.696117162704468 	 8.343594312667847 	 5.173683166503906e-05 	 0.0002741813659667969 	 None 	 None 	 None 	 None 	 
2025-07-25 20:17:30.719961 test begin: paddle.isin(Tensor([8, 64],"float64"), Tensor([4, 6350401],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float64"), Tensor([4, 6350401],"float64"), False, False, ) 	 25402116 	 1000 	 16.34313178062439 	 12.019763708114624 	 4.696846008300781e-05 	 0.0002472400665283203 	 None 	 None 	 None 	 None 	 
2025-07-25 20:17:59.743121 test begin: paddle.isin(Tensor([8, 64],"float64"), Tensor([99226, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float64"), Tensor([99226, 256],"float64"), False, False, ) 	 25402368 	 1000 	 15.735822916030884 	 12.06455111503601 	 5.245208740234375e-05 	 0.00023245811462402344 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:28.259219 test begin: paddle.isinf(Tensor([14, 226801, 16],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 226801, 16],"float32"), ) 	 50803424 	 1000 	 0.23372721672058105 	 0.48686981201171875 	 0.22470593452453613 	 0.24809908866882324 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:29.821405 test begin: paddle.isinf(Tensor([14, 36655, 99],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 36655, 99],"float32"), ) 	 50803830 	 1000 	 0.23242902755737305 	 0.485567569732666 	 0.21872496604919434 	 0.24810528755187988 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:31.401971 test begin: paddle.isinf(Tensor([14, 64, 56701],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 64, 56701],"float32"), ) 	 50804096 	 1000 	 0.23328900337219238 	 0.4880189895629883 	 0.22604107856750488 	 0.24932146072387695 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:32.976402 test begin: paddle.isinf(Tensor([14, 7, 518401],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 7, 518401],"float32"), ) 	 50803298 	 1000 	 0.23299336433410645 	 0.4868323802947998 	 0.22580456733703613 	 0.24944186210632324 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:34.575428 test begin: paddle.isinf(Tensor([28462, 17, 5, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([28462, 17, 5, 6, 7],"float16"), ) 	 101609340 	 1000 	 0.38991832733154297 	 0.5296359062194824 	 0.3760185241699219 	 0.26624441146850586 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:39.175676 test begin: paddle.isinf(Tensor([49613, 64, 16],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([49613, 64, 16],"float32"), ) 	 50803712 	 1000 	 0.23490047454833984 	 0.4866487979888916 	 0.22756671905517578 	 0.24924087524414062 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:41.081590 test begin: paddle.isinf(Tensor([73310, 7, 99],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([73310, 7, 99],"float32"), ) 	 50803830 	 1000 	 0.23241353034973145 	 0.48551321029663086 	 0.22510886192321777 	 0.24807000160217285 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:42.618638 test begin: paddle.isinf(Tensor([8, 17, 17789, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 17789, 6, 7],"float16"), ) 	 101610768 	 1000 	 0.38937807083129883 	 0.5220496654510498 	 0.3818538188934326 	 0.2674407958984375 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:45.549402 test begin: paddle.isinf(Tensor([8, 17, 5, 21346, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 5, 21346, 7],"float16"), ) 	 101606960 	 1000 	 0.39043140411376953 	 0.5206201076507568 	 0.3832709789276123 	 0.2660212516784668 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:48.329887 test begin: paddle.isinf(Tensor([8, 17, 5, 6, 24904],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 5, 6, 24904],"float16"), ) 	 101608320 	 1000 	 0.39145398139953613 	 0.5236625671386719 	 0.3841989040374756 	 0.2659909725189209 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:51.176350 test begin: paddle.isinf(Tensor([8, 60481, 5, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 60481, 5, 6, 7],"float16"), ) 	 101608080 	 1000 	 0.38743138313293457 	 0.5223495960235596 	 0.3776414394378662 	 0.26599907875061035 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:53.968601 test begin: paddle.isnan(Tensor([10445, 4864],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([10445, 4864],"float32"), ) 	 50804480 	 1000 	 0.23374462127685547 	 0.18595337867736816 	 0.2264573574066162 	 0.17557597160339355 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:55.212962 test begin: paddle.isnan(Tensor([16, 64, 320, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([16, 64, 320, 320],"float16"), ) 	 104857600 	 1000 	 0.40549468994140625 	 0.24310946464538574 	 0.3980274200439453 	 0.22217488288879395 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:57.859562 test begin: paddle.isnan(Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 125, 320, 320],"float32"), ) 	 51200000 	 1000 	 0.23608994483947754 	 0.18869614601135254 	 0.22873759269714355 	 0.1774754524230957 	 None 	 None 	 None 	 None 	 
2025-07-25 20:18:59.162687 test begin: paddle.isnan(Tensor([4, 249, 320, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 249, 320, 320],"float16"), ) 	 101990400 	 1000 	 0.3939831256866455 	 0.22572970390319824 	 0.38671422004699707 	 0.21472382545471191 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:01.729205 test begin: paddle.isnan(Tensor([4, 64, 1241, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 1241, 320],"float16"), ) 	 101662720 	 1000 	 0.3918759822845459 	 0.22591495513916016 	 0.38454103469848633 	 0.21397781372070312 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:04.365837 test begin: paddle.isnan(Tensor([4, 64, 320, 1241],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 320, 1241],"float16"), ) 	 101662720 	 1000 	 0.3918783664703369 	 0.23056435585021973 	 0.3846874237060547 	 0.21539902687072754 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:07.170411 test begin: paddle.isnan(Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 320, 621],"float32"), ) 	 50872320 	 1000 	 0.23449134826660156 	 0.18624544143676758 	 0.22729086875915527 	 0.17263484001159668 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:08.541137 test begin: paddle.isnan(Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 621, 320],"float32"), ) 	 50872320 	 1000 	 0.2359023094177246 	 0.18621826171875 	 0.22848939895629883 	 0.17488932609558105 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:09.785659 test begin: paddle.isnan(Tensor([4864, 10445],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4864, 10445],"float32"), ) 	 50804480 	 1000 	 0.23373746871948242 	 0.1859738826751709 	 0.2265000343322754 	 0.17551684379577637 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:11.029923 test begin: paddle.isnan(Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([8, 64, 320, 320],"float32"), ) 	 52428800 	 1000 	 0.24168038368225098 	 0.19174551963806152 	 0.2261655330657959 	 0.18079113960266113 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:12.389457 test begin: paddle.isneginf(Tensor([11, 17, 2716],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 17, 2716],"int32"), ) 	 507892 	 1000 	 20.645715951919556 	 0.010810613632202148 	 4.8160552978515625e-05 	 2.8371810913085938e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:19:33.079588 test begin: paddle.isneginf(Tensor([11, 17, 5433],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 17, 5433],"int16"), ) 	 1015971 	 1000 	 40.9723334312439 	 0.014623641967773438 	 5.14984130859375e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:20:14.341812 test begin: paddle.isneginf(Tensor([11, 4618, 10],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 4618, 10],"int32"), ) 	 507980 	 1000 	 20.323904991149902 	 0.011857748031616211 	 6.437301635742188e-05 	 6.4849853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:20:34.705407 test begin: paddle.isneginf(Tensor([11, 46184],"float32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 46184],"float32"), ) 	 508024 	 1000 	 20.622349500656128 	 0.010070562362670898 	 4.458427429199219e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:20:55.369650 test begin: paddle.isneginf(Tensor([11, 9236, 10],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 9236, 10],"int16"), ) 	 1015960 	 1000 	 40.55464220046997 	 0.8846995830535889 	 5.030632019042969e-05 	 7.367134094238281e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:21:37.253698 test begin: paddle.isneginf(Tensor([2988, 17, 10],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([2988, 17, 10],"int32"), ) 	 507960 	 1000 	 20.55791163444519 	 0.010911703109741211 	 4.482269287109375e-05 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:21:57.851300 test begin: paddle.isneginf(Tensor([29884, 17],"float32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([29884, 17],"float32"), ) 	 508028 	 1000 	 20.551174640655518 	 0.010219097137451172 	 4.5299530029296875e-05 	 4.100799560546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:22:18.464190 test begin: paddle.isneginf(Tensor([5976, 17, 10],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([5976, 17, 10],"int16"), ) 	 1015920 	 1000 	 41.304052114486694 	 0.012178421020507812 	 4.291534423828125e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:22:59.830304 test begin: paddle.isposinf(Tensor([11, 17, 2716],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 17, 2716],"int32"), ) 	 507892 	 1000 	 20.476247549057007 	 0.010864734649658203 	 4.291534423828125e-05 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:23:20.349921 test begin: paddle.isposinf(Tensor([11, 17, 5433],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 17, 5433],"int16"), ) 	 1015971 	 1000 	 40.66188716888428 	 0.011321067810058594 	 4.7206878662109375e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:24:01.075684 test begin: paddle.isposinf(Tensor([11, 4618, 10],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 4618, 10],"int32"), ) 	 507980 	 1000 	 20.548240661621094 	 0.01076817512512207 	 5.125999450683594e-05 	 3.6716461181640625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:24:21.663734 test begin: paddle.isposinf(Tensor([11, 46184],"float32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 46184],"float32"), ) 	 508024 	 1000 	 20.425775051116943 	 0.009932756423950195 	 4.267692565917969e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:24:42.128458 test begin: paddle.isposinf(Tensor([11, 9236, 10],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 9236, 10],"int16"), ) 	 1015960 	 1000 	 40.61416554450989 	 0.011447429656982422 	 4.363059997558594e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:25:22.838118 test begin: paddle.isposinf(Tensor([2988, 17, 10],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([2988, 17, 10],"int32"), ) 	 507960 	 1000 	 20.325491666793823 	 0.01755046844482422 	 5.364418029785156e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:25:43.208126 test begin: paddle.isposinf(Tensor([29884, 17],"float32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([29884, 17],"float32"), ) 	 508028 	 1000 	 20.122452974319458 	 0.009896039962768555 	 4.410743713378906e-05 	 3.170967102050781e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:03.369491 test begin: paddle.isposinf(Tensor([5976, 17, 10],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([5976, 17, 10],"int16"), ) 	 1015920 	 1000 	 40.16672492027283 	 0.013790130615234375 	 4.363059997558594e-05 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:43.601167 test begin: paddle.isreal(Tensor([1587601, 32],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([1587601, 32],"bool"), ) 	 50803232 	 1000 	 0.04210090637207031 	 0.035782814025878906 	 0.02578139305114746 	 0.02503061294555664 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:44.498505 test begin: paddle.isreal(Tensor([3175201, 32],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([3175201, 32],"bfloat16"), ) 	 101606432 	 1000 	 0.08023905754089355 	 0.07155179977416992 	 0.0642707347869873 	 0.05330848693847656 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:46.324679 test begin: paddle.isreal(Tensor([3175201, 32],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([3175201, 32],"float16"), ) 	 101606432 	 1000 	 0.08012700080871582 	 1.395587682723999 	 0.0638282299041748 	 0.05739927291870117 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:50.002669 test begin: paddle.isreal(Tensor([64, 1587601],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([64, 1587601],"bfloat16"), ) 	 101606464 	 1000 	 0.08051133155822754 	 0.20084261894226074 	 0.06424403190612793 	 0.051729679107666016 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:52.436844 test begin: paddle.isreal(Tensor([64, 1587601],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([64, 1587601],"float16"), ) 	 101606464 	 1000 	 0.07985424995422363 	 0.06890535354614258 	 0.06352782249450684 	 0.05740642547607422 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:54.533826 test begin: paddle.isreal(Tensor([64, 793801],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([64, 793801],"bool"), ) 	 50803264 	 1000 	 0.04204702377319336 	 0.035790443420410156 	 0.02590036392211914 	 0.025180578231811523 	 None 	 None 	 None 	 None 	 
2025-07-25 20:26:55.307610 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([22336, 5, 4, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([22336, 5, 4, 3, 2],"float32"), ) 	 2680420 	 1000 	 9.780835390090942 	 1.3648481369018555 	 8.797645568847656e-05 	 1.3482568264007568 	 14.992425441741943 	 5.963028192520142 	 7.05718994140625e-05 	 1.218980073928833 	 
2025-07-25 20:27:32.089728 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 22336, 4, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 22336, 4, 3, 2],"float32"), ) 	 2680420 	 1000 	 9.774482727050781 	 1.364537239074707 	 0.00013494491577148438 	 1.3437936305999756 	 14.985048770904541 	 5.9663074016571045 	 6.747245788574219e-05 	 1.2197678089141846 	 
2025-07-25 20:28:08.797646 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 13868, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 13868, 3, 2],"float32"), ) 	 2080300 	 1000 	 7.626404285430908 	 1.0586864948272705 	 9.131431579589844e-05 	 1.0425331592559814 	 11.662108421325684 	 4.865072965621948 	 6.628036499023438e-05 	 0.9930930137634277 	 
2025-07-25 20:28:39.544789 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 15401, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 15401, 2],"float32"), ) 	 3080300 	 1000 	 11.146320104598999 	 1.569730520248413 	 8.749961853027344e-05 	 1.5523998737335205 	 16.938220500946045 	 6.460949659347534 	 3.8623809814453125e-05 	 1.320194959640503 	 
2025-07-25 20:29:20.904210 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 8934],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 8934],"float32"), ) 	 2680300 	 1000 	 9.736967086791992 	 1.3625707626342773 	 7.581710815429688e-05 	 1.346022129058838 	 17.26267433166504 	 5.006504058837891 	 5.078315734863281e-05 	 1.022237777709961 	 
2025-07-25 20:29:58.853561 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, ) 	 50808000 	 1000 	 4.009880781173706 	 4.256173372268677 	 1.023700475692749 	 4.1136345863342285 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:30:09.047060 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, keepdim=True, ) 	 50808000 	 1000 	 4.013203382492065 	 4.144778251647949 	 1.0231654644012451 	 4.117117166519165 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:30:18.423699 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=2, ) 	 50808000 	 1000 	 3.0990493297576904 	 2.498199939727783 	 3.089534044265747 	 2.4793498516082764 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:30:25.197569 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, ) 	 50804400 	 1000 	 4.513588905334473 	 11.037013530731201 	 1.149811029434204 	 11.010204315185547 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:30:42.557302 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, keepdim=True, ) 	 50804400 	 1000 	 4.461407899856567 	 11.283624649047852 	 1.1369595527648926 	 11.266982793807983 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:31:00.046070 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=2, ) 	 50804400 	 1000 	 5.223951816558838 	 5.1377012729644775 	 5.214295387268066 	 5.119162559509277 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:31:11.792840 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, ) 	 50808000 	 1000 	 3.9852521419525146 	 4.13934588432312 	 1.014603853225708 	 4.118942737579346 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:31:21.012893 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, keepdim=True, ) 	 50808000 	 1000 	 3.9852194786071777 	 4.149836301803589 	 1.0149948596954346 	 4.120566129684448 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:31:30.389775 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=2, ) 	 50808000 	 1000 	 5.224395036697388 	 5.143282413482666 	 5.214741945266724 	 5.124442100524902 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:31:42.327838 test begin: paddle.lcm(Tensor([1],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([1],"int64"), Tensor([25401601],"int64"), ) 	 25401602 	 1000 	 92.48251247406006 	 5.759867429733276 	 0.002244710922241211 	 0.0009148120880126953 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:33:21.564547 test begin: paddle.lcm(Tensor([25401601],"int64"), Tensor([1],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([25401601],"int64"), Tensor([1],"int64"), ) 	 25401602 	 1000 	 97.25615572929382 	 5.705078840255737 	 0.0022475719451904297 	 0.0009148120880126953 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:35:07.234099 test begin: paddle.lcm(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 106.75311708450317 	 5.8920300006866455 	 0.0024068355560302734 	 0.0009169578552246094 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:37:01.396301 test begin: paddle.lcm(Tensor([50803201],"int32"), Tensor([1],"int32"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([50803201],"int32"), Tensor([1],"int32"), ) 	 50803202 	 1000 	 96.2873764038086 	 7.971088647842407 	 0.0023255348205566406 	 0.001310110092163086 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:38:48.174868 test begin: paddle.ldexp(Tensor([25401601],"float64"), Tensor([25401601],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([25401601],"float64"), Tensor([25401601],"int32"), ) 	 50803202 	 1000 	 1.2822115421295166 	 1.1078996658325195 	 0.32764554023742676 	 0.3699984550476074 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:40:17.185124 test begin: paddle.ldexp(Tensor([25401601],"int64"), Tensor([25401601],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([25401601],"int64"), Tensor([25401601],"int32"), ) 	 50803202 	 1000 	 0.8284649848937988 	 0.6444218158721924 	 0.16911935806274414 	 0.2190401554107666 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:40:51.828306 test begin: paddle.ldexp(Tensor([50803201],"float64"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"float64"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 2.554783344268799 	 2.156403064727783 	 0.6523663997650146 	 0.7340471744537354 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:43:49.757210 test begin: paddle.ldexp(Tensor([50803201],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"int32"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.4733245372772217 	 1.1362004280090332 	 0.3014647960662842 	 0.3847815990447998 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:44:58.359590 test begin: paddle.ldexp(Tensor([50803201],"int64"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"int64"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.6297345161437988 	 1.2745451927185059 	 0.33302879333496094 	 0.4346275329589844 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 20:46:07.552516 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 604801],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 604801],"float32"), 0.36, ) 	 50803285 	 1000 	 0.30007123947143555 	 0.3027036190032959 	 0.15390467643737793 	 0.2887251377105713 	 0.6294410228729248 	 0.749143123626709 	 0.21410870552062988 	 0.1911635398864746 	 
2025-07-25 20:46:11.360236 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 604801, 28],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 604801, 28],"float32"), 0.36, ) 	 50803285 	 1000 	 0.29882264137268066 	 0.3080253601074219 	 0.15270090103149414 	 0.2902677059173584 	 0.6331801414489746 	 0.7489752769470215 	 0.21540307998657227 	 0.19108963012695312 	 
2025-07-25 20:46:15.095418 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([64801, 28, 28],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([64801, 28, 28],"float32"), 0.36, ) 	 50803985 	 1000 	 0.29900097846984863 	 0.32016539573669434 	 0.15276193618774414 	 0.2903263568878174 	 0.6321361064910889 	 0.750216007232666 	 0.21508049964904785 	 0.19109344482421875 	 
2025-07-25 20:46:18.912923 test begin: paddle.lerp(Tensor([1, 1814401, 28],"float32"), Tensor([3, 1814401, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1814401, 28],"float32"), Tensor([3, 1814401, 28],"float32"), 1.0, ) 	 203212912 	 1000 	 1.34450364112854 	 1.3255932331085205 	 0.6876332759857178 	 1.3119144439697266 	 2.2121803760528564 	 2.3578593730926514 	 1.1315991878509521 	 0.8031442165374756 	 
2025-07-25 20:46:32.310005 test begin: paddle.lerp(Tensor([1, 28, 1814401],"float32"), Tensor([3, 28, 1814401],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 28, 1814401],"float32"), Tensor([3, 28, 1814401],"float32"), 1.0, ) 	 203212912 	 1000 	 1.3404884338378906 	 1.3418471813201904 	 0.6849544048309326 	 1.3138351440429688 	 2.2112009525299072 	 2.356578826904297 	 1.1321101188659668 	 0.8031704425811768 	 
2025-07-25 20:46:47.323379 test begin: paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, ) 	 50804768 	 1000 	 0.2998368740081787 	 0.3046913146972656 	 0.15254640579223633 	 0.2911379337310791 	 0.792036771774292 	 0.783238410949707 	 0.2703838348388672 	 0.19958901405334473 	 
2025-07-25 20:46:51.170285 test begin: paddle.lerp(Tensor([3, 28, 604801],"float32"), Tensor([3, 28, 604801],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([3, 28, 604801],"float32"), Tensor([3, 28, 604801],"float32"), 1.2, ) 	 101606568 	 1000 	 0.4539484977722168 	 0.4669663906097412 	 0.23122310638427734 	 0.43571901321411133 	 0.4726297855377197 	 0.5968136787414551 	 0.41396403312683105 	 0.3054506778717041 	 
2025-07-25 20:46:55.732043 test begin: paddle.lerp(Tensor([3, 604801, 28],"float32"), Tensor([3, 604801, 28],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([3, 604801, 28],"float32"), Tensor([3, 604801, 28],"float32"), 1.2, ) 	 101606568 	 1000 	 0.4526498317718506 	 0.4491279125213623 	 0.23128724098205566 	 0.43564701080322266 	 0.47261786460876465 	 0.5968170166015625 	 0.4140892028808594 	 0.3055281639099121 	 
2025-07-25 20:47:00.329525 test begin: paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, ) 	 101607968 	 1000 	 0.45270323753356934 	 0.44698071479797363 	 0.23131299018859863 	 0.4346024990081787 	 0.4734649658203125 	 0.596778154373169 	 0.4150857925415039 	 0.3054475784301758 	 
2025-07-25 20:47:04.805101 test begin: paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.2, ) 	 101607968 	 1000 	 0.4541950225830078 	 0.4470686912536621 	 0.23137164115905762 	 0.42774224281311035 	 0.4736461639404297 	 0.5971086025238037 	 0.4054687023162842 	 0.3057844638824463 	 
2025-07-25 20:47:09.386144 test begin: paddle.less(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.1918628215789795 	 0.2437894344329834 	 0.18202638626098633 	 0.23269033432006836 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:10.654277 test begin: paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18811750411987305 	 0.24430418014526367 	 0.17831110954284668 	 0.23311781883239746 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:11.919803 test begin: paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3265805244445801 	 0.32889366149902344 	 0.31746935844421387 	 0.31867313385009766 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:14.221682 test begin: paddle.less(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.32660937309265137 	 0.32764673233032227 	 0.3174915313720703 	 0.31736254692077637 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:16.510713 test begin: paddle.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.32663488388061523 	 0.32894110679626465 	 0.31760549545288086 	 0.3185908794403076 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:18.842403 test begin: paddle.less(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3266265392303467 	 0.32763004302978516 	 0.31737732887268066 	 0.3173837661743164 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:21.208994 test begin: paddle.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), ) 	 101607424 	 1000 	 0.326265811920166 	 0.328873872756958 	 0.3171987533569336 	 0.3186941146850586 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:23.549869 test begin: paddle.less(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.32658982276916504 	 0.3276486396789551 	 0.31759142875671387 	 0.31748509407043457 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:25.842362 test begin: paddle.less_equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.1906299591064453 	 0.2438371181488037 	 0.18122339248657227 	 0.23263764381408691 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:27.111638 test begin: paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18812823295593262 	 0.2442798614501953 	 0.17872047424316406 	 0.2324662208557129 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:28.364101 test begin: paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.32659244537353516 	 0.3276479244232178 	 0.31769323348999023 	 0.31722593307495117 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:30.663914 test begin: paddle.less_equal(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.32659220695495605 	 0.32765650749206543 	 0.3176579475402832 	 0.31719398498535156 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:33.083793 test begin: paddle.less_equal(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), )
W0725 20:47:36.406875 68714 dygraph_functions.cc:90806] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), ) 	 203212812 	 1000 	 1.1284561157226562 	 1.7915639877319336 	 0.5766041278839111 	 0.7088582515716553 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:39.896246 test begin: paddle.less_equal(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3266255855560303 	 0.32770729064941406 	 0.3177347183227539 	 0.317380428314209 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:42.199672 test begin: paddle.less_equal(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), ) 	 203212816 	 1000 	 1.128462314605713 	 1.3054101467132568 	 0.5766894817352295 	 0.7016274929046631 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:48.748726 test begin: paddle.less_equal(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 0.5697512626647949 	 0.3736543655395508 	 0.29116225242614746 	 0.35236382484436035 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:51.953950 test begin: paddle.less_equal(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), ) 	 203212824 	 1000 	 1.130878210067749 	 0.7345912456512451 	 0.5790877342224121 	 0.711280345916748 	 None 	 None 	 None 	 None 	 
2025-07-25 20:47:57.435949 test begin: paddle.less_equal(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 0.5697450637817383 	 0.3640170097351074 	 0.29114532470703125 	 0.34614133834838867 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:00.174505 test begin: paddle.less_equal(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 0.569727897644043 	 0.36411309242248535 	 0.29109978675842285 	 0.34641098976135254 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:02.900483 test begin: paddle.less_than(Tensor([1, 128, 198451],"int64"), Tensor([1, 128, 198451],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 198451],"int64"), Tensor([1, 128, 198451],"int64"), ) 	 50803456 	 1000 	 0.3101918697357178 	 0.31338000297546387 	 0.3011658191680908 	 0.29911065101623535 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:04.370382 test begin: paddle.less_than(Tensor([1, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), ) 	 50855936 	 1000 	 0.19283342361450195 	 0.2442338466644287 	 0.18307948112487793 	 0.23309564590454102 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:05.788185 test begin: paddle.less_than(Tensor([1, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), ) 	 25460736 	 1000 	 0.2084364891052246 	 0.18163728713989258 	 0.198960542678833 	 0.1701371669769287 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:06.585480 test begin: paddle.less_than(Tensor([1, 128, 396901],"float32"), Tensor([1, 128, 396901],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 396901],"float32"), Tensor([1, 128, 396901],"float32"), ) 	 101606656 	 1000 	 0.32686400413513184 	 0.32771944999694824 	 0.316143274307251 	 0.31742048263549805 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:08.859254 test begin: paddle.less_than(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 256],"float32"), ) 	 101606912 	 1000 	 0.3279566764831543 	 0.3276822566986084 	 0.3187747001647949 	 0.31732654571533203 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:11.222019 test begin: paddle.less_than(Tensor([1, 99226, 256],"int64"), Tensor([1, 99226, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 99226, 256],"int64"), Tensor([1, 99226, 256],"int64"), ) 	 50803712 	 1000 	 0.31026482582092285 	 0.3133563995361328 	 0.3012378215789795 	 0.3031024932861328 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:12.662711 test begin: paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1, 128, 256],"float32"), ) 	 50855936 	 1000 	 0.18941354751586914 	 0.2444605827331543 	 0.17977309226989746 	 0.23322510719299316 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:14.061646 test begin: paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), ) 	 101646336 	 1000 	 0.32637906074523926 	 0.32781386375427246 	 0.31723880767822266 	 0.3176150321960449 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:16.344965 test begin: paddle.less_than(Tensor([3101, 1, 128, 128],"float32"), Tensor([3101, 1, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([3101, 1, 128, 128],"float32"), Tensor([3101, 1, 128, 128],"float32"), ) 	 101613568 	 1000 	 0.32624173164367676 	 0.3276822566986084 	 0.3172025680541992 	 0.3174002170562744 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:18.730820 test begin: paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([1, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([1, 128, 256],"int64"), ) 	 25460736 	 1000 	 0.1757504940032959 	 0.18308544158935547 	 0.16625404357910156 	 0.17075300216674805 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:19.503038 test begin: paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), ) 	 50855936 	 1000 	 0.31066179275512695 	 0.3136017322540283 	 0.2943613529205322 	 0.2968132495880127 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:20.983140 test begin: paddle.less_than(Tensor([8, 1, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), ) 	 50987008 	 1000 	 0.19408965110778809 	 0.2590057849884033 	 0.1844313144683838 	 0.24562716484069824 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:22.283700 test begin: paddle.less_than(Tensor([8, 1, 128, 49613],"float32"), Tensor([8, 1, 128, 49613],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 128, 49613],"float32"), Tensor([8, 1, 128, 49613],"float32"), ) 	 101607424 	 1000 	 0.3276498317718506 	 0.32886314392089844 	 0.31873655319213867 	 0.318530797958374 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:24.597038 test begin: paddle.less_than(Tensor([8, 1, 49613, 128],"float32"), Tensor([8, 1, 49613, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 49613, 128],"float32"), Tensor([8, 1, 49613, 128],"float32"), ) 	 101607424 	 1000 	 0.3262939453125 	 0.32767772674560547 	 0.3171117305755615 	 0.317058801651001 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:26.957462 test begin: paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 1, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 1, 128, 128],"float32"), ) 	 50987008 	 1000 	 0.19143128395080566 	 0.26056599617004395 	 0.1815648078918457 	 0.2488994598388672 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:28.364683 test begin: paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), ) 	 101711872 	 1000 	 0.32662320137023926 	 0.3280508518218994 	 0.3175361156463623 	 0.3178904056549072 	 None 	 None 	 None 	 None 	 
2025-07-25 20:48:30.659188 test begin: paddle.lgamma(Tensor([10, 10, 10, 25402],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 10, 10, 25402],"float64"), ) 	 25402000 	 1000 	 0.7129342555999756 	 0.6935381889343262 	 0.7046399116516113 	 0.6814630031585693 	 1.38981294631958 	 1.5866529941558838 	 1.3395016193389893 	 0.8107686042785645 	 
2025-07-25 20:48:39.230598 test begin: paddle.lgamma(Tensor([10, 10, 127009, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 10, 127009, 2],"float64"), ) 	 25401800 	 1000 	 0.7154722213745117 	 0.6906235218048096 	 0.7072038650512695 	 0.6807544231414795 	 1.3834004402160645 	 1.5893409252166748 	 1.3331243991851807 	 0.8134341239929199 	 
2025-07-25 20:48:44.781257 test begin: paddle.lgamma(Tensor([10, 127009, 10, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 127009, 10, 2],"float64"), ) 	 25401800 	 1000 	 0.7156271934509277 	 0.6918923854827881 	 0.707348108291626 	 0.680361270904541 	 1.3809325695037842 	 1.590705156326294 	 1.3305082321166992 	 0.8120949268341064 	 
2025-07-25 20:48:50.364883 test begin: paddle.lgamma(Tensor([100, 254017],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([100, 254017],"float64"), ) 	 25401700 	 1000 	 0.7131068706512451 	 1.8690812587738037 	 0.7047483921051025 	 0.6774187088012695 	 1.3812470436096191 	 1.5920171737670898 	 1.3204333782196045 	 0.8134346008300781 	 
2025-07-25 20:48:57.979586 test begin: paddle.lgamma(Tensor([127009, 10, 10, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([127009, 10, 10, 2],"float64"), ) 	 25401800 	 1000 	 0.7133955955505371 	 0.7051982879638672 	 0.7050638198852539 	 0.6841902732849121 	 1.3821067810058594 	 1.585716724395752 	 1.3322529792785645 	 0.810206413269043 	 
2025-07-25 20:49:03.467895 test begin: paddle.lgamma(Tensor([1948, 26080],"float32"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([1948, 26080],"float32"), ) 	 50803840 	 1000 	 0.39789342880249023 	 0.3795790672302246 	 0.3895108699798584 	 0.36969828605651855 	 0.9673736095428467 	 1.5086829662322998 	 0.9164040088653564 	 0.770885705947876 	 
2025-07-25 20:49:08.429442 test begin: paddle.lgamma(Tensor([254017, 100],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([254017, 100],"float64"), ) 	 25401700 	 1000 	 0.714214563369751 	 0.6899938583374023 	 0.7059056758880615 	 0.6800594329833984 	 1.3846843242645264 	 1.585822582244873 	 1.3344616889953613 	 0.8103220462799072 	 
2025-07-25 20:49:13.906520 test begin: paddle.lgamma(Tensor([50803201, 1],"float32"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([50803201, 1],"float32"), ) 	 50803201 	 1000 	 0.4011063575744629 	 0.38057589530944824 	 0.39275455474853516 	 0.3693654537200928 	 0.9622728824615479 	 1.5087180137634277 	 0.9118657112121582 	 0.770909309387207 	 
2025-07-25 20:49:18.844352 test begin: paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-1, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-1, ) 	 25401664 	 1000 	 90.45619559288025 	 3.5043442249298096 	 0.0012042522430419922 	 0.05367255210876465 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [4, 396901, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-25 20:51:15.365503 test begin: paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-math.inf, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-math.inf, ) 	 25401664 	 1000 	 86.44718170166016 	 3.4832534790039062 	 0.0011348724365234375 	 0.053436994552612305 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [4, 396901, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-25 20:53:06.607135 test begin: paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-1, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-1, ) 	 25401632 	 1000 	 79.21927809715271 	 3.500458002090454 	 0.0012271404266357422 	 0.0536494255065918 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [793801, 2, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-25 20:54:50.552965 test begin: paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-math.inf, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-math.inf, ) 	 25401632 	 1000 	 78.71869254112244 	 3.481506824493408 	 0.0011675357818603516 	 0.05337643623352051 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [793801, 2, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-25 20:56:33.885542 test begin: paddle.linalg.corrcoef(Tensor([10160641, 5],"float32"), rowvar=False, )
[Error] CUDA out of memory. Tried to allocate 384593.85 GiB. GPU 0 has a total capacity of 39.39 GiB of which 24.05 GiB is free. Process 149191 has 15.33 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 127.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-25 20:56:47.264773 test begin: paddle.linalg.corrcoef(Tensor([4, 12700801],"float32"), )
W0725 20:56:48.271953 115853 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.linalg.corrcoef 	 paddle.linalg.corrcoef(Tensor([4, 12700801],"float32"), ) 	 50803204 	 1000 	 2.879023551940918 	 2.3263330459594727 	 0.1636033058166504 	 0.002025604248046875 	 4.533154487609863 	 3.4469146728515625 	 0.10382509231567383 	 0.0636301040649414 	 
2025-07-25 20:57:02.644495 test begin: paddle.linalg.corrcoef(Tensor([4, 6350401],"float64"), )
[Prof] paddle.linalg.corrcoef 	 paddle.linalg.corrcoef(Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 1.975076675415039 	 1.271787166595459 	 0.11185908317565918 	 0.0009377002716064453 	 4.956777095794678 	 3.358827829360962 	 0.1546928882598877 	 0.0786275863647461 	 
2025-07-25 20:57:14.904615 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([50803201],"int32"), )
W0725 20:57:15.591920 118285 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([50803201],"int32"), ) 	 50803401 	 1000 	 0.6583259105682373 	 0.47330808639526367 	 2.3603439331054688e-05 	 0.00011444091796875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:16.078375 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([25401601],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([25401601],"float64"), ) 	 25401811 	 1000 	 0.7674760818481445 	 0.40690159797668457 	 1.7881393432617188e-05 	 7.534027099609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:17.841288 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([10],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([10],"float64"), ) 	 25401811 	 1000 	 0.7787208557128906 	 0.42296576499938965 	 1.52587890625e-05 	 0.0001380443572998047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:19.503681 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([50803201],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([50803201],"int32"), aweights=None, ) 	 50803401 	 1000 	 0.6293706893920898 	 0.3157362937927246 	 1.71661376953125e-05 	 6.985664367675781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:20.823332 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([10],"int32"), )
W0725 20:57:24.016064 118774 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([10],"int32"), ) 	 25401630 	 1000 	 2.1798272132873535 	 1.7249698638916016 	 0.0015683174133300781 	 0.0009062290191650391 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:25.831504 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([1270081],"int32"), )
W0725 20:57:29.044057 119257 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([1270081],"int32"), ) 	 26671701 	 1000 	 2.1491332054138184 	 1.7170398235321045 	 0.0015742778778076172 	 0.0009050369262695312 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:33.796517 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int32"), aweights=None, ) 	 25401630 	 1000 	 2.2859232425689697 	 1.693955898284912 	 0.0016796588897705078 	 0.0009131431579589844 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:43.166187 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([10],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([10],"float64"), ) 	 25401640 	 1000 	 2.4193005561828613 	 1.78853440284729 	 0.001669168472290039 	 0.0009262561798095703 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:57:52.367794 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int32"), aweights=None, ) 	 26671701 	 1000 	 2.2684056758880615 	 1.6785047054290771 	 0.001688241958618164 	 0.0009202957153320312 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:58:01.188219 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int64"), aweights=Tensor([1270081],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int64"), aweights=Tensor([1270081],"float64"), ) 	 27941782 	 1000 	 2.4781386852264404 	 1.7824907302856445 	 0.0016624927520751953 	 0.0009264945983886719 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 20:58:10.464911 test begin: paddle.linalg.cov(Tensor([20, 25401601],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([25401601],"float64"), )
[Error] CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacity of 39.39 GiB of which 3.26 GiB is free. Process 69861 has 36.13 GiB memory in use. Of the allocated memory 4.37 GiB is allocated by PyTorch, and 7.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-25 21:00:34.644995 test begin: paddle.linalg.det(Tensor([12737, 3, 5, 5],"float32"), )
W0725 21:00:34.890095 135070 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.linalg.det 	 paddle.linalg.det(Tensor([12737, 3, 5, 5],"float32"), ) 	 955275 	 1000 	 11.651500225067139 	 0.13204574584960938 	 0.00010085105895996094 	 8.463859558105469e-05 	 2.11507511138916 	 0.29212164878845215 	 5.2928924560546875e-05 	 9.655952453613281e-05 	 
2025-07-25 21:00:51.310460 test begin: paddle.linalg.det(Tensor([3, 12737, 5, 5],"float32"), )
[Prof] paddle.linalg.det 	 paddle.linalg.det(Tensor([3, 12737, 5, 5],"float32"), ) 	 955275 	 1000 	 11.633515119552612 	 0.12250733375549316 	 0.00012493133544921875 	 7.939338684082031e-05 	 2.107710599899292 	 0.2147367000579834 	 4.57763671875e-05 	 7.05718994140625e-05 	 
2025-07-25 21:01:07.303359 test begin: paddle.linalg.inv(x=Tensor([5, 31752, 4, 4],"float64"), )
[Prof] paddle.linalg.inv 	 paddle.linalg.inv(x=Tensor([5, 31752, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.70467209815979 	 0.3413975238800049 	 0.00010991096496582031 	 7.486343383789062e-05 	 2.2983238697052 	 1.9821252822875977 	 0.3353109359741211 	 0.2889368534088135 	 
2025-07-25 21:01:19.832485 test begin: paddle.linalg.inv(x=Tensor([52920, 3, 4, 4],"float64"), )
[Prof] paddle.linalg.inv 	 paddle.linalg.inv(x=Tensor([52920, 3, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.6990392208099365 	 0.33925509452819824 	 0.00010466575622558594 	 8.130073547363281e-05 	 2.570086717605591 	 1.9809439182281494 	 0.49334287643432617 	 0.28908872604370117 	 
2025-07-25 21:01:32.545692 test begin: paddle.linalg.lu(Tensor([103, 5, 5, 5],"float64"), )
/usr/local/lib/python3.10/dist-packages/torch/functional.py:2162: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([103, 5, 5, 5],"float64"), ) 	 12875 	 1000 	 13.28311014175415 	 0.038945913314819336 	 9.870529174804688e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:01:50.172996 test begin: paddle.linalg.lu(Tensor([106, 5, 5, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([106, 5, 5, 5],"float32"), ) 	 13250 	 1000 	 13.461670875549316 	 0.03804373741149902 	 9.274482727050781e-05 	 3.743171691894531e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:02:08.013710 test begin: paddle.linalg.lu(Tensor([3, 138, 5, 5],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 138, 5, 5],"float64"), ) 	 10350 	 1000 	 10.68372917175293 	 0.03820037841796875 	 4.982948303222656e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:02:22.203481 test begin: paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), ) 	 13275 	 1000 	 13.951069831848145 	 0.0382382869720459 	 0.00010609626770019531 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:02:40.716482 test begin: paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 13.494223356246948 	 0.0383000373840332 	 0.00010180473327636719 	 6.628036499023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:02:58.619579 test begin: paddle.linalg.lu(Tensor([3, 5, 138, 5],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 138, 5],"float64"), ) 	 10350 	 1000 	 0.49059200286865234 	 0.11635637283325195 	 4.00543212890625e-05 	 5.745887756347656e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:02:59.700722 test begin: paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), ) 	 13275 	 1000 	 0.46396446228027344 	 0.11591887474060059 	 4.7206878662109375e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:01.727437 test begin: paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 0.4683394432067871 	 0.11331677436828613 	 4.220008850097656e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:04.200420 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 138],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 138],"float64"), ) 	 10350 	 1000 	 0.5785231590270996 	 0.15088391304016113 	 4.3392181396484375e-05 	 7.534027099609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:05.455016 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), ) 	 13275 	 1000 	 0.5703964233398438 	 0.15346717834472656 	 4.38690185546875e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:06.645573 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 0.5689666271209717 	 0.15656805038452148 	 4.172325134277344e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:07.826187 test begin: paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float32"), Tensor([203, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float32"), Tensor([203, 5, 5],"int32"), ) 	 2545200 	 1000 	 8.676720380783081 	 0.11091136932373047 	 0.00010037422180175781 	 0.013241767883300781 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([203, 5, 5, 5]) and output[0] has a shape of torch.Size([20321, 5, 5, 5]).
2025-07-25 21:03:16.922437 test begin: paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float64"), Tensor([203, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float64"), Tensor([203, 5, 5],"int32"), ) 	 2545200 	 1000 	 8.830643653869629 	 0.14799070358276367 	 4.9591064453125e-05 	 0.018802642822265625 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([203, 5, 5, 5]) and output[0] has a shape of torch.Size([20321, 5, 5, 5]).
2025-07-25 21:03:26.405690 test begin: paddle.linalg.lu_unpack(Tensor([3, 5, 5, 338689],"float64"), Tensor([3, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([3, 5, 5, 338689],"float64"), Tensor([3, 5, 5],"int32"), ) 	 25401750 	 1000 	 0.9397895336151123 	 0.36420774459838867 	 7.772445678710938e-05 	 0.04656028747558594 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:30.369782 test begin: paddle.linalg.lu_unpack(Tensor([3, 5, 5, 677377],"float32"), Tensor([3, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([3, 5, 5, 677377],"float32"), Tensor([3, 5, 5],"int32"), ) 	 50803350 	 1000 	 1.192821979522705 	 0.40646958351135254 	 5.555152893066406e-05 	 0.05187511444091797 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:03:39.201560 test begin: paddle.linalg.lu_unpack(Tensor([4064, 5, 5, 5],"float32"), Tensor([406, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([4064, 5, 5, 5],"float32"), Tensor([406, 5, 5],"int32"), ) 	 518150 	 1000 	 15.713220834732056 	 0.06451702117919922 	 0.00011539459228515625 	 6.651878356933594e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([406, 5, 5, 5]) and output[0] has a shape of torch.Size([4064, 5, 5, 5]).
2025-07-25 21:03:55.161142 test begin: paddle.linalg.lu_unpack(Tensor([6773, 5, 5, 3],"float32"), Tensor([277, 5, 3],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([6773, 5, 5, 3],"float32"), Tensor([277, 5, 3],"int32"), ) 	 512130 	 1000 	 10.691393613815308 	 0.07916378974914551 	 0.00010132789611816406 	 8.20159912109375e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([277, 5, 5, 5]) and output[0] has a shape of torch.Size([6773, 5, 5, 5]).
2025-07-25 21:04:06.356184 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4233601],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 4233601],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401606 	 1000 	 0.9423329830169678 	 0.2041456699371338 	 0.11967301368713379 	 0.15755391120910645 	 1.2985308170318604 	 1.2545616626739502 	 0.4414710998535156 	 0.32065749168395996 	 
2025-07-25 21:04:12.022378 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 	 25401630 	 1000 	 17.255702257156372 	 17.348777055740356 	 7.987022399902344e-05 	 0.0003180503845214844 	 1.3040812015533447 	 1.7042231559753418 	 0.07031393051147461 	 0.24948668479919434 	 
2025-07-25 21:04:50.469757 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 	 25401630 	 1000 	 17.624406814575195 	 17.796777725219727 	 8.440017700195312e-05 	 0.00027298927307128906 	 1.3088247776031494 	 1.7027678489685059 	 0.06724858283996582 	 0.24815034866333008 	 
2025-07-25 21:05:30.714226 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3175201, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3175201, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401608 	 1000 	 5.246854543685913 	 0.1588888168334961 	 1.7884416580200195 	 0.08117246627807617 	 1.083662986755371 	 0.9091877937316895 	 0.3693053722381592 	 0.23328471183776855 	 
2025-07-25 21:05:40.091058 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 	 25401640 	 1000 	 17.727030754089355 	 16.06962776184082 	 0.0002570152282714844 	 0.0002493858337402344 	 2.5729424953460693 	 1.7613577842712402 	 0.1385180950164795 	 0.2570629119873047 	 
2025-07-25 21:06:18.939450 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 	 25401640 	 1000 	 17.665979623794556 	 16.064903497695923 	 0.00022363662719726562 	 0.0002503395080566406 	 2.5689988136291504 	 1.7609550952911377 	 0.13161396980285645 	 0.2570781707763672 	 
2025-07-25 21:06:57.868934 test begin: paddle.linalg.matrix_norm(x=Tensor([2116801, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2116801, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401612 	 1000 	 5.245326042175293 	 0.15882587432861328 	 1.7882397174835205 	 0.08112430572509766 	 1.0837104320526123 	 0.907883882522583 	 0.36962151527404785 	 0.2320704460144043 	 
2025-07-25 21:07:05.979489 test begin: paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-10, ) 	 25411584 	 1000 	 7.199092864990234 	 6.2572407722473145 	 0.003222942352294922 	 0.0015251636505126953 	 20.571372270584106 	 6.765792369842529 	 0.016367435455322266 	 0.4602820873260498 	 
2025-07-25 21:07:48.113353 test begin: paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-2, ) 	 25411584 	 1000 	 4.753289699554443 	 5.030360221862793 	 0.0003223419189453125 	 0.00036787986755371094 	 6.181114435195923 	 2.6166460514068604 	 0.00222015380859375 	 0.44530296325683594 	 
2025-07-25 21:08:07.906006 test begin: paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-10, ) 	 25417728 	 1000 	 7.212307453155518 	 8.085566997528076 	 0.0036008358001708984 	 0.0015308856964111328 	 20.578073978424072 	 6.7704620361328125 	 0.0163421630859375 	 0.46044182777404785 	 
2025-07-25 21:08:52.702820 test begin: paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-2, ) 	 25417728 	 1000 	 4.702619552612305 	 5.0378124713897705 	 0.00032830238342285156 	 0.0003638267517089844 	 6.18046498298645 	 2.617367744445801 	 0.0022110939025878906 	 0.4454050064086914 	 
2025-07-25 21:09:12.427440 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 2005, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 2005, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25407360 	 1000 	 17.468772888183594 	 17.13184690475464 	 0.34349727630615234 	 0.3504929542541504 	 46.53466868400574 	 42.68449091911316 	 0.3645944595336914 	 0.4263796806335449 	 
2025-07-25 21:11:19.085930 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 1719, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 1719, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.469230890274048 	 17.118247032165527 	 0.34366416931152344 	 0.35059237480163574 	 46.5334198474884 	 42.84137177467346 	 0.3634524345397949 	 0.42691469192504883 	 
2025-07-25 21:13:25.997519 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 3151, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 3151, 4, 4],"float64"), n=3, ) 	 25409664 	 1000 	 17.466237545013428 	 17.11388111114502 	 0.3437056541442871 	 0.3503234386444092 	 46.47758984565735 	 42.716453552246094 	 0.3634476661682129 	 0.4280390739440918 	 
2025-07-25 21:15:31.123686 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 287, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 287, 11, 4, 4],"float64"), n=3, ) 	 25458048 	 1000 	 17.49327039718628 	 17.155391454696655 	 0.34429073333740234 	 0.3510761260986328 	 46.71482014656067 	 42.856300354003906 	 0.3642435073852539 	 0.4272458553314209 	 
2025-07-25 21:17:39.272761 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-10, ) 	 25411584 	 1000 	 7.229973077774048 	 6.253397703170776 	 0.003214597702026367 	 0.0015337467193603516 	 20.591060876846313 	 6.76482629776001 	 0.01639246940612793 	 0.46027183532714844 	 
2025-07-25 21:18:21.596234 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-2, ) 	 25411584 	 1000 	 4.724068880081177 	 5.040949106216431 	 0.00032711029052734375 	 0.0003592967987060547 	 6.191047668457031 	 2.619521141052246 	 0.0022172927856445312 	 0.44792699813842773 	 
2025-07-25 21:18:42.264711 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-10, ) 	 25417728 	 1000 	 7.218900680541992 	 6.2548089027404785 	 0.003221273422241211 	 0.00145721435546875 	 20.58900737762451 	 6.765731334686279 	 0.016396284103393555 	 0.46036720275878906 	 
2025-07-25 21:19:24.906021 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-2, ) 	 25417728 	 1000 	 4.764282464981079 	 5.0286102294921875 	 0.00031447410583496094 	 0.0003771781921386719 	 6.177001237869263 	 2.6171908378601074 	 0.0022101402282714844 	 0.4467647075653076 	 
2025-07-25 21:19:45.330507 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-10, ) 	 25436160 	 1000 	 7.200837135314941 	 6.278705835342407 	 0.0032210350036621094 	 0.0015337467193603516 	 20.614134550094604 	 6.770820140838623 	 0.016382932662963867 	 0.46063804626464844 	 
2025-07-25 21:20:27.618877 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-2, ) 	 25436160 	 1000 	 4.724579811096191 	 5.061672925949097 	 0.0003161430358886719 	 0.0003597736358642578 	 6.180805444717407 	 2.6190648078918457 	 0.0021622180938720703 	 0.4471769332885742 	 
2025-07-25 21:20:49.202160 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 573, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 573, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.491966009140015 	 17.120771646499634 	 0.3439772129058838 	 0.3508272171020508 	 46.49469590187073 	 42.78362059593201 	 0.36308741569519043 	 0.4280095100402832 	 
2025-07-25 21:22:54.528600 test begin: paddle.linalg.matrix_power(x=Tensor([3, 573, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 573, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.48479175567627 	 17.123933792114258 	 0.3457372188568115 	 0.3506150245666504 	 46.520004749298096 	 42.68116760253906 	 0.3634161949157715 	 0.42685914039611816 	 
2025-07-25 21:24:59.629039 test begin: paddle.linalg.matrix_power(x=Tensor([860, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([860, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25428480 	 1000 	 17.483742713928223 	 17.134085178375244 	 0.34958887100219727 	 0.3505666255950928 	 46.616827726364136 	 42.809014558792114 	 0.3683288097381592 	 0.4267258644104004 	 
2025-07-25 21:27:05.589548 test begin: paddle.linalg.matrix_transpose(Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([2, 3, 8467201],"float32"), ) 	 50803206 	 1000 	 0.004552364349365234 	 0.00415349006652832 	 7.152557373046875e-06 	 4.9114227294921875e-05 	 0.03887128829956055 	 0.052538156509399414 	 5.221366882324219e-05 	 5.0067901611328125e-05 	 combined
2025-07-25 21:27:07.390076 test begin: paddle.linalg.matrix_transpose(Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([2, 6350401, 4],"float32"), ) 	 50803208 	 1000 	 0.007005214691162109 	 0.0038933753967285156 	 3.600120544433594e-05 	 2.0265579223632812e-05 	 0.03857707977294922 	 0.05382490158081055 	 2.7179718017578125e-05 	 5.245208740234375e-05 	 combined
2025-07-25 21:27:09.170470 test begin: paddle.linalg.matrix_transpose(Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([4233601, 3, 4],"float32"), ) 	 50803212 	 1000 	 0.004567623138427734 	 0.003939390182495117 	 1.0251998901367188e-05 	 1.9073486328125e-05 	 0.039148807525634766 	 0.053876399993896484 	 3.361701965332031e-05 	 6.341934204101562e-05 	 combined
2025-07-25 21:27:11.050800 test begin: paddle.linalg.multi_dot(list[Tensor([25401601],"float64"),Tensor([25401601, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([25401601],"float64"),Tensor([25401601, 31],"float64"),], ) 	 812851232 	 1000 	 6.221966981887817 	 6.222919940948486 	 3.1775729656219482 	 3.1760547161102295 	 12.587153434753418 	 12.586108446121216 	 0.5019388198852539 	 0.49866437911987305 	 
2025-07-25 21:28:08.422150 test begin: paddle.linalg.multi_dot(list[Tensor([4, 4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4, 4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401620 	 1000 	 0.9981000423431396 	 0.7749490737915039 	 0.11310482025146484 	 0.11309242248535156 	 2.0266473293304443 	 2.0491697788238525 	 0.2300257682800293 	 0.23466849327087402 	 
2025-07-25 21:28:16.849929 test begin: paddle.linalg.multi_dot(list[Tensor([4233601, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4233601, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 25401656 	 1000 	 2.1529757976531982 	 1.0502586364746094 	 0.31424975395202637 	 0.15332627296447754 	 3.3962762355804443 	 2.142119884490967 	 0.15122175216674805 	 0.1875624656677246 	 
2025-07-25 21:28:26.629574 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401608 	 1000 	 0.19454312324523926 	 0.19399309158325195 	 0.1787724494934082 	 0.16878366470336914 	 0.5721640586853027 	 0.5673248767852783 	 0.06498861312866211 	 0.0644233226776123 	 
2025-07-25 21:28:28.841520 test begin: paddle.linalg.multi_dot(list[Tensor([6350401, 4],"float64"),Tensor([4, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([6350401, 4],"float64"),Tensor([4, 31],"float64"),], ) 	 25401728 	 1000 	 1.7419157028198242 	 1.7872278690338135 	 0.2532386779785156 	 0.2590503692626953 	 3.4229373931884766 	 3.7549140453338623 	 0.38798975944519043 	 0.42670249938964844 	 
2025-07-25 21:28:45.412780 test begin: paddle.linalg.multi_dot(list[Tensor([8, 3175201],"float64"),Tensor([3175201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 3175201],"float64"),Tensor([3175201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 34927243 	 1000 	 0.40125131607055664 	 0.4084815979003906 	 0.10217094421386719 	 0.10371017456054688 	 1.9556519985198975 	 1.6166372299194336 	 0.11103510856628418 	 0.1370408535003662 	 
2025-07-25 21:28:50.631056 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401682 	 1000 	 1.3607847690582275 	 1.4117796421051025 	 0.1546487808227539 	 0.16118597984313965 	 3.464332342147827 	 2.1315689086914062 	 0.14713382720947266 	 0.16694402694702148 	 
2025-07-25 21:29:00.710479 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 5080321],"float64"),Tensor([5080321, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 5080321],"float64"),Tensor([5080321, 5],"float64"),], ) 	 40642634 	 1000 	 0.6482048034667969 	 0.6328198909759521 	 0.16514968872070312 	 0.16137456893920898 	 3.0569443702697754 	 2.5050160884857178 	 0.1559898853302002 	 0.18389129638671875 	 
2025-07-25 21:29:08.431073 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 8467201],"float64"),Tensor([8467201, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 8467201],"float64"),Tensor([8467201, 5],"float64"),], ) 	 67737674 	 1000 	 1.0472028255462646 	 1.026444911956787 	 0.2665541172027588 	 0.26145315170288086 	 5.044366836547852 	 4.163716554641724 	 0.18421149253845215 	 0.19443821907043457 	 
2025-07-25 21:29:22.991870 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 4233601],"float64"),Tensor([4233601, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 4233601],"float64"),Tensor([4233601, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 42336078 	 1000 	 0.5260176658630371 	 0.5305967330932617 	 0.1339399814605713 	 0.13624048233032227 	 2.5821728706359863 	 2.1376163959503174 	 0.1316852569580078 	 0.15593695640563965 	 
2025-07-25 21:29:29.672861 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 6350401],"float64"),Tensor([6350401, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 6350401],"float64"),Tensor([6350401, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 63504078 	 1000 	 0.7733476161956787 	 0.7782411575317383 	 0.19698095321655273 	 0.19849753379821777 	 3.83909273147583 	 3.1991021633148193 	 0.1639857292175293 	 0.1818528175354004 	 
2025-07-25 21:29:41.938482 test begin: paddle.linalg.multi_dot(list[Tensor([8, 8467201],"float64"),Tensor([8467201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 8467201],"float64"),Tensor([8467201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 93139243 	 1000 	 1.0217525959014893 	 1.0313091278076172 	 0.2594931125640869 	 0.26172518730163574 	 5.106450319290161 	 4.2547948360443115 	 0.1858046054840088 	 0.19715499877929688 	 
2025-07-25 21:29:55.404803 test begin: paddle.linalg.multi_dot(list[Tensor([819407],"float64"),Tensor([819407, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([819407],"float64"),Tensor([819407, 31],"float64"),], ) 	 26221024 	 1000 	 0.1639246940612793 	 0.16405248641967773 	 0.0837090015411377 	 0.0837392807006836 	 0.4454069137573242 	 0.3366119861602783 	 0.22752737998962402 	 0.17188143730163574 	 
2025-07-25 21:29:57.083405 test begin: paddle.linalg.norm(Tensor([12700801, 1, 4],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([12700801, 1, 4],"float32"), p=1.0, axis=-1, ) 	 50803204 	 1000 	 0.406583309173584 	 0.48803067207336426 	 0.3859214782714844 	 0.4677309989929199 	 1.9871375560760498 	 0.6396269798278809 	 1.9358108043670654 	 0.3267631530761719 	 
2025-07-25 21:30:01.668985 test begin: paddle.linalg.norm(Tensor([25402, 50, 20],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([25402, 50, 20],"float64"), p=2.0, axis=-1, ) 	 25402000 	 1000 	 0.32119274139404297 	 0.26819610595703125 	 0.1636364459991455 	 0.2479543685913086 	 1.464421272277832 	 0.93668532371521 	 1.4133713245391846 	 0.23904037475585938 	 
2025-07-25 21:30:05.343405 test begin: paddle.linalg.norm(Tensor([50, 25402, 20],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50, 25402, 20],"float64"), p=2.0, axis=-1, ) 	 25402000 	 1000 	 0.3218994140625 	 0.26668262481689453 	 0.1636190414428711 	 0.2470688819885254 	 1.4643237590789795 	 0.9352800846099854 	 1.4127357006072998 	 0.23905563354492188 	 
2025-07-25 21:30:09.314601 test begin: paddle.linalg.norm(Tensor([50, 50, 10161],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50, 50, 10161],"float64"), p=2.0, axis=-1, ) 	 25402500 	 1000 	 0.15502405166625977 	 0.15104365348815918 	 0.07900357246398926 	 0.13166213035583496 	 1.471954584121704 	 0.9122636318206787 	 1.4204654693603516 	 0.2328190803527832 	 
2025-07-25 21:30:12.581745 test begin: paddle.linalg.norm(Tensor([50803201],"float32"), p=2, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50803201],"float32"), p=2, ) 	 50803201 	 1000 	 0.15427231788635254 	 0.15244555473327637 	 0.052019357681274414 	 0.07785844802856445 	 0.9993433952331543 	 0.9106101989746094 	 0.9482877254486084 	 0.2327730655670166 	 
2025-07-25 21:30:17.391804 test begin: paddle.linalg.norm(Tensor([8550, 1, 5942],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([8550, 1, 5942],"float32"), p=1.0, axis=-1, ) 	 50804100 	 1000 	 0.15044021606445312 	 0.15854358673095703 	 0.13209867477416992 	 0.1392049789428711 	 1.9144959449768066 	 0.6083323955535889 	 1.8618543148040771 	 0.30944132804870605 	 
2025-07-25 21:30:21.292520 test begin: paddle.linalg.norm(Tensor([8550, 1486, 4],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([8550, 1486, 4],"float32"), p=1.0, axis=-1, ) 	 50821200 	 1000 	 0.4078660011291504 	 0.49200868606567383 	 0.38773655891418457 	 0.46903347969055176 	 1.98360013961792 	 0.6411519050598145 	 1.931602954864502 	 0.326840877532959 	 
2025-07-25 21:30:25.892492 test begin: paddle.linalg.pinv(Tensor([21, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([21, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 	 2520 	 1000 	 56.71455216407776 	 0.4148581027984619 	 4.029273986816406e-05 	 7.2479248046875e-05 	 0.4530649185180664 	 0.2692434787750244 	 4.2438507080078125e-05 	 6.723403930664062e-05 	 
2025-07-25 21:31:25.060124 test begin: paddle.linalg.pinv(Tensor([22, 20, 3],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([22, 20, 3],"float64"), rcond=1e-15, hermitian=False, ) 	 1320 	 1000 	 9.706217765808105 	 0.3689141273498535 	 4.1961669921875e-05 	 0.0001621246337890625 	 0.45757365226745605 	 0.2751345634460449 	 4.57763671875e-05 	 7.534027099609375e-05 	 
2025-07-25 21:31:36.542313 test begin: paddle.linalg.pinv(Tensor([3, 22, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([3, 22, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 	 1320 	 1000 	 29.818328380584717 	 0.37780189514160156 	 4.410743713378906e-05 	 7.271766662597656e-05 	 0.449756383895874 	 0.27025580406188965 	 2.8848648071289062e-05 	 7.224082946777344e-05 	 
2025-07-25 21:32:07.502347 test begin: paddle.linalg.pinv(x=Tensor([58, 4, 4],"float64"), )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(x=Tensor([58, 4, 4],"float64"), ) 	 928 	 1000 	 25.13684582710266 	 0.36745381355285645 	 3.8623809814453125e-05 	 7.319450378417969e-05 	 0.3970344066619873 	 0.26529622077941895 	 2.9325485229492188e-05 	 6.699562072753906e-05 	 
2025-07-25 21:32:33.707113 test begin: paddle.linalg.qr(Tensor([105, 3, 50, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([105, 3, 50, 8],"float64"), ) 	 126000 	 1000 	 29.941667556762695 	 11.120466709136963 	 0.00010967254638671875 	 0.003937244415283203 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:33:14.884276 test begin: paddle.linalg.qr(Tensor([112, 3, 20, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([112, 3, 20, 6],"float64"), ) 	 40320 	 1000 	 29.098601818084717 	 11.37645673751831 	 0.00011992454528808594 	 0.003740072250366211 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:33:55.410716 test begin: paddle.linalg.qr(Tensor([2, 105, 100, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 105, 100, 12],"float64"), ) 	 252000 	 1000 	 30.797109603881836 	 8.062203407287598 	 0.00010013580322265625 	 0.004241466522216797 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:34:34.321059 test begin: paddle.linalg.qr(Tensor([2, 158, 100, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 158, 100, 8],"float64"), ) 	 252800 	 1000 	 32.081589460372925 	 11.497727870941162 	 0.00010275840759277344 	 0.004041910171508789 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:35:18.038568 test begin: paddle.linalg.qr(Tensor([2, 211, 100, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 211, 100, 6],"float64"), ) 	 253200 	 1000 	 40.05342721939087 	 15.003673315048218 	 0.00010395050048828125 	 0.003939390182495117 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:36:13.160445 test begin: paddle.linalg.qr(Tensor([2, 3, 100, 423],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 100, 423],"float64"), ) 	 253800 	 1000 	 4.4831390380859375 	 47.43585777282715 	 5.459785461425781e-05 	 0.5706584453582764 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:37:05.140532 test begin: paddle.linalg.qr(Tensor([2, 3, 3528, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 3528, 12],"float64"), ) 	 254016 	 1000 	 1.8067033290863037 	 1.523545265197754 	 3.62396240234375e-05 	 0.0201418399810791 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:37:08.482662 test begin: paddle.linalg.qr(Tensor([2, 3, 529201, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 529201, 8],"float64"), ) 	 25401648 	 1000 	 12.66125202178955 	 11.34972357749939 	 0.0008828639984130859 	 0.14008569717407227 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:37:33.114790 test begin: paddle.linalg.qr(Tensor([2, 3, 705601, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 705601, 6],"float64"), ) 	 25401636 	 1000 	 13.693624019622803 	 12.197638273239136 	 0.0008947849273681641 	 0.1514902114868164 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:38:00.119956 test begin: paddle.linalg.qr(Tensor([70, 3, 50, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([70, 3, 50, 12],"float64"), ) 	 126000 	 1000 	 23.381659030914307 	 7.933488368988037 	 0.00010228157043457031 	 0.004177093505859375 	 None 	 None 	 None 	 None 	 combined
2025-07-25 21:38:31.481209 test begin: paddle.linalg.slogdet(Tensor([3, 6773, 5, 5],"float32"), )
[Prof] paddle.linalg.slogdet 	 paddle.linalg.slogdet(Tensor([3, 6773, 5, 5],"float32"), ) 	 507975 	 1000 	 6.505694150924683 	 0.1880345344543457 	 0.00010013580322265625 	 8.988380432128906e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 3, 6773]) and output[0] has a shape of torch.Size([3, 6773]).
2025-07-25 21:38:39.417341 test begin: paddle.linalg.slogdet(Tensor([6773, 3, 5, 5],"float32"), )
[Prof] paddle.linalg.slogdet 	 paddle.linalg.slogdet(Tensor([6773, 3, 5, 5],"float32"), ) 	 507975 	 1000 	 6.600416421890259 	 0.17907166481018066 	 0.00010704994201660156 	 0.000133514404296875 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 6773, 3]) and output[0] has a shape of torch.Size([6773, 3]).
2025-07-25 21:38:47.446559 test begin: paddle.linalg.solve(x=Tensor([129601, 14, 14],"float64"), y=Tensor([129601, 14, 2],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([129601, 14, 14],"float64"), y=Tensor([129601, 14, 2],"float64"), ) 	 29030624 	 1000 	 3.6870808601379395 	 2.3691017627716064 	 0.0012221336364746094 	 0.00011348724365234375 	 6.009684085845947 	 2.7673895359039307 	 0.0026912689208984375 	 0.25728297233581543 	 
2025-07-25 21:39:05.046423 test begin: paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 1814401],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 1814401],"float64"), ) 	 25401810 	 1000 	 5.0383758544921875 	 3.8888890743255615 	 0.0038983821868896484 	 0.00025010108947753906 	 6.023283004760742 	 4.149372339248657 	 0.004473209381103516 	 0.4733574390411377 	 
2025-07-25 21:39:25.354262 test begin: paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 453601],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 453601],"float64"), ) 	 25402440 	 1000 	 4.284854173660278 	 2.886552572250366 	 0.0031168460845947266 	 0.0001571178436279297 	 11.078545570373535 	 10.27146053314209 	 0.009569406509399414 	 0.5855197906494141 	 
2025-07-25 21:39:55.151446 test begin: paddle.linalg.solve(x=Tensor([907201, 14, 14],"float64"), y=Tensor([907201, 14, 2],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([907201, 14, 14],"float64"), y=Tensor([907201, 14, 2],"float64"), ) 	 203213024 	 1000 	 26.765350341796875 	 15.486408948898315 	 0.00855255126953125 	 0.0002529621124267578 	 42.58575749397278 	 18.95689368247986 	 0.0187833309173584 	 0.4150853157043457 	 
2025-07-25 21:41:47.264414 test begin: paddle.linalg.svdvals(Tensor([10, 3, 8467],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 3, 8467],"float64"), ) 	 254010 	 1000 	 6.984597206115723 	 6.790668964385986 	 7.224082946777344e-05 	 0.0002636909484863281 	 15.192145347595215 	 0.09699034690856934 	 8.654594421386719e-05 	 7.033348083496094e-05 	 
2025-07-25 21:42:17.772570 test begin: paddle.linalg.svdvals(Tensor([10, 4233, 6],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 4233, 6],"float64"), ) 	 253980 	 1000 	 7.882021188735962 	 7.758223056793213 	 9.5367431640625e-05 	 0.00030040740966796875 	 19.440391540527344 	 0.0967566967010498 	 7.653236389160156e-05 	 6.365776062011719e-05 	 
2025-07-25 21:42:53.009024 test begin: paddle.linalg.svdvals(Tensor([10, 5080],"float32"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 5080],"float32"), ) 	 50800 	 1000 	 2.4453482627868652 	 0.8729355335235596 	 8.153915405273438e-05 	 7.557868957519531e-05 	 6.510741949081421 	 0.08481669425964355 	 5.364418029785156e-05 	 6.699562072753906e-05 	 
2025-07-25 21:43:03.002919 test begin: paddle.linalg.svdvals(Tensor([40, 6350],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([40, 6350],"float64"), ) 	 254000 	 1000 	 36.062352895736694 	 3.006053924560547 	 9.179115295410156e-05 	 8.416175842285156e-05 	 105.36595487594604 	 0.10018682479858398 	 7.963180541992188e-05 	 7.081031799316406e-05 	 
2025-07-25 21:45:27.697880 test begin: paddle.linalg.svdvals(Tensor([611, 3, 6],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([611, 3, 6],"float64"), ) 	 10998 	 1000 	 4.6001808643341064 	 0.5009546279907227 	 8.487701416015625e-05 	 8.273124694824219e-05 	 5.736988067626953 	 0.11347103118896484 	 4.935264587402344e-05 	 8.20159912109375e-05 	 
2025-07-25 21:45:39.611459 test begin: paddle.linalg.svdvals(Tensor([623, 12],"float32"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([623, 12],"float32"), ) 	 7476 	 1000 	 0.43860507011413574 	 0.8290531635284424 	 4.315376281738281e-05 	 0.00010609626770019531 	 1.42649507522583 	 0.08149909973144531 	 3.719329833984375e-05 	 5.221366882324219e-05 	 
2025-07-25 21:45:42.399053 test begin: paddle.linalg.svdvals(Tensor([635, 40],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([635, 40],"float64"), ) 	 25400 	 1000 	 3.7041547298431396 	 2.9374353885650635 	 4.5299530029296875e-05 	 7.224082946777344e-05 	 11.835182666778564 	 0.08216619491577148 	 7.176399230957031e-05 	 6.723403930664062e-05 	 
2025-07-25 21:46:00.983801 test begin: paddle.log(Tensor([192, 40, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([192, 40, 6625],"float32"), ) 	 50880000 	 1000 	 0.2969174385070801 	 0.2993783950805664 	 0.28791165351867676 	 0.28793835639953613 	 0.451113224029541 	 0.4514613151550293 	 0.4008290767669678 	 0.3883786201477051 	 
2025-07-25 21:46:04.435249 test begin: paddle.log(Tensor([307, 25, 6626],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([307, 25, 6626],"float32"), ) 	 50854550 	 1000 	 0.29618382453918457 	 0.2980155944824219 	 0.2876095771789551 	 0.2867403030395508 	 0.4511287212371826 	 0.45137691497802734 	 0.3990178108215332 	 0.3844914436340332 	 
2025-07-25 21:46:07.579880 test begin: paddle.log(Tensor([64, 120, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 120, 6625],"float32"), ) 	 50880000 	 1000 	 0.29738950729370117 	 0.298168420791626 	 0.2879941463470459 	 0.28650617599487305 	 0.45104193687438965 	 0.4516775608062744 	 0.40097951889038086 	 0.3903636932373047 	 
2025-07-25 21:46:10.748962 test begin: paddle.log(Tensor([64, 120, 6626],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 120, 6626],"float32"), ) 	 50887680 	 1000 	 0.29845309257507324 	 0.300091028213501 	 0.2888946533203125 	 0.28776121139526367 	 0.45122742652893066 	 0.45148134231567383 	 0.4006938934326172 	 0.39019250869750977 	 
2025-07-25 21:46:13.989724 test begin: paddle.log(Tensor([64, 25, 31753],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 25, 31753],"float32"), ) 	 50804800 	 1000 	 0.2958805561065674 	 0.29920434951782227 	 0.28734755516052246 	 0.2879197597503662 	 0.4504368305206299 	 0.44962406158447266 	 0.4005553722381592 	 0.387526273727417 	 
2025-07-25 21:46:17.138420 test begin: paddle.log(Tensor([64, 40, 19846],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 40, 19846],"float32"), ) 	 50805760 	 1000 	 0.2965989112854004 	 0.301405668258667 	 0.2876169681549072 	 0.287700891494751 	 0.45052671432495117 	 0.449596643447876 	 0.39664626121520996 	 0.3840041160583496 	 
2025-07-25 21:46:20.345746 test begin: paddle.log(Tensor([64, 80, 9923],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 80, 9923],"float32"), ) 	 50805760 	 1000 	 0.3132915496826172 	 0.29850149154663086 	 0.28885459899902344 	 0.2865331172943115 	 0.4518861770629883 	 0.44966959953308105 	 0.4014921188354492 	 0.3889014720916748 	 
2025-07-25 21:46:23.597894 test begin: paddle.log(Tensor([96, 80, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([96, 80, 6625],"float32"), ) 	 50880000 	 1000 	 0.29691123962402344 	 0.303530216217041 	 0.28792500495910645 	 0.2879598140716553 	 0.452547550201416 	 0.4502146244049072 	 0.4021949768066406 	 0.3794741630554199 	 
2025-07-25 21:46:26.765237 test begin: paddle.log10(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29619574546813965 	 0.3031747341156006 	 0.28723740577697754 	 0.28650569915771484 	 0.4515836238861084 	 0.745863676071167 	 0.3998379707336426 	 0.3810722827911377 	 
2025-07-25 21:46:30.237677 test begin: paddle.log10(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2965226173400879 	 0.29768991470336914 	 0.28720951080322266 	 0.2866213321685791 	 0.45043444633483887 	 0.745812177658081 	 0.39914989471435547 	 0.3810129165649414 	 
2025-07-25 21:46:33.918527 test begin: paddle.log10(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29996800422668457 	 0.3140096664428711 	 0.28839683532714844 	 0.2801945209503174 	 0.4505350589752197 	 0.746126651763916 	 0.39967823028564453 	 0.3811478614807129 	 
2025-07-25 21:46:39.689684 test begin: paddle.log10(x=Tensor([12700801, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.9719512462615967 	 0.3181724548339844 	 0.29685044288635254 	 0.2969343662261963 	 0.4490172863006592 	 0.7447974681854248 	 0.3958134651184082 	 0.38045692443847656 	 
2025-07-25 21:46:46.139237 test begin: paddle.log10(x=Tensor([2, 12700801],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.30632710456848145 	 0.3066580295562744 	 0.2970921993255615 	 0.29542112350463867 	 0.4498450756072998 	 0.7460691928863525 	 0.3951582908630371 	 0.38046908378601074 	 
2025-07-25 21:46:49.061356 test begin: paddle.log10(x=Tensor([2, 3, 2, 2116801],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3, 2, 2116801],"float64"), ) 	 25401612 	 1000 	 0.3059263229370117 	 0.30669116973876953 	 0.2968761920928955 	 0.2954237461090088 	 0.44886112213134766 	 0.7448031902313232 	 0.3965015411376953 	 0.38053274154663086 	 
2025-07-25 21:46:51.985591 test begin: paddle.log10(x=Tensor([2, 3, 2116801, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3, 2116801, 2],"float64"), ) 	 25401612 	 1000 	 0.31896042823791504 	 0.322080135345459 	 0.2983396053314209 	 0.29541015625 	 0.44759225845336914 	 0.7448179721832275 	 0.39760684967041016 	 0.3805530071258545 	 
2025-07-25 21:46:54.990932 test begin: paddle.log10(x=Tensor([2, 3175201, 2, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3175201, 2, 2],"float64"), ) 	 25401608 	 1000 	 0.306687593460083 	 0.31239867210388184 	 0.29695606231689453 	 0.2968747615814209 	 0.4476337432861328 	 0.7485785484313965 	 0.3975999355316162 	 0.3817875385284424 	 
2025-07-25 21:46:57.896815 test begin: paddle.log10(x=Tensor([2116801, 3, 2, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2116801, 3, 2, 2],"float64"), ) 	 25401612 	 1000 	 0.30601048469543457 	 0.30733346939086914 	 0.29701709747314453 	 0.2952606678009033 	 0.44890522956848145 	 0.7447433471679688 	 0.3985590934753418 	 0.3805534839630127 	 
2025-07-25 21:47:00.775373 test begin: paddle.log1p(Tensor([10, 16935, 300],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([10, 16935, 300],"float32"), ) 	 50805000 	 1000 	 0.29733943939208984 	 0.2990834712982178 	 0.28853464126586914 	 0.2880270481109619 	 0.4504375457763672 	 0.7470219135284424 	 0.39899206161499023 	 0.3822786808013916 	 
2025-07-25 21:47:04.259347 test begin: paddle.log1p(Tensor([10, 200, 25402],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([10, 200, 25402],"float32"), ) 	 50804000 	 1000 	 0.2960934638977051 	 0.301572322845459 	 0.28422021865844727 	 0.2889730930328369 	 0.45041561126708984 	 0.7459087371826172 	 0.3988468647003174 	 0.38106441497802734 	 
2025-07-25 21:47:07.924663 test begin: paddle.log1p(Tensor([1016065, 5, 5],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([1016065, 5, 5],"float64"), ) 	 25401625 	 1000 	 0.30686140060424805 	 0.33625125885009766 	 0.2977254390716553 	 0.32524991035461426 	 0.4477195739746094 	 0.7461421489715576 	 0.39762353897094727 	 0.38193416595458984 	 
2025-07-25 21:47:10.862791 test begin: paddle.log1p(Tensor([108, 157920, 3],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([108, 157920, 3],"float32"), ) 	 51166080 	 1000 	 0.30081868171691895 	 0.3046541213989258 	 0.29041051864624023 	 0.29007554054260254 	 0.45338964462280273 	 0.7511444091796875 	 0.4029715061187744 	 0.38376760482788086 	 
2025-07-25 21:47:14.505362 test begin: paddle.log1p(Tensor([4, 157920, 81],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([4, 157920, 81],"float32"), ) 	 51166080 	 1000 	 0.31114840507507324 	 0.304044246673584 	 0.29062438011169434 	 0.29013657569885254 	 0.4536006450653076 	 0.7522904872894287 	 0.4001426696777344 	 0.3837010860443115 	 
2025-07-25 21:47:18.129587 test begin: paddle.log1p(Tensor([4, 4233601, 3],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([4, 4233601, 3],"float32"), ) 	 50803212 	 1000 	 0.29671263694763184 	 0.29899001121520996 	 0.28711962699890137 	 0.2878756523132324 	 0.4504413604736328 	 0.7481777667999268 	 0.400193452835083 	 0.38100457191467285 	 
2025-07-25 21:47:21.594052 test begin: paddle.log1p(Tensor([50000, 102, 5],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([50000, 102, 5],"float64"), ) 	 25500000 	 1000 	 0.30983924865722656 	 0.33769893646240234 	 0.2991044521331787 	 0.32643771171569824 	 0.45011281967163086 	 0.7488453388214111 	 0.3754153251647949 	 0.38315844535827637 	 
2025-07-25 21:47:24.588487 test begin: paddle.log1p(Tensor([50000, 5, 102],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([50000, 5, 102],"float64"), ) 	 25500000 	 1000 	 0.30664491653442383 	 0.3389134407043457 	 0.29760289192199707 	 0.32778096199035645 	 0.44998669624328613 	 0.7476091384887695 	 0.39989447593688965 	 0.38192272186279297 	 
2025-07-25 21:47:27.564140 test begin: paddle.log1p(Tensor([847, 200, 300],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([847, 200, 300],"float32"), ) 	 50820000 	 1000 	 0.29604339599609375 	 0.2990458011627197 	 0.2872493267059326 	 0.28797483444213867 	 0.45061206817626953 	 0.7486922740936279 	 0.3996710777282715 	 0.3825795650482178 	 
2025-07-25 21:47:31.110428 test begin: paddle.log2(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29637980461120605 	 0.2991499900817871 	 0.2867913246154785 	 0.28591060638427734 	 0.45178747177124023 	 0.745851993560791 	 0.4008359909057617 	 0.38104867935180664 	 
2025-07-25 21:47:34.584991 test begin: paddle.log2(Tensor([10, 2540161],"float64"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 2540161],"float64"), ) 	 25401610 	 1000 	 0.30747175216674805 	 0.31101155281066895 	 0.2987329959869385 	 0.2956535816192627 	 0.44760704040527344 	 0.7447617053985596 	 0.3974471092224121 	 0.3804028034210205 	 
2025-07-25 21:47:39.322539 test begin: paddle.log2(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29858851432800293 	 0.2977287769317627 	 0.28701305389404297 	 0.2865586280822754 	 0.45060062408447266 	 0.7457361221313477 	 0.39418792724609375 	 0.38101720809936523 	 
2025-07-25 21:47:42.812449 test begin: paddle.log2(Tensor([10, 5080321],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2962148189544678 	 0.29959750175476074 	 0.2870926856994629 	 0.2848060131072998 	 0.4502255916595459 	 0.7470273971557617 	 0.3977982997894287 	 0.38102221488952637 	 
2025-07-25 21:47:48.180814 test begin: paddle.log2(Tensor([2116801, 12],"float64"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([2116801, 12],"float64"), ) 	 25401612 	 1000 	 0.5251929759979248 	 0.31671667098999023 	 0.29752087593078613 	 0.2957437038421631 	 0.4476463794708252 	 0.7471420764923096 	 0.397411584854126 	 0.38042497634887695 	 
2025-07-25 21:47:52.346710 test begin: paddle.log2(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2959444522857666 	 0.29774022102355957 	 0.28671836853027344 	 0.2862741947174072 	 0.45043134689331055 	 0.7456893920898438 	 0.39981985092163086 	 0.38100433349609375 	 
2025-07-25 21:47:55.822517 test begin: paddle.log2(Tensor([4233601, 12],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([4233601, 12],"float32"), ) 	 50803212 	 1000 	 0.29596424102783203 	 0.2977609634399414 	 0.2871062755584717 	 0.28667354583740234 	 0.450453519821167 	 0.7456977367401123 	 0.3991434574127197 	 0.381000280380249 	 
2025-07-25 21:47:59.267633 test begin: paddle.logaddexp(Tensor([10, 16935, 300],"float32"), Tensor([10, 16935, 300],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 16935, 300],"float32"), Tensor([10, 16935, 300],"float32"), ) 	 101610000 	 1000 	 2.5411531925201416 	 0.45201873779296875 	 0.3701636791229248 	 0.44059062004089355 	 4.618291854858398 	 2.983999729156494 	 0.5232064723968506 	 0.38056349754333496 	 
2025-07-25 21:48:12.650909 test begin: paddle.logaddexp(Tensor([10, 16935, 300],"int32"), Tensor([10, 16935, 300],"int32"), )
W0725 21:48:17.598767 50382 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 16935, 300],"int32"), Tensor([10, 16935, 300],"int32"), ) 	 101610000 	 1000 	 2.835613489151001 	 0.4520299434661865 	 0.3615419864654541 	 0.4408419132232666 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:48:18.257792 test begin: paddle.logaddexp(Tensor([10, 200, 12701],"int64"), Tensor([10, 200, 12701],"int64"), )
W0725 21:48:21.702360 51142 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 12701],"int64"), Tensor([10, 200, 12701],"int64"), ) 	 50804000 	 1000 	 2.3257102966308594 	 0.22975921630859375 	 0.2963297367095947 	 0.21812939643859863 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:48:22.077684 test begin: paddle.logaddexp(Tensor([10, 200, 25402],"float32"), Tensor([10, 200, 25402],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 25402],"float32"), Tensor([10, 200, 25402],"float32"), ) 	 101608000 	 1000 	 2.5401272773742676 	 0.45404839515686035 	 0.3700907230377197 	 0.44054746627807617 	 4.616917133331299 	 2.983652353286743 	 0.5229935646057129 	 0.3817305564880371 	 
2025-07-25 21:48:35.405372 test begin: paddle.logaddexp(Tensor([10, 200, 25402],"int32"), Tensor([10, 200, 25402],"int32"), )
W0725 21:48:42.999444 52671 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 25402],"int32"), Tensor([10, 200, 25402],"int32"), ) 	 101608000 	 1000 	 3.0646355152130127 	 0.4506371021270752 	 0.36399126052856445 	 0.43880176544189453 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:48:43.722657 test begin: paddle.logaddexp(Tensor([10, 8468, 300],"int64"), Tensor([10, 8468, 300],"int64"), )
W0725 21:48:47.166343 53109 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 8468, 300],"int64"), Tensor([10, 8468, 300],"int64"), ) 	 50808000 	 1000 	 2.3270437717437744 	 0.22983813285827637 	 0.29777002334594727 	 0.21815085411071777 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:48:47.541222 test begin: paddle.logaddexp(Tensor([424, 200, 300],"int64"), Tensor([424, 200, 300],"int64"), )
W0725 21:48:50.964486 53433 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([424, 200, 300],"int64"), Tensor([424, 200, 300],"int64"), ) 	 50880000 	 1000 	 2.3268215656280518 	 0.24632573127746582 	 0.2967061996459961 	 0.21887588500976562 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:48:53.447087 test begin: paddle.logaddexp(Tensor([847, 200, 300],"float32"), Tensor([847, 200, 300],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([847, 200, 300],"float32"), Tensor([847, 200, 300],"float32"), ) 	 101640000 	 1000 	 2.546067953109741 	 0.45072412490844727 	 0.3703029155731201 	 0.43796753883361816 	 4.619559049606323 	 2.9850411415100098 	 0.5233626365661621 	 0.3806595802307129 	 
2025-07-25 21:49:07.775213 test begin: paddle.logaddexp(Tensor([847, 200, 300],"int32"), Tensor([847, 200, 300],"int32"), )
W0725 21:49:12.504526 55046 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([847, 200, 300],"int32"), Tensor([847, 200, 300],"int32"), ) 	 101640000 	 1000 	 2.836472988128662 	 0.45078134536743164 	 0.3629469871520996 	 0.43947458267211914 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 21:49:13.199852 test begin: paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=-1, ) 	 50803300 	 1000 	 3.391819953918457 	 2.478101968765259 	 3.382091999053955 	 2.4655091762542725 	 10.942478656768799 	 10.836782932281494 	 1.018073320388794 	 0.5525603294372559 	 
2025-07-25 21:49:42.770315 test begin: paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=0, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=0, ) 	 50803300 	 1000 	 23.788331270217896 	 0.35542774200439453 	 8.110482215881348 	 0.34301161766052246 	 192.27774834632874 	 6.571011066436768 	 13.072412967681885 	 0.3353235721588135 	 
2025-07-25 21:53:27.764422 test begin: paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=-1, ) 	 50803300 	 1000 	 22.84462857246399 	 103.669748544693 	 22.835021018981934 	 103.65751504898071 	 190.22868967056274 	 213.22239780426025 	 17.693475246429443 	 10.877565145492554 	 
2025-07-25 22:02:20.029684 test begin: paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=0, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=0, ) 	 50803300 	 1000 	 23.7870831489563 	 0.35376644134521484 	 8.103609323501587 	 0.3419835567474365 	 192.05222487449646 	 6.572792053222656 	 13.061797857284546 	 0.3353385925292969 	 
2025-07-25 22:06:04.769731 test begin: paddle.logcumsumexp(Tensor([508033, 10, 10],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([508033, 10, 10],"float32"), axis=-1, ) 	 50803300 	 1000 	 22.84069514274597 	 103.56066560745239 	 22.83116316795349 	 103.53981852531433 	 190.22167778015137 	 213.21767663955688 	 17.68485736846924 	 10.87369155883789 	 
2025-07-25 22:14:58.867865 test begin: paddle.logical_and(Tensor([138, 369303],"bool"), Tensor([138, 369303],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([138, 369303],"bool"), Tensor([138, 369303],"bool"), ) 	 101927628 	 1000 	 0.8051977157592773 	 0.12426424026489258 	 0.10967278480529785 	 0.10215473175048828 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:01.339979 test begin: paddle.logical_and(Tensor([146, 349866],"bool"), Tensor([146, 349866],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([146, 349866],"bool"), Tensor([146, 349866],"bool"), ) 	 102160872 	 1000 	 0.11913371086120605 	 0.11936807632446289 	 0.10987710952758789 	 0.10235738754272461 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:02.990313 test begin: paddle.logical_and(Tensor([49, 1036801],"bool"), Tensor([49, 1036801],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([49, 1036801],"bool"), Tensor([49, 1036801],"bool"), ) 	 101606498 	 1000 	 0.11846423149108887 	 0.11620593070983887 	 0.10930132865905762 	 0.10262036323547363 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:04.640664 test begin: paddle.logical_and(Tensor([53, 958551],"bool"), Tensor([53, 958551],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([53, 958551],"bool"), Tensor([53, 958551],"bool"), ) 	 101606406 	 1000 	 0.11959362030029297 	 0.11847043037414551 	 0.11036562919616699 	 0.10221171379089355 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:06.466162 test begin: paddle.logical_and(Tensor([55, 923695],"bool"), Tensor([55, 923695],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([55, 923695],"bool"), Tensor([55, 923695],"bool"), ) 	 101606450 	 1000 	 0.11844253540039062 	 0.11622953414916992 	 0.10913825035095215 	 0.10260009765625 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:08.108976 test begin: paddle.logical_not(Tensor([215040, 237],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([215040, 237],"bool"), ) 	 50964480 	 1000 	 0.08275866508483887 	 0.08063626289367676 	 0.07409524917602539 	 0.0665128231048584 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:09.122892 test begin: paddle.logical_not(Tensor([220416, 231],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([220416, 231],"bool"), ) 	 50916096 	 1000 	 0.08182191848754883 	 0.08053112030029297 	 0.07329320907592773 	 0.06776762008666992 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:10.035163 test begin: paddle.logical_not(Tensor([225792, 226],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([225792, 226],"bool"), ) 	 51028992 	 1000 	 0.08285760879516602 	 0.08111000061035156 	 0.07443928718566895 	 0.06673145294189453 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:10.953680 test begin: paddle.logical_not(Tensor([635041, 80],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([635041, 80],"bool"), ) 	 50803280 	 1000 	 0.0833749771118164 	 0.08115077018737793 	 0.07478523254394531 	 0.0683295726776123 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:11.873670 test begin: paddle.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11797022819519043 	 0.11610817909240723 	 0.10881447792053223 	 0.10260629653930664 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:13.509096 test begin: paddle.logical_or(Tensor([640, 79381],"bool"), Tensor([640, 79381],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([640, 79381],"bool"), Tensor([640, 79381],"bool"), ) 	 101607680 	 1000 	 0.11826729774475098 	 0.11514925956726074 	 0.10928821563720703 	 0.10165548324584961 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:15.210503 test begin: paddle.logical_or(Tensor([79381, 640],"bool"), Tensor([79381, 640],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([79381, 640],"bool"), Tensor([79381, 640],"bool"), ) 	 101607680 	 1000 	 0.11824393272399902 	 0.11512112617492676 	 0.10914897918701172 	 0.1015779972076416 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:16.876715 test begin: paddle.logical_xor(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.191375732421875 	 0.23993897438049316 	 0.1814115047454834 	 0.22321367263793945 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:18.156707 test begin: paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.19376921653747559 	 0.24371004104614258 	 0.17903709411621094 	 0.22502636909484863 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:19.453159 test begin: paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3320276737213135 	 0.32785940170288086 	 0.3193345069885254 	 0.31412553787231445 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:21.823268 test begin: paddle.logical_xor(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.3272590637207031 	 0.34135866165161133 	 0.3183269500732422 	 0.309598445892334 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:24.226293 test begin: paddle.logical_xor(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3291962146759033 	 0.3278770446777344 	 0.3180708885192871 	 0.31433606147766113 	 None 	 None 	 None 	 None 	 
2025-07-25 22:15:26.738209 test begin: paddle.logit(Tensor([10, 20, 254017],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([10, 20, 254017],"float32"), 0.001, ) 	 50803400 	 1000 	 0.29842185974121094 	 0.3020932674407959 	 0.28887367248535156 	 0.2881968021392822 	 0.4505765438079834 	 0.4512474536895752 	 0.3996272087097168 	 0.3907303810119629 	 
2025-07-25 22:15:30.111887 test begin: paddle.logit(Tensor([10, 5080321, 1],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([10, 5080321, 1],"float32"), 0.001, ) 	 50803210 	 1000 	 0.29913806915283203 	 0.2999999523162842 	 0.2897353172302246 	 0.28697752952575684 	 0.4502577781677246 	 0.4512481689453125 	 0.39997220039367676 	 0.38867926597595215 	 
2025-07-25 22:15:33.275979 test begin: paddle.logit(Tensor([2540161, 20, 1],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([2540161, 20, 1],"float32"), 0.001, ) 	 50803220 	 1000 	 0.31247687339782715 	 0.5369057655334473 	 0.2896134853363037 	 0.2869861125946045 	 0.450667142868042 	 0.4499680995941162 	 0.3990511894226074 	 0.3864619731903076 	 
2025-07-25 22:15:39.459497 test begin: paddle.logit(Tensor([50803201],"float32"), 1e-08, )
[Prof] paddle.logit 	 paddle.logit(Tensor([50803201],"float32"), 1e-08, ) 	 50803201 	 1000 	 0.29863929748535156 	 0.30000877380371094 	 0.28951072692871094 	 0.28708314895629883 	 0.45306396484375 	 0.4500386714935303 	 0.4008786678314209 	 0.38991355895996094 	 
2025-07-25 22:15:42.649286 test begin: paddle.logit(x=Tensor([4, 3, 2, 1058401],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 3, 2, 1058401],"float64"), eps=0.2, ) 	 25401624 	 1000 	 0.3252229690551758 	 0.30306291580200195 	 0.31600284576416016 	 0.29000306129455566 	 0.4447505474090576 	 0.45003294944763184 	 0.392657995223999 	 0.3878157138824463 	 
2025-07-25 22:15:45.272292 test begin: paddle.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, ) 	 25401660 	 1000 	 0.32505226135253906 	 0.30304646492004395 	 0.3159475326538086 	 0.2899646759033203 	 0.44445085525512695 	 0.44876742362976074 	 0.38988566398620605 	 0.3835792541503906 	 
2025-07-25 22:15:47.909264 test begin: paddle.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, ) 	 25401640 	 1000 	 0.32521629333496094 	 0.3061962127685547 	 0.3158690929412842 	 0.2890775203704834 	 0.4445047378540039 	 0.448718786239624 	 0.39346981048583984 	 0.3868269920349121 	 
2025-07-25 22:15:50.727312 test begin: paddle.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, ) 	 25401630 	 1000 	 0.3296198844909668 	 0.30307817459106445 	 0.3161437511444092 	 0.29001474380493164 	 0.4446685314178467 	 0.4487576484680176 	 0.3946044445037842 	 0.3827695846557617 	 
2025-07-25 17:48:52.318241 test begin: paddle.logsumexp(Tensor([1024, 49613],"float32"), axis=1, )
W0725 17:48:53.321926 97175 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([1024, 49613],"float32"), axis=1, ) 	 50803712 	 1000 	 0.711181640625 	 0.9355213642120361 	 0.10379910469055176 	 0.10629892349243164 	 0.8087584972381592 	 0.905771017074585 	 0.7440319061279297 	 0.30846166610717773 	 
2025-07-25 17:48:57.840927 test begin: paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=-1, keepdim=False, ) 	 50808000 	 1000 	 0.634873628616333 	 0.9387857913970947 	 0.12949633598327637 	 0.10683631896972656 	 1.2050347328186035 	 0.9100198745727539 	 1.1266045570373535 	 0.3099822998046875 	 
2025-07-25 17:49:02.387674 test begin: paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=list[0,2,], keepdim=False, ) 	 50808000 	 1000 	 0.7331855297088623 	 0.9835648536682129 	 0.10705065727233887 	 0.09137725830078125 	 1.2015228271484375 	 0.9127664566040039 	 1.1376314163208008 	 0.3109316825866699 	 
2025-07-25 17:49:07.112378 test begin: paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=-1, keepdim=False, ) 	 50804400 	 1000 	 0.6641690731048584 	 1.6273157596588135 	 0.3389928340911865 	 0.18498468399047852 	 1.2302932739257812 	 0.9188535213470459 	 1.166985273361206 	 0.31298828125 	 
2025-07-25 17:49:12.441558 test begin: paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=list[0,2,], keepdim=False, ) 	 50804400 	 1000 	 0.7221400737762451 	 0.9494678974151611 	 0.14730381965637207 	 0.10804462432861328 	 1.2095270156860352 	 0.9133858680725098 	 1.156090497970581 	 0.3110933303833008 	 
2025-07-25 17:49:17.090370 test begin: paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=-1, keepdim=False, ) 	 50808000 	 1000 	 0.6643800735473633 	 1.6277315616607666 	 0.3392043113708496 	 0.18502235412597656 	 1.2304809093475342 	 0.918997049331665 	 1.1768066883087158 	 0.3130354881286621 	 
2025-07-25 17:49:22.494376 test begin: paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=list[0,2,], keepdim=False, ) 	 50808000 	 1000 	 0.7384951114654541 	 0.988133430480957 	 0.10781025886535645 	 0.09198141098022461 	 1.2021100521087646 	 0.9127230644226074 	 1.1484160423278809 	 0.3108985424041748 	 
2025-07-25 17:49:27.222500 test begin: paddle.masked_fill(Tensor([20, 127009, 20],"int32"), Tensor([20, 127009, 20],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([20, 127009, 20],"int32"), Tensor([20, 127009, 20],"bool"), 0, ) 	 101607200 	 1000 	 0.376345157623291 	 0.6515235900878906 	 0.09617352485656738 	 0.22178959846496582 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:30.561601 test begin: paddle.masked_fill(Tensor([20, 60, 42337],"int32"), Tensor([20, 60, 42337],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([20, 60, 42337],"int32"), Tensor([20, 60, 42337],"bool"), 0, ) 	 101608800 	 1000 	 0.3764629364013672 	 0.6511721611022949 	 0.09622526168823242 	 0.22166776657104492 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:33.833413 test begin: paddle.masked_fill(Tensor([28225, 60, 30],"int32"), Tensor([28225, 60, 30],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([28225, 60, 30],"int32"), Tensor([28225, 60, 30],"bool"), 0, ) 	 101610000 	 1000 	 0.38164663314819336 	 0.6605179309844971 	 0.09618568420410156 	 0.2214648723602295 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:40.335647 test begin: paddle.masked_fill(Tensor([30, 56449, 30],"int32"), Tensor([30, 56449, 30],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([30, 56449, 30],"int32"), Tensor([30, 56449, 30],"bool"), 0, ) 	 101608200 	 1000 	 0.3954916000366211 	 0.6507692337036133 	 0.0962228775024414 	 0.22153353691101074 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:44.466747 test begin: paddle.masked_fill(Tensor([30, 60, 28225],"int32"), Tensor([30, 60, 28225],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([30, 60, 28225],"int32"), Tensor([30, 60, 28225],"bool"), 0, ) 	 101610000 	 1000 	 0.3766298294067383 	 0.6529648303985596 	 0.0962820053100586 	 0.22155284881591797 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:47.746981 test begin: paddle.masked_fill(Tensor([42337, 60, 20],"int32"), Tensor([42337, 60, 20],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([42337, 60, 20],"int32"), Tensor([42337, 60, 20],"bool"), 0, ) 	 101608800 	 1000 	 0.3767821788787842 	 0.6511967182159424 	 0.09621644020080566 	 0.22167181968688965 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:49:50.982744 test begin: paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([169345, 300],"float32"), ) 	 50839620 	 1000 	 0.4547555446624756 	 0.03717923164367676 	 1.811981201171875e-05 	 8.96453857421875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:49:52.680225 test begin: paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([300, 169345],"float32"), ) 	 50839620 	 1000 	 0.4698753356933594 	 0.03552412986755371 	 1.811981201171875e-05 	 6.723403930664062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:49:54.310985 test begin: paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([169345, 300],"float32"), ) 	 50815540 	 1000 	 0.44049715995788574 	 0.044708967208862305 	 1.8358230590820312e-05 	 5.626678466796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:49:55.799786 test begin: paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([300, 169345],"float32"), ) 	 50815540 	 1000 	 0.43834447860717773 	 0.04406142234802246 	 3.4809112548828125e-05 	 5.626678466796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:49:57.281312 test begin: paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([169345, 300],"float32"), ) 	 50819052 	 1000 	 0.4458596706390381 	 0.03407120704650879 	 3.6716461181640625e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:49:58.749904 test begin: paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([300, 169345],"float32"), ) 	 50819052 	 1000 	 0.4323723316192627 	 0.03530740737915039 	 1.8358230590820312e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:00.242384 test begin: paddle.masked_select(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"bool"), ) 	 101802624 	 1000 	 1.372513771057129 	 3.122727155685425 	 0.0008599758148193359 	 0.003012418746948242 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:08.698535 test begin: paddle.masked_select(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"bool"), ) 	 101669568 	 1000 	 1.3761053085327148 	 3.120156764984131 	 0.0008580684661865234 	 0.0030117034912109375 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:17.126347 test begin: paddle.masked_select(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"bool"), ) 	 101799936 	 1000 	 1.3825066089630127 	 3.1244654655456543 	 0.0008537769317626953 	 0.003019571304321289 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:25.494574 test begin: paddle.masked_select(Tensor([16, 46695, 68],"float32"), Tensor([16, 46695, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 46695, 68],"float32"), Tensor([16, 46695, 68],"bool"), ) 	 101608320 	 1000 	 1.3683671951293945 	 3.119065046310425 	 0.0008499622344970703 	 0.003011465072631836 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:33.811199 test begin: paddle.masked_select(Tensor([62, 12096, 68],"float32"), Tensor([62, 12096, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([62, 12096, 68],"float32"), Tensor([62, 12096, 68],"bool"), ) 	 101993472 	 1000 	 1.3808417320251465 	 3.149811029434204 	 0.0008378028869628906 	 0.0030126571655273438 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:44.997197 test begin: paddle.masked_select(Tensor([68, 11109, 68],"float32"), Tensor([68, 11109, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([68, 11109, 68],"float32"), Tensor([68, 11109, 68],"bool"), ) 	 102736032 	 1000 	 1.3892943859100342 	 3.170745372772217 	 0.0008623600006103516 	 0.0030510425567626953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:50:54.719159 test begin: paddle.masked_select(Tensor([74, 10164, 68],"float32"), Tensor([74, 10164, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([74, 10164, 68],"float32"), Tensor([74, 10164, 68],"bool"), ) 	 102290496 	 1000 	 1.3827474117279053 	 3.139744758605957 	 0.0008649826049804688 	 0.0030236244201660156 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:51:03.130660 test begin: paddle.matmul(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), ) 	 67633152 	 1000 	 1.6406958103179932 	 1.6409273147583008 	 1.6242690086364746 	 1.6162056922912598 	 1.826634407043457 	 1.8263757228851318 	 0.9331142902374268 	 0.933161735534668 	 
2025-07-25 17:51:13.974398 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), ) 	 553648128 	 1000 	 8.162617683410645 	 8.967676162719727 	 8.149782419204712 	 8.13451361656189 	 16.31049418449402 	 16.326810836791992 	 8.335922241210938 	 8.342085838317871 	 
2025-07-25 17:52:14.690170 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 388],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 388],"float32"), ) 	 587726848 	 1000 	 30.984314918518066 	 30.980507612228394 	 30.971592903137207 	 30.9576199054718 	 54.98006463050842 	 54.97181749343872 	 28.09210228919983 	 28.0906662940979 	 
2025-07-25 17:55:17.825149 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), ) 	 603979776 	 1000 	 31.10012197494507 	 43.33729815483093 	 0.00013899803161621094 	 8.874706029891968 	 71.4527862071991 	 80.78668856620789 	 0.0077097415924072266 	 13.743177652359009 	 
2025-07-25 17:59:16.855058 test begin: paddle.matmul(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 128],"float32"), ) 	 69206016 	 1000 	 1.640082597732544 	 1.6397960186004639 	 1.6194028854370117 	 1.6072914600372314 	 2.665539503097534 	 2.665519952774048 	 1.3619956970214844 	 1.3619506359100342 	 
2025-07-25 17:59:28.482909 test begin: paddle.matmul(Tensor([1, 97, 4096, 4096],"float32"), Tensor([1, 97, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 97, 4096, 4096],"float32"), Tensor([1, 97, 4096, 128],"float32"), ) 	 1678245888 	 1000 	 23.65129566192627 	 23.64969301223755 	 23.635870456695557 	 23.619892835617065 	 48.332093238830566 	 48.32958459854126 	 24.697376251220703 	 24.695645809173584 	 
2025-07-25 18:02:22.968131 test begin: paddle.matmul(Tensor([10, 23, 499, 3600],"float32"), Tensor([10, 23, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 23, 499, 3600],"float32"), Tensor([10, 23, 3600, 64],"float32"), ) 	 466164000 	 1000 	 6.456839084625244 	 6.467258453369141 	 6.444167852401733 	 6.424227476119995 	 10.044173955917358 	 9.86582612991333 	 5.22174072265625 	 5.041335105895996 	 
2025-07-25 18:03:06.001817 test begin: paddle.matmul(Tensor([10, 3, 499, 3600],"float32"), Tensor([10, 3, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 3, 499, 3600],"float32"), Tensor([10, 3, 3600, 64],"float32"), ) 	 60804000 	 1000 	 1.4419591426849365 	 1.442004680633545 	 1.4293761253356934 	 1.4183175563812256 	 1.390810251235962 	 1.3910038471221924 	 0.7106680870056152 	 0.7106997966766357 	 
2025-07-25 18:03:12.767460 test begin: paddle.matmul(Tensor([10, 8, 177, 3600],"float32"), Tensor([10, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 177, 3600],"float32"), Tensor([10, 8, 3600, 64],"float32"), ) 	 69408000 	 1000 	 1.4415411949157715 	 1.4416217803955078 	 1.4287745952606201 	 1.418541431427002 	 1.4716298580169678 	 1.471632480621338 	 0.7519288063049316 	 0.7518942356109619 	 
2025-07-25 18:03:19.851474 test begin: paddle.matmul(Tensor([10, 8, 499, 1273],"float32"), Tensor([10, 8, 1273, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 1273],"float32"), Tensor([10, 8, 1273, 64],"float32"), ) 	 57335920 	 1000 	 0.7772350311279297 	 0.777240514755249 	 0.7643232345581055 	 0.753159761428833 	 1.259037733078003 	 1.2588284015655518 	 0.6432955265045166 	 0.6431488990783691 	 
2025-07-25 18:03:24.955414 test begin: paddle.matmul(Tensor([10, 8, 499, 3600],"float32"), Tensor([10, 8, 3600, 177],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 3600],"float32"), Tensor([10, 8, 3600, 177],"float32"), ) 	 194688000 	 1000 	 4.308072805404663 	 4.313760042190552 	 4.295217752456665 	 4.28240704536438 	 7.622523784637451 	 7.628571510314941 	 3.8950366973876953 	 3.898052453994751 	 
2025-07-25 18:03:52.376449 test begin: paddle.matmul(Tensor([10, 8, 499, 9923],"float32"), Tensor([10, 8, 9923, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 9923],"float32"), Tensor([10, 8, 9923, 64],"float32"), ) 	 446931920 	 1000 	 5.934533596038818 	 5.934676885604858 	 5.9189841747283936 	 5.900447845458984 	 9.248144149780273 	 9.248482942581177 	 4.7257421016693115 	 4.7258076667785645 	 
2025-07-25 18:04:30.678956 test begin: paddle.matmul(Tensor([1379, 4, 256, 256],"float32"), Tensor([1379, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1379, 4, 256, 256],"float32"), Tensor([1379, 4, 256, 36],"float32"), ) 	 412332032 	 1000 	 5.301559925079346 	 5.302314043045044 	 5.288938999176025 	 5.2787559032440186 	 7.246309757232666 	 7.234902858734131 	 3.702763795852661 	 3.6971728801727295 	 
2025-07-25 18:05:03.925320 test begin: paddle.matmul(Tensor([194, 4, 256, 256],"float32"), Tensor([194, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([194, 4, 256, 256],"float32"), Tensor([194, 4, 256, 36],"float32"), ) 	 58007552 	 1000 	 0.7879238128662109 	 0.7882802486419678 	 0.7748355865478516 	 0.7616064548492432 	 1.0714738368988037 	 1.0696470737457275 	 0.5473954677581787 	 0.5464704036712646 	 
2025-07-25 18:05:08.784169 test begin: paddle.matmul(Tensor([28, 8, 499, 3600],"float32"), Tensor([28, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([28, 8, 499, 3600],"float32"), Tensor([28, 8, 3600, 64],"float32"), ) 	 454003200 	 1000 	 6.456768035888672 	 6.457245349884033 	 6.444096088409424 	 6.433257579803467 	 9.614978790283203 	 9.614017724990845 	 4.913733720779419 	 4.912521123886108 	 
2025-07-25 18:05:50.475118 test begin: paddle.matmul(Tensor([4, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([4, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), ) 	 2214592512 	 1000 	 30.98846673965454 	 30.985332012176514 	 30.975377082824707 	 30.950014114379883 	 63.53875756263733 	 63.872902154922485 	 32.47567963600159 	 32.79472613334656 	 
2025-07-25 18:09:41.029786 test begin: paddle.matmul(Tensor([4, 8, 499, 3600],"float32"), Tensor([4, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([4, 8, 499, 3600],"float32"), Tensor([4, 8, 3600, 64],"float32"), ) 	 64857600 	 1000 	 1.4420630931854248 	 1.4421696662902832 	 1.421574354171753 	 1.4076781272888184 	 1.4310262203216553 	 1.4309031963348389 	 0.7311365604400635 	 0.7310452461242676 	 
2025-07-25 18:09:47.995699 test begin: paddle.matmul(Tensor([512, 11, 256, 256],"float32"), Tensor([512, 11, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 11, 256, 256],"float32"), Tensor([512, 11, 256, 36],"float32"), ) 	 421003264 	 1000 	 5.450118064880371 	 5.451045036315918 	 5.436444282531738 	 5.42476487159729 	 7.427960157394409 	 7.427190542221069 	 3.795649290084839 	 3.795189619064331 	 
2025-07-25 18:10:21.909464 test begin: paddle.matmul(Tensor([512, 2, 256, 256],"float32"), Tensor([512, 2, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 2, 256, 256],"float32"), Tensor([512, 2, 256, 36],"float32"), ) 	 76546048 	 1000 	 0.9977450370788574 	 0.9980201721191406 	 0.9851243495941162 	 0.9749643802642822 	 1.3634169101715088 	 1.3634817600250244 	 0.6966323852539062 	 0.6965935230255127 	 
2025-07-25 18:10:29.233201 test begin: paddle.matmul(Tensor([512, 4, 256, 256],"float32"), Tensor([512, 4, 256, 97],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 4, 256, 256],"float32"), Tensor([512, 4, 256, 97],"float32"), ) 	 185073664 	 1000 	 1.997035026550293 	 2.0097672939300537 	 1.984544038772583 	 1.972503423690796 	 3.6866915225982666 	 3.687190055847168 	 1.8838233947753906 	 1.884037733078003 	 
2025-07-25 18:10:45.960853 test begin: paddle.matmul(Tensor([512, 4, 97, 256],"float32"), Tensor([512, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 4, 97, 256],"float32"), Tensor([512, 4, 256, 36],"float32"), ) 	 69730304 	 1000 	 0.9944131374359131 	 0.9946513175964355 	 0.9817872047424316 	 0.9715032577514648 	 1.2195384502410889 	 1.2195606231689453 	 0.6230580806732178 	 0.6230983734130859 	 
2025-07-25 18:10:51.709009 test begin: paddle.matrix_transpose(Tensor([2, 12700801, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2, 12700801, 4],"float16"), ) 	 101606408 	 1000 	 0.00450444221496582 	 0.003698110580444336 	 8.58306884765625e-06 	 1.9788742065429688e-05 	 0.04020071029663086 	 0.056871652603149414 	 4.506111145019531e-05 	 4.2438507080078125e-05 	 combined
2025-07-25 18:10:55.624700 test begin: paddle.matrix_transpose(Tensor([2, 3, 16934401],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2, 3, 16934401],"float16"), ) 	 101606406 	 1000 	 0.00436854362487793 	 0.0037012100219726562 	 8.106231689453125e-06 	 1.8596649169921875e-05 	 0.0423123836517334 	 0.05974698066711426 	 2.3365020751953125e-05 	 5.4836273193359375e-05 	 combined
2025-07-25 18:10:59.695639 test begin: paddle.matrix_transpose(Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2, 3, 4233601],"float64"), ) 	 25401606 	 1000 	 0.004350185394287109 	 0.007164478302001953 	 1.2636184692382812e-05 	 1.8835067749023438e-05 	 0.05206727981567383 	 0.06492114067077637 	 5.91278076171875e-05 	 7.271766662597656e-05 	 combined
2025-07-25 18:11:00.959071 test begin: paddle.matrix_transpose(Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2, 3, 8467201],"float32"), ) 	 50803206 	 1000 	 0.00435638427734375 	 0.003722667694091797 	 8.344650268554688e-06 	 1.811981201171875e-05 	 0.04014992713928223 	 0.05701494216918945 	 2.09808349609375e-05 	 3.814697265625e-05 	 combined
2025-07-25 18:11:02.761463 test begin: paddle.matrix_transpose(Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2, 3175201, 4],"float64"), ) 	 25401608 	 1000 	 0.00557398796081543 	 0.003683328628540039 	 3.0517578125e-05 	 1.621246337890625e-05 	 0.04019308090209961 	 0.05702948570251465 	 2.5987625122070312e-05 	 5.078315734863281e-05 	 combined
2025-07-25 18:11:03.948813 test begin: paddle.matrix_transpose(Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2, 6350401, 4],"float32"), ) 	 50803208 	 1000 	 0.004336118698120117 	 0.0037300586700439453 	 1.2636184692382812e-05 	 1.6450881958007812e-05 	 0.04007291793823242 	 0.05750846862792969 	 2.0742416381835938e-05 	 4.00543212890625e-05 	 combined
2025-07-25 18:11:07.563353 test begin: paddle.matrix_transpose(Tensor([2116801, 3, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([2116801, 3, 4],"float64"), ) 	 25401612 	 1000 	 0.004305601119995117 	 0.003767251968383789 	 7.62939453125e-06 	 2.0265579223632812e-05 	 0.03992652893066406 	 0.05718708038330078 	 2.1457672119140625e-05 	 5.173683166503906e-05 	 combined
2025-07-25 18:11:10.439286 test begin: paddle.matrix_transpose(Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([4233601, 3, 4],"float32"), ) 	 50803212 	 1000 	 0.004445552825927734 	 0.0037016868591308594 	 1.8358230590820312e-05 	 1.71661376953125e-05 	 0.04016375541687012 	 0.057096004486083984 	 1.811981201171875e-05 	 5.936622619628906e-05 	 combined
2025-07-25 18:11:12.247458 test begin: paddle.matrix_transpose(Tensor([8467201, 3, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([8467201, 3, 4],"float16"), ) 	 101606412 	 1000 	 0.004654407501220703 	 0.0036725997924804688 	 2.8133392333984375e-05 	 1.71661376953125e-05 	 0.04009222984313965 	 0.05764198303222656 	 2.8371810913085938e-05 	 7.677078247070312e-05 	 combined
2025-07-25 18:11:16.264522 test begin: paddle.max(Tensor([416, 50, 10, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 50, 10, 256],"float32"), axis=1, ) 	 53248000 	 1000 	 0.1951313018798828 	 0.16024422645568848 	 0.1836223602294922 	 0.1453535556793213 	 1.1380176544189453 	 1.391347885131836 	 0.290799617767334 	 0.28423261642456055 	 
2025-07-25 18:11:20.082173 test begin: paddle.max(Tensor([416, 50, 7, 349],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 50, 7, 349],"float32"), axis=1, ) 	 50814400 	 1000 	 0.1956930160522461 	 0.1627652645111084 	 0.18416595458984375 	 0.1477372646331787 	 1.1068956851959229 	 1.3332524299621582 	 0.2828552722930908 	 0.27231860160827637 	 
2025-07-25 18:11:23.744340 test begin: paddle.max(Tensor([416, 69, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 69, 7, 256],"float32"), axis=1, ) 	 51437568 	 1000 	 0.19312667846679688 	 0.15486836433410645 	 0.18170762062072754 	 0.1402125358581543 	 1.0932226181030273 	 1.336719274520874 	 0.2794055938720703 	 0.27307772636413574 	 
2025-07-25 18:11:27.417632 test begin: paddle.max(Tensor([49, 1024, 1024],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([49, 1024, 1024],"float32"), axis=-1, keepdim=True, ) 	 51380224 	 1000 	 0.15543484687805176 	 0.14956021308898926 	 0.14328789710998535 	 0.13598012924194336 	 1.056593418121338 	 1.2878453731536865 	 0.27004551887512207 	 0.2630424499511719 	 
2025-07-25 18:11:30.985843 test begin: paddle.max(Tensor([512, 50, 7, 284],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 50, 7, 284],"float32"), axis=1, ) 	 50892800 	 1000 	 0.2030336856842041 	 0.15614581108093262 	 0.19139361381530762 	 0.14133548736572266 	 1.115126371383667 	 1.333942174911499 	 0.2849452495574951 	 0.2724344730377197 	 
2025-07-25 18:11:37.980203 test begin: paddle.max(Tensor([512, 50, 8, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 50, 8, 256],"float32"), axis=1, ) 	 52428800 	 1000 	 0.19423556327819824 	 0.1573648452758789 	 0.18283319473266602 	 0.1425316333770752 	 1.122434139251709 	 1.371190071105957 	 0.28679728507995605 	 0.2800333499908447 	 
2025-07-25 18:11:44.697199 test begin: paddle.max(Tensor([512, 56, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 56, 7, 256],"float32"), axis=1, ) 	 51380224 	 1000 	 0.1951286792755127 	 0.15425872802734375 	 0.18360376358032227 	 0.1394357681274414 	 1.0964064598083496 	 1.338397741317749 	 0.2801504135131836 	 0.27336764335632324 	 
2025-07-25 18:11:48.338858 test begin: paddle.max(Tensor([568, 50, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([568, 50, 7, 256],"float32"), axis=1, ) 	 50892800 	 1000 	 0.18945050239562988 	 0.15354442596435547 	 0.1780869960784912 	 0.1385505199432373 	 1.0920357704162598 	 1.3310091495513916 	 0.2790868282318115 	 0.2718636989593506 	 
2025-07-25 18:11:52.003278 test begin: paddle.max(Tensor([8, 1024, 6202],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([8, 1024, 6202],"float32"), axis=-1, keepdim=True, ) 	 50806784 	 1000 	 0.15179824829101562 	 0.16310787200927734 	 0.13966608047485352 	 0.14934372901916504 	 1.0481879711151123 	 1.2888779640197754 	 0.2678380012512207 	 0.2631721496582031 	 
2025-07-25 18:11:55.538891 test begin: paddle.max(Tensor([8, 6202, 1024],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([8, 6202, 1024],"float32"), axis=-1, keepdim=True, ) 	 50806784 	 1000 	 0.15398383140563965 	 0.14790058135986328 	 0.14185881614685059 	 0.13429641723632812 	 1.0459303855895996 	 1.2737348079681396 	 0.2672741413116455 	 0.260159969329834 	 
2025-07-25 18:11:59.020006 test begin: paddle.maximum(Tensor([11585, 4386],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([11585, 4386],"float32"), Tensor([1],"float32"), ) 	 50811811 	 1000 	 0.296616792678833 	 0.3044312000274658 	 0.2837238311767578 	 0.2926943302154541 	 0.7403950691223145 	 3.303974151611328 	 0.2518291473388672 	 0.2810060977935791 	 
2025-07-25 18:12:05.467987 test begin: paddle.maximum(Tensor([120961, 420],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([120961, 420],"float32"), Tensor([1],"float32"), ) 	 50803621 	 1000 	 0.2965083122253418 	 0.3044416904449463 	 0.28553175926208496 	 0.290463924407959 	 0.7399775981903076 	 3.3029322624206543 	 0.25171566009521484 	 0.280897855758667 	 
2025-07-25 18:12:11.859387 test begin: paddle.maximum(Tensor([121539, 418],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([121539, 418],"float32"), Tensor([1],"float32"), ) 	 50803303 	 1000 	 0.29639601707458496 	 0.3080012798309326 	 0.2858121395111084 	 0.292508602142334 	 0.7400224208831787 	 3.298985004425049 	 0.2517361640930176 	 0.2805368900299072 	 
2025-07-25 18:12:18.187000 test begin: paddle.maximum(Tensor([14877, 3415],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([14877, 3415],"float32"), Tensor([1],"float32"), ) 	 50804956 	 1000 	 0.2967836856842041 	 0.3058152198791504 	 0.28614044189453125 	 0.29260969161987305 	 0.740309476852417 	 3.2966737747192383 	 0.25184106826782227 	 0.28039050102233887 	 
2025-07-25 18:12:24.574359 test begin: paddle.maximum(Tensor([16121, 3152],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([16121, 3152],"float32"), Tensor([1],"float32"), ) 	 50813393 	 1000 	 0.29692959785461426 	 0.30438685417175293 	 0.2812378406524658 	 0.292618989944458 	 0.7405433654785156 	 3.2985734939575195 	 0.2519071102142334 	 0.2805061340332031 	 
2025-07-25 18:12:30.978158 test begin: paddle.maximum(Tensor([62643, 811],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([62643, 811],"float32"), Tensor([1],"float32"), ) 	 50803474 	 1000 	 0.29650115966796875 	 0.30433106422424316 	 0.2858271598815918 	 0.2926337718963623 	 0.7403144836425781 	 3.3018555641174316 	 0.25179457664489746 	 0.2808113098144531 	 
2025-07-25 18:12:37.909526 test begin: paddle.mean(Tensor([7573, 11, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7573, 11, 1280],"bfloat16"), axis=1, ) 	 106627840 	 1000 	 0.2100505828857422 	 0.21747446060180664 	 0.19864273071289062 	 0.18072032928466797 	 0.3470118045806885 	 0.44948601722717285 	 0.2866666316986084 	 0.2296133041381836 	 
2025-07-25 18:12:41.161414 test begin: paddle.mean(Tensor([7573, 8, 1678],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7573, 8, 1678],"bfloat16"), axis=1, ) 	 101659952 	 1000 	 0.1850905418395996 	 0.20765399932861328 	 0.17377114295959473 	 0.1672377586364746 	 0.34969067573547363 	 0.44283270835876465 	 0.2851440906524658 	 0.22623372077941895 	 
2025-07-25 18:12:44.301627 test begin: paddle.mean(Tensor([7710, 11, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7710, 11, 1280],"bfloat16"), axis=1, ) 	 108556800 	 1000 	 0.21386265754699707 	 0.20284724235534668 	 0.20247817039489746 	 0.18379974365234375 	 0.3528859615325928 	 0.45777368545532227 	 0.2811007499694824 	 0.23386430740356445 	 
2025-07-25 18:12:47.508041 test begin: paddle.mean(Tensor([7710, 8, 1648],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7710, 8, 1648],"bfloat16"), axis=1, ) 	 101648640 	 1000 	 0.18548798561096191 	 0.17869234085083008 	 0.17418479919433594 	 0.16338682174682617 	 0.34990811347961426 	 0.4452235698699951 	 0.28612804412841797 	 0.22744107246398926 	 
2025-07-25 18:12:50.661125 test begin: paddle.mean(Tensor([8162, 10, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([8162, 10, 1280],"bfloat16"), axis=1, ) 	 104473600 	 1000 	 0.20476794242858887 	 0.19205141067504883 	 0.1934037208557129 	 0.1773061752319336 	 0.34496474266052246 	 0.44757604598999023 	 0.2850375175476074 	 0.22866010665893555 	 
2025-07-25 18:12:53.829136 test begin: paddle.mean(Tensor([8162, 8, 1557],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([8162, 8, 1557],"bfloat16"), axis=1, ) 	 101665872 	 1000 	 0.18524909019470215 	 0.2205498218536377 	 0.1729426383972168 	 0.2003476619720459 	 0.3499014377593994 	 0.4601616859436035 	 0.2901887893676758 	 0.23508572578430176 	 
2025-07-25 18:12:56.932407 test begin: paddle.mean(Tensor([9923, 8, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([9923, 8, 1280],"bfloat16"), axis=1, ) 	 101611520 	 1000 	 0.1821892261505127 	 0.1762380599975586 	 0.17078661918640137 	 0.1604170799255371 	 0.3511948585510254 	 0.45243191719055176 	 0.29132986068725586 	 0.23111987113952637 	 
2025-07-25 18:12:59.980171 test begin: paddle.median(Tensor([2, 254016],"float32"), axis=1, mode="min", )
[Prof] paddle.median 	 paddle.median(Tensor([2, 254016],"float32"), axis=1, mode="min", ) 	 508032 	 1000 	 9.567634582519531 	 1.1589417457580566 	 0.19342660903930664 	 1.1400606632232666 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:11.091621 test begin: paddle.median(Tensor([254016],"int64"), )
W0725 18:13:16.814239 113393 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.median 	 paddle.median(Tensor([254016],"int64"), ) 	 254016 	 1000 	 5.711328744888306 	 0.18068814277648926 	 0.2408609390258789 	 0.007127046585083008 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:17.033921 test begin: paddle.median(Tensor([5080, 100],"float32"), axis=1, mode="min", )
[Prof] paddle.median 	 paddle.median(Tensor([5080, 100],"float32"), axis=1, mode="min", ) 	 508000 	 1000 	 2.6911838054656982 	 0.04344344139099121 	 0.06992173194885254 	 0.024738788604736328 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:13:20.003318 test begin: paddle.median(Tensor([508032],"float32"), )
[Prof] paddle.median 	 paddle.median(Tensor([508032],"float32"), ) 	 508032 	 1000 	 6.821917772293091 	 0.15959429740905762 	 0.3852500915527344 	 0.009523391723632812 	 0.5075738430023193 	 0.16675138473510742 	 0.043471336364746094 	 7.081031799316406e-05 	 combined
2025-07-25 18:13:27.692924 test begin: paddle.min(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 8.205143213272095 	 0.1572709083557129 	 0.008062601089477539 	 0.08031845092773438 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:43.037839 test begin: paddle.min(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.3294532299041748 	 0.17467141151428223 	 0.0002319812774658203 	 0.08924150466918945 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:45.242904 test begin: paddle.min(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402412 	 1000 	 0.3689584732055664 	 0.1689159870147705 	 0.00033926963806152344 	 0.15423274040222168 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:49.062660 test begin: paddle.min(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.2581925392150879 	 0.15147662162780762 	 0.0001747608184814453 	 0.13701558113098145 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:52.007711 test begin: paddle.min(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.20657777786254883 	 0.15388274192810059 	 0.00017690658569335938 	 0.13924241065979004 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:54.078883 test begin: paddle.min(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.19447898864746094 	 0.15441513061523438 	 0.0001678466796875 	 0.1397080421447754 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:56.086521 test begin: paddle.min(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 8.197262048721313 	 0.15726232528686523 	 0.008057832717895508 	 0.08027219772338867 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:14:11.403668 test begin: paddle.min(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402007 	 1000 	 0.8677995204925537 	 0.1671137809753418 	 0.0008356571197509766 	 0.15227794647216797 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:14:14.484364 test begin: paddle.min(Tensor([64, 1, 28, 28351],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1, 28, 28351],"float32"), ) 	 50804992 	 1000 	 0.1519777774810791 	 0.15271568298339844 	 0.07765817642211914 	 0.0780191421508789 	 1.043971061706543 	 1.2478880882263184 	 0.21353602409362793 	 0.212446928024292 	 
2025-07-25 18:14:18.061794 test begin: paddle.min(Tensor([64, 1, 28351, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1, 28351, 28],"float32"), ) 	 50804992 	 1000 	 0.15194296836853027 	 0.1527106761932373 	 0.0776205062866211 	 0.07801985740661621 	 1.0438978672027588 	 1.247671365737915 	 0.2135162353515625 	 0.21240615844726562 	 
2025-07-25 18:14:21.509838 test begin: paddle.min(Tensor([64, 1013, 28, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1013, 28, 28],"float32"), ) 	 50828288 	 1000 	 0.15200424194335938 	 0.15279746055603027 	 0.07765531539916992 	 0.07804703712463379 	 1.044257402420044 	 1.24818754196167 	 0.213623046875 	 0.21248579025268555 	 
2025-07-25 18:14:24.933556 test begin: paddle.min(Tensor([64801, 1, 28, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64801, 1, 28, 28],"float32"), ) 	 50803984 	 1000 	 0.15206098556518555 	 0.15265846252441406 	 0.07770204544067383 	 0.0780029296875 	 1.0443975925445557 	 1.2477216720581055 	 0.21363353729248047 	 0.21243596076965332 	 
2025-07-25 18:14:28.376238 test begin: paddle.minimum(Tensor([13, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([13, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980628 	 1000 	 3.788224697113037 	 4.095523118972778 	 3.7774875164031982 	 2.0925045013427734 	 18.578077793121338 	 47.0911431312561 	 4.740449905395508 	 2.1817240715026855 	 
2025-07-25 18:15:54.199521 test begin: paddle.minimum(Tensor([13, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([13, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803228 	 1000 	 3.772918701171875 	 4.075566291809082 	 3.762279748916626 	 2.082343816757202 	 32.01273536682129 	 46.67027235031128 	 8.169654607772827 	 2.1619772911071777 	 
2025-07-25 18:17:33.259228 test begin: paddle.minimum(Tensor([16, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([16, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980967 	 1000 	 4.664064645767212 	 5.040379524230957 	 4.6494529247283936 	 2.5717556476593018 	 22.563792943954468 	 57.30433011054993 	 5.757500410079956 	 2.6550745964050293 	 
2025-07-25 18:19:20.157479 test begin: paddle.minimum(Tensor([16, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([16, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803234 	 1000 	 4.644980430603027 	 5.011643409729004 	 4.625121116638184 	 2.5606114864349365 	 38.23921322822571 	 58.629947662353516 	 9.758064270019531 	 2.7175872325897217 	 
2025-07-25 18:21:21.650245 test begin: paddle.minimum(Tensor([9, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([9, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980176 	 1000 	 2.624114990234375 	 2.8301477432250977 	 2.606029748916626 	 2.8106846809387207 	 13.116878986358643 	 32.0434832572937 	 3.3471717834472656 	 2.516843318939209 	 
2025-07-25 18:22:20.987108 test begin: paddle.minimum(Tensor([9, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([9, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803220 	 1000 	 2.6142044067382812 	 2.8177413940429688 	 2.596069574356079 	 2.8047986030578613 	 23.357162714004517 	 31.97806406021118 	 5.961877107620239 	 2.5117454528808594 	 
2025-07-25 18:23:31.500504 test begin: paddle.mm(Tensor([1838, 6, 144, 144],"float32"), Tensor([1838, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([1838, 6, 144, 144],"float32"), Tensor([1838, 6, 144, 32],"float32"), ) 	 279493632 	 1000 	 6.462390661239624 	 6.032849311828613 	 6.010598182678223 	 5.9995739459991455 	 9.455262184143066 	 9.454616785049438 	 4.8314433097839355 	 4.831262111663818 	 
2025-07-25 18:24:08.728327 test begin: paddle.mm(Tensor([2048, 2, 144, 144],"float32"), Tensor([2048, 2, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 2, 144, 144],"float32"), Tensor([2048, 2, 144, 32],"float32"), ) 	 103809024 	 1000 	 2.2530224323272705 	 2.253213405609131 	 2.232468843460083 	 2.2301366329193115 	 3.530444622039795 	 3.5300729274749756 	 1.8040032386779785 	 1.8037643432617188 	 
2025-07-25 18:24:22.366562 test begin: paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 29],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 29],"float32"), ) 	 306118656 	 1000 	 6.7390429973602295 	 6.7359938621521 	 6.7226386070251465 	 6.702846050262451 	 10.28774881362915 	 10.286918640136719 	 5.2570641040802 	 5.25656795501709 	 
2025-07-25 18:25:02.562119 test begin: paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), ) 	 311427072 	 1000 	 6.73697304725647 	 6.7389976978302 	 6.723318815231323 	 6.710367679595947 	 10.549521207809448 	 10.550656080245972 	 5.390655279159546 	 5.391179084777832 	 
2025-07-25 18:25:43.519667 test begin: paddle.mm(Tensor([2048, 6, 29, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 29, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), ) 	 107937792 	 1000 	 3.368760585784912 	 3.3813507556915283 	 3.3535614013671875 	 3.343092679977417 	 3.727200746536255 	 3.727247953414917 	 1.9045767784118652 	 1.9045021533966064 	 
2025-07-25 18:26:01.309299 test begin: paddle.mm(Tensor([2757, 4, 144, 144],"float32"), Tensor([2757, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2757, 4, 144, 144],"float32"), Tensor([2757, 4, 144, 32],"float32"), ) 	 279493632 	 1000 	 6.0340282917022705 	 6.160071611404419 	 6.020941257476807 	 6.136781692504883 	 9.458288192749023 	 9.456373929977417 	 4.833756923675537 	 4.8320910930633545 	 
2025-07-25 18:26:39.757635 test begin: paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 1, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 1, 144, 32],"float32"), ) 	 97320960 	 1000 	 2.11513090133667 	 2.115154981613159 	 2.1026456356048584 	 2.0918939113616943 	 3.3133351802825928 	 3.3131015300750732 	 1.6930174827575684 	 1.6928207874298096 	 
2025-07-25 18:26:52.554315 test begin: paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), ) 	 150405120 	 1000 	 9.532932758331299 	 9.872786283493042 	 9.775161743164062e-05 	 5.045409917831421 	 14.569296598434448 	 14.31723165512085 	 0.0011873245239257812 	 4.874215602874756 	 
2025-07-25 18:27:44.642057 test begin: paddle.mm(Tensor([3840, 3, 144, 144],"float32"), Tensor([3840, 3, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 3, 144, 144],"float32"), Tensor([3840, 3, 144, 32],"float32"), ) 	 291962880 	 1000 	 6.322014808654785 	 6.3243796825408936 	 6.307854175567627 	 6.292925119400024 	 9.89811635017395 	 9.897249698638916 	 5.057840585708618 	 5.057352066040039 	 
2025-07-25 18:28:24.434701 test begin: paddle.mm(Tensor([3840, 4, 144, 144],"float32"), Tensor([3840, 4, 144, 23],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 4, 144, 144],"float32"), Tensor([3840, 4, 144, 23],"float32"), ) 	 369377280 	 1000 	 8.75768518447876 	 8.405609369277954 	 8.742130041122437 	 8.381832838058472 	 11.908296823501587 	 11.906332969665527 	 6.084801912307739 	 6.083914279937744 	 
2025-07-25 18:29:13.695876 test begin: paddle.mm(Tensor([3840, 4, 23, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 4, 23, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), ) 	 121651200 	 1000 	 4.213336706161499 	 4.214088439941406 	 4.200634241104126 	 4.190615653991699 	 4.208961248397827 	 4.209280967712402 	 2.150717258453369 	 2.1508355140686035 	 
2025-07-25 18:29:32.901182 test begin: paddle.mm(Tensor([409, 6, 144, 144],"float32"), Tensor([409, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([409, 6, 144, 144],"float32"), Tensor([409, 6, 144, 32],"float32"), ) 	 62194176 	 1000 	 1.366652011871338 	 1.382378339767456 	 1.353844165802002 	 1.3326239585876465 	 2.136082887649536 	 2.135979175567627 	 1.091416835784912 	 1.0913763046264648 	 
2025-07-25 18:29:43.445860 test begin: paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 1, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 1, 144, 32],"float32"), ) 	 103809024 	 1000 	 2.253403663635254 	 2.2534279823303223 	 2.2407047748565674 	 2.2301671504974365 	 3.5303165912628174 	 3.530193328857422 	 1.8038876056671143 	 1.8038196563720703 	 
2025-07-25 18:29:57.186583 test begin: paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), ) 	 160432128 	 1000 	 10.140692949295044 	 10.705688238143921 	 0.00011873245239257812 	 5.561072111129761 	 15.525146722793579 	 15.259305000305176 	 0.0012657642364501953 	 5.194289922714233 	 
2025-07-25 18:30:53.044260 test begin: paddle.mm(Tensor([4096, 3, 144, 144],"float32"), Tensor([4096, 3, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 3, 144, 144],"float32"), Tensor([4096, 3, 144, 32],"float32"), ) 	 311427072 	 1000 	 6.737792253494263 	 6.734911918640137 	 6.724129676818848 	 6.711654424667358 	 10.55427098274231 	 10.548135995864868 	 5.393372058868408 	 5.389846563339233 	 
2025-07-25 18:31:38.109743 test begin: paddle.mm(Tensor([4096, 4, 144, 144],"float32"), Tensor([4096, 4, 144, 22],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 4, 144, 144],"float32"), Tensor([4096, 4, 144, 22],"float32"), ) 	 391643136 	 1000 	 8.958177328109741 	 8.958782196044922 	 8.937633275985718 	 8.935346364974976 	 12.692363739013672 	 12.693512439727783 	 6.48598313331604 	 6.4864068031311035 	 
2025-07-25 18:32:29.429713 test begin: paddle.mm(Tensor([4096, 4, 22, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 4, 22, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), ) 	 127401984 	 1000 	 4.491237163543701 	 4.4910643100738525 	 4.4682300090789795 	 4.454861164093018 	 4.483358383178711 	 4.483391761779785 	 2.290930986404419 	 2.290938138961792 	 
2025-07-25 18:32:51.470712 test begin: paddle.mm(Tensor([613, 4, 144, 144],"float32"), Tensor([613, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([613, 4, 144, 144],"float32"), Tensor([613, 4, 144, 32],"float32"), ) 	 62143488 	 1000 	 1.3666670322418213 	 1.3667457103729248 	 1.353940486907959 	 1.3436737060546875 	 2.1354877948760986 	 2.1356565952301025 	 1.0911545753479004 	 1.0912079811096191 	 
2025-07-25 18:32:59.746597 test begin: paddle.mod(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4489312171936035 	 0.44736313819885254 	 0.4395766258239746 	 0.43594789505004883 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:02.730324 test begin: paddle.mod(Tensor([10, 5080321],"int32"), Tensor([10, 5080321],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([10, 5080321],"int32"), Tensor([10, 5080321],"int32"), ) 	 101606420 	 1000 	 0.45088624954223633 	 0.44955945014953613 	 0.4413142204284668 	 0.4375178813934326 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:06.582017 test begin: paddle.mod(Tensor([1270081, 2, 4, 5],"int32"), Tensor([1270081, 2, 4, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([1270081, 2, 4, 5],"int32"), Tensor([1270081, 2, 4, 5],"int32"), ) 	 101606480 	 1000 	 0.4509758949279785 	 0.4536101818084717 	 0.4414403438568115 	 0.43843603134155273 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:10.388955 test begin: paddle.mod(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4484860897064209 	 0.447127103805542 	 0.43913745880126953 	 0.4298553466796875 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:13.309937 test begin: paddle.mod(Tensor([2540161, 20],"int32"), Tensor([2540161, 20],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([2540161, 20],"int32"), Tensor([2540161, 20],"int32"), ) 	 101606440 	 1000 	 0.45246362686157227 	 0.4507026672363281 	 0.4427635669708252 	 0.4382321834564209 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:17.195380 test begin: paddle.mod(Tensor([6, 2, 4, 1058401],"int32"), Tensor([6, 2, 4, 1058401],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 2, 4, 1058401],"int32"), Tensor([6, 2, 4, 1058401],"int32"), ) 	 101606496 	 1000 	 0.4510653018951416 	 0.45064735412597656 	 0.44119977951049805 	 0.4383561611175537 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:21.005587 test begin: paddle.mod(Tensor([6, 2, 846721, 5],"int32"), Tensor([6, 2, 846721, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 2, 846721, 5],"int32"), Tensor([6, 2, 846721, 5],"int32"), ) 	 101606520 	 1000 	 0.4510324001312256 	 0.4495573043823242 	 0.4413774013519287 	 0.43850016593933105 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:24.912992 test begin: paddle.mod(Tensor([6, 423361, 4, 5],"int32"), Tensor([6, 423361, 4, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 423361, 4, 5],"int32"), Tensor([6, 423361, 4, 5],"int32"), ) 	 101606640 	 1000 	 0.4511103630065918 	 0.4495511054992676 	 0.441509485244751 	 0.4387035369873047 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:28.752461 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), -1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), -1, ) 	 240 	 1000 	 7.816960334777832 	 0.019122838973999023 	 0.00010156631469726562 	 4.76837158203125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:37.508560 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), -1, keepdim=True, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), -1, keepdim=True, ) 	 240 	 1000 	 7.992691993713379 	 0.016781091690063477 	 0.00010442733764648438 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:45.586534 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), 1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), 1, ) 	 240 	 1000 	 9.682742357254028 	 0.030922412872314453 	 9.584426879882812e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:55.374870 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), -1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), -1, ) 	 240 	 1000 	 10.205160856246948 	 0.027127742767333984 	 0.00010323524475097656 	 6.437301635742188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:34:05.691693 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), -1, keepdim=True, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), -1, keepdim=True, ) 	 240 	 1000 	 9.39171051979065 	 0.022662639617919922 	 9.560585021972656e-05 	 7.677078247070312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:34:15.191507 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), 1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), 1, ) 	 240 	 1000 	 7.812389850616455 	 0.03090047836303711 	 0.00012135505676269531 	 6.389617919921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:34:23.101654 test begin: paddle.moveaxis(Tensor([2, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([2, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 25401810 	 1000 	 0.008751392364501953 	 0.005964517593383789 	 1.2874603271484375e-05 	 1.9311904907226562e-05 	 0.03969860076904297 	 0.05920076370239258 	 1.9788742065429688e-05 	 6.008148193359375e-05 	 
2025-07-25 18:34:24.269919 test begin: paddle.moveaxis(Tensor([2, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([2, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 25401768 	 1000 	 0.008046388626098633 	 0.005837917327880859 	 1.3828277587890625e-05 	 2.09808349609375e-05 	 0.04105520248413086 	 0.059513092041015625 	 5.817413330078125e-05 	 7.009506225585938e-05 	 
2025-07-25 18:34:25.458184 test begin: paddle.moveaxis(Tensor([2, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([2, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 25401720 	 1000 	 0.008164405822753906 	 0.005904197692871094 	 1.2159347534179688e-05 	 1.8358230590820312e-05 	 0.04699087142944336 	 0.05856037139892578 	 7.224082946777344e-05 	 4.506111145019531e-05 	 
2025-07-25 18:34:26.649799 test begin: paddle.moveaxis(Tensor([2, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([2, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 25401880 	 1000 	 0.008223772048950195 	 0.010011434555053711 	 2.6941299438476562e-05 	 2.0265579223632812e-05 	 0.04887533187866211 	 0.06601977348327637 	 6.031990051269531e-05 	 6.008148193359375e-05 	 
2025-07-25 18:34:27.874569 test begin: paddle.moveaxis(Tensor([60481, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([60481, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 25402020 	 1000 	 0.007905721664428711 	 0.005883932113647461 	 8.106231689453125e-06 	 1.8358230590820312e-05 	 0.04012560844421387 	 0.05892491340637207 	 2.9802322387695312e-05 	 6.4849853515625e-05 	 
2025-07-25 18:34:29.094748 test begin: paddle.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 25401810 	 1000 	 0.007029533386230469 	 0.004688262939453125 	 1.7404556274414062e-05 	 1.8358230590820312e-05 	 0.039792537689208984 	 0.05989575386047363 	 3.3855438232421875e-05 	 4.124641418457031e-05 	 
2025-07-25 18:34:30.262587 test begin: paddle.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([120961, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401810 	 1000 	 0.0074803829193115234 	 0.005845546722412109 	 8.106231689453125e-06 	 1.7642974853515625e-05 	 0.039882659912109375 	 0.05851149559020996 	 3.933906555175781e-05 	 6.318092346191406e-05 	 
2025-07-25 18:34:31.425230 test begin: paddle.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 25401768 	 1000 	 0.006949901580810547 	 0.004725217819213867 	 7.867813110351562e-06 	 1.6927719116210938e-05 	 0.0397648811340332 	 0.05877375602722168 	 3.457069396972656e-05 	 5.984306335449219e-05 	 
2025-07-25 18:34:32.589287 test begin: paddle.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401768 	 1000 	 0.007447957992553711 	 0.010069608688354492 	 1.2636184692382812e-05 	 2.4080276489257812e-05 	 0.04721665382385254 	 0.06163787841796875 	 3.504753112792969e-05 	 7.486343383789062e-05 	 
2025-07-25 18:34:33.776072 test begin: paddle.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 25401720 	 1000 	 0.006975650787353516 	 0.004690408706665039 	 6.9141387939453125e-06 	 2.1219253540039062e-05 	 0.04181623458862305 	 0.06085371971130371 	 3.409385681152344e-05 	 7.200241088867188e-05 	 
2025-07-25 18:34:34.949285 test begin: paddle.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401720 	 1000 	 0.0074541568756103516 	 0.005830049514770508 	 1.3589859008789062e-05 	 2.7894973754882812e-05 	 0.040283918380737305 	 0.06171846389770508 	 4.38690185546875e-05 	 7.82012939453125e-05 	 
2025-07-25 18:34:37.232913 test begin: paddle.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 25401880 	 1000 	 0.006944417953491211 	 0.004694938659667969 	 1.0013580322265625e-05 	 1.8358230590820312e-05 	 0.039542436599731445 	 0.06148481369018555 	 2.8371810913085938e-05 	 7.176399230957031e-05 	 
2025-07-25 18:34:39.840259 test begin: paddle.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25401880 	 1000 	 0.0076901912689208984 	 0.009134531021118164 	 4.458427429199219e-05 	 3.4809112548828125e-05 	 0.0433199405670166 	 0.06281733512878418 	 3.647804260253906e-05 	 8.034706115722656e-05 	 
2025-07-25 18:34:41.042832 test begin: paddle.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 25402020 	 1000 	 0.012033700942993164 	 0.008460760116577148 	 1.049041748046875e-05 	 2.4318695068359375e-05 	 0.04751753807067871 	 0.06632447242736816 	 4.696846008300781e-05 	 6.651878356933594e-05 	 
2025-07-25 18:34:42.260522 test begin: paddle.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([4, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 25402020 	 1000 	 0.00737452507019043 	 0.0070037841796875 	 7.867813110351562e-06 	 5.435943603515625e-05 	 0.03981661796569824 	 0.05850052833557129 	 3.910064697265625e-05 	 5.078315734863281e-05 	 
2025-07-25 18:34:45.338565 test begin: paddle.multigammaln(Tensor([10, 2540161],"float64"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([10, 2540161],"float64"), 2, ) 	 25401610 	 1000 	 2.9488353729248047 	 2.8025670051574707 	 0.5015723705291748 	 0.5726399421691895 	 4.0176918506622314 	 3.6681978702545166 	 1.0277009010314941 	 0.7493243217468262 	 
2025-07-25 18:34:59.961072 test begin: paddle.multigammaln(Tensor([10, 5080321],"float32"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([10, 5080321],"float32"), 2, ) 	 50803210 	 1000 	 2.3987414836883545 	 2.582288980484009 	 0.4087710380554199 	 0.528038501739502 	 3.453756809234619 	 3.9847021102905273 	 0.8834164142608643 	 0.814140796661377 	 
2025-07-25 18:35:14.184765 test begin: paddle.multigammaln(Tensor([1270081, 20],"float64"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([1270081, 20],"float64"), 2, ) 	 25401620 	 1000 	 2.9461891651153564 	 2.8020970821380615 	 0.5016107559204102 	 0.5724432468414307 	 4.017143726348877 	 3.667898654937744 	 1.027620792388916 	 0.7491817474365234 	 
2025-07-25 18:35:28.774162 test begin: paddle.multigammaln(Tensor([2540161, 20],"float32"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([2540161, 20],"float32"), 2, ) 	 50803220 	 1000 	 2.3984546661376953 	 2.5854878425598145 	 0.40872955322265625 	 0.5280618667602539 	 3.453420877456665 	 3.9838669300079346 	 0.8833034038543701 	 0.8141443729400635 	 
2025-07-25 18:35:44.051005 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([127, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([127, 1],"int32"), ) 	 101606535 	 1000 	 0.4389364719390869 	 3.2528762817382812 	 4.1961669921875e-05 	 0.0001533031463623047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:35:50.224699 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([6, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([6, 1],"int32"), ) 	 101606414 	 1000 	 0.0649411678314209 	 0.17717242240905762 	 3.457069396972656e-05 	 6.580352783203125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:35:53.235925 test begin: paddle.multiplex(inputs=list[Tensor([7, 7257601],"float32"),Tensor([7, 7257601],"float32"),], index=Tensor([6, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([7, 7257601],"float32"),Tensor([7, 7257601],"float32"),], index=Tensor([6, 1],"int32"), ) 	 101606420 	 1000 	 0.33240509033203125 	 0.45076465606689453 	 0.00028634071350097656 	 0.00028896331787109375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:35:57.121254 test begin: paddle.multiply(Tensor([298, 872, 14, 14],"float32"), Tensor([298, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([298, 872, 14, 14],"float32"), Tensor([298, 872, 1, 1],"float32"), ) 	 51191632 	 1000 	 0.302309513092041 	 0.30835676193237305 	 0.2797536849975586 	 0.2853536605834961 	 0.8777329921722412 	 0.9122810363769531 	 0.44844913482666016 	 0.3105475902557373 	 
2025-07-25 18:36:01.192047 test begin: paddle.multiply(Tensor([512, 507, 14, 14],"float32"), Tensor([512, 507, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 507, 14, 14],"float32"), Tensor([512, 507, 1, 1],"float32"), ) 	 51138048 	 1000 	 0.2971177101135254 	 0.3067488670349121 	 0.2794077396392822 	 0.2878282070159912 	 0.8763835430145264 	 0.9115159511566162 	 0.44772791862487793 	 0.3104517459869385 	 
2025-07-25 18:36:05.291997 test begin: paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 1],"float32"), ) 	 56700928 	 1000 	 0.32917070388793945 	 0.3394312858581543 	 0.3105154037475586 	 0.32045888900756836 	 0.8953430652618408 	 1.0284368991851807 	 0.45743274688720703 	 0.35016846656799316 	 
2025-07-25 18:36:09.756406 test begin: paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 9],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 9],"float32"), ) 	 60272640 	 1000 	 0.33859944343566895 	 0.35463547706604004 	 0.32774853706359863 	 0.34245991706848145 	 0.8709766864776611 	 1.0407397747039795 	 0.4449753761291504 	 0.354341983795166 	 
2025-07-25 18:36:14.251703 test begin: paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 1, 1],"float32"), ) 	 56700928 	 1000 	 0.32855653762817383 	 0.339432954788208 	 0.3157978057861328 	 0.3268401622772217 	 0.8953526020050049 	 1.0284335613250732 	 0.4574310779571533 	 0.35013318061828613 	 
2025-07-25 18:36:18.739923 test begin: paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 9, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 9, 1],"float32"), ) 	 60272640 	 1000 	 0.3387730121612549 	 0.3508479595184326 	 0.32520270347595215 	 0.33709216117858887 	 0.9313254356384277 	 1.1858017444610596 	 0.4758150577545166 	 0.4038410186767578 	 
2025-07-25 18:36:23.456833 test begin: paddle.multiply(x=Tensor([128, 127, 56, 56],"float32"), y=Tensor([128, 127, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 127, 56, 56],"float32"), y=Tensor([128, 127, 1, 1],"float32"), ) 	 50995072 	 1000 	 0.29698610305786133 	 0.30881619453430176 	 0.28638744354248047 	 0.29537463188171387 	 0.7425196170806885 	 0.9049234390258789 	 0.37932491302490234 	 0.30814290046691895 	 
2025-07-25 18:36:27.330894 test begin: paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 1, 1],"float32"), ) 	 51408896 	 1000 	 0.2992990016937256 	 0.3147587776184082 	 0.28865885734558105 	 0.3009920120239258 	 0.7469305992126465 	 0.9128186702728271 	 0.3816235065460205 	 0.3107945919036865 	 
2025-07-25 18:36:31.282489 test begin: paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 32, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 32, 1],"float32"), ) 	 52297728 	 1000 	 0.30196166038513184 	 0.3140749931335449 	 0.29137086868286133 	 0.3002464771270752 	 0.8609542846679688 	 1.0879056453704834 	 0.4398820400238037 	 0.3705170154571533 	 
2025-07-25 18:36:37.260530 test begin: paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 1],"float32"), ) 	 51408896 	 1000 	 0.5206942558288574 	 0.32029294967651367 	 0.2886064052581787 	 0.30057454109191895 	 0.746920108795166 	 0.9127953052520752 	 0.38160157203674316 	 0.31078290939331055 	 
2025-07-25 18:36:41.723631 test begin: paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 32],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 32],"float32"), ) 	 52297728 	 1000 	 0.30553722381591797 	 0.3154256343841553 	 0.2911064624786377 	 0.30341315269470215 	 0.7863812446594238 	 0.9183609485626221 	 0.40175867080688477 	 0.31264591217041016 	 
2025-07-25 18:36:45.763392 test begin: paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 1, 1],"float32"), ) 	 51412992 	 1000 	 0.2993321418762207 	 0.3121681213378906 	 0.2885746955871582 	 0.3000040054321289 	 0.7497823238372803 	 0.9137189388275146 	 0.3830862045288086 	 0.31108951568603516 	 
2025-07-25 18:36:49.785042 test begin: paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 28, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 28, 1],"float32"), ) 	 52297728 	 1000 	 0.30196642875671387 	 0.31220030784606934 	 0.2912888526916504 	 0.30030083656311035 	 0.8609199523925781 	 1.0879297256469727 	 0.4398617744445801 	 0.37050461769104004 	 
2025-07-25 18:36:55.037212 test begin: paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 1],"float32"), ) 	 51412992 	 1000 	 0.8373661041259766 	 0.31216979026794434 	 0.2884683609008789 	 0.29839420318603516 	 0.7499291896820068 	 0.9137380123138428 	 0.3830549716949463 	 0.3110966682434082 	 
2025-07-25 18:36:59.946284 test begin: paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 28],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 28],"float32"), ) 	 52297728 	 1000 	 0.3018357753753662 	 0.31617164611816406 	 0.29088568687438965 	 0.3041684627532959 	 1.0086958408355713 	 0.9233198165893555 	 0.5153765678405762 	 0.31437253952026367 	 
2025-07-25 18:37:04.177463 test begin: paddle.multiply(x=Tensor([64, 256, 56, 56],"float32"), y=Tensor([64, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([64, 256, 56, 56],"float32"), y=Tensor([64, 256, 1, 1],"float32"), ) 	 51396608 	 1000 	 0.3002464771270752 	 0.31122756004333496 	 0.2886795997619629 	 0.2993443012237549 	 0.7479867935180664 	 0.9116199016571045 	 0.3821539878845215 	 0.31034064292907715 	 
2025-07-25 18:37:08.110696 test begin: paddle.multiply(x=Tensor([73, 224, 56, 56],"float32"), y=Tensor([73, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([73, 224, 56, 56],"float32"), y=Tensor([73, 224, 1, 1],"float32"), ) 	 51296224 	 1000 	 0.2989521026611328 	 0.3106229305267334 	 0.28629517555236816 	 0.29858970642089844 	 0.7466063499450684 	 0.9099471569061279 	 0.38146114349365234 	 0.30980587005615234 	 
2025-07-25 18:37:12.036821 test begin: paddle.mv(Tensor([1411201, 36],"float32"), Tensor([36],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([1411201, 36],"float32"), Tensor([36],"float32"), ) 	 50803272 	 1000 	 0.19677329063415527 	 0.1933891773223877 	 0.18527770042419434 	 0.17711138725280762 	 0.49188995361328125 	 0.41822361946105957 	 0.16745471954345703 	 0.14242959022521973 	 
2025-07-25 18:37:14.284273 test begin: paddle.mv(Tensor([254017, 100],"float64"), Tensor([100],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([254017, 100],"float64"), Tensor([100],"float64"), ) 	 25401800 	 1000 	 0.1582016944885254 	 0.1584172248840332 	 0.14698004722595215 	 0.1364452838897705 	 0.33835816383361816 	 0.3313713073730469 	 0.11516356468200684 	 0.11278676986694336 	 
2025-07-25 18:37:15.912503 test begin: paddle.mv(Tensor([3, 16934401],"float32"), Tensor([16934401],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([3, 16934401],"float32"), Tensor([16934401],"float32"), ) 	 67737604 	 1000 	 0.23552536964416504 	 0.23343729972839355 	 0.12033724784851074 	 0.11924219131469727 	 0.6260688304901123 	 0.6058769226074219 	 0.3198375701904297 	 0.3094964027404785 	 
2025-07-25 18:37:18.788753 test begin: paddle.mv(Tensor([3, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([3, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 203212804 	 1000 	 0.6754183769226074 	 0.6737957000732422 	 0.34516072273254395 	 0.34427595138549805 	 1.8501055240631104 	 1.7993621826171875 	 0.9453411102294922 	 0.9194004535675049 	 
2025-07-25 18:37:27.176515 test begin: paddle.mv(Tensor([5, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([5, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 152409606 	 1000 	 0.9595000743865967 	 0.9346637725830078 	 0.490262508392334 	 0.4776163101196289 	 2.401242971420288 	 2.4081063270568848 	 1.2268943786621094 	 1.2304131984710693 	 
2025-07-25 18:37:37.500520 test begin: paddle.mv(Tensor([5, 5080321],"float64"), Tensor([5080321],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([5, 5080321],"float64"), Tensor([5080321],"float64"), ) 	 30481926 	 1000 	 0.22967910766601562 	 0.2263648509979248 	 0.11736488342285156 	 0.1156620979309082 	 0.49091482162475586 	 0.4927561283111572 	 0.25068235397338867 	 0.2517380714416504 	 
2025-07-25 18:37:40.862665 test begin: paddle.mv(Tensor([64, 396901],"float64"), Tensor([396901],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([64, 396901],"float64"), Tensor([396901],"float64"), ) 	 25798565 	 1000 	 0.15615439414978027 	 0.15442681312561035 	 0.07956528663635254 	 0.07889175415039062 	 0.3267323970794678 	 0.3294353485107422 	 0.1669008731842041 	 0.16823148727416992 	 
2025-07-25 18:37:42.405531 test begin: paddle.mv(Tensor([793801, 32],"float64"), Tensor([32],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([793801, 32],"float64"), Tensor([32],"float64"), ) 	 25401664 	 1000 	 0.17241930961608887 	 0.1626601219177246 	 0.15080618858337402 	 0.13495326042175293 	 0.33395934104919434 	 0.33736491203308105 	 0.11368584632873535 	 0.11480140686035156 	 
2025-07-25 18:37:43.996122 test begin: paddle.nan_to_num(Tensor([148, 114422, 3],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([148, 114422, 3],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803368 	 1000 	 3.0068118572235107 	 0.30320048332214355 	 0.279463529586792 	 0.28514885902404785 	 1.253387451171875 	 1.1595237255096436 	 0.42699337005615234 	 0.23701167106628418 	 
2025-07-25 18:37:51.422641 test begin: paddle.nan_to_num(Tensor([148, 5, 68653],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([148, 5, 68653],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803220 	 1000 	 3.0080559253692627 	 0.2978935241699219 	 0.2795867919921875 	 0.28497862815856934 	 1.2534534931182861 	 1.1590354442596436 	 0.4269437789916992 	 0.23691439628601074 	 
2025-07-25 18:38:00.497243 test begin: paddle.nan_to_num(Tensor([1948, 26080],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([1948, 26080],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803840 	 1000 	 3.0081064701080322 	 0.297914981842041 	 0.2795548439025879 	 0.28531956672668457 	 1.256824254989624 	 1.158266544342041 	 0.42812156677246094 	 0.2367560863494873 	 
2025-07-25 18:38:09.900011 test begin: paddle.nan_to_num(Tensor([25401601, 1],"float64"), neginf=-2.220446049250313e-16, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([25401601, 1],"float64"), neginf=-2.220446049250313e-16, ) 	 25401601 	 1000 	 2.8837759494781494 	 0.299088716506958 	 0.26804232597351074 	 0.2866475582122803 	 0.9844801425933838 	 1.029792308807373 	 0.3353288173675537 	 0.21037507057189941 	 
2025-07-25 18:38:16.168683 test begin: paddle.nan_to_num(Tensor([25401601, 2],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([25401601, 2],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803202 	 1000 	 3.008594036102295 	 0.3014342784881592 	 0.2797207832336426 	 0.28539013862609863 	 1.253723382949829 	 1.158923625946045 	 0.42706918716430664 	 0.23684477806091309 	 
2025-07-25 18:38:23.592524 test begin: paddle.nan_to_num(Tensor([3386881, 5, 3],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([3386881, 5, 3],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803215 	 1000 	 3.00846529006958 	 0.29792356491088867 	 0.2796502113342285 	 0.285250186920166 	 1.253814935684204 	 1.1590940952301025 	 0.4270949363708496 	 0.23690581321716309 	 
2025-07-25 18:38:31.078173 test begin: paddle.nan_to_num(Tensor([400, 63505],"float64"), neginf=-2.220446049250313e-16, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([400, 63505],"float64"), neginf=-2.220446049250313e-16, ) 	 25402000 	 1000 	 2.8837790489196777 	 0.5298221111297607 	 0.26817846298217773 	 0.2862231731414795 	 0.9840092658996582 	 1.0309321880340576 	 0.335176944732666 	 0.21067476272583008 	 
2025-07-25 18:38:40.612916 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), -1, False, ) 	 50803240 	 1000 	 2.482987403869629 	 1.6961114406585693 	 0.25342321395874023 	 0.28771162033081055 	 0.7110641002655029 	 0.7390620708465576 	 0.24233102798461914 	 0.18885564804077148 	 
2025-07-25 18:38:47.379929 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), 2, True, ) 	 50803240 	 1000 	 2.819901704788208 	 1.377601146697998 	 0.28784751892089844 	 0.23451924324035645 	 0.7386043071746826 	 0.7876608371734619 	 0.2517266273498535 	 0.20087409019470215 	 
2025-07-25 18:38:54.222302 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), None, False, ) 	 50803240 	 1000 	 1.9803593158721924 	 1.100515365600586 	 0.16823840141296387 	 0.14061832427978516 	 0.5611796379089355 	 0.5927011966705322 	 0.19132018089294434 	 0.15151381492614746 	 
2025-07-25 18:38:59.352925 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), -1, False, ) 	 50803230 	 1000 	 2.483032703399658 	 1.6900393962860107 	 0.2535085678100586 	 0.28773975372314453 	 0.7055189609527588 	 0.7389295101165771 	 0.24043679237365723 	 0.1888291835784912 	 
2025-07-25 18:39:06.021123 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), 2, True, ) 	 50803230 	 1000 	 14.39838457107544 	 1.131849765777588 	 1.2238819599151611 	 0.14464974403381348 	 0.5590231418609619 	 0.6293144226074219 	 0.19056940078735352 	 0.160888671875 	 
2025-07-25 18:39:25.478088 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), None, False, ) 	 50803230 	 1000 	 1.9800777435302734 	 1.1002278327941895 	 0.16823244094848633 	 0.14061880111694336 	 0.5552492141723633 	 0.5933964252471924 	 0.18927335739135742 	 0.15168166160583496 	 
2025-07-25 18:39:30.528186 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), -1, False, ) 	 50803224 	 1000 	 2.0411112308502197 	 1.1004433631896973 	 0.1734938621520996 	 0.14059782028198242 	 0.5562520027160645 	 0.6106083393096924 	 0.1896073818206787 	 0.15608739852905273 	 
2025-07-25 18:39:37.380765 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), 2, True, ) 	 50803224 	 1000 	 2.34224009513855 	 1.3756132125854492 	 0.23780488967895508 	 0.23419857025146484 	 0.7535996437072754 	 0.7905614376068115 	 0.2568545341491699 	 0.20203018188476562 	 
2025-07-25 18:39:45.228300 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), None, False, ) 	 50803224 	 1000 	 1.9799106121063232 	 1.100064992904663 	 0.16824984550476074 	 0.14055132865905762 	 0.5553011894226074 	 0.5933928489685059 	 0.18933510780334473 	 0.15168499946594238 	 
2025-07-25 18:39:50.297066 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), -1, False, ) 	 50803260 	 1000 	 2.4829845428466797 	 1.6928620338439941 	 0.25342345237731934 	 0.28774046897888184 	 0.7110123634338379 	 0.7390549182891846 	 0.24236226081848145 	 0.1888408660888672 	 
2025-07-25 18:39:56.959033 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), 2, True, ) 	 50803260 	 1000 	 2.8197100162506104 	 1.3774960041046143 	 0.287794828414917 	 0.23449277877807617 	 0.7386608123779297 	 0.785895824432373 	 0.2517375946044922 	 0.20085930824279785 	 
2025-07-25 18:40:03.769212 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), None, False, ) 	 50803260 	 1000 	 1.9799127578735352 	 1.1005516052246094 	 0.16828489303588867 	 0.14064812660217285 	 0.5611569881439209 	 0.5927166938781738 	 0.1913158893585205 	 0.15149259567260742 	 
2025-07-25 18:40:08.837194 test begin: paddle.nanmedian(Tensor([2, 254016],"float32"), axis=1, mode="min", )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([2, 254016],"float32"), axis=1, mode="min", ) 	 508032 	 1000 	 3.496799945831299 	 1.3909521102905273 	 0.00339508056640625 	 1.3724074363708496 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:40:14.086782 test begin: paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, ) 	 508032 	 1000 	 6.876598596572876 	 0.24730420112609863 	 0.006760835647583008 	 7.534027099609375e-05 	 0.05658459663391113 	 0.5360550880432129 	 4.8160552978515625e-05 	 0.0003387928009033203 	 combined
2025-07-25 18:40:21.842602 test begin: paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, mode="min", )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, mode="min", ) 	 508032 	 1000 	 6.878146171569824 	 0.27349019050598145 	 0.006762266159057617 	 8.082389831542969e-05 	 0.056958675384521484 	 0.1384739875793457 	 2.002716064453125e-05 	 4.9591064453125e-05 	 combined
2025-07-25 18:40:29.247455 test begin: paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0, axis=1, )
W0725 18:40:29.253422 131903 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 0.4808509349822998 	 0.32448816299438477 	 0.013215303421020508 	 0.0024487972259521484 	 0.19715309143066406 	 0.22627043724060059 	 2.4080276489257812e-05 	 6.580352783203125e-05 	 
2025-07-25 18:40:30.540289 test begin: paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 18.961865186691284 	 0.21732592582702637 	 0.5877077579498291 	 7.319450378417969e-05 	 0.1661059856414795 	 0.20302748680114746 	 3.314018249511719e-05 	 4.1961669921875e-05 	 
2025-07-25 18:40:50.148734 test begin: paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0, axis=1, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 16.3042094707489 	 1.0380806922912598 	 0.45644474029541016 	 7.653236389160156e-05 	 0.19655823707580566 	 0.2211294174194336 	 2.956390380859375e-05 	 4.38690185546875e-05 	 
2025-07-25 18:41:08.345875 test begin: paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 0.3990364074707031 	 0.30015993118286133 	 0.002964019775390625 	 0.006575584411621094 	 0.16359925270080566 	 0.2059335708618164 	 3.4332275390625e-05 	 7.677078247070312e-05 	 
2025-07-25 18:41:10.130145 test begin: paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0, axis=1, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 16.309560298919678 	 0.21755385398864746 	 0.4565732479095459 	 6.842613220214844e-05 	 0.19580435752868652 	 0.22410321235656738 	 5.316734313964844e-05 	 5.221366882324219e-05 	 
2025-07-25 18:41:27.833994 test begin: paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 18.960684299468994 	 0.21063852310180664 	 0.5877189636230469 	 4.601478576660156e-05 	 0.164931058883667 	 0.21384334564208984 	 3.3855438232421875e-05 	 7.009506225585938e-05 	 
2025-07-25 18:41:47.416044 test begin: paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803240 	 1000 	 1.0084421634674072 	 0.15235662460327148 	 0.20587873458862305 	 0.07783865928649902 	 0.5517082214355469 	 0.5891005992889404 	 0.28186726570129395 	 0.20064139366149902 	 
2025-07-25 18:41:50.592712 test begin: paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803240 	 1000 	 1.0084419250488281 	 0.1523749828338623 	 0.20584511756896973 	 0.07783627510070801 	 0.5517628192901611 	 0.5890746116638184 	 0.28187108039855957 	 0.20062661170959473 	 
2025-07-25 18:41:53.748107 test begin: paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803230 	 1000 	 1.0101335048675537 	 0.15240216255187988 	 0.20589041709899902 	 0.07786393165588379 	 0.5517761707305908 	 0.5890810489654541 	 0.2819032669067383 	 0.20065641403198242 	 
2025-07-25 18:41:56.943763 test begin: paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803230 	 1000 	 1.0084421634674072 	 0.1523573398590088 	 0.20589113235473633 	 0.07783174514770508 	 0.5517215728759766 	 0.5891754627227783 	 0.281876802444458 	 0.2006385326385498 	 
2025-07-25 18:42:00.085795 test begin: paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=False, name=None, ) 	 50803224 	 1000 	 1.009688138961792 	 0.1523294448852539 	 0.20582914352416992 	 0.07780218124389648 	 0.5517687797546387 	 0.5891227722167969 	 0.2818937301635742 	 0.20064735412597656 	 
2025-07-25 18:42:03.256005 test begin: paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=True, name=None, ) 	 50803224 	 1000 	 1.0084202289581299 	 0.15236330032348633 	 0.20589041709899902 	 0.07783007621765137 	 0.5517399311065674 	 0.5891218185424805 	 0.28188061714172363 	 0.2006676197052002 	 
2025-07-25 18:42:06.423113 test begin: paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803260 	 1000 	 1.0084199905395508 	 0.15231609344482422 	 0.20588088035583496 	 0.07780599594116211 	 0.5517268180847168 	 0.5891308784484863 	 0.28186655044555664 	 0.200669527053833 	 
2025-07-25 18:42:09.556764 test begin: paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803260 	 1000 	 1.0084216594696045 	 0.15240693092346191 	 0.20587849617004395 	 0.07787847518920898 	 0.551734447479248 	 0.5890333652496338 	 0.28189563751220703 	 0.2006244659423828 	 
2025-07-25 18:42:12.721442 test begin: paddle.nansum(x=Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0632619857788086 	 0.18949460983276367 	 0.2719278335571289 	 0.17389416694641113 	 0.5296101570129395 	 0.4412500858306885 	 0.27056193351745605 	 0.15023207664489746 	 
2025-07-25 18:42:15.653277 test begin: paddle.nansum(x=Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0630874633789062 	 0.18949341773986816 	 0.2718491554260254 	 0.17381882667541504 	 0.5296416282653809 	 0.44124674797058105 	 0.2705874443054199 	 0.15021276473999023 	 
2025-07-25 18:42:18.629790 test begin: paddle.nansum(x=Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401780 	 1000 	 5.656128406524658 	 0.17350101470947266 	 1.1586692333221436 	 0.08861899375915527 	 0.46532225608825684 	 0.4175257682800293 	 0.23771142959594727 	 0.1420307159423828 	 
2025-07-25 18:42:26.869998 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401744 	 1000 	 0.9741191864013672 	 0.19016814231872559 	 0.24899792671203613 	 0.17445874214172363 	 0.5118305683135986 	 0.44333434104919434 	 0.26148295402526855 	 0.15096783638000488 	 
2025-07-25 18:42:29.685544 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 0.9748423099517822 	 0.19356036186218262 	 0.24922800064086914 	 0.17499208450317383 	 0.5118489265441895 	 0.44368600845336914 	 0.26155734062194824 	 0.15104913711547852 	 
2025-07-25 18:42:32.473705 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, ) 	 25402320 	 1000 	 0.9761083126068115 	 0.19176077842712402 	 0.24920272827148438 	 0.1746060848236084 	 0.51167893409729 	 0.4452693462371826 	 0.26137328147888184 	 0.1515953540802002 	 
2025-07-25 18:42:37.910372 test begin: paddle.nansum(x=Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 1.0687103271484375 	 0.19510293006896973 	 0.27202296257019043 	 0.16724276542663574 	 0.5292973518371582 	 0.44158506393432617 	 0.2704463005065918 	 0.1503453254699707 	 
2025-07-25 18:42:43.187043 test begin: paddle.neg(Tensor([3175201, 8],"float64"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([3175201, 8],"float64"), ) 	 25401608 	 1000 	 0.29826831817626953 	 0.2985038757324219 	 0.28176307678222656 	 0.28122806549072266 	 0.2977907657623291 	 0.29839205741882324 	 0.23829340934753418 	 0.22532939910888672 	 
2025-07-25 18:42:45.481783 test begin: paddle.neg(Tensor([32, 1587601],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 0.2958657741546631 	 0.2978782653808594 	 0.28653788566589355 	 0.28736400604248047 	 0.29622912406921387 	 0.29778003692626953 	 0.24314475059509277 	 0.23230624198913574 	 
2025-07-25 18:42:48.359699 test begin: paddle.neg(Tensor([32, 793801],"float64"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([32, 793801],"float64"), ) 	 25401632 	 1000 	 0.2982172966003418 	 0.2983548641204834 	 0.28900885581970215 	 0.2877693176269531 	 0.29776525497436523 	 0.29818034172058105 	 0.24739694595336914 	 0.23053741455078125 	 
2025-07-25 18:42:50.674676 test begin: paddle.neg(Tensor([6350401, 8],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([6350401, 8],"float32"), ) 	 50803208 	 1000 	 0.30021238327026367 	 0.2979090213775635 	 0.2865016460418701 	 0.2871735095977783 	 0.29622745513916016 	 0.29775333404541016 	 0.24602580070495605 	 0.23265361785888672 	 
2025-07-25 18:42:53.509861 test begin: paddle.neg(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2981746196746826 	 0.29804491996765137 	 0.2865736484527588 	 0.28437042236328125 	 0.2962646484375 	 0.29775571823120117 	 0.24346637725830078 	 0.23233652114868164 	 
2025-07-25 18:42:56.344042 test begin: paddle.neg(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2965879440307617 	 0.2978849411010742 	 0.28667354583740234 	 0.28727126121520996 	 0.2962174415588379 	 0.2977294921875 	 0.24112248420715332 	 0.22846174240112305 	 
2025-07-25 18:42:59.182168 test begin: paddle.neg(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2958972454071045 	 0.29790449142456055 	 0.2865304946899414 	 0.28246116638183594 	 0.2963101863861084 	 0.2977635860443115 	 0.2424921989440918 	 0.23177289962768555 	 
2025-07-25 18:43:02.122533 test begin: paddle.negative(Tensor([1693441, 3, 4, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([1693441, 3, 4, 5],"float16"), ) 	 101606460 	 1000 	 0.29871559143066406 	 0.2964024543762207 	 0.28660130500793457 	 0.2856101989746094 	 0.29822325706481934 	 0.29615306854248047 	 0.24442744255065918 	 0.22964787483215332 	 
2025-07-25 18:43:07.119394 test begin: paddle.negative(Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 1270081, 4, 5],"float32"), ) 	 50803240 	 1000 	 0.2959096431732178 	 0.2979097366333008 	 0.2836029529571533 	 0.28714799880981445 	 0.2961857318878174 	 0.2977592945098877 	 0.24602508544921875 	 0.2287890911102295 	 
2025-07-25 18:43:09.969238 test begin: paddle.negative(Tensor([2, 2540161, 4, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 2540161, 4, 5],"float16"), ) 	 101606440 	 1000 	 0.29871153831481934 	 0.2994232177734375 	 0.2866098880767822 	 0.28560495376586914 	 0.2982470989227295 	 0.296128511428833 	 0.24642157554626465 	 0.22963976860046387 	 
2025-07-25 18:43:15.038244 test begin: paddle.negative(Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 1693441, 5],"float32"), ) 	 50803230 	 1000 	 0.2969512939453125 	 0.2978959083557129 	 0.28386735916137695 	 0.28554797172546387 	 0.296205997467041 	 0.2977936267852783 	 0.24528741836547852 	 0.23108649253845215 	 
2025-07-25 18:43:17.890192 test begin: paddle.negative(Tensor([2, 3, 3386881, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 3386881, 5],"float16"), ) 	 101606430 	 1000 	 0.29869604110717773 	 0.29633665084838867 	 0.2865171432495117 	 0.285550594329834 	 0.29825711250305176 	 0.29610323905944824 	 0.24757933616638184 	 0.22820639610290527 	 
2025-07-25 18:43:22.932879 test begin: paddle.negative(Tensor([2, 3, 4, 1058401],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 1058401],"float64"), ) 	 25401624 	 1000 	 0.29833197593688965 	 0.3015158176422119 	 0.2810389995574951 	 0.2875387668609619 	 0.29778623580932617 	 0.29828357696533203 	 0.24739885330200195 	 0.2306983470916748 	 
2025-07-25 18:43:25.214312 test begin: paddle.negative(Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 2116801],"float32"), ) 	 50803224 	 1000 	 0.2958707809448242 	 0.3107752799987793 	 0.28394317626953125 	 0.28739428520202637 	 0.29628634452819824 	 0.29772162437438965 	 0.24576520919799805 	 0.22768139839172363 	 
2025-07-25 18:43:30.034346 test begin: paddle.negative(Tensor([2, 3, 4, 4233601],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 4233601],"float16"), ) 	 101606424 	 1000 	 0.7589528560638428 	 1.653580665588379 	 0.2865619659423828 	 0.285569429397583 	 0.2982203960418701 	 0.2961616516113281 	 0.24759149551391602 	 0.22921109199523926 	 
2025-07-25 18:43:40.145860 test begin: paddle.negative(Tensor([2, 3, 846721, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 846721, 5],"float64"), ) 	 25401630 	 1000 	 0.3020157814025879 	 0.2982637882232666 	 0.2848358154296875 	 0.28102707862854004 	 0.2977876663208008 	 0.298292875289917 	 0.23782920837402344 	 0.22278761863708496 	 
2025-07-25 18:43:42.421765 test begin: paddle.negative(Tensor([2, 635041, 4, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 635041, 4, 5],"float64"), ) 	 25401640 	 1000 	 0.3114039897918701 	 0.3007700443267822 	 0.28643035888671875 	 0.2876873016357422 	 0.2977628707885742 	 0.29830360412597656 	 0.24639201164245605 	 0.2216792106628418 	 
2025-07-25 18:43:44.673785 test begin: paddle.negative(Tensor([423361, 3, 4, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([423361, 3, 4, 5],"float64"), ) 	 25401660 	 1000 	 0.2982907295227051 	 0.29833531379699707 	 0.2865908145904541 	 0.28751206398010254 	 0.297748327255249 	 0.29833459854125977 	 0.24771380424499512 	 0.23099184036254883 	 
2025-07-25 18:43:47.000107 test begin: paddle.negative(Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([846721, 3, 4, 5],"float32"), ) 	 50803260 	 1000 	 0.2958254814147949 	 0.29788875579833984 	 0.2837846279144287 	 0.2870755195617676 	 0.296234130859375 	 0.29778027534484863 	 0.2423868179321289 	 0.23119854927062988 	 
2025-07-25 18:43:49.848894 test begin: paddle.nextafter(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 0.4507145881652832 	 0.45246124267578125 	 0.44196248054504395 	 0.4377150535583496 	 None 	 None 	 None 	 None 	 
2025-07-25 18:43:52.410533 test begin: paddle.nextafter(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 0.45444369316101074 	 0.4517397880554199 	 0.43450021743774414 	 0.4314239025115967 	 None 	 None 	 None 	 None 	 
2025-07-25 18:43:55.064506 test begin: paddle.nextafter(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 0.4509541988372803 	 0.45182371139526367 	 0.44083428382873535 	 0.43774962425231934 	 None 	 None 	 None 	 None 	 
2025-07-25 18:43:57.726059 test begin: paddle.nextafter(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), )
W0725 18:43:58.572111 133909 dygraph_functions.cc:57914] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 0.6851248741149902 	 0.3877263069152832 	 0.3498959541320801 	 0.3764500617980957 	 None 	 None 	 None 	 None 	 
2025-07-25 18:43:59.735559 test begin: paddle.nextafter(Tensor([4, 3, 2116801],"float64"), Tensor([4, 3, 2116801],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 2116801],"float64"), Tensor([4, 3, 2116801],"float32"), ) 	 50803224 	 1000 	 0.6843981742858887 	 0.38380002975463867 	 0.349703311920166 	 0.3723301887512207 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:01.738344 test begin: paddle.nextafter(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), ) 	 101606424 	 1000 	 1.3641729354858398 	 0.7666246891021729 	 0.6965241432189941 	 0.7552366256713867 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:05.734522 test begin: paddle.nextafter(Tensor([4, 3, 4233601],"float64"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 4233601],"float64"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 1.3636753559112549 	 0.7587838172912598 	 0.6966986656188965 	 0.7475073337554932 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:09.802786 test begin: paddle.nextafter(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 0.6843931674957275 	 0.38788819313049316 	 0.34970903396606445 	 0.3739171028137207 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:11.830921 test begin: paddle.nextafter(Tensor([4, 3175201, 2],"float64"), Tensor([4, 3175201, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3175201, 2],"float64"), Tensor([4, 3175201, 2],"float32"), ) 	 50803216 	 1000 	 0.6839256286621094 	 0.3839099407196045 	 0.3495442867279053 	 0.372495174407959 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:13.877642 test begin: paddle.nextafter(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), ) 	 101606416 	 1000 	 1.3643090724945068 	 0.7708323001861572 	 0.6969592571258545 	 0.7551865577697754 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:17.922545 test begin: paddle.nextafter(Tensor([4, 6350401, 2],"float64"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 6350401, 2],"float64"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 1.3658952713012695 	 0.7589151859283447 	 0.6968858242034912 	 0.7446498870849609 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:22.048187 test begin: paddle.nextafter(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 0.6851816177368164 	 0.38774681091308594 	 0.34976720809936523 	 0.37629199028015137 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:24.086946 test begin: paddle.nextafter(Tensor([4233601, 3, 2],"float64"), Tensor([4233601, 3, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4233601, 3, 2],"float64"), Tensor([4233601, 3, 2],"float32"), ) 	 50803212 	 1000 	 0.6846392154693604 	 0.3955068588256836 	 0.3496823310852051 	 0.37195706367492676 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:26.172176 test begin: paddle.nextafter(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), ) 	 101606412 	 1000 	 1.3644838333129883 	 0.7667362689971924 	 0.6969444751739502 	 0.7552521228790283 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:30.186370 test begin: paddle.nextafter(Tensor([8467201, 3, 2],"float64"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([8467201, 3, 2],"float64"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 1.3636677265167236 	 1.4238214492797852 	 0.6969437599182129 	 0.741541862487793 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:38.090217 test begin: paddle.nextafter(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 0.4591944217681885 	 1.32657790184021 	 0.4353218078613281 	 0.4372270107269287 	 None 	 None 	 None 	 None 	 
2025-07-25 18:44:43.479046 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 1536, 267],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 1536, 267],"float32"), 1, None, ) 	 50853888 	 1000 	 0.30342888832092285 	 0.17531538009643555 	 0.25652384757995605 	 0.1568443775177002 	 0.837604284286499 	 0.1697978973388672 	 0.42791318893432617 	 0.07465481758117676 	 
2025-07-25 18:44:45.840786 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 8362, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 8362, 49],"float32"), 1, None, ) 	 50807512 	 1000 	 0.3545863628387451 	 0.37680578231811523 	 0.30660033226013184 	 0.35779738426208496 	 0.8634874820709229 	 0.17415738105773926 	 0.44115138053894043 	 0.08353185653686523 	 
2025-07-25 18:44:48.486797 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 1536, 259],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 1536, 259],"float32"), 1, None, ) 	 50921472 	 1000 	 0.2848625183105469 	 0.15382075309753418 	 0.23967361450195312 	 0.13548588752746582 	 0.8391754627227783 	 0.17021560668945312 	 0.4286797046661377 	 0.06679844856262207 	 
2025-07-25 18:44:50.780932 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 8101, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 8101, 49],"float32"), 1, None, ) 	 50809472 	 1000 	 0.3546621799468994 	 0.3768653869628906 	 0.3102610111236572 	 0.35854578018188477 	 0.8633170127868652 	 0.17423391342163086 	 0.44107985496520996 	 0.0743255615234375 	 
2025-07-25 18:44:53.396434 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([345, 1024, 144],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([345, 1024, 144],"float32"), 1, None, ) 	 50872320 	 1000 	 0.46778178215026855 	 0.21936488151550293 	 0.4136083126068115 	 0.20131564140319824 	 0.8467121124267578 	 0.17094731330871582 	 0.43259263038635254 	 0.05908370018005371 	 
2025-07-25 18:44:55.985843 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 1024, 776],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 1024, 776],"float32"), 1, None, ) 	 50855936 	 1000 	 0.1894068717956543 	 0.15408039093017578 	 0.1452016830444336 	 0.1359090805053711 	 0.8214340209960938 	 0.1715385913848877 	 0.41962409019470215 	 0.08059382438659668 	 
2025-07-25 18:44:58.179579 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 5513, 144],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 5513, 144],"float32"), 1, None, ) 	 50807808 	 1000 	 0.45766639709472656 	 0.2187786102294922 	 0.4106624126434326 	 0.2006547451019287 	 0.8455700874328613 	 0.17009758949279785 	 0.4319624900817871 	 0.07991433143615723 	 
2025-07-25 18:45:00.711457 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([676, 1536, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([676, 1536, 49],"float32"), 1, None, ) 	 50878464 	 1000 	 0.35510802268981934 	 0.377366304397583 	 0.3106496334075928 	 0.3588442802429199 	 0.8643665313720703 	 0.17449665069580078 	 0.441617488861084 	 0.08265376091003418 	 
2025-07-25 18:45:03.359563 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 2, 7],"float32"), output_size=1, ) 	 58404864 	 1000 	 0.30025744438171387 	 0.36417245864868164 	 0.2689635753631592 	 0.34297895431518555 	 1.021806001663208 	 0.22362756729125977 	 0.5220043659210205 	 0.14846539497375488 	 
2025-07-25 18:45:06.295300 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 7, 2],"float32"), output_size=1, ) 	 58404864 	 1000 	 0.30411624908447266 	 0.36408114433288574 	 0.26915669441223145 	 0.34435009956359863 	 1.0221283435821533 	 0.223602294921875 	 0.5222527980804443 	 0.14681363105773926 	 
2025-07-25 18:45:09.269729 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 509, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 509, 7, 7],"float32"), output_size=1, ) 	 50804817 	 1000 	 0.3544785976409912 	 0.37681055068969727 	 0.32388782501220703 	 0.3570225238800049 	 0.8636393547058105 	 0.17412447929382324 	 0.44125866889953613 	 0.09826374053955078 	 
2025-07-25 18:45:11.883559 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 2, 7],"float32"), output_size=1, ) 	 58634240 	 1000 	 0.30141496658325195 	 0.3675534725189209 	 0.27030086517333984 	 0.3459136486053467 	 1.0280272960662842 	 0.2245934009552002 	 0.5252659320831299 	 0.13767266273498535 	 
2025-07-25 18:45:14.815614 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 7, 2],"float32"), output_size=1, ) 	 58634240 	 1000 	 0.3013646602630615 	 0.36549854278564453 	 0.2694218158721924 	 0.34636998176574707 	 1.0280795097351074 	 0.22457504272460938 	 0.525275468826294 	 0.14055752754211426 	 
2025-07-25 18:45:17.734623 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 507, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 507, 7, 7],"float32"), output_size=1, ) 	 50803935 	 1000 	 0.35446643829345703 	 0.37677478790283203 	 0.32379913330078125 	 0.35733866691589355 	 0.8636300563812256 	 0.17410659790039062 	 0.44124603271484375 	 0.09826493263244629 	 
2025-07-25 18:45:20.378363 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 2, 7],"float32"), output_size=1, ) 	 58720256 	 1000 	 0.30178213119506836 	 0.36614108085632324 	 0.26996707916259766 	 0.34652137756347656 	 1.0269856452941895 	 0.2249433994293213 	 0.5247194766998291 	 0.15039515495300293 	 
2025-07-25 18:45:23.330452 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 7, 2],"float32"), output_size=1, ) 	 58720256 	 1000 	 0.3012657165527344 	 0.3692135810852051 	 0.26883459091186523 	 0.3466324806213379 	 1.0270512104034424 	 0.22492408752441406 	 0.5247640609741211 	 0.14873313903808594 	 
2025-07-25 18:45:26.267995 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 507, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 507, 7, 7],"float32"), output_size=1, ) 	 50878464 	 1000 	 0.35479021072387695 	 0.3773336410522461 	 0.32309961318969727 	 0.3581123352050781 	 0.8636150360107422 	 0.17435693740844727 	 0.4412357807159424 	 0.10119128227233887 	 
2025-07-25 18:45:28.889868 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([507, 2048, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([507, 2048, 7, 7],"float32"), output_size=1, ) 	 50878464 	 1000 	 0.3548128604888916 	 0.3773341178894043 	 0.3238987922668457 	 0.3579888343811035 	 0.8635909557342529 	 0.17435526847839355 	 0.4412233829498291 	 0.10043978691101074 	 
2025-07-25 18:45:31.522485 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 45361, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 45361, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804320 	 1000 	 0.8953444957733154 	 0.1490929126739502 	 0.8698341846466064 	 0.1185150146484375 	 2.2279911041259766 	 0.1730334758758545 	 1.1384272575378418 	 0.09099483489990234 	 
2025-07-25 18:45:36.926556 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804208 	 1000 	 0.505211353302002 	 0.15134549140930176 	 0.48021674156188965 	 0.12981295585632324 	 2.2616934776306152 	 0.17255425453186035 	 1.1556222438812256 	 0.09677505493164062 	 
2025-07-25 18:45:41.379191 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804208 	 1000 	 0.5449995994567871 	 0.15140748023986816 	 0.51985764503479 	 0.12918424606323242 	 2.2611875534057617 	 0.1725022792816162 	 1.1554410457611084 	 0.09765625 	 
2025-07-25 18:45:45.952929 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50851584 	 1000 	 16.003947973251343 	 0.1505906581878662 	 15.979253053665161 	 0.12873220443725586 	 2.2604894638061523 	 0.16528010368347168 	 1.155022144317627 	 0.09027576446533203 	 
2025-07-25 18:46:05.443993 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50851584 	 1000 	 19.330390214920044 	 0.15053153038024902 	 19.30548858642578 	 0.12573480606079102 	 2.2606945037841797 	 0.16524052619934082 	 1.1551063060760498 	 0.0845041275024414 	 
2025-07-25 18:46:28.243543 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 414, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 414, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.3157160282135 	 0.1498425006866455 	 39.29057717323303 	 0.11738848686218262 	 2.219665765762329 	 0.1653423309326172 	 1.134218692779541 	 0.08421754837036133 	 
2025-07-25 18:47:10.997510 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 460, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 460, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.181838035583496 	 0.14982104301452637 	 39.15691518783569 	 0.12796831130981445 	 2.2196996212005615 	 0.1655128002166748 	 1.1342179775238037 	 0.09064483642578125 	 
2025-07-25 18:47:55.859138 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 591, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 591, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50835456 	 1000 	 24.427851676940918 	 0.14992904663085938 	 24.402369022369385 	 0.12749767303466797 	 2.2177414894104004 	 0.16525816917419434 	 1.1330914497375488 	 0.08493280410766602 	 
2025-07-25 18:48:23.721861 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 591],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 591],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50835456 	 1000 	 23.196462154388428 	 0.14992308616638184 	 23.1713809967041 	 0.12782597541809082 	 2.1589741706848145 	 0.16537141799926758 	 1.1031126976013184 	 0.08991765975952148 	 
2025-07-25 18:48:50.309278 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 9, 460],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 9, 460],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.06862020492554 	 0.1497652530670166 	 39.042261362075806 	 0.12800049781799316 	 2.1599085330963135 	 0.16539978981018066 	 1.103579044342041 	 0.0803074836730957 	 
2025-07-25 18:49:32.772873 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 946, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 946, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50856960 	 1000 	 17.35368037223816 	 0.14979314804077148 	 17.327765941619873 	 0.12786459922790527 	 2.2206032276153564 	 0.16539621353149414 	 1.1346619129180908 	 0.08789634704589844 	 
2025-07-25 18:49:53.580893 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([60, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([60, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51609600 	 1000 	 0.8955333232879639 	 0.15121817588806152 	 0.8702709674835205 	 0.12953639030456543 	 2.263441324234009 	 0.1754288673400879 	 1.1564967632293701 	 0.10021424293518066 	 
2025-07-25 18:49:57.966536 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51093504 	 1000 	 0.5072758197784424 	 0.1520833969116211 	 0.4822835922241211 	 0.13027215003967285 	 2.2747559547424316 	 0.17351818084716797 	 1.1623728275299072 	 0.09868693351745605 	 
2025-07-25 18:50:01.908065 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51093504 	 1000 	 0.547947883605957 	 0.15214824676513672 	 0.5227813720703125 	 0.13028669357299805 	 2.273716688156128 	 0.17354393005371094 	 1.1617381572723389 	 0.09367990493774414 	 
2025-07-25 18:50:07.375758 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 3175201],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
W0725 18:50:08.529922 137934 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 3175201],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 50805392 	 1000 	 12.619372129440308 	 8.113693237304688 	 0.00946044921875 	 0.006616115570068359 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:49.752590 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([25401601, 16],"float32"), Tensor([25401601],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([25401601, 16],"float32"), Tensor([25401601],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 431827345 	 1000 	 49.84930205345154 	 20.968599557876587 	 0.0072591304779052734 	 0.005532503128051758 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:46.555130 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([3175201, 16],"float32"), Tensor([3175201],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([3175201, 16],"float32"), Tensor([3175201],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 53978545 	 1000 	 6.73673415184021 	 3.153602123260498 	 0.0008065700531005859 	 0.00063323974609375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:53:02.333268 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([8, 8],"float32"), Tensor([8],"int64"), Tensor([8, 6350401],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, )
[Error] (InvalidArgument) The insert dimension value should not be larger than the dimension size of input tensor
  [Hint: Expected cur <= cur_output_rank, but received cur:1 > cur_output_rank:0.] (at ../paddle/phi/kernels/funcs/unsqueeze.h:128)

[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:53:07.995891 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 4233601],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 4233601],"float64"), 8, False, None, ) 	 25401606 	 1000 	 62.28071737289429 	 62.75534272193909 	 62.25665354728699 	 62.7329638004303 	 0.4498147964477539 	 0.13812017440795898 	 0.22970342636108398 	 0.04718017578125 	 
2025-07-25 18:55:14.337672 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), 16, False, None, ) 	 50803206 	 1000 	 48.73285984992981 	 42.08521270751953 	 48.708436012268066 	 42.062705278396606 	 0.7595727443695068 	 0.13832497596740723 	 0.38803744316101074 	 0.04644179344177246 	 
2025-07-25 18:56:47.062427 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), output_size=16, ) 	 50803206 	 1000 	 48.732584714889526 	 42.08511233329773 	 48.70810627937317 	 42.06229543685913 	 0.7598135471343994 	 0.13741636276245117 	 0.38815903663635254 	 0.04667353630065918 	 
2025-07-25 18:58:21.427144 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 396901, 32],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 396901, 32],"float64"), 8, False, None, ) 	 25401664 	 1000 	 0.2111647129058838 	 0.858161449432373 	 0.1843574047088623 	 0.8350059986114502 	 0.5200269222259521 	 0.7767624855041504 	 0.2656550407409668 	 0.39684414863586426 	 
2025-07-25 18:58:24.472396 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), 16, False, None, ) 	 50803264 	 1000 	 0.4088401794433594 	 1.7011003494262695 	 0.38406872749328613 	 1.6752753257751465 	 0.8851323127746582 	 1.410522222518921 	 0.45216846466064453 	 0.7206916809082031 	 
2025-07-25 18:58:30.126700 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), output_size=16, ) 	 50803264 	 1000 	 0.4110569953918457 	 1.6984972953796387 	 0.3838155269622803 	 1.6760478019714355 	 0.8850319385528564 	 1.4105618000030518 	 0.4521663188934326 	 0.720689058303833 	 
2025-07-25 18:58:37.565655 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([264601, 3, 32],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([264601, 3, 32],"float64"), 8, False, None, ) 	 25401696 	 1000 	 0.2209606170654297 	 3.416381597518921 	 0.18317484855651855 	 3.3725292682647705 	 0.524385929107666 	 3.3267831802368164 	 0.2678816318511963 	 1.6998755931854248 	 
2025-07-25 18:58:47.473814 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), 16, False, None, ) 	 50803296 	 1000 	 0.408872127532959 	 6.801756381988525 	 0.3840761184692383 	 6.773414611816406 	 0.8849844932556152 	 6.716688632965088 	 0.4521293640136719 	 3.532437324523926 	 
2025-07-25 18:59:04.460835 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), output_size=16, ) 	 50803296 	 1000 	 0.40886855125427246 	 6.799018383026123 	 0.38373374938964844 	 6.775846481323242 	 0.8850579261779785 	 6.5111634731292725 	 0.4521915912628174 	 3.3270914554595947 	 
2025-07-25 18:59:20.343337 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 1209601, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 1209601, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803242 	 1000 	 327.7650525569916 	 136.34026169776917 	 327.75203108787537 	 136.321768283844 	 0.7819862365722656 	 0.1375877857208252 	 0.3995027542114258 	 0.04558277130126953 	 
2025-07-25 19:07:06.845537 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803242 	 1000 	 114.44645977020264 	 56.62638235092163 	 114.43355011940002 	 56.60087180137634 	 0.8056280612945557 	 0.13753652572631836 	 0.4116215705871582 	 0.052561283111572266 	 
2025-07-25 19:10:00.831658 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 	 50803242 	 1000 	 176.06844806671143 	 79.4198808670044 	 176.04817152023315 	 79.39985799789429 	 0.7733209133148193 	 0.13732647895812988 	 0.3950350284576416 	 0.05876445770263672 	 
2025-07-25 19:14:18.362716 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 	 50803242 	 1000 	 221.90101313591003 	 95.78295540809631 	 221.88077855110168 	 95.75501561164856 	 0.7838163375854492 	 0.13736271858215332 	 0.4004249572753906 	 0.05049443244934082 	 
2025-07-25 19:19:40.360625 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803298 	 1000 	 0.5871436595916748 	 4.678541421890259 	 0.5687804222106934 	 4.6602606773376465 	 1.0901622772216797 	 1.1768674850463867 	 0.5570681095123291 	 0.6020030975341797 	 
2025-07-25 19:19:49.232226 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 	 50803298 	 1000 	 0.43830132484436035 	 2.6309759616851807 	 0.4255242347717285 	 2.610295295715332 	 1.013152837753296 	 0.9685266017913818 	 0.5176348686218262 	 0.49482107162475586 	 
2025-07-25 19:19:57.128287 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 	 50803298 	 1000 	 1.1404194831848145 	 3.274723529815674 	 0.36739230155944824 	 3.2544031143188477 	 1.0354804992675781 	 0.9991989135742188 	 0.528348445892334 	 0.5098328590393066 	 
2025-07-25 19:20:05.714703 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803690 	 1000 	 1.9664433002471924 	 10.27608060836792 	 1.942427396774292 	 0.6559183597564697 	 1.2627174854278564 	 1.4863886833190918 	 0.6459000110626221 	 0.08929061889648438 	 
2025-07-25 19:20:22.021245 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803690 	 1000 	 1.5644707679748535 	 5.53778600692749 	 1.5437769889831543 	 0.8076703548431396 	 0.47484397888183594 	 0.5943052768707275 	 0.2426140308380127 	 0.0758509635925293 	 
2025-07-25 19:20:31.164895 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803690 	 1000 	 1.917334794998169 	 6.857248306274414 	 1.8951387405395508 	 0.7005641460418701 	 0.5779240131378174 	 0.8094649314880371 	 0.29517340660095215 	 0.07513618469238281 	 
2025-07-25 19:20:42.310940 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803494 	 1000 	 30.395109176635742 	 39.884594678878784 	 30.382240056991577 	 39.86725091934204 	 0.15232467651367188 	 0.13775181770324707 	 0.07771492004394531 	 0.05745267868041992 	 
2025-07-25 19:21:54.807921 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803494 	 1000 	 103.040283203125 	 135.79837465286255 	 103.02742505073547 	 135.77839469909668 	 0.15254545211791992 	 0.137542724609375 	 0.0778191089630127 	 0.0649268627166748 	 
2025-07-25 19:25:56.177088 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803494 	 1000 	 72.06316828727722 	 91.093834400177 	 72.05046081542969 	 91.07376194000244 	 0.15231108665466309 	 0.13764023780822754 	 0.07778644561767578 	 0.06546640396118164 	 
2025-07-25 19:28:40.727733 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803410 	 1000 	 23.826478004455566 	 29.975327730178833 	 23.81349468231201 	 29.958032608032227 	 0.15238070487976074 	 0.13772988319396973 	 0.07780981063842773 	 0.06499123573303223 	 
2025-07-25 19:29:37.657251 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803410 	 1000 	 106.2180655002594 	 136.9556884765625 	 106.20517182350159 	 136.93567824363708 	 0.15253996849060059 	 0.1375110149383545 	 0.0779118537902832 	 0.0648951530456543 	 
2025-07-25 19:33:42.279635 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803410 	 1000 	 108.92333698272705 	 133.5343325138092 	 108.91031551361084 	 133.51420736312866 	 0.1522073745727539 	 0.13754487037658691 	 0.07770347595214844 	 0.06582021713256836 	 
2025-07-25 19:37:46.130302 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803410 	 1000 	 10.160953521728516 	 11.898257970809937 	 10.147931814193726 	 11.872620105743408 	 0.1537325382232666 	 0.1376051902770996 	 0.07786774635314941 	 0.05359148979187012 	 
2025-07-25 19:38:09.406038 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803410 	 1000 	 31.445717096328735 	 36.09276604652405 	 31.432828187942505 	 36.07275342941284 	 0.15263986587524414 	 0.13770031929016113 	 0.0779111385345459 	 0.06582403182983398 	 
2025-07-25 19:39:18.180209 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803410 	 1000 	 48.468496322631836 	 58.629175662994385 	 48.45555853843689 	 58.60903882980347 	 0.15415191650390625 	 0.13778471946716309 	 0.07804274559020996 	 0.06575226783752441 	 
2025-07-25 19:41:07.563797 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803935 	 1000 	 1.9750432968139648 	 10.283857822418213 	 1.9524571895599365 	 0.6571288108825684 	 1.2623720169067383 	 1.4871621131896973 	 0.6442101001739502 	 0.08921289443969727 	 
2025-07-25 19:41:25.666520 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803935 	 1000 	 1.5650584697723389 	 5.551925420761108 	 1.5504577159881592 	 0.8082737922668457 	 0.47676563262939453 	 0.5938053131103516 	 0.2442934513092041 	 0.07576489448547363 	 
2025-07-25 19:41:34.815986 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803935 	 1000 	 2.7996323108673096 	 6.874727487564087 	 1.8944118022918701 	 0.6998355388641357 	 0.5775136947631836 	 0.8090505599975586 	 0.2949867248535156 	 0.07509040832519531 	 
2025-07-25 19:41:47.702650 test begin: paddle.nn.functional.avg_pool1d(Tensor([13, 1, 3907939],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([13, 1, 3907939],"float32"), 25, 1, 0, True, False, None, ) 	 50803207 	 1000 	 36.73354935646057 	 1.5879096984863281 	 36.69904851913452 	 1.566157579421997 	 45.77577877044678 	 3.72957706451416 	 45.69597864151001 	 3.636282205581665 	 
2025-07-25 19:43:17.381019 test begin: paddle.nn.functional.avg_pool1d(Tensor([13, 32567, 120],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([13, 32567, 120],"float32"), 25, 1, 0, True, False, None, ) 	 50804520 	 1000 	 7.491312742233276 	 1.3924129009246826 	 7.456987142562866 	 1.3646128177642822 	 11.477688550949097 	 3.8450510501861572 	 11.395453929901123 	 3.758082628250122 	 
2025-07-25 19:43:44.236997 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 1, 3175201],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 1, 3175201],"float32"), 25, 1, 0, True, False, None, ) 	 50803216 	 1000 	 36.72861838340759 	 1.5840167999267578 	 36.6929976940155 	 1.564469337463379 	 45.780290603637695 	 3.7273645401000977 	 45.70050239562988 	 3.641247034072876 	 
2025-07-25 19:45:13.965469 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 2, 1587601],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 2, 1587601],"float32"), 25, 1, 0, True, False, None, ) 	 50803232 	 1000 	 18.44805097579956 	 1.578502893447876 	 18.41362762451172 	 1.5627660751342773 	 22.912558794021606 	 3.7276928424835205 	 22.8329439163208 	 3.642266035079956 	 
2025-07-25 19:46:02.565207 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 26461, 120],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 26461, 120],"float32"), 25, 1, 0, True, False, None, ) 	 50805120 	 1000 	 7.493402004241943 	 1.3854949474334717 	 7.459181785583496 	 1.3581311702728271 	 11.406312227249146 	 3.8480491638183594 	 11.326866388320923 	 3.746309757232666 	 
2025-07-25 19:46:29.460080 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 127, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 127, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50978816 	 1000 	 0.19527959823608398 	 0.4158642292022705 	 0.17489981651306152 	 0.40411853790283203 	 0.35314249992370605 	 1.5701324939727783 	 0.29273438453674316 	 1.4921793937683105 	 
2025-07-25 19:46:33.040895 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 256, 28, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 256, 28, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.20046591758728027 	 0.41925477981567383 	 0.1792621612548828 	 0.3987884521484375 	 0.3332407474517822 	 1.574425458908081 	 0.27282094955444336 	 1.4782063961029053 	 
2025-07-25 19:46:38.460581 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 256, 56, 28],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 256, 56, 28],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.21364593505859375 	 0.44748616218566895 	 0.17972564697265625 	 0.4017765522003174 	 0.33602333068847656 	 1.578932523727417 	 0.2652006149291992 	 1.4990754127502441 	 
2025-07-25 19:46:42.275140 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 128, 256, 97],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 128, 256, 97],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50855936 	 1000 	 0.19270658493041992 	 0.40907835960388184 	 0.1620635986328125 	 0.3908219337463379 	 0.3303401470184326 	 1.563338041305542 	 0.2575099468231201 	 1.4884984493255615 	 
2025-07-25 19:46:45.924648 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 128, 97, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 128, 97, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50855936 	 1000 	 0.19051599502563477 	 0.4051203727722168 	 0.16002368927001953 	 0.38692808151245117 	 0.3288435935974121 	 1.5479202270507812 	 0.2587859630584717 	 1.4605934619903564 	 
2025-07-25 19:46:49.436507 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 49, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 49, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.20273566246032715 	 0.41802024841308594 	 0.16759467124938965 	 0.3949737548828125 	 0.3546583652496338 	 1.5640642642974854 	 0.28382158279418945 	 1.4901299476623535 	 
2025-07-25 19:46:53.077553 test begin: paddle.nn.functional.avg_pool2d(Tensor([4, 256, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([4, 256, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 58982400 	 1000 	 0.22458672523498535 	 0.4806854724884033 	 0.2038123607635498 	 0.46793508529663086 	 0.38219404220581055 	 1.8057031631469727 	 0.32186126708984375 	 1.7398576736450195 	 
2025-07-25 19:46:57.229122 test begin: paddle.nn.functional.avg_pool2d(Tensor([64, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([64, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.2007908821105957 	 0.43018317222595215 	 0.17619752883911133 	 0.4086625576019287 	 0.35315513610839844 	 1.5819108486175537 	 0.29237914085388184 	 1.5153985023498535 	 
2025-07-25 19:47:00.850976 test begin: paddle.nn.functional.avg_pool2d(Tensor([7, 128, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([7, 128, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 58720256 	 1000 	 0.22170329093933105 	 0.4715149402618408 	 0.1985182762145996 	 0.45959019660949707 	 0.38205456733703613 	 1.792264461517334 	 0.3206307888031006 	 1.7238552570343018 	 
2025-07-25 19:47:04.966342 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 111, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 111, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51148800 	 1000 	 0.1951463222503662 	 0.4158976078033447 	 0.17506885528564453 	 0.40419769287109375 	 0.3350715637207031 	 1.567992925643921 	 0.2747044563293457 	 1.4952263832092285 	 
2025-07-25 19:47:08.579153 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 256, 104, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 256, 104, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51118080 	 1000 	 0.1951594352722168 	 0.41569948196411133 	 0.17510700225830078 	 0.403989315032959 	 0.3333878517150879 	 1.5647647380828857 	 0.2727053165435791 	 1.4978790283203125 	 
2025-07-25 19:47:12.138838 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 256, 240, 104],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 256, 240, 104],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51118080 	 1000 	 0.19510889053344727 	 0.43544936180114746 	 0.17397451400756836 	 0.40570998191833496 	 0.3337991237640381 	 1.5688977241516113 	 0.27362871170043945 	 1.4982905387878418 	 
2025-07-25 19:47:15.723171 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 776, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(Tensor([2, 776, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", ) 	 50855936 	 1000 	 0.1766037940979004 	 0.4264836311340332 	 0.15775609016418457 	 0.4076571464538574 	 0.42415547370910645 	 0.49938249588012695 	 0.3634347915649414 	 0.2543904781341553 	 
2025-07-25 19:47:18.205151 test begin: paddle.nn.functional.avg_pool3d(Tensor([517, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(Tensor([517, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", ) 	 50823168 	 1000 	 0.1782665252685547 	 0.42209410667419434 	 0.15952610969543457 	 0.40811920166015625 	 0.5568161010742188 	 0.4976229667663574 	 0.49532103538513184 	 0.2541954517364502 	 
2025-07-25 19:47:20.798729 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([127, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([127, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50978816 	 1000 	 0.24047541618347168 	 2.245039939880371 	 0.20781421661376953 	 0.5728955268859863 	 3.141984224319458 	 2.890822172164917 	 3.068204164505005 	 0.17356109619140625 	 
2025-07-25 19:47:31.832714 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([127, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([127, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50978816 	 1000 	 0.2616000175476074 	 1.986985445022583 	 0.22975659370422363 	 1.9735734462738037 	 2.8895442485809326 	 2.8769543170928955 	 2.8182239532470703 	 0.17252802848815918 	 
2025-07-25 19:47:42.071825 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 111, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 111, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.34059977531433105 	 10.939419031143188 	 0.317929744720459 	 10.926019191741943 	 4.4349963665008545 	 4.756128787994385 	 4.373564004898071 	 1.621614694595337 	 
2025-07-25 19:48:03.440352 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 111],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 111],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.3846766948699951 	 0.7715137004852295 	 0.36152029037475586 	 0.7581322193145752 	 3.0766069889068604 	 0.9815146923065186 	 3.0152907371520996 	 0.33541083335876465 	 
2025-07-25 19:48:09.545303 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 64, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 64, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 51380224 	 1000 	 0.31818079948425293 	 7.9069743156433105 	 0.295346736907959 	 0.5057113170623779 	 4.291062593460083 	 4.356702089309692 	 4.229701995849609 	 0.2484602928161621 	 
2025-07-25 19:48:27.448944 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 111, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 111, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.35856056213378906 	 10.57200026512146 	 0.33554649353027344 	 10.55695390701294 	 4.426767110824585 	 4.74919319152832 	 4.365310430526733 	 1.6207020282745361 	 
2025-07-25 19:48:49.458399 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 111],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 111],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.4144458770751953 	 0.9868221282958984 	 0.3916893005371094 	 0.9702785015106201 	 3.066220998764038 	 0.9591207504272461 	 3.0037941932678223 	 0.326885461807251 	 
2025-07-25 19:48:55.819046 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 507, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 507, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50878464 	 1000 	 2.217142105102539 	 50.5217981338501 	 2.194378137588501 	 3.4428560733795166 	 15.1167893409729 	 17.59581470489502 	 15.05119276046753 	 1.0575575828552246 	 
2025-07-25 19:50:22.264396 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 32401, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 32401, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50804768 	 1000 	 0.2394256591796875 	 2.2378907203674316 	 0.21675825119018555 	 0.5724921226501465 	 3.1329500675201416 	 2.8822598457336426 	 3.071770191192627 	 0.17299365997314453 	 
2025-07-25 19:50:31.759636 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 4051, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 4051, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50815744 	 1000 	 0.26727819442749023 	 1.981863260269165 	 0.24408555030822754 	 1.9680862426757812 	 2.881099224090576 	 2.8682851791381836 	 2.817822217941284 	 0.17199015617370605 	 
2025-07-25 19:50:42.159955 test begin: paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50823388 	 1000 	 0.3765387535095215 	 0.3791673183441162 	 0.35787391662597656 	 0.3471038341522217 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 40, 50, 847]) and output[0] has a shape of torch.Size([30, 847, 40, 50]).
2025-07-25 19:50:51.038242 test begin: paddle.nn.functional.batch_norm(Tensor([30, 40, 706, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 40, 706, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50832240 	 1000 	 0.3729979991912842 	 0.3815634250640869 	 0.3535449504852295 	 0.3465754985809326 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 40, 706, 60]) and output[0] has a shape of torch.Size([30, 60, 40, 706]).
2025-07-25 19:50:57.097388 test begin: paddle.nn.functional.batch_norm(Tensor([30, 565, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 565, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50850240 	 1000 	 0.3817918300628662 	 0.37877821922302246 	 0.36098384857177734 	 0.34915828704833984 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 565, 50, 60]) and output[0] has a shape of torch.Size([30, 60, 565, 50]).
2025-07-25 19:51:03.346145 test begin: paddle.nn.functional.batch_norm(Tensor([424, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([424, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50880240 	 1000 	 0.34319233894348145 	 0.5925133228302002 	 0.32448649406433105 	 0.3154292106628418 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([424, 40, 50, 60]) and output[0] has a shape of torch.Size([424, 60, 40, 50]).
2025-07-25 19:51:10.608935 test begin: paddle.nn.functional.bilinear(Tensor([25401601, 1],"float32"), Tensor([25401601, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([25401601, 1],"float32"), Tensor([25401601, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, ) 	 76204815 	 1000 	 15.04512906074524 	 118.44713163375854 	 0.14784455299377441 	 0.07281637191772461 	 30.263272285461426 	 125.11907005310059 	 0.24940896034240723 	 0.07887673377990723 	 
2025-07-25 19:56:02.869350 test begin: paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 12700801],"float32"), Tensor([4, 1, 12700801],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 12700801],"float32"), Tensor([4, 1, 12700801],"float32"), Tensor([1, 4],"float32"), None, ) 	 88905614 	 1000 	 3.3980486392974854 	 45.75655221939087 	 0.05335354804992676 	 0.7539596557617188 	 6.6864001750946045 	 49.81177568435669 	 0.09088540077209473 	 0.5515103340148926 	 
2025-07-25 19:57:51.402830 test begin: paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 16934401],"float32"), Tensor([4, 1, 16934401],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 16934401],"float32"), Tensor([4, 1, 16934401],"float32"), Tensor([1, 4],"float32"), None, ) 	 118540814 	 1000 	 4.5604331493377686 	 60.60485649108887 	 0.05750703811645508 	 0.8015143871307373 	 8.79534649848938 	 65.79879641532898 	 0.09804248809814453 	 0.6002297401428223 	 
2025-07-25 20:00:13.464929 test begin: paddle.nn.functional.bilinear(Tensor([5, 5],"float32"), Tensor([5, 10161],"float32"), Tensor([1000, 5, 10161],"float32"), Tensor([1, 1000],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([5, 5],"float32"), Tensor([5, 10161],"float32"), Tensor([1000, 5, 10161],"float32"), Tensor([1, 1000],"float32"), None, ) 	 50856830 	 1000 	 30.858777284622192 	 50.238847494125366 	 0.007853984832763672 	 0.0002894401550292969 	 38.78841018676758 	 114.95135855674744 	 0.006524562835693359 	 0.0002498626708984375 	 
2025-07-25 20:04:09.418168 test begin: paddle.nn.functional.bilinear(Tensor([50803201, 1],"float32"), Tensor([50803201, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([50803201, 1],"float32"), Tensor([50803201, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, ) 	 152409615 	 1000 	 30.00813889503479 	 236.81284761428833 	 0.15495705604553223 	 0.07416486740112305 	 60.314016342163086 	 249.84302520751953 	 0.2803523540496826 	 0.09019231796264648 	 
2025-07-25 20:13:53.356015 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"float32"), weight=Tensor([16, 10164, 313],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"float32"), weight=Tensor([16, 10164, 313],"float32"), reduction="sum", ) 	 152703936 	 1000 	 1.0482428073883057 	 1.0575921535491943 	 0.2674880027770996 	 0.2167057991027832 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:13:59.856938 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"float32"), weight=Tensor([16, 11109, 286],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"float32"), weight=Tensor([16, 11109, 286],"float32"), reduction="sum", ) 	 152504352 	 1000 	 1.049546480178833 	 1.0539007186889648 	 0.26711297035217285 	 0.21508049964904785 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:06.309144 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"float32"), weight=Tensor([16, 12096, 263],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"float32"), weight=Tensor([16, 12096, 263],"float32"), reduction="sum", ) 	 152699904 	 1000 	 1.051128625869751 	 1.0552656650543213 	 0.26751041412353516 	 0.2153787612915039 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:12.935107 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="sum", ) 	 152413440 	 1000 	 1.0474753379821777 	 1.0546824932098389 	 0.266995906829834 	 0.21499300003051758 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:19.554315 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([53, 12096, 80],"float32"), Tensor([53, 12096, 80],"float32"), weight=Tensor([53, 12096, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([53, 12096, 80],"float32"), Tensor([53, 12096, 80],"float32"), weight=Tensor([53, 12096, 80],"float32"), reduction="sum", ) 	 153861120 	 1000 	 1.0603504180908203 	 1.0671396255493164 	 0.27098798751831055 	 0.2169482707977295 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:25.966584 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([58, 11109, 80],"float32"), Tensor([58, 11109, 80],"float32"), weight=Tensor([58, 11109, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([58, 11109, 80],"float32"), Tensor([58, 11109, 80],"float32"), weight=Tensor([58, 11109, 80],"float32"), reduction="sum", ) 	 154637280 	 1000 	 1.0617659091949463 	 1.074106216430664 	 0.27092409133911133 	 0.21794581413269043 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:32.579511 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([63, 10164, 80],"float32"), Tensor([63, 10164, 80],"float32"), weight=Tensor([63, 10164, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([63, 10164, 80],"float32"), Tensor([63, 10164, 80],"float32"), weight=Tensor([63, 10164, 80],"float32"), reduction="sum", ) 	 153679680 	 1000 	 1.055314540863037 	 1.0763587951660156 	 0.26932501792907715 	 0.21674466133117676 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:41.207789 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 300, 10585],"float32"), Tensor([16, 300, 10585],"float32"), weight=Tensor([16, 300, 10585],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 300, 10585],"float32"), Tensor([16, 300, 10585],"float32"), weight=Tensor([16, 300, 10585],"float32"), reduction="none", ) 	 152424000 	 1000 	 1.040226697921753 	 2.214329481124878 	 0.3555338382720947 	 0.37748098373413086 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:50.882936 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="none", ) 	 152413440 	 1000 	 1.0435948371887207 	 2.2171099185943604 	 0.3555166721343994 	 0.3785362243652344 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:14:59.631275 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2117, 300, 80],"float32"), Tensor([2117, 300, 80],"float32"), weight=Tensor([2117, 300, 80],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2117, 300, 80],"float32"), Tensor([2117, 300, 80],"float32"), weight=Tensor([2117, 300, 80],"float32"), reduction="none", ) 	 152424000 	 1000 	 1.0385146141052246 	 2.2290050983428955 	 0.35398316383361816 	 0.3772423267364502 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:15:08.131468 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), weight=Tensor([300, 169345],"float32"), reduction="none", pos_weight=None, )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), weight=Tensor([300, 169345],"float32"), reduction="none", pos_weight=None, ) 	 152410500 	 1000 	 1.0382001399993896 	 2.2164182662963867 	 0.3539280891418457 	 0.3772156238555908 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:15:16.899681 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([50804, 1000],"float32"), Tensor([50804, 1000],"float32"), weight=Tensor([50804, 1000],"float32"), reduction="none", pos_weight=None, )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([50804, 1000],"float32"), Tensor([50804, 1000],"float32"), weight=Tensor([50804, 1000],"float32"), reduction="none", pos_weight=None, ) 	 152412000 	 1000 	 1.03961181640625 	 2.2166407108306885 	 0.3539609909057617 	 0.3772146701812744 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:15:25.690956 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 28, 3544],"float32"), Tensor([512, 28, 3544],"float32"), weight=Tensor([512, 1, 3544],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 28, 3544],"float32"), Tensor([512, 28, 3544],"float32"), weight=Tensor([512, 1, 3544],"float32"), reduction="mean", ) 	 103428096 	 1000 	 1.0418212413787842 	 2.2452313899993896 	 0.2126326560974121 	 0.28638362884521484 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:15:32.430034 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 3544, 28],"float32"), Tensor([512, 3544, 28],"float32"), weight=Tensor([512, 3544, 1],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 3544, 28],"float32"), Tensor([512, 3544, 28],"float32"), weight=Tensor([512, 3544, 1],"float32"), reduction="mean", ) 	 103428096 	 1000 	 1.0449020862579346 	 2.236264944076538 	 0.2127218246459961 	 0.28580284118652344 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:15:40.049093 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), weight=Tensor([64801, 1, 1],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), weight=Tensor([64801, 1, 1],"float32"), reduction="mean", ) 	 101672769 	 1000 	 1.0374705791473389 	 2.2352633476257324 	 0.21157431602478027 	 0.28650736808776855 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 20:15:46.921547 test begin: paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 0.2, None, ) 	 25401616 	 1000 	 0.30833888053894043 	 0.30727314949035645 	 0.29119443893432617 	 0.2874600887298584 	 0.44809412956237793 	 0.4494931697845459 	 0.3854234218597412 	 0.37900233268737793 	 
2025-07-25 20:15:49.570335 test begin: paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 1.0, None, ) 	 25401616 	 1000 	 0.31330323219299316 	 0.30911946296691895 	 0.2985260486602783 	 0.2791709899902344 	 0.4480407238006592 	 0.4520730972290039 	 0.39560842514038086 	 0.3856546878814697 	 
2025-07-25 20:15:52.236429 test begin: paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 0.2, None, ) 	 25401608 	 1000 	 0.307114839553833 	 0.30635595321655273 	 0.29137754440307617 	 0.28798770904541016 	 0.44803404808044434 	 0.4494593143463135 	 0.395658016204834 	 0.38204121589660645 	 
2025-07-25 20:15:56.220929 test begin: paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 1.0, None, ) 	 25401608 	 1000 	 0.3089728355407715 	 0.30976247787475586 	 0.29920053482055664 	 0.28704380989074707 	 0.448131799697876 	 0.449507474899292 	 0.3947582244873047 	 0.3592708110809326 	 
2025-07-25 20:16:00.328689 test begin: paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 0.2, None, ) 	 25401608 	 1000 	 0.307145357131958 	 0.3194706439971924 	 0.29821085929870605 	 0.2872600555419922 	 0.4492945671081543 	 0.44947361946105957 	 0.3964695930480957 	 0.3615257740020752 	 
2025-07-25 20:16:02.878916 test begin: paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 1.0, None, ) 	 25401608 	 1000 	 0.3070836067199707 	 0.3050804138183594 	 0.2984890937805176 	 0.2882544994354248 	 0.4493846893310547 	 0.4507472515106201 	 0.39610815048217773 	 0.38377881050109863 	 
2025-07-25 20:16:05.458279 test begin: paddle.nn.functional.celu(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.30819129943847656 	 0.30403685569763184 	 0.2899806499481201 	 0.2874486446380615 	 0.4480767250061035 	 0.4499027729034424 	 0.39496660232543945 	 0.361858606338501 	 
2025-07-25 20:16:08.258811 test begin: paddle.nn.functional.celu(x=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([2, 3175201, 4],"float64"), ) 	 25401608 	 1000 	 0.31012964248657227 	 0.31059932708740234 	 0.29961538314819336 	 0.28758907318115234 	 0.4493680000305176 	 0.4494302272796631 	 0.3968226909637451 	 0.3818075656890869 	 
2025-07-25 20:16:10.957667 test begin: paddle.nn.functional.celu(x=Tensor([2, 4, 3175201],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([2, 4, 3175201],"float64"), ) 	 25401608 	 1000 	 0.30707645416259766 	 0.3132779598236084 	 0.2982165813446045 	 0.28594279289245605 	 0.4480013847351074 	 0.4507739543914795 	 0.39525938034057617 	 0.38110899925231934 	 
2025-07-25 20:16:13.564241 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", ) 	 25401744 	 1000 	 0.3163795471191406 	 0.2975122928619385 	 0.30486226081848145 	 0.2785520553588867 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([176401, 4, 4, 9]) and output[0] has a shape of torch.Size([176401, 9, 4, 4]).
2025-07-25 20:16:15.702322 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", None, ) 	 25401744 	 1000 	 0.31548166275024414 	 0.29944944381713867 	 0.3049936294555664 	 0.2786240577697754 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([176401, 4, 4, 9]) and output[0] has a shape of torch.Size([176401, 9, 4, 4]).
2025-07-25 20:16:17.801768 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 9, 4, 4],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 9, 4, 4],"float64"), 3, "NCHW", ) 	 25401744 	 1000 	 0.3154609203338623 	 0.31558680534362793 	 0.304750919342041 	 0.2838919162750244 	 0.31544041633605957 	 0.302764892578125 	 0.26271510124206543 	 0.22470498085021973 	 
2025-07-25 20:16:20.243072 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", ) 	 25401672 	 1000 	 0.31474757194519043 	 1.3056678771972656 	 0.3043689727783203 	 1.275430679321289 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 352801, 4, 9]) and output[0] has a shape of torch.Size([2, 9, 352801, 4]).
2025-07-25 20:16:23.282476 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", None, ) 	 25401672 	 1000 	 0.3176705837249756 	 1.307718276977539 	 0.30567240715026855 	 1.2854735851287842 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 352801, 4, 9]) and output[0] has a shape of torch.Size([2, 9, 352801, 4]).
2025-07-25 20:16:26.361971 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", ) 	 25401672 	 1000 	 0.31655383110046387 	 1.306915044784546 	 0.30423855781555176 	 1.2870352268218994 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 4, 352801, 9]) and output[0] has a shape of torch.Size([2, 9, 4, 352801]).
2025-07-25 20:16:29.355513 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", None, ) 	 25401672 	 1000 	 0.31479907035827637 	 1.3058114051818848 	 0.30454373359680176 	 1.2857692241668701 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 4, 352801, 9]) and output[0] has a shape of torch.Size([2, 9, 4, 352801]).
2025-07-25 20:16:32.354930 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 9, 352801, 4],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 9, 352801, 4],"float64"), 3, "NCHW", ) 	 25401672 	 1000 	 0.32707738876342773 	 0.3051929473876953 	 0.3050398826599121 	 0.28373265266418457 	 0.31614136695861816 	 0.30382227897644043 	 0.26452207565307617 	 0.22655844688415527 	 
2025-07-25 20:16:34.723425 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 352801],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 352801],"float64"), 3, "NCHW", ) 	 25401672 	 1000 	 0.7827692031860352 	 0.7493155002593994 	 0.30374622344970703 	 0.2838141918182373 	 0.3148624897003174 	 0.3025209903717041 	 0.2633841037750244 	 0.2101449966430664 	 
2025-07-25 20:16:39.496288 test begin: paddle.nn.functional.conv1d(Tensor([16, 125, 25500],"float32"), Tensor([1, 125, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([16, 125, 25500],"float32"), Tensor([1, 125, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51000126 	 1000 	 0.3297312259674072 	 0.16251468658447266 	 0.08448910713195801 	 0.08299493789672852 	 0.8299570083618164 	 0.33647799491882324 	 0.14085721969604492 	 0.0685427188873291 	 
2025-07-25 20:16:42.241969 test begin: paddle.nn.functional.conv1d(Tensor([16, 64, 49613],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([16, 64, 49613],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50803777 	 1000 	 0.3381667137145996 	 0.1684737205505371 	 0.10047197341918945 	 0.08605623245239258 	 0.7341775894165039 	 0.36330604553222656 	 0.12505769729614258 	 0.0735628604888916 	 
2025-07-25 20:16:44.805754 test begin: paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52040609 	 1000 	 0.3950819969177246 	 0.1842350959777832 	 0.1339564323425293 	 0.09409761428833008 	 0.7701873779296875 	 0.3928554058074951 	 0.1309671401977539 	 0.0801243782043457 	 
2025-07-25 20:16:47.486127 test begin: paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52041632 	 1000 	 0.6790907382965088 	 0.9985945224761963 	 0.17365241050720215 	 0.5101339817047119 	 1.2978017330169678 	 12.795050382614136 	 0.16509151458740234 	 2.610060453414917 	 
2025-07-25 20:17:05.128271 test begin: paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50803745 	 1000 	 0.3856062889099121 	 0.18042588233947754 	 0.13082194328308105 	 0.09245443344116211 	 0.740323543548584 	 0.37093663215637207 	 0.12588167190551758 	 0.07563090324401855 	 
2025-07-25 20:17:07.674711 test begin: paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50804768 	 1000 	 0.6574106216430664 	 0.9478731155395508 	 0.16814517974853516 	 0.4849271774291992 	 1.3630506992340088 	 11.076545715332031 	 0.17407727241516113 	 2.2572007179260254 	 
2025-07-25 20:17:23.632332 test begin: paddle.nn.functional.conv1d(Tensor([32, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52224065 	 1000 	 0.3484017848968506 	 0.17243242263793945 	 0.11757922172546387 	 0.08733081817626953 	 0.638495922088623 	 0.3482205867767334 	 0.08157038688659668 	 0.07071208953857422 	 
2025-07-25 20:17:26.041487 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50978641 	 1000 	 2.255660057067871 	 2.360919713973999 	 0.7694544792175293 	 0.806410551071167 	 1.3144423961639404 	 1.0704658031463623 	 0.2706339359283447 	 0.2735283374786377 	 
2025-07-25 20:17:33.962088 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50822772 	 1000 	 0.2670402526855469 	 0.26844286918640137 	 0.09056520462036133 	 0.09151959419250488 	 21.465975522994995 	 9.585787534713745 	 4.354016542434692 	 2.4457056522369385 	 
2025-07-25 20:18:07.341754 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50859776 	 1000 	 0.26791834831237793 	 0.2657623291015625 	 0.06302976608276367 	 0.09059619903564453 	 21.457576036453247 	 20.122600078582764 	 4.378668785095215 	 4.105731964111328 	 
2025-07-25 20:18:51.402593 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 99226],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 99226],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51852544 	 1000 	 14.530911922454834 	 14.647407293319702 	 4.954581260681152 	 4.99365234375 	 40.04650354385376 	 26.76501226425171 	 6.819969177246094 	 4.550659656524658 	 
2025-07-25 20:20:30.227492 test begin: paddle.nn.functional.conv1d_transpose(Tensor([14176, 512, 7],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([14176, 512, 7],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51855616 	 1000 	 62.83253526687622 	 63.26355266571045 	 21.424702167510986 	 21.56588125228882 	 128.71590089797974 	 127.21581101417542 	 21.9899160861969 	 21.624953746795654 	 
2025-07-25 20:26:55.467112 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51152290 	 1000 	 2.2314634323120117 	 2.3397648334503174 	 0.7620794773101807 	 0.7986998558044434 	 1.3164384365081787 	 1.6043715476989746 	 0.26883578300476074 	 0.40999269485473633 	 
2025-07-25 20:27:03.831003 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 128, 1551],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 128, 1551],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50837632 	 1000 	 0.4890286922454834 	 0.4939737319946289 	 0.16668152809143066 	 0.1684587001800537 	 17.719597578048706 	 39.676634073257446 	 3.616554021835327 	 8.08767032623291 	 
2025-07-25 20:28:03.246540 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 24807, 8],"float32"), bias=Tensor([24807],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 24807, 8],"float32"), bias=Tensor([24807],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50843879 	 1000 	 0.5395374298095703 	 1.042017936706543 	 0.18384027481079102 	 0.3552529811859131 	 43.286932945251465 	 20.393425941467285 	 7.362447500228882 	 5.20129132270813 	 
2025-07-25 20:29:09.568652 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 99226],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 99226],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51065984 	 1000 	 7.892699956893921 	 7.976588726043701 	 2.691594362258911 	 2.7200608253479004 	 17.125491619110107 	 13.628000497817993 	 2.9145092964172363 	 2.3164637088775635 	 
2025-07-25 20:29:59.050501 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 49613, 28],"float32"), Tensor([49613, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 49613, 28],"float32"), Tensor([49613, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 53582168 	 1000 	 4.42894434928894 	 4.629709482192993 	 1.510507583618164 	 1.5773706436157227 	 1.837144374847412 	 1.8888554573059082 	 0.3125326633453369 	 0.4833836555480957 	 
2025-07-25 20:30:14.503505 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 49613],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 49613],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51852544 	 1000 	 14.541906833648682 	 14.659372329711914 	 4.958254814147949 	 4.999298095703125 	 29.54993486404419 	 26.76184892654419 	 5.036787509918213 	 4.550540924072266 	 
2025-07-25 20:31:42.885912 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50826356 	 1000 	 0.4756464958190918 	 0.883568286895752 	 0.16165852546691895 	 0.3012712001800537 	 21.281713008880615 	 9.598258256912231 	 4.342465877532959 	 2.446080207824707 	 
2025-07-25 20:32:18.169827 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50863360 	 1000 	 0.46947383880615234 	 0.47483348846435547 	 0.15998530387878418 	 0.16187548637390137 	 20.767198085784912 	 20.113851308822632 	 3.532881021499634 	 4.102454423904419 	 
2025-07-25 20:33:03.549625 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 907201, 28],"float32"), Tensor([907201, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 907201, 28],"float32"), Tensor([907201, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 979777208 	 1000 	 81.10017108917236 	 84.77655220031738 	 27.652140855789185 	 28.90851879119873 	 35.75243592262268 	 36.06792759895325 	 6.0985448360443115 	 7.378124952316284 	 
2025-07-25 20:37:18.737455 test begin: paddle.nn.functional.conv1d_transpose(Tensor([7088, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([7088, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51069056 	 1000 	 8.876861572265625 	 8.979410171508789 	 3.0260612964630127 	 3.0607030391693115 	 23.83974814414978 	 22.079749822616577 	 4.067433834075928 	 3.7544822692871094 	 
2025-07-25 20:38:27.460799 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 191, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 191, 4],"float32"), ) 	 50852604 	 1000 	 0.3750114440917969 	 0.37621092796325684 	 0.32957005500793457 	 0.3555572032928467 	 69.96042847633362 	 4.02286696434021 	 23.786691427230835 	 1.025160551071167 	 
2025-07-25 20:39:43.657837 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50851856 	 1000 	 1.0991196632385254 	 1.1058192253112793 	 1.0539233684539795 	 1.0846772193908691 	 11.800731658935547 	 13.114087104797363 	 4.018155574798584 	 4.47212290763855 	 
2025-07-25 20:40:12.540770 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 192, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 192, 4],"float32"), ) 	 50922240 	 1000 	 0.9601187705993652 	 1.1825141906738281 	 0.49054622650146484 	 1.161921501159668 	 70.32385587692261 	 70.75917077064514 	 23.901942253112793 	 24.056665182113647 	 
2025-07-25 20:42:39.136212 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50921488 	 1000 	 1.0995597839355469 	 1.1221566200256348 	 1.05387282371521 	 1.0808231830596924 	 11.920720338821411 	 13.13724946975708 	 4.063461065292358 	 4.4778525829315186 	 
2025-07-25 20:43:08.247306 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 193, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 193, 4],"float32"), ) 	 50989828 	 1000 	 0.9810428619384766 	 0.38839077949523926 	 0.5012161731719971 	 0.35463452339172363 	 70.8638322353363 	 71.31556129455566 	 24.09785509109497 	 24.24974775314331 	 
2025-07-25 20:45:32.830974 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50989072 	 1000 	 1.538292646408081 	 1.1075100898742676 	 1.0529494285583496 	 1.087181568145752 	 11.917412281036377 	 13.139993906021118 	 4.06133770942688 	 4.479379177093506 	 
2025-07-25 20:46:03.169008 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 193],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 193],"float32"), ) 	 50989828 	 1000 	 1.368619680404663 	 2.845557451248169 	 0.6977312564849854 	 2.8251564502716064 	 58.79006385803223 	 58.81450080871582 	 19.992592096328735 	 19.99539303779602 	 
2025-07-25 20:48:06.015484 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50989072 	 1000 	 1.1048448085784912 	 1.1125826835632324 	 1.0601396560668945 	 1.0922753810882568 	 12.107049465179443 	 13.161426067352295 	 4.126352071762085 	 4.485760927200317 	 
2025-07-25 20:48:39.226359 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 68161552 	 1000 	 1.4786889553070068 	 1.4819750785827637 	 1.429170846939087 	 1.461073875427246 	 15.926121473312378 	 17.62937617301941 	 5.42465353012085 	 6.007161855697632 	 
2025-07-25 20:49:18.647967 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 192],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 192],"float32"), ) 	 50922240 	 1000 	 2.3159515857696533 	 2.261549949645996 	 1.181020975112915 	 2.240572929382324 	 58.4756383895874 	 58.492961168289185 	 19.88815999031067 	 19.884016036987305 	 
2025-07-25 20:51:21.245227 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50921488 	 1000 	 1.1045336723327637 	 1.2583959102630615 	 1.0598301887512207 	 1.21964693069458 	 12.06342363357544 	 13.14056944847107 	 4.2091710567474365 	 4.478710412979126 	 
2025-07-25 20:51:52.029020 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 68690960 	 1000 	 1.4845280647277832 	 1.4920217990875244 	 1.4365565776824951 	 1.4715063571929932 	 16.054689645767212 	 17.788777828216553 	 5.474045753479004 	 6.062447547912598 	 
2025-07-25 20:52:31.232503 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 191],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 191],"float32"), ) 	 50852604 	 1000 	 2.853130578994751 	 2.9066689014434814 	 2.8000056743621826 	 2.8864402770996094 	 57.72138500213623 	 3.2647922039031982 	 19.627387285232544 	 0.8334901332855225 	 
2025-07-25 20:53:39.425358 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50851856 	 1000 	 1.1032874584197998 	 1.1124091148376465 	 1.0581295490264893 	 1.0809314250946045 	 12.065201044082642 	 13.126362085342407 	 4.099488019943237 	 4.4741129875183105 	 
2025-07-25 20:54:08.637851 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 69222416 	 1000 	 1.493077278137207 	 1.509678840637207 	 1.44679594039917 	 1.4889450073242188 	 16.111915588378906 	 17.906110525131226 	 5.497201204299927 	 6.103036165237427 	 
2025-07-25 20:54:48.049920 test begin: paddle.nn.functional.conv2d(Tensor([752, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([752, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50835216 	 1000 	 1.1001760959625244 	 1.1105916500091553 	 1.0377285480499268 	 1.0820374488830566 	 12.638046979904175 	 12.74638032913208 	 4.308917999267578 	 4.3459320068359375 	 
2025-07-25 20:55:17.458956 test begin: paddle.nn.functional.conv2d(Tensor([758, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([758, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50847414 	 1000 	 1.1175026893615723 	 1.1095833778381348 	 1.0574290752410889 	 1.0892560482025146 	 12.594781160354614 	 12.706856966018677 	 4.294835090637207 	 4.332144737243652 	 
2025-07-25 20:55:47.273960 test begin: paddle.nn.functional.conv2d(Tensor([764, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([764, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50854912 	 1000 	 1.0989935398101807 	 1.1086442470550537 	 1.0514280796051025 	 1.0781950950622559 	 12.514970541000366 	 12.653448820114136 	 4.265337228775024 	 4.3135011196136475 	 
2025-07-25 20:56:16.456101 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 32, 320, 320],"float32"), Tensor([32, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 32, 320, 320],"float32"), Tensor([32, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 52428929 	 1000 	 0.6258397102355957 	 0.6321711540222168 	 0.2133350372314453 	 0.21449041366577148 	 0.6695654392242432 	 0.6207082271575928 	 0.09725642204284668 	 0.10546565055847168 	 
2025-07-25 20:56:19.986487 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 156, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 156, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51118337 	 1000 	 0.5170197486877441 	 0.5221226215362549 	 0.17621374130249023 	 0.17718291282653809 	 0.5639879703521729 	 0.5396227836608887 	 0.08324265480041504 	 0.09144783020019531 	 
2025-07-25 20:56:23.159233 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 320, 156],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 320, 156],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51118337 	 1000 	 0.5170660018920898 	 0.5265235900878906 	 0.1762223243713379 	 0.17748475074768066 	 0.548973560333252 	 0.5373821258544922 	 0.07999658584594727 	 0.09127140045166016 	 
2025-07-25 20:56:28.849528 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 56, 480, 480],"float32"), Tensor([56, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 56, 480, 480],"float32"), Tensor([56, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51609825 	 1000 	 0.5374033451080322 	 0.5398027896881104 	 0.18230462074279785 	 0.1830916404724121 	 0.6117808818817139 	 0.6102557182312012 	 0.08924484252929688 	 0.10370945930480957 	 
2025-07-25 20:56:32.084361 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 414, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 414, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5136256217956543 	 0.5286343097686768 	 0.17507457733154297 	 0.17780232429504395 	 0.5805425643920898 	 0.5741384029388428 	 0.08462738990783691 	 0.09717011451721191 	 
2025-07-25 20:56:35.527172 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 414],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 414],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5136640071868896 	 1.1951358318328857 	 0.17506694793701172 	 0.17644739151000977 	 0.5815639495849609 	 0.5718562602996826 	 0.0848226547241211 	 0.09694552421569824 	 
2025-07-25 20:56:40.743530 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 58982657 	 1000 	 0.6045172214508057 	 0.6025130748748779 	 0.20380592346191406 	 0.20332932472229004 	 0.6631791591644287 	 0.6569108963012695 	 0.0967555046081543 	 0.11164212226867676 	 
2025-07-25 20:56:44.319580 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 28, 480, 480],"float32"), Tensor([28, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 28, 480, 480],"float32"), Tensor([28, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51609713 	 1000 	 0.7110414505004883 	 0.7128767967224121 	 0.240217924118042 	 0.24019908905029297 	 0.6976134777069092 	 0.663853645324707 	 0.10162210464477539 	 0.11281800270080566 	 
2025-07-25 20:56:48.118671 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 207, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 207, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5135962963104248 	 0.520988941192627 	 0.17503833770751953 	 0.1764521598815918 	 0.5632922649383545 	 0.556729793548584 	 0.08190011978149414 	 0.0944218635559082 	 
2025-07-25 20:56:51.467258 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 320, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 320, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 52429057 	 1000 	 0.530085563659668 	 0.5335512161254883 	 0.18067669868469238 	 0.18185091018676758 	 0.5674901008605957 	 0.5599973201751709 	 0.08278131484985352 	 0.09515953063964844 	 
2025-07-25 20:56:54.643110 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 480, 207],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 480, 207],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5136196613311768 	 0.5176475048065186 	 0.1750781536102295 	 0.17642617225646973 	 0.5586333274841309 	 0.5537099838256836 	 0.08105587959289551 	 0.09410572052001953 	 
2025-07-25 20:56:57.745578 test begin: paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 6.3845789432525635 	 1.4831862449645996 	 6.282525300979614 	 1.4611024856567383 	 43.281856536865234 	 18.353420734405518 	 22.11531925201416 	 9.366660833358765 	 
2025-07-25 20:58:08.994481 test begin: paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.039804458618164 	 12.304777145385742 	 11.93653130531311 	 12.026833534240723 	 81.10684943199158 	 22.976605653762817 	 20.76026177406311 	 5.868100881576538 	 
2025-07-25 21:00:21.320376 test begin: paddle.nn.functional.conv3d(Tensor([33076, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([33076, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50805146 	 1000 	 19.009325742721558 	 26.37210512161255 	 9.713376998901367 	 13.47601056098938 	 240.96697449684143 	 47.26720070838928 	 35.177247762680054 	 6.903000354766846 	 
2025-07-25 21:05:58.537632 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 66151, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 66151, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 19.24820041656494 	 19.200615882873535 	 9.831549644470215 	 9.81320309638977 	 278.1707103252411 	 277.69904112815857 	 47.53875803947449 	 47.1998724937439 	 
2025-07-25 21:15:56.576341 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 8, 66151, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 8, 66151, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 15.279376029968262 	 15.469592809677124 	 7.807817459106445 	 7.902329444885254 	 214.60530924797058 	 224.69748306274414 	 36.67226982116699 	 38.18470597267151 	 
2025-07-25 21:23:50.886051 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 66151],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 66151],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 14.963429689407349 	 15.433656215667725 	 7.646972179412842 	 7.88483190536499 	 200.39218258857727 	 221.96425795555115 	 34.270400524139404 	 37.739073753356934 	 
2025-07-25 21:31:27.010564 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.518315315246582 	 1.9534730911254883 	 8.40461277961731 	 1.9335362911224365 	 57.368549823760986 	 22.266494035720825 	 29.31418228149414 	 11.38257098197937 	 
2025-07-25 21:32:59.334813 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.210532426834106 	 12.267735719680786 	 12.087598085403442 	 12.21228814125061 	 88.86090135574341 	 87.01711511611938 	 18.210748195648193 	 22.191199779510498 	 
2025-07-25 21:36:22.142867 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.569068193435669 	 1.9612162113189697 	 8.45437502861023 	 1.942835807800293 	 57.48410367965698 	 12.202089786529541 	 29.376523971557617 	 6.236470937728882 	 
2025-07-25 21:37:44.528918 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.03405237197876 	 12.06419038772583 	 11.93073582649231 	 12.021528720855713 	 88.83155274391174 	 92.68773889541626 	 18.20920419692993 	 31.507291555404663 	 
2025-07-25 21:41:12.871704 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 33076],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f7b2642a950>,)) (kwargs={}) timed out after 600.000000 seconds.

terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753491815 (unix time) try "date -d @1753491815" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a96) received by PID 96918 (TID 0x7f7af1bff640) from PID 96918 ***]

2025-07-26 09:03:45.500119 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
W0726 09:03:46.481437 113619 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 09:03:46.489291 113619 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.35104513168335 	 2.011441230773926 	 8.25248098373413 	 1.9906344413757324 	 59.66028141975403 	 13.676213502883911 	 30.487760543823242 	 6.985303163528442 	 
2025-07-26 09:05:11.849579 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 11.947502613067627 	 11.994720220565796 	 11.852468252182007 	 11.94877028465271 	 94.83227801322937 	 100.47070050239563 	 19.46010446548462 	 34.16742205619812 	 
2025-07-26 09:08:53.603732 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([8, 3, 235201, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7fd10e9c6770>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 09:21:26.480706 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 235201, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
W0726 09:21:27.479200 48653 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 09:21:27.538811 48653 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f1aa5ff2e00>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 09:31:47.522133 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 235201],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
W0726 09:31:48.504113 98512 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 09:31:48.553501 98512 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f7643c02e00>,)) (kwargs={}) timed out after 600.000000 seconds.

W0726 09:41:48.312434 98512 backward.cc:462] While running Node (Conv3dGradNode) raises an EnforceNotMet exception
terminate called without an active exception


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753494108 (unix time) try "date -d @1753494108" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17f28) received by PID 98088 (TID 0x7f763f1c1640) from PID 98088 ***]

2025-07-26 09:41:54.646911 test begin: paddle.nn.functional.conv3d_transpose(Tensor([2, 2451, 2, 2, 2],"float32"), Tensor([2451, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
W0726 09:41:55.609081 131789 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 09:41:55.660215 131789 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([2, 2451, 2, 2, 2],"float32"), Tensor([2451, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", ) 	 50863164 	 1000 	 3.11781907081604 	 0.6362931728363037 	 1.0625770092010498 	 0.2161269187927246 	 4.522559404373169 	 4.513286113739014 	 0.7695093154907227 	 1.1519370079040527 	 
2025-07-26 09:42:09.295621 test begin: paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 12, 12, 12, 9801],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f88fa249270>,)) (kwargs={}) timed out after 600.000000 seconds.

FATAL: exception not rethrown


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753494870 (unix time) try "date -d @1753494870" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2021c) received by PID 131612 (TID 0x7f8692fc1640) from PID 131612 ***]

2025-07-26 09:54:41.734589 test begin: paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 12, 12, 9801, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
W0726 09:54:42.718401 148351 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 09:54:42.777109 148351 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f95a5d6f220>,)) (kwargs={}) timed out after 600.000000 seconds.

FATAL: exception not rethrown


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753495681 (unix time) try "date -d @1753495681" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x242b6) received by PID 148150 (TID 0x7f959cdfa640) from PID 148150 ***]

2025-07-26 10:08:07.559720 test begin: paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 12, 9801, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
W0726 10:08:08.546464  2190 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 10:08:08.597009  2190 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f362e8d71c0>,)) (kwargs={}) timed out after 600.000000 seconds.

FATAL: exception not rethrown


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753496491 (unix time) try "date -d @1753496491" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x817) received by PID 2071 (TID 0x7f3629e7d640) from PID 2071 ***]

2025-07-26 10:21:37.765094 test begin: paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
W0726 10:21:39.413141 19734 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
W0726 10:21:39.420419 19734 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805066 	 1000 	 15.662487268447876 	 26.98597264289856 	 8.004172801971436 	 13.788669109344482 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([24807, 6, 8, 6, 8]) and output[0] has a shape of torch.Size([24807, 6, 10, 10, 10]).
2025-07-26 10:24:24.955480 test begin: paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", ) 	 50805172 	 1000 	 20.934293270111084 	 20.084668159484863 	 7.138548851013184 	 6.848150253295898 	 133.94936656951904 	 25.605495929718018 	 22.906274795532227 	 5.222737550735474 	 
2025-07-26 10:27:49.546951 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 49613, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 49613, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 5.689055919647217 	 31.455082178115845 	 2.9062862396240234 	 16.071901321411133 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 49613, 6, 8]) and output[0] has a shape of torch.Size([4, 6, 49615, 10, 10]).
2025-07-26 10:30:46.026587 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 49613, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 49613, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 7.406129837036133 	 28.58294987678528 	 3.784402370452881 	 14.602198600769043 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 8, 49611, 8]) and output[0] has a shape of torch.Size([4, 6, 10, 49615, 10]).
2025-07-26 10:33:46.366192 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 49613],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 49613],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 5.611550331115723 	 30.617624282836914 	 2.868760824203491 	 15.64350175857544 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 8, 6, 49613]) and output[0] has a shape of torch.Size([4, 6, 10, 10, 49615]).
2025-07-26 10:36:24.982749 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), Tensor([10],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), Tensor([10],"int64"), margin=0.5, reduction="mean", name=None, ) 	 101606430 	 1000 	 1.7360796928405762 	 1.6272237300872803 	 0.06763172149658203 	 0.0660088062286377 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:36:33.717034 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([16934401, 3],"float32"), Tensor([16934401, 3],"float32"), Tensor([16934401],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([16934401, 3],"float32"), Tensor([16934401, 3],"float32"), Tensor([16934401],"int64"), margin=0.5, reduction="mean", name=None, ) 	 118540807 	 1000 	 3.9629101753234863 	 3.9220292568206787 	 0.16763997077941895 	 0.17304754257202148 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:36:50.719396 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([25401601, 3],"float32"), Tensor([25401601, 3],"float32"), Tensor([25401601],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([25401601, 3],"float32"), Tensor([25401601, 3],"float32"), Tensor([25401601],"int64"), margin=0.5, reduction="mean", name=None, ) 	 177811207 	 1000 	 5.881131887435913 	 5.823001384735107 	 0.24930596351623535 	 0.25769519805908203 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:37:13.792116 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="mean", ) 	 50803215 	 1000 	 1.814260482788086 	 1.5763494968414307 	 0.0706777572631836 	 0.06399202346801758 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:37:21.160981 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="none", ) 	 50803215 	 1000 	 1.833164930343628 	 1.5702271461486816 	 0.07435250282287598 	 0.06599044799804688 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:37:30.099261 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="mean", ) 	 355622407 	 1000 	 19.415030002593994 	 19.417909383773804 	 0.8228092193603516 	 0.8593604564666748 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:38:47.414396 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="none", ) 	 355622407 	 1000 	 19.13120198249817 	 19.15279221534729 	 0.8859622478485107 	 0.9261806011199951 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:40:04.558200 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="mean", ) 	 59270407 	 1000 	 3.3348824977874756 	 3.3402411937713623 	 0.14109253883361816 	 0.1478593349456787 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:40:17.408464 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="none", ) 	 59270407 	 1000 	 3.274747371673584 	 3.2797083854675293 	 0.1514444351196289 	 0.15880918502807617 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 10:40:30.147790 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 12, 423361],"float32"), Tensor([10, 1, 423361],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 12, 423361],"float32"), Tensor([10, 1, 423361],"float32"), axis=2, eps=1e-06, ) 	 55036930 	 1000 	 1.0552079677581787 	 1.412182331085205 	 0.08237481117248535 	 0.11058163642883301 	 3.189573287963867 	 7.059161424636841 	 0.20372819900512695 	 0.2667670249938965 	 
2025-07-26 10:40:47.360826 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, ) 	 50803400 	 1000 	 1.4041879177093506 	 2.099869966506958 	 0.1437680721282959 	 0.17911052703857422 	 7.754603147506714 	 7.844582557678223 	 0.4406611919403076 	 0.30774903297424316 	 
2025-07-26 10:41:09.757642 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 508033, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 508033, 10],"float32"), axis=2, eps=1e-06, ) 	 101606600 	 1000 	 2.2052042484283447 	 2.5569751262664795 	 0.22466278076171875 	 0.21800923347473145 	 5.899731874465942 	 7.799121141433716 	 0.4301590919494629 	 0.33155155181884766 	 
2025-07-26 10:41:29.915245 test begin: paddle.nn.functional.cosine_similarity(Tensor([210, 241921],"float32"), Tensor([210, 241921],"float32"), axis=-1, eps=1e-08, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([210, 241921],"float32"), Tensor([210, 241921],"float32"), axis=-1, eps=1e-08, ) 	 101606820 	 1000 	 1.5871076583862305 	 1.5594048500061035 	 0.12427592277526855 	 0.12237119674682617 	 5.435156345367432 	 7.007904529571533 	 0.39650511741638184 	 0.27554941177368164 	 
2025-07-26 10:41:48.024011 test begin: paddle.nn.functional.cosine_similarity(Tensor([32, 1587601],"float32"), Tensor([32, 1587601],"float32"), )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([32, 1587601],"float32"), Tensor([32, 1587601],"float32"), ) 	 101606464 	 1000 	 1.5270400047302246 	 1.615832805633545 	 0.11958789825439453 	 0.12709355354309082 	 5.4346089363098145 	 7.04971981048584 	 0.39630675315856934 	 0.27720117568969727 	 
2025-07-26 10:42:06.233910 test begin: paddle.nn.functional.cosine_similarity(Tensor([396901, 128],"float32"), Tensor([396901, 128],"float32"), )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([396901, 128],"float32"), Tensor([396901, 128],"float32"), ) 	 101606656 	 1000 	 2.334765672683716 	 1.5889384746551514 	 0.2380228042602539 	 0.1355454921722412 	 5.485265016555786 	 7.051477909088135 	 0.4025733470916748 	 0.2998237609863281 	 
2025-07-26 10:42:24.372663 test begin: paddle.nn.functional.cosine_similarity(Tensor([423361, 12, 10],"float32"), Tensor([423361, 1, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([423361, 12, 10],"float32"), Tensor([423361, 1, 10],"float32"), axis=2, eps=1e-06, ) 	 55036930 	 1000 	 1.4599459171295166 	 2.1205902099609375 	 0.14893627166748047 	 0.1823725700378418 	 3.5895156860351562 	 7.8435516357421875 	 0.22914505004882812 	 0.3216214179992676 	 
2025-07-26 10:42:40.356815 test begin: paddle.nn.functional.cosine_similarity(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), axis=-1, eps=1e-08, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), axis=-1, eps=1e-08, ) 	 101607424 	 1000 	 1.5002164840698242 	 1.528313159942627 	 0.155228853225708 	 0.15649819374084473 	 5.445927381515503 	 7.023076295852661 	 0.39841127395629883 	 0.29863905906677246 	 
2025-07-26 10:42:59.319195 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 1024, 50304],"float32"), Tensor([1, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 1024, 50304],"float32"), Tensor([1, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 51512320 	 1000 	 0.6497070789337158 	 86.1291069984436 	 0.1330573558807373 	 29.369953393936157 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1024, 1]) and output[0] has a shape of torch.Size([1, 1024]).
2025-07-26 10:44:27.521139 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2048, 151936],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 2048, 151936],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 311166976 	 1000 	 3.7752394676208496 	 270.4700753688812 	 0.7732019424438477 	 92.212721824646 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 2048, 1]) and output[0] has a shape of torch.Size([1, 2048]).
2025-07-26 10:49:10.076011 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2048, 24807],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 2048, 24807],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50806784 	 1000 	 0.47336649894714355 	 42.9606146812439 	 0.09695005416870117 	 14.648332118988037 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 2048, 1]) and output[0] has a shape of torch.Size([1, 2048]).
2025-07-26 10:49:54.827359 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 335, 151936],"float32"), Tensor([1, 335, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 335, 151936],"float32"), Tensor([1, 335, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50898895 	 1000 	 0.6736702919006348 	 238.95007705688477 	 0.13799762725830078 	 81.47477459907532 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 335, 1]) and output[0] has a shape of torch.Size([1, 335]).
2025-07-26 10:53:55.970276 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 4096, 100352],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 4096, 100352],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 411045888 	 1000 	 4.9482128620147705 	 190.129625082016 	 1.0141592025756836 	 64.81922483444214 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 4096, 1]) and output[0] has a shape of torch.Size([1, 4096]).
2025-07-26 10:57:21.632362 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 4096, 12404],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 4096, 12404],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50810880 	 1000 	 0.3915989398956299 	 22.21251344680786 	 0.08022904396057129 	 7.572803974151611 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 4096, 1]) and output[0] has a shape of torch.Size([1, 4096]).
2025-07-26 10:57:45.553376 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 507, 100352],"float32"), Tensor([1, 507, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 507, 100352],"float32"), Tensor([1, 507, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50878971 	 1000 	 0.6506855487823486 	 161.29631185531616 	 0.1353776454925537 	 54.99947929382324 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 507, 1]) and output[0] has a shape of torch.Size([1, 507]).
2025-07-26 11:00:28.931657 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 1024, 6202],"float32"), Tensor([8, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([8, 1024, 6202],"float32"), Tensor([8, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50814976 	 1000 	 0.4358065128326416 	 11.631585836410522 	 0.08901166915893555 	 3.96405291557312 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 1024, 1]) and output[0] has a shape of torch.Size([8, 1024]).
2025-07-26 11:00:42.319679 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 127, 50304],"float32"), Tensor([8, 127, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([8, 127, 50304],"float32"), Tensor([8, 127, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 51109880 	 1000 	 0.6468849182128906 	 72.6108751296997 	 0.13202786445617676 	 24.75972008705139 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 127, 1]) and output[0] has a shape of torch.Size([8, 127]).
2025-07-26 11:01:56.936868 test begin: paddle.nn.functional.dropout(Tensor([7576, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([7576, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 101609312 	 1000 	 0.0010602474212646484 	 0.006910562515258789 	 6.9141387939453125e-06 	 2.1219253540039062e-05 	 0.03211832046508789 	 0.4565005302429199 	 2.9087066650390625e-05 	 0.38507771492004395 	 combined
2025-07-26 11:02:00.567368 test begin: paddle.nn.functional.dropout(Tensor([7712, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([7712, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 101613312 	 1000 	 0.0010042190551757812 	 0.006840229034423828 	 6.9141387939453125e-06 	 2.5510787963867188e-05 	 0.03178858757019043 	 0.45363426208496094 	 2.0265579223632812e-05 	 0.3834550380706787 	 combined
2025-07-26 11:02:04.135849 test begin: paddle.nn.functional.dropout(Tensor([79381, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([79381, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 101607680 	 1000 	 0.0010020732879638672 	 0.006789684295654297 	 6.67572021484375e-06 	 2.1457672119140625e-05 	 0.032621145248413086 	 0.4535996913909912 	 3.790855407714844e-05 	 0.3845224380493164 	 combined
2025-07-26 11:02:07.703405 test begin: paddle.nn.functional.dropout(Tensor([8168, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([8168, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 101609920 	 1000 	 0.001009225845336914 	 0.009404182434082031 	 9.059906005859375e-06 	 6.079673767089844e-05 	 0.03150510787963867 	 0.4536130428314209 	 2.8848648071289062e-05 	 0.3838050365447998 	 combined
2025-07-26 11:02:11.496337 test begin: paddle.nn.functional.elu(Tensor([1, 21504, 2363],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1, 21504, 2363],"float32"), ) 	 50813952 	 1000 	 0.2955739498138428 	 0.29934239387512207 	 0.27959489822387695 	 0.2759249210357666 	 0.45038771629333496 	 0.44854187965393066 	 0.38677310943603516 	 0.37879323959350586 	 
2025-07-26 11:02:14.626405 test begin: paddle.nn.functional.elu(Tensor([1, 25401601, 2],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1, 25401601, 2],"float32"), ) 	 50803202 	 1000 	 0.29553675651550293 	 0.2992236614227295 	 0.286776065826416 	 0.2828047275543213 	 0.4500284194946289 	 0.4510018825531006 	 0.39563941955566406 	 0.3890960216522217 	 
2025-07-26 11:02:17.667277 test begin: paddle.nn.functional.elu(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29553937911987305 	 0.3019556999206543 	 0.2867617607116699 	 0.2827582359313965 	 0.45023560523986816 	 0.44840192794799805 	 0.39634060859680176 	 0.3864140510559082 	 
2025-07-26 11:02:20.708421 test begin: paddle.nn.functional.elu(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29547929763793945 	 0.3084437847137451 	 0.28672146797180176 	 0.2826879024505615 	 0.4500141143798828 	 0.4483919143676758 	 0.3940722942352295 	 0.38629770278930664 	 
2025-07-26 11:02:24.840309 test begin: paddle.nn.functional.elu(Tensor([1182, 21504, 2],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1182, 21504, 2],"float32"), ) 	 50835456 	 1000 	 0.29607653617858887 	 0.2993917465209961 	 0.2869887351989746 	 0.27599120140075684 	 0.45041894912719727 	 0.44870805740356445 	 0.3820943832397461 	 0.37973856925964355 	 
2025-07-26 11:02:28.394805 test begin: paddle.nn.functional.elu(Tensor([15, 3386881],"float32"), 1.0, )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([15, 3386881],"float32"), 1.0, ) 	 50803215 	 1000 	 0.2954843044281006 	 0.2992565631866455 	 0.2794773578643799 	 0.274921178817749 	 0.45006656646728516 	 0.44843077659606934 	 0.36269140243530273 	 0.3793511390686035 	 
2025-07-26 11:02:31.482075 test begin: paddle.nn.functional.elu(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29553651809692383 	 0.2992682456970215 	 0.279693603515625 	 0.2756767272949219 	 0.45010852813720703 	 0.4497063159942627 	 0.38628363609313965 	 0.38059568405151367 	 
2025-07-26 11:02:34.593439 test begin: paddle.nn.functional.elu(Tensor([2540161, 20],"float32"), 1.0, )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([2540161, 20],"float32"), 1.0, ) 	 50803220 	 1000 	 0.29549336433410645 	 0.30253028869628906 	 0.2868790626525879 	 0.2819783687591553 	 0.45003557205200195 	 0.4483768939971924 	 0.39601635932922363 	 0.38524723052978516 	 
2025-07-26 11:02:38.783080 test begin: paddle.nn.functional.embedding(Tensor([1, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0726 11:02:40.265796 72099 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([1, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101646208 	 1000 	 0.01126861572265625 	 0.020888328552246094 	 2.7418136596679688e-05 	 5.0067901611328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 11:02:40.385137 test begin: paddle.nn.functional.embedding(Tensor([1, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0726 11:02:41.869313 72188 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([1, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101610496 	 1000 	 0.015065193176269531 	 0.047052621841430664 	 0.003844738006591797 	 0.025745391845703125 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 11:02:42.000588 test begin: paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0726 11:02:43.508472 72193 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101660673 	 1000 	 0.013924598693847656 	 0.04699301719665527 	 0.002745389938354492 	 0.025655746459960938 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 11:02:43.630012 test begin: paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([12404, 8192],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0726 11:02:45.751150 72264 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([12404, 8192],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101617665 	 1000 	 0.1513659954071045 	 0.39768290519714355 	 0.1402277946472168 	 0.37612009048461914 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 11:02:46.246356 test begin: paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([24807, 4096],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([24807, 4096],"float16"), padding_idx=None, sparse=False, name=None, ) 	 101617664 	 1000 	 0.14972233772277832 	 0.4398038387298584 	 0.1389784812927246 	 0.4188392162322998 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 11:02:49.518538 test begin: paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, ) 	 101622272 	 1000 	 0.07944011688232422 	 0.22627758979797363 	 0.06874775886535645 	 0.20283889770507812 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-26 11:02:52.127786 test begin: paddle.nn.functional.fold(Tensor([176401, 12, 12],"float64"), output_sizes=list[4,5,], kernel_sizes=2, )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7fc537ffad70>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 11:12:57.049320 test begin: paddle.nn.functional.fold(Tensor([176401, 12, 12],"float64"), output_sizes=list[4,5,], kernel_sizes=list[2,2,], strides=list[1,1,], paddings=list[0,0,0,0,], dilations=list[1,1,], name=None, )
W0726 11:12:57.719362 85419 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f4d9a077010>,)) (kwargs={}) timed out after 600.000000 seconds.

FATAL: exception not rethrown


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753500177 (unix time) try "date -d @1753500177" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14cfb) received by PID 85243 (TID 0x7f4d90dfa640) from PID 85243 ***]

2025-07-26 11:23:04.148992 test begin: paddle.nn.functional.fold(Tensor([352801, 12, 12],"float32"), output_sizes=list[4,5,], kernel_sizes=2, )
W0726 11:23:05.232997 98356 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f63c24c3070>,)) (kwargs={}) timed out after 600.000000 seconds.

FATAL: exception not rethrown


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1753500784 (unix time) try "date -d @1753500784" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17f76) received by PID 98166 (TID 0x7f63b97fb640) from PID 98166 ***]

2025-07-26 11:33:10.670327 test begin: paddle.nn.functional.gather_tree(Tensor([11, 288655, 8],"int64"), Tensor([11, 288655, 8],"int64"), )
W0726 11:34:19.528374 111550 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7fc2ac382d70>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 11:43:14.968769 test begin: paddle.nn.functional.gather_tree(Tensor([11, 4, 577310],"int64"), Tensor([11, 4, 577310],"int64"), )
W0726 11:44:18.146801 124478 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f8a0f1eafb0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 11:53:19.416270 test begin: paddle.nn.functional.gather_tree(Tensor([11, 577310, 4],"int64"), Tensor([11, 577310, 4],"int64"), )
W0726 11:54:21.334962 137387 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7fda8da52f50>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 12:03:23.735849 test begin: paddle.nn.functional.gather_tree(Tensor([1587601, 4, 4],"int64"), Tensor([1587601, 4, 4],"int64"), )
W0726 12:04:32.738584 147769 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f7dc9cff130>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 12:13:28.009309 test begin: paddle.nn.functional.gather_tree(Tensor([21, 302401, 4],"int64"), Tensor([21, 302401, 4],"int64"), )
W0726 12:14:33.391289 150949 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f5fd12e6fb0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 12:23:32.358664 test begin: paddle.nn.functional.gather_tree(Tensor([21, 8, 151201],"int64"), Tensor([21, 8, 151201],"int64"), )
W0726 12:24:39.243413 154080 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f381fd62fb0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 12:33:37.088521 test begin: paddle.nn.functional.gather_tree(Tensor([793801, 4, 8],"int64"), Tensor([793801, 4, 8],"int64"), )
W0726 12:34:47.783555 157233 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f4534126ef0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 12:43:44.346921 test begin: paddle.nn.functional.gather_tree(Tensor([793801, 8, 4],"int64"), Tensor([793801, 8, 4],"int64"), )
W0726 12:44:49.870023 160398 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f1bcf0df0d0>,)) (kwargs={}) timed out after 600.000000 seconds.

2025-07-26 12:53:48.715318 test begin: paddle.nn.functional.gelu(Tensor([11, 96, 96, 512],"float32"), False, None, )
W0726 12:53:49.738956 163562 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([11, 96, 96, 512],"float32"), False, None, ) 	 51904512 	 1000 	 0.3466379642486572 	 0.3057546615600586 	 0.33756446838378906 	 0.29309558868408203 	 0.45820021629333496 	 0.45940160751342773 	 0.40395545959472656 	 0.3643226623535156 	 
2025-07-26 12:53:52.563420 test begin: paddle.nn.functional.gelu(Tensor([124, 9, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 9, 96, 512],"float32"), False, None, ) 	 54853632 	 1000 	 0.3666093349456787 	 0.321666955947876 	 0.35714197158813477 	 0.3035757541656494 	 0.4842853546142578 	 0.4851498603820801 	 0.4175584316253662 	 0.40399932861328125 	 
2025-07-26 12:53:56.233537 test begin: paddle.nn.functional.gelu(Tensor([124, 96, 9, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 96, 9, 512],"float32"), False, None, ) 	 54853632 	 1000 	 0.36629176139831543 	 0.321533203125 	 0.35031652450561523 	 0.30399465560913086 	 0.4836151599884033 	 0.4852590560913086 	 0.4165232181549072 	 0.4083728790283203 	 
2025-07-26 12:53:59.872161 test begin: paddle.nn.functional.gelu(Tensor([124, 96, 96, 45],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 96, 96, 45],"float32"), False, None, ) 	 51425280 	 1000 	 0.3437943458557129 	 0.3016703128814697 	 0.33487391471862793 	 0.2905151844024658 	 0.45427703857421875 	 0.4551820755004883 	 0.3680851459503174 	 0.39255833625793457 	 
2025-07-26 12:54:03.254225 test begin: paddle.nn.functional.gelu(Tensor([128, 6, 96, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 6, 96, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.3780090808868408 	 0.3315763473510742 	 0.36857175827026367 	 0.32080078125 	 0.49922871589660645 	 0.5006041526794434 	 0.4448709487915039 	 0.4378945827484131 	 
2025-07-26 12:54:07.026739 test begin: paddle.nn.functional.gelu(Tensor([128, 9, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 9, 96, 512],"float32"), False, None, ) 	 56623104 	 1000 	 0.3780641555786133 	 0.33493781089782715 	 0.3618483543395996 	 0.3140535354614258 	 0.49916768074035645 	 0.50052809715271 	 0.43642210960388184 	 0.43146824836730957 	 
2025-07-26 12:54:10.564776 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 6, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 6, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.37760281562805176 	 0.33399486541748047 	 0.36186766624450684 	 0.3142094612121582 	 0.49923133850097656 	 0.5005686283111572 	 0.43657946586608887 	 0.4295015335083008 	 
2025-07-26 12:54:14.122395 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 9, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 9, 512],"float32"), False, None, ) 	 56623104 	 1000 	 0.3776237964630127 	 0.33150482177734375 	 0.36885762214660645 	 0.32054948806762695 	 0.4996352195739746 	 0.5005145072937012 	 0.44492602348327637 	 0.43770837783813477 	 
2025-07-26 12:54:17.683203 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 96, 44],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 96, 44],"float32"), False, None, ) 	 51904512 	 1000 	 0.3468811511993408 	 0.3044285774230957 	 0.3381071090698242 	 0.29350757598876953 	 0.4581947326660156 	 0.45940661430358887 	 0.4050178527832031 	 0.39772558212280273 	 
2025-07-26 12:54:20.985067 test begin: paddle.nn.functional.gelu(Tensor([8, 96, 96, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([8, 96, 96, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.377549409866333 	 0.3387942314147949 	 0.3686971664428711 	 0.3204967975616455 	 0.4995443820953369 	 0.500478982925415 	 0.44593214988708496 	 0.43723320960998535 	 
2025-07-26 12:54:26.873860 test begin: paddle.nn.functional.glu(Tensor([200, 498, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([200, 498, 512],"float32"), -1, None, ) 	 50995200 	 1000 	 0.7180838584899902 	 0.24660968780517578 	 0.24444055557250977 	 0.22191214561462402 	 1.0950605869293213 	 0.380049467086792 	 0.37280988693237305 	 0.31650376319885254 	 
2025-07-26 12:54:30.751150 test begin: paddle.nn.functional.glu(Tensor([209, 477, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([209, 477, 512],"float32"), -1, None, ) 	 51042816 	 1000 	 0.7206020355224609 	 0.2484300136566162 	 0.24532413482666016 	 0.22565293312072754 	 1.0960419178009033 	 0.38040995597839355 	 0.37306666374206543 	 0.3159043788909912 	 
2025-07-26 12:54:34.418319 test begin: paddle.nn.functional.glu(Tensor([218, 457, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([218, 457, 512],"float32"), -1, None, ) 	 51008512 	 1000 	 0.7282373905181885 	 0.24844145774841309 	 0.24484610557556152 	 0.22543072700500488 	 1.095613956451416 	 0.38013648986816406 	 0.3729851245880127 	 0.31319308280944824 	 
2025-07-26 12:54:40.245986 test begin: paddle.nn.functional.glu(Tensor([30, 3308, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([30, 3308, 512],"float32"), -1, None, ) 	 50810880 	 1000 	 0.71630859375 	 0.24484777450561523 	 0.24382948875427246 	 0.2246260643005371 	 1.0908136367797852 	 0.3785429000854492 	 0.3713202476501465 	 0.3150973320007324 	 
2025-07-26 12:54:43.939164 test begin: paddle.nn.functional.glu(Tensor([30, 457, 3706],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([30, 457, 3706],"float32"), -1, None, ) 	 50809260 	 1000 	 0.7442402839660645 	 0.24933409690856934 	 0.25338077545166016 	 0.2211167812347412 	 1.1541390419006348 	 0.3822646141052246 	 0.39292335510253906 	 0.3108987808227539 	 
2025-07-26 12:54:47.840963 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 662, 768],"float32"), Tensor([100, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 662, 768],"float32"), Tensor([100, 1, 12544, 2],"float32"), align_corners=False, ) 	 53350400 	 1000 	 0.06285929679870605 	 0.0620424747467041 	 0.05095171928405762 	 0.04402613639831543 	 0.33257460594177246 	 0.32148194313049316 	 0.16989517211914062 	 0.16422080993652344 	 
2025-07-26 12:54:49.514878 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 662, 768],"float32"), Tensor([100, 1, 662, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 662, 768],"float32"), Tensor([100, 1, 662, 2],"float32"), align_corners=False, ) 	 50974000 	 1000 	 0.019545793533325195 	 0.025807619094848633 	 1.4066696166992188e-05 	 7.915496826171875e-05 	 0.1754164695739746 	 0.16973066329956055 	 0.08957433700561523 	 0.07406330108642578 	 
2025-07-26 12:54:50.720111 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 662],"float32"), Tensor([100, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 662],"float32"), Tensor([100, 1, 12544, 2],"float32"), align_corners=False, ) 	 53350400 	 1000 	 0.0649411678314209 	 0.06409025192260742 	 0.0451962947845459 	 0.038385629653930664 	 0.3376743793487549 	 0.3295292854309082 	 0.17249774932861328 	 0.16832208633422852 	 
2025-07-26 12:54:52.373520 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 12544, 2],"float32"), align_corners=False, ) 	 61491200 	 1000 	 0.06599688529968262 	 0.06558585166931152 	 0.04640531539916992 	 0.038922786712646484 	 0.3625218868255615 	 0.34951281547546387 	 0.18515443801879883 	 0.17854905128479004 	 
2025-07-26 12:54:54.291871 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 254017, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 254017, 2],"float32"), align_corners=False, ) 	 109785800 	 1000 	 0.7018442153930664 	 0.7274186611175537 	 0.6823461055755615 	 0.7086384296417236 	 2.7096638679504395 	 2.7656381130218506 	 1.3847200870513916 	 1.4132380485534668 	 
2025-07-26 12:55:03.794351 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, ) 	 111667200 	 1000 	 0.7270009517669678 	 0.7507450580596924 	 0.707481861114502 	 0.7244963645935059 	 2.8030776977539062 	 2.8598220348358154 	 1.432373285293579 	 1.4615037441253662 	 
2025-07-26 12:55:13.227883 test begin: paddle.nn.functional.grid_sample(Tensor([100, 21, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 21, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, ) 	 1291315200 	 1000 	 17.18155527114868 	 14.998582124710083 	 17.15401864051819 	 14.979292631149292 	 58.141517639160156 	 58.30647087097168 	 29.709744930267334 	 11.949628829956055 	 
2025-07-26 12:58:19.350370 test begin: paddle.nn.functional.grid_sample(Tensor([172, 1, 544, 544],"float32"), Tensor([172, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([172, 1, 544, 544],"float32"), Tensor([172, 1, 12544, 2],"float32"), align_corners=False, ) 	 55216128 	 1000 	 0.08004903793334961 	 0.080963134765625 	 0.05972576141357422 	 0.05445361137390137 	 0.4055781364440918 	 0.40111231803894043 	 0.2070615291595459 	 0.20489263534545898 	 
2025-07-26 12:58:21.255303 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 467, 544],"float32"), Tensor([200, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 467, 544],"float32"), Tensor([200, 1, 12544, 2],"float32"), align_corners=False, ) 	 55827200 	 1000 	 0.08484435081481934 	 0.08783459663391113 	 0.07255434989929199 	 0.06992626190185547 	 0.4297773838043213 	 0.4257640838623047 	 0.21957993507385254 	 0.21748018264770508 	 
2025-07-26 12:58:23.204992 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 467, 544],"float32"), Tensor([200, 1, 467, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 467, 544],"float32"), Tensor([200, 1, 467, 2],"float32"), align_corners=False, ) 	 50996400 	 1000 	 0.011610746383666992 	 0.019870996475219727 	 1.2636184692382812e-05 	 7.677078247070312e-05 	 0.18532896041870117 	 0.1808462142944336 	 0.09463667869567871 	 0.0923616886138916 	 
2025-07-26 12:58:24.413655 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 467],"float32"), Tensor([200, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 467],"float32"), Tensor([200, 1, 12544, 2],"float32"), align_corners=False, ) 	 55827200 	 1000 	 0.08502197265625 	 0.08772850036621094 	 0.0734093189239502 	 0.06983399391174316 	 0.43471312522888184 	 0.4316236972808838 	 0.2220456600189209 	 0.22045588493347168 	 
2025-07-26 12:58:26.351963 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 12544, 2],"float32"), align_corners=False, ) 	 64204800 	 1000 	 0.08957028388977051 	 0.09235358238220215 	 0.0777897834777832 	 0.07424354553222656 	 0.46579623222351074 	 0.46056652069091797 	 0.23793768882751465 	 0.23525619506835938 	 
2025-07-26 12:58:28.496343 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 127009, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 127009, 2],"float32"), align_corners=False, ) 	 109990800 	 1000 	 0.6622438430786133 	 0.695904016494751 	 0.6505279541015625 	 0.6727035045623779 	 2.6532692909240723 	 2.6752963066101074 	 1.3557014465332031 	 1.367091178894043 	 
2025-07-26 12:58:38.936428 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, ) 	 114380800 	 1000 	 0.7164788246154785 	 0.7564008235931396 	 0.7047181129455566 	 0.7257437705993652 	 2.867734909057617 	 2.9041714668273926 	 1.4653282165527344 	 1.4838018417358398 	 
2025-07-26 12:58:50.789413 test begin: paddle.nn.functional.grid_sample(Tensor([200, 11, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 11, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, ) 	 706252800 	 1000 	 8.71701455116272 	 8.03604793548584 	 8.697305917739868 	 8.013479948043823 	 28.831421852111816 	 28.59147596359253 	 14.733178853988647 	 9.748576164245605 	 
2025-07-26 13:00:24.974803 test begin: paddle.nn.functional.grid_sample(Tensor([2026, 1, 544, 544],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2026, 1, 544, 544],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, ) 	 650394624 	 1000 	 0.8442628383636475 	 0.8689920902252197 	 0.8324658870697021 	 0.8504843711853027 	 4.730109691619873 	 4.511410713195801 	 2.416541814804077 	 1.53755784034729 	 
2025-07-26 13:00:47.835532 test begin: paddle.nn.functional.grid_sample(Tensor([2026, 1, 768, 768],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2026, 1, 768, 768],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, ) 	 1245811712 	 1000 	 1.2054390907287598 	 1.1796197891235352 	 1.1936979293823242 	 1.1612052917480469 	 7.420677900314331 	 6.7717413902282715 	 3.7939398288726807 	 1.3854942321777344 	 
2025-07-26 13:01:29.957656 test begin: paddle.nn.functional.grid_sample(Tensor([87, 1, 768, 768],"float32"), Tensor([87, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([87, 1, 768, 768],"float32"), Tensor([87, 1, 12544, 2],"float32"), align_corners=False, ) 	 53497344 	 1000 	 0.05800056457519531 	 0.05703449249267578 	 0.04632163047790527 	 0.03882741928100586 	 0.320143461227417 	 0.3072669506072998 	 0.16354751586914062 	 0.15695905685424805 	 
2025-07-26 13:01:31.608985 test begin: paddle.nn.functional.grid_sample(x=Tensor([1, 64, 80, 94, 311],"float32"), grid=Tensor([1, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([1, 64, 80, 94, 311],"float32"), grid=Tensor([1, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 157574080 	 1000 	 13.821078300476074 	 11.547383308410645 	 13.808665990829468 	 11.520636796951294 	 95.9167971611023 	 95.87480330467224 	 49.05958127975464 	 49.10747051239014 	 
2025-07-26 13:05:14.405595 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 87713280 	 1000 	 5.353730916976929 	 3.6635143756866455 	 5.341618061065674 	 3.6443681716918945 	 11.151033639907837 	 12.025283813476562 	 5.6981282234191895 	 6.144677400588989 	 
2025-07-26 13:05:50.214663 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 6, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 6, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 56806080 	 1000 	 0.13982081413269043 	 0.09829163551330566 	 0.12714242935180664 	 0.07213068008422852 	 0.46062564849853516 	 0.4600696563720703 	 0.2354414463043213 	 0.23568153381347656 	 
2025-07-26 13:05:52.465490 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 83971328 	 1000 	 37.87127757072449 	 34.20211410522461 	 37.85859441757202 	 34.17484664916992 	 109.7724142074585 	 119.43101358413696 	 56.09418845176697 	 61.03000330924988 	 
2025-07-26 13:11:07.184212 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 7, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 7, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 52975328 	 1000 	 0.8224828243255615 	 0.7167782783508301 	 0.8103795051574707 	 0.6982588768005371 	 2.44096040725708 	 2.6739025115966797 	 1.2470717430114746 	 1.3660736083984375 	 
2025-07-26 13:11:14.941501 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 82538240 	 1000 	 39.33495759963989 	 34.098336696624756 	 39.32239747047424 	 34.06515550613403 	 109.25248980522156 	 119.00728130340576 	 55.82812547683716 	 60.81228184700012 	 
2025-07-26 13:16:31.197081 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 8, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 8, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 61061120 	 1000 	 11.540561437606812 	 10.919595718383789 	 11.528317213058472 	 10.900433778762817 	 35.36942958831787 	 37.96030116081238 	 18.07410764694214 	 19.396894454956055 	 
2025-07-26 13:18:12.130765 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 27],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 27],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 83562240 	 1000 	 41.984323263168335 	 35.347368001937866 	 41.53668570518494 	 35.32564306259155 	 115.53680396080017 	 124.9385404586792 	 59.04025864601135 	 63.84631109237671 	 
2025-07-26 13:23:44.169493 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 41, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
Traceback (most recent call last):
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 189, in <module>
    main()
  File "/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/engine.py", line 163, in main
    case.test()
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 185, in <lambda>
    return wraps(func)(lambda *args, **kwargs : func_timeout(defaultTimeout, func, args=args, kwargs=kwargs))
  File "/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py", line 101, in func_timeout
    raise FunctionTimedOut('', timeout, func, args, kwargs)
func_timeout.exceptions.FunctionTimedOut: Function test (args=(<tester.paddle_torch_gpu_performance.APITestPaddleTorchGPUPerformance object at 0x7f8835a5a9e0>,)) (kwargs={}) timed out after 600.000000 seconds.

malloc_consolidate(): invalid chunk size
2025-07-25 17:48:55.463728 test begin: paddle.nn.functional.label_smooth(label=Tensor([48, 32, 33712],"float32"), epsilon=0.1, )
W0725 17:48:56.457854 97355 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.nn.functional.label_smooth 	 paddle.nn.functional.label_smooth(label=Tensor([48, 32, 33712],"float32"), epsilon=0.1, ) 	 51781632 	 1000 	 0.3064565658569336 	 0.63395094871521 	 0.2964751720428467 	 0.21563100814819336 	 0.30327725410461426 	 0.3034095764160156 	 0.24992060661315918 	 0.21798038482666016 	 combined
2025-07-25 17:48:59.572676 test begin: paddle.nn.functional.label_smooth(label=Tensor([76, 20, 33712],"float32"), epsilon=0.1, )
[Prof] paddle.nn.functional.label_smooth 	 paddle.nn.functional.label_smooth(label=Tensor([76, 20, 33712],"float32"), epsilon=0.1, ) 	 51242240 	 1000 	 0.29853391647338867 	 0.6098804473876953 	 0.28829169273376465 	 0.20765972137451172 	 0.29866838455200195 	 0.30037927627563477 	 0.24567532539367676 	 0.20204854011535645 	 combined
2025-07-25 17:49:02.783401 test begin: paddle.nn.functional.layer_norm(Tensor([115, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([115, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 51227648 	 1000 	 0.3023793697357178 	 0.3163926601409912 	 0.28603386878967285 	 0.29366326332092285 	 0.47130656242370605 	 1.0155913829803467 	 0.24071073532104492 	 0.5188946723937988 	 
2025-07-25 17:49:06.578058 test begin: paddle.nn.functional.layer_norm(Tensor([174, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([174, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50960384 	 1000 	 0.3006551265716553 	 0.31520748138427734 	 0.2846822738647461 	 0.28315067291259766 	 0.46907591819763184 	 1.0103788375854492 	 0.23960447311401367 	 0.5162827968597412 	 
2025-07-25 17:49:10.411208 test begin: paddle.nn.functional.layer_norm(Tensor([226, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([226, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50915328 	 1000 	 0.3004727363586426 	 0.3145465850830078 	 0.28432130813598633 	 0.291640043258667 	 0.4681260585784912 	 1.0097763538360596 	 0.23911666870117188 	 0.5158922672271729 	 
2025-07-25 17:49:14.198909 test begin: paddle.nn.functional.layer_norm(Tensor([7, 7088, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([7, 7088, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50808832 	 1000 	 0.30019450187683105 	 0.31403470039367676 	 0.2838566303253174 	 0.29104089736938477 	 0.4675135612487793 	 1.0072247982025146 	 0.23879718780517578 	 0.5145909786224365 	 
2025-07-25 17:49:17.969578 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 26, 304, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 26, 304, 544],"float32"), 0.1, ) 	 51597312 	 1000 	 0.3008260726928711 	 0.3025786876678467 	 0.2848482131958008 	 0.27829980850219727 	 0.45751285552978516 	 0.453596830368042 	 0.3940310478210449 	 0.38888049125671387 	 
2025-07-25 17:49:21.325779 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 32, 122, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 32, 122, 1088],"float32"), 0.1, ) 	 50970624 	 1000 	 0.2970547676086426 	 0.29892516136169434 	 0.28792405128479004 	 0.2818789482116699 	 0.4519047737121582 	 0.4481644630432129 	 0.39633631706237793 	 0.38630247116088867 	 
2025-07-25 17:49:24.498465 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 32, 608, 218],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 32, 608, 218],"float32"), 0.1, ) 	 50896896 	 1000 	 0.29662013053894043 	 0.3027322292327881 	 0.2874419689178467 	 0.27231860160827637 	 0.4512789249420166 	 0.44759392738342285 	 0.39683008193969727 	 0.3556492328643799 	 
2025-07-25 17:49:27.658297 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 64, 122, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 64, 122, 544],"float32"), 0.1, ) 	 50970624 	 1000 	 0.2971200942993164 	 0.29898929595947266 	 0.2879652976989746 	 0.27473998069763184 	 0.4519164562225342 	 0.44815945625305176 	 0.3976001739501953 	 0.37818431854248047 	 
2025-07-25 17:49:30.825911 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 64, 304, 218],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 64, 304, 218],"float32"), 0.1, ) 	 50896896 	 1000 	 0.2966930866241455 	 0.2985398769378662 	 0.2875845432281494 	 0.2813096046447754 	 0.45121169090270996 	 0.4474632740020752 	 0.3965616226196289 	 0.3855421543121338 	 
2025-07-25 17:49:34.036495 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 7, 608, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 7, 608, 1088],"float32"), 0.1, ) 	 55566336 	 1000 	 0.32747435569763184 	 0.3265204429626465 	 0.31436944007873535 	 0.29655933380126953 	 0.49204468727111816 	 0.48819923400878906 	 0.4282355308532715 	 0.4161946773529053 	 
2025-07-25 17:49:42.473687 test begin: paddle.nn.functional.leaky_relu(Tensor([13, 64, 256, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([13, 64, 256, 256],"float32"), 0.1, None, ) 	 54525952 	 1000 	 0.3183434009552002 	 0.31935882568359375 	 0.30807018280029297 	 0.30282068252563477 	 0.48299717903137207 	 0.4791219234466553 	 0.4253246784210205 	 0.41408228874206543 	 
2025-07-25 17:49:45.885653 test begin: paddle.nn.functional.leaky_relu(Tensor([3, 32, 608, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([3, 32, 608, 1088],"float32"), 0.1, ) 	 63504384 	 1000 	 0.36983609199523926 	 0.3710651397705078 	 0.3602256774902344 	 0.3541383743286133 	 0.5615134239196777 	 0.5572309494018555 	 0.5072822570800781 	 0.49463868141174316 	 
2025-07-25 17:49:49.785835 test begin: paddle.nn.functional.leaky_relu(Tensor([5, 64, 304, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([5, 64, 304, 544],"float32"), 0.1, ) 	 52920320 	 1000 	 0.3082268238067627 	 0.3101003170013428 	 0.2991139888763428 	 0.29352760314941406 	 0.46883654594421387 	 0.4650263786315918 	 0.4124116897583008 	 0.4027688503265381 	 
2025-07-25 17:49:53.089200 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 13, 256, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 13, 256, 256],"float32"), 0.1, None, ) 	 54525952 	 1000 	 0.3175690174102783 	 0.3193478584289551 	 0.30822086334228516 	 0.302837610244751 	 0.4828824996948242 	 0.4791250228881836 	 0.42549800872802734 	 0.4180893898010254 	 
2025-07-25 17:49:56.497800 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 64, 256, 49],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 64, 256, 49],"float32"), 0.1, None, ) 	 51380224 	 1000 	 0.2994508743286133 	 0.3012208938598633 	 0.290233850479126 	 0.2846341133117676 	 0.4553532600402832 	 0.4516868591308594 	 0.4004783630371094 	 0.38985466957092285 	 
2025-07-25 17:49:59.680597 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 64, 49, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 64, 49, 256],"float32"), 0.1, None, ) 	 51380224 	 1000 	 0.29943108558654785 	 0.3014712333679199 	 0.2902412414550781 	 0.28302550315856934 	 0.4553258419036865 	 0.45170140266418457 	 0.40083789825439453 	 0.3895680904388428 	 
2025-07-25 17:50:02.905924 test begin: paddle.nn.functional.linear(x=Tensor([1, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
Warning: The core code of paddle.nn.functional.linear is too complex.
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([1, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 50823284 	 1000 	 0.16011357307434082 	 0.15411877632141113 	 0.05439257621765137 	 0.133345365524292 	 0.31475353240966797 	 0.3173198699951172 	 0.08041119575500488 	 0.10793399810791016 	 
2025-07-25 17:50:04.862333 test begin: paddle.nn.functional.linear(x=Tensor([1, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([1, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, ) 	 50855402 	 1000 	 0.16790056228637695 	 0.15631318092346191 	 0.05709052085876465 	 0.12673330307006836 	 0.3220069408416748 	 0.3220663070678711 	 0.08234715461730957 	 0.10959029197692871 	 
2025-07-25 17:50:06.709669 test begin: paddle.nn.functional.linear(x=Tensor([2, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 50835688 	 1000 	 0.21481990814208984 	 0.2607419490814209 	 0.07302427291870117 	 0.06671595573425293 	 0.4326498508453369 	 0.4236938953399658 	 0.07388639450073242 	 0.08647656440734863 	 
2025-07-25 17:50:08.893470 test begin: paddle.nn.functional.linear(x=Tensor([2, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, ) 	 50880490 	 1000 	 0.2293987274169922 	 0.31287503242492676 	 0.07798194885253906 	 0.08007645606994629 	 0.33546972274780273 	 0.3354370594024658 	 0.08580493927001953 	 0.1141195297241211 	 
2025-07-25 17:50:10.939437 test begin: paddle.nn.functional.linear(x=Tensor([2026, 25088],"float32"), weight=Tensor([25088, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2026, 25088],"float32"), weight=Tensor([25088, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 153592832 	 1000 	 23.877968549728394 	 24.864351749420166 	 12.20111632347107 	 24.838895082473755 	 48.134716272354126 	 48.065937757492065 	 9.866571187973022 	 12.256234884262085 	 
2025-07-25 17:52:41.064597 test begin: paddle.nn.functional.linear(x=Tensor([4051, 12544],"float32"), weight=Tensor([12544, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4051, 12544],"float32"), weight=Tensor([12544, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 63661824 	 1000 	 6.266171932220459 	 6.271034240722656 	 3.2019906044006348 	 6.243664026260376 	 12.160818099975586 	 12.151270389556885 	 2.492894411087036 	 3.09849214553833 	 
2025-07-25 17:53:19.143098 test begin: paddle.nn.functional.linear(x=Tensor([4096, 12404],"float32"), weight=Tensor([12404, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 12404],"float32"), weight=Tensor([12404, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 63509504 	 1000 	 6.207179069519043 	 6.209838628768921 	 3.1717963218688965 	 6.177838563919067 	 12.062945127487183 	 12.029063940048218 	 2.472733497619629 	 3.0673718452453613 	 
2025-07-25 17:53:58.072631 test begin: paddle.nn.functional.linear(x=Tensor([4096, 12544],"float32"), weight=Tensor([12544, 4051],"float32"), bias=Tensor([4051],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 12544],"float32"), weight=Tensor([12544, 4051],"float32"), bias=Tensor([4051],"float32"), name=None, ) 	 102200019 	 1000 	 24.036011695861816 	 24.036404132843018 	 12.282458543777466 	 24.015124082565308 	 48.09176826477051 	 47.94946479797363 	 9.85845685005188 	 12.226929903030396 	 
2025-07-25 17:56:25.557838 test begin: paddle.nn.functional.linear(x=Tensor([4096, 49613],"float32"), weight=Tensor([49613, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 49613],"float32"), weight=Tensor([49613, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 254019584 	 1000 	 24.775614023208618 	 24.770124197006226 	 12.66056752204895 	 24.74855637550354 	 47.812400102615356 	 47.75055766105652 	 9.80145812034607 	 12.176081895828247 	 
2025-07-25 17:58:55.367487 test begin: paddle.nn.functional.local_response_norm(Tensor([10585, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
W0725 17:58:56.164136 103808 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([10585, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50808000 	 1000 	 4.248970031738281 	 5.090550422668457 	 0.723121166229248 	 0.6509430408477783 	 8.876065492630005 	 8.64112401008606 	 1.0056495666503906 	 0.5193326473236084 	 
2025-07-25 17:59:24.154283 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 10585, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 10585, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50808000 	 1000 	 3.429882526397705 	 4.766095876693726 	 0.5835311412811279 	 0.6077871322631836 	 7.178370237350464 	 7.564279317855835 	 0.8138642311096191 	 0.48316526412963867 	 
2025-07-25 17:59:51.667932 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 3, 141121, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 3, 141121, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50803560 	 1000 	 4.324591398239136 	 5.252809047698975 	 0.7359449863433838 	 0.6717116832733154 	 8.957229137420654 	 8.848678588867188 	 1.0146985054016113 	 0.5654218196868896 	 
2025-07-25 18:00:20.803406 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 3, 40, 141121],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 3, 40, 141121],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50803560 	 1000 	 4.324102401733398 	 4.30931830406189 	 0.735898494720459 	 0.5497739315032959 	 8.925410747528076 	 7.903520584106445 	 1.0111255645751953 	 0.5049848556518555 	 
2025-07-25 18:00:49.812654 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 40, 47041],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 40, 47041],"float32"), size=5, data_format="NCDHW", ) 	 50804280 	 1000 	 4.322641372680664 	 4.678053855895996 	 0.735623836517334 	 0.5981011390686035 	 8.872314929962158 	 8.561981439590454 	 1.0052344799041748 	 0.5470795631408691 	 
2025-07-25 18:01:18.520371 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 47041, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 47041, 40],"float32"), size=5, data_format="NCDHW", ) 	 50804280 	 1000 	 4.324423551559448 	 4.677763223648071 	 0.7356245517730713 	 0.5980682373046875 	 8.8722403049469 	 8.562493324279785 	 1.0051977634429932 	 0.5470454692840576 	 
2025-07-25 18:01:47.069315 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3529, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3529, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 4.328178882598877 	 4.2481653690338135 	 0.7351827621459961 	 0.5431225299835205 	 8.9488844871521 	 7.830936431884766 	 1.0137155055999756 	 0.5003318786621094 	 
2025-07-25 18:02:14.298742 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 40, 3529],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 40, 3529],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.121111869812012 	 4.819136619567871 	 1.211359977722168 	 0.6159017086029053 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 40, 40, 3529]) and output[0] has a shape of torch.Size([3, 3529, 3, 40, 40]).
2025-07-25 18:02:42.101259 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 47041, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 47041, 3],"float32"), size=5, data_format="NDHWC", ) 	 50804280 	 1000 	 7.919705152511597 	 4.983397006988525 	 1.3468122482299805 	 0.637258768081665 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 40, 47041, 3]) and output[0] has a shape of torch.Size([3, 3, 3, 40, 47041]).
2025-07-25 18:03:22.815262 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 47041, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 47041, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50804280 	 1000 	 7.918112277984619 	 4.98787784576416 	 1.3468620777130127 	 0.6372823715209961 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 47041, 40, 3]) and output[0] has a shape of torch.Size([3, 3, 3, 47041, 40]).
2025-07-25 18:04:03.064195 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 3, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 3.4292354583740234 	 4.2347259521484375 	 0.5837898254394531 	 0.5416111946105957 	 7.145777463912964 	 7.33056902885437 	 0.8101487159729004 	 0.46825408935546875 	 
2025-07-25 18:04:26.994212 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 40, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.920083045959473 	 4.552335023880005 	 1.3471825122833252 	 0.5820865631103516 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3529, 40, 40, 3]) and output[0] has a shape of torch.Size([3, 3, 3529, 40, 40]).
2025-07-25 18:05:08.064058 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 4.253327131271362 	 4.525031566619873 	 0.7232062816619873 	 0.5785806179046631 	 8.775968313217163 	 8.541411876678467 	 0.9942779541015625 	 0.5456836223602295 	 
2025-07-25 18:05:37.377559 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.949190378189087 	 4.5373969078063965 	 1.347782850265503 	 0.5800943374633789 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3529, 3, 40, 40, 3]) and output[0] has a shape of torch.Size([3529, 3, 3, 40, 40]).
2025-07-25 18:06:19.951945 test begin: paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), )
[Prof] paddle.nn.functional.log_loss 	 paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), ) 	 101606402 	 1000 	 0.4929013252258301 	 3.4186806678771973 	 0.4833817481994629 	 0.34958791732788086 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:06:27.012568 test begin: paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), epsilon=1e-07, )
[Prof] paddle.nn.functional.log_loss 	 paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), epsilon=1e-07, ) 	 101606402 	 1000 	 0.4929342269897461 	 3.4185519218444824 	 0.48291015625 	 0.3495604991912842 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:06:34.175025 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 10, 254017],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 10, 254017],"float64"), None, ) 	 25401700 	 1000 	 0.4409487247467041 	 0.47186803817749023 	 0.4320046901702881 	 0.44266343116760254 	 0.4498939514160156 	 0.4508330821990967 	 0.3950045108795166 	 0.3812906742095947 	 
2025-07-25 18:06:41.604331 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 10, 508033],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 10, 508033],"float32"), None, ) 	 50803300 	 1000 	 0.30057740211486816 	 0.3018331527709961 	 0.29152894020080566 	 0.2850642204284668 	 0.4503161907196045 	 0.4500999450683594 	 0.39569616317749023 	 0.3830299377441406 	 
2025-07-25 18:06:44.771529 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 254017, 10],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 254017, 10],"float64"), None, ) 	 25401700 	 1000 	 0.4409034252166748 	 0.4562551975250244 	 0.4320559501647949 	 0.44306516647338867 	 0.44987034797668457 	 0.4507911205291748 	 0.3949582576751709 	 0.38373899459838867 	 
2025-07-25 18:06:47.657958 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 508033, 10],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 508033, 10],"float32"), None, ) 	 50803300 	 1000 	 0.3005695343017578 	 0.3002779483795166 	 0.29141950607299805 	 0.28505587577819824 	 0.45030808448791504 	 0.4501659870147705 	 0.39507079124450684 	 0.38133978843688965 	 
2025-07-25 18:06:50.852382 test begin: paddle.nn.functional.log_sigmoid(Tensor([254017, 10, 10],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([254017, 10, 10],"float64"), None, ) 	 25401700 	 1000 	 0.44092440605163574 	 0.4622986316680908 	 0.4319601058959961 	 0.4427914619445801 	 0.44991087913513184 	 0.4508364200592041 	 0.395007848739624 	 0.3837258815765381 	 
2025-07-25 18:06:53.738322 test begin: paddle.nn.functional.log_sigmoid(Tensor([508033, 10, 10],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([508033, 10, 10],"float32"), None, ) 	 50803300 	 1000 	 0.300534725189209 	 0.29841089248657227 	 0.29143738746643066 	 0.28524160385131836 	 0.4502687454223633 	 0.4501676559448242 	 0.39373350143432617 	 0.36960387229919434 	 
2025-07-25 18:06:56.953423 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([10, 10, 508033],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([10, 10, 508033],"float32"), ) 	 50803300 	 1000 	 0.3005554676055908 	 0.2984001636505127 	 0.29116034507751465 	 0.28514885902404785 	 0.450286865234375 	 0.45018982887268066 	 0.3957045078277588 	 0.3819143772125244 	 
2025-07-25 18:07:00.133857 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([10, 508033, 10],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([10, 508033, 10],"float32"), ) 	 50803300 	 1000 	 0.300616979598999 	 0.2984161376953125 	 0.2909374237060547 	 0.2851707935333252 	 0.45029640197753906 	 0.4501194953918457 	 0.39565253257751465 	 0.38296079635620117 	 
2025-07-25 18:07:03.307401 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([508033, 10, 10],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([508033, 10, 10],"float32"), ) 	 50803300 	 1000 	 0.3006458282470703 	 0.29837656021118164 	 0.2912266254425049 	 0.2849278450012207 	 0.4500162601470947 	 0.45017528533935547 	 0.3927757740020752 	 0.38301992416381836 	 
2025-07-25 18:07:06.467326 test begin: paddle.nn.functional.log_softmax(Tensor([128, 396901],"float32"), axis=-1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([128, 396901],"float32"), axis=-1, ) 	 50803328 	 1000 	 0.7077810764312744 	 0.6311740875244141 	 0.6988077163696289 	 0.6108744144439697 	 1.3950221538543701 	 0.6504635810852051 	 1.33754301071167 	 0.5635850429534912 	 
2025-07-25 18:07:12.514047 test begin: paddle.nn.functional.log_softmax(Tensor([264, 192612],"float32"), axis=-1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([264, 192612],"float32"), axis=-1, ) 	 50849568 	 1000 	 0.6193215847015381 	 0.6447319984436035 	 0.6102917194366455 	 0.6298508644104004 	 0.8638110160827637 	 0.6638591289520264 	 0.8070816993713379 	 0.5987927913665771 	 
2025-07-25 18:07:17.003255 test begin: paddle.nn.functional.log_softmax(Tensor([2944, 17257],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([2944, 17257],"float32"), axis=1, ) 	 50804608 	 1000 	 0.3335301876068115 	 0.33765292167663574 	 0.32308220863342285 	 0.32309412956237793 	 0.6460165977478027 	 0.5233497619628906 	 0.5870938301086426 	 0.4581742286682129 	 
2025-07-25 18:07:20.546506 test begin: paddle.nn.functional.log_softmax(Tensor([4224, 12028],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([4224, 12028],"float32"), axis=1, ) 	 50806272 	 1000 	 0.3052213191986084 	 0.3079831600189209 	 0.29458093643188477 	 0.29313206672668457 	 0.6299993991851807 	 0.4548482894897461 	 0.5727572441101074 	 0.39040660858154297 	 
2025-07-25 18:07:23.939618 test begin: paddle.nn.functional.log_softmax(Tensor([7664, 6629],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([7664, 6629],"float32"), axis=1, ) 	 50804656 	 1000 	 0.3031008243560791 	 0.2990109920501709 	 0.2924985885620117 	 0.2844274044036865 	 0.5959055423736572 	 0.515911340713501 	 0.538684606552124 	 0.45013952255249023 	 
2025-07-25 18:07:27.337298 test begin: paddle.nn.functional.lp_pool1d(Tensor([2, 3, 8467201],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([2, 3, 8467201],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803206 	 1000 	 0.9307608604431152 	 1.9150192737579346 	 0.8997020721435547 	 0.24416351318359375 	 1.4198100566864014 	 4.9460859298706055 	 0.7254469394683838 	 0.3162388801574707 	 
2025-07-25 18:07:38.079408 test begin: paddle.nn.functional.lp_pool1d(Tensor([2, 793801, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([2, 793801, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803264 	 1000 	 0.9310281276702881 	 1.9484491348266602 	 0.8857951164245605 	 0.2470686435699463 	 1.4241039752960205 	 5.139695405960083 	 0.7276792526245117 	 0.3286278247833252 	 
2025-07-25 18:07:48.871801 test begin: paddle.nn.functional.lp_pool1d(Tensor([529201, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([529201, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803296 	 1000 	 0.9310595989227295 	 1.9382350444793701 	 0.8856351375579834 	 0.24709057807922363 	 1.4227683544158936 	 5.140712261199951 	 0.727008581161499 	 0.3287222385406494 	 
2025-07-25 18:07:59.583323 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50804736 	 1000 	 2.10150408744812 	 3.4932053089141846 	 2.084169387817383 	 0.44537854194641113 	 2.2535388469696045 	 6.8023693561553955 	 1.1514620780944824 	 0.46332693099975586 	 
2025-07-25 18:08:16.220933 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50804736 	 1000 	 0.5549545288085938 	 1.24086332321167 	 0.5303523540496826 	 0.15359735488891602 	 0.9963304996490479 	 3.6526660919189453 	 0.5091543197631836 	 0.24911880493164062 	 
2025-07-25 18:08:24.606641 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, ) 	 50804736 	 1000 	 0.9392673969268799 	 0.7890908718109131 	 0.9143764972686768 	 0.10037040710449219 	 1.9223251342773438 	 3.2901604175567627 	 0.9822185039520264 	 0.22442126274108887 	 
2025-07-25 18:08:32.496599 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50804736 	 1000 	 2.3193109035491943 	 3.533463478088379 	 2.2944791316986084 	 0.4455242156982422 	 2.777864933013916 	 6.800936222076416 	 1.6756813526153564 	 0.46321940422058105 	 
2025-07-25 18:08:51.364609 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50804736 	 1000 	 0.5549156665802002 	 1.2065918445587158 	 0.53029465675354 	 0.15343475341796875 	 0.9964017868041992 	 3.6479926109313965 	 0.5090398788452148 	 0.24878311157226562 	 
2025-07-25 18:08:58.889880 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, ) 	 50804736 	 1000 	 0.9393324851989746 	 0.7890059947967529 	 0.9144022464752197 	 0.10033488273620605 	 1.922597885131836 	 3.2962100505828857 	 0.9821999073028564 	 0.22489118576049805 	 
2025-07-25 18:09:06.757342 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50803392 	 1000 	 2.168642520904541 	 3.512800693511963 	 2.151740550994873 	 0.4477813243865967 	 2.2980544567108154 	 6.939058542251587 	 1.1742839813232422 	 0.44360780715942383 	 
2025-07-25 18:09:23.516466 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50803392 	 1000 	 0.555645227432251 	 1.2126076221466064 	 0.5307388305664062 	 0.15371465682983398 	 0.99825119972229 	 3.654299020767212 	 0.5098366737365723 	 0.23373818397521973 	 
2025-07-25 18:09:31.010681 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50803392 	 1000 	 2.0924530029296875 	 3.6192467212677 	 2.0677027702331543 	 0.4564628601074219 	 2.2972240447998047 	 6.927264928817749 	 1.1738395690917969 	 0.44277215003967285 	 
2025-07-25 18:09:48.557211 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50803392 	 1000 	 0.5553293228149414 	 1.2117149829864502 	 0.5307807922363281 	 0.15433216094970703 	 0.9946229457855225 	 3.60860538482666 	 0.5081517696380615 	 0.23082566261291504 	 
2025-07-25 18:09:55.986893 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([1373060, 37],"float32"), Tensor([1373060],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([1373060, 37],"float32"), Tensor([1373060],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 52176280 	 1000 	 2.945107936859131 	 1.6512045860290527 	 0.3342926502227783 	 0.11233091354370117 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:10:02.134528 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float16"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float16"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 965260838 	 1000 	 52.47870993614197 	 19.44274640083313 	 5.958773136138916 	 1.3226099014282227 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:11:54.239586 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float32"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float32"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 965260838 	 1000 	 54.94017720222473 	 30.16898775100708 	 6.236445903778076 	 1.8114721775054932 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:13:49.006947 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([2746119, 37],"float16"), Tensor([2746119],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([2746119, 37],"float16"), Tensor([2746119],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 104352522 	 1000 	 5.752811431884766 	 2.1475372314453125 	 0.6527276039123535 	 0.1461777687072754 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:14:01.939754 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([5, 10160641],"float32"), Tensor([5],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([5, 10160641],"float32"), Tensor([5],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 50803210 	 1000 	 70.01773595809937 	 6.188054323196411 	 6.511078596115112 	 0.420682430267334 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:15:19.474007 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", ) 	 25401610 	 1000 	 41.96994638442993 	 15.892572402954102 	 3.6075923442840576 	 1.0869855880737305 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:16:19.239580 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([686530, 37],"float64"), Tensor([686530],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([686530, 37],"float64"), Tensor([686530],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", ) 	 26088140 	 1000 	 2.4844369888305664 	 25.82114839553833 	 0.23069334030151367 	 1.7796974182128906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:16:49.655353 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", ) 	 76204830 	 1000 	 1.3381893634796143 	 1.935521125793457 	 0.27311110496520996 	 0.28261613845825195 	 1.8091065883636475 	 2.109095811843872 	 0.4625558853149414 	 0.2697150707244873 	 
2025-07-25 18:16:58.607578 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", None, ) 	 76204830 	 1000 	 1.3398354053497314 	 1.9416797161102295 	 0.273392915725708 	 0.28264808654785156 	 1.8081693649291992 	 2.109722852706909 	 0.46225738525390625 	 0.2697939872741699 	 
2025-07-25 18:17:09.540182 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", ) 	 76204830 	 1000 	 1.3402495384216309 	 1.935551643371582 	 0.27351903915405273 	 0.28255319595336914 	 1.8088321685791016 	 2.1090340614318848 	 0.4624338150024414 	 0.269742488861084 	 
2025-07-25 18:17:18.362753 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", None, ) 	 76204830 	 1000 	 1.339674711227417 	 1.9355010986328125 	 0.27342700958251953 	 0.2825794219970703 	 1.808246374130249 	 2.1092278957366943 	 0.4622664451599121 	 0.2698171138763428 	 
2025-07-25 18:17:27.208629 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([50803201],"float32"), Tensor([50803201],"float32"), Tensor([50803201],"float32"), 0.5, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([50803201],"float32"), Tensor([50803201],"float32"), Tensor([50803201],"float32"), 0.5, "mean", None, ) 	 152409603 	 1000 	 1.6442108154296875 	 1.9392290115356445 	 0.23991179466247559 	 0.2831685543060303 	 2.186974287033081 	 2.247490167617798 	 0.5592050552368164 	 0.2874772548675537 	 
2025-07-25 18:17:38.446751 test begin: paddle.nn.functional.max_pool1d(Tensor([2, 3, 8467201],"float32"), 2, None, 0, False, False, None, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([2, 3, 8467201],"float32"), 2, None, 0, False, False, None, ) 	 50803206 	 1000 	 0.272916316986084 	 0.4159724712371826 	 0.23455047607421875 	 0.38964319229125977 	 0.7783012390136719 	 1.5096113681793213 	 0.3975667953491211 	 0.7713346481323242 	 
2025-07-25 18:17:43.739915 test begin: paddle.nn.functional.max_pool1d(Tensor([226801, 32, 7],"float32"), 7, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([226801, 32, 7],"float32"), 7, ) 	 50803424 	 1000 	 0.31736230850219727 	 0.2157268524169922 	 0.2811620235443115 	 0.18793177604675293 	 18.17153024673462 	 4.399837970733643 	 18.090067386627197 	 2.248241662979126 	 
2025-07-25 18:18:07.887344 test begin: paddle.nn.functional.max_pool1d(Tensor([91, 32, 17447],"float32"), 7, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([91, 32, 17447],"float32"), 7, ) 	 50805664 	 1000 	 0.31371164321899414 	 0.4523911476135254 	 0.26433682441711426 	 0.1804208755493164 	 0.7462007999420166 	 1.4897427558898926 	 0.3812136650085449 	 0.761066198348999 	 
2025-07-25 18:18:14.427247 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 128, 480, 83],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 128, 480, 83],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50995200 	 1000 	 0.21054935455322266 	 0.2756950855255127 	 0.19058823585510254 	 0.2437267303466797 	 0.6716480255126953 	 1.5728797912597656 	 0.3431227207183838 	 0.8036839962005615 	 
2025-07-25 18:18:18.265536 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 128, 83, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 128, 83, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50995200 	 1000 	 0.19670891761779785 	 0.27317237854003906 	 0.17815136909484863 	 0.2538318634033203 	 0.6641597747802734 	 1.575871229171753 	 0.33929896354675293 	 0.80515456199646 	 
2025-07-25 18:18:22.103135 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 23, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 23, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 52992000 	 1000 	 0.21090412139892578 	 0.28807640075683594 	 0.19092822074890137 	 0.2691178321838379 	 0.696448564529419 	 1.6399245262145996 	 0.3558027744293213 	 0.8379366397857666 	 
2025-07-25 18:18:26.036977 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 24, 112, 13],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 24, 112, 13],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 53673984 	 1000 	 0.36470723152160645 	 0.38228559494018555 	 0.34461450576782227 	 0.36304688453674316 	 0.4994933605194092 	 1.6836276054382324 	 0.434934139251709 	 0.8602409362792969 	 
2025-07-25 18:18:30.096406 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 24, 13, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 24, 13, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 53673984 	 1000 	 0.3387899398803711 	 0.3669595718383789 	 0.31930017471313477 	 0.3477339744567871 	 0.49019718170166016 	 1.674792766571045 	 0.427340030670166 	 0.8557260036468506 	 
2025-07-25 18:18:34.114716 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 3, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 3, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 57802752 	 1000 	 0.4053623676300049 	 0.3922157287597656 	 0.3855421543121338 	 0.35854244232177734 	 0.9105134010314941 	 1.8137948513031006 	 0.4653322696685791 	 0.9268403053283691 	 
2025-07-25 18:18:40.288159 test begin: paddle.nn.functional.max_pool2d(Tensor([169, 24, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([169, 24, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50878464 	 1000 	 0.30166077613830566 	 0.3332488536834717 	 0.2824552059173584 	 0.3143651485443115 	 0.8054945468902588 	 1.598745346069336 	 0.4115462303161621 	 0.8169050216674805 	 
2025-07-25 18:18:44.402385 test begin: paddle.nn.functional.max_pool2d(Tensor([2, 128, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([2, 128, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 58982400 	 1000 	 0.23052453994750977 	 0.3200099468231201 	 0.2116401195526123 	 0.3006782531738281 	 0.7732377052307129 	 1.824601411819458 	 0.39504075050354004 	 0.9323165416717529 	 
2025-07-25 18:18:48.777992 test begin: paddle.nn.functional.max_pool2d(Tensor([2, 64, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([2, 64, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 63438848 	 1000 	 0.3830406665802002 	 0.417834997177124 	 0.3647799491882324 	 0.39905524253845215 	 1.006960153579712 	 2.0221712589263916 	 0.5144562721252441 	 1.0332379341125488 	 
2025-07-25 18:18:53.980587 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 13, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 13, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 51544064 	 1000 	 0.35260868072509766 	 0.34068799018859863 	 0.3350398540496826 	 0.32153868675231934 	 0.821530818939209 	 1.6446683406829834 	 0.41975998878479004 	 0.8403961658477783 	 
2025-07-25 18:18:58.216222 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 64, 141, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 64, 141, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 50823168 	 1000 	 0.30805063247680664 	 0.337078332901001 	 0.29027605056762695 	 0.31261396408081055 	 0.8050229549407959 	 1.6203453540802002 	 0.4113001823425293 	 0.827908992767334 	 
2025-07-25 18:19:02.338356 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 64, 704, 141],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 64, 704, 141],"float32"), kernel_size=3, stride=2, padding=1, ) 	 50823168 	 1000 	 0.30911993980407715 	 0.33801841735839844 	 0.29133081436157227 	 0.31954026222229004 	 0.8065807819366455 	 1.6033267974853516 	 0.4121096134185791 	 0.8192260265350342 	 
2025-07-25 18:19:06.447967 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float32"), Tensor([1, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float32"), Tensor([1, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 101606406 	 1000 	 0.04461812973022461 	 0.04079389572143555 	 2.3126602172851562e-05 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:06.624777 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float32"), Tensor([1, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float32"), Tensor([1, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 76204806 	 1000 	 0.04535365104675293 	 0.04132080078125 	 1.6927719116210938e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:06.793639 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50803227 	 1000 	 0.045716285705566406 	 0.03998875617980957 	 1.3828277587890625e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:06.964680 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 101606406 	 1000 	 2.2117433547973633 	 2.3603615760803223 	 1.1293785572052002 	 1.204585075378418 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:20.026916 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606406 	 1000 	 2.2121214866638184 	 2.3298757076263428 	 1.1297249794006348 	 1.1903560161590576 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:30.605980 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float32"), Tensor([1, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float32"), Tensor([1, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50803206 	 1000 	 0.044440507888793945 	 0.04027915000915527 	 3.123283386230469e-05 	 5.269050598144531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:30.779560 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 76204806 	 1000 	 1.1244728565216064 	 1.1738169193267822 	 0.573979377746582 	 0.5997004508972168 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:37.161328 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204806 	 1000 	 1.133713960647583 	 1.1734862327575684 	 0.5709478855133057 	 0.5994033813476562 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:43.697125 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, ) 	 50803206 	 1000 	 1.126451015472412 	 1.1739537715911865 	 0.5739114284515381 	 0.599768877029419 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:49.028747 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803206 	 1000 	 1.1246705055236816 	 1.1737372875213623 	 0.574246883392334 	 0.599621057510376 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:54.392214 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401627 	 1000 	 1.1241495609283447 	 1.1738531589508057 	 0.5740289688110352 	 0.5996525287628174 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:59.723716 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401627 	 1000 	 1.1262469291687012 	 1.173926591873169 	 0.5743935108184814 	 0.599750280380249 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:05.047280 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25401627 	 1000 	 0.0447697639465332 	 0.04012107849121094 	 3.552436828613281e-05 	 4.076957702636719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:05.220810 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25401632 	 1000 	 0.04425954818725586 	 0.04042959213256836 	 2.7179718017578125e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:05.398062 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25401648 	 1000 	 0.044974327087402344 	 0.040084123611450195 	 2.2411346435546875e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:05.567269 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 50803227 	 1000 	 0.038437843322753906 	 0.0387117862701416 	 1.8358230590820312e-05 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:05.730600 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803227 	 1000 	 0.0392603874206543 	 0.03870749473571777 	 1.9311904907226562e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:05.897243 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 50803232 	 1000 	 0.03852105140686035 	 0.03855776786804199 	 1.621246337890625e-05 	 3.0040740966796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:06.059400 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803232 	 1000 	 0.0400385856628418 	 0.03894972801208496 	 2.193450927734375e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:06.221782 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50803248 	 1000 	 0.03824782371520996 	 0.038747549057006836 	 1.6450881958007812e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:06.382569 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803248 	 1000 	 0.04415178298950195 	 0.038655996322631836 	 2.2411346435546875e-05 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:06.547972 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float32"), Tensor([1, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float32"), Tensor([1, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50803216 	 1000 	 0.04445219039916992 	 0.04323244094848633 	 2.1219253540039062e-05 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:06.723889 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401632 	 1000 	 1.1190204620361328 	 1.173581838607788 	 0.5707924365997314 	 0.5995399951934814 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:12.080477 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401632 	 1000 	 1.1251368522644043 	 1.17386794090271 	 0.5745739936828613 	 0.599708080291748 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:17.384128 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, ) 	 50803216 	 1000 	 1.1247446537017822 	 1.1911921501159668 	 0.5741045475006104 	 0.5996229648590088 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:25.359851 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803216 	 1000 	 1.1254470348358154 	 1.173872947692871 	 0.5744712352752686 	 0.5997202396392822 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:30.691156 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 76204816 	 1000 	 1.127732515335083 	 1.1738691329956055 	 0.5741724967956543 	 0.5996410846710205 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:37.827529 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204816 	 1000 	 1.1305341720581055 	 1.1735527515411377 	 0.5718545913696289 	 0.5995442867279053 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:44.509412 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50803232 	 1000 	 0.044646501541137695 	 0.04178786277770996 	 1.8596649169921875e-05 	 5.745887756347656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:44.685818 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float32"), Tensor([1, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float32"), Tensor([1, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 76204816 	 1000 	 0.04489946365356445 	 0.04020571708679199 	 1.71661376953125e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:44.857477 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float32"), Tensor([1, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float32"), Tensor([1, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 101606416 	 1000 	 0.0491337776184082 	 0.040215253829956055 	 2.7179718017578125e-05 	 6.318092346191406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:45.033298 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 101606416 	 1000 	 2.211202383041382 	 2.3320391178131104 	 1.1292932033538818 	 1.190429449081421 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:20:55.544494 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606416 	 1000 	 2.212404727935791 	 2.7109835147857666 	 1.129377841949463 	 1.5691490173339844 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:08.211315 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50803248 	 1000 	 0.04442739486694336 	 0.04190540313720703 	 2.8371810913085938e-05 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:08.399579 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401648 	 1000 	 1.1255261898040771 	 1.1811819076538086 	 0.5726988315582275 	 0.5996484756469727 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:15.314382 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401648 	 1000 	 1.124572992324829 	 1.1743314266204834 	 0.5740482807159424 	 0.5999512672424316 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:20.630567 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50803248 	 1000 	 1.1237409114837646 	 1.1740095615386963 	 0.573737382888794 	 0.5998063087463379 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:27.810622 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803248 	 1000 	 1.1244099140167236 	 1.1780719757080078 	 0.5735385417938232 	 0.5999264717102051 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:34.268647 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 76204848 	 1000 	 1.1314101219177246 	 1.1779162883758545 	 0.573805570602417 	 0.5999929904937744 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:41.599904 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204848 	 1000 	 1.118661880493164 	 1.1743927001953125 	 0.571352481842041 	 0.599938154220581 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:46.925778 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50803248 	 1000 	 0.04485774040222168 	 0.040087223052978516 	 2.765655517578125e-05 	 6.604194641113281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:47.099821 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 76204848 	 1000 	 0.0452427864074707 	 0.04042220115661621 	 3.647804260253906e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:47.268941 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([2116801, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([2116801, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 101606448 	 1000 	 0.04559516906738281 	 0.045614004135131836 	 4.220008850097656e-05 	 5.9604644775390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:47.445581 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 101606448 	 1000 	 2.217409610748291 	 2.329925775527954 	 1.131669282913208 	 1.1903986930847168 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:21:58.144720 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606448 	 1000 	 2.215960741043091 	 2.329925298690796 	 1.1316566467285156 	 1.1903777122497559 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:08.698956 test begin: paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 101639616 	 1000 	 0.05898332595825195 	 0.08538675308227539 	 0.029912948608398438 	 0.04346108436584473 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:09.160282 test begin: paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52537056 	 1000 	 0.05857706069946289 	 0.08537554740905762 	 0.029894113540649414 	 0.04346609115600586 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:09.614016 test begin: paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 101621728 	 1000 	 0.022223711013793945 	 0.0311586856842041 	 3.504753112792969e-05 	 6.246566772460938e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:09.847575 test begin: paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51647472 	 1000 	 0.022333860397338867 	 0.030094385147094727 	 2.574920654296875e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:10.086429 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 2612, 19],"float32"), Tensor([64, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 2612, 19],"float32"), Tensor([64, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 101638144 	 1000 	 0.022231340408325195 	 0.03272843360900879 	 2.4080276489257812e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:10.320036 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 2612, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 2612, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51655680 	 1000 	 0.022168397903442383 	 0.030015230178833008 	 2.4080276489257812e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:10.551267 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 1154],"float32"), Tensor([64, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 1154],"float32"), Tensor([64, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 101625856 	 1000 	 0.024030208587646484 	 0.03018951416015625 	 2.8133392333984375e-05 	 6.270408630371094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:10.787568 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 1154],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 1154],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51649536 	 1000 	 0.022412538528442383 	 0.031229734420776367 	 2.1696090698242188e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:11.038346 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51647472 	 1000 	 0.022207260131835938 	 0.036286354064941406 	 2.3603439331054688e-05 	 7.081031799316406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:11.277587 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([64, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([64, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51655680 	 1000 	 0.02221202850341797 	 0.030065536499023438 	 2.2649765014648438e-05 	 6.604194641113281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:11.514325 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([64, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([64, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51649536 	 1000 	 0.022768735885620117 	 0.03168153762817383 	 2.4080276489257812e-05 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:11.752808 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([64, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([64, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51660544 	 1000 	 0.022180795669555664 	 0.030936241149902344 	 2.3365020751953125e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:11.985422 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 237, 86, 39],"float32"), Tensor([64, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 237, 86, 39],"float32"), Tensor([64, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 101746944 	 1000 	 0.058565378189086914 	 0.08533573150634766 	 0.029879331588745117 	 0.04345393180847168 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:12.461098 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 237, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 237, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52590720 	 1000 	 0.05854535102844238 	 0.08536624908447266 	 0.029883861541748047 	 0.043462514877319336 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:12.904700 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 1182],"float32"), Tensor([64, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 1182],"float32"), Tensor([64, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 101670912 	 1000 	 0.0327908992767334 	 0.030637264251708984 	 3.910064697265625e-05 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:13.109775 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 1182],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 1182],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51222528 	 1000 	 0.024238109588623047 	 0.031400203704833984 	 2.9802322387695312e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:13.286034 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([64, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([64, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51222528 	 1000 	 0.02239680290222168 	 0.030782699584960938 	 1.5735626220703125e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:13.458291 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([64, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([64, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51204096 	 1000 	 0.02237248420715332 	 0.031195402145385742 	 1.621246337890625e-05 	 6.4849853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:13.627994 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([64, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([64, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51202368 	 1000 	 0.023828506469726562 	 0.03074336051940918 	 2.7418136596679688e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:13.802561 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51196320 	 1000 	 0.022382497787475586 	 0.03247213363647461 	 1.7404556274414062e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:13.996308 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 2757, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 2757, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51204096 	 1000 	 0.022287368774414062 	 0.030580759048461914 	 2.0265579223632812e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:14.171946 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 2757, 9],"float32"), Tensor([64, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 2757, 9],"float32"), Tensor([64, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 101634048 	 1000 	 0.022158145904541016 	 0.03198981285095215 	 1.5020370483398438e-05 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:14.356175 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 4201, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 4201, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51202368 	 1000 	 0.023746252059936523 	 0.0391840934753418 	 1.8835067749023438e-05 	 8.630752563476562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:14.540008 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 4201, 21, 9],"float32"), Tensor([64, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 4201, 21, 9],"float32"), Tensor([64, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 101630592 	 1000 	 0.022466182708740234 	 0.030834197998046875 	 2.09808349609375e-05 	 6.604194641113281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:14.716673 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 2545, 39],"float32"), Tensor([64, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 2545, 39],"float32"), Tensor([64, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 101637120 	 1000 	 0.058565616607666016 	 0.08539986610412598 	 0.0299222469329834 	 0.043509721755981445 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:15.169841 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 2545, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 2545, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52535808 	 1000 	 0.05853867530822754 	 0.08542060852050781 	 0.029872655868530273 	 0.04349517822265625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:15.619573 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 1154],"float32"), Tensor([64, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 1154],"float32"), Tensor([64, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 101625856 	 1000 	 0.058508872985839844 	 0.08626389503479004 	 0.02987837791442871 	 0.04346799850463867 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:16.076392 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 1154],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 1154],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52530176 	 1000 	 0.05856943130493164 	 0.08539223670959473 	 0.029911279678344727 	 0.04347634315490723 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:16.524797 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52537056 	 1000 	 0.05856800079345703 	 0.08539128303527832 	 0.0298917293548584 	 0.04350018501281738 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:16.971604 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([64, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([64, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52590720 	 1000 	 0.058585405349731445 	 0.08537769317626953 	 0.029908418655395508 	 0.04346275329589844 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:17.422132 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([64, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([64, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52535808 	 1000 	 0.05855917930603027 	 0.08536410331726074 	 0.02987360954284668 	 0.04347991943359375 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:17.867229 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([64, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([64, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 52530176 	 1000 	 0.058551788330078125 	 0.08538985252380371 	 0.029886245727539062 	 0.0434873104095459 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:18.324571 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 972, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 972, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 51660544 	 1000 	 0.02223682403564453 	 0.030125856399536133 	 2.5510787963867188e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:18.571610 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 972, 43, 19],"float32"), Tensor([64, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 972, 43, 19],"float32"), Tensor([64, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 101647872 	 1000 	 0.022434711456298828 	 0.030144691467285156 	 2.765655517578125e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:18.803958 test begin: paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 51196320 	 1000 	 0.02243351936340332 	 0.03110790252685547 	 1.9311904907226562e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:18.977912 test begin: paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 101618496 	 1000 	 0.022379398345947266 	 0.03059673309326172 	 2.2172927856445312e-05 	 6.4849853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:19.153929 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803440 	 1000 	 1.7049548625946045 	 1.7694141864776611 	 0.8708338737487793 	 0.16379737854003906 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:29.325200 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803440 	 1000 	 2.638845443725586 	 2.600517511367798 	 1.3468964099884033 	 0.18983745574951172 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:45.422246 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803440 	 1000 	 1.7314043045043945 	 1.772284984588623 	 0.8827698230743408 	 0.16378283500671387 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:22:55.867604 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 1.7055838108062744 	 1.768979787826538 	 0.8708810806274414 	 0.16355085372924805 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:06.137995 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402080 	 1000 	 2.6380045413970947 	 2.5971357822418213 	 1.3475382328033447 	 0.18955492973327637 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:21.141633 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 1.728001356124878 	 1.7685120105743408 	 0.8824870586395264 	 0.1636812686920166 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:31.496553 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76205040 	 1000 	 1.7080638408660889 	 2.8372063636779785 	 0.8704288005828857 	 0.16359782218933105 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:43.301086 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76205040 	 1000 	 2.6364829540252686 	 2.6052029132843018 	 1.3464457988739014 	 0.18999338150024414 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:58.266628 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803380 	 1000 	 0.029439210891723633 	 0.03358125686645508 	 1.33514404296875e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:58.398305 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803380 	 1000 	 0.029794931411743164 	 0.03350353240966797 	 3.504753112792969e-05 	 4.00543212890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:58.526865 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803380 	 1000 	 0.029386043548583984 	 0.035570621490478516 	 1.621246337890625e-05 	 6.532669067382812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:58.657459 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402050 	 1000 	 0.03143644332885742 	 0.03355550765991211 	 3.1948089599609375e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:58.788724 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402050 	 1000 	 0.02974534034729004 	 0.034911155700683594 	 3.790855407714844e-05 	 5.364418029785156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:58.923552 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402050 	 1000 	 0.029405832290649414 	 0.033743858337402344 	 1.5735626220703125e-05 	 6.437301635742188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.062364 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76204980 	 1000 	 0.02967524528503418 	 0.03383374214172363 	 2.9325485229492188e-05 	 4.887580871582031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.193946 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 282241, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76204980 	 1000 	 0.03260207176208496 	 0.03375864028930664 	 2.9325485229492188e-05 	 6.723403930664062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.328221 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803344 	 1000 	 0.029592514038085938 	 0.03464651107788086 	 2.1219253540039062e-05 	 6.604194641113281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.476611 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803344 	 1000 	 0.029407739639282227 	 0.03333330154418945 	 2.3603439331054688e-05 	 3.5762786865234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.604565 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803344 	 1000 	 0.029753446578979492 	 0.03355908393859863 	 1.621246337890625e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.735020 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402032 	 1000 	 0.0304718017578125 	 0.033734798431396484 	 3.266334533691406e-05 	 5.3882598876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.867193 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402032 	 1000 	 0.0316922664642334 	 0.03345465660095215 	 3.695487976074219e-05 	 3.719329833984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:23:59.998504 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402032 	 1000 	 0.029443979263305664 	 0.037137508392333984 	 1.3113021850585938e-05 	 7.152557373046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.134409 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76204944 	 1000 	 0.029764652252197266 	 0.03416109085083008 	 3.314018249511719e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.264164 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 352801, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76204944 	 1000 	 0.03059673309326172 	 0.03432869911193848 	 1.5974044799804688e-05 	 6.890296936035156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.399018 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803320 	 1000 	 0.03199052810668945 	 0.033623695373535156 	 2.5033950805664062e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.529341 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803320 	 1000 	 0.029558897018432617 	 0.03362751007080078 	 2.765655517578125e-05 	 3.695487976074219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.658189 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803320 	 1000 	 0.031514644622802734 	 0.033902645111083984 	 1.7404556274414062e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.788928 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402020 	 1000 	 0.02976679801940918 	 0.03382515907287598 	 2.9802322387695312e-05 	 6.556510925292969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:00.921749 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402020 	 1000 	 0.029738903045654297 	 0.03338623046875 	 2.47955322265625e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.051861 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402020 	 1000 	 0.03093862533569336 	 0.03354477882385254 	 1.6450881958007812e-05 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.181889 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76204920 	 1000 	 0.03014373779296875 	 0.034452199935913086 	 2.9087066650390625e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.318128 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 423361],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76204920 	 1000 	 0.029416561126708984 	 0.03365588188171387 	 1.621246337890625e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.450843 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 0.029504060745239258 	 0.03311014175415039 	 1.811981201171875e-05 	 3.5762786865234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.577866 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402050 	 1000 	 0.029490232467651367 	 0.03510713577270508 	 1.4543533325195312e-05 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.709317 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402032 	 1000 	 0.02928447723388672 	 0.03346610069274902 	 1.1682510375976562e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.836394 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402020 	 1000 	 0.029381990432739258 	 0.03371262550354004 	 2.1457672119140625e-05 	 4.00543212890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:01.969328 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803620 	 1000 	 0.0293276309967041 	 0.03337454795837402 	 1.1920928955078125e-05 	 6.365776062011719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.096455 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803620 	 1000 	 0.03015613555908203 	 0.03371453285217285 	 2.6702880859375e-05 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.225142 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803632 	 1000 	 0.029786109924316406 	 0.0335087776184082 	 2.0742416381835938e-05 	 6.866455078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.353949 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803632 	 1000 	 0.031829118728637695 	 0.033728837966918945 	 2.0503997802734375e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.507568 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803650 	 1000 	 0.029379844665527344 	 0.03791451454162598 	 1.8596649169921875e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.645048 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803650 	 1000 	 0.029331684112548828 	 0.03331351280212402 	 1.5974044799804688e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.772529 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803680 	 1000 	 0.02940511703491211 	 0.036463260650634766 	 1.5735626220703125e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:02.904376 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803680 	 1000 	 0.04883766174316406 	 0.03540444374084473 	 4.315376281738281e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:03.070294 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 0.030623197555541992 	 0.04347944259643555 	 1.5735626220703125e-05 	 6.818771362304688e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:03.222177 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803920 	 1000 	 0.04665017127990723 	 0.03385663032531738 	 2.4318695068359375e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:03.388455 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 0.03859591484069824 	 0.04320406913757324 	 3.910064697265625e-05 	 5.3882598876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:03.545764 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 846721],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 846721],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101606520 	 1000 	 0.038417816162109375 	 0.043427228927612305 	 1.4781951904296875e-05 	 7.2479248046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:03.702685 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 846721],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 846721],"float64"), Tensor([1, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101606520 	 1000 	 0.038161277770996094 	 0.043593406677246094 	 2.0265579223632812e-05 	 6.914138793945312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:03.865103 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 705601, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 705601, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101606544 	 1000 	 0.038425445556640625 	 0.0434718132019043 	 2.9802322387695312e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:04.022864 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 705601, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 705601, 6],"float64"), Tensor([1, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101606544 	 1000 	 0.03813815116882324 	 0.04669332504272461 	 1.8835067749023438e-05 	 7.152557373046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:04.183285 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 564481, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 564481, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101606580 	 1000 	 0.038514137268066406 	 0.04449176788330078 	 1.811981201171875e-05 	 8.0108642578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:04.343396 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 564481, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 564481, 5, 6],"float64"), Tensor([1, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101606580 	 1000 	 0.04216194152832031 	 0.04407167434692383 	 4.0531158447265625e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:04.509003 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101606640 	 1000 	 3.3928568363189697 	 3.54583477973938 	 1.7327728271484375 	 0.1640615463256836 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:24.928336 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101606640 	 1000 	 5.267466306686401 	 5.179724454879761 	 2.6905598640441895 	 0.1880476474761963 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:24:58.580909 test begin: paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101607120 	 1000 	 3.378720760345459 	 3.56767201423645 	 1.7259771823883057 	 0.16506385803222656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:25:19.675242 test begin: paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101607120 	 1000 	 5.2642295360565186 	 5.174074172973633 	 2.6886978149414062 	 0.18787622451782227 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:25:50.030318 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 1.7060823440551758 	 1.7668170928955078 	 0.867546796798706 	 0.16355133056640625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:26:01.334131 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402320 	 1000 	 2.635216236114502 	 2.6014347076416016 	 1.3458020687103271 	 0.18985986709594727 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:26:16.321037 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 1.728581190109253 	 1.769902229309082 	 0.8826582431793213 	 0.16380095481872559 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:26:26.619668 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76205520 	 1000 	 1.7055184841156006 	 1.767435073852539 	 0.8712265491485596 	 0.16391825675964355 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:26:37.543171 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76205520 	 1000 	 2.6373329162597656 	 2.601161003112793 	 1.3475637435913086 	 0.18984675407409668 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:26:52.515722 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 1.6992464065551758 	 1.773346185684204 	 0.8677055835723877 	 0.16370820999145508 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:27:04.292184 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803920 	 1000 	 2.6381418704986572 	 2.5970706939697266 	 1.3468806743621826 	 0.18953514099121094 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:27:19.312661 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 1.7281358242034912 	 1.767106533050537 	 0.8824765682220459 	 0.16352152824401855 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:27:29.790533 test begin: paddle.nn.functional.maxout(Tensor([100, 4, 21169, 3],"float64"), 2, 1, None, )
[Error] shape '[100, 0, 2, 2, 2, 21169, 3]' is invalid for input of size 25402800
2025-07-25 18:27:31.598731 test begin: paddle.nn.functional.maxout(Tensor([100, 4, 3, 21169],"float64"), 2, 1, None, )
[Error] shape '[100, 0, 2, 2, 2, 3, 21169]' is invalid for input of size 25402800
2025-07-25 18:27:33.367348 test begin: paddle.nn.functional.maxout(Tensor([100, 4, 3, 42337],"float32"), 2, 1, None, )
[Error] shape '[100, 0, 2, 2, 2, 3, 42337]' is invalid for input of size 50804400
2025-07-25 18:27:37.496150 test begin: paddle.nn.functional.maxout(Tensor([100, 4, 42337, 3],"float32"), 2, 1, None, )
[Error] shape '[100, 0, 2, 2, 2, 42337, 3]' is invalid for input of size 50804400
2025-07-25 18:27:40.895209 test begin: paddle.nn.functional.maxout(Tensor([1411201, 4, 3, 3],"float32"), 2, 1, None, )
[Error] shape '[1411201, 0, 2, 2, 2, 3, 3]' is invalid for input of size 50803236
2025-07-25 18:27:43.314430 test begin: paddle.nn.functional.maxout(Tensor([705601, 4, 3, 3],"float64"), 2, 1, None, )
[Error] shape '[705601, 0, 2, 2, 2, 3, 3]' is invalid for input of size 25401636
2025-07-25 18:27:45.096372 test begin: paddle.nn.functional.maxout(x=Tensor([100, 4, 3, 42337],"float32"), groups=2, )
[Error] shape '[100, 0, 2, 2, 2, 3, 42337]' is invalid for input of size 50804400
2025-07-25 18:27:47.537163 test begin: paddle.nn.functional.maxout(x=Tensor([100, 4, 42337, 3],"float32"), groups=2, )
[Error] shape '[100, 0, 2, 2, 2, 42337, 3]' is invalid for input of size 50804400
2025-07-25 18:27:49.965845 test begin: paddle.nn.functional.maxout(x=Tensor([1411201, 4, 3, 3],"float32"), groups=2, )
[Error] shape '[1411201, 0, 2, 2, 2, 3, 3]' is invalid for input of size 50803236
2025-07-25 18:27:52.361793 test begin: paddle.nn.functional.mish(Tensor([12, 10585, 20, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 10585, 20, 20],"float32"), ) 	 50808000 	 1000 	 0.3064730167388916 	 0.3003096580505371 	 0.29277920722961426 	 0.2845914363861084 	 0.4532454013824463 	 0.45440244674682617 	 0.3993651866912842 	 0.38379549980163574 	 
2025-07-25 18:27:55.613297 test begin: paddle.nn.functional.mish(Tensor([12, 128, 40, 827],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 128, 40, 827],"float32"), ) 	 50810880 	 1000 	 0.30542802810668945 	 0.3004336357116699 	 0.29572486877441406 	 0.2847626209259033 	 0.45351290702819824 	 0.454390287399292 	 0.3992159366607666 	 0.3846421241760254 	 
2025-07-25 18:27:58.826020 test begin: paddle.nn.functional.mish(Tensor([12, 128, 827, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 128, 827, 40],"float32"), ) 	 50810880 	 1000 	 0.30464839935302734 	 0.3002479076385498 	 0.29543185234069824 	 0.28490591049194336 	 0.4536147117614746 	 0.45433974266052246 	 0.39891648292541504 	 0.38555431365966797 	 
2025-07-25 18:28:02.019902 test begin: paddle.nn.functional.mish(Tensor([12, 256, 40, 414],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 256, 40, 414],"float32"), ) 	 50872320 	 1000 	 0.528555154800415 	 0.3100156784057617 	 0.2889573574066162 	 0.2777690887451172 	 0.45443105697631836 	 0.45479917526245117 	 0.39170289039611816 	 0.38025951385498047 	 
2025-07-25 18:28:08.568988 test begin: paddle.nn.functional.mish(Tensor([12, 256, 414, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 256, 414, 40],"float32"), ) 	 50872320 	 1000 	 0.30501484870910645 	 0.30054450035095215 	 0.2958836555480957 	 0.28476929664611816 	 0.4539668560028076 	 0.45476365089416504 	 0.39945387840270996 	 0.3823976516723633 	 
2025-07-25 18:28:11.798689 test begin: paddle.nn.functional.mish(Tensor([12, 2647, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 2647, 40, 40],"float32"), ) 	 50822400 	 1000 	 0.30538296699523926 	 0.3038163185119629 	 0.2959151268005371 	 0.28423261642456055 	 0.4536170959472656 	 0.45441436767578125 	 0.3995695114135742 	 0.3856344223022461 	 
2025-07-25 18:28:15.036058 test begin: paddle.nn.functional.mish(Tensor([12, 512, 20, 414],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 512, 20, 414],"float32"), ) 	 50872320 	 1000 	 0.3050534725189209 	 0.3004765510559082 	 0.295867919921875 	 0.28433918952941895 	 0.4540989398956299 	 0.45481038093566895 	 0.4003026485443115 	 0.38559579849243164 	 
2025-07-25 18:28:18.267793 test begin: paddle.nn.functional.mish(Tensor([12, 512, 414, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 512, 414, 20],"float32"), ) 	 50872320 	 1000 	 0.30504727363586426 	 0.30047011375427246 	 0.2959737777709961 	 0.28447771072387695 	 0.45416879653930664 	 0.4547584056854248 	 0.39923620223999023 	 0.3852105140686035 	 
2025-07-25 18:28:21.486292 test begin: paddle.nn.functional.mish(Tensor([125, 256, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([125, 256, 40, 40],"float32"), ) 	 51200000 	 1000 	 0.30757832527160645 	 0.30746030807495117 	 0.29792332649230957 	 0.286517858505249 	 0.45716190338134766 	 0.45787787437438965 	 0.4028646945953369 	 0.38895583152770996 	 
2025-07-25 18:28:24.718860 test begin: paddle.nn.functional.mish(Tensor([249, 128, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([249, 128, 40, 40],"float32"), ) 	 50995200 	 1000 	 0.30788373947143555 	 0.3012113571166992 	 0.29808783531188965 	 0.28554868698120117 	 0.4553334712982178 	 0.4558684825897217 	 0.4005730152130127 	 0.3866081237792969 	 
2025-07-25 18:28:27.947203 test begin: paddle.nn.functional.mish(Tensor([249, 512, 20, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([249, 512, 20, 20],"float32"), ) 	 50995200 	 1000 	 0.3091151714324951 	 0.30123281478881836 	 0.2968127727508545 	 0.28547120094299316 	 0.4549236297607422 	 0.4558987617492676 	 0.3998534679412842 	 0.386519193649292 	 
2025-07-25 18:28:31.170657 test begin: paddle.nn.functional.mse_loss(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), "mean", ) 	 101608320 	 1000 	 0.8937122821807861 	 0.5987818241119385 	 0.22806191444396973 	 0.2036271095275879 	 1.0591919422149658 	 1.16021728515625 	 0.36096954345703125 	 0.29654932022094727 	 
2025-07-25 18:28:37.548404 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), "mean", ) 	 101671488 	 1000 	 0.8999910354614258 	 0.599090576171875 	 0.22815370559692383 	 0.2037348747253418 	 1.0600380897521973 	 1.1607248783111572 	 0.3613109588623047 	 0.296489953994751 	 
2025-07-25 18:28:43.899283 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", )
/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Using a target size (torch.Size([3548, 12, 170, 8])) that is different to the input size (torch.Size([3548, 12, 170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", ) 	 65141280 	 1000 	 0.8648817539215088 	 0.5752902030944824 	 0.22061467170715332 	 0.1956923007965088 	 1.546405553817749 	 1.6174650192260742 	 0.3951873779296875 	 0.3308734893798828 	 
2025-07-25 18:28:49.614644 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), "mean", )
/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Using a target size (torch.Size([3548, 12, 170, 1])) that is different to the input size (torch.Size([3548, 12, 170, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), "mean", ) 	 65141280 	 1000 	 0.8651530742645264 	 0.5756394863128662 	 0.22079968452453613 	 0.19552373886108398 	 1.1365571022033691 	 1.6180641651153564 	 0.38735008239746094 	 0.3309621810913086 	 
2025-07-25 18:28:54.906722 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", ) 	 115806720 	 1000 	 1.0162978172302246 	 0.7095232009887695 	 0.2593679428100586 	 0.2413482666015625 	 1.2063002586364746 	 1.3185174465179443 	 0.41117262840270996 	 0.33681154251098633 	 
2025-07-25 18:29:01.073221 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), "mean", ) 	 102537200 	 1000 	 0.9015848636627197 	 0.6098790168762207 	 0.23003745079040527 	 0.20537519454956055 	 1.0688450336456299 	 1.1701903343200684 	 0.3642578125 	 0.29892587661743164 	 
2025-07-25 18:29:06.610679 test begin: paddle.nn.functional.mse_loss(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), "none", ) 	 101646336 	 1000 	 0.9873466491699219 	 0.4539909362792969 	 0.38108372688293457 	 0.41094422340393066 	 0.9238317012786865 	 1.4459233283996582 	 0.4719831943511963 	 0.36930322647094727 	 
2025-07-25 18:29:15.740173 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), "none", ) 	 101670912 	 1000 	 0.7462806701660156 	 0.4471263885498047 	 0.38126158714294434 	 0.4232509136199951 	 0.9247770309448242 	 1.446138858795166 	 0.47247743606567383 	 0.3695206642150879 	 
2025-07-25 18:29:22.009108 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), "none", ) 	 101744640 	 1000 	 0.7469232082366943 	 0.447357177734375 	 0.3815751075744629 	 0.4151933193206787 	 0.9249513149261475 	 1.4474055767059326 	 0.47257184982299805 	 0.3697810173034668 	 
2025-07-25 18:29:28.159263 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), "none", ) 	 103809024 	 1000 	 0.7617177963256836 	 0.45630955696105957 	 0.38913726806640625 	 0.4289698600769043 	 0.9447743892669678 	 1.4762928485870361 	 0.48272275924682617 	 0.37738490104675293 	 
2025-07-25 18:29:34.473481 test begin: paddle.nn.functional.mse_loss(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), "none", ) 	 103809024 	 1000 	 0.7677719593048096 	 0.47118711471557617 	 0.3891334533691406 	 0.42452001571655273 	 0.9449923038482666 	 1.476278305053711 	 0.48279404640197754 	 0.37703680992126465 	 
2025-07-25 18:29:42.269278 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), "none", ) 	 104857600 	 1000 	 0.7829568386077881 	 0.4639458656311035 	 0.3929324150085449 	 0.43666529655456543 	 0.9512815475463867 	 1.4908010959625244 	 0.4860396385192871 	 0.3807539939880371 	 
2025-07-25 18:29:48.715788 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), "none", ) 	 101646336 	 1000 	 0.7457902431488037 	 0.44697046279907227 	 0.3810617923736572 	 0.42317748069763184 	 0.9234123229980469 	 1.446169137954712 	 0.471757173538208 	 0.36939048767089844 	 
2025-07-25 18:29:54.787208 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), "none", ) 	 101646336 	 1000 	 0.7458600997924805 	 0.4485347270965576 	 0.38103294372558594 	 0.42234301567077637 	 0.9246697425842285 	 1.4459147453308105 	 0.4724586009979248 	 0.36934971809387207 	 
2025-07-25 18:30:00.952497 test begin: paddle.nn.functional.mse_loss(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), "none", ) 	 101744640 	 1000 	 0.746661901473999 	 0.4473583698272705 	 0.3814365863800049 	 0.42317843437194824 	 0.9248144626617432 	 1.4473299980163574 	 0.47251248359680176 	 0.36977076530456543 	 
2025-07-25 18:30:07.065358 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=None, ) 	 50803210 	 1000 	 3.372227430343628 	 3.3348183631896973 	 0.31307148933410645 	 0.28261351585388184 	 4.63322639465332 	 4.300436019897461 	 0.3652796745300293 	 0.338698148727417 	 
2025-07-25 18:30:24.629441 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=Tensor([5, 5080321],"float64"), )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=Tensor([5, 5080321],"float64"), ) 	 76204815 	 1000 	 3.817462682723999 	 3.767075777053833 	 0.3247101306915283 	 0.29563188552856445 	 5.378406524658203 	 5.062588214874268 	 0.3925955295562744 	 0.3451089859008789 	 
2025-07-25 18:30:46.686930 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), weight=Tensor([5, 5080321],"float64"), reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), weight=Tensor([5, 5080321],"float64"), reduction="mean", name=None, ) 	 76204815 	 1000 	 3.8179683685302734 	 3.7668590545654297 	 0.32466769218444824 	 0.29563379287719727 	 5.379585266113281 	 5.062469720840454 	 0.3926558494567871 	 0.3451409339904785 	 
2025-07-25 18:31:07.693861 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=None, ) 	 50803210 	 1000 	 3.394585371017456 	 3.486077308654785 	 0.31490206718444824 	 0.2964146137237549 	 4.715377569198608 	 4.45677924156189 	 0.3717460632324219 	 0.3509087562561035 	 
2025-07-25 18:31:27.252591 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=Tensor([5080321, 5],"float64"), )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=Tensor([5080321, 5],"float64"), ) 	 76204815 	 1000 	 3.838346004486084 	 3.936316967010498 	 0.32631921768188477 	 0.3087139129638672 	 5.46492338180542 	 5.211315393447876 	 0.3989238739013672 	 0.3552417755126953 	 
2025-07-25 18:31:49.612086 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), weight=Tensor([5080321, 5],"float64"), reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), weight=Tensor([5080321, 5],"float64"), reduction="mean", name=None, ) 	 76204815 	 1000 	 3.838301658630371 	 3.9307572841644287 	 0.32630038261413574 	 0.3086080551147461 	 5.464908838272095 	 5.211329698562622 	 0.3989124298095703 	 0.3552262783050537 	 
2025-07-25 18:32:09.742551 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
W0725 18:32:10.419201 126004 dygraph_functions.cc:93089] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 38102403 	 1000 	 3.87223744392395 	 16.25368571281433 	 0.00017833709716796875 	 5.526402711868286 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:32:34.907170 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 38102403 	 1000 	 3.8009212017059326 	 16.175596475601196 	 0.00014066696166992188 	 16.1488356590271 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:33:02.488256 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 38102403 	 1000 	 3.874333620071411 	 16.257004261016846 	 0.00019431114196777344 	 5.527075529098511 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:33:27.638408 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 76204803 	 1000 	 7.534106731414795 	 32.48906135559082 	 0.00040435791015625 	 11.046358346939087 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:34:17.502605 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 76204803 	 1000 	 7.398030996322632 	 32.72839641571045 	 0.0002703666687011719 	 32.28778266906738 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:35:09.223980 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 76204803 	 1000 	 7.533772945404053 	 32.486013412475586 	 0.0003910064697265625 	 11.045367956161499 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:35:59.089660 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 25401610 	 1000 	 1.334303379058838 	 6.035441160202026 	 4.863739013671875e-05 	 3.083491325378418 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:36:09.363142 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 25401610 	 1000 	 1.287691354751587 	 6.038944244384766 	 2.2411346435546875e-05 	 6.020777463912964 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:36:19.608819 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 25401610 	 1000 	 1.321678876876831 	 6.042835235595703 	 2.2172927856445312e-05 	 3.088684558868408 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:36:29.867143 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, ) 	 25443143 	 1000 	 0.028743267059326172 	 0.039606571197509766 	 2.3603439331054688e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:36:30.627115 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, ) 	 25443143 	 1000 	 0.03046250343322754 	 0.025763988494873047 	 4.744529724121094e-05 	 4.172325134277344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:36:31.390231 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="sum", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="sum", name=None, ) 	 25443143 	 1000 	 0.025827407836914062 	 0.034626007080078125 	 1.5020370483398438e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:36:32.147080 test begin: paddle.nn.functional.normalize(Tensor([2009, 25288],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2009, 25288],"float32"), ) 	 50803592 	 1000 	 0.473966121673584 	 1.2435126304626465 	 0.09694814682006836 	 0.15985321998596191 	 2.681009531021118 	 3.202430248260498 	 0.548802375793457 	 0.23375940322875977 	 
2025-07-25 18:36:43.164110 test begin: paddle.nn.functional.normalize(Tensor([2081, 24413],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2081, 24413],"float32"), ) 	 50803453 	 1000 	 0.47488951683044434 	 0.47122740745544434 	 0.09714984893798828 	 0.16048574447631836 	 2.681427478790283 	 3.203324556350708 	 0.5489554405212402 	 0.23380684852600098 	 
2025-07-25 18:36:51.835270 test begin: paddle.nn.functional.normalize(Tensor([2331, 21795],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2331, 21795],"float32"), ) 	 50804145 	 1000 	 0.46936583518981934 	 0.4867892265319824 	 0.09591913223266602 	 0.16029858589172363 	 2.6814870834350586 	 3.203199863433838 	 0.5488884449005127 	 0.23380160331726074 	 
2025-07-25 18:37:01.724667 test begin: paddle.nn.functional.normalize(Tensor([99226, 512],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([99226, 512],"float32"), ) 	 50803712 	 1000 	 0.4884006977081299 	 0.46750617027282715 	 0.09985733032226562 	 0.1592237949371338 	 2.7163209915161133 	 3.212589979171753 	 0.5560958385467529 	 0.23450946807861328 	 
2025-07-25 18:37:10.324284 test begin: paddle.nn.functional.npair_loss(Tensor([18, 2822401],"float32"), positive=Tensor([18, 2822401],"float32"), labels=Tensor([18],"float32"), l2_reg=0.002, )
[Prof] paddle.nn.functional.npair_loss 	 paddle.nn.functional.npair_loss(Tensor([18, 2822401],"float32"), positive=Tensor([18, 2822401],"float32"), labels=Tensor([18],"float32"), l2_reg=0.002, ) 	 101606454 	 1000 	 1.466857671737671 	 1.4152131080627441 	 0.06254959106445312 	 0.07206010818481445 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 18:37:18.082465 test begin: paddle.nn.functional.pad(Tensor([7573, 11, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7573, 11, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 106627840 	 1000 	 1.2363371849060059 	 0.46883726119995117 	 1.22511625289917 	 0.15966176986694336 	 0.9864587783813477 	 0.8024189472198486 	 0.929858922958374 	 0.27309560775756836 	 
2025-07-25 18:37:25.192189 test begin: paddle.nn.functional.pad(Tensor([7573, 8, 1678],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7573, 8, 1678],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 101659952 	 1000 	 1.1789851188659668 	 0.4475066661834717 	 1.16717529296875 	 0.1524200439453125 	 0.9408214092254639 	 0.765413761138916 	 0.8834948539733887 	 0.2605102062225342 	 
2025-07-25 18:37:32.023514 test begin: paddle.nn.functional.pad(Tensor([7710, 11, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7710, 11, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 108556800 	 1000 	 1.2580232620239258 	 0.48680591583251953 	 1.2464559078216553 	 0.16257548332214355 	 1.0043833255767822 	 0.8164365291595459 	 0.947922945022583 	 0.2778294086456299 	 
2025-07-25 18:37:40.975235 test begin: paddle.nn.functional.pad(Tensor([7710, 8, 1648],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7710, 8, 1648],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 101648640 	 1000 	 1.1800808906555176 	 0.44734954833984375 	 1.167208194732666 	 0.15231537818908691 	 0.9406375885009766 	 0.765261173248291 	 0.8842551708221436 	 0.26046180725097656 	 
2025-07-25 18:37:47.821139 test begin: paddle.nn.functional.pad(Tensor([8162, 10, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([8162, 10, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 104473600 	 1000 	 1.2120940685272217 	 0.4596428871154785 	 1.2002949714660645 	 0.1565244197845459 	 0.9667713642120361 	 0.7866425514221191 	 0.909625768661499 	 0.26776981353759766 	 
2025-07-25 18:37:54.771021 test begin: paddle.nn.functional.pad(Tensor([8162, 8, 1557],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([8162, 8, 1557],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 101665872 	 1000 	 1.1830785274505615 	 0.45726966857910156 	 1.1669304370880127 	 0.1524977684020996 	 0.9409654140472412 	 0.7655956745147705 	 0.8833999633789062 	 0.260545015335083 	 
2025-07-25 18:38:04.602247 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1794350147247314 	 0.4446721076965332 	 1.167649745941162 	 0.22713398933410645 	 0.9403538703918457 	 0.7619867324829102 	 0.8841450214385986 	 0.3893105983734131 	 
2025-07-25 18:38:11.474250 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1794171333312988 	 0.44545459747314453 	 1.1674902439117432 	 0.22711753845214844 	 0.9403486251831055 	 0.7619571685791016 	 0.8811805248260498 	 0.3893008232116699 	 
2025-07-25 18:38:18.249102 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1791572570800781 	 0.4447140693664551 	 1.167358160018921 	 0.2271277904510498 	 0.9402856826782227 	 0.7622902393341064 	 0.8833651542663574 	 0.3894221782684326 	 
2025-07-25 18:38:25.186005 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, False, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, False, None, ) 	 101606600 	 1000 	 1.1411569118499756 	 1.062697172164917 	 0.19400334358215332 	 0.27132606506347656 	 1.893712043762207 	 2.77474045753479 	 0.9675595760345459 	 0.2836031913757324 	 
2025-07-25 18:38:33.935159 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, True, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, True, None, ) 	 101606600 	 1000 	 1.1569063663482666 	 1.062955617904663 	 0.19391775131225586 	 0.2713906764984131 	 1.8950450420379639 	 2.7748825550079346 	 0.9682581424713135 	 0.28365063667297363 	 
2025-07-25 18:38:44.146716 test begin: paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, False, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, False, None, ) 	 101606600 	 1000 	 1.5257701873779297 	 1.6454434394836426 	 0.3120434284210205 	 0.5606956481933594 	 1.9824182987213135 	 2.7860608100891113 	 1.0129671096801758 	 0.28473472595214844 	 
2025-07-25 18:38:53.978601 test begin: paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, True, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, True, None, ) 	 101606600 	 1000 	 1.5257823467254639 	 1.6452562808990479 	 0.31205129623413086 	 0.5606250762939453 	 1.982564926147461 	 2.7860567569732666 	 1.0130281448364258 	 0.2848029136657715 	 
2025-07-25 18:39:03.664292 test begin: paddle.nn.functional.pixel_shuffle(Tensor([13, 256, 128, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([13, 256, 128, 128],"float32"), 2, "NCHW", None, ) 	 54525952 	 1000 	 0.4104349613189697 	 0.3599705696105957 	 0.38939452171325684 	 0.3245108127593994 	 0.3956587314605713 	 0.3430924415588379 	 0.32843995094299316 	 0.25944972038269043 	 
2025-07-25 18:39:09.451284 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 128, 388],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 128, 388],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.37476587295532227 	 0.33808422088623047 	 0.3640711307525635 	 0.31380558013916016 	 0.4020252227783203 	 0.32523059844970703 	 0.34524011611938477 	 0.2502131462097168 	 
2025-07-25 18:39:12.593873 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 388, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 388, 128],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.3828144073486328 	 0.33405423164367676 	 0.37284016609191895 	 0.3155086040496826 	 0.399824857711792 	 0.3223707675933838 	 0.345386266708374 	 0.2434532642364502 	 
2025-07-25 18:39:15.711896 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 776, 128, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 776, 128, 128],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.37799811363220215 	 0.3282649517059326 	 0.3679382801055908 	 0.30957984924316406 	 0.3678250312805176 	 0.32033300399780273 	 0.31548500061035156 	 0.24668192863464355 	 
2025-07-25 18:39:18.810974 test begin: paddle.nn.functional.pixel_shuffle(Tensor([49, 256, 64, 64],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([49, 256, 64, 64],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.386660099029541 	 0.3351578712463379 	 0.3766133785247803 	 0.3086516857147217 	 0.36614179611206055 	 0.32771992683410645 	 0.312821626663208 	 0.24994373321533203 	 
2025-07-25 18:39:21.934261 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 128, 25],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 128, 25],"float32"), 2, "NCHW", None, ) 	 52428800 	 1000 	 0.385897159576416 	 0.340177059173584 	 0.37590670585632324 	 0.3215291500091553 	 0.3908836841583252 	 0.34163451194763184 	 0.3386542797088623 	 0.26571083068847656 	 
2025-07-25 18:39:25.172756 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 25, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 25, 128],"float32"), 2, "NCHW", None, ) 	 52428800 	 1000 	 0.3939669132232666 	 0.33884096145629883 	 0.38390421867370605 	 0.3111836910247803 	 0.37972426414489746 	 0.32224464416503906 	 0.3210775852203369 	 0.24527573585510254 	 
2025-07-25 18:39:28.379727 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 49, 64],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 49, 64],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.38604116439819336 	 0.33657336235046387 	 0.3757474422454834 	 0.3164968490600586 	 0.3668503761291504 	 0.31888365745544434 	 0.3117711544036865 	 0.2443554401397705 	 
2025-07-25 18:39:31.508216 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 64, 49],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 64, 49],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.3781914710998535 	 0.33408522605895996 	 0.3681046962738037 	 0.3118288516998291 	 0.376800537109375 	 0.3334391117095947 	 0.322559118270874 	 0.25005269050598145 	 
2025-07-25 18:39:34.733366 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", ) 	 25401744 	 1000 	 0.9870314598083496 	 0.5426220893859863 	 0.3061690330505371 	 0.28232741355895996 	 0.3163299560546875 	 0.3022346496582031 	 0.2516164779663086 	 0.22530531883239746 	 
2025-07-25 18:39:40.366779 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", None, ) 	 25401744 	 1000 	 0.3176703453063965 	 0.30210137367248535 	 0.2995729446411133 	 0.27561306953430176 	 0.3163266181945801 	 0.3021688461303711 	 0.25310301780700684 	 0.21842551231384277 	 
2025-07-25 18:39:42.704270 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 176401, 12, 12],"float32"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 176401, 12, 12],"float32"), 3, "NCHW", ) 	 50803488 	 1000 	 0.36689209938049316 	 0.3272693157196045 	 0.34860777854919434 	 0.29996228218078613 	 0.36283040046691895 	 0.32305407524108887 	 0.2963986396789551 	 0.24195528030395508 	 
2025-07-25 18:39:45.808733 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", ) 	 25401888 	 1000 	 0.3176150321960449 	 0.3075294494628906 	 0.299405574798584 	 0.27555012702941895 	 0.31645989418029785 	 0.302229642868042 	 0.2524561882019043 	 0.2184617519378662 	 
2025-07-25 18:39:48.177815 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", None, ) 	 25401888 	 1000 	 0.31771397590637207 	 0.3021411895751953 	 0.2984800338745117 	 0.2757439613342285 	 0.31645941734313965 	 0.3022022247314453 	 0.2553079128265381 	 0.21421146392822266 	 
2025-07-25 18:39:50.522820 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([352801, 1, 12, 12],"float32"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([352801, 1, 12, 12],"float32"), 3, "NCHW", ) 	 50803344 	 1000 	 0.36763525009155273 	 0.32878971099853516 	 0.34851527214050293 	 0.2998921871185303 	 0.36272168159484863 	 0.32309436798095703 	 0.2907707691192627 	 0.23657608032226562 	 
2025-07-25 18:39:53.663204 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"bfloat16"), )
W0725 18:39:56.790491 131265 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"bfloat16"), ) 	 203212812 	 1000 	 3.1499252319335938 	 2.593693733215332 	 0.5356507301330566 	 0.5294320583343506 	 5.694979906082153 	 4.8103554248809814 	 0.9695823192596436 	 0.7022948265075684 	 
2025-07-25 18:40:14.682024 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"float16"), ) 	 203212812 	 1000 	 3.1489646434783936 	 2.588567018508911 	 0.5356125831604004 	 0.5283792018890381 	 5.698041200637817 	 4.8074140548706055 	 0.9699652194976807 	 0.7018623352050781 	 
2025-07-25 18:40:34.633069 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"bfloat16"), ) 	 203212816 	 1000 	 3.153002977371216 	 2.5925228595733643 	 0.5356850624084473 	 0.529151201248169 	 5.7012410163879395 	 4.810442924499512 	 0.9707362651824951 	 0.7023167610168457 	 
2025-07-25 18:40:55.711162 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"float16"), ) 	 203212816 	 1000 	 3.1491191387176514 	 2.5901272296905518 	 0.5356943607330322 	 0.5283846855163574 	 5.697423696517944 	 4.807604074478149 	 0.9700038433074951 	 0.7018609046936035 	 
2025-07-25 18:41:17.587732 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 1.6719744205474854 	 1.0689260959625244 	 0.2435588836669922 	 0.2181868553161621 	 2.2719643115997314 	 2.170159339904785 	 0.3317229747772217 	 0.2773168087005615 	 
2025-07-25 18:41:27.672025 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"bfloat16"), ) 	 101606424 	 1000 	 1.5908567905426025 	 1.3131563663482666 	 0.26975560188293457 	 0.26801562309265137 	 2.8677334785461426 	 2.4211747646331787 	 0.4881627559661865 	 0.3534553050994873 	 
2025-07-25 18:41:40.669328 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float16"), ) 	 101606424 	 1000 	 1.5879604816436768 	 1.311086893081665 	 0.26985883712768555 	 0.2676565647125244 	 2.8668766021728516 	 2.4188220500946045 	 0.48784875869750977 	 0.3531646728515625 	 
2025-07-25 18:41:50.735198 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), ) 	 101606424 	 1000 	 3.309069871902466 	 2.103083610534668 	 0.4830915927886963 	 0.4293937683105469 	 4.515233278274536 	 4.299166440963745 	 0.6592397689819336 	 0.5493814945220947 	 
2025-07-25 18:42:07.028886 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"bfloat16"), ) 	 203212824 	 1000 	 3.1499412059783936 	 2.5924205780029297 	 0.535696268081665 	 0.5291333198547363 	 5.697144269943237 	 4.81023907661438 	 0.9698634147644043 	 0.7022757530212402 	 
2025-07-25 18:42:27.719214 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"float16"), ) 	 203212824 	 1000 	 3.1487367153167725 	 2.5946743488311768 	 0.535588264465332 	 0.528679609298706 	 5.6974077224731445 	 4.807701826095581 	 0.9701812267303467 	 0.7018873691558838 	 
2025-07-25 18:42:48.336218 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 1.6681926250457764 	 1.0690269470214844 	 0.24361276626586914 	 0.21827220916748047 	 2.271883487701416 	 2.1701204776763916 	 0.3316807746887207 	 0.27733850479125977 	 
2025-07-25 18:42:56.536177 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"bfloat16"), ) 	 101606416 	 1000 	 1.5864894390106201 	 1.3141708374023438 	 0.26982712745666504 	 0.26827049255371094 	 2.8644814491271973 	 2.420280933380127 	 0.48754358291625977 	 0.3533482551574707 	 
2025-07-25 18:43:06.465114 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float16"), ) 	 101606416 	 1000 	 1.5871045589447021 	 1.3112199306488037 	 0.26981639862060547 	 0.2677185535430908 	 2.8659563064575195 	 2.4189093112945557 	 0.4879119396209717 	 0.35314011573791504 	 
2025-07-25 18:43:16.579114 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), ) 	 101606416 	 1000 	 3.3093504905700684 	 2.1012282371520996 	 0.4832026958465576 	 0.4289712905883789 	 4.515348434448242 	 4.299402713775635 	 0.6591987609863281 	 0.5494072437286377 	 
2025-07-25 18:43:33.630269 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 1.6682841777801514 	 1.0701563358306885 	 0.24359488487243652 	 0.21825075149536133 	 2.2721219062805176 	 2.1701126098632812 	 0.33162569999694824 	 0.2773163318634033 	 
2025-07-25 18:43:43.476473 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"bfloat16"), ) 	 101606412 	 1000 	 1.5865676403045654 	 1.3130497932434082 	 0.26985597610473633 	 0.26805567741394043 	 2.864717960357666 	 2.4201645851135254 	 0.48772501945495605 	 0.35332226753234863 	 
2025-07-25 18:43:53.388123 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float16"), ) 	 101606412 	 1000 	 1.5860545635223389 	 1.3110957145690918 	 0.2697889804840088 	 0.2676408290863037 	 2.8656814098358154 	 2.418935775756836 	 0.48787903785705566 	 0.3531792163848877 	 
2025-07-25 18:44:03.501630 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), ) 	 101606412 	 1000 	 3.309920310974121 	 2.1010971069335938 	 0.48319149017333984 	 0.42893075942993164 	 4.515003442764282 	 4.298953294754028 	 0.6591689586639404 	 0.5493669509887695 	 
2025-07-25 18:44:19.815242 test begin: paddle.nn.functional.prelu(Tensor([104, 128, 56, 69],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 128, 56, 69],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51437696 	 1000 	 0.3053572177886963 	 0.31932687759399414 	 0.2826359272003174 	 0.28957629203796387 	 1.1007423400878906 	 0.796875 	 0.3743879795074463 	 0.2710702419281006 	 
2025-07-25 18:44:24.073058 test begin: paddle.nn.functional.prelu(Tensor([104, 128, 69, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 128, 69, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51437696 	 1000 	 0.3073906898498535 	 0.31265830993652344 	 0.28804731369018555 	 0.2897980213165283 	 1.1009502410888672 	 0.796297550201416 	 0.37438368797302246 	 0.27086472511291504 	 
2025-07-25 18:44:28.524732 test begin: paddle.nn.functional.prelu(Tensor([104, 156, 56, 56],"float32"), Tensor([156],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 156, 56, 56],"float32"), Tensor([156],"float32"), data_format="NCHW", ) 	 50878620 	 1000 	 0.3074924945831299 	 0.3092622756958008 	 0.2765367031097412 	 0.2937202453613281 	 1.0829944610595703 	 0.7934963703155518 	 0.36832284927368164 	 0.26994967460632324 	 
2025-07-25 18:44:32.759356 test begin: paddle.nn.functional.prelu(Tensor([127, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([127, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 50978944 	 1000 	 0.529599666595459 	 0.3157193660736084 	 0.28235888481140137 	 0.2934300899505615 	 1.088395357131958 	 0.7875518798828125 	 0.37018418312072754 	 0.26787233352661133 	 
2025-07-25 18:44:40.366497 test begin: paddle.nn.functional.prelu(Tensor([128, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51380352 	 1000 	 1.082524061203003 	 0.31423354148864746 	 0.291644811630249 	 0.2965817451477051 	 1.0948665142059326 	 0.7938187122344971 	 0.37241077423095703 	 0.26999568939208984 	 
2025-07-25 18:44:45.557981 test begin: paddle.nn.functional.prelu(Tensor([128, 256, 28, 56],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 256, 28, 56],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 51380480 	 1000 	 0.30429768562316895 	 0.31320619583129883 	 0.29152464866638184 	 0.29660606384277344 	 1.0946910381317139 	 0.7937355041503906 	 0.3723874092102051 	 0.2700083255767822 	 
2025-07-25 18:44:49.863363 test begin: paddle.nn.functional.prelu(Tensor([128, 256, 56, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 256, 56, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 51380480 	 1000 	 0.3042416572570801 	 0.3121633529663086 	 0.29144835472106934 	 0.2963685989379883 	 1.0946218967437744 	 0.7946386337280273 	 0.3723316192626953 	 0.2703745365142822 	 
2025-07-25 18:44:54.196640 test begin: paddle.nn.functional.prelu(Tensor([128, 507, 28, 28],"float32"), Tensor([507],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 507, 28, 28],"float32"), Tensor([507],"float32"), data_format="NCHW", ) 	 50878971 	 1000 	 0.3014676570892334 	 0.30922389030456543 	 0.28910326957702637 	 0.29334068298339844 	 1.0751588344573975 	 0.7799046039581299 	 0.3657257556915283 	 0.39835429191589355 	 
2025-07-25 18:44:58.346598 test begin: paddle.nn.functional.prelu(Tensor([254, 256, 28, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([254, 256, 28, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 50979072 	 1000 	 0.30212950706481934 	 0.3097820281982422 	 0.2830028533935547 	 0.2937307357788086 	 1.0890326499938965 	 0.7893569469451904 	 0.37044620513916016 	 0.2685561180114746 	 
2025-07-25 18:45:02.545118 test begin: paddle.nn.functional.relu(Tensor([10, 128, 480, 83],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 128, 480, 83],"float32"), None, ) 	 50995200 	 1000 	 0.2975349426269531 	 0.3008615970611572 	 0.28808069229125977 	 0.2825791835784912 	 0.452073335647583 	 0.4483637809753418 	 0.3974030017852783 	 0.37783169746398926 	 
2025-07-25 18:45:05.772176 test begin: paddle.nn.functional.relu(Tensor([10, 128, 83, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 128, 83, 480],"float32"), None, ) 	 50995200 	 1000 	 0.29689574241638184 	 0.2990117073059082 	 0.2879819869995117 	 0.28298282623291016 	 0.45194458961486816 	 0.4483931064605713 	 0.3964807987213135 	 0.3800013065338135 	 
2025-07-25 18:45:08.967198 test begin: paddle.nn.functional.relu(Tensor([10, 23, 480, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 23, 480, 480],"float32"), None, ) 	 52992000 	 1000 	 0.30844593048095703 	 0.3106498718261719 	 0.29959964752197266 	 0.2937452793121338 	 0.4694845676422119 	 0.46572446823120117 	 0.415513277053833 	 0.39766955375671387 	 
2025-07-25 18:45:12.280110 test begin: paddle.nn.functional.relu(Tensor([2, 128, 480, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([2, 128, 480, 480],"float32"), None, ) 	 58982400 	 1000 	 0.34287571907043457 	 0.34721922874450684 	 0.33382081985473633 	 0.32904839515686035 	 0.522052526473999 	 0.5179696083068848 	 0.4678516387939453 	 0.44945216178894043 	 
2025-07-25 18:45:16.018822 test begin: paddle.nn.functional.relu(Tensor([2, 256, 352, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([2, 256, 352, 352],"float32"), ) 	 63438848 	 1000 	 0.3707091808319092 	 0.3714902400970459 	 0.3588230609893799 	 0.35461974143981934 	 0.5610489845275879 	 0.5566532611846924 	 0.502795934677124 	 0.4884817600250244 	 
2025-07-25 18:45:20.026715 test begin: paddle.nn.functional.relu(Tensor([64, 64, 112, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([64, 64, 112, 112],"float32"), None, ) 	 51380224 	 1000 	 0.29917120933532715 	 0.30125999450683594 	 0.29027700424194336 	 0.2843935489654541 	 0.45546531677246094 	 0.45168113708496094 	 0.40016627311706543 	 0.37856006622314453 	 
2025-07-25 18:45:23.289081 test begin: paddle.nn.functional.relu(Tensor([640, 64, 112, 12],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 64, 112, 12],"float32"), None, ) 	 55050240 	 1000 	 0.3201413154602051 	 0.32451629638671875 	 0.3112068176269531 	 0.30635905265808105 	 0.4874553680419922 	 0.4834713935852051 	 0.4329495429992676 	 0.41417574882507324 	 
2025-07-25 18:45:26.786408 test begin: paddle.nn.functional.relu(Tensor([640, 64, 12, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 64, 12, 112],"float32"), None, ) 	 55050240 	 1000 	 0.3201298713684082 	 0.32233643531799316 	 0.31096553802490234 	 0.3063511848449707 	 0.48741650581359863 	 0.4834935665130615 	 0.429854154586792 	 0.41530513763427734 	 
2025-07-25 18:45:30.251139 test begin: paddle.nn.functional.relu(Tensor([640, 7, 112, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 7, 112, 112],"float32"), None, ) 	 56197120 	 1000 	 0.3268256187438965 	 0.332777738571167 	 0.3179349899291992 	 0.31259655952453613 	 0.49755096435546875 	 0.49362850189208984 	 0.4374537467956543 	 0.42515993118286133 	 
2025-07-25 18:45:33.788159 test begin: paddle.nn.functional.relu(Tensor([8, 256, 352, 71],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 256, 352, 71],"float32"), ) 	 51183616 	 1000 	 0.2980473041534424 	 0.3103609085083008 	 0.289264440536499 	 0.28387880325317383 	 0.45371222496032715 	 0.4499471187591553 	 0.3993217945098877 	 0.3822214603424072 	 
2025-07-25 18:45:39.393020 test begin: paddle.nn.functional.relu(Tensor([8, 256, 71, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 256, 71, 352],"float32"), ) 	 51183616 	 1000 	 0.30136585235595703 	 0.3000221252441406 	 0.28909730911254883 	 0.28423404693603516 	 0.45371246337890625 	 0.4500598907470703 	 0.39876413345336914 	 0.3728489875793457 	 
2025-07-25 18:45:42.605877 test begin: paddle.nn.functional.relu(Tensor([8, 52, 352, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 52, 352, 352],"float32"), ) 	 51544064 	 1000 	 1.5962467193603516 	 0.312314510345459 	 0.2912425994873047 	 0.2860143184661865 	 0.45687079429626465 	 0.4530487060546875 	 0.40196895599365234 	 0.38357019424438477 	 
2025-07-25 18:45:49.297939 test begin: paddle.nn.functional.relu6(Tensor([128, 144, 112, 25],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 144, 112, 25],"float32"), ) 	 51609600 	 1000 	 0.3008413314819336 	 0.30259013175964355 	 0.2914600372314453 	 0.2838592529296875 	 0.45731186866760254 	 0.4536857604980469 	 0.3956773281097412 	 0.37848377227783203 	 
2025-07-25 18:45:52.648502 test begin: paddle.nn.functional.relu6(Tensor([128, 144, 25, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 144, 25, 112],"float32"), ) 	 51609600 	 1000 	 0.3004636764526367 	 0.3025655746459961 	 0.2913639545440674 	 0.2836730480194092 	 0.45741772651672363 	 0.45370006561279297 	 0.40189123153686523 	 0.38417506217956543 	 
2025-07-25 18:45:55.917263 test begin: paddle.nn.functional.relu6(Tensor([128, 192, 112, 19],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 192, 112, 19],"float32"), ) 	 52297728 	 1000 	 0.30433011054992676 	 0.30648016929626465 	 0.2948033809661865 	 0.2880985736846924 	 0.46326208114624023 	 0.45960545539855957 	 0.3968992233276367 	 0.3921339511871338 	 
2025-07-25 18:45:59.185308 test begin: paddle.nn.functional.relu6(Tensor([128, 192, 19, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 192, 19, 112],"float32"), ) 	 52297728 	 1000 	 0.3042943477630615 	 0.30646491050720215 	 0.295196533203125 	 0.2858750820159912 	 0.463423490524292 	 0.45963501930236816 	 0.40987396240234375 	 0.39130163192749023 	 
2025-07-25 18:46:02.447452 test begin: paddle.nn.functional.relu6(Tensor([128, 32, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 32, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.2991805076599121 	 0.3013033866882324 	 0.28998565673828125 	 0.28095078468322754 	 0.4553542137145996 	 0.45175933837890625 	 0.3820457458496094 	 0.38327550888061523 	 
2025-07-25 18:46:05.673306 test begin: paddle.nn.functional.relu6(Tensor([22, 192, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([22, 192, 112, 112],"float32"), ) 	 52985856 	 1000 	 0.3084068298339844 	 0.3105747699737549 	 0.2992734909057617 	 0.29172372817993164 	 0.46935319900512695 	 0.46562719345092773 	 0.4140627384185791 	 0.3980143070220947 	 
2025-07-25 18:46:09.027142 test begin: paddle.nn.functional.relu6(Tensor([256, 16, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 16, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.30023622512817383 	 0.30124568939208984 	 0.29009556770324707 	 0.2823827266693115 	 0.4553341865539551 	 0.45174288749694824 	 0.4018087387084961 	 0.3730440139770508 	 
2025-07-25 18:46:12.305780 test begin: paddle.nn.functional.relu6(Tensor([256, 96, 112, 19],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 96, 112, 19],"float32"), ) 	 52297728 	 1000 	 0.3043386936187744 	 0.30651021003723145 	 0.29514265060424805 	 0.28710317611694336 	 0.46332287788391113 	 0.459578275680542 	 0.40975046157836914 	 0.3913419246673584 	 
2025-07-25 18:46:15.619358 test begin: paddle.nn.functional.relu6(Tensor([256, 96, 19, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 96, 19, 112],"float32"), ) 	 52297728 	 1000 	 0.3043053150177002 	 0.3065638542175293 	 0.2953042984008789 	 0.28653597831726074 	 0.4634208679199219 	 0.459580659866333 	 0.40982580184936523 	 0.3933231830596924 	 
2025-07-25 18:46:18.955756 test begin: paddle.nn.functional.relu6(Tensor([29, 144, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([29, 144, 112, 112],"float32"), ) 	 52383744 	 1000 	 0.3056061267852783 	 0.306990385055542 	 0.2957477569580078 	 0.2885875701904297 	 0.4641120433807373 	 0.46038818359375 	 0.4075143337249756 	 0.39279770851135254 	 
2025-07-25 18:46:22.319813 test begin: paddle.nn.functional.relu6(Tensor([43, 96, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([43, 96, 112, 112],"float32"), ) 	 51781632 	 1000 	 0.30142736434936523 	 0.30634617805480957 	 0.292431116104126 	 0.2852816581726074 	 0.4589078426361084 	 0.45524168014526367 	 0.401503324508667 	 0.38625574111938477 	 
2025-07-25 18:46:25.586912 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 4233601],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2, 3, 4233601],"float64"), 0.05, 0.25, training=False, ) 	 25401606 	 1000 	 0.481264591217041 	 0.2988870143890381 	 0.47075486183166504 	 0.27724647521972656 	 0.58432936668396 	 0.4432539939880371 	 0.5301806926727295 	 0.3739502429962158 	 
2025-07-25 18:46:28.481622 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3175201, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2, 3175201, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401608 	 1000 	 0.48124241828918457 	 0.29877400398254395 	 0.4708526134490967 	 0.277022123336792 	 0.58432936668396 	 0.44318342208862305 	 0.5315852165222168 	 0.3745870590209961 	 
2025-07-25 18:46:31.389393 test begin: paddle.nn.functional.rrelu(Tensor([1, 2116801, 3, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2116801, 3, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401612 	 1000 	 0.4821462631225586 	 0.298795223236084 	 0.47037482261657715 	 0.27699804306030273 	 0.5843732357025146 	 0.44321274757385254 	 0.5262839794158936 	 0.3692643642425537 	 
2025-07-25 18:46:34.317060 test begin: paddle.nn.functional.rrelu(Tensor([1058401, 2, 3, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1058401, 2, 3, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401624 	 1000 	 0.48127245903015137 	 0.30553102493286133 	 0.4636268615722656 	 0.267963171005249 	 0.5848004817962646 	 0.4431726932525635 	 0.5231118202209473 	 0.36959242820739746 	 
2025-07-25 18:46:39.036881 test begin: paddle.nn.functional.rrelu(Tensor([2, 1270081, 4, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 1270081, 4, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803240 	 1000 	 0.4922943115234375 	 0.3081939220428467 	 0.47250795364379883 	 0.2637317180633545 	 0.6033875942230225 	 0.4467282295227051 	 0.5389742851257324 	 0.3766810894012451 	 
2025-07-25 18:46:42.671511 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 1693441, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 1693441, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803230 	 1000 	 0.4899122714996338 	 0.2982289791107178 	 0.4725208282470703 	 0.2537393569946289 	 0.6033661365509033 	 0.44669127464294434 	 0.5416450500488281 	 0.372844934463501 	 
2025-07-25 18:46:46.212876 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 1058401],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 4, 1058401],"float64"), 0.1, 0.3, training=False, ) 	 25401624 	 1000 	 0.48378777503967285 	 0.29882073402404785 	 0.47077345848083496 	 0.2768979072570801 	 0.5842726230621338 	 0.4431030750274658 	 0.5312583446502686 	 0.37646484375 	 
2025-07-25 18:46:50.688941 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 2116801],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 4, 2116801],"float32"), 0.1, 0.3, training=False, ) 	 50803224 	 1000 	 0.7259228229522705 	 0.2992854118347168 	 0.4794290065765381 	 0.2764592170715332 	 0.6033520698547363 	 0.44668078422546387 	 0.5503623485565186 	 0.3705263137817383 	 
2025-07-25 18:46:55.853716 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 846721, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 846721, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401630 	 1000 	 0.48114943504333496 	 0.30118393898010254 	 0.47076869010925293 	 0.2769505977630615 	 0.584326982498169 	 0.44321298599243164 	 0.5310280323028564 	 0.3755764961242676 	 
2025-07-25 18:46:58.768594 test begin: paddle.nn.functional.rrelu(Tensor([2, 635041, 4, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 635041, 4, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401640 	 1000 	 0.4808511734008789 	 0.2987697124481201 	 0.4703495502471924 	 0.2769510746002197 	 0.5842757225036621 	 0.4432075023651123 	 0.5313596725463867 	 0.37509632110595703 	 
2025-07-25 18:47:01.658191 test begin: paddle.nn.functional.rrelu(Tensor([423361, 3, 4, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([423361, 3, 4, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401660 	 1000 	 0.4810049533843994 	 0.29874467849731445 	 0.46562886238098145 	 0.27695655822753906 	 0.5843188762664795 	 0.44325900077819824 	 0.5307273864746094 	 0.3748030662536621 	 
2025-07-25 18:47:04.540760 test begin: paddle.nn.functional.rrelu(Tensor([846721, 3, 4, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([846721, 3, 4, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803260 	 1000 	 0.4898498058319092 	 0.2980349063873291 	 0.4794955253601074 	 0.2752645015716553 	 0.6034505367279053 	 0.44669079780578613 	 0.5487804412841797 	 0.3782186508178711 	 
2025-07-25 18:47:08.102340 test begin: paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.29984068870544434 	 1.826359510421753 	 0.2905573844909668 	 0.3112812042236328 	 0.4479086399078369 	 2.1237075328826904 	 0.39330124855041504 	 0.27152037620544434 	 
2025-07-25 18:47:13.921539 test begin: paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.2998321056365967 	 1.8265395164489746 	 0.29087257385253906 	 0.31126832962036133 	 0.44762587547302246 	 2.123690128326416 	 0.3944087028503418 	 0.27150440216064453 	 
2025-07-25 18:47:19.755305 test begin: paddle.nn.functional.selu(Tensor([2822401, 3, 3],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([2822401, 3, 3],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.2999415397644043 	 1.8288965225219727 	 0.29087209701538086 	 0.3112668991088867 	 0.44794559478759766 	 2.1237335205078125 	 0.3951230049133301 	 0.27152395248413086 	 
2025-07-25 18:47:25.550898 test begin: paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.3014395236968994 	 1.8265130519866943 	 0.2908444404602051 	 0.31124424934387207 	 0.44809699058532715 	 2.1237423419952393 	 0.39582157135009766 	 0.27150392532348633 	 
2025-07-25 18:47:31.358348 test begin: paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.29987525939941406 	 1.8263225555419922 	 0.2908744812011719 	 0.3112599849700928 	 0.4481067657470703 	 2.123732566833496 	 0.39583587646484375 	 0.271543025970459 	 
2025-07-25 18:47:37.740967 test begin: paddle.nn.functional.selu(Tensor([3, 2822401, 3],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 2822401, 3],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.527735710144043 	 1.8284642696380615 	 0.28391194343566895 	 0.31123900413513184 	 0.4479677677154541 	 2.1236226558685303 	 0.3872835636138916 	 0.271500825881958 	 
2025-07-25 18:47:44.619217 test begin: paddle.nn.functional.selu(Tensor([3, 3, 2822401],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 3, 2822401],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.3021690845489502 	 1.8263611793518066 	 0.2908446788787842 	 0.3112823963165283 	 0.4479069709777832 	 2.1237354278564453 	 0.39568233489990234 	 0.27149534225463867 	 
2025-07-25 18:47:50.423285 test begin: paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.3015303611755371 	 1.8333625793457031 	 0.28365421295166016 	 0.3112449645996094 	 0.44805145263671875 	 2.1238014698028564 	 0.38706421852111816 	 0.27150678634643555 	 
2025-07-25 18:47:58.583606 test begin: paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.29985642433166504 	 1.8265430927276611 	 0.2908198833465576 	 0.31123900413513184 	 0.44801878929138184 	 2.1237123012542725 	 0.3894329071044922 	 0.27151036262512207 	 
2025-07-25 18:48:04.384672 test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, ) 	 25401675 	 1000 	 0.30094480514526367 	 1.8263461589813232 	 0.29149508476257324 	 0.3112356662750244 	 0.4479236602783203 	 2.12361741065979 	 0.389575719833374 	 0.271500825881958 	 
2025-07-25 18:48:10.196685 test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, None, ) 	 25401675 	 1000 	 0.3005192279815674 	 1.8262050151824951 	 0.29087257385253906 	 0.3111591339111328 	 0.44741225242614746 	 2.123587131500244 	 0.38682103157043457 	 0.2714667320251465 	 
2025-07-25 18:48:16.031928 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 705601],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 705601],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7793078422546387 	 1.4865128993988037 	 0.7672345638275146 	 0.5055041313171387 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:48:18.844488 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 705601, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 705601, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.779242753982544 	 1.4827077388763428 	 0.767035961151123 	 0.5054819583892822 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:48:21.660780 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 705601, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 705601, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7792274951934814 	 1.4826080799102783 	 0.7672929763793945 	 0.505483865737915 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:48:24.470855 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 470401, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 470401, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401654 	 1000 	 0.7797167301177979 	 1.4826467037200928 	 0.767291784286499 	 0.5055115222930908 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:48:27.268051 test begin: paddle.nn.functional.sequence_mask(Tensor([470401, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([470401, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401654 	 1000 	 0.7792630195617676 	 1.4826128482818604 	 0.7672841548919678 	 0.5054852962493896 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:48:30.074771 test begin: paddle.nn.functional.sequence_mask(Tensor([50803201],"int32"), maxlen=4, dtype="float32", )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([50803201],"int32"), maxlen=4, dtype="float32", ) 	 50803201 	 1000 	 1.2115888595581055 	 2.4262406826019287 	 1.1989521980285645 	 0.8272478580474854 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:48:34.816326 test begin: paddle.nn.functional.sigmoid(Tensor([10, 32, 400, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([10, 32, 400, 400],"float32"), ) 	 51200000 	 1000 	 1.229494571685791 	 0.3142688274383545 	 0.28818702697753906 	 0.28949785232543945 	 0.4537687301635742 	 0.45009446144104004 	 0.3862171173095703 	 0.38147735595703125 	 
2025-07-25 18:48:41.098496 test begin: paddle.nn.functional.sigmoid(Tensor([364, 304, 460],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([364, 304, 460],"float32"), ) 	 50901760 	 1000 	 0.29641103744506836 	 0.29889702796936035 	 0.2864212989807129 	 0.2877211570739746 	 0.4511892795562744 	 0.4474613666534424 	 0.3966236114501953 	 0.3796844482421875 	 
2025-07-25 18:48:44.307045 test begin: paddle.nn.functional.sigmoid(Tensor([364, 416, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([364, 416, 336],"float32"), ) 	 50878464 	 1000 	 0.2954375743865967 	 0.2987494468688965 	 0.28626132011413574 	 0.2874753475189209 	 0.45091772079467773 	 0.4472227096557617 	 0.39129042625427246 	 0.3801918029785156 	 
2025-07-25 18:48:47.514083 test begin: paddle.nn.functional.sigmoid(Tensor([372, 304, 450],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([372, 304, 450],"float32"), ) 	 50889600 	 1000 	 0.29606151580810547 	 0.30006957054138184 	 0.2789604663848877 	 0.2866978645324707 	 0.4510021209716797 	 0.44734835624694824 	 0.3965756893157959 	 0.3796226978302002 	 
2025-07-25 18:48:50.725433 test begin: paddle.nn.functional.sigmoid(Tensor([372, 407, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([372, 407, 336],"float32"), ) 	 50871744 	 1000 	 0.30007028579711914 	 0.29877781867980957 	 0.28609561920166016 	 0.2869396209716797 	 0.45090222358703613 	 0.4471871852874756 	 0.38701844215393066 	 0.38033270835876465 	 
2025-07-25 18:48:53.977200 test begin: paddle.nn.functional.sigmoid(Tensor([498, 304, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([498, 304, 336],"float32"), ) 	 50867712 	 1000 	 0.2954127788543701 	 0.2987046241760254 	 0.28627777099609375 	 0.2874643802642822 	 0.45082736015319824 	 0.44716382026672363 	 0.3961958885192871 	 0.3792905807495117 	 
2025-07-25 18:48:57.153697 test begin: paddle.nn.functional.sigmoid(Tensor([8, 32, 400, 497],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 32, 400, 497],"float32"), ) 	 50892800 	 1000 	 0.2969498634338379 	 0.3069274425506592 	 0.28633666038513184 	 0.28759264945983887 	 0.4511733055114746 	 0.4473845958709717 	 0.3967931270599365 	 0.3792729377746582 	 
2025-07-25 18:49:04.267654 test begin: paddle.nn.functional.sigmoid(Tensor([8, 32, 497, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 32, 497, 400],"float32"), ) 	 50892800 	 1000 	 0.2972991466522217 	 0.2988595962524414 	 0.2864396572113037 	 0.28714537620544434 	 0.4510462284088135 	 0.44733309745788574 	 0.39372920989990234 	 0.3711569309234619 	 
2025-07-25 18:49:07.520556 test begin: paddle.nn.functional.sigmoid(Tensor([8, 40, 400, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 40, 400, 400],"float32"), ) 	 51200000 	 1000 	 0.2973341941833496 	 0.30068492889404297 	 0.28815197944641113 	 0.28971004486083984 	 0.45378923416137695 	 0.45003342628479004 	 0.39754271507263184 	 0.3714115619659424 	 
2025-07-25 18:49:10.785865 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803248 	 1000 	 6.902052164077759 	 5.640043020248413 	 0.0006692409515380859 	 0.3034229278564453 	 9.259300947189331 	 9.1670241355896 	 0.41170835494995117 	 0.3748178482055664 	 combined
2025-07-25 18:49:42.903586 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803249 	 1000 	 7.202414512634277 	 5.941031455993652 	 0.0008983612060546875 	 0.30318760871887207 	 10.01163625717163 	 10.963404178619385 	 0.39361143112182617 	 0.35033249855041504 	 combined
2025-07-25 18:50:18.132468 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803249 	 1000 	 7.202353239059448 	 5.96928596496582 	 0.0009799003601074219 	 0.3031792640686035 	 10.018522500991821 	 10.963477849960327 	 0.39377403259277344 	 0.35037922859191895 	 combined
2025-07-25 18:50:57.099889 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803320 	 1000 	 6.900979042053223 	 5.656630754470825 	 0.0006401538848876953 	 0.30339765548706055 	 9.265453100204468 	 9.165324211120605 	 0.4119715690612793 	 0.37474632263183594 	 combined
2025-07-25 18:51:29.257338 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803321 	 1000 	 7.20151424407959 	 5.940810918807983 	 0.0009746551513671875 	 0.30323195457458496 	 10.02338719367981 	 10.96357011795044 	 0.394012451171875 	 0.350405216217041 	 combined
2025-07-25 18:52:05.529741 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803321 	 1000 	 7.201547384262085 	 5.953073024749756 	 0.0009827613830566406 	 0.3031435012817383 	 10.021209955215454 	 10.963374614715576 	 0.39394617080688477 	 0.3504040241241455 	 combined
2025-07-25 18:52:41.333764 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803360 	 1000 	 6.9023497104644775 	 5.640108108520508 	 0.0006921291351318359 	 0.3033747673034668 	 9.257826566696167 	 9.164786338806152 	 0.4116041660308838 	 0.3746650218963623 	 combined
2025-07-25 18:53:13.401170 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803361 	 1000 	 7.206826210021973 	 5.941117286682129 	 0.0009729862213134766 	 0.30313754081726074 	 10.020875692367554 	 10.963003396987915 	 0.3938918113708496 	 0.35031580924987793 	 combined
2025-07-25 18:53:48.687389 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803361 	 1000 	 7.203227758407593 	 5.940699577331543 	 0.0009772777557373047 	 0.3031439781188965 	 10.02001428604126 	 10.96278429031372 	 0.3939025402069092 	 0.3503742218017578 	 combined
2025-07-25 18:54:23.936463 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803440 	 1000 	 6.901239395141602 	 5.673885107040405 	 0.0006861686706542969 	 0.30343103408813477 	 9.263877391815186 	 9.165355443954468 	 0.4119739532470703 	 0.37468433380126953 	 combined
2025-07-25 18:54:56.482014 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803441 	 1000 	 7.19825005531311 	 5.940646171569824 	 0.0009729862213134766 	 0.30318188667297363 	 10.014382123947144 	 10.962418794631958 	 0.39366960525512695 	 0.35033631324768066 	 combined
2025-07-25 18:55:31.696019 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803441 	 1000 	 7.196398735046387 	 5.940656423568726 	 0.0009808540344238281 	 0.30316781997680664 	 10.012794971466064 	 10.963226318359375 	 0.3936195373535156 	 0.35036635398864746 	 combined
2025-07-25 18:56:07.565800 test begin: paddle.nn.functional.silu(Tensor([128, 128, 128, 25],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 128, 128, 25],"float32"), None, ) 	 52428800 	 1000 	 0.3052201271057129 	 0.3140096664428711 	 0.2920236587524414 	 0.2923109531402588 	 0.46459388732910156 	 0.46445441246032715 	 0.4101889133453369 	 0.3945271968841553 	 
2025-07-25 18:56:10.878753 test begin: paddle.nn.functional.silu(Tensor([128, 128, 25, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 128, 25, 128],"float32"), None, ) 	 52428800 	 1000 	 0.30470871925354004 	 0.30758070945739746 	 0.29573607444763184 	 0.2902228832244873 	 0.4647707939147949 	 0.4647097587585449 	 0.40397071838378906 	 0.39830517768859863 	 
2025-07-25 18:56:14.250278 test begin: paddle.nn.functional.silu(Tensor([128, 25, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 25, 128, 128],"float32"), None, ) 	 52428800 	 1000 	 0.30473804473876953 	 0.30756187438964844 	 0.2958064079284668 	 0.292391300201416 	 0.46479010581970215 	 0.46474218368530273 	 0.40582728385925293 	 0.3904545307159424 	 
2025-07-25 18:56:17.573684 test begin: paddle.nn.functional.silu(Tensor([128, 256, 25, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 256, 25, 64],"float32"), None, ) 	 52428800 	 1000 	 0.3047809600830078 	 0.3107173442840576 	 0.2957272529602051 	 0.29211997985839844 	 0.46474409103393555 	 0.4647257328033447 	 0.4099924564361572 	 0.39719319343566895 	 
2025-07-25 18:56:20.901891 test begin: paddle.nn.functional.silu(Tensor([128, 256, 64, 25],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 256, 64, 25],"float32"), None, ) 	 52428800 	 1000 	 0.3046550750732422 	 0.3075683116912842 	 0.2956657409667969 	 0.29215478897094727 	 0.46485137939453125 	 0.4647409915924072 	 0.3880302906036377 	 0.3971216678619385 	 
2025-07-25 18:56:24.163279 test begin: paddle.nn.functional.silu(Tensor([128, 64, 128, 49],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 64, 128, 49],"float32"), None, ) 	 51380224 	 1000 	 0.298891544342041 	 0.30164170265197754 	 0.28974437713623047 	 0.2862696647644043 	 0.45558762550354004 	 0.4552326202392578 	 0.40051937103271484 	 0.3880133628845215 	 
2025-07-25 18:56:27.378613 test begin: paddle.nn.functional.silu(Tensor([128, 64, 49, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 64, 49, 128],"float32"), None, ) 	 51380224 	 1000 	 0.29912304878234863 	 0.30165815353393555 	 0.2897062301635742 	 0.28570055961608887 	 0.4554462432861328 	 0.4553513526916504 	 0.3997478485107422 	 0.3883328437805176 	 
2025-07-25 18:56:30.637045 test begin: paddle.nn.functional.silu(Tensor([128, 97, 64, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 97, 64, 64],"float32"), None, ) 	 50855936 	 1000 	 0.29569029808044434 	 0.2987020015716553 	 0.28679776191711426 	 0.2834758758544922 	 0.4508073329925537 	 0.4507589340209961 	 0.3961026668548584 	 0.37615251541137695 	 
2025-07-25 18:56:33.835223 test begin: paddle.nn.functional.silu(Tensor([25, 128, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([25, 128, 128, 128],"float32"), None, ) 	 52428800 	 1000 	 0.30477094650268555 	 0.31086063385009766 	 0.29591894149780273 	 0.2921791076660156 	 0.4648299217224121 	 0.4646594524383545 	 0.4056992530822754 	 0.39778923988342285 	 
2025-07-25 18:56:39.304767 test begin: paddle.nn.functional.silu(Tensor([49, 256, 64, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([49, 256, 64, 64],"float32"), None, ) 	 51380224 	 1000 	 0.3003664016723633 	 0.3015937805175781 	 0.2897343635559082 	 0.2859945297241211 	 0.45548319816589355 	 0.4552886486053467 	 0.3972048759460449 	 0.3886716365814209 	 
2025-07-25 18:56:42.522184 test begin: paddle.nn.functional.silu(Tensor([49, 64, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([49, 64, 128, 128],"float32"), None, ) 	 51380224 	 1000 	 0.30185747146606445 	 0.302811861038208 	 0.28981614112854004 	 0.28624963760375977 	 0.45546627044677734 	 0.4551692008972168 	 0.40092897415161133 	 0.3876049518585205 	 
2025-07-25 18:56:45.775324 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"float32"), reduction="none", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"float32"), reduction="none", ) 	 101606500 	 1000 	 0.8159520626068115 	 0.48526668548583984 	 0.4151186943054199 	 0.40680861473083496 	 1.6254079341888428 	 1.446746587753296 	 0.41522741317749023 	 0.3696279525756836 	 
2025-07-25 18:56:54.190710 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1017, 50000],"float32"), Tensor([1017, 50000],"float32"), reduction="mean", delta=1.0, name=None, )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1017, 50000],"float32"), Tensor([1017, 50000],"float32"), reduction="mean", delta=1.0, name=None, ) 	 101700000 	 1000 	 0.9650211334228516 	 0.5985479354858398 	 0.24625158309936523 	 0.20364165306091309 	 1.765059471130371 	 1.1614997386932373 	 0.3608565330505371 	 0.2966780662536621 	 
2025-07-25 18:57:00.390600 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1914, 26543],"float32"), Tensor([1914, 26543],"float32"), reduction="none", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1914, 26543],"float32"), Tensor([1914, 26543],"float32"), reduction="none", ) 	 101606604 	 1000 	 0.8113088607788086 	 0.4469616413116455 	 0.41452646255493164 	 0.4216578006744385 	 1.6252176761627197 	 1.4466767311096191 	 0.4152078628540039 	 0.3695807456970215 	 
2025-07-25 18:57:07.325730 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([33960, 187, 8],"float32"), Tensor([33960, 187, 8],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([33960, 187, 8],"float32"), Tensor([33960, 187, 8],"float32"), reduction="sum", ) 	 101608320 	 1000 	 0.9660718441009521 	 0.5986831188201904 	 0.2463376522064209 	 0.20372819900512695 	 1.761598825454712 	 1.1607882976531982 	 0.36013007164001465 	 0.296536922454834 	 
2025-07-25 18:57:13.494659 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([64, 187, 4245],"float32"), Tensor([64, 187, 4245],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([64, 187, 4245],"float32"), Tensor([64, 187, 4245],"float32"), reduction="sum", ) 	 101608320 	 1000 	 0.965024471282959 	 0.5985968112945557 	 0.24621891975402832 	 0.20366406440734863 	 1.7602105140686035 	 1.1608009338378906 	 0.35993194580078125 	 0.29657602310180664 	 
2025-07-25 18:57:19.661244 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([64, 99226, 8],"float32"), Tensor([64, 99226, 8],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([64, 99226, 8],"float32"), Tensor([64, 99226, 8],"float32"), reduction="sum", ) 	 101607424 	 1000 	 0.9654273986816406 	 0.5986435413360596 	 0.2463538646697998 	 0.2037041187286377 	 1.7602603435516357 	 1.1607623100280762 	 0.3598349094390869 	 0.2965219020843506 	 
2025-07-25 18:57:25.913155 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([7, 7257601],"float32"), Tensor([7, 7257601],"float32"), reduction="mean", delta=1.0, name=None, )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([7, 7257601],"float32"), Tensor([7, 7257601],"float32"), reduction="mean", delta=1.0, name=None, ) 	 101606414 	 1000 	 0.9651656150817871 	 0.5985286235809326 	 0.2463209629058838 	 0.20362114906311035 	 1.7615838050842285 	 1.1608049869537354 	 0.36016130447387695 	 0.29657626152038574 	 
2025-07-25 18:57:32.130916 test begin: paddle.nn.functional.softmax(Tensor([10, 2304, 2304],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([10, 2304, 2304],"float32"), axis=-1, ) 	 53084160 	 1000 	 0.315967321395874 	 0.5298967361450195 	 0.30498671531677246 	 0.5148508548736572 	 0.4899616241455078 	 0.931171178817749 	 0.4330451488494873 	 0.4756896495819092 	 
2025-07-25 18:57:37.810566 test begin: paddle.nn.functional.softmax(Tensor([3840, 1, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 1, 144, 144],"float32"), -1, name=None, ) 	 79626240 	 1000 	 0.6875708103179932 	 0.5061559677124023 	 0.45302367210388184 	 0.4873621463775635 	 0.7009572982788086 	 1.392639398574829 	 0.6479403972625732 	 0.7116217613220215 	 
2025-07-25 18:57:44.887996 test begin: paddle.nn.functional.softmax(Tensor([3840, 4, 144, 23],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 4, 144, 23],"float32"), -1, name=None, ) 	 50872320 	 1000 	 0.36682844161987305 	 0.5065691471099854 	 0.357651948928833 	 0.48810482025146484 	 0.451509952545166 	 0.8951625823974609 	 0.39800596237182617 	 0.4573366641998291 	 
2025-07-25 18:57:48.845405 test begin: paddle.nn.functional.softmax(Tensor([3840, 4, 23, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 4, 23, 144],"float32"), -1, name=None, ) 	 50872320 	 1000 	 0.29919981956481934 	 0.3239598274230957 	 0.28757309913635254 	 0.3082141876220703 	 0.44977569580078125 	 0.892371416091919 	 0.3967447280883789 	 0.4558858871459961 	 
2025-07-25 18:57:52.549982 test begin: paddle.nn.functional.softmax(Tensor([4096, 1, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 1, 144, 144],"float32"), -1, name=None, ) 	 84934656 	 1000 	 0.49826765060424805 	 0.5442197322845459 	 0.48285937309265137 	 0.5201587677001953 	 0.74755859375 	 1.484987497329712 	 0.6927862167358398 	 0.7587378025054932 	 
2025-07-25 18:58:00.930023 test begin: paddle.nn.functional.softmax(Tensor([4096, 4, 144, 22],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 4, 144, 22],"float32"), -1, name=None, ) 	 51904512 	 1000 	 0.46230030059814453 	 0.5363597869873047 	 0.45209693908691406 	 0.5214691162109375 	 0.46233320236206055 	 0.9147367477416992 	 0.40903735160827637 	 0.4673435688018799 	 
2025-07-25 18:58:05.060015 test begin: paddle.nn.functional.softmax(Tensor([4096, 4, 22, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 4, 22, 144],"float32"), -1, name=None, ) 	 51904512 	 1000 	 0.3032190799713135 	 0.33040952682495117 	 0.2936134338378906 	 0.31548595428466797 	 0.45868873596191406 	 0.9105579853057861 	 0.40532875061035156 	 0.4652700424194336 	 
2025-07-25 18:58:08.805923 test begin: paddle.nn.functional.softmax(Tensor([60, 2304, 368],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([60, 2304, 368],"float32"), axis=-1, ) 	 50872320 	 1000 	 0.3007032871246338 	 0.30289697647094727 	 0.2915012836456299 	 0.28496742248535156 	 0.4504528045654297 	 0.8927819728851318 	 0.39732861518859863 	 0.4560976028442383 	 
2025-07-25 18:58:12.516056 test begin: paddle.nn.functional.softmax(Tensor([60, 368, 2304],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([60, 368, 2304],"float32"), axis=-1, ) 	 50872320 	 1000 	 0.3024868965148926 	 0.5081310272216797 	 0.2915382385253906 	 0.4932091236114502 	 0.4690232276916504 	 0.8922731876373291 	 0.4098958969116211 	 0.45587778091430664 	 
2025-07-25 18:58:16.423366 test begin: paddle.nn.functional.softmax(Tensor([613, 4, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([613, 4, 144, 144],"float32"), -1, name=None, ) 	 50844672 	 1000 	 0.29665207862854004 	 0.32376790046691895 	 0.28751564025878906 	 0.30879878997802734 	 0.4494643211364746 	 0.8919532299041748 	 0.39641857147216797 	 0.4557347297668457 	 
2025-07-25 18:58:20.130617 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=-1, )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:129: VisibleDeprecationWarning: [93m
Warning:
API "paddle.nn.functional.loss.softmax_with_cross_entropy" is deprecated since 2.0.0, and will be removed in future versions. Please use "paddle.nn.functional.cross_entropy" instead.
    Reason: Please notice that behavior of "paddle.nn.functional.softmax_with_cross_entropy" and "paddle.nn.functional.cross_entropy" is different. [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:147: VisibleDeprecationWarning: [93m
Warning:
API "paddle.nn.functional.loss.softmax_with_cross_entropy" is deprecated since 2.0.0, and will be removed in future versions. Please use "paddle.nn.functional.cross_entropy" instead.
    Reason: Please notice that behavior of "paddle.nn.functional.softmax_with_cross_entropy" and "paddle.nn.functional.cross_entropy" is different. [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=-1, ) 	 51617280 	 1000 	 0.34557580947875977 	 1.2811756134033203 	 0.3271200656890869 	 0.2603645324707031 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:23.195196 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=3, ) 	 51617280 	 1000 	 0.3452768325805664 	 1.2761375904083252 	 0.32739973068237305 	 0.2603614330291748 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:26.249256 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 1, 64],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 1, 64],"int64"), axis=2, ) 	 52394496 	 1000 	 1.2729122638702393 	 2.2446038722991943 	 0.6486475467681885 	 0.38162708282470703 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:31.217328 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=-1, ) 	 51600640 	 1000 	 0.34609150886535645 	 1.278064250946045 	 0.3269331455230713 	 0.26026296615600586 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:34.297809 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=3, ) 	 51600640 	 1000 	 0.34653711318969727 	 1.2836391925811768 	 0.3229219913482666 	 0.2602560520172119 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:58:39.689582 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, ) 	 50806784 	 1000 	 25.708213806152344 	 1.5055580139160156 	 13.13611102104187 	 0.2559373378753662 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:59:08.263268 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=-1, ) 	 51598560 	 1000 	 0.3445005416870117 	 1.2767541408538818 	 0.326549768447876 	 0.26024484634399414 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:59:11.290547 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=3, ) 	 51598560 	 1000 	 0.3447272777557373 	 1.2755711078643799 	 0.32679009437561035 	 0.2602272033691406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:59:14.316603 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 1, 49613],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 1, 49613],"int64"), axis=2, ) 	 52391328 	 1000 	 1.5386223793029785 	 2.218024253845215 	 0.7862334251403809 	 0.3771059513092041 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:59:19.539268 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, ) 	 50804736 	 1000 	 0.641836404800415 	 1.074920415878296 	 0.6239080429077148 	 0.21927523612976074 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:59:22.561820 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, ) 	 50804736 	 1000 	 0.6417236328125 	 1.0769164562225342 	 0.6238958835601807 	 0.21931076049804688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:59:25.598451 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 793801],"float32"), Tensor([2, 16, 1, 793801],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 793801],"float32"), Tensor([2, 16, 1, 793801],"int64"), axis=2, ) 	 838253856 	 1000 	 23.996402740478516 	 44.56384873390198 	 12.25886344909668 	 5.046957969665527 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:00:59.390455 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 793801, 64],"float32"), Tensor([2, 16, 793801, 1],"int64"), axis=-1, )
[Error] CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacity of 39.39 GiB of which 1.35 GiB is free. Process 150752 has 38.03 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 199.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-25 19:02:00.733712 test begin: paddle.nn.functional.softplus(Tensor([113401, 7, 64],"float32"), )
W0725 19:02:01.712414 145643 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([113401, 7, 64],"float32"), ) 	 50803648 	 1000 	 0.2998695373535156 	 0.3013010025024414 	 0.2837517261505127 	 0.2877047061920166 	 0.4507787227630615 	 0.4507629871368408 	 0.3842589855194092 	 0.3569939136505127 	 
2025-07-25 19:02:04.847929 test begin: paddle.nn.functional.softplus(Tensor([13, 10, 390794],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 10, 390794],"float32"), ) 	 50803220 	 1000 	 0.29990220069885254 	 0.30000829696655273 	 0.2909970283508301 	 0.28818583488464355 	 0.4507124423980713 	 0.45080113410949707 	 0.3982536792755127 	 0.3601243495941162 	 
2025-07-25 19:02:08.016385 test begin: paddle.nn.functional.softplus(Tensor([13, 1007, 3881],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 1007, 3881],"float32"), ) 	 50806171 	 1000 	 0.3002786636352539 	 0.3003368377685547 	 0.29081010818481445 	 0.2880873680114746 	 0.4508399963378906 	 0.45097899436950684 	 0.3954195976257324 	 0.38196277618408203 	 
2025-07-25 19:02:11.874244 test begin: paddle.nn.functional.softplus(Tensor([13, 61062, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 61062, 64],"float32"), ) 	 50803584 	 1000 	 0.30145740509033203 	 0.30265092849731445 	 0.29257750511169434 	 0.2882199287414551 	 0.45076894760131836 	 0.4508481025695801 	 0.3978135585784912 	 0.36913347244262695 	 
2025-07-25 19:02:15.132666 test begin: paddle.nn.functional.softplus(Tensor([14, 56701, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([14, 56701, 64],"float32"), ) 	 50804096 	 1000 	 0.9789495468139648 	 0.307955265045166 	 0.2920095920562744 	 0.28815269470214844 	 0.4507784843444824 	 0.45076489448547363 	 0.3982408046722412 	 0.36501264572143555 	 
2025-07-25 19:02:20.733161 test begin: paddle.nn.functional.softplus(Tensor([14, 7, 518401],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([14, 7, 518401],"float32"), ) 	 50803298 	 1000 	 0.30156564712524414 	 0.30002689361572266 	 0.2927062511444092 	 0.2820625305175781 	 0.45070862770080566 	 0.4506678581237793 	 0.39789700508117676 	 0.3811066150665283 	 
2025-07-25 19:02:23.853731 test begin: paddle.nn.functional.softplus(Tensor([789, 1007, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([789, 1007, 64],"float32"), ) 	 50849472 	 1000 	 0.30050039291381836 	 0.30025482177734375 	 0.29100799560546875 	 0.2886486053466797 	 0.45106053352355957 	 0.45107531547546387 	 0.3984692096710205 	 0.3679497241973877 	 
2025-07-25 19:02:27.045498 test begin: paddle.nn.functional.softplus(Tensor([79381, 10, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([79381, 10, 64],"float32"), ) 	 50803840 	 1000 	 0.30142664909362793 	 0.29997730255126953 	 0.2925422191619873 	 0.288358211517334 	 0.45083022117614746 	 0.450742244720459 	 0.3981449604034424 	 0.3682742118835449 	 
2025-07-25 19:02:30.228884 test begin: paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 0, None, ) 	 25401609 	 1000 	 0.2984578609466553 	 0.29904985427856445 	 0.2894740104675293 	 0.28671956062316895 	 0.4479563236236572 	 0.4459550380706787 	 0.39554595947265625 	 0.3635549545288086 	 
2025-07-25 19:02:32.787418 test begin: paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 5, None, ) 	 25401609 	 1000 	 0.2983744144439697 	 0.2989211082458496 	 0.28951382637023926 	 0.28672337532043457 	 0.44859862327575684 	 0.446014404296875 	 0.39543771743774414 	 0.36471080780029297 	 
2025-07-25 19:02:37.392025 test begin: paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 0, None, ) 	 25401609 	 1000 	 0.7574818134307861 	 0.3134305477142334 	 0.2894001007080078 	 0.2866637706756592 	 0.44849252700805664 	 0.4462125301361084 	 0.3855757713317871 	 0.35839128494262695 	 
2025-07-25 19:02:40.948018 test begin: paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 5, None, ) 	 25401609 	 1000 	 0.298475980758667 	 0.30371952056884766 	 0.28951144218444824 	 0.28647589683532715 	 0.4482710361480713 	 0.44607996940612793 	 0.39602208137512207 	 0.36449241638183594 	 
2025-07-25 19:02:43.643489 test begin: paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 0, None, ) 	 25401609 	 1000 	 0.29868102073669434 	 0.299224853515625 	 0.28908371925354004 	 0.2864253520965576 	 0.44837141036987305 	 0.44639062881469727 	 0.39205098152160645 	 0.3563039302825928 	 
2025-07-25 19:02:46.411080 test begin: paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 5, None, ) 	 25401609 	 1000 	 0.29845428466796875 	 0.2988452911376953 	 0.2891843318939209 	 0.2861804962158203 	 0.4480464458465576 	 0.4459724426269531 	 0.3951847553253174 	 0.3565957546234131 	 
2025-07-25 19:02:48.869529 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 207, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 207, 8, 32, 2],"float32"), threshold=0.01, ) 	 50872320 	 1000 	 0.297161340713501 	 0.2989208698272705 	 0.28691744804382324 	 0.2852802276611328 	 0.4509298801422119 	 0.4473848342895508 	 0.3983590602874756 	 0.3577558994293213 	 
2025-07-25 19:02:52.017792 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 207, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 207, 32, 2],"float32"), threshold=0.01, ) 	 50872320 	 1000 	 0.2965571880340576 	 0.30164575576782227 	 0.28696227073669434 	 0.28523898124694824 	 0.4510672092437744 	 0.447307825088501 	 0.3987159729003906 	 0.3567814826965332 	 
2025-07-25 19:02:55.238601 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 32, 52],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 32, 52],"float32"), threshold=0.01, ) 	 51118080 	 1000 	 0.2984039783477783 	 0.30115294456481934 	 0.28829383850097656 	 0.2874331474304199 	 0.4530494213104248 	 0.4496335983276367 	 0.4006941318511963 	 0.35882043838500977 	 
2025-07-25 19:02:58.459092 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 827, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 827, 2],"float32"), threshold=0.01, ) 	 50810880 	 1000 	 0.29605650901794434 	 0.2986164093017578 	 0.2865276336669922 	 0.285750150680542 	 0.4505453109741211 	 0.4469294548034668 	 0.3981163501739502 	 0.34483790397644043 	 
2025-07-25 19:03:01.651307 test begin: paddle.nn.functional.softshrink(Tensor([32, 388, 8, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 388, 8, 8, 32, 2],"float32"), threshold=0.01, ) 	 50855936 	 1000 	 0.2963600158691406 	 0.29891419410705566 	 0.28626322746276855 	 0.285630464553833 	 0.4507935047149658 	 0.44727253913879395 	 0.3974132537841797 	 0.34681272506713867 	 
2025-07-25 19:03:04.816995 test begin: paddle.nn.functional.softshrink(Tensor([827, 15, 8, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([827, 15, 8, 8, 32, 2],"float32"), threshold=0.01, ) 	 50810880 	 1000 	 0.298018217086792 	 0.2986266613006592 	 0.28617429733276367 	 0.2816159725189209 	 0.4504275321960449 	 0.4468843936920166 	 0.39795470237731934 	 0.3502197265625 	 
2025-07-25 19:03:07.915873 test begin: paddle.nn.functional.softsign(Tensor([12404, 4096],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([12404, 4096],"float32"), ) 	 50806784 	 1000 	 0.29562997817993164 	 1.043426275253296 	 0.2866542339324951 	 0.35538315773010254 	 0.45017409324645996 	 3.279616594314575 	 0.38846468925476074 	 0.41887903213500977 	 
2025-07-25 19:03:14.730613 test begin: paddle.nn.functional.softsign(Tensor([2822401, 3, 3],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([2822401, 3, 3],"float64"), None, ) 	 25401609 	 1000 	 0.29941558837890625 	 1.0432169437408447 	 0.29062986373901367 	 0.35539865493774414 	 0.4478743076324463 	 3.270195245742798 	 0.3957080841064453 	 0.4176023006439209 	 
2025-07-25 19:03:22.681337 test begin: paddle.nn.functional.softsign(Tensor([3, 2822401, 3],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([3, 2822401, 3],"float64"), None, ) 	 25401609 	 1000 	 0.3035447597503662 	 1.0500037670135498 	 0.28423047065734863 	 0.3553283214569092 	 0.4483158588409424 	 3.2703633308410645 	 0.3877260684967041 	 0.41766953468322754 	 
2025-07-25 19:03:29.845023 test begin: paddle.nn.functional.softsign(Tensor([3, 3, 2822401],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([3, 3, 2822401],"float64"), None, ) 	 25401609 	 1000 	 0.2993943691253662 	 1.0431902408599854 	 0.29087042808532715 	 0.35529613494873047 	 0.4480609893798828 	 3.270235776901245 	 0.3965027332305908 	 0.41765427589416504 	 
2025-07-25 19:03:37.606902 test begin: paddle.nn.functional.softsign(Tensor([300, 169345],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([300, 169345],"float32"), ) 	 50803500 	 1000 	 0.9765965938568115 	 1.0434215068817139 	 0.28645849227905273 	 0.35546016693115234 	 0.45050907135009766 	 3.2795979976654053 	 0.3986635208129883 	 0.41884875297546387 	 
2025-07-25 19:03:45.417391 test begin: paddle.nn.functional.softsign(Tensor([32, 1587601],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 0.2978694438934326 	 1.0434105396270752 	 0.2863485813140869 	 0.355499267578125 	 0.45043325424194336 	 3.2797281742095947 	 0.38918232917785645 	 0.4190056324005127 	 
2025-07-25 19:03:52.232424 test begin: paddle.nn.functional.softsign(Tensor([396901, 128],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2966296672821045 	 1.0499298572540283 	 0.28629207611083984 	 0.35541439056396484 	 0.45046353340148926 	 3.2796928882598877 	 0.38965654373168945 	 0.4188404083251953 	 
2025-07-25 19:03:59.084996 test begin: paddle.nn.functional.square_error_cost(Tensor([10161, 100, 100],"float16"), Tensor([10161, 100, 100],"float32"), )
W0725 19:04:02.415320 146967 dygraph_functions.cc:93089] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([10161, 100, 100],"float16"), Tensor([10161, 100, 100],"float32"), ) 	 203220000 	 1000 	 1.9634711742401123 	 1.4028420448303223 	 0.6689035892486572 	 0.7166657447814941 	 2.291926145553589 	 3.1380608081817627 	 0.7805881500244141 	 0.5343923568725586 	 combined
2025-07-25 19:04:13.306672 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), ) 	 25401624 	 1000 	 0.6066174507141113 	 0.5989887714385986 	 0.3059813976287842 	 0.30594944953918457 	 4.142090320587158 	 1.5172622203826904 	 1.059300184249878 	 0.2214217185974121 	 combined
2025-07-25 19:04:21.319939 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 4233601],"float64"), label=Tensor([3, 2, 1, 4233601],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 4233601],"float64"), label=Tensor([3, 2, 1, 4233601],"float64"), ) 	 50803212 	 1000 	 0.7435901165008545 	 0.7415602207183838 	 0.37984538078308105 	 0.3788421154022217 	 0.9264266490936279 	 1.3525888919830322 	 0.47330546379089355 	 0.2765929698944092 	 combined
2025-07-25 19:04:27.823469 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 1, 2],"float64"), ) 	 25401624 	 1000 	 0.5996289253234863 	 0.5989649295806885 	 0.30492639541625977 	 0.3060109615325928 	 3.8522140979766846 	 1.5173463821411133 	 1.3130970001220703 	 0.2209470272064209 	 combined
2025-07-25 19:04:37.459302 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), ) 	 50803224 	 1000 	 0.9717707633972168 	 0.7414069175720215 	 0.38008880615234375 	 0.378741979598999 	 0.9265272617340088 	 1.3526325225830078 	 0.4734160900115967 	 0.27663683891296387 	 combined
2025-07-25 19:04:43.940366 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 4233601, 1, 2],"float64"), label=Tensor([3, 4233601, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 4233601, 1, 2],"float64"), label=Tensor([3, 4233601, 1, 2],"float64"), ) 	 50803212 	 1000 	 0.744189977645874 	 0.7415146827697754 	 0.38017964363098145 	 0.37879228591918945 	 0.926541805267334 	 1.3526957035064697 	 0.47336769104003906 	 0.27668261528015137 	 combined
2025-07-25 19:04:49.289655 test begin: paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float16"), Tensor([5081, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float16"), Tensor([5081, 100, 100],"float32"), ) 	 101620000 	 1000 	 0.986830472946167 	 0.7212812900543213 	 0.3361496925354004 	 0.3609757423400879 	 1.1505746841430664 	 1.5804686546325684 	 0.39184021949768066 	 0.26918911933898926 	 combined
2025-07-25 19:04:56.465845 test begin: paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float32"), Tensor([5081, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float32"), Tensor([5081, 100, 100],"float32"), ) 	 101620000 	 1000 	 0.7483947277069092 	 0.7433657646179199 	 0.3810844421386719 	 0.379730224609375 	 0.9245631694793701 	 1.3537571430206299 	 0.472348690032959 	 0.27681994438171387 	 combined
2025-07-25 19:05:02.898345 test begin: paddle.nn.functional.square_error_cost(Tensor([6350401, 2, 1, 2],"float64"), label=Tensor([6350401, 2, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([6350401, 2, 1, 2],"float64"), label=Tensor([6350401, 2, 1, 2],"float64"), ) 	 50803208 	 1000 	 0.7440900802612305 	 0.7413904666900635 	 0.38014650344848633 	 0.3787658214569092 	 0.9265551567077637 	 1.3528573513031006 	 0.473400354385376 	 0.27677083015441895 	 combined
2025-07-25 19:05:08.175429 test begin: paddle.nn.functional.square_error_cost(Tensor([8, 100, 63505],"float32"), Tensor([8, 100, 63505],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([8, 100, 63505],"float32"), Tensor([8, 100, 63505],"float32"), ) 	 101608000 	 1000 	 0.746009349822998 	 0.7431943416595459 	 0.38111424446105957 	 0.3796703815460205 	 0.9245245456695557 	 1.3538246154785156 	 0.4723215103149414 	 0.27683067321777344 	 combined
2025-07-25 19:05:14.320197 test begin: paddle.nn.functional.square_error_cost(Tensor([8, 63505, 100],"float32"), Tensor([8, 63505, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([8, 63505, 100],"float32"), Tensor([8, 63505, 100],"float32"), ) 	 101608000 	 1000 	 0.7459452152252197 	 0.7432301044464111 	 0.3810758590698242 	 0.3796679973602295 	 0.9243040084838867 	 1.3537607192993164 	 0.4722621440887451 	 0.27684712409973145 	 combined
2025-07-25 19:05:20.414487 test begin: paddle.nn.functional.swish(Tensor([128, 32, 112, 112],"float32"), )
2025-07-25 19:05:24.560338 test begin: paddle.nn.functional.swish(Tensor([128, 96, 112, 37],"float32"), )
2025-07-25 19:05:28.646705 test begin: paddle.nn.functional.swish(Tensor([128, 96, 37, 112],"float32"), )
2025-07-25 19:05:33.534849 test begin: paddle.nn.functional.swish(Tensor([16, 22, 384, 384],"float32"), )
2025-07-25 19:05:42.672782 test begin: paddle.nn.functional.swish(Tensor([16, 24, 368, 368],"float32"), )
2025-07-25 19:05:46.896476 test begin: paddle.nn.functional.swish(Tensor([16, 64, 130, 384],"float32"), )
2025-07-25 19:05:51.101619 test begin: paddle.nn.functional.swish(Tensor([16, 64, 135, 368],"float32"), )
2025-07-25 19:05:55.257797 test begin: paddle.nn.functional.swish(Tensor([16, 64, 368, 135],"float32"), )
2025-07-25 19:05:59.399326 test begin: paddle.nn.functional.swish(Tensor([16, 64, 384, 130],"float32"), )
2025-07-25 19:06:03.526440 test begin: paddle.nn.functional.swish(Tensor([43, 96, 112, 112],"float32"), )
2025-07-25 19:06:07.714080 test begin: paddle.nn.functional.swish(Tensor([6, 64, 368, 368],"float32"), )
2025-07-25 19:06:11.940125 test begin: paddle.nn.functional.swish(Tensor([6, 64, 384, 384],"float32"), )
2025-07-25 19:06:16.509544 test begin: paddle.nn.functional.tanh(Tensor([1016065, 50],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([1016065, 50],"float32"), None, ) 	 50803250 	 1000 	 0.29568028450012207 	 0.2981536388397217 	 0.2869575023651123 	 0.2864043712615967 	 0.45032691955566406 	 0.44669151306152344 	 0.39829587936401367 	 0.3644709587097168 	 
2025-07-25 19:06:19.552219 test begin: paddle.nn.functional.tanh(Tensor([147015, 346],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([147015, 346],"float32"), None, ) 	 50867190 	 1000 	 0.29610252380371094 	 0.29852795600891113 	 0.2872602939605713 	 0.28646326065063477 	 0.45085811614990234 	 0.44722771644592285 	 0.39841556549072266 	 0.36252617835998535 	 
2025-07-25 19:06:22.627999 test begin: paddle.nn.functional.tanh(Tensor([282600, 180],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([282600, 180],"float32"), None, ) 	 50868000 	 1000 	 0.2961275577545166 	 0.2985103130340576 	 0.28729748725891113 	 0.28646039962768555 	 0.4509236812591553 	 0.44724297523498535 	 0.3991529941558838 	 0.3642306327819824 	 
2025-07-25 19:06:25.761083 test begin: paddle.nn.functional.tanh(Tensor([564481, 90],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([564481, 90],"float32"), None, ) 	 50803290 	 1000 	 0.29549121856689453 	 0.2982182502746582 	 0.2867610454559326 	 0.28667426109313965 	 0.4503161907196045 	 0.44663572311401367 	 0.3985576629638672 	 0.36608004570007324 	 
2025-07-25 19:06:28.879022 test begin: paddle.nn.functional.tanh(Tensor([93401, 544],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([93401, 544],"float32"), None, ) 	 50810144 	 1000 	 0.2956557273864746 	 0.2981855869293213 	 0.28666257858276367 	 0.2866024971008301 	 0.45035696029663086 	 0.44663166999816895 	 0.39555931091308594 	 0.3608682155609131 	 
2025-07-25 19:06:32.008912 test begin: paddle.nn.functional.tanhshrink(Tensor([2822401, 3, 3],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([2822401, 3, 3],"float64"), None, ) 	 25401609 	 1000 	 0.29955625534057617 	 0.7456822395324707 	 0.29069018363952637 	 0.3797023296356201 	 0.4484097957611084 	 1.185147762298584 	 0.3970601558685303 	 0.4037284851074219 	 
2025-07-25 19:06:37.325152 test begin: paddle.nn.functional.tanhshrink(Tensor([3, 2822401, 3],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([3, 2822401, 3],"float64"), None, ) 	 25401609 	 1000 	 0.5262346267700195 	 2.189307451248169 	 0.2907392978668213 	 0.3797481060028076 	 0.4483675956726074 	 1.1852715015411377 	 0.3941519260406494 	 0.403841495513916 	 
2025-07-25 19:06:45.962144 test begin: paddle.nn.functional.tanhshrink(Tensor([3, 3, 2822401],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([3, 3, 2822401],"float64"), None, ) 	 25401609 	 1000 	 0.3040306568145752 	 0.7431774139404297 	 0.2907288074493408 	 0.3796665668487549 	 0.44760918617248535 	 1.1852741241455078 	 0.3963449001312256 	 0.40381431579589844 	 
2025-07-25 19:06:49.667738 test begin: paddle.nn.functional.tanhshrink(Tensor([50803201],"float32"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([50803201],"float32"), None, ) 	 50803201 	 1000 	 0.2956044673919678 	 0.7520186901092529 	 0.2865171432495117 	 0.3797640800476074 	 0.45021963119506836 	 1.189192533493042 	 0.3987002372741699 	 0.4051859378814697 	 
2025-07-25 19:06:53.955300 test begin: paddle.nn.functional.tanhshrink(x=Tensor([2822401, 3, 3],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([2822401, 3, 3],"float64"), ) 	 25401609 	 1000 	 0.3022575378417969 	 0.7430739402770996 	 0.29048895835876465 	 0.37967348098754883 	 0.44771862030029297 	 1.1852047443389893 	 0.39621639251708984 	 0.40377140045166016 	 
2025-07-25 19:06:57.636163 test begin: paddle.nn.functional.tanhshrink(x=Tensor([3, 2822401, 3],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([3, 2822401, 3],"float64"), ) 	 25401609 	 1000 	 0.3008592128753662 	 0.7432901859283447 	 0.29050612449645996 	 0.3796718120574951 	 0.4482400417327881 	 1.1851935386657715 	 0.3966984748840332 	 0.40381860733032227 	 
2025-07-25 19:07:01.328319 test begin: paddle.nn.functional.tanhshrink(x=Tensor([3, 3, 2822401],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([3, 3, 2822401],"float64"), ) 	 25401609 	 1000 	 0.29955172538757324 	 0.7432620525360107 	 0.2904479503631592 	 0.3797154426574707 	 0.4478800296783447 	 1.1850812435150146 	 0.39627981185913086 	 0.403745174407959 	 
2025-07-25 19:07:04.971215 test begin: paddle.nn.functional.temporal_shift(Tensor([128, 127, 56, 56],"float32"), 8, 0.125, )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:07.633612 test begin: paddle.nn.functional.temporal_shift(Tensor([128, 256, 28, 56],"float32"), 8, 0.125, )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:10.267775 test begin: paddle.nn.functional.temporal_shift(Tensor([128, 256, 56, 28],"float32"), 8, 0.125, )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:12.843496 test begin: paddle.nn.functional.temporal_shift(Tensor([240, 256, 15, 56],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:15.431485 test begin: paddle.nn.functional.temporal_shift(Tensor([240, 256, 56, 15],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:18.015777 test begin: paddle.nn.functional.temporal_shift(Tensor([240, 271, 28, 28],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:20.588496 test begin: paddle.nn.functional.temporal_shift(Tensor([240, 512, 15, 28],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:23.220077 test begin: paddle.nn.functional.temporal_shift(Tensor([240, 512, 28, 15],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:25.875860 test begin: paddle.nn.functional.temporal_shift(Tensor([240, 68, 56, 56],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:28.463717 test begin: paddle.nn.functional.temporal_shift(Tensor([64, 256, 56, 56],"float32"), 8, 0.125, )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:31.054966 test begin: paddle.nn.functional.temporal_shift(Tensor([64, 256, 56, 56],"float32"), 8, 0.125, data_format="NCHW", )
[Error] too many values to unpack (expected 4)
2025-07-25 19:07:33.628910 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 28225, 3, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 28225, 3, 3],"float64"), 1.0, 0.0, None, ) 	 25402500 	 1000 	 0.30059814453125 	 2.023594856262207 	 0.28909969329833984 	 0.27738094329833984 	 0.44870710372924805 	 0.4460775852203369 	 0.3975403308868408 	 0.363187313079834 	 
2025-07-25 19:07:39.215925 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 21169, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 21169, 3],"float64"), 1.0, 0.0, None, ) 	 25402800 	 1000 	 0.3006749153137207 	 0.3028242588043213 	 0.2891082763671875 	 0.2771339416503906 	 0.44853734970092773 	 0.4460601806640625 	 0.3968832492828369 	 0.36612892150878906 	 
2025-07-25 19:07:41.729391 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 21169],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 21169],"float64"), 1.0, 0.0, None, ) 	 25402800 	 1000 	 0.2982943058013916 	 0.2982940673828125 	 0.28906822204589844 	 0.2774026393890381 	 0.4484410285949707 	 0.44599366188049316 	 0.39754271507263184 	 0.362764835357666 	 
2025-07-25 19:07:44.238622 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 42337],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 42337],"float32"), 1.0, 0.0, None, ) 	 50804400 	 1000 	 0.29598331451416016 	 0.5343048572540283 	 0.2867152690887451 	 0.26972198486328125 	 0.45026397705078125 	 0.44680285453796387 	 0.3984498977661133 	 0.36220502853393555 	 
2025-07-25 19:07:50.720565 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 42337, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 42337, 3],"float32"), 1.0, 0.0, None, ) 	 50804400 	 1000 	 0.2959721088409424 	 0.2982058525085449 	 0.2867000102996826 	 0.27783870697021484 	 0.45028162002563477 	 0.44681620597839355 	 0.3987104892730713 	 0.361558198928833 	 
2025-07-25 19:07:53.830693 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 56449, 3, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 56449, 3, 3],"float32"), 1.0, 0.0, None, ) 	 50804100 	 1000 	 0.29603147506713867 	 0.29818224906921387 	 0.2867705821990967 	 0.277634859085083 	 0.45026254653930664 	 0.4467337131500244 	 0.39882445335388184 	 0.3640310764312744 	 
2025-07-25 19:07:56.901070 test begin: paddle.nn.functional.thresholded_relu(Tensor([1411201, 4, 3, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([1411201, 4, 3, 3],"float32"), 1.0, 0.0, None, ) 	 50803236 	 1000 	 0.2959299087524414 	 0.2981104850769043 	 0.28672361373901367 	 0.2775380611419678 	 0.450253963470459 	 0.4467782974243164 	 0.39815688133239746 	 0.36226630210876465 	 
2025-07-25 19:07:59.977160 test begin: paddle.nn.functional.thresholded_relu(Tensor([705601, 4, 3, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([705601, 4, 3, 3],"float64"), 1.0, 0.0, None, ) 	 25401636 	 1000 	 0.298229455947876 	 0.2983100414276123 	 0.2891108989715576 	 0.2779970169067383 	 0.44866442680358887 	 0.445955753326416 	 0.39724016189575195 	 0.3572385311126709 	 
2025-07-25 19:08:02.436789 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 42337],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 42337],"float32"), ) 	 50804400 	 1000 	 0.2960224151611328 	 0.29814696311950684 	 0.286313533782959 	 0.2776939868927002 	 0.4503519535064697 	 0.44673871994018555 	 0.3978769779205322 	 0.3623526096343994 	 
2025-07-25 19:08:05.531143 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 42337, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 42337, 3],"float32"), ) 	 50804400 	 1000 	 0.29600071907043457 	 0.29811620712280273 	 0.2862834930419922 	 0.27756333351135254 	 0.4502537250518799 	 0.44684839248657227 	 0.39397501945495605 	 0.3625776767730713 	 
2025-07-25 19:08:08.582495 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 56449, 3, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 56449, 3, 3],"float32"), ) 	 50804100 	 1000 	 0.298201322555542 	 0.2981276512145996 	 0.28643131256103516 	 0.277801513671875 	 0.45029640197753906 	 0.446765661239624 	 0.39296483993530273 	 0.3636589050292969 	 
2025-07-25 19:08:11.689216 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([1411201, 4, 3, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([1411201, 4, 3, 3],"float32"), ) 	 50803236 	 1000 	 0.29596590995788574 	 0.3138763904571533 	 0.2838766574859619 	 0.27763843536376953 	 0.45029640197753906 	 0.4467582702636719 	 0.3988001346588135 	 0.3629276752471924 	 
2025-07-25 19:08:14.805702 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 	 76204815 	 1000 	 2.362281084060669 	 1.8224163055419922 	 3.9577484130859375e-05 	 0.15487217903137207 	 4.072316884994507 	 2.8686940670013428 	 0.46416163444519043 	 0.1835322380065918 	 
2025-07-25 19:08:28.090285 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 	 76204815 	 1000 	 2.3182051181793213 	 2.298384666442871 	 2.6941299438476562e-05 	 0.1685795783996582 	 4.070037603378296 	 2.8650550842285156 	 0.5209534168243408 	 0.19552254676818848 	 
2025-07-25 19:08:43.914794 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 	 76204815 	 1000 	 2.32547926902771 	 1.825465440750122 	 2.4557113647460938e-05 	 0.1548290252685547 	 4.072910308837891 	 2.865168571472168 	 0.46424102783203125 	 0.19551610946655273 	 
2025-07-25 19:08:58.741392 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 	 76204815 	 1000 	 2.776606559753418 	 2.2347412109375 	 0.00018715858459472656 	 0.20737910270690918 	 4.420430421829224 	 3.257398843765259 	 0.5035250186920166 	 0.20836853981018066 	 
2025-07-25 19:09:12.939419 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 	 76204815 	 1000 	 2.7420711517333984 	 2.198146343231201 	 0.00015473365783691406 	 0.24913954734802246 	 4.387482643127441 	 3.2245609760284424 	 0.5614078044891357 	 0.21995306015014648 	 
2025-07-25 19:09:27.146472 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 	 76204815 	 1000 	 2.781583786010742 	 2.236748695373535 	 0.0001761913299560547 	 0.2074589729309082 	 4.420189380645752 	 3.2015621662139893 	 0.5036106109619141 	 0.21841692924499512 	 
2025-07-25 19:09:43.267567 test begin: paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50831360 	 1000 	 1.7481067180633545 	 3.1143767833709717 	 0.17856597900390625 	 0.24560165405273438 	 3.739699363708496 	 7.177762746810913 	 0.34763479232788086 	 7.097743034362793 	 
2025-07-25 19:10:08.973407 test begin: paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50831360 	 1000 	 1.747563123703003 	 2.6457505226135254 	 0.17857074737548828 	 0.24558758735656738 	 3.739652156829834 	 7.177762031555176 	 0.3475944995880127 	 7.096647262573242 	 
2025-07-25 19:10:32.575275 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50805120 	 1000 	 1.8287131786346436 	 2.65274715423584 	 0.18686294555664062 	 0.22592401504516602 	 3.7793796062469482 	 7.225032567977905 	 0.3513367176055908 	 7.1373090744018555 	 
2025-07-25 19:10:57.828345 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50805120 	 1000 	 1.828829288482666 	 2.6647958755493164 	 0.18687868118286133 	 0.22590374946594238 	 3.77951979637146 	 7.224844455718994 	 0.3513221740722656 	 7.1420183181762695 	 
2025-07-25 19:11:23.306432 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50805120 	 1000 	 2.1575348377227783 	 2.9931576251983643 	 0.22047042846679688 	 0.254610538482666 	 3.7126541137695312 	 7.098452806472778 	 0.3450896739959717 	 7.016014814376831 	 
2025-07-25 19:11:48.424527 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50805120 	 1000 	 2.157557487487793 	 2.988992929458618 	 0.22048687934875488 	 0.2545642852783203 	 3.7127811908721924 	 7.275660276412964 	 0.34516310691833496 	 7.192413330078125 	 
2025-07-25 19:12:13.516826 test begin: paddle.nn.functional.unfold(Tensor([338, 3, 224, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([338, 3, 224, 224],"float32"), 16, 16, ) 	 50878464 	 1000 	 24.97545862197876 	 24.106731414794922 	 0.07338213920593262 	 0.07290244102478027 	 3.3272945880889893 	 2.110384225845337 	 0.010007143020629883 	 2.0282540321350098 	 
2025-07-25 19:13:10.834645 test begin: paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50810880 	 1000 	 36.99141788482666 	 31.290698528289795 	 0.009124994277954102 	 0.00764775276184082 	 81.29800295829773 	 7.175208330154419 	 0.020033597946166992 	 7.094411849975586 	 
2025-07-25 19:15:55.997009 test begin: paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50810880 	 1000 	 37.014506816864014 	 31.290927171707153 	 0.009123563766479492 	 0.007639408111572266 	 81.29739022254944 	 7.175091028213501 	 0.020025253295898438 	 7.087205171585083 	 
2025-07-25 19:18:42.386450 test begin: paddle.nn.functional.unfold(Tensor([64, 16, 224, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 16, 224, 224],"float32"), 16, 16, ) 	 51380224 	 1000 	 15.388662576675415 	 7.9208455085754395 	 0.24564623832702637 	 0.1264481544494629 	 1.8765645027160645 	 2.131251573562622 	 0.029386520385742188 	 2.0510220527648926 	 
2025-07-25 19:19:11.456871 test begin: paddle.nn.functional.unfold(Tensor([64, 3, 1182, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 3, 1182, 224],"float32"), 16, 16, ) 	 50835456 	 1000 	 15.355732440948486 	 7.871351957321167 	 0.24511027336120605 	 0.12569546699523926 	 1.8666129112243652 	 2.410240650177002 	 0.029235363006591797 	 1.2308061122894287 	 
2025-07-25 19:19:41.595544 test begin: paddle.nn.functional.unfold(Tensor([64, 3, 224, 1182],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 3, 224, 1182],"float32"), 16, 16, ) 	 50835456 	 1000 	 15.77395224571228 	 7.9729554653167725 	 0.2518177032470703 	 0.1272745132446289 	 1.8697600364685059 	 2.4125349521636963 	 0.02930283546447754 	 1.2320106029510498 	 
2025-07-25 19:20:11.775390 test begin: paddle.nn.functional.zeropad2d(Tensor([169, 3, 224, 224],"int64"), Tensor([4],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:129: VisibleDeprecationWarning: [93m
Warning:
API "paddle.nn.functional.common.zeropad2d" is deprecated since 3.0.0, and will be removed in future versions. Please use "paddle.nn.ZeroPad2D" instead.
    Reason: Please use class ZeroPad2D [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:147: VisibleDeprecationWarning: [93m
Warning:
API "paddle.nn.functional.common.zeropad2d" is deprecated since 3.0.0, and will be removed in future versions. Please use "paddle.nn.ZeroPad2D" instead.
    Reason: Please use class ZeroPad2D [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
W0725 19:20:12.838112 158928 backward.cc:462] While running Node (Pad3dGradNode) raises an EnforceNotMet exception
[Error] (NotFound) The kernel with key (GPU, Undefined(AnyLayout), int64) of kernel `pad3d_grad` is not registered and fail to fallback to CPU one. Selected wrong DataType `int64`. Paddle support following DataTypes: float64, complex128, float16, float32, complex64, bfloat16.
  [Hint: Expected kernel_iter != iter->second.end(), but received kernel_iter == iter->second.end().] (at ../paddle/phi/core/kernel_factory.cc:380)

[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([169, 3, 224, 224],"int64"), Tensor([4],"int32"), ) 	 25439236 	 1000 	 0.37074828147888184 	 0.509063720703125 	 0.00032067298889160156 	 0.0004305839538574219 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:20:13.424826 test begin: paddle.nn.functional.zeropad2d(Tensor([338, 3, 224, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([338, 3, 224, 224],"float32"), list[2,2,2,2,], ) 	 50878464 	 1000 	 0.6338822841644287 	 0.468184232711792 	 0.5998749732971191 	 0.23912906646728516 	 0.7480714321136475 	 0.311720609664917 	 0.3821382522583008 	 0.2399001121520996 	 combined
2025-07-25 19:20:17.237579 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"float64"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"float64"), list[2,2,2,2,], ) 	 25489408 	 1000 	 0.3240833282470703 	 0.4669952392578125 	 0.2929379940032959 	 0.23462367057800293 	 0.46114110946655273 	 0.3038449287414551 	 0.23563623428344727 	 0.23349905014038086 	 combined
2025-07-25 19:20:19.831652 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"int64"), Tensor([4],"int32"), )
W0725 19:20:20.915854 159518 backward.cc:462] While running Node (Pad3dGradNode) raises an EnforceNotMet exception
[Error] (NotFound) The kernel with key (GPU, Undefined(AnyLayout), int64) of kernel `pad3d_grad` is not registered and fail to fallback to CPU one. Selected wrong DataType `int64`. Paddle support following DataTypes: float64, complex128, float16, float32, complex64, bfloat16.
  [Hint: Expected kernel_iter != iter->second.end(), but received kernel_iter == iter->second.end().] (at ../paddle/phi/core/kernel_factory.cc:380)

[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"int64"), Tensor([4],"int32"), ) 	 25489412 	 1000 	 0.38146114349365234 	 0.5345923900604248 	 0.0003330707550048828 	 0.0004506111145019531 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:20:21.535607 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 254, 224, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 254, 224, 224],"float32"), list[2,2,2,2,], ) 	 50978816 	 1000 	 0.6313071250915527 	 0.46924448013305664 	 0.6000263690948486 	 0.23968291282653809 	 0.7507646083831787 	 0.3122894763946533 	 0.38286685943603516 	 0.2417452335357666 	 combined
2025-07-25 19:20:25.334788 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 18901, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 18901, 224],"float32"), list[2,2,2,2,], ) 	 50805888 	 1000 	 0.619154691696167 	 0.4650766849517822 	 0.5873918533325195 	 0.23752737045288086 	 0.7478740215301514 	 0.31108522415161133 	 0.38268089294433594 	 0.23801422119140625 	 combined
2025-07-25 19:20:29.076232 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 18901],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 18901],"float32"), list[2,2,2,2,], ) 	 50805888 	 1000 	 0.617809534072876 	 0.44603967666625977 	 0.5863621234893799 	 0.2285010814666748 	 0.7466616630554199 	 0.30849289894104004 	 0.3814809322357178 	 0.23787260055541992 	 combined
2025-07-25 19:20:32.886047 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 9451],"float64"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 9451],"float64"), list[2,2,2,2,], ) 	 25404288 	 1000 	 0.3199753761291504 	 0.4402804374694824 	 0.2887427806854248 	 0.22482657432556152 	 0.457592248916626 	 0.29999876022338867 	 0.2336277961730957 	 0.22934889793395996 	 combined
2025-07-25 19:20:37.698457 test begin: paddle.nonzero(Tensor([510, 128, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 128, 28, 28],"float32"), ) 	 51179520 	 1000 	 7.423947334289551 	 2.3278489112854004 	 0.005429744720458984 	 0.0021698474884033203 	 None 	 None 	 None 	 None 	 
2025-07-25 19:20:50.102866 test begin: paddle.nonzero(Tensor([510, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 80, 28, 45],"float32"), ) 	 51408000 	 1000 	 7.453406810760498 	 2.3394200801849365 	 0.005492210388183594 	 0.002131223678588867 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:02.634722 test begin: paddle.nonzero(Tensor([510, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 80, 45, 28],"float32"), ) 	 51408000 	 1000 	 7.448264837265015 	 2.3580710887908936 	 0.005476713180541992 	 0.0021262168884277344 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:17.105280 test begin: paddle.nonzero(Tensor([511, 127, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 127, 28, 28],"float32"), ) 	 50879248 	 1000 	 7.430092811584473 	 2.334494113922119 	 0.005444526672363281 	 0.002129077911376953 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:27.668266 test begin: paddle.nonzero(Tensor([511, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 80, 28, 45],"float32"), ) 	 51508800 	 1000 	 7.445581912994385 	 2.8051819801330566 	 0.005449771881103516 	 0.002126932144165039 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:41.423315 test begin: paddle.nonzero(Tensor([511, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 80, 45, 28],"float32"), ) 	 51508800 	 1000 	 7.483619451522827 	 2.3538637161254883 	 0.005500316619873047 	 0.002161741256713867 	 None 	 None 	 None 	 None 	 
2025-07-25 19:21:52.116092 test begin: paddle.nonzero(Tensor([512, 127, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 127, 28, 28],"float32"), ) 	 50978816 	 1000 	 7.420229196548462 	 2.3216683864593506 	 0.005449771881103516 	 0.0021262168884277344 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:02.711203 test begin: paddle.nonzero(Tensor([512, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 80, 28, 45],"float32"), ) 	 51609600 	 1000 	 7.470799446105957 	 2.3718068599700928 	 0.005473613739013672 	 0.0021104812622070312 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:14.772836 test begin: paddle.nonzero(Tensor([512, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 80, 45, 28],"float32"), ) 	 51609600 	 1000 	 7.461335897445679 	 2.3443949222564697 	 0.00547337532043457 	 0.002144336700439453 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:25.452638 test begin: paddle.nonzero(Tensor([811, 80, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([811, 80, 28, 28],"float32"), ) 	 50865920 	 1000 	 7.358350992202759 	 2.3126039505004883 	 0.005361318588256836 	 0.002112150192260742 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:38.073071 test begin: paddle.not_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), ) 	 38103936 	 1000 	 1.9282116889953613 	 0.5214085578918457 	 0.5428032875061035 	 0.5019943714141846 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:42.024176 test begin: paddle.not_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), ) 	 38102688 	 1000 	 0.5584022998809814 	 0.5220563411712646 	 0.5470325946807861 	 0.5023863315582275 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:43.770798 test begin: paddle.not_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), ) 	 31753280 	 1000 	 0.21319055557250977 	 0.21958041191101074 	 0.2032487392425537 	 0.20655035972595215 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:44.671565 test begin: paddle.not_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), ) 	 25403456 	 1000 	 0.5650768280029297 	 0.47240376472473145 	 0.5510354042053223 	 0.4593956470489502 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:46.108642 test begin: paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), ) 	 25405120 	 1000 	 1.0448250770568848 	 0.9492764472961426 	 1.0350167751312256 	 0.9367043972015381 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:48.470786 test begin: paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), ) 	 228616128 	 1000 	 1.7880034446716309 	 1.5707964897155762 	 1.7780370712280273 	 1.5581493377685547 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:55.276695 test begin: paddle.not_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), ) 	 76205064 	 1000 	 1.1065168380737305 	 1.0246024131774902 	 1.0966756343841553 	 1.0118632316589355 	 None 	 None 	 None 	 None 	 
2025-07-25 19:22:58.559655 test begin: paddle.not_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), ) 	 76205376 	 1000 	 1.105809211730957 	 1.0259275436401367 	 1.0892889499664307 	 1.0117995738983154 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:01.889076 test begin: paddle.not_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), ) 	 76205184 	 1000 	 1.0980534553527832 	 1.0261054039001465 	 1.0880823135375977 	 1.013456106185913 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:05.165651 test begin: paddle.not_equal(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 0.31336116790771484 	 0.3132820129394531 	 0.3013894557952881 	 0.30113720893859863 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:06.533265 test begin: paddle.not_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), ) 	 38102784 	 1000 	 0.5592446327209473 	 0.5154628753662109 	 0.5471944808959961 	 0.5023791790008545 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:08.172083 test begin: paddle.numel(Tensor([50803201],"float32"), )
[Prof] paddle.numel 	 paddle.numel(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.008992433547973633 	 0.029457569122314453 	 2.1219253540039062e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:08.986321 test begin: paddle.ones_like(Tensor([144, 392, 901],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([144, 392, 901],"float32"), ) 	 50859648 	 1000 	 0.13494324684143066 	 0.13448381423950195 	 0.12364697456359863 	 0.12189865112304688 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:10.123290 test begin: paddle.ones_like(Tensor([144, 901, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([144, 901, 392],"float32"), ) 	 50859648 	 1000 	 0.13451433181762695 	 0.1344127655029297 	 0.12359118461608887 	 0.12180876731872559 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:11.237431 test begin: paddle.ones_like(Tensor([160, 392, 811],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([160, 392, 811],"float32"), ) 	 50865920 	 1000 	 0.13724112510681152 	 0.13450050354003906 	 0.12365889549255371 	 0.11743569374084473 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:12.299345 test begin: paddle.ones_like(Tensor([160, 811, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([160, 811, 392],"float32"), ) 	 50865920 	 1000 	 1.0474352836608887 	 0.13736438751220703 	 0.12337732315063477 	 0.12198567390441895 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:15.523055 test begin: paddle.ones_like(Tensor([176, 392, 737],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([176, 392, 737],"float32"), ) 	 50847104 	 1000 	 0.1392066478729248 	 0.14588260650634766 	 0.1234750747680664 	 0.12226319313049316 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:18.948178 test begin: paddle.ones_like(Tensor([176, 737, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([176, 737, 392],"float32"), ) 	 50847104 	 1000 	 0.13430380821228027 	 0.1360323429107666 	 0.12355613708496094 	 0.12229442596435547 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:19.999322 test begin: paddle.ones_like(Tensor([331, 392, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([331, 392, 392],"float32"), ) 	 50862784 	 1000 	 0.13431668281555176 	 0.13705062866210938 	 0.12364673614501953 	 0.1218414306640625 	 None 	 None 	 None 	 None 	 
2025-07-25 19:23:21.051850 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([2],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([2],"float32"), ) 	 50803203 	 1000 	 5.29498291015625 	 0.518561840057373 	 0.1103675365447998 	 0.5038204193115234 	 3.711217164993286 	 2.6148648262023926 	 1.2617180347442627 	 0.5333936214447021 	 
2025-07-25 19:23:37.414662 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([32],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([32],"float32"), ) 	 50803233 	 1000 	 5.629226446151733 	 5.555495262145996 	 0.112548828125 	 1.4185104370117188 	 13.175384283065796 	 40.72772240638733 	 4.483143329620361 	 2.0791494846343994 	 
2025-07-25 19:25:14.210623 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([4],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([4],"float32"), ) 	 50803205 	 1000 	 5.304147005081177 	 0.9456148147583008 	 0.11055326461791992 	 0.9303367137908936 	 4.347085237503052 	 5.06798243522644 	 1.4788107872009277 	 1.0340750217437744 	 
2025-07-25 19:25:37.432747 test begin: paddle.pdist(Tensor([10, 5080321],"float32"), 0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([10, 5080321],"float32"), 0, ) 	 50803210 	 1000 	 6.593853950500488 	 9.021356582641602 	 4.57763671875e-05 	 9.00955605506897 	 5.638438940048218 	 0.13420820236206055 	 0.005540132522583008 	 0.058797359466552734 	 
2025-07-25 19:26:00.502194 test begin: paddle.pdist(Tensor([10, 5080321],"float32"), 1.0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([10, 5080321],"float32"), 1.0, ) 	 50803210 	 1000 	 5.9200804233551025 	 8.379312515258789 	 4.649162292480469e-05 	 8.36769962310791 	 22.81326174736023 	 13.571463108062744 	 0.022679805755615234 	 6.933133125305176 	 
2025-07-25 19:26:53.451803 test begin: paddle.pdist(Tensor([50, 508033],"float64"), 2.0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([50, 508033],"float64"), 2.0, ) 	 25401650 	 1000 	 22.964290142059326 	 2.300351619720459 	 4.863739013671875e-05 	 2.2886228561401367 	 87.94694757461548 	 39.30702328681946 	 0.08772587776184082 	 4.447581768035889 	 
2025-07-25 19:29:28.218665 test begin: paddle.polar(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), ) 	 101606528 	 1000 	 2.108555555343628 	 2.1025736331939697 	 0.4249429702758789 	 0.42413783073425293 	 4.601176023483276 	 5.037598371505737 	 0.6716389656066895 	 0.4677586555480957 	 combined
2025-07-25 19:29:45.492872 test begin: paddle.polar(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), ) 	 101613568 	 1000 	 2.0795207023620605 	 2.149892568588257 	 0.4248931407928467 	 0.42412495613098145 	 4.59809684753418 	 5.038144826889038 	 0.6710371971130371 	 0.46781277656555176 	 combined
2025-07-25 19:30:04.004631 test begin: paddle.polar(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 51380224 	 1000 	 1.7934141159057617 	 1.8471488952636719 	 0.36670660972595215 	 0.36875128746032715 	 3.499725103378296 	 4.652553081512451 	 0.3969602584838867 	 0.3654646873474121 	 combined
2025-07-25 19:30:17.723445 test begin: paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), ) 	 51380224 	 1000 	 1.2104151248931885 	 1.229346752166748 	 0.24779295921325684 	 0.24997806549072266 	 2.607574701309204 	 2.8946533203125 	 0.29528164863586426 	 0.22739696502685547 	 combined
2025-07-25 19:30:27.566860 test begin: paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 101711872 	 1000 	 2.080174684524536 	 2.1076884269714355 	 0.4253659248352051 	 0.42452073097229004 	 4.603686094284058 	 5.042742013931274 	 0.671802282333374 	 0.4682629108428955 	 combined
2025-07-25 19:30:44.615091 test begin: paddle.polygamma(Tensor([10, 20, 254017],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([10, 20, 254017],"float32"), 1, ) 	 50803400 	 1000 	 5.580672740936279 	 0.6285650730133057 	 5.571270227432251 	 0.615140438079834 	 9.08345079421997 	 10.272173404693604 	 9.031399250030518 	 5.248631715774536 	 
2025-07-25 19:31:12.689349 test begin: paddle.polygamma(Tensor([10, 5080321, 1],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([10, 5080321, 1],"float32"), 1, ) 	 50803210 	 1000 	 5.578997611999512 	 0.6320369243621826 	 5.569703817367554 	 0.6160135269165039 	 9.083682298660278 	 10.267822742462158 	 9.0320405960083 	 5.2462427616119385 	 
2025-07-25 19:31:40.305403 test begin: paddle.polygamma(Tensor([2, 12700801],"float64"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 12700801],"float64"), 1, ) 	 25401602 	 1000 	 9.265904188156128 	 0.644716739654541 	 9.255838394165039 	 0.6294271945953369 	 11.440995454788208 	 21.528167247772217 	 11.389878988265991 	 11.000754833221436 	 
2025-07-25 19:32:24.322489 test begin: paddle.polygamma(Tensor([2, 2, 6350401],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 2, 6350401],"float64"), 2, ) 	 25401604 	 1000 	 11.383636951446533 	 21.09468960762024 	 11.37448000907898 	 21.08227777481079 	 9.133098840713501 	 9.297483682632446 	 9.078075647354126 	 4.753800630569458 	 
2025-07-25 19:33:17.935656 test begin: paddle.polygamma(Tensor([2, 2116801, 6],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 2116801, 6],"float64"), 2, ) 	 25401612 	 1000 	 11.394068479537964 	 21.09743332862854 	 11.380899429321289 	 21.075249433517456 	 9.132404804229736 	 9.291889905929565 	 9.081413745880127 	 4.746817350387573 	 
2025-07-25 19:34:10.357586 test begin: paddle.polygamma(Tensor([2116801, 2, 6],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2116801, 2, 6],"float64"), 2, ) 	 25401612 	 1000 	 11.390460968017578 	 21.104963302612305 	 11.3804292678833 	 21.088290691375732 	 9.136932373046875 	 9.302882194519043 	 9.08571720123291 	 4.756211757659912 	 
2025-07-25 19:35:02.875061 test begin: paddle.polygamma(Tensor([2540161, 20, 1],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2540161, 20, 1],"float32"), 1, ) 	 50803220 	 1000 	 5.584532022476196 	 0.628077507019043 	 5.575245380401611 	 0.6167619228363037 	 9.090175151824951 	 10.273155450820923 	 9.03889536857605 	 5.249659538269043 	 
2025-07-25 19:35:30.146925 test begin: paddle.polygamma(Tensor([4233601, 6],"float64"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([4233601, 6],"float64"), 1, ) 	 25401606 	 1000 	 9.269649505615234 	 0.6414191722869873 	 9.259279251098633 	 0.6303207874298096 	 11.45116114616394 	 21.542375564575195 	 11.400152683258057 	 11.007637977600098 	 
2025-07-25 19:36:14.205441 test begin: paddle.positive(Tensor([10, 5080321],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.001795053482055664 	 0.0002009868621826172 	 1.0251998901367188e-05 	 1.33514404296875e-05 	 0.02902507781982422 	 0.04655122756958008 	 2.5272369384765625e-05 	 4.00543212890625e-05 	 combined
2025-07-25 19:36:15.841490 test begin: paddle.positive(Tensor([1693441, 3, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([1693441, 3, 4, 5],"float16"), ) 	 101606460 	 1000 	 0.0018851757049560547 	 0.0002048015594482422 	 1.5735626220703125e-05 	 1.3113021850585938e-05 	 0.028793811798095703 	 0.054204463958740234 	 2.9802322387695312e-05 	 6.4849853515625e-05 	 combined
2025-07-25 19:36:19.618527 test begin: paddle.positive(Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([2, 1270081, 4, 5],"float32"), ) 	 50803240 	 1000 	 0.0017998218536376953 	 0.0002067089080810547 	 5.7220458984375e-06 	 2.0265579223632812e-05 	 0.02902078628540039 	 0.04755449295043945 	 2.002716064453125e-05 	 3.910064697265625e-05 	 combined
2025-07-25 19:36:21.342901 test begin: paddle.positive(Tensor([2, 2540161, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([2, 2540161, 4, 5],"float16"), ) 	 101606440 	 1000 	 0.0017864704132080078 	 0.00020384788513183594 	 5.0067901611328125e-06 	 1.2874603271484375e-05 	 0.0294342041015625 	 0.04767298698425293 	 2.384185791015625e-05 	 5.1021575927734375e-05 	 combined
2025-07-25 19:36:25.130895 test begin: paddle.positive(Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([2, 3, 1693441, 5],"float32"), ) 	 50803230 	 1000 	 0.0017886161804199219 	 0.00020813941955566406 	 5.4836273193359375e-06 	 1.430511474609375e-05 	 0.02906203269958496 	 0.047738075256347656 	 3.361701965332031e-05 	 4.9114227294921875e-05 	 combined
2025-07-25 19:36:26.739793 test begin: paddle.positive(Tensor([2, 3, 3386881, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([2, 3, 3386881, 5],"float16"), ) 	 101606430 	 1000 	 0.0018076896667480469 	 0.0003402233123779297 	 5.7220458984375e-06 	 3.457069396972656e-05 	 0.02872490882873535 	 0.04771614074707031 	 2.0265579223632812e-05 	 5.793571472167969e-05 	 combined
2025-07-25 19:36:31.313015 test begin: paddle.positive(Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([2, 3, 4, 2116801],"float32"), ) 	 50803224 	 1000 	 0.001779317855834961 	 0.00020194053649902344 	 1.1444091796875e-05 	 1.3113021850585938e-05 	 0.02898383140563965 	 0.04988813400268555 	 1.1682510375976562e-05 	 5.054473876953125e-05 	 combined
2025-07-25 19:36:34.354705 test begin: paddle.positive(Tensor([2, 3, 4, 4233601],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([2, 3, 4, 4233601],"float16"), ) 	 101606424 	 1000 	 0.0018100738525390625 	 0.00020432472229003906 	 9.298324584960938e-06 	 1.3113021850585938e-05 	 0.04217958450317383 	 0.04729628562927246 	 3.933906555175781e-05 	 4.410743713378906e-05 	 combined
2025-07-25 19:36:40.039917 test begin: paddle.positive(Tensor([49613, 1024],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([49613, 1024],"float32"), ) 	 50803712 	 1000 	 0.001775503158569336 	 0.00020051002502441406 	 5.0067901611328125e-06 	 1.3113021850585938e-05 	 0.02895331382751465 	 0.04640030860900879 	 2.7418136596679688e-05 	 4.172325134277344e-05 	 combined
2025-07-25 19:36:41.771416 test begin: paddle.positive(Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([846721, 3, 4, 5],"float32"), ) 	 50803260 	 1000 	 0.0025911331176757812 	 0.00020241737365722656 	 8.344650268554688e-06 	 1.4543533325195312e-05 	 0.03252458572387695 	 0.051587820053100586 	 4.458427429199219e-05 	 8.153915405273438e-05 	 combined
2025-07-25 19:36:43.646801 test begin: paddle.pow(Tensor([1024, 1024, 25],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 1024, 25],"float64"), 2, ) 	 26214400 	 1000 	 0.5918607711791992 	 0.30896854400634766 	 0.5820560455322266 	 0.29448699951171875 	 0.6255276203155518 	 1.0859580039978027 	 0.5720138549804688 	 0.3694753646850586 	 
2025-07-25 19:36:47.350578 test begin: paddle.pow(Tensor([1024, 1024, 49],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 1024, 49],"float32"), 2, ) 	 51380224 	 1000 	 0.3734560012817383 	 0.30115509033203125 	 0.3638134002685547 	 0.2877190113067627 	 0.459043025970459 	 1.0656025409698486 	 0.40437769889831543 	 0.36254191398620605 	 
2025-07-25 19:36:51.169244 test begin: paddle.pow(Tensor([1024, 3101, 8],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 3101, 8],"float64"), 2, ) 	 25403392 	 1000 	 0.5733969211578369 	 0.2983667850494385 	 0.5639622211456299 	 0.285247802734375 	 0.6048803329467773 	 1.0526249408721924 	 0.5523676872253418 	 0.35817813873291016 	 
2025-07-25 19:36:54.756475 test begin: paddle.pow(Tensor([1024, 6202, 8],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 6202, 8],"float32"), 2, ) 	 50806784 	 1000 	 0.3693249225616455 	 0.2986593246459961 	 0.35980892181396484 	 0.28322625160217285 	 0.4523189067840576 	 1.0525712966918945 	 0.39995646476745605 	 0.35859084129333496 	 
2025-07-25 19:36:58.543615 test begin: paddle.pow(Tensor([22, 81, 94, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([22, 81, 94, 311],"float32"), 2.0, ) 	 52094988 	 1000 	 0.37887048721313477 	 0.30639219284057617 	 0.36933135986328125 	 0.2911529541015625 	 0.46375489234924316 	 1.0818610191345215 	 0.4114985466003418 	 0.27659130096435547 	 
2025-07-25 19:37:02.415321 test begin: paddle.pow(Tensor([3101, 1024, 8],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([3101, 1024, 8],"float64"), 2, ) 	 25403392 	 1000 	 0.5812957286834717 	 0.29831838607788086 	 0.5653693675994873 	 0.2852656841278076 	 0.6063792705535889 	 1.0514681339263916 	 0.546046257019043 	 0.3581709861755371 	 
2025-07-25 19:37:05.958826 test begin: paddle.pow(Tensor([4, 435, 94, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 435, 94, 311],"float32"), 2.0, ) 	 50867160 	 1000 	 0.3699989318847656 	 0.29959917068481445 	 0.36049318313598633 	 0.28496789932250977 	 0.45305323600769043 	 1.0567333698272705 	 0.39899468421936035 	 0.27021169662475586 	 
2025-07-25 19:37:09.840687 test begin: paddle.pow(Tensor([4, 81, 505, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 81, 505, 311],"float32"), 2.0, ) 	 50885820 	 1000 	 0.37435150146484375 	 0.30347394943237305 	 0.36086225509643555 	 0.2853243350982666 	 0.453139066696167 	 1.0583522319793701 	 0.3999490737915039 	 0.2702031135559082 	 
2025-07-25 19:37:13.630522 test begin: paddle.pow(Tensor([4, 81, 94, 1669],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 81, 94, 1669],"float32"), 2.0, ) 	 50831064 	 1000 	 0.37039661407470703 	 0.3047933578491211 	 0.3600602149963379 	 0.2842140197753906 	 0.45270776748657227 	 1.0588405132293701 	 0.39168524742126465 	 0.27004218101501465 	 
2025-07-25 19:37:17.428683 test begin: paddle.pow(Tensor([6202, 1024, 8],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([6202, 1024, 8],"float32"), 2, ) 	 50806784 	 1000 	 0.3693821430206299 	 0.2979302406311035 	 0.3600037097930908 	 0.2843799591064453 	 0.4525291919708252 	 1.0526232719421387 	 0.40049219131469727 	 0.35865068435668945 	 
2025-07-25 19:37:21.311251 test begin: paddle.prod(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
Warning: The core code of paddle.prod is too complex.
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.25904321670532227 	 0.03825211524963379 	 0.000171661376953125 	 4.2438507080078125e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([28225]) and output[0] has a shape of torch.Size([1, 1, 28225, 1]).
2025-07-25 19:37:22.999208 test begin: paddle.prod(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.31625795364379883 	 0.038092613220214844 	 0.00022983551025390625 	 4.792213439941406e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([28225]) and output[0] has a shape of torch.Size([1, 1, 1, 28225]).
2025-07-25 19:37:24.751095 test begin: paddle.prod(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402412 	 1000 	 0.2560555934906006 	 0.02642369270324707 	 0.000225067138671875 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10, 31361]) and output[0] has a shape of torch.Size([10, 31361, 1, 1]).
2025-07-25 19:37:26.543009 test begin: paddle.prod(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.3214383125305176 	 0.03776836395263672 	 0.0002300739288330078 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9]) and output[0] has a shape of torch.Size([1, 1, 9, 1]).
2025-07-25 19:37:28.244052 test begin: paddle.prod(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.3158528804779053 	 0.02695178985595703 	 0.00028634071350097656 	 4.8160552978515625e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10, 56449]) and output[0] has a shape of torch.Size([10, 1, 56449, 1]).
2025-07-25 19:37:29.954591 test begin: paddle.prod(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.20030522346496582 	 0.026253938674926758 	 0.00017642974853515625 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9, 56449]) and output[0] has a shape of torch.Size([1, 1, 9, 56449]).
2025-07-25 19:37:31.547367 test begin: paddle.prod(Tensor([16, 3175201],"float32"), -1, )
[Prof] paddle.prod 	 paddle.prod(Tensor([16, 3175201],"float32"), -1, ) 	 50803216 	 1000 	 0.17850947380065918 	 0.15265250205993652 	 0.09119534492492676 	 0.077972412109375 	 0.7923643589019775 	 1.5830307006835938 	 0.7392146587371826 	 0.0006411075592041016 	 
2025-07-25 19:37:36.572515 test begin: paddle.prod(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.3211996555328369 	 0.03808903694152832 	 0.00023317337036132812 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9]) and output[0] has a shape of torch.Size([1, 1, 9, 1]).
2025-07-25 19:37:43.639496 test begin: paddle.prod(Tensor([49613, 1024],"float32"), -1, )
[Prof] paddle.prod 	 paddle.prod(Tensor([49613, 1024],"float32"), -1, ) 	 50803712 	 1000 	 0.14656472206115723 	 0.14740991592407227 	 0.131011962890625 	 0.13312244415283203 	 0.7939858436584473 	 1.595059871673584 	 0.7404475212097168 	 0.0006253719329833984 	 
2025-07-25 19:37:47.199621 test begin: paddle.prod(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402007 	 1000 	 0.8067700862884521 	 0.025916576385498047 	 0.0007755756378173828 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9, 9]) and output[0] has a shape of torch.Size([1, 1, 9, 9]).
2025-07-25 19:37:49.380508 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 25402750 	 1000 	 39.420390129089355 	 52.72010540962219 	 0.03876614570617676 	 17.981900453567505 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:40:21.375444 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([2032129, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([2032129, 5, 5],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.12879467010498047 	 0.028089523315429688 	 2.002716064453125e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:48:58.475997 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 2032129, 5],"float32"), 1, "mul", True, False, )
W0725 17:48:58.675799 97420 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 2032129, 5],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.14245271682739258 	 0.027256250381469727 	 2.1457672119140625e-05 	 6.67572021484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:48:59.397561 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 2032129],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 2032129],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13199305534362793 	 0.025825977325439453 	 2.2172927856445312e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:48:59.651683 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 2032129, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 2032129, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 46.52854061126709 	 46.201005697250366 	 0.04607367515563965 	 15.755338191986084 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:52:37.399479 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([2032129, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([2032129, 5, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13298797607421875 	 0.025861740112304688 	 2.0265579223632812e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:52:38.652667 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 2032129, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 2032129, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.1319270133972168 	 0.025891780853271484 	 1.71661376953125e-05 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:52:39.751782 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 2032129],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 2032129],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13283085823059082 	 0.026056289672851562 	 2.2172927856445312e-05 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:52:40.021090 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 26.393627882003784 	 25.22088098526001 	 0.025532960891723633 	 8.597191333770752 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:33.877124 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([1016065, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([1016065, 5, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.13308262825012207 	 0.02588963508605957 	 1.6689300537109375e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:34.139092 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 1016065, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 1016065, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.13272881507873535 	 0.025998830795288086 	 1.2636184692382812e-05 	 3.790855407714844e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:34.389927 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 1016065],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 1016065],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.1330099105834961 	 0.026738643646240234 	 2.0503997802734375e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:34.648154 test begin: paddle.put_along_axis(Tensor([10, 10, 254017],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 254017],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.37823057174682617 	 0.6412074565887451 	 0.00030803680419921875 	 0.1287839412689209 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:39.710468 test begin: paddle.put_along_axis(Tensor([10, 10, 508033],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 508033],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3786184787750244 	 0.6309366226196289 	 0.0003032684326171875 	 0.12869644165039062 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:54:42.915015 test begin: paddle.put_along_axis(Tensor([10, 10, 508033],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 508033],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37409162521362305 	 0.6348116397857666 	 0.0003027915954589844 	 0.12872600555419922 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:45.611628 test begin: paddle.put_along_axis(Tensor([10, 254017, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 254017, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.3807215690612793 	 0.6339881420135498 	 0.00030803680419921875 	 0.1285867691040039 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:48.002750 test begin: paddle.put_along_axis(Tensor([10, 508033, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 508033, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3752126693725586 	 0.633336067199707 	 0.0003039836883544922 	 0.1285388469696045 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:54:51.347055 test begin: paddle.put_along_axis(Tensor([10, 508033, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 508033, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3733234405517578 	 0.6303622722625732 	 0.00030303001403808594 	 0.12855935096740723 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:54:54.261854 test begin: paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([254017, 5, 5],"int64"), Tensor([254017, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([254017, 5, 5],"int64"), Tensor([254017, 5, 5],"int64"), 1, "mul", True, False, ) 	 38102550 	 1000 	 0.839120626449585 	 1.0304324626922607 	 0.0006177425384521484 	 0.2106459140777588 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:55:13.150394 test begin: paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.3784148693084717 	 0.6309959888458252 	 0.0003082752227783203 	 0.12870359420776367 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:55:15.398010 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([254017, 5, 5],"int64"), Tensor([508033, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([254017, 5, 5],"int64"), Tensor([508033, 5, 5],"float32"), 1, "mul", True, False, ) 	 69854550 	 1000 	 0.7776715755462646 	 0.9541974067687988 	 0.0005686283111572266 	 0.19498825073242188 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:55:33.370270 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.375931978225708 	 0.6481480598449707 	 0.0003037452697753906 	 0.12867188453674316 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 17:55:39.833169 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3835563659667969 	 0.6307094097137451 	 0.0003027915954589844 	 0.12865471839904785 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:55:42.548248 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([508033, 5, 5],"int32"), Tensor([508033, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([508033, 5, 5],"int32"), Tensor([508033, 5, 5],"int32"), 1, "mul", True, False, ) 	 76204950 	 1000 	 1.0560505390167236 	 1.2604351043701172 	 0.0008242130279541016 	 0.2577824592590332 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:17.681836 test begin: paddle.rad2deg(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2965888977050781 	 0.29787731170654297 	 0.28089022636413574 	 0.2816503047943115 	 0.29613685607910156 	 0.29787755012512207 	 0.24279165267944336 	 0.23407196998596191 	 
2025-07-25 17:56:20.531612 test begin: paddle.rad2deg(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29622411727905273 	 0.2978060245513916 	 0.28127169609069824 	 0.2836596965789795 	 0.29619312286376953 	 0.29778242111206055 	 0.24116039276123047 	 0.23006534576416016 	 
2025-07-25 17:56:23.415372 test begin: paddle.rad2deg(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2969341278076172 	 0.2978365421295166 	 0.2815375328063965 	 0.2833843231201172 	 0.29616618156433105 	 0.29772043228149414 	 0.24183440208435059 	 0.23425960540771484 	 
2025-07-25 17:56:26.246392 test begin: paddle.rad2deg(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.2981410026550293 	 0.2989981174468994 	 0.28287458419799805 	 0.28408312797546387 	 0.2979269027709961 	 0.2984297275543213 	 0.24070191383361816 	 0.2337021827697754 	 
2025-07-25 17:56:28.567881 test begin: paddle.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2981412410736084 	 0.29830384254455566 	 0.28282952308654785 	 0.28405046463012695 	 0.297924280166626 	 0.29837512969970703 	 0.24395751953125 	 0.23352670669555664 	 
2025-07-25 17:56:30.825206 test begin: paddle.rad2deg(x=Tensor([4, 1587601, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 1587601, 4],"float64"), ) 	 25401616 	 1000 	 0.29814648628234863 	 0.2983670234680176 	 0.2826831340789795 	 0.28409647941589355 	 0.29792070388793945 	 0.2983696460723877 	 0.24394750595092773 	 0.2352619171142578 	 
2025-07-25 17:56:33.104772 test begin: paddle.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2981100082397461 	 0.2983548641204834 	 0.283186674118042 	 0.28420042991638184 	 0.29793787002563477 	 0.2984766960144043 	 0.2439136505126953 	 0.23498034477233887 	 
2025-07-25 17:56:37.331114 test begin: paddle.rad2deg(x=Tensor([4, 4, 1587601],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 1587601],"float64"), ) 	 25401616 	 1000 	 0.9347455501556396 	 0.30762815475463867 	 0.28278374671936035 	 0.28415799140930176 	 0.29790592193603516 	 0.2984163761138916 	 0.24397611618041992 	 0.23138928413391113 	 
2025-07-25 17:56:40.792164 test begin: paddle.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.2987844944000244 	 0.29844093322753906 	 0.28281521797180176 	 0.2787795066833496 	 0.29791831970214844 	 0.29842281341552734 	 0.24427366256713867 	 0.2349686622619629 	 
2025-07-25 17:56:43.081533 test begin: paddle.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.2981278896331787 	 0.29836440086364746 	 0.2829251289367676 	 0.2843003273010254 	 0.2979297637939453 	 0.29839086532592773 	 0.24306178092956543 	 0.23462653160095215 	 
2025-07-25 17:56:45.373115 test begin: paddle.rank(Tensor([10160641, 5],"float32"), )
[Prof] paddle.rank 	 paddle.rank(Tensor([10160641, 5],"float32"), ) 	 50803205 	 1000 	 0.04276871681213379 	 0.02853870391845703 	 2.3603439331054688e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:46.312929 test begin: paddle.rank(Tensor([3, 16934401],"float32"), )
[Prof] paddle.rank 	 paddle.rank(Tensor([3, 16934401],"float32"), ) 	 50803203 	 1000 	 0.04459214210510254 	 0.028261423110961914 	 2.2411346435546875e-05 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:47.237473 test begin: paddle.rank(input=Tensor([12700801, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.04260540008544922 	 0.03371548652648926 	 2.193450927734375e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:47.871459 test begin: paddle.rank(input=Tensor([2, 12700801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.04129433631896973 	 0.028592586517333984 	 2.47955322265625e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:48.513458 test begin: paddle.rank(input=Tensor([3, 2, 2, 2116801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([3, 2, 2, 2116801],"float64"), ) 	 25401612 	 1000 	 0.04180335998535156 	 0.02854013442993164 	 1.4781951904296875e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:49.182641 test begin: paddle.rank(input=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([3, 2, 2116801, 2],"float64"), ) 	 25401612 	 1000 	 0.04151201248168945 	 0.02842998504638672 	 1.6689300537109375e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:49.809667 test begin: paddle.rank(input=Tensor([3, 2116801, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([3, 2116801, 2, 2],"float64"), ) 	 25401612 	 1000 	 0.042388916015625 	 0.030627727508544922 	 3.337860107421875e-05 	 8.630752563476562e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:50.398126 test begin: paddle.rank(input=Tensor([3175201, 2, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([3175201, 2, 2, 2],"float64"), ) 	 25401608 	 1000 	 0.04211902618408203 	 0.02838134765625 	 2.3365020751953125e-05 	 3.910064697265625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 17:56:51.034941 test begin: paddle.reciprocal(Tensor([125, 1, 640, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([125, 1, 640, 640],"float32"), ) 	 51200000 	 1000 	 0.29828786849975586 	 0.30065345764160156 	 0.289642333984375 	 0.2899813652038574 	 0.45408010482788086 	 1.0485138893127441 	 0.3985726833343506 	 0.3572406768798828 	 
2025-07-25 17:56:54.896393 test begin: paddle.reciprocal(Tensor([16, 1, 4962, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 1, 4962, 640],"float32"), ) 	 50810880 	 1000 	 0.29592204093933105 	 0.29819202423095703 	 0.28748297691345215 	 0.28764939308166504 	 0.45054173469543457 	 1.0406303405761719 	 0.3950772285461426 	 0.3545348644256592 	 
2025-07-25 17:56:58.686285 test begin: paddle.reciprocal(Tensor([16, 1, 640, 4962],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 1, 640, 4962],"float32"), ) 	 50810880 	 1000 	 0.29598212242126465 	 0.2988858222961426 	 0.28748464584350586 	 0.2871265411376953 	 0.45050859451293945 	 1.0405468940734863 	 0.3949449062347412 	 0.3545033931732178 	 
2025-07-25 17:57:02.486507 test begin: paddle.reciprocal(Tensor([16, 8, 640, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 8, 640, 640],"float32"), ) 	 52428800 	 1000 	 0.30596256256103516 	 0.3084256649017334 	 0.29703330993652344 	 0.29531264305114746 	 0.46457839012145996 	 1.0733187198638916 	 0.40920209884643555 	 0.36565494537353516 	 
2025-07-25 17:57:06.352295 test begin: paddle.reciprocal(Tensor([4, 1, 13231, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 1, 13231, 960],"float32"), ) 	 50807040 	 1000 	 0.2959573268890381 	 0.29819822311401367 	 0.2874321937561035 	 0.2875387668609619 	 0.4502596855163574 	 1.0406107902526855 	 0.39441370964050293 	 0.3545522689819336 	 
2025-07-25 17:57:10.149248 test begin: paddle.reciprocal(Tensor([4, 1, 960, 13231],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 1, 960, 13231],"float32"), ) 	 50807040 	 1000 	 0.2985966205596924 	 0.2982046604156494 	 0.2871055603027344 	 0.2872028350830078 	 0.4504680633544922 	 1.0405230522155762 	 0.39481329917907715 	 0.35449862480163574 	 
2025-07-25 17:57:14.008567 test begin: paddle.reciprocal(Tensor([4, 14, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 14, 960, 960],"float32"), ) 	 51609600 	 1000 	 1.4578096866607666 	 1.4342854022979736 	 0.29198431968688965 	 0.2918431758880615 	 0.4573678970336914 	 1.0569918155670166 	 0.40222954750061035 	 0.36007022857666016 	 
2025-07-25 17:57:21.369585 test begin: paddle.reciprocal(Tensor([56, 1, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([56, 1, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3006443977355957 	 0.30287957191467285 	 0.2866365909576416 	 0.2918972969055176 	 0.45735692977905273 	 1.056917667388916 	 0.39164042472839355 	 0.3601267337799072 	 
2025-07-25 17:57:25.182032 test begin: paddle.reciprocal(Tensor([8, 1, 6616, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 1, 6616, 960],"float32"), ) 	 50810880 	 1000 	 0.2960195541381836 	 0.29816746711730957 	 0.2875053882598877 	 0.2873530387878418 	 0.4503598213195801 	 1.0406594276428223 	 0.39489316940307617 	 0.3545207977294922 	 
2025-07-25 17:57:28.991776 test begin: paddle.reciprocal(Tensor([8, 1, 960, 6616],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 1, 960, 6616],"float32"), ) 	 50810880 	 1000 	 0.296048641204834 	 0.2982144355773926 	 0.2875947952270508 	 0.2874886989593506 	 0.45047616958618164 	 1.0406088829040527 	 0.389681339263916 	 0.3544588088989258 	 
2025-07-25 17:57:32.753694 test begin: paddle.reciprocal(Tensor([8, 7, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 7, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3005094528198242 	 0.3100442886352539 	 0.2920858860015869 	 0.29189133644104004 	 0.4574301242828369 	 1.057138442993164 	 0.4003620147705078 	 0.36005687713623047 	 
2025-07-25 17:57:38.113164 test begin: paddle.reduce_as(Tensor([30, 1270081, 40],"float32"), Tensor([1270081, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 1270081, 40],"float32"), Tensor([1270081, 40],"float32"), ) 	 1574900440 	 1000 	 5.190786361694336 	 5.344055891036987 	 5.179986000061035 	 1.3653786182403564 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 17:58:26.200438 test begin: paddle.reduce_as(Tensor([30, 200, 254017],"float32"), Tensor([200, 254017],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 200, 254017],"float32"), Tensor([200, 254017],"float32"), ) 	 1574905400 	 1000 	 5.1916680335998535 	 5.344179391860962 	 5.180262327194214 	 1.3654863834381104 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 17:59:12.138994 test begin: paddle.reduce_as(Tensor([30, 200, 8468],"float32"), Tensor([200, 8468],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 200, 8468],"float32"), Tensor([200, 8468],"float32"), ) 	 52501600 	 1000 	 0.1778409481048584 	 0.15561318397521973 	 0.1668252944946289 	 0.1202383041381836 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 17:59:13.570739 test begin: paddle.reduce_as(Tensor([30, 42337, 40],"float32"), Tensor([42337, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 42337, 40],"float32"), Tensor([42337, 40],"float32"), ) 	 52497880 	 1000 	 0.17885589599609375 	 0.1563732624053955 	 0.1679675579071045 	 0.12196969985961914 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 17:59:14.981795 test begin: paddle.reduce_as(Tensor([6351, 200, 40],"float32"), Tensor([200, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([6351, 200, 40],"float32"), Tensor([200, 40],"float32"), ) 	 50816000 	 1000 	 0.26012396812438965 	 0.15575170516967773 	 0.13292670249938965 	 0.07954883575439453 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 17:59:16.363249 test begin: paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"float32"), Tensor([1, 2, 1270081, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"float32"), Tensor([1, 2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 0.4500918388366699 	 0.44948720932006836 	 0.4407076835632324 	 0.4380941390991211 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:18.962061 test begin: paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"int32"), Tensor([1, 2, 1270081, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"int32"), Tensor([1, 2, 1270081, 4, 5],"int32"), ) 	 101606480 	 1000 	 0.4501821994781494 	 0.4503474235534668 	 0.4407799243927002 	 0.4379758834838867 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:21.131260 test begin: paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"float32"), Tensor([1, 2, 3, 1693441, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"float32"), Tensor([1, 2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 0.45015978813171387 	 0.4493129253387451 	 0.44031190872192383 	 0.4379618167877197 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:23.692522 test begin: paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"int32"), Tensor([1, 2, 3, 1693441, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"int32"), Tensor([1, 2, 3, 1693441, 5],"int32"), ) 	 101606460 	 1000 	 0.45018482208251953 	 0.44960737228393555 	 0.4407930374145508 	 0.4379615783691406 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:25.775538 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 1058401],"float64"), Tensor([1, 2, 3, 4, 1058401],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 1058401],"float64"), Tensor([1, 2, 3, 4, 1058401],"float64"), ) 	 50803248 	 1000 	 0.4467158317565918 	 0.4712843894958496 	 0.43765950202941895 	 0.44469261169433594 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:28.984321 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"float32"), Tensor([1, 2, 3, 4, 2116801],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"float32"), Tensor([1, 2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 0.4500765800476074 	 0.4518711566925049 	 0.44069457054138184 	 0.43792271614074707 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:31.905834 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"int32"), Tensor([1, 2, 3, 4, 2116801],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"int32"), Tensor([1, 2, 3, 4, 2116801],"int32"), ) 	 101606448 	 1000 	 0.4501686096191406 	 0.44966745376586914 	 0.4408388137817383 	 0.4383723735809326 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:33.989442 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), ) 	 50803440 	 1000 	 0.2977864742279053 	 0.3348062038421631 	 0.28734803199768066 	 0.3192014694213867 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:37.135530 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), ) 	 25401840 	 1000 	 0.43732619285583496 	 0.38303542137145996 	 0.4272773265838623 	 0.35866880416870117 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:39.726813 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), ) 	 50803440 	 1000 	 0.300121545791626 	 0.3433668613433838 	 0.2895629405975342 	 0.33107995986938477 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:40.956489 test begin: paddle.remainder(Tensor([1, 2, 3, 846721, 5],"float64"), Tensor([1, 2, 3, 846721, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 846721, 5],"float64"), Tensor([1, 2, 3, 846721, 5],"float64"), ) 	 50803260 	 1000 	 0.446636438369751 	 0.4567432403564453 	 0.43769216537475586 	 0.4452807903289795 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:42.985540 test begin: paddle.remainder(Tensor([1, 2, 635041, 4, 5],"float64"), Tensor([1, 2, 635041, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 635041, 4, 5],"float64"), Tensor([1, 2, 635041, 4, 5],"float64"), ) 	 50803280 	 1000 	 0.4466888904571533 	 0.4632761478424072 	 0.4377620220184326 	 0.4450089931488037 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:44.980069 test begin: paddle.remainder(Tensor([1, 423361, 3, 4, 5],"float64"), Tensor([1, 423361, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 423361, 3, 4, 5],"float64"), Tensor([1, 423361, 3, 4, 5],"float64"), ) 	 50803320 	 1000 	 0.4467301368713379 	 0.45662593841552734 	 0.43744492530822754 	 0.4454221725463867 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:46.963340 test begin: paddle.remainder(Tensor([1, 846721, 3, 4, 5],"float32"), Tensor([1, 846721, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 846721, 3, 4, 5],"float32"), Tensor([1, 846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 0.4501180648803711 	 0.45051050186157227 	 0.43312883377075195 	 0.4313833713531494 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:49.490350 test begin: paddle.remainder(Tensor([1, 846721, 3, 4, 5],"int32"), Tensor([1, 846721, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 846721, 3, 4, 5],"int32"), Tensor([1, 846721, 3, 4, 5],"int32"), ) 	 101606520 	 1000 	 0.4501762390136719 	 0.4518744945526123 	 0.43309831619262695 	 0.4317300319671631 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:51.567899 test begin: paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([1, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([1, 2, 3, 4, 5],"float64"), ) 	 25401840 	 1000 	 0.4061927795410156 	 0.36676931381225586 	 0.3882267475128174 	 0.34793734550476074 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:52.858461 test begin: paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), ) 	 50803440 	 1000 	 0.44689440727233887 	 0.4653337001800537 	 0.4301130771636963 	 0.4453415870666504 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:54.799778 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([1, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([1, 2, 3, 4, 5],"float32"), ) 	 50803440 	 1000 	 0.2968876361846924 	 0.3342723846435547 	 0.2866518497467041 	 0.3195152282714844 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:56.271906 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), ) 	 101606640 	 1000 	 0.4501652717590332 	 0.44927024841308594 	 0.44072389602661133 	 0.4379756450653076 	 None 	 None 	 None 	 None 	 
2025-07-25 17:59:58.908184 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([1, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([1, 2, 3, 4, 5],"int32"), ) 	 50803440 	 1000 	 0.29814767837524414 	 0.33828067779541016 	 0.2877976894378662 	 0.3261985778808594 	 None 	 None 	 None 	 None 	 
2025-07-25 18:00:00.134608 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), ) 	 101606640 	 1000 	 0.45009493827819824 	 0.44975733757019043 	 0.4407651424407959 	 0.43547940254211426 	 None 	 None 	 None 	 None 	 
2025-07-25 18:00:02.218891 test begin: paddle.renorm(Tensor([10, 20, 254017],"float32"), 1.0, -1, 2.05, )
[Prof] paddle.renorm 	 paddle.renorm(Tensor([10, 20, 254017],"float32"), 1.0, -1, 2.05, ) 	 50803400 	 1000 	 2.8538575172424316 	 0.4817185401916504 	 0.7281343936920166 	 0.16396260261535645 	 5.5614917278289795 	 2.9209775924682617 	 1.421159029006958 	 0.22935843467712402 	 
2025-07-25 18:00:15.897206 test begin: paddle.repeat_interleave(Tensor([1, 1500, 33869],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([1, 1500, 33869],"float32"), 5, axis=0, ) 	 50803500 	 1000 	 1.8594470024108887 	 1.508429765701294 	 0.949998140335083 	 1.486147165298462 	 2.4140539169311523 	 0.8743698596954346 	 0.8229944705963135 	 0.791978120803833 	 
2025-07-25 18:00:27.561602 test begin: paddle.repeat_interleave(Tensor([1, 39691, 1280],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([1, 39691, 1280],"float32"), 5, axis=0, ) 	 50804480 	 1000 	 1.8648886680603027 	 1.5107197761535645 	 0.9529283046722412 	 1.465324878692627 	 2.4124457836151123 	 0.8629629611968994 	 0.8224785327911377 	 0.780454158782959 	 
2025-07-25 18:00:40.966045 test begin: paddle.repeat_interleave(Tensor([14, 1, 384, 9451],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 1, 384, 9451],"float32"), repeats=3, axis=1, ) 	 50808576 	 1000 	 1.1033179759979248 	 0.8487546443939209 	 0.5636014938354492 	 0.8259947299957275 	 1.2305774688720703 	 0.5868382453918457 	 0.4193544387817383 	 0.5033047199249268 	 
2025-07-25 18:00:48.127183 test begin: paddle.repeat_interleave(Tensor([14, 1, 9451, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 1, 9451, 384],"float32"), repeats=3, axis=1, ) 	 50808576 	 1000 	 1.1032235622406006 	 0.8487858772277832 	 0.5635538101196289 	 0.8262255191802979 	 1.2299280166625977 	 0.5868456363677979 	 0.4191610813140869 	 0.5029957294464111 	 
2025-07-25 18:00:55.151616 test begin: paddle.repeat_interleave(Tensor([14, 25, 384, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 25, 384, 384],"float32"), repeats=3, axis=1, ) 	 51609600 	 1000 	 1.0468542575836182 	 0.7309906482696533 	 0.5347325801849365 	 0.7064039707183838 	 1.2065300941467285 	 0.6027326583862305 	 0.4129352569580078 	 0.5180203914642334 	 
2025-07-25 18:01:02.148415 test begin: paddle.repeat_interleave(Tensor([27, 1500, 1280],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([27, 1500, 1280],"float32"), 5, axis=0, ) 	 51840000 	 1000 	 1.694629192352295 	 1.1129553318023682 	 0.865778923034668 	 1.084684133529663 	 1.876366138458252 	 0.8809077739715576 	 0.6396119594573975 	 0.7986690998077393 	 
2025-07-25 18:01:12.877980 test begin: paddle.repeat_interleave(Tensor([345, 1, 384, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([345, 1, 384, 384],"float32"), repeats=3, axis=1, ) 	 50872320 	 1000 	 1.0314342975616455 	 0.7205698490142822 	 0.526909589767456 	 0.6973304748535156 	 1.1970038414001465 	 0.594310998916626 	 0.4079170227050781 	 0.5109615325927734 	 
2025-07-25 18:01:19.829780 test begin: paddle.repeat_interleave(Tensor([5, 1, 13231, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 1, 13231, 768],"float32"), repeats=3, axis=1, ) 	 50807040 	 1000 	 1.1223931312561035 	 0.9040641784667969 	 0.5735011100769043 	 0.8756852149963379 	 1.5041754245758057 	 0.5868110656738281 	 0.5127382278442383 	 0.49803972244262695 	 
2025-07-25 18:01:27.349204 test begin: paddle.repeat_interleave(Tensor([5, 1, 768, 13231],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 1, 768, 13231],"float32"), repeats=3, axis=1, ) 	 50807040 	 1000 	 1.122363567352295 	 0.9038798809051514 	 0.5734915733337402 	 0.8806660175323486 	 1.504866361618042 	 0.5868659019470215 	 0.5130481719970703 	 0.5023164749145508 	 
2025-07-25 18:01:34.846019 test begin: paddle.repeat_interleave(Tensor([5, 18, 768, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 18, 768, 768],"float32"), repeats=3, axis=1, ) 	 53084160 	 1000 	 1.0556530952453613 	 0.716785192489624 	 0.5393776893615723 	 0.6807425022125244 	 1.2543795108795166 	 0.6254897117614746 	 0.42740678787231445 	 0.5393517017364502 	 
2025-07-25 18:01:43.150751 test begin: paddle.repeat_interleave(Tensor([87, 1, 768, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([87, 1, 768, 768],"float32"), repeats=3, axis=1, ) 	 51314688 	 1000 	 1.0206499099731445 	 0.6803319454193115 	 0.5213136672973633 	 0.6569411754608154 	 1.213414192199707 	 0.6048953533172607 	 0.4135119915008545 	 0.5220673084259033 	 
2025-07-25 18:01:49.995368 test begin: paddle.reshape(Tensor([14176, 7168],"bfloat16"), list[-1,7168,], )
[Prof] paddle.reshape 	 paddle.reshape(Tensor([14176, 7168],"bfloat16"), list[-1,7168,], ) 	 101613568 	 1000 	 0.005305051803588867 	 0.0039825439453125 	 1.6689300537109375e-05 	 1.9073486328125e-05 	 0.050316572189331055 	 0.45362067222595215 	 4.267692565917969e-05 	 0.3754727840423584 	 
2025-07-25 18:01:53.817995 test begin: paddle.reverse(Tensor([12, 132301, 16],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 132301, 16],"float64"), axis=list[0,], ) 	 25401792 	 1000 	 0.5101306438446045 	 0.304002046585083 	 0.5008792877197266 	 0.29022812843322754 	 0.5091836452484131 	 0.3037598133087158 	 0.4560401439666748 	 0.24073362350463867 	 
2025-07-25 18:01:56.512321 test begin: paddle.reverse(Tensor([12, 264601, 8],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 264601, 8],"float64"), axis=0, ) 	 25401696 	 1000 	 0.5103509426116943 	 0.3039066791534424 	 0.5014185905456543 	 0.2901906967163086 	 0.5095312595367432 	 0.3038060665130615 	 0.4564323425292969 	 0.24091005325317383 	 
2025-07-25 18:01:59.217710 test begin: paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=0, ) 	 25401648 	 1000 	 0.509014368057251 	 0.3067748546600342 	 0.4999535083770752 	 0.29007887840270996 	 0.5104901790618896 	 0.30378174781799316 	 0.4572715759277344 	 0.24161911010742188 	 
2025-07-25 18:02:01.950445 test begin: paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=list[0,], ) 	 25401648 	 1000 	 0.5090270042419434 	 0.3039224147796631 	 0.5001180171966553 	 0.2901179790496826 	 0.5106265544891357 	 0.30379557609558105 	 0.45754218101501465 	 0.23032116889953613 	 
2025-07-25 18:02:04.668520 test begin: paddle.reverse(Tensor([396901, 4, 16],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([396901, 4, 16],"float64"), axis=list[0,], ) 	 25401664 	 1000 	 0.5032439231872559 	 0.3078019618988037 	 0.4942474365234375 	 0.2875239849090576 	 0.5046443939208984 	 0.30251073837280273 	 0.45087528228759766 	 0.24001550674438477 	 
2025-07-25 18:02:07.350080 test begin: paddle.reverse(Tensor([4, 12, 529201],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([4, 12, 529201],"float64"), axis=1, ) 	 25401648 	 1000 	 0.509082555770874 	 0.30576515197753906 	 0.5000953674316406 	 0.2891077995300293 	 0.5103352069854736 	 0.3055896759033203 	 0.45726776123046875 	 0.24306583404541016 	 
2025-07-25 18:02:10.064625 test begin: paddle.reverse(Tensor([4, 198451, 32],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([4, 198451, 32],"float64"), axis=1, ) 	 25401728 	 1000 	 0.5047111511230469 	 0.30336523056030273 	 0.4957919120788574 	 0.2888004779815674 	 0.5036237239837646 	 0.30318593978881836 	 0.45041942596435547 	 0.23820042610168457 	 
2025-07-25 18:02:12.774153 test begin: paddle.reverse(Tensor([66151, 12, 32],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([66151, 12, 32],"float64"), axis=1, ) 	 25401984 	 1000 	 0.5034534931182861 	 0.3034839630126953 	 0.4945547580718994 	 0.289644718170166 	 0.5033278465270996 	 0.3033146858215332 	 0.44976305961608887 	 0.2336864471435547 	 
2025-07-25 18:02:15.422803 test begin: paddle.reverse(Tensor([793801, 4, 8],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([793801, 4, 8],"float64"), axis=0, ) 	 25401632 	 1000 	 0.5043220520019531 	 0.302976131439209 	 0.4953947067260742 	 0.28929686546325684 	 0.5045287609100342 	 0.3027207851409912 	 0.45003676414489746 	 0.2408285140991211 	 
2025-07-25 18:02:18.107456 test begin: paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5461616516113281 	 0.7863953113555908 	 0.5341746807098389 	 0.40182042121887207 	 0.5461993217468262 	 0.7840123176574707 	 0.48999977111816406 	 0.4005742073059082 	 
2025-07-25 18:02:22.469034 test begin: paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5459871292114258 	 0.7840266227722168 	 0.5344185829162598 	 0.40062665939331055 	 0.5461368560791016 	 0.7865195274353027 	 0.49059557914733887 	 0.40186572074890137 	 
2025-07-25 18:02:26.767850 test begin: paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5457863807678223 	 0.7889242172241211 	 0.5324575901031494 	 0.40312695503234863 	 0.5457398891448975 	 0.7868964672088623 	 0.48966050148010254 	 0.40206456184387207 	 
2025-07-25 18:02:31.108666 test begin: paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5457501411437988 	 0.8135852813720703 	 0.5341191291809082 	 0.4020066261291504 	 0.545771598815918 	 0.7892124652862549 	 0.490062952041626 	 0.4031996726989746 	 
2025-07-25 18:02:37.073652 test begin: paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50978816 	 1000 	 0.5465199947357178 	 0.8007161617279053 	 0.5350239276885986 	 0.40316247940063477 	 0.5467641353607178 	 0.7863352298736572 	 0.49124932289123535 	 0.4017813205718994 	 
2025-07-25 18:02:41.544839 test begin: paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50978816 	 1000 	 0.5463733673095703 	 0.7862727642059326 	 0.5344831943511963 	 0.401766300201416 	 0.5463516712188721 	 0.7888622283935547 	 0.49074220657348633 	 0.4030487537384033 	 
2025-07-25 18:02:45.915145 test begin: paddle.roll(Tensor([44, 96, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([44, 96, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51904512 	 1000 	 0.5561342239379883 	 0.8084564208984375 	 0.5446281433105469 	 0.407681941986084 	 0.5561094284057617 	 0.7949471473693848 	 0.5007400512695312 	 0.4061279296875 	 
2025-07-25 18:02:52.146472 test begin: paddle.roll(Tensor([64, 65, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 65, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51118080 	 1000 	 0.5480644702911377 	 0.7855987548828125 	 0.5361747741699219 	 0.40146446228027344 	 0.5479700565338135 	 0.783266544342041 	 0.4918043613433838 	 0.400118350982666 	 
2025-07-25 18:02:56.450933 test begin: paddle.roll(Tensor([64, 96, 65, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 96, 65, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51118080 	 1000 	 0.5479271411895752 	 0.786442756652832 	 0.5358889102935791 	 0.40184998512268066 	 0.5478713512420654 	 0.7840571403503418 	 0.4925105571746826 	 0.4005918502807617 	 
2025-07-25 18:03:00.825198 test begin: paddle.roll(Tensor([64, 96, 96, 87],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 96, 96, 87],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51314688 	 1000 	 0.5501952171325684 	 0.7917912006378174 	 0.5386106967926025 	 0.4046025276184082 	 0.5501854419708252 	 0.7889015674591064 	 0.4948604106903076 	 0.40306878089904785 	 
2025-07-25 18:03:05.227410 test begin: paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 51179520 	 1000 	 0.5487940311431885 	 0.7907168865203857 	 0.5371766090393066 	 0.4033498764038086 	 0.5487957000732422 	 0.7872359752655029 	 0.49311137199401855 	 0.4022214412689209 	 
2025-07-25 18:03:09.609849 test begin: paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 51179520 	 1000 	 0.5488266944885254 	 0.7870864868164062 	 0.5364882946014404 	 0.4021782875061035 	 0.5488076210021973 	 0.7895162105560303 	 0.49327707290649414 	 0.4033987522125244 	 
2025-07-25 18:03:13.997976 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5160174369812012 	 0.30347442626953125 	 0.4907975196838379 	 0.28771162033081055 	 0.8276424407958984 	 0.30376458168029785 	 0.42289257049560547 	 0.23859763145446777 	 
2025-07-25 18:03:17.084264 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8215501308441162 	 0.30504846572875977 	 0.4196641445159912 	 0.28643035888671875 	 0.516810417175293 	 0.30334997177124023 	 0.45575428009033203 	 0.23743009567260742 	 
2025-07-25 18:03:20.094112 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.816709041595459 	 0.30349111557006836 	 0.417172908782959 	 0.2865886688232422 	 0.5167632102966309 	 0.3029475212097168 	 0.4555220603942871 	 0.2372884750366211 	 
2025-07-25 18:03:23.164993 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5191757678985596 	 0.30637288093566895 	 0.49462223052978516 	 0.2886812686920166 	 0.8313906192779541 	 0.3024578094482422 	 0.42479896545410156 	 0.23645424842834473 	 
2025-07-25 18:03:26.226902 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.9545993804931641 	 0.3042445182800293 	 0.48775267601013184 	 0.28727197647094727 	 0.5219113826751709 	 0.30413246154785156 	 0.4609706401824951 	 0.23870587348937988 	 
2025-07-25 18:03:29.370315 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8166508674621582 	 0.30350756645202637 	 0.4172182083129883 	 0.28661561012268066 	 0.5166776180267334 	 0.3029823303222656 	 0.4555823802947998 	 0.23544836044311523 	 
2025-07-25 18:03:32.405361 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.5205731391906738 	 0.3043699264526367 	 0.49619150161743164 	 0.2887599468231201 	 0.8316679000854492 	 0.3037571907043457 	 0.4249262809753418 	 0.2374875545501709 	 
2025-07-25 18:03:37.394560 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8332333564758301 	 0.31188106536865234 	 0.4257528781890869 	 0.2874479293823242 	 0.5166800022125244 	 0.3033020496368408 	 0.45601511001586914 	 0.2356553077697754 	 
2025-07-25 18:03:40.434968 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8220641613006592 	 0.30431151390075684 	 0.419968843460083 	 0.2875981330871582 	 0.5212247371673584 	 0.3056209087371826 	 0.459214448928833 	 0.2390909194946289 	 
2025-07-25 18:03:43.477991 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.5206193923950195 	 0.3044087886810303 	 0.4959874153137207 	 0.2887701988220215 	 0.8317267894744873 	 0.30373334884643555 	 0.4249892234802246 	 0.23782682418823242 	 
2025-07-25 18:03:46.542932 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8315582275390625 	 0.3062918186187744 	 0.42494702339172363 	 0.28733372688293457 	 0.5216114521026611 	 0.3061516284942627 	 0.4594461917877197 	 0.24065661430358887 	 
2025-07-25 18:03:49.576281 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8125252723693848 	 0.3094322681427002 	 0.41526103019714355 	 0.2889275550842285 	 0.5166878700256348 	 0.3029160499572754 	 0.45553016662597656 	 0.23679304122924805 	 
2025-07-25 18:03:54.867959 test begin: paddle.round(Tensor([128, 396901],"float32"), )
[Prof] paddle.round 	 paddle.round(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2957801818847656 	 0.30207037925720215 	 0.28725147247314453 	 0.2851254940032959 	 0.13399338722229004 	 0.13461804389953613 	 0.0811769962310791 	 0.06537461280822754 	 
2025-07-25 18:03:58.163785 test begin: paddle.round(Tensor([16, 1587601],"float64"), )
[Prof] paddle.round 	 paddle.round(Tensor([16, 1587601],"float64"), ) 	 25401616 	 1000 	 0.3049283027648926 	 0.29844021797180176 	 0.2966196537017822 	 0.2878081798553467 	 0.13381266593933105 	 0.13457369804382324 	 0.08126306533813477 	 0.07483315467834473 	 
2025-07-25 18:04:00.097536 test begin: paddle.round(Tensor([396901, 128],"float32"), )
[Prof] paddle.round 	 paddle.round(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2958230972290039 	 0.29788899421691895 	 0.28730177879333496 	 0.28743886947631836 	 0.13404178619384766 	 0.13410425186157227 	 0.08118152618408203 	 0.07419824600219727 	 
2025-07-25 18:04:02.624194 test begin: paddle.round(Tensor([99226, 256],"float64"), )
[Prof] paddle.round 	 paddle.round(Tensor([99226, 256],"float64"), ) 	 25401856 	 1000 	 0.30428457260131836 	 0.30306506156921387 	 0.2959401607513428 	 0.28774476051330566 	 0.13388609886169434 	 0.13453269004821777 	 0.08144998550415039 	 0.07425785064697266 	 
2025-07-25 18:04:04.550966 test begin: paddle.round(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.2956726551055908 	 0.3005082607269287 	 0.2868201732635498 	 0.28726840019226074 	 0.1339874267578125 	 0.13419795036315918 	 0.0810995101928711 	 0.07299923896789551 	 
2025-07-25 18:04:07.069022 test begin: paddle.round(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.29561614990234375 	 0.29786109924316406 	 0.2868969440460205 	 0.2872776985168457 	 0.13414359092712402 	 0.13418221473693848 	 0.08046817779541016 	 0.0730593204498291 	 
2025-07-25 18:04:09.624785 test begin: paddle.round(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.29569125175476074 	 0.29787349700927734 	 0.2867927551269531 	 0.2872133255004883 	 0.13397598266601562 	 0.13417530059814453 	 0.08115458488464355 	 0.07373428344726562 	 
2025-07-25 18:04:12.140490 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9548861980438232 	 0.922313928604126 	 0.16266274452209473 	 0.9041914939880371 	 0.9382407665252686 	 0.07366275787353516 	 0.1597764492034912 	 6.937980651855469e-05 	 
2025-07-25 18:04:18.286095 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3158116340637207 	 0.3167099952697754 	 0.1613626480102539 	 0.15994572639465332 	 0.3156626224517822 	 0.05599832534790039 	 0.1612393856048584 	 6.914138793945312e-05 	 
2025-07-25 18:04:20.363973 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3213188648223877 	 0.32329750061035156 	 0.08224797248840332 	 0.30887842178344727 	 0.31642603874206543 	 0.06798267364501953 	 0.080963134765625 	 9.512901306152344e-05 	 
2025-07-25 18:04:22.488943 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3255605697631836 	 0.32138490676879883 	 0.08302879333496094 	 0.30323004722595215 	 0.3159646987915039 	 0.06788063049316406 	 0.08052444458007812 	 5.841255187988281e-05 	 
2025-07-25 18:04:24.582188 test begin: paddle.row_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9581561088562012 	 0.9147529602050781 	 0.16321039199829102 	 0.9004957675933838 	 0.9545707702636719 	 0.06884551048278809 	 0.16256237030029297 	 7.867813110351562e-05 	 
2025-07-25 18:04:30.745610 test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.32187986373901367 	 0.32169055938720703 	 0.08239603042602539 	 0.30741119384765625 	 0.3212087154388428 	 0.06661224365234375 	 0.08218002319335938 	 3.719329833984375e-05 	 
2025-07-25 18:04:32.846320 test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.3281583786010742 	 0.31857991218566895 	 0.08368992805480957 	 0.3044121265411377 	 0.3263816833496094 	 0.07148528099060059 	 0.08320212364196777 	 7.486343383789062e-05 	 
2025-07-25 18:04:34.981109 test begin: paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9461374282836914 	 0.9349045753479004 	 0.16117310523986816 	 0.902519941329956 	 0.9460351467132568 	 0.06920361518859863 	 0.16112208366394043 	 6.365776062011719e-05 	 
2025-07-25 18:04:41.535761 test begin: paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3145575523376465 	 0.31317901611328125 	 0.16073226928710938 	 0.15990805625915527 	 0.31311607360839844 	 0.05599188804626465 	 0.15994763374328613 	 5.745887756347656e-05 	 
2025-07-25 18:04:43.602671 test begin: paddle.row_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9562742710113525 	 0.9199140071868896 	 0.16289114952087402 	 0.9053704738616943 	 0.9453516006469727 	 0.06825494766235352 	 0.16099810600280762 	 6.866455078125e-05 	 
2025-07-25 18:04:49.734409 test begin: paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9557738304138184 	 0.9291760921478271 	 0.1627826690673828 	 0.9141049385070801 	 0.9436385631561279 	 0.06712603569030762 	 0.16073250770568848 	 3.814697265625e-05 	 
2025-07-25 18:04:55.883554 test begin: paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3158090114593506 	 0.31317901611328125 	 0.1613600254058838 	 0.15990352630615234 	 0.3156607151031494 	 0.06211972236633301 	 0.16124224662780762 	 5.555152893066406e-05 	 
2025-07-25 18:04:59.831991 test begin: paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.32088708877563477 	 0.31622958183288574 	 0.08182668685913086 	 0.29413819313049316 	 0.32010602951049805 	 0.09302377700805664 	 0.08158254623413086 	 0.00011324882507324219 	 
2025-07-25 18:05:02.919111 test begin: paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.9556403160095215 	 0.9162600040435791 	 0.1627359390258789 	 0.9008016586303711 	 0.9421463012695312 	 0.07174491882324219 	 0.16041946411132812 	 4.100799560546875e-05 	 
2025-07-25 18:05:09.086469 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3198103904724121 	 0.31150245666503906 	 0.08154082298278809 	 0.2971072196960449 	 0.3132174015045166 	 0.07077503204345703 	 0.07983279228210449 	 7.891654968261719e-05 	 
2025-07-25 18:05:11.173483 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.939983606338501 	 0.9229929447174072 	 0.1601104736328125 	 0.9069371223449707 	 0.9410073757171631 	 0.06829571723937988 	 0.16024541854858398 	 7.224082946777344e-05 	 
2025-07-25 18:05:17.319861 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3145785331726074 	 0.31323862075805664 	 0.1607198715209961 	 0.1599562168121338 	 0.31314635276794434 	 0.05674552917480469 	 0.15996861457824707 	 6.794929504394531e-05 	 
2025-07-25 18:05:19.386794 test begin: paddle.rsqrt(Tensor([10000, 1694, 3],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 1694, 3],"float32"), ) 	 50820000 	 1000 	 0.29593539237976074 	 0.2980778217315674 	 0.287473201751709 	 0.2873544692993164 	 0.44943714141845703 	 1.0409693717956543 	 0.39321303367614746 	 0.3546297550201416 	 
2025-07-25 18:05:23.308421 test begin: paddle.rsqrt(Tensor([10000, 2, 1271],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 2, 1271],"float64"), ) 	 25420000 	 1000 	 0.2986288070678711 	 0.2992985248565674 	 0.29047226905822754 	 0.2885921001434326 	 0.4476144313812256 	 1.0399715900421143 	 0.3916194438934326 	 0.35433220863342285 	 
2025-07-25 18:05:26.500405 test begin: paddle.rsqrt(Tensor([10000, 2, 2541],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 2, 2541],"float32"), ) 	 50820000 	 1000 	 0.29590916633605957 	 0.30083322525024414 	 0.2875823974609375 	 0.28728628158569336 	 0.449383020401001 	 1.0409221649169922 	 0.39304018020629883 	 0.3546013832092285 	 
2025-07-25 18:05:30.338328 test begin: paddle.rsqrt(Tensor([10000, 847, 3],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 847, 3],"float64"), ) 	 25410000 	 1000 	 0.2985210418701172 	 0.30385422706604004 	 0.2899129390716553 	 0.28825950622558594 	 0.4476151466369629 	 1.0396809577941895 	 0.39192628860473633 	 0.3541996479034424 	 
2025-07-25 18:05:33.523229 test begin: paddle.rsqrt(Tensor([13, 1007, 3881],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([13, 1007, 3881],"float32"), ) 	 50806171 	 1000 	 0.2957625389099121 	 0.3091742992401123 	 0.28746652603149414 	 0.28717565536499023 	 0.44927263259887695 	 1.040698766708374 	 0.3929634094238281 	 0.35454392433166504 	 
2025-07-25 18:05:41.021277 test begin: paddle.rsqrt(Tensor([13, 3907939, 1],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([13, 3907939, 1],"float32"), ) 	 50803207 	 1000 	 0.29579710960388184 	 0.2979745864868164 	 0.28738975524902344 	 0.2870662212371826 	 0.44925689697265625 	 1.0405030250549316 	 0.39212489128112793 	 0.3544459342956543 	 
2025-07-25 18:05:44.813983 test begin: paddle.rsqrt(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.2983686923980713 	 0.3027231693267822 	 0.2901451587677002 	 0.2883167266845703 	 0.4475839138031006 	 1.0394301414489746 	 0.39225029945373535 	 0.35408997535705566 	 
2025-07-25 18:05:48.013775 test begin: paddle.rsqrt(Tensor([50451, 1007, 1],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([50451, 1007, 1],"float32"), ) 	 50804157 	 1000 	 0.29564428329467773 	 0.30023813247680664 	 0.2872159481048584 	 0.28700757026672363 	 0.4492301940917969 	 1.0405480861663818 	 0.39304518699645996 	 0.3544921875 	 
2025-07-25 18:05:51.846047 test begin: paddle.rsqrt(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2957603931427002 	 0.30310630798339844 	 0.28736162185668945 	 0.2786259651184082 	 0.4492983818054199 	 1.0404469966888428 	 0.3935694694519043 	 0.35446906089782715 	 
2025-07-25 18:05:55.654572 test begin: paddle.scale(Tensor([2, 256, 256, 388],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 256, 256, 388],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2959318161010742 	 0.598895788192749 	 0.2864654064178467 	 0.3045368194580078 	 0.29584503173828125 	 0.29801177978515625 	 0.24181175231933594 	 0.2315506935119629 	 combined
2025-07-25 18:05:58.849135 test begin: paddle.scale(Tensor([2, 256, 388, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 256, 388, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29592037200927734 	 0.5982916355133057 	 0.2865324020385742 	 0.3045032024383545 	 0.29581141471862793 	 0.2979893684387207 	 0.2420024871826172 	 0.23006081581115723 	 combined
2025-07-25 18:06:01.990139 test begin: paddle.scale(Tensor([2, 388, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 388, 256, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29590630531311035 	 0.6103019714355469 	 0.28650569915771484 	 0.30449557304382324 	 0.29576945304870605 	 0.29799628257751465 	 0.23968291282653809 	 0.23051142692565918 	 combined
2025-07-25 18:06:08.100274 test begin: paddle.scale(Tensor([4, 194, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 194, 256, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29590487480163574 	 0.595994234085083 	 0.2866334915161133 	 0.30452775955200195 	 0.2958052158355713 	 0.2979922294616699 	 0.2420518398284912 	 0.23159384727478027 	 combined
2025-07-25 18:06:11.227751 test begin: paddle.scale(Tensor([4, 256, 194, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 194, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29593396186828613 	 0.595914363861084 	 0.2866382598876953 	 0.30447936058044434 	 0.29579806327819824 	 0.2979764938354492 	 0.24149394035339355 	 0.23185372352600098 	 combined
2025-07-25 18:06:14.397922 test begin: paddle.scale(Tensor([4, 256, 256, 194],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 194],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29595494270324707 	 0.5959577560424805 	 0.28656673431396484 	 0.30449390411376953 	 0.29580140113830566 	 0.297992467880249 	 0.24149870872497559 	 0.22298026084899902 	 combined
2025-07-25 18:06:17.528309 test begin: paddle.scale(Tensor([4, 256, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 256],"float32"), scale=1.1111111111111112, ) 	 67108864 	 1000 	 0.38902735710144043 	 0.7833058834075928 	 0.37966442108154297 	 0.400193452835083 	 0.3890535831451416 	 0.3916311264038086 	 0.33513832092285156 	 0.3219599723815918 	 combined
2025-07-25 18:06:21.657979 test begin: paddle.scale(Tensor([4, 256, 256, 388],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 388],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.29874491691589355 	 0.5926296710968018 	 0.28950071334838867 	 0.30281853675842285 	 0.29881930351257324 	 0.29633569717407227 	 0.2154533863067627 	 0.22961902618408203 	 combined
2025-07-25 18:06:26.947148 test begin: paddle.scale(Tensor([4, 256, 388, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 388, 256],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.29869842529296875 	 0.5926485061645508 	 0.28586411476135254 	 0.30281829833984375 	 0.29882049560546875 	 0.29633450508117676 	 0.24313879013061523 	 0.22972750663757324 	 combined
2025-07-25 18:06:32.271774 test begin: paddle.scale(Tensor([4, 388, 256, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 388, 256, 256],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.29869818687438965 	 0.6074562072753906 	 0.28936290740966797 	 0.30280590057373047 	 0.2988004684448242 	 0.29644107818603516 	 0.24474406242370605 	 0.22979521751403809 	 combined
2025-07-25 18:06:41.607168 test begin: paddle.scale(Tensor([7, 256, 256, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([7, 256, 256, 256],"float16"), scale=1.1111111111111112, ) 	 117440512 	 1000 	 0.3442542552947998 	 0.6830437183380127 	 0.3346405029296875 	 0.3489987850189209 	 0.34421825408935547 	 0.34175777435302734 	 0.28833627700805664 	 0.2532074451446533 	 combined
2025-07-25 18:06:47.664056 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([197],"int32"), Tensor([197, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([197],"int32"), Tensor([197, 194],"float32"), overwrite=True, ) 	 50894351 	 1000 	 0.3120760917663574 	 6.669746160507202 	 0.15945124626159668 	 0.0002474784851074219 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:06:56.806674 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([205],"int32"), Tensor([205, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([205],"int32"), Tensor([205, 194],"float32"), overwrite=True, ) 	 50895911 	 1000 	 0.3117868900299072 	 6.958882808685303 	 0.15930604934692383 	 0.00023245811462402344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:07:06.137443 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([219],"int32"), Tensor([219, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([219],"int32"), Tensor([219, 194],"float32"), overwrite=True, ) 	 50898641 	 1000 	 0.31101226806640625 	 8.496510028839111 	 0.15891766548156738 	 0.0002295970916748047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:07:17.881123 test begin: paddle.scatter(Tensor([262144, 2314],"float32"), Tensor([219],"int32"), Tensor([219, 2314],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2314],"float32"), Tensor([219],"int32"), Tensor([219, 2314],"float32"), overwrite=True, ) 	 607108201 	 1000 	 3.6037638187408447 	 7.345065355300903 	 1.224226713180542 	 6.67572021484375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:07:52.484687 test begin: paddle.scatter(Tensor([262144, 2476],"float32"), Tensor([205],"int32"), Tensor([205, 2476],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2476],"float32"), Tensor([205],"int32"), Tensor([205, 2476],"float32"), overwrite=True, ) 	 649576329 	 1000 	 3.858694314956665 	 6.95435643196106 	 1.3106627464294434 	 0.00024199485778808594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:08:29.202305 test begin: paddle.scatter(Tensor([262144, 2569],"float32"), Tensor([197],"int32"), Tensor([197, 2569],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2569],"float32"), Tensor([197],"int32"), Tensor([197, 2569],"float32"), overwrite=True, ) 	 673954226 	 1000 	 4.829789400100708 	 6.787365436553955 	 1.358776569366455 	 7.605552673339844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:09:07.254140 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([197],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([197],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285445 	 1000 	 0.11128902435302734 	 6.634758710861206 	 0.056383609771728516 	 0.00023984909057617188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:09:14.723218 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([205],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([205],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285453 	 1000 	 0.11033296585083008 	 6.93599009513855 	 0.05636954307556152 	 0.00023984909057617188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:09:22.843515 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([219],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([219],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285467 	 1000 	 0.1103982925415039 	 7.413259267807007 	 0.05639529228210449 	 0.0002295970916748047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:09:33.410967 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([197],"int32"), Tensor([197, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([197],"int32"), Tensor([197, 64],"float32"), overwrite=True, ) 	 50816069 	 1000 	 0.32163453102111816 	 6.757530689239502 	 0.10937309265136719 	 0.00023102760314941406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:09:44.721421 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([205],"int32"), Tensor([205, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([205],"int32"), Tensor([205, 64],"float32"), overwrite=True, ) 	 50816589 	 1000 	 0.3216099739074707 	 6.949044942855835 	 0.10934901237487793 	 0.00023293495178222656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:09:54.087313 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([219],"int32"), Tensor([219, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([219],"int32"), Tensor([219, 64],"float32"), overwrite=True, ) 	 50817499 	 1000 	 0.32324647903442383 	 7.469558954238892 	 0.10990667343139648 	 0.0002338886260986328 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:10:03.973921 test begin: paddle.scatter_nd(Tensor([128, 2],"int64"), Tensor([128, 9, 10],"float32"), list[3,5,9,10,], )
[Prof] paddle.scatter_nd 	 paddle.scatter_nd(Tensor([128, 2],"int64"), Tensor([128, 9, 10],"float32"), list[3,5,9,10,], ) 	 11776 	 1000 	 0.03792548179626465 	 15.619273662567139 	 1.3113021850585938e-05 	 0.0002014636993408203 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:10:19.723342 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), ) 	 105808018 	 1000 	 0.3979332447052002 	 70.83119869232178 	 0.20332884788513184 	 0.00021147727966308594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:11:35.528103 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587 7168],"bfloat16"), )
[config parse error] paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587 7168],"bfloat16"), ) invalid syntax. Perhaps you forgot a comma? (<string>, line 1)
2025-07-25 18:11:35.528526 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), ) 	 105879718 	 1000 	 0.3980882167816162 	 72.01862072944641 	 0.20341086387634277 	 0.00021839141845703125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:12:55.686495 test begin: paddle.scatter_nd_add(Tensor([1, 8192, 12404],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 12404],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 8192, 12404],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 12404],"bfloat16"), ) 	 108895890 	 1000 	 0.5360562801361084 	 70.9535276889801 	 0.27392125129699707 	 0.00020933151245117188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:14:11.397752 test begin: paddle.scatter_nd_add(Tensor([1, 8192, 17069],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 17069],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 8192, 17069],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 17069],"bfloat16"), ) 	 149986493 	 1000 	 0.9022977352142334 	 72.28357791900635 	 0.4610252380371094 	 0.0002117156982421875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:15:30.665726 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), ) 	 121634962 	 1000 	 0.4437696933746338 	 71.54810976982117 	 0.2267472743988037 	 0.00021767616271972656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:16:49.737988 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 7168],"bfloat16"), ) 	 121649302 	 1000 	 0.44443511962890625 	 71.90223908424377 	 0.22709131240844727 	 0.00021147727966308594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:18:06.862424 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), ) 	 121706662 	 1000 	 0.4449787139892578 	 72.14055609703064 	 0.22738003730773926 	 0.0002143383026123047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:19:24.457638 test begin: paddle.searchsorted(Tensor([1024],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"float32"), Tensor([50803201],"float32"), ) 	 50804225 	 1000 	 1.3772814273834229 	 1.0382270812988281 	 1.3695785999298096 	 1.0274133682250977 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:27.710793 test begin: paddle.searchsorted(Tensor([1024],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"float64"), Tensor([25401601],"float64"), ) 	 25402625 	 1000 	 0.6402835845947266 	 0.538015604019165 	 0.6323261260986328 	 0.5176980495452881 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:29.428116 test begin: paddle.searchsorted(Tensor([1024],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"int32"), Tensor([50803201],"int32"), ) 	 50804225 	 1000 	 1.3465557098388672 	 1.0313525199890137 	 1.3388855457305908 	 1.0204331874847412 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:32.404485 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 1.3963375091552734 	 1.141944408416748 	 1.3886425495147705 	 1.1312837600708008 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:37.116137 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([512],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([512],"float64"), ) 	 25402113 	 1000 	 0.010454654693603516 	 0.01051640510559082 	 3.337860107421875e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:39.531793 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 2.9671571254730225 	 2.3195128440856934 	 2.9594173431396484 	 2.3059470653533936 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:46.532253 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([512],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([512],"float32"), ) 	 50803713 	 1000 	 0.008791208267211914 	 0.0105438232421875 	 0.0006473064422607422 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:47.391409 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 2.9592130184173584 	 2.3177380561828613 	 2.951531171798706 	 2.3068771362304688 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:53.886384 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([512],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([512],"int32"), ) 	 50803713 	 1000 	 0.008418083190917969 	 0.010619401931762695 	 0.0006041526794433594 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 18:19:54.501347 test begin: paddle.select_scatter(Tensor([12700801, 3, 4],"float32"), Tensor([12700801, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([12700801, 3, 4],"float32"), Tensor([12700801, 4],"float32"), 1, 1, ) 	 203212816 	 1000 	 0.7276699542999268 	 1.6513113975524902 	 0.706143856048584 	 0.5619931221008301 	 3.2564101219177246 	 1.7950646877288818 	 0.4158599376678467 	 0.45848798751831055 	 
2025-07-25 18:20:07.914077 test begin: paddle.select_scatter(Tensor([1693441, 3, 4, 5],"float64"), Tensor([1693441, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([1693441, 3, 4, 5],"float64"), Tensor([1693441, 3, 5],"float64"), 2, 1, ) 	 127008075 	 1000 	 0.744375467300415 	 1.984527349472046 	 0.7236969470977783 	 0.6753945350646973 	 3.5655946731567383 	 2.131995439529419 	 0.4552161693572998 	 0.5443587303161621 	 
2025-07-25 18:20:22.582992 test begin: paddle.select_scatter(Tensor([2, 211681, 4, 5, 6],"int32"), Tensor([2, 211681, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 211681, 4, 5, 6],"int32"), Tensor([2, 211681, 5, 6],"int32"), 2, 1, ) 	 63504300 	 1000 	 0.17920851707458496 	 0.49762749671936035 	 0.15831923484802246 	 0.16747450828552246 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:20:25.967131 test begin: paddle.select_scatter(Tensor([2, 2540161, 4, 5],"float64"), Tensor([2, 2540161, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 2540161, 4, 5],"float64"), Tensor([2, 2540161, 5],"float64"), 2, 1, ) 	 127008050 	 1000 	 0.7452418804168701 	 1.9846761226654053 	 0.7248437404632568 	 0.6753139495849609 	 3.5653302669525146 	 2.1323745250701904 	 0.4540133476257324 	 0.5444488525390625 	 
2025-07-25 18:20:40.433583 test begin: paddle.select_scatter(Tensor([2, 3, 25401601],"float32"), Tensor([2, 25401601],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 25401601],"float32"), Tensor([2, 25401601],"float32"), 1, 1, ) 	 203212808 	 1000 	 0.3649415969848633 	 1.228105068206787 	 0.34421300888061523 	 0.41779041290283203 	 2.6858465671539307 	 1.3630483150482178 	 0.3428537845611572 	 0.3478670120239258 	 
2025-07-25 18:20:52.124264 test begin: paddle.select_scatter(Tensor([2, 3, 282241, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 282241, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, ) 	 50803560 	 1000 	 0.021153926849365234 	 0.3224325180053711 	 1.4543533325195312e-05 	 0.10768413543701172 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:20:53.934531 test begin: paddle.select_scatter(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 1058401],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 1058401],"float64"), 2, 1, ) 	 31752030 	 1000 	 0.07997894287109375 	 0.3941378593444824 	 0.05001258850097656 	 0.13355660438537598 	 0.717750072479248 	 0.43108201026916504 	 0.09147095680236816 	 0.11006617546081543 	 
2025-07-25 18:20:56.838260 test begin: paddle.select_scatter(Tensor([2, 3, 4, 1411201, 6],"int32"), Tensor([2, 3, 1411201, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 1411201, 6],"int32"), Tensor([2, 3, 1411201, 6],"int32"), 2, 1, ) 	 254016180 	 1000 	 0.5415892601013184 	 1.544806957244873 	 0.5198953151702881 	 0.5213479995727539 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:21:11.185826 test begin: paddle.select_scatter(Tensor([2, 3, 4, 352801, 6],"int32"), Tensor([2, 3, 352801, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 352801, 6],"int32"), Tensor([2, 3, 352801, 6],"int32"), 2, 1, ) 	 63504180 	 1000 	 0.13852381706237793 	 0.3960762023925781 	 0.11712980270385742 	 0.1334857940673828 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:21:13.956555 test begin: paddle.select_scatter(Tensor([2, 3, 4, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), 2, 1, ) 	 127008030 	 1000 	 0.3046448230743408 	 1.5304274559020996 	 0.27471280097961426 	 0.5203263759613037 	 2.765850305557251 	 1.6652703285217285 	 0.35272789001464844 	 0.42488574981689453 	 
2025-07-25 18:21:25.261172 test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 1693441],"int32"), Tensor([2, 3, 5, 1693441],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 5, 1693441],"int32"), Tensor([2, 3, 5, 1693441],"int32"), 2, 1, ) 	 254016150 	 1000 	 0.5421907901763916 	 1.5353786945343018 	 0.5212147235870361 	 0.5213561058044434 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:21:37.218977 test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 423361],"int32"), Tensor([2, 3, 5, 423361],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 5, 423361],"int32"), Tensor([2, 3, 5, 423361],"int32"), 2, 1, ) 	 63504150 	 1000 	 0.13872313499450684 	 0.3997476100921631 	 0.11763477325439453 	 0.13350129127502441 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:21:40.058764 test begin: paddle.select_scatter(Tensor([2, 3, 8467201],"float32"), Tensor([2, 8467201],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 8467201],"float32"), Tensor([2, 8467201],"float32"), 1, 1, ) 	 67737608 	 1000 	 0.12464165687561035 	 0.4174668788909912 	 0.10399055480957031 	 0.14199542999267578 	 0.9077889919281006 	 0.4654419422149658 	 0.11583161354064941 	 0.11878013610839844 	 
2025-07-25 18:21:43.986326 test begin: paddle.select_scatter(Tensor([2, 3, 846721, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 846721, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, ) 	 25401660 	 1000 	 0.02032756805419922 	 0.3163943290710449 	 1.2159347534179688e-05 	 0.10749959945678711 	 0.33124423027038574 	 0.31839942932128906 	 0.04206442832946777 	 0.08113217353820801 	 
2025-07-25 18:21:46.045869 test begin: paddle.select_scatter(Tensor([2, 6350401, 4],"float32"), Tensor([2, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 6350401, 4],"float32"), Tensor([2, 4],"float32"), 1, 1, ) 	 50803216 	 1000 	 0.020453929901123047 	 0.3164224624633789 	 1.2874603271484375e-05 	 0.10752487182617188 	 0.33051347732543945 	 0.31832432746887207 	 0.04198598861694336 	 0.08113837242126465 	 
2025-07-25 18:21:48.673072 test begin: paddle.select_scatter(Tensor([2, 635041, 4, 5],"float64"), Tensor([2, 635041, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 635041, 4, 5],"float64"), Tensor([2, 635041, 5],"float64"), 2, 1, ) 	 31752050 	 1000 	 0.18534541130065918 	 0.49951982498168945 	 0.16475796699523926 	 0.16949081420898438 	 0.8954668045043945 	 0.5470523834228516 	 0.11427521705627441 	 0.13968658447265625 	 
2025-07-25 18:21:52.032641 test begin: paddle.select_scatter(Tensor([2, 846721, 4, 5, 6],"int32"), Tensor([2, 846721, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 846721, 4, 5, 6],"int32"), Tensor([2, 846721, 5, 6],"int32"), 2, 1, ) 	 254016300 	 1000 	 0.7044069766998291 	 1.974543571472168 	 0.6831660270690918 	 0.6720435619354248 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:22:03.885228 test begin: paddle.select_scatter(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 4],"float32"), 1, 1, ) 	 67737616 	 1000 	 0.24453067779541016 	 0.5597436428070068 	 0.22391223907470703 	 0.19048810005187988 	 1.1112384796142578 	 0.6158161163330078 	 0.14193987846374512 	 0.15639853477478027 	 
2025-07-25 18:22:08.350386 test begin: paddle.select_scatter(Tensor([423361, 3, 4, 5],"float64"), Tensor([423361, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([423361, 3, 4, 5],"float64"), Tensor([423361, 3, 5],"float64"), 2, 1, ) 	 31752075 	 1000 	 0.1854567527770996 	 0.49831533432006836 	 0.16475677490234375 	 0.16955018043518066 	 0.8954257965087891 	 0.5469107627868652 	 0.11426734924316406 	 0.1395716667175293 	 
2025-07-25 18:22:11.759521 test begin: paddle.sgn(Tensor([12, 1058401, 2],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 1058401, 2],"float64"), ) 	 25401624 	 1000 	 0.308809757232666 	 0.29844093322753906 	 0.29206323623657227 	 0.2879490852355957 	 0.2980363368988037 	 0.051317453384399414 	 0.24465394020080566 	 3.504753112792969e-05 	 
2025-07-25 18:22:13.807185 test begin: paddle.sgn(Tensor([12, 20, 105841],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 20, 105841],"float64"), ) 	 25401840 	 1000 	 0.30837011337280273 	 0.2985055446624756 	 0.2916259765625 	 0.2879204750061035 	 0.2980613708496094 	 0.05182814598083496 	 0.24466753005981445 	 2.9325485229492188e-05 	 
2025-07-25 18:22:15.826244 test begin: paddle.sgn(Tensor([12, 20, 211681],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 20, 211681],"float32"), ) 	 50803440 	 1000 	 0.3440420627593994 	 0.29787302017211914 	 0.32829713821411133 	 0.28719115257263184 	 0.29553937911987305 	 0.05797219276428223 	 0.24165749549865723 	 6.4849853515625e-05 	 
2025-07-25 18:22:18.464115 test begin: paddle.sgn(Tensor([12, 2116801, 2],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 2116801, 2],"float32"), ) 	 50803224 	 1000 	 0.3443183898925781 	 0.300142765045166 	 0.32849931716918945 	 0.2870523929595947 	 0.29558634757995605 	 0.05137276649475098 	 0.24181342124938965 	 5.14984130859375e-05 	 
2025-07-25 18:22:21.120406 test begin: paddle.sgn(Tensor([1270081, 20, 2],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([1270081, 20, 2],"float32"), ) 	 50803240 	 1000 	 0.3442983627319336 	 0.3014540672302246 	 0.32819652557373047 	 0.2869882583618164 	 0.29561614990234375 	 0.051282644271850586 	 0.24193954467773438 	 3.2901763916015625e-05 	 
2025-07-25 18:22:23.814408 test begin: paddle.sgn(Tensor([635041, 20, 2],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([635041, 20, 2],"float64"), ) 	 25401640 	 1000 	 0.3089585304260254 	 0.29853129386901855 	 0.2898435592651367 	 0.28792238235473633 	 0.2975773811340332 	 0.05151486396789551 	 0.2434673309326172 	 2.9802322387695312e-05 	 
2025-07-25 18:22:25.855403 test begin: paddle.shape(Tensor([1, 1600, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([1, 1600, 376, 280],"float32"), ) 	 168448000 	 1000 	 0.0044422149658203125 	 0.031115293502807617 	 8.106231689453125e-06 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:28.629546 test begin: paddle.shape(Tensor([13, 128, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([13, 128, 256, 256],"float16"), ) 	 109051904 	 1000 	 0.004302978515625 	 0.031131982803344727 	 9.059906005859375e-06 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:32.308483 test begin: paddle.shape(Tensor([4, 121, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 121, 376, 280],"float32"), ) 	 50955520 	 1000 	 0.004364490509033203 	 0.03119206428527832 	 8.344650268554688e-06 	 6.818771362304688e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:34.694111 test begin: paddle.shape(Tensor([4, 128, 256, 388],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 128, 256, 388],"float32"), ) 	 50855936 	 1000 	 0.004302978515625 	 0.030730724334716797 	 7.867813110351562e-06 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:37.153292 test begin: paddle.shape(Tensor([4, 128, 256, 776],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 128, 256, 776],"float16"), ) 	 101711872 	 1000 	 0.004302978515625 	 0.031286001205444336 	 7.3909759521484375e-06 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:39.643266 test begin: paddle.shape(Tensor([4, 128, 388, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 128, 388, 256],"float32"), ) 	 50855936 	 1000 	 0.004351615905761719 	 0.03132915496826172 	 1.4781951904296875e-05 	 5.0067901611328125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:40.532262 test begin: paddle.shape(Tensor([4, 128, 776, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 128, 776, 256],"float16"), ) 	 101711872 	 1000 	 0.004346609115600586 	 0.030895709991455078 	 1.0251998901367188e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:42.499767 test begin: paddle.shape(Tensor([4, 1600, 29, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 1600, 29, 280],"float32"), ) 	 51968000 	 1000 	 0.004309654235839844 	 0.03110671043395996 	 8.106231689453125e-06 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:43.376376 test begin: paddle.shape(Tensor([4, 1600, 376, 22],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 1600, 376, 22],"float32"), ) 	 52940800 	 1000 	 0.004359245300292969 	 0.03104400634765625 	 1.6689300537109375e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:44.289217 test begin: paddle.shape(Tensor([4, 194, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 194, 256, 256],"float32"), ) 	 50855936 	 1000 	 0.004324197769165039 	 0.03110790252685547 	 1.3113021850585938e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:45.160397 test begin: paddle.shape(Tensor([4, 388, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([4, 388, 256, 256],"float16"), ) 	 101711872 	 1000 	 0.00433659553527832 	 0.031336069107055664 	 1.049041748046875e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:47.074719 test begin: paddle.shape(Tensor([7, 128, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([7, 128, 256, 256],"float32"), ) 	 58720256 	 1000 	 0.004274606704711914 	 0.03065633773803711 	 7.867813110351562e-06 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:48.051418 test begin: paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ) 	 25401602 	 1000 	 0.30946969985961914 	 2.038665533065796 	 0.30039143562316895 	 0.0006551742553710938 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:51.097441 test begin: paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, ) 	 25401602 	 1000 	 0.3094780445098877 	 2.041088819503784 	 0.3009068965911865 	 0.0006649494171142578 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:54.142498 test begin: paddle.shard_index(input=Tensor([25401601, 1],"int64"), index_num=13, nshards=3, shard_id=0, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([25401601, 1],"int64"), index_num=13, nshards=3, shard_id=0, ) 	 25401601 	 1000 	 0.3099551200866699 	 2.235023021697998 	 0.30164027214050293 	 0.0007565021514892578 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:22:57.197181 test begin: paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ) 	 25401604 	 1000 	 0.3094825744628906 	 2.0410773754119873 	 0.3011956214904785 	 0.0006613731384277344 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:23:00.220536 test begin: paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, ) 	 25401604 	 1000 	 0.3094918727874756 	 2.0428261756896973 	 0.30103135108947754 	 0.0006663799285888672 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:23:03.241992 test begin: paddle.sign(Tensor([12404, 32, 128],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([12404, 32, 128],"float32"), ) 	 50806784 	 1000 	 0.3429419994354248 	 0.29784631729125977 	 0.3350653648376465 	 0.2870907783508301 	 0.2955191135406494 	 0.05110669136047363 	 0.2405397891998291 	 3.0517578125e-05 	 
2025-07-25 18:23:05.889646 test begin: paddle.sign(Tensor([32, 12404, 128],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([32, 12404, 128],"float32"), ) 	 50806784 	 1000 	 0.3429875373840332 	 0.297823429107666 	 0.33474159240722656 	 0.28709888458251953 	 0.2954094409942627 	 0.05133962631225586 	 0.24185824394226074 	 4.1484832763671875e-05 	 
2025-07-25 18:23:08.572784 test begin: paddle.sign(Tensor([32, 32, 49613],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([32, 32, 49613],"float32"), ) 	 50803712 	 1000 	 0.3438434600830078 	 0.2985990047454834 	 0.3358798027038574 	 0.287003755569458 	 0.29558801651000977 	 0.05398058891296387 	 0.24164223670959473 	 6.437301635742188e-05 	 
2025-07-25 18:23:11.247205 test begin: paddle.sign(Tensor([64, 1, 28, 28351],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1, 28, 28351],"float32"), ) 	 50804992 	 1000 	 0.34423208236694336 	 0.30130815505981445 	 0.3363308906555176 	 0.28711462020874023 	 0.29563307762145996 	 0.0520319938659668 	 0.24016928672790527 	 3.075599670410156e-05 	 
2025-07-25 18:23:13.890082 test begin: paddle.sign(Tensor([64, 1, 28351, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1, 28351, 28],"float32"), ) 	 50804992 	 1000 	 0.3441340923309326 	 0.29790592193603516 	 0.33603882789611816 	 0.2869133949279785 	 0.2955789566040039 	 0.05178236961364746 	 0.24198579788208008 	 3.814697265625e-05 	 
2025-07-25 18:23:16.516970 test begin: paddle.sign(Tensor([64, 1013, 28, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1013, 28, 28],"float32"), ) 	 50828288 	 1000 	 0.34511280059814453 	 0.297990083694458 	 0.3370547294616699 	 0.2872180938720703 	 0.2957184314727783 	 0.05235123634338379 	 0.24150991439819336 	 5.125999450683594e-05 	 
2025-07-25 18:23:19.171477 test begin: paddle.sign(Tensor([64801, 1, 28, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64801, 1, 28, 28],"float32"), ) 	 50803984 	 1000 	 0.3444957733154297 	 0.29785585403442383 	 0.3334667682647705 	 0.2870917320251465 	 0.2956123352050781 	 0.05191493034362793 	 0.2418689727783203 	 3.0040740966796875e-05 	 
2025-07-25 18:23:21.844336 test begin: paddle.sign(Tensor([66151, 1, 384],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([66151, 1, 384],"int64"), ) 	 25401984 	 1000 	 0.3073756694793701 	 0.2986443042755127 	 0.29949426651000977 	 0.28803443908691406 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:23:23.569133 test begin: paddle.sign(Tensor([7, 1, 3628801],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([7, 1, 3628801],"int64"), ) 	 25401607 	 1000 	 0.30778956413269043 	 0.3021245002746582 	 0.2998335361480713 	 0.2878272533416748 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:23:25.315667 test begin: paddle.sign(Tensor([7, 9451, 384],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([7, 9451, 384],"int64"), ) 	 25404288 	 1000 	 0.3074760437011719 	 0.299177885055542 	 0.29641175270080566 	 0.2851829528808594 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:23:27.049428 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([16, 3175201],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", ) 	 50803816 	 1000 	 19.40850281715393 	 4.760330677032471 	 2.4835472106933594 	 0.975433349609375 	 43.27071261405945 	 33.870789527893066 	 2.9431307315826416 	 1.7280540466308594 	 
2025-07-25 18:25:14.814508 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([16, 3175201],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", ) 	 50804416 	 1000 	 19.797938346862793 	 4.984293699264526 	 2.5333688259124756 	 1.0213801860809326 	 43.094297647476196 	 32.3503737449646 	 2.93104887008667 	 1.651174783706665 	 
2025-07-25 18:27:02.300171 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 512, 50, 240, window=Tensor([240],"float32"), center=True, pad_mode="reflect", )
[Error] CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 39.39 GiB of which 1.77 GiB is free. Process 155350 has 37.61 GiB memory in use. Of the allocated memory 4.26 GiB is allocated by PyTorch, and 5.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-25 18:28:27.940778 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", )
W0725 18:28:28.938594 123974 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([1993, 25500],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", ) 	 50822100 	 1000 	 17.689509868621826 	 4.783913612365723 	 2.263324737548828 	 0.9803111553192139 	 42.44201469421387 	 31.101964712142944 	 2.886552572250366 	 1.586698293685913 	 
2025-07-25 18:30:11.508194 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([1993, 25500],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", ) 	 50822700 	 1000 	 18.158304452896118 	 5.074527978897095 	 2.323004722595215 	 1.039846420288086 	 42.722392082214355 	 31.48328161239624 	 2.905749559402466 	 1.6061761379241943 	 
2025-07-25 18:31:54.951707 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 512, 50, 240, window=Tensor([240],"float32"), center=True, pad_mode="reflect", )
[Error] CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 39.39 GiB of which 1.15 GiB is free. Process 110729 has 38.24 GiB memory in use. Of the allocated memory 4.47 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-25 18:33:17.127623 test begin: paddle.signbit(Tensor([11, 17, 271],"int32"), )
W0725 18:33:17.325328 126965 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 17, 271],"int32"), ) 	 50677 	 1000 	 2.22745943069458 	 0.016536712646484375 	 3.0517578125e-05 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:20.000743 test begin: paddle.signbit(Tensor([11, 17, 543],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 17, 543],"int16"), ) 	 101541 	 1000 	 4.135569095611572 	 0.009937524795532227 	 7.081031799316406e-05 	 3.0040740966796875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:24.184577 test begin: paddle.signbit(Tensor([11, 461, 10],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 461, 10],"int32"), ) 	 50710 	 1000 	 2.1722028255462646 	 0.009989023208618164 	 3.528594970703125e-05 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:26.400651 test begin: paddle.signbit(Tensor([11, 923, 10],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 923, 10],"int16"), ) 	 101530 	 1000 	 4.10992693901062 	 0.009903430938720703 	 4.863739013671875e-05 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:30.557171 test begin: paddle.signbit(Tensor([12, 20, 211],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([12, 20, 211],"float32"), ) 	 50640 	 1000 	 2.217820405960083 	 0.016094207763671875 	 4.076957702636719e-05 	 2.8371810913085938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:32.832974 test begin: paddle.signbit(Tensor([12, 2116, 2],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([12, 2116, 2],"float32"), ) 	 50784 	 1000 	 2.2005224227905273 	 0.01618218421936035 	 2.288818359375e-05 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:35.331033 test begin: paddle.signbit(Tensor([1270, 20, 2],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([1270, 20, 2],"float32"), ) 	 50800 	 1000 	 2.2160160541534424 	 0.009837865829467773 	 3.218650817871094e-05 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:38.377306 test begin: paddle.signbit(Tensor([298, 17, 10],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([298, 17, 10],"int32"), ) 	 50660 	 1000 	 2.1952784061431885 	 0.016771554946899414 	 4.172325134277344e-05 	 0.00012350082397460938 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:40.639558 test begin: paddle.signbit(Tensor([597, 17, 10],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([597, 17, 10],"int16"), ) 	 101490 	 1000 	 4.0939717292785645 	 0.01667022705078125 	 2.1696090698242188e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:33:44.792873 test begin: paddle.sin(Tensor([128512, 396],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([128512, 396],"float32"), ) 	 50890752 	 1000 	 0.29613614082336426 	 0.29873013496398926 	 0.28693079948425293 	 0.2816348075866699 	 0.45130348205566406 	 0.7450473308563232 	 0.38787031173706055 	 0.38059449195861816 	 
2025-07-25 18:33:48.302451 test begin: paddle.sin(Tensor([254017, 200],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([254017, 200],"float32"), ) 	 50803400 	 1000 	 0.2958371639251709 	 0.3012678623199463 	 0.28539252281188965 	 0.28148460388183594 	 0.4505460262298584 	 0.7436702251434326 	 0.38707780838012695 	 0.3799130916595459 	 
2025-07-25 18:33:51.846924 test begin: paddle.sin(Tensor([50000, 1017],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([50000, 1017],"float32"), ) 	 50850000 	 1000 	 0.29593682289123535 	 0.30185604095458984 	 0.27999162673950195 	 0.28174328804016113 	 0.45087623596191406 	 0.7443110942840576 	 0.3878192901611328 	 0.3802330493927002 	 
2025-07-25 18:33:55.347599 test begin: paddle.sin(Tensor([508033, 100],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([508033, 100],"float32"), ) 	 50803300 	 1000 	 0.2956559658050537 	 0.2982368469238281 	 0.286590576171875 	 0.28760290145874023 	 0.45039892196655273 	 0.7436354160308838 	 0.3962228298187256 	 0.3799421787261963 	 
2025-07-25 18:33:58.772049 test begin: paddle.sin(Tensor([68608, 741],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([68608, 741],"float32"), ) 	 50838528 	 1000 	 0.29595446586608887 	 0.29842448234558105 	 0.2870619297027588 	 0.28774476051330566 	 0.45101380348205566 	 0.7441413402557373 	 0.3967325687408447 	 0.3802182674407959 	 
2025-07-25 18:34:02.187539 test begin: paddle.sinc(Tensor([16, 1587601],"float64"), )
[Prof] paddle.sinc 	 paddle.sinc(Tensor([16, 1587601],"float64"), ) 	 25401616 	 1000 	 2.9463112354278564 	 0.30198144912719727 	 0.25096797943115234 	 0.28548288345336914 	 2.5892627239227295 	 3.767490863800049 	 0.44077205657958984 	 0.3207681179046631 	 
2025-07-25 18:34:13.045253 test begin: paddle.sinc(Tensor([396901, 64],"float64"), )
[Prof] paddle.sinc 	 paddle.sinc(Tensor([396901, 64],"float64"), ) 	 25401664 	 1000 	 2.9455978870391846 	 0.3019993305206299 	 0.2510066032409668 	 0.2858867645263672 	 2.589341878890991 	 3.7675089836120605 	 0.4407782554626465 	 0.32068848609924316 	 
2025-07-25 18:34:23.980399 test begin: paddle.sinh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2955188751220703 	 0.29828619956970215 	 0.2864513397216797 	 0.2877388000488281 	 0.4504392147064209 	 0.7437829971313477 	 0.3964657783508301 	 0.38002896308898926 	 
2025-07-25 18:34:27.389662 test begin: paddle.sinh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29582953453063965 	 0.298290491104126 	 0.27938294410705566 	 0.2872014045715332 	 0.4503922462463379 	 0.7437880039215088 	 0.38680100440979004 	 0.3800008296966553 	 
2025-07-25 18:34:30.791399 test begin: paddle.sinh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2956252098083496 	 0.2982518672943115 	 0.28659844398498535 	 0.2877016067504883 	 0.4503648281097412 	 0.7438430786132812 	 0.3965795040130615 	 0.3800656795501709 	 
2025-07-25 18:34:34.216564 test begin: paddle.slice(Tensor([65344, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0725 18:34:36.993981 127955 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([65344, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 101609920 	 1000 	 0.008975982666015625 	 0.013194561004638672 	 2.4557113647460938e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:34:39.900998 test begin: paddle.slice(Tensor([65344, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0725 18:34:41.613435 127995 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([65344, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 101609920 	 1000 	 0.008011102676391602 	 0.013046741485595703 	 1.7404556274414062e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:34:41.998678 test begin: paddle.slice(Tensor([65344, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0725 18:34:45.319219 128014 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([65344, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 101609920 	 1000 	 0.013555049896240234 	 0.013002634048461914 	 2.3603439331054688e-05 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:34:45.756161 test begin: paddle.slice(Tensor([79381, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0725 18:34:48.220098 128052 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([79381, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 101607680 	 1000 	 0.013330221176147461 	 0.0200808048248291 	 1.5020370483398438e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:34:48.624302 test begin: paddle.slice(Tensor([79381, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0725 18:34:50.347800 128062 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([79381, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 101607680 	 1000 	 0.012711286544799805 	 0.012853860855102539 	 2.5987625122070312e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:34:50.727128 test begin: paddle.slice(Tensor([79381, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0725 18:34:52.400441 128092 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([79381, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 101607680 	 1000 	 0.00796365737915039 	 0.012980461120605469 	 1.049041748046875e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-25 18:34:52.764546 test begin: paddle.slice_scatter(Tensor([8, 1058401, 3, 9],"float32"), Tensor([8, 1058401, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 1058401, 3, 9],"float32"), Tensor([8, 1058401, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 279417864 	 1000 	 1.469881534576416 	 2.8454532623291016 	 1.4540019035339355 	 0.9688022136688232 	 4.067298650741577 	 3.786785840988159 	 0.6924629211425781 	 0.7740573883056641 	 combined
2025-07-25 18:35:13.365280 test begin: paddle.slice_scatter(Tensor([8, 117601, 3, 9],"float64"), Tensor([8, 117601, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 117601, 3, 9],"float64"), Tensor([8, 117601, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 31046664 	 1000 	 0.23403143882751465 	 0.5513753890991211 	 0.2175002098083496 	 0.1875922679901123 	 0.8284938335418701 	 0.7752494812011719 	 0.1410222053527832 	 0.1583271026611328 	 combined
2025-07-25 18:35:16.893604 test begin: paddle.slice_scatter(Tensor([8, 235201, 3, 9],"float32"), Tensor([8, 235201, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 235201, 3, 9],"float32"), Tensor([8, 235201, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 62093064 	 1000 	 0.3283114433288574 	 0.6432056427001953 	 0.31220149993896484 	 0.21843791007995605 	 0.9297521114349365 	 0.8658616542816162 	 0.15827012062072754 	 0.17697858810424805 	 combined
2025-07-25 18:35:21.512114 test begin: paddle.slice_scatter(Tensor([8, 423361, 3, 5],"float32"), Tensor([8, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 423361, 3, 5],"float32"), Tensor([8, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 50803560 	 1000 	 0.016097068786621094 	 0.3172457218170166 	 1.049041748046875e-05 	 0.10778570175170898 	 0.3239095211029053 	 0.3222951889038086 	 0.05503225326538086 	 0.06572365760803223 	 combined
2025-07-25 18:35:24.116710 test begin: paddle.slice_scatter(Tensor([8, 529201, 3, 9],"float64"), Tensor([8, 529201, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 529201, 3, 9],"float64"), Tensor([8, 529201, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 139709064 	 1000 	 1.05812406539917 	 2.4563398361206055 	 1.0417468547821045 	 0.8356621265411377 	 3.61342191696167 	 3.3906760215759277 	 0.6153345108032227 	 0.6927142143249512 	 combined
2025-07-25 18:35:42.075918 test begin: paddle.slice_scatter(Tensor([8, 6, 117601, 9],"float32"), Tensor([8, 6, 117601, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 117601, 9],"float32"), Tensor([8, 6, 117601, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 62093328 	 1000 	 0.3282625675201416 	 0.6416382789611816 	 0.3034348487854004 	 0.2184135913848877 	 0.9336240291595459 	 0.8663239479064941 	 0.15891194343566895 	 0.17705082893371582 	 combined
2025-07-25 18:35:46.681745 test begin: paddle.slice_scatter(Tensor([8, 6, 211681, 5],"float32"), Tensor([8, 2, 211681, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 211681, 5],"float32"), Tensor([8, 2, 211681, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 67737920 	 1000 	 0.18399429321289062 	 0.42692089080810547 	 0.16723299026489258 	 0.14240479469299316 	 0.7747676372528076 	 0.5730869770050049 	 0.131911039352417 	 0.11700248718261719 	 combined
2025-07-25 18:35:52.719078 test begin: paddle.slice_scatter(Tensor([8, 6, 264601, 9],"float64"), Tensor([8, 6, 264601, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 264601, 9],"float64"), Tensor([8, 6, 264601, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 139709328 	 1000 	 1.058349847793579 	 2.4597198963165283 	 1.0415172576904297 	 0.835637092590332 	 3.6124584674835205 	 3.3901071548461914 	 0.6151375770568848 	 0.6928415298461914 	 combined
2025-07-25 18:36:08.261234 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 1058401],"float32"), Tensor([8, 2, 3, 1058401],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 1058401],"float32"), Tensor([8, 2, 3, 1058401],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 203212992 	 1000 	 0.5411083698272705 	 1.2358241081237793 	 0.524712324142456 	 0.418684720993042 	 2.2787234783172607 	 1.6734540462493896 	 0.3880124092102051 	 0.34184741973876953 	 combined
2025-07-25 18:36:20.257565 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 176401],"float64"), Tensor([8, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 176401],"float64"), Tensor([8, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 25402032 	 1000 	 0.016060829162597656 	 0.3174610137939453 	 1.0013580322265625e-05 	 0.10786175727844238 	 0.3262009620666504 	 0.3226618766784668 	 0.055458784103393555 	 0.06575393676757812 	 combined
2025-07-25 18:36:22.320730 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 2, 3, 352801],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 2, 3, 352801],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 67737792 	 1000 	 0.1833951473236084 	 0.41863226890563965 	 0.16723942756652832 	 0.14236044883728027 	 0.7761797904968262 	 0.5729072093963623 	 0.1321578025817871 	 0.1169881820678711 	 combined
2025-07-25 18:36:26.243295 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 50803632 	 1000 	 0.024552106857299805 	 0.31752824783325195 	 2.0265579223632812e-05 	 0.10792374610900879 	 0.32697010040283203 	 0.32273221015930176 	 0.05554699897766113 	 0.06575369834899902 	 combined
2025-07-25 18:36:28.917081 test begin: paddle.slice_scatter(Tensor([8, 6, 529201, 9],"float32"), Tensor([8, 6, 529201, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 529201, 9],"float32"), Tensor([8, 6, 529201, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 279418128 	 1000 	 1.4704172611236572 	 2.845489740371704 	 1.453613042831421 	 0.9688992500305176 	 4.067277908325195 	 3.786956787109375 	 0.6923580169677734 	 0.7740738391876221 	 combined
2025-07-25 18:36:51.380740 test begin: paddle.slice_scatter(Tensor([8, 6, 58801, 9],"float64"), Tensor([8, 6, 58801, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 58801, 9],"float64"), Tensor([8, 6, 58801, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 31046928 	 1000 	 0.23432421684265137 	 0.5602219104766846 	 0.21820974349975586 	 0.18765974044799805 	 0.8313412666320801 	 0.775188684463501 	 0.1415424346923828 	 0.1584482192993164 	 combined
2025-07-25 18:36:57.876842 test begin: paddle.slice_scatter(Tensor([8, 6, 635041, 5],"float32"), Tensor([8, 2, 635041, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 635041, 5],"float32"), Tensor([8, 2, 635041, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 203213120 	 1000 	 0.5410454273223877 	 1.2303252220153809 	 0.5249032974243164 	 0.41851091384887695 	 2.2786223888397217 	 1.6732206344604492 	 0.38805055618286133 	 0.34171080589294434 	 combined
2025-07-25 18:37:09.506288 test begin: paddle.sqrt(Tensor([128, 396901],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2947566509246826 	 0.30423784255981445 	 0.28595876693725586 	 0.2886207103729248 	 0.45049357414245605 	 0.7473618984222412 	 0.39572978019714355 	 0.38189220428466797 	 
2025-07-25 18:37:13.034405 test begin: paddle.sqrt(Tensor([18, 15, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([18, 15, 3, 256, 256],"float32"), ) 	 53084160 	 1000 	 0.3072211742401123 	 0.31446099281311035 	 0.2914755344390869 	 0.29493093490600586 	 0.470278263092041 	 0.7803890705108643 	 0.4066123962402344 	 0.398709774017334 	 
2025-07-25 18:37:16.742973 test begin: paddle.sqrt(Tensor([259, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([259, 3, 256, 256],"float32"), ) 	 50921472 	 1000 	 0.29526352882385254 	 0.2997150421142578 	 0.28612780570983887 	 0.2884349822998047 	 0.4514298439025879 	 0.748856782913208 	 0.3921382427215576 	 0.3825845718383789 	 
2025-07-25 18:37:20.231055 test begin: paddle.sqrt(Tensor([4, 15, 13, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 13, 256, 256],"float32"), ) 	 51118080 	 1000 	 0.2961242198944092 	 0.3005940914154053 	 0.2872626781463623 	 0.2900357246398926 	 0.4530143737792969 	 0.7517294883728027 	 0.39795565605163574 	 0.3840465545654297 	 
2025-07-25 18:37:23.679441 test begin: paddle.sqrt(Tensor([4, 15, 3, 1103, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 3, 1103, 256],"float32"), ) 	 50826240 	 1000 	 0.29475903511047363 	 0.2991492748260498 	 0.2825462818145752 	 0.2868790626525879 	 0.4505281448364258 	 0.7476718425750732 	 0.3958098888397217 	 0.3820066452026367 	 
2025-07-25 18:37:27.146403 test begin: paddle.sqrt(Tensor([4, 15, 3, 256, 1103],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 3, 256, 1103],"float32"), ) 	 50826240 	 1000 	 0.2947351932525635 	 0.29904985427856445 	 0.2858448028564453 	 0.2884395122528076 	 0.4505574703216553 	 0.7476544380187988 	 0.3961305618286133 	 0.3820219039916992 	 
2025-07-25 18:37:30.606121 test begin: paddle.sqrt(Tensor([4, 65, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 65, 3, 256, 256],"float32"), ) 	 51118080 	 1000 	 0.29619336128234863 	 0.30313873291015625 	 0.28729677200317383 	 0.29001379013061523 	 0.4531066417694092 	 0.7517745494842529 	 0.3981761932373047 	 0.3840749263763428 	 
2025-07-25 18:37:34.067054 test begin: paddle.sqrt(Tensor([544, 93431],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([544, 93431],"float32"), ) 	 50826464 	 1000 	 0.2947237491607666 	 0.3175806999206543 	 0.28585386276245117 	 0.28871774673461914 	 0.4505898952484131 	 0.7477736473083496 	 0.39293718338012695 	 0.3819549083709717 	 
2025-07-25 18:37:39.526211 test begin: paddle.sqrt(Tensor([64, 13, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 13, 256, 256],"float32"), ) 	 54525952 	 1000 	 0.315493106842041 	 0.32372546195983887 	 0.3065643310546875 	 0.3030104637145996 	 0.48304009437561035 	 0.8015339374542236 	 0.41869258880615234 	 0.40976548194885254 	 
2025-07-25 18:37:43.274643 test begin: paddle.sqrt(Tensor([64, 3, 1034, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 3, 1034, 256],"float32"), ) 	 50823168 	 1000 	 0.29459476470947266 	 0.29912471771240234 	 0.2857401371002197 	 0.2886190414428711 	 0.45067548751831055 	 0.7475419044494629 	 0.3957326412200928 	 0.3819127082824707 	 
2025-07-25 18:37:46.710336 test begin: paddle.sqrt(Tensor([64, 3, 256, 1034],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 3, 256, 1034],"float32"), ) 	 50823168 	 1000 	 0.29457759857177734 	 0.29912543296813965 	 0.28576040267944336 	 0.28853416442871094 	 0.45061683654785156 	 0.7475588321685791 	 0.39612674713134766 	 0.3819582462310791 	 
2025-07-25 18:37:50.184981 test begin: paddle.square(Tensor([104, 488493],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([104, 488493],"float32"), ) 	 50803272 	 1000 	 0.29598021507263184 	 0.2980787754058838 	 0.2870938777923584 	 0.28623437881469727 	 0.44984912872314453 	 1.0557677745819092 	 0.3956606388092041 	 0.26992368698120117 	 
2025-07-25 18:37:53.986574 test begin: paddle.square(Tensor([128, 396901],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2959768772125244 	 0.2979142665863037 	 0.28714847564697266 	 0.28612518310546875 	 0.44983673095703125 	 1.0558404922485352 	 0.39499378204345703 	 0.2699551582336426 	 
2025-07-25 18:37:57.732661 test begin: paddle.square(Tensor([24904, 12, 170, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([24904, 12, 170, 1],"float32"), ) 	 50804160 	 1000 	 0.2958953380584717 	 0.3038952350616455 	 0.280078649520874 	 0.2861971855163574 	 0.4497075080871582 	 1.0558192729949951 	 0.3860127925872803 	 0.269913911819458 	 
2025-07-25 18:38:03.025989 test begin: paddle.square(Tensor([3548, 12, 1194, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 12, 1194, 1],"float32"), ) 	 50835744 	 1000 	 0.2961411476135254 	 0.2981123924255371 	 0.28019189834594727 	 0.27970361709594727 	 0.44997119903564453 	 1.0563864707946777 	 0.3867051601409912 	 0.2700943946838379 	 
2025-07-25 18:38:06.756927 test begin: paddle.square(Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 12, 170, 8],"float32"), ) 	 57903360 	 1000 	 0.3363058567047119 	 0.33882808685302734 	 0.32341670989990234 	 0.32672905921936035 	 0.5121498107910156 	 1.2010154724121094 	 0.4575057029724121 	 0.30706238746643066 	 
2025-07-25 18:38:11.028646 test begin: paddle.square(Tensor([3548, 85, 170, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 85, 170, 1],"float32"), ) 	 51268600 	 1000 	 0.29848361015319824 	 0.3004448413848877 	 0.2896101474761963 	 0.28876495361328125 	 0.45351243019104004 	 1.065110206604004 	 0.39592981338500977 	 0.27234935760498047 	 
2025-07-25 18:38:14.809255 test begin: paddle.square(Tensor([544, 93431],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([544, 93431],"float32"), ) 	 50826464 	 1000 	 0.2959177494049072 	 0.2992074489593506 	 0.287156343460083 	 0.286482572555542 	 0.4496583938598633 	 1.0561368465423584 	 0.3955204486846924 	 0.269970178604126 	 
2025-07-25 18:38:18.605590 test begin: paddle.squeeze(Tensor([10, 512, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([10, 512, 1, 100, 100],"float32"), axis=list[2,], ) 	 51200000 	 1000 	 0.009587287902832031 	 0.008749008178710938 	 1.5020370483398438e-05 	 2.956390380859375e-05 	 0.04970145225524902 	 0.06522536277770996 	 4.267692565917969e-05 	 7.700920104980469e-05 	 
2025-07-25 18:38:20.548127 test begin: paddle.squeeze(Tensor([105344, 483],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([105344, 483],"float32"), ) 	 50881152 	 1000 	 0.008083343505859375 	 0.006606340408325195 	 1.1205673217773438e-05 	 2.2172927856445312e-05 	 0.04948568344116211 	 0.05822491645812988 	 3.2901763916015625e-05 	 3.7670135498046875e-05 	 
2025-07-25 18:38:22.601045 test begin: paddle.squeeze(Tensor([396901, 128],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.003932476043701172 	 0.0037992000579833984 	 1.1920928955078125e-05 	 1.621246337890625e-05 	 0.0426938533782959 	 0.05705690383911133 	 4.029273986816406e-05 	 7.319450378417969e-05 	 
2025-07-25 18:38:24.415011 test begin: paddle.squeeze(Tensor([421120, 25, 5],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([421120, 25, 5],"float32"), axis=-1, ) 	 52640000 	 1000 	 0.004667043685913086 	 0.003930091857910156 	 7.867813110351562e-06 	 1.6689300537109375e-05 	 0.0432124137878418 	 0.05316948890686035 	 2.9325485229492188e-05 	 4.935264587402344e-05 	 
2025-07-25 18:38:26.208788 test begin: paddle.squeeze(Tensor([421120, 31, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([421120, 31, 4],"float32"), axis=-1, ) 	 52218880 	 1000 	 0.009719371795654297 	 0.003958463668823242 	 2.3365020751953125e-05 	 1.811981201171875e-05 	 0.04268956184387207 	 0.05229520797729492 	 1.811981201171875e-05 	 3.9577484130859375e-05 	 
2025-07-25 18:38:28.077828 test begin: paddle.squeeze(Tensor([508033, 25, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([508033, 25, 4],"float32"), axis=-1, ) 	 50803300 	 1000 	 0.004591464996337891 	 0.003938913345336914 	 6.67572021484375e-06 	 1.6927719116210938e-05 	 0.0431058406829834 	 0.05294060707092285 	 2.5510787963867188e-05 	 5.054473876953125e-05 	 
2025-07-25 18:38:29.816168 test begin: paddle.squeeze(Tensor([8, 512, 1, 100, 125],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([8, 512, 1, 100, 125],"float32"), axis=list[2,], ) 	 51200000 	 1000 	 0.004728794097900391 	 0.004916191101074219 	 6.4373016357421875e-06 	 1.7642974853515625e-05 	 0.04272747039794922 	 0.05675005912780762 	 3.600120544433594e-05 	 3.695487976074219e-05 	 
2025-07-25 18:38:31.621161 test begin: paddle.squeeze(Tensor([8, 512, 1, 125, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([8, 512, 1, 125, 100],"float32"), axis=list[2,], ) 	 51200000 	 1000 	 0.0047953128814697266 	 0.004885435104370117 	 2.2172927856445312e-05 	 1.5974044799804688e-05 	 0.0425724983215332 	 0.057173728942871094 	 2.9087066650390625e-05 	 4.744529724121094e-05 	 
2025-07-25 18:38:33.405989 test begin: paddle.squeeze(Tensor([8, 512, 2, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([8, 512, 2, 100, 100],"float32"), axis=list[2,], ) 	 81920000 	 1000 	 0.004786968231201172 	 0.004877567291259766 	 1.3589859008789062e-05 	 1.7642974853515625e-05 	 0.0423433780670166 	 0.05337333679199219 	 3.910064697265625e-05 	 4.4345855712890625e-05 	 
2025-07-25 18:38:37.165655 test begin: paddle.squeeze(Tensor([8, 636, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([8, 636, 1, 100, 100],"float32"), axis=list[2,], ) 	 50880000 	 1000 	 0.009393930435180664 	 0.008843183517456055 	 1.3113021850585938e-05 	 2.5987625122070312e-05 	 0.049643754959106445 	 0.0730292797088623 	 2.7179718017578125e-05 	 6.175041198730469e-05 	 
2025-07-25 18:38:39.719389 test begin: paddle.stack(list[Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),], axis=-2, ) 	 259269120 	 1000 	 1.8136177062988281 	 7.124450206756592 	 1.7988746166229248 	 7.107434988021851 	 2.0271193981170654 	 0.10117554664611816 	 1.9465391635894775 	 6.103515625e-05 	 
2025-07-25 18:38:59.357853 test begin: paddle.stack(list[Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),], axis=-2, ) 	 270103680 	 1000 	 1.894063949584961 	 7.424034833908081 	 1.8779804706573486 	 7.4064857959747314 	 2.112913131713867 	 0.09157443046569824 	 2.035620927810669 	 6.413459777832031e-05 	 
2025-07-25 18:39:19.937492 test begin: paddle.stack(list[Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),], axis=0, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),], axis=0, ) 	 609681408 	 1000 	 2.952101945877075 	 2.591223955154419 	 2.9388177394866943 	 2.5745506286621094 	 4.568998336791992 	 2.7016749382019043 	 4.438493490219116 	 1.3803181648254395 	 
2025-07-25 18:39:53.127646 test begin: paddle.stack(list[Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),], axis=0, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),], axis=0, ) 	 609681408 	 1000 	 2.952465534210205 	 2.5913262367248535 	 2.9389469623565674 	 2.5744411945343018 	 4.569697856903076 	 2.701664447784424 	 4.46073842048645 	 1.3792803287506104 	 
2025-07-25 18:40:27.313303 test begin: paddle.stack(list[Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),], axis=-2, ) 	 282839040 	 1000 	 2.0667526721954346 	 8.157432794570923 	 2.0544934272766113 	 8.139748811721802 	 2.217575788497925 	 0.0951852798461914 	 2.140378952026367 	 6.604194641113281e-05 	 
2025-07-25 18:40:50.462631 test begin: paddle.stack(list[Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),], axis=-2, ) 	 294658560 	 1000 	 2.093510150909424 	 8.93575644493103 	 2.080427646636963 	 8.460158109664917 	 2.3030669689178467 	 0.09641742706298828 	 2.217963933944702 	 7.009506225585938e-05 	 
2025-07-25 18:41:17.679711 test begin: paddle.stack(list[Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),], axis=-2, ) 	 254018560 	 1000 	 1.7590062618255615 	 6.980169296264648 	 1.746774673461914 	 6.95502781867981 	 1.9827446937561035 	 0.09310150146484375 	 1.9001655578613281 	 6.890296936035156e-05 	 
2025-07-25 18:41:37.755260 test begin: paddle.stack(list[Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),], axis=-2, ) 	 257826240 	 1000 	 1.7963943481445312 	 7.0896594524383545 	 1.7713963985443115 	 7.063185453414917 	 2.014958381652832 	 0.09898996353149414 	 1.9272229671478271 	 5.0067901611328125e-05 	 
2025-07-25 18:41:58.027431 test begin: paddle.stack(list[Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),], axis=-2, ) 	 259269120 	 1000 	 1.8075032234191895 	 7.126060485839844 	 1.7919096946716309 	 7.108975172042847 	 2.026886224746704 	 0.10767221450805664 	 1.9490811824798584 	 4.673004150390625e-05 	 
2025-07-25 18:42:17.929999 test begin: paddle.stanh(x=Tensor([12700801, 2],"float64"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([12700801, 2],"float64"), scale_a=6.42, scale_b=3.58, ) 	 25401602 	 1000 	 0.3074629306793213 	 0.3070523738861084 	 0.29725050926208496 	 0.29660916328430176 	 0.44623279571533203 	 0.7414519786834717 	 0.39089274406433105 	 0.3787693977355957 	 
2025-07-25 18:42:22.887332 test begin: paddle.stanh(x=Tensor([2, 12700801],"float64"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 12700801],"float64"), scale_a=6.42, scale_b=3.58, ) 	 25401602 	 1000 	 0.30721378326416016 	 0.3275418281555176 	 0.2958221435546875 	 0.2894008159637451 	 0.446152925491333 	 0.7413864135742188 	 0.38257265090942383 	 0.3787214756011963 	 
2025-07-25 18:42:27.431359 test begin: paddle.stanh(x=Tensor([2, 25401601],"float32"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 25401601],"float32"), scale_a=6.42, scale_b=3.58, ) 	 50803202 	 1000 	 0.29509639739990234 	 0.30330657958984375 	 0.2783987522125244 	 0.28212738037109375 	 0.4506709575653076 	 0.7431268692016602 	 0.3875763416290283 	 0.37972044944763184 	 
2025-07-25 18:42:30.972546 test begin: paddle.stanh(x=Tensor([2, 3, 2, 2116801],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3, 2, 2116801],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.3003203868865967 	 0.30034685134887695 	 0.29093146324157715 	 0.29006195068359375 	 0.4470705986022949 	 0.7413647174835205 	 0.39336061477661133 	 0.3787825107574463 	 
2025-07-25 18:42:33.810246 test begin: paddle.stanh(x=Tensor([2, 3, 2116801, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3, 2116801, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.3023090362548828 	 0.3137784004211426 	 0.28826260566711426 	 0.28334951400756836 	 0.4469945430755615 	 0.7414150238037109 	 0.39313316345214844 	 0.37876200675964355 	 
2025-07-25 18:42:40.671846 test begin: paddle.stanh(x=Tensor([2, 3175201, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3175201, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401608 	 1000 	 0.306943416595459 	 0.31577467918395996 	 0.29088544845581055 	 0.28984808921813965 	 0.44715142250061035 	 0.7413833141326904 	 0.3933887481689453 	 0.3787968158721924 	 
2025-07-25 18:42:43.611381 test begin: paddle.stanh(x=Tensor([2116801, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2116801, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.3043959140777588 	 0.3004879951477051 	 0.29095029830932617 	 0.2901582717895508 	 0.44704699516296387 	 0.7413370609283447 	 0.38686323165893555 	 0.3787686824798584 	 
2025-07-25 18:42:46.451410 test begin: paddle.stanh(x=Tensor([25401601, 2],"float32"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([25401601, 2],"float32"), scale_a=6.42, scale_b=3.58, ) 	 50803202 	 1000 	 0.29505395889282227 	 0.298825740814209 	 0.2854888439178467 	 0.28841638565063477 	 0.4505002498626709 	 0.7430281639099121 	 0.3949456214904785 	 0.3796417713165283 	 
2025-07-25 18:42:49.914382 test begin: paddle.std(Tensor([1, 1270081, 4, 10],"float32"), list[1,3,], True, False, )
W0725 18:42:50.675472 133377 dygraph_functions.cc:88394] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.std 	 paddle.std(Tensor([1, 1270081, 4, 10],"float32"), list[1,3,], True, False, ) 	 50803240 	 1000 	 1.2590265274047852 	 0.23157334327697754 	 2.574920654296875e-05 	 0.11828041076660156 	 1.4177148342132568 	 0.8035256862640381 	 0.18143773078918457 	 0.09152936935424805 	 
2025-07-25 18:42:54.891594 test begin: paddle.std(Tensor([1, 3, 1693441, 10],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 1693441, 10],"float32"), list[1,3,], True, False, ) 	 50803230 	 1000 	 1.5413758754730225 	 0.7941288948059082 	 3.504753112792969e-05 	 0.7764506340026855 	 1.6478593349456787 	 1.074965238571167 	 0.2405564785003662 	 0.13752341270446777 	 
2025-07-25 18:43:00.898118 test begin: paddle.std(Tensor([1, 3, 4, 2116801],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 4, 2116801],"float64"), 2, True, False, ) 	 25401612 	 1000 	 1.6459708213806152 	 0.21829009056091309 	 0.00011420249938964844 	 0.20036768913269043 	 2.0225462913513184 	 1.486903190612793 	 0.2952578067779541 	 0.19014501571655273 	 
2025-07-25 18:43:06.969538 test begin: paddle.std(Tensor([1, 3, 4, 4233601],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 4, 4233601],"float32"), list[1,3,], True, False, ) 	 50803212 	 1000 	 1.2097771167755127 	 0.23529434204101562 	 2.2172927856445312e-05 	 0.12018132209777832 	 1.4020159244537354 	 0.7974457740783691 	 0.17938995361328125 	 0.09087967872619629 	 
2025-07-25 18:43:11.481062 test begin: paddle.std(Tensor([1, 3, 846721, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 846721, 10],"float64"), 2, True, False, ) 	 25401630 	 1000 	 7.973849296569824 	 0.1859579086303711 	 4.8160552978515625e-05 	 0.09498262405395508 	 4.8081746101379395 	 0.779442310333252 	 0.6154394149780273 	 0.08880901336669922 	 
2025-07-25 18:43:25.835170 test begin: paddle.std(Tensor([1, 635041, 4, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 635041, 4, 10],"float64"), 2, True, False, ) 	 25401640 	 1000 	 1.7554678916931152 	 1.5746564865112305 	 0.00011491775512695312 	 0.1809847354888916 	 1.9400215148925781 	 1.2674059867858887 	 0.28319334983825684 	 0.16203045845031738 	 
2025-07-25 18:43:34.385516 test begin: paddle.std(Tensor([1587601, 32],"float32"), )
[Prof] paddle.std 	 paddle.std(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 1.3512024879455566 	 0.16668081283569336 	 3.409385681152344e-05 	 0.08511948585510254 	 1.33858060836792 	 0.7764134407043457 	 0.17122268676757812 	 0.08844184875488281 	 
2025-07-25 18:43:41.093410 test begin: paddle.std(Tensor([211681, 3, 4, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([211681, 3, 4, 10],"float64"), 2, True, False, ) 	 25401720 	 1000 	 1.7542169094085693 	 0.19878721237182617 	 0.00011992454528808594 	 0.18123817443847656 	 1.9402148723602295 	 1.2673487663269043 	 0.28325653076171875 	 0.16203641891479492 	 
2025-07-25 18:43:47.010717 test begin: paddle.std(Tensor([32, 1587601],"float32"), )
[Prof] paddle.std 	 paddle.std(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 1.093958854675293 	 0.1666429042816162 	 2.4080276489257812e-05 	 0.08516907691955566 	 1.3387196063995361 	 0.7763590812683105 	 0.1712801456451416 	 0.08846783638000488 	 
2025-07-25 18:43:51.233436 test begin: paddle.std(Tensor([423361, 3, 4, 10],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([423361, 3, 4, 10],"float32"), list[1,3,], True, False, ) 	 50803320 	 1000 	 1.5248544216156006 	 0.8262770175933838 	 2.193450927734375e-05 	 0.8083455562591553 	 1.635437250137329 	 1.10284423828125 	 0.23874759674072266 	 0.1411278247833252 	 
2025-07-25 18:43:57.235545 test begin: paddle.strided_slice(x=Tensor([3, 4, 352801, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([3, 4, 352801, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 25401672 	 1000 	 0.006270885467529297 	 0.21534204483032227 	 8.821487426757812e-06 	 8.726119995117188e-05 	 0.14755868911743164 	 0.2549729347229004 	 0.07529020309448242 	 8.20159912109375e-05 	 combined
2025-07-25 18:43:58.511753 test begin: paddle.strided_slice(x=Tensor([3, 4, 5, 423361],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([3, 4, 5, 423361],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 25401660 	 1000 	 0.006276130676269531 	 0.20885086059570312 	 7.152557373046875e-06 	 7.2479248046875e-05 	 0.14755916595458984 	 0.19859099388122559 	 0.07524228096008301 	 7.987022399902344e-05 	 combined
2025-07-25 18:43:59.638238 test begin: paddle.strided_slice(x=Tensor([3, 4, 5, 846721],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([3, 4, 5, 846721],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 50803260 	 1000 	 0.006342172622680664 	 0.21004509925842285 	 1.4543533325195312e-05 	 0.00010538101196289062 	 0.1477975845336914 	 0.20312881469726562 	 0.07543706893920898 	 8.606910705566406e-05 	 combined
2025-07-25 18:44:01.052350 test begin: paddle.strided_slice(x=Tensor([3, 4, 5, 846721],"int32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([3, 4, 5, 846721],"int32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 50803260 	 1000 	 0.011028528213500977 	 0.28101038932800293 	 1.3113021850585938e-05 	 8.606910705566406e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:44:02.112339 test begin: paddle.strided_slice(x=Tensor([3, 4, 705601, 6],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([3, 4, 705601, 6],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 50803272 	 1000 	 0.00625300407409668 	 0.20789432525634766 	 1.0251998901367188e-05 	 7.414817810058594e-05 	 0.14767813682556152 	 0.1966242790222168 	 0.07536029815673828 	 0.00010228157043457031 	 combined
2025-07-25 18:44:03.501372 test begin: paddle.strided_slice(x=Tensor([3, 4, 705601, 6],"int32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([3, 4, 705601, 6],"int32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 50803272 	 1000 	 0.006245136260986328 	 0.2252194881439209 	 7.3909759521484375e-06 	 7.200241088867188e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:44:04.468179 test begin: paddle.strided_slice(x=Tensor([423361, 4, 5, 6],"int32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([423361, 4, 5, 6],"int32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 50803320 	 1000 	 0.006249427795410156 	 0.28063440322875977 	 7.3909759521484375e-06 	 0.023929595947265625 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:44:05.653615 test begin: paddle.subtract(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), ) 	 101608320 	 1000 	 0.4510331153869629 	 0.4500570297241211 	 0.4408233165740967 	 0.43517231941223145 	 0.4736778736114502 	 0.2978055477142334 	 0.4139988422393799 	 0.22534561157226562 	 
2025-07-25 18:44:09.845086 test begin: paddle.subtract(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), ) 	 101671488 	 1000 	 0.4509453773498535 	 0.4471266269683838 	 0.43390417098999023 	 0.42929553985595703 	 0.4741051197052002 	 0.2979574203491211 	 0.40584492683410645 	 0.21857333183288574 	 
2025-07-25 18:44:14.095111 test begin: paddle.subtract(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), ) 	 65141280 	 1000 	 0.3583064079284668 	 0.37601351737976074 	 0.3474879264831543 	 0.3574652671813965 	 0.8839969635009766 	 0.8983666896820068 	 0.4514739513397217 	 0.4589827060699463 	 
2025-07-25 18:44:18.624847 test begin: paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), ) 	 65141280 	 1000 	 0.357830286026001 	 0.3698081970214844 	 0.3471989631652832 	 0.3575408458709717 	 0.8196666240692139 	 0.8983569145202637 	 0.2794933319091797 	 0.4589979648590088 	 
2025-07-25 18:44:23.112419 test begin: paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), ) 	 115806720 	 1000 	 0.5130360126495361 	 0.5099081993103027 	 0.5013141632080078 	 0.4967925548553467 	 0.5405063629150391 	 0.3387308120727539 	 0.4815812110900879 	 0.26528000831604004 	 
2025-07-25 18:44:27.899161 test begin: paddle.subtract(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), ) 	 102537200 	 1000 	 0.4547996520996094 	 0.4508821964263916 	 0.44422149658203125 	 0.43950724601745605 	 0.47980546951293945 	 0.300553560256958 	 0.419680118560791 	 0.22821545600891113 	 
2025-07-25 18:44:32.091637 test begin: paddle.subtract(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), ) 	 101646336 	 1000 	 0.45607662200927734 	 0.4714772701263428 	 0.4379127025604248 	 0.43476033210754395 	 0.4734199047088623 	 0.298081636428833 	 0.41428160667419434 	 0.210723876953125 	 
2025-07-25 18:44:43.028764 test begin: paddle.subtract(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), ) 	 101670912 	 1000 	 0.4509739875793457 	 0.44701290130615234 	 0.4410572052001953 	 0.43564820289611816 	 0.4739227294921875 	 0.2979860305786133 	 0.4148976802825928 	 0.21178865432739258 	 
2025-07-25 18:44:47.191773 test begin: paddle.subtract(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), ) 	 101744640 	 1000 	 0.45131850242614746 	 0.4474482536315918 	 0.44142889976501465 	 0.4356663227081299 	 0.4744572639465332 	 0.2982451915740967 	 0.4153170585632324 	 0.22371220588684082 	 
2025-07-25 18:44:51.404183 test begin: paddle.subtract(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), ) 	 103809024 	 1000 	 0.4606485366821289 	 0.45876336097717285 	 0.45060205459594727 	 0.44478821754455566 	 0.48566317558288574 	 0.3041083812713623 	 0.4264676570892334 	 0.22934246063232422 	 
2025-07-25 18:44:55.700795 test begin: paddle.subtract(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), ) 	 103809024 	 1000 	 0.4602773189544678 	 0.4563779830932617 	 0.45000576972961426 	 0.444934606552124 	 0.4839024543762207 	 0.3041496276855469 	 0.42347264289855957 	 0.21393585205078125 	 
2025-07-25 18:45:00.090753 test begin: paddle.subtract(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), ) 	 104857600 	 1000 	 0.4649221897125244 	 0.46091675758361816 	 0.44750022888183594 	 0.4488794803619385 	 0.4888801574707031 	 0.3071110248565674 	 0.4200422763824463 	 0.20649003982543945 	 
2025-07-25 18:45:04.397104 test begin: paddle.subtract(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), ) 	 101646336 	 1000 	 0.45401859283447266 	 0.44710826873779297 	 0.43378353118896484 	 0.4293630123138428 	 0.4736602306365967 	 0.2978990077972412 	 0.4030423164367676 	 0.22118473052978516 	 
2025-07-25 18:45:08.608444 test begin: paddle.subtract(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), ) 	 101646336 	 1000 	 0.450824499130249 	 0.45005345344543457 	 0.43378686904907227 	 0.42908477783203125 	 0.47356319427490234 	 0.29799365997314453 	 0.3886904716491699 	 0.21826481819152832 	 
2025-07-25 18:45:12.832424 test begin: paddle.subtract(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), ) 	 101744640 	 1000 	 0.45126795768737793 	 0.44740915298461914 	 0.43414998054504395 	 0.4291558265686035 	 0.47534751892089844 	 0.29822635650634766 	 0.40710878372192383 	 0.20801997184753418 	 
2025-07-25 18:45:17.138703 test begin: paddle.sum(Tensor([3544, 32, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([3544, 32, 896],"bfloat16"), axis=1, keepdim=False, ) 	 101613568 	 1000 	 0.17226672172546387 	 0.1600511074066162 	 0.15188193321228027 	 0.13849377632141113 	 0.26919984817504883 	 0.09288954734802246 	 0.19801831245422363 	 7.2479248046875e-05 	 
2025-07-25 18:45:19.604036 test begin: paddle.sum(Tensor([6017, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6017, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 102433408 	 1000 	 0.1761326789855957 	 0.1785259246826172 	 0.155517578125 	 0.15365362167358398 	 0.27106380462646484 	 0.09400773048400879 	 0.1997842788696289 	 7.772445678710938e-05 	 
2025-07-25 18:45:22.077983 test begin: paddle.sum(Tensor([6017, 32, 528],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6017, 32, 528],"bfloat16"), axis=1, keepdim=False, ) 	 101663232 	 1000 	 0.18398308753967285 	 0.16243433952331543 	 0.16353344917297363 	 0.14089202880859375 	 0.2690150737762451 	 0.08871269226074219 	 0.197770357131958 	 7.700920104980469e-05 	 
2025-07-25 18:45:24.545740 test begin: paddle.sum(Tensor([6036, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6036, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 102756864 	 1000 	 0.1766350269317627 	 0.17561650276184082 	 0.15603899955749512 	 0.1532118320465088 	 0.2719123363494873 	 0.09323477745056152 	 0.19565200805664062 	 7.486343383789062e-05 	 
2025-07-25 18:45:27.055762 test begin: paddle.sum(Tensor([6036, 32, 527],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6036, 32, 527],"bfloat16"), axis=1, keepdim=False, ) 	 101791104 	 1000 	 0.18659496307373047 	 0.17979121208190918 	 0.16612648963928223 	 0.15817904472351074 	 0.26921629905700684 	 0.08733320236206055 	 0.19832277297973633 	 6.818771362304688e-05 	 
2025-07-25 18:45:29.480496 test begin: paddle.sum(Tensor([6078, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6078, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 103471872 	 1000 	 0.17765069007873535 	 0.1767866611480713 	 0.1563422679901123 	 0.1548478603363037 	 0.27372241020202637 	 0.09429717063903809 	 0.20274615287780762 	 7.557868957519531e-05 	 
2025-07-25 18:45:32.031678 test begin: paddle.sum(Tensor([6078, 32, 523],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6078, 32, 523],"bfloat16"), axis=1, keepdim=False, ) 	 101721408 	 1000 	 0.18246221542358398 	 0.17551708221435547 	 0.1621565818786621 	 0.15372514724731445 	 0.2694704532623291 	 0.09052443504333496 	 0.19225049018859863 	 7.724761962890625e-05 	 
2025-07-25 18:45:34.477657 test begin: paddle.t(Tensor([10, 5080321],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.008770465850830078 	 0.0068476200103759766 	 1.4543533325195312e-05 	 1.9073486328125e-05 	 0.04822492599487305 	 0.06811690330505371 	 3.5762786865234375e-05 	 7.724761962890625e-05 	 
2025-07-25 18:45:37.122155 test begin: paddle.t(Tensor([20, 2540161],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([20, 2540161],"float32"), ) 	 50803220 	 1000 	 0.004255056381225586 	 0.0037772655487060547 	 1.1682510375976562e-05 	 2.288818359375e-05 	 0.04072737693786621 	 0.05766034126281738 	 4.124641418457031e-05 	 8.416175842285156e-05 	 
2025-07-25 18:45:39.580109 test begin: paddle.t(Tensor([2540161, 20],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.004263162612915039 	 0.0040531158447265625 	 1.6689300537109375e-05 	 5.7697296142578125e-05 	 0.043202877044677734 	 0.06181144714355469 	 5.9604644775390625e-05 	 8.273124694824219e-05 	 
2025-07-25 18:45:41.355579 test begin: paddle.t(Tensor([49613, 512],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([49613, 512],"int64"), ) 	 25401856 	 1000 	 0.008590221405029297 	 0.006878852844238281 	 1.049041748046875e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:42.303503 test begin: paddle.t(Tensor([5080321, 10],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([5080321, 10],"float32"), ) 	 50803210 	 1000 	 0.004273176193237305 	 0.0068356990814208984 	 7.62939453125e-06 	 1.9788742065429688e-05 	 0.048000335693359375 	 0.06375670433044434 	 4.863739013671875e-05 	 7.009506225585938e-05 	 
2025-07-25 18:45:45.879965 test begin: paddle.t(Tensor([512, 49613],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([512, 49613],"int64"), ) 	 25401856 	 1000 	 0.008572578430175781 	 0.00592041015625 	 1.0967254638671875e-05 	 8.058547973632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:45:48.507379 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", ) 	 76204806 	 1000 	 3.1980104446411133 	 2.91162371635437 	 0.6533386707305908 	 0.425126314163208 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:01.342178 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 3],"int64"), mode="raise", ) 	 50803210 	 1000 	 0.0891573429107666 	 0.12281131744384766 	 3.0040740966796875e-05 	 7.891654968261719e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:02.533720 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([6350401, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([6350401, 3],"int64"), mode="raise", ) 	 69854407 	 1000 	 2.403064250946045 	 2.1958558559417725 	 0.4920783042907715 	 0.32056641578674316 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:12.653814 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 3],"int64"), mode="raise", ) 	 50803209 	 1000 	 0.13487005233764648 	 0.16793608665466309 	 4.100799560546875e-05 	 0.00010657310485839844 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:14.032212 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 8467201],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 8467201],"int64"), mode="raise", ) 	 67737605 	 1000 	 2.139028549194336 	 1.9576826095581055 	 0.4379258155822754 	 0.28554487228393555 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:22.918531 test begin: paddle.take(Tensor([3, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", ) 	 25401614 	 1000 	 1.5444071292877197 	 1.1553657054901123 	 0.3157196044921875 	 0.1668105125427246 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:39.044784 test begin: paddle.take(Tensor([3, 4],"float32"), Tensor([8467201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float32"), Tensor([8467201, 3],"int64"), mode="raise", ) 	 25401615 	 1000 	 1.5469655990600586 	 1.153796911239624 	 0.3158071041107178 	 0.16687297821044922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:46:54.540208 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="clip", ) 	 25401620 	 1000 	 0.6439692974090576 	 0.6028809547424316 	 0.3289196491241455 	 0.3079493045806885 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:47:12.188246 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="wrap", ) 	 25401620 	 1000 	 3.3463916778564453 	 1.20078706741333 	 0.31107306480407715 	 0.30669736862182617 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:47:33.340997 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="clip", ) 	 25401617 	 1000 	 0.6448619365692139 	 0.6028392314910889 	 0.3289039134979248 	 0.30793046951293945 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:47:51.022021 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="wrap", ) 	 25401617 	 1000 	 3.3462698459625244 	 1.2008271217346191 	 0.31107234954833984 	 0.3067500591278076 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:11.971195 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="clip", ) 	 67737608 	 1000 	 3.9840612411499023 	 4.004338264465332 	 2.0357115268707275 	 2.0461363792419434 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:30.345741 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="wrap", ) 	 67737608 	 1000 	 8.45331358909607 	 4.9949610233306885 	 0.7862992286682129 	 1.2776644229888916 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:54.193679 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="clip", ) 	 25401643 	 1000 	 0.05809736251831055 	 0.042851924896240234 	 3.886222839355469e-05 	 7.009506225585938e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:55.005843 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="wrap", ) 	 25401643 	 1000 	 0.14784526824951172 	 0.08254098892211914 	 2.86102294921875e-05 	 9.107589721679688e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:55.924498 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="clip", ) 	 25401644 	 1000 	 0.05698418617248535 	 0.042798757553100586 	 2.1696090698242188e-05 	 6.723403930664062e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:56.705463 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", ) 	 25401644 	 1000 	 0.14971256256103516 	 0.0716700553894043 	 2.6702880859375e-05 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:48:57.608323 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="clip", ) 	 76204812 	 1000 	 5.444193601608276 	 4.805236339569092 	 2.442220687866211 	 2.4553613662719727 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:49:21.872652 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="wrap", ) 	 76204812 	 1000 	 10.131953954696655 	 5.98980975151062 	 0.9419434070587158 	 1.5321941375732422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:49:50.308406 test begin: paddle.take_along_axis(Tensor([1024, 384],"float32"), Tensor([1024, 24807],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 384],"float32"), Tensor([1024, 24807],"int64"), axis=-1, ) 	 25795584 	 1000 	 0.5836589336395264 	 0.2434248924255371 	 0.1977527141571045 	 0.22376418113708496 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:49:55.088467 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 24807],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 24807],"int64"), axis=-1, ) 	 76206080 	 1000 	 1.0036828517913818 	 0.4402439594268799 	 0.3419008255004883 	 0.42153072357177734 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:00.912073 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 7],"int64"), axis=-1, ) 	 50810880 	 1000 	 0.3055379390716553 	 0.01682877540588379 	 0.10388636589050293 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:02.510940 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 8],"int64"), axis=-1, ) 	 50811904 	 1000 	 0.30652403831481934 	 0.02925276756286621 	 0.10386419296264648 	 5.745887756347656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:04.215849 test begin: paddle.take_along_axis(Tensor([1051, 63, 768],"float32"), axis=1, indices=Tensor([1051, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1051, 63, 768],"float32"), axis=1, indices=Tensor([1051, 7, 768],"int64"), ) 	 56501760 	 1000 	 0.5606551170349121 	 0.3074371814727783 	 0.18828034400939941 	 0.28058624267578125 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:10.584288 test begin: paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 7],"int64"), axis=-1, ) 	 51729691 	 1000 	 0.3765139579772949 	 0.05713200569152832 	 0.12430644035339355 	 0.04014873504638672 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:12.523532 test begin: paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 8],"int64"), axis=-1, ) 	 51861992 	 1000 	 0.3715846538543701 	 0.06252145767211914 	 0.1265730857849121 	 0.032752037048339844 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:50:14.441820 test begin: paddle.take_along_axis(Tensor([3175201, 384],"float32"), Tensor([3175201, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([3175201, 384],"float32"), Tensor([3175201, 8],"int64"), axis=-1, ) 	 1244678792 	 1000 	 8.847981452941895 	 1.3754372596740723 	 2.935243606567383 	 0.3513636589050293 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:51:03.991508 test begin: paddle.take_along_axis(Tensor([3628801, 384],"float32"), Tensor([3628801, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([3628801, 384],"float32"), Tensor([3628801, 7],"int64"), axis=-1, ) 	 1418861191 	 1000 	 9.94191837310791 	 1.419766902923584 	 3.577951669692993 	 0.3627007007598877 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:01.326386 test begin: paddle.take_along_axis(Tensor([4726, 63, 768],"float32"), axis=1, indices=Tensor([4726, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([4726, 63, 768],"float32"), axis=1, indices=Tensor([4726, 7, 768],"int64"), ) 	 254069760 	 1000 	 2.429358720779419 	 1.381460189819336 	 0.8281552791595459 	 1.3616352081298828 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:14.425713 test begin: paddle.take_along_axis(Tensor([8, 63, 100801],"float32"), axis=1, indices=Tensor([8, 7, 100801],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 100801],"float32"), axis=1, indices=Tensor([8, 7, 100801],"int64"), ) 	 56448560 	 1000 	 0.5715041160583496 	 0.3078799247741699 	 0.19481348991394043 	 0.2822287082672119 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:17.509196 test begin: paddle.take_along_axis(Tensor([8, 63, 453601],"float32"), axis=1, indices=Tensor([8, 7, 453601],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 453601],"float32"), axis=1, indices=Tensor([8, 7, 453601],"int64"), ) 	 254016560 	 1000 	 3.0331900119781494 	 1.5887482166290283 	 1.0340425968170166 	 1.562814474105835 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:34.177018 test begin: paddle.take_along_axis(Tensor([8, 63, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), ) 	 25792512 	 1000 	 0.5995121002197266 	 0.2956218719482422 	 0.204146146774292 	 0.2578098773956299 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:40.757196 test begin: paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), ) 	 76210176 	 1000 	 1.3526840209960938 	 0.9498627185821533 	 0.4609818458557129 	 0.9319961071014404 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:48.061205 test begin: paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 7, 768],"int64"), ) 	 50847744 	 1000 	 0.30768656730651855 	 0.01721787452697754 	 0.10490942001342773 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 18:52:49.712866 test begin: paddle.tan(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29514384269714355 	 0.3002934455871582 	 0.2863736152648926 	 0.2872297763824463 	 0.45137524604797363 	 1.0406181812286377 	 0.39713144302368164 	 0.35451412200927734 	 
2025-07-25 18:52:53.461217 test begin: paddle.tan(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2951066493988037 	 0.2980976104736328 	 0.2862517833709717 	 0.28754734992980957 	 0.45107483863830566 	 1.0404927730560303 	 0.3967773914337158 	 0.35445475578308105 	 
2025-07-25 18:52:57.253378 test begin: paddle.tan(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29509401321411133 	 0.29816699028015137 	 0.28629398345947266 	 0.2875688076019287 	 0.4510316848754883 	 1.0404918193817139 	 0.3974738121032715 	 0.35446691513061523 	 
2025-07-25 18:53:01.028115 test begin: paddle.tanh(Tensor([16, 125, 25500],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([16, 125, 25500],"float32"), ) 	 51000000 	 1000 	 0.29674291610717773 	 0.2992832660675049 	 0.2876298427581787 	 0.28852248191833496 	 0.4511897563934326 	 0.4483623504638672 	 0.38414692878723145 	 0.3820207118988037 	 
2025-07-25 18:53:04.189216 test begin: paddle.tanh(Tensor([16, 64, 49613],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([16, 64, 49613],"float32"), ) 	 50803712 	 1000 	 0.29512524604797363 	 0.2981855869293213 	 0.28589820861816406 	 0.28770017623901367 	 0.44914865493774414 	 0.44670629501342773 	 0.39260292053222656 	 0.3771495819091797 	 
2025-07-25 18:53:07.346833 test begin: paddle.tanh(Tensor([28, 32, 241, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([28, 32, 241, 241],"float32"), ) 	 52040576 	 1000 	 0.30304789543151855 	 0.30539679527282715 	 0.29382896423339844 	 0.2946317195892334 	 0.4601597785949707 	 0.45735669136047363 	 0.40485095977783203 	 0.38244080543518066 	 
2025-07-25 18:53:10.593108 test begin: paddle.tanh(Tensor([32, 64, 25500],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([32, 64, 25500],"float32"), ) 	 52224000 	 1000 	 0.3034493923187256 	 0.30858707427978516 	 0.2942347526550293 	 0.2958981990814209 	 0.4616813659667969 	 0.45897531509399414 	 0.4069344997406006 	 0.3925154209136963 	 
2025-07-25 18:53:13.835609 test begin: paddle.tanh(Tensor([64, 26, 512, 1, 60],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 512, 1, 60],"float32"), ) 	 51118080 	 1000 	 0.2970247268676758 	 0.29993128776550293 	 0.2879006862640381 	 0.2893180847167969 	 0.45186614990234375 	 0.4493448734283447 	 0.3936123847961426 	 0.3786966800689697 	 
2025-07-25 18:53:17.046872 test begin: paddle.tanh(Tensor([64, 26, 512, 2, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 512, 2, 40],"float32"), ) 	 68157440 	 1000 	 0.39450812339782715 	 0.39807629585266113 	 0.38546228408813477 	 0.3874356746673584 	 0.600985050201416 	 0.5976126194000244 	 0.5460116863250732 	 0.5301632881164551 	 
2025-07-25 18:53:21.286441 test begin: paddle.tanh(Tensor([64, 26, 764, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 764, 1, 40],"float32"), ) 	 50851840 	 1000 	 0.2955629825592041 	 0.29846978187561035 	 0.28641366958618164 	 0.28789496421813965 	 0.4494774341583252 	 0.4471120834350586 	 0.39488935470581055 	 0.37842679023742676 	 
2025-07-25 18:53:26.470941 test begin: paddle.tanh(Tensor([64, 39, 512, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 39, 512, 1, 40],"float32"), ) 	 51118080 	 1000 	 0.29704809188842773 	 0.3045487403869629 	 0.2813427448272705 	 0.28287315368652344 	 0.45183515548706055 	 0.449343204498291 	 0.3882129192352295 	 0.38053321838378906 	 
2025-07-25 18:53:30.501722 test begin: paddle.tanh(Tensor([8, 110, 241, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 110, 241, 241],"float32"), ) 	 51111280 	 1000 	 0.2971816062927246 	 0.30142664909362793 	 0.28815197944641113 	 0.28862833976745605 	 0.45194435119628906 	 0.44937968254089355 	 0.3964076042175293 	 0.3818657398223877 	 
2025-07-25 18:53:33.708019 test begin: paddle.tanh(Tensor([8, 32, 241, 824],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 32, 241, 824],"float32"), ) 	 50837504 	 1000 	 0.29543185234069824 	 0.3059499263763428 	 0.2791154384613037 	 0.28154897689819336 	 0.44951939582824707 	 0.44691991806030273 	 0.38567686080932617 	 0.37301135063171387 	 
2025-07-25 18:53:40.633882 test begin: paddle.tanh(Tensor([8, 32, 824, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 32, 824, 241],"float32"), ) 	 50837504 	 1000 	 0.295468807220459 	 0.3069183826446533 	 0.2862997055053711 	 0.28777027130126953 	 0.44944047927856445 	 0.44692206382751465 	 0.39429235458374023 	 0.3801546096801758 	 
2025-07-25 18:53:43.828537 test begin: paddle.tanh(Tensor([96, 26, 512, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([96, 26, 512, 1, 40],"float32"), ) 	 51118080 	 1000 	 0.29704713821411133 	 0.29997706413269043 	 0.2812337875366211 	 0.28306055068969727 	 0.45179176330566406 	 0.4493529796600342 	 0.3879992961883545 	 0.3666400909423828 	 
2025-07-25 18:53:47.069698 test begin: paddle.tensor_split(Tensor([226801, 4, 4, 7],"int64"), list[2,3,], axis=3, )
W0725 18:53:47.804910 140236 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([226801, 4, 4, 7],"int64"), list[2,3,], axis=3, ) 	 25401712 	 1000 	 0.025075674057006836 	 0.007826566696166992 	 8.58306884765625e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:47.944396 test begin: paddle.tensor_split(Tensor([226801, 4, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0725 18:53:48.684289 140240 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([226801, 4, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 25401712 	 1000 	 0.05284476280212402 	 0.014312505722045898 	 3.0279159545898438e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:48.870229 test begin: paddle.tensor_split(Tensor([226801, 4, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0725 18:53:49.596141 140245 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([226801, 4, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 25401712 	 1000 	 0.024989843368530273 	 0.0076978206634521484 	 1.2636184692382812e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:49.721465 test begin: paddle.tensor_split(Tensor([4, 226801, 4, 7],"int64"), list[2,3,], axis=3, )
W0725 18:53:50.452486 140260 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 226801, 4, 7],"int64"), list[2,3,], axis=3, ) 	 25401712 	 1000 	 0.02482748031616211 	 0.007831096649169922 	 7.867813110351562e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:50.577096 test begin: paddle.tensor_split(Tensor([4, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0725 18:53:51.309845 140264 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 25401712 	 1000 	 0.03226780891418457 	 0.009089469909667969 	 1.5974044799804688e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:51.447601 test begin: paddle.tensor_split(Tensor([4, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0725 18:53:52.198344 140273 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 25401712 	 1000 	 0.04048299789428711 	 0.01332998275756836 	 1.049041748046875e-05 	 5.698204040527344e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:52.358981 test begin: paddle.tensor_split(Tensor([4, 4, 226801, 7],"int64"), list[2,3,], axis=3, )
W0725 18:53:53.103193 140274 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 4, 226801, 7],"int64"), list[2,3,], axis=3, ) 	 25401712 	 1000 	 0.04092741012573242 	 0.012663125991821289 	 2.5272369384765625e-05 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:53.244033 test begin: paddle.tensor_split(Tensor([4, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, )
W0725 18:53:53.968362 140284 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, ) 	 25401712 	 1000 	 0.03266310691833496 	 0.009020328521728516 	 1.9550323486328125e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:54.115436 test begin: paddle.tensor_split(Tensor([4, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, )
W0725 18:53:54.829119 140288 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, ) 	 25401712 	 1000 	 0.025267362594604492 	 0.0078122615814208984 	 2.0742416381835938e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:54.959036 test begin: paddle.tensor_split(Tensor([4, 4, 4, 396901],"int64"), list[2,3,], axis=3, )
W0725 18:53:55.676362 140297 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 4, 4, 396901],"int64"), list[2,3,], axis=3, ) 	 25401664 	 1000 	 0.025571823120117188 	 0.012655973434448242 	 0.00011301040649414062 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:55.811225 test begin: paddle.tensor_split(Tensor([4, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, )
W0725 18:53:56.547501 140313 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, ) 	 25401664 	 1000 	 0.03328275680541992 	 0.008917570114135742 	 2.8371810913085938e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:56.672082 test begin: paddle.tensor_split(Tensor([4, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, )
W0725 18:53:57.396891 140320 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([4, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, ) 	 25401664 	 1000 	 0.02500295639038086 	 0.007669210433959961 	 8.58306884765625e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 18:53:57.523780 test begin: paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[0,], ) 	 101606500 	 1000 	 1.0817546844482422 	 0.8448336124420166 	 0.3683888912200928 	 0.43161702156066895 	 1.5928137302398682 	 1.5980074405670166 	 0.8138084411621094 	 0.8164074420928955 	 
2025-07-25 18:54:04.505359 test begin: paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[3,0,], ) 	 101606500 	 1000 	 1.161461353302002 	 3.550874948501587 	 0.29648661613464355 	 0.9058842658996582 	 0.8009052276611328 	 0.7951290607452393 	 0.20459818840026855 	 0.20299386978149414 	 
2025-07-25 18:54:12.522642 test begin: paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.105289936065674 	 4.1297852993011475 	 0.47350549697875977 	 0.4218111038208008 	 11.544250011444092 	 10.653467893600464 	 0.909334659576416 	 0.906571626663208 	 
2025-07-25 18:55:05.767000 test begin: paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 1.4223287105560303 	 0.7261581420898438 	 0.3630216121673584 	 0.18546628952026367 	 0.785966157913208 	 0.7842669486999512 	 0.20070791244506836 	 0.20026230812072754 	 
2025-07-25 18:55:11.114452 test begin: paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.104919195175171 	 4.13945460319519 	 0.4735567569732666 	 0.42178797721862793 	 11.530591487884521 	 10.651909112930298 	 0.9076540470123291 	 0.9064221382141113 	 
2025-07-25 18:56:04.264657 test begin: paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 1.4223802089691162 	 0.7260191440582275 	 0.3630554676055908 	 0.1854259967803955 	 0.7859029769897461 	 0.7842202186584473 	 0.20075774192810059 	 0.2002406120300293 	 
2025-07-25 18:56:09.623626 test begin: paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[3,0,], ) 	 101606500 	 1000 	 2.094625949859619 	 2.51906156539917 	 0.5345346927642822 	 0.6427779197692871 	 0.800891637802124 	 0.7950241565704346 	 0.20455002784729004 	 0.20301556587219238 	 
2025-07-25 18:56:17.586815 test begin: paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.1056578159332275 	 4.128520488739014 	 0.4734838008880615 	 0.421720027923584 	 11.543201208114624 	 10.651156425476074 	 0.9088585376739502 	 0.9062292575836182 	 
2025-07-25 18:57:10.962990 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 4.593115568161011 	 4.550384044647217 	 0.4266996383666992 	 0.46493959426879883 	 12.361329078674316 	 12.231924533843994 	 0.06680107116699219 	 0.07194209098815918 	 
2025-07-25 18:58:06.644303 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 0.8635039329528809 	 1.2755045890808105 	 0.22051215171813965 	 0.3253202438354492 	 0.7965264320373535 	 0.7972226142883301 	 0.20345544815063477 	 0.20357346534729004 	 
2025-07-25 18:58:12.075166 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 4.592149496078491 	 4.550494432449341 	 0.42664003372192383 	 0.464890718460083 	 12.361568450927734 	 12.23162317276001 	 0.06684112548828125 	 0.0719597339630127 	 
2025-07-25 18:59:07.270424 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 0.863408088684082 	 1.2745795249938965 	 0.22048640251159668 	 0.32535219192504883 	 0.7965641021728516 	 0.7971193790435791 	 0.20346641540527344 	 0.20357966423034668 	 
2025-07-25 18:59:12.676620 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[0,], ) 	 50803875 	 1000 	 4.5929248332977295 	 4.550170660018921 	 0.42673301696777344 	 0.46482300758361816 	 12.361998319625854 	 12.232027053833008 	 0.06687664985656738 	 0.07194352149963379 	 
2025-07-25 19:00:08.146610 test begin: paddle.tensordot(x=Tensor([4, 105841, 3, 5, 4],"float64"), y=Tensor([105841, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 105841, 3, 5, 4],"float64"), y=Tensor([105841, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205520 	 1000 	 1.681023120880127 	 1.3658671379089355 	 0.42937159538269043 	 0.46430444717407227 	 3.3506124019622803 	 3.418799877166748 	 0.24454307556152344 	 0.2494978904724121 	 
2025-07-25 19:00:19.704193 test begin: paddle.tensordot(x=Tensor([4, 2, 158761, 5, 4],"float64"), y=Tensor([2, 4, 158761, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 158761, 5, 4],"float64"), y=Tensor([2, 4, 158761, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205280 	 1000 	 1.669935941696167 	 1.3548367023468018 	 0.42656683921813965 	 0.4609029293060303 	 3.329824209213257 	 3.418323278427124 	 0.24303746223449707 	 0.24948596954345703 	 
2025-07-25 19:00:31.212051 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 132301, 4],"float64"), y=Tensor([2, 4, 3, 132301, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 132301, 4],"float64"), y=Tensor([2, 4, 3, 132301, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38102688 	 1000 	 0.839970588684082 	 0.6925644874572754 	 0.214552640914917 	 0.23576569557189941 	 1.6714212894439697 	 1.7153337001800537 	 0.21343493461608887 	 0.2189311981201172 	 
2025-07-25 19:00:39.418146 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 264601, 4],"float64"), y=Tensor([2, 4, 3, 264601, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 264601, 4],"float64"), y=Tensor([2, 4, 3, 264601, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205088 	 1000 	 1.6719672679901123 	 1.3568415641784668 	 0.4270823001861572 	 0.46198487281799316 	 3.3321943283081055 	 3.4187369346618652 	 0.24319863319396973 	 0.24948430061340332 	 
2025-07-25 19:00:50.901151 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 5, 211681],"float64"), y=Tensor([2, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 5, 211681],"float64"), y=Tensor([2, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 25402680 	 1000 	 0.5310394763946533 	 0.2005629539489746 	 0.1809241771697998 	 0.10216784477233887 	 0.3526766300201416 	 0.377518892288208 	 0.12000894546508789 	 0.12840795516967773 	 
2025-07-25 19:00:52.941786 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 5, 4],"float64"), y=Tensor([2, 4, 3, 5, 211681],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 5, 4],"float64"), y=Tensor([2, 4, 3, 5, 211681],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 25402200 	 1000 	 0.48958635330200195 	 0.48848748207092285 	 0.16658854484558105 	 0.24946928024291992 	 0.3841288089752197 	 0.370647668838501 	 0.1306769847869873 	 0.12608551979064941 	 
2025-07-25 19:00:55.303884 test begin: paddle.tensordot(x=Tensor([4, 2, 79381, 5, 4],"float64"), y=Tensor([2, 4, 79381, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 79381, 5, 4],"float64"), y=Tensor([2, 4, 79381, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38102880 	 1000 	 0.8410813808441162 	 0.6924917697906494 	 0.2148301601409912 	 0.2357316017150879 	 1.6696281433105469 	 1.7151541709899902 	 0.2131943702697754 	 0.21890974044799805 	 
2025-07-25 19:01:01.046430 test begin: paddle.tensordot(x=Tensor([4, 52921, 3, 5, 4],"float64"), y=Tensor([52921, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 52921, 3, 5, 4],"float64"), y=Tensor([52921, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38103120 	 1000 	 0.8489842414855957 	 0.6959617137908936 	 0.21682333946228027 	 0.23692560195922852 	 1.682941198348999 	 1.7151446342468262 	 0.2148895263671875 	 0.21893978118896484 	 
2025-07-25 19:01:07.388989 test begin: paddle.tile(Tensor([102426, 248, 1, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([102426, 248, 1, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50803296 	 1000 	 0.296252965927124 	 0.31577396392822266 	 0.2767775058746338 	 0.1599893569946289 	 0.3132157325744629 	 0.05935239791870117 	 0.1599886417388916 	 5.817413330078125e-05 	 
2025-07-25 19:01:10.143164 test begin: paddle.tile(Tensor([1511, 10, 1, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([1511, 10, 1, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 50830040 	 1000 	 1.96864652633667 	 0.9378824234008789 	 1.0059263706207275 	 0.9138739109039307 	 1.8874609470367432 	 0.7313013076782227 	 1.8312296867370605 	 0.6554663181304932 	 
2025-07-25 19:01:19.888566 test begin: paddle.tile(Tensor([16, 1, 1, 3, 16538, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 3, 16538, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50804736 	 1000 	 6.064704418182373 	 2.7540323734283447 	 3.0991289615631104 	 1.4032254219055176 	 3.3643600940704346 	 1.7348501682281494 	 3.2987265586853027 	 0.8864700794219971 	 
2025-07-25 19:01:45.079315 test begin: paddle.tile(Tensor([16, 1, 1, 3, 64, 16538],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 3, 64, 16538],"float32"), list[1,11,1,1,1,1,], ) 	 50804736 	 1000 	 6.067470073699951 	 2.746544599533081 	 3.0988714694976807 	 1.4031798839569092 	 3.3644750118255615 	 1.7348389625549316 	 3.308338165283203 	 0.8864529132843018 	 
2025-07-25 19:02:09.376349 test begin: paddle.tile(Tensor([16, 1, 1, 776, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 776, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50855936 	 1000 	 6.109223365783691 	 2.7533037662506104 	 3.1415116786956787 	 1.4066431522369385 	 3.364060401916504 	 1.7358386516571045 	 3.2971019744873047 	 0.8869092464447021 	 
2025-07-25 19:02:33.801688 test begin: paddle.tile(Tensor([16, 1, 259, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 259, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50921472 	 1000 	 6.077529191970825 	 2.7599472999572754 	 3.1054141521453857 	 1.4100251197814941 	 3.36504864692688 	 1.7381548881530762 	 3.2993078231811523 	 0.8881442546844482 	 
2025-07-25 19:02:58.152171 test begin: paddle.tile(Tensor([16, 10, 1, 5475, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 1, 5475, 58],"float32"), list[1,1,4,1,1,], ) 	 50808000 	 1000 	 1.9303646087646484 	 0.8692302703857422 	 0.9864323139190674 	 0.8350145816802979 	 1.8878929615020752 	 0.7453970909118652 	 1.8177344799041748 	 0.6613566875457764 	 
2025-07-25 19:03:07.801573 test begin: paddle.tile(Tensor([16, 10, 1, 58, 5475],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 1, 58, 5475],"float32"), list[1,1,4,1,1,], ) 	 50808000 	 1000 	 1.9302716255187988 	 0.8663058280944824 	 0.9863619804382324 	 0.8439130783081055 	 1.8875718116760254 	 0.7454636096954346 	 1.8309221267700195 	 0.6712827682495117 	 
2025-07-25 19:03:17.400820 test begin: paddle.tile(Tensor([16, 10, 95, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 95, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 51132800 	 1000 	 1.941253662109375 	 0.8798661231994629 	 0.9919826984405518 	 0.848630428314209 	 1.899202823638916 	 0.7385604381561279 	 1.8425393104553223 	 0.664278507232666 	 
2025-07-25 19:03:27.560430 test begin: paddle.tile(Tensor([16, 259, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 259, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50921472 	 1000 	 6.077370882034302 	 2.760105609893799 	 3.1055142879486084 	 1.410060167312622 	 3.364983081817627 	 1.7381911277770996 	 3.30768084526062 	 0.8881435394287109 	 
2025-07-25 19:03:51.922770 test begin: paddle.tile(Tensor([16, 944, 1, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 944, 1, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 50809856 	 1000 	 1.9663722515106201 	 0.9364168643951416 	 1.004730463027954 	 0.9141712188720703 	 1.8869960308074951 	 0.7310662269592285 	 1.827622890472412 	 0.655998945236206 	 
2025-07-25 19:04:01.758599 test begin: paddle.tile(Tensor([216, 117601, 1, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 117601, 1, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50803632 	 1000 	 0.29607391357421875 	 0.3132598400115967 	 0.28391051292419434 	 0.15995478630065918 	 0.3147547245025635 	 0.06166982650756836 	 0.16078686714172363 	 6.747245788574219e-05 	 
2025-07-25 19:04:04.410291 test begin: paddle.tile(Tensor([216, 248, 1, 1, 949],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 1, 1, 949],"float32"), list[1,1,1,1,1,], ) 	 50836032 	 1000 	 0.29630374908447266 	 0.31401610374450684 	 0.2842371463775635 	 0.15996599197387695 	 0.3159675598144531 	 0.05416536331176758 	 0.1613941192626953 	 3.62396240234375e-05 	 
2025-07-25 19:04:07.061989 test begin: paddle.tile(Tensor([216, 248, 1, 475, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 1, 475, 2],"float32"), list[1,1,1,1,1,], ) 	 50889600 	 1000 	 0.2967195510864258 	 0.31612229347229004 	 0.28458166122436523 	 0.16036009788513184 	 0.3152194023132324 	 0.05474543571472168 	 0.1610100269317627 	 4.8160552978515625e-05 	 
2025-07-25 19:04:09.705816 test begin: paddle.tile(Tensor([216, 248, 475, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 475, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50889600 	 1000 	 0.29669690132141113 	 0.3140220642089844 	 0.27712345123291016 	 0.16036176681518555 	 0.3152039051055908 	 0.061334848403930664 	 0.16100239753723145 	 6.985664367675781e-05 	 
2025-07-25 19:04:12.430666 test begin: paddle.tile(Tensor([4135, 1, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([4135, 1, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50810880 	 1000 	 5.002527713775635 	 2.4673171043395996 	 2.556267023086548 	 1.2566804885864258 	 3.3548285961151123 	 1.7478141784667969 	 3.289332389831543 	 0.8930320739746094 	 
2025-07-25 19:04:37.562120 test begin: paddle.tolist(Tensor([10160, 5],"float32"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([10160, 5],"float32"), ) 	 50800 	 1000 	 9.564195156097412 	 13.57134485244751 	 9.107589721679688e-05 	 0.00011444091796875 	 None 	 None 	 None 	 None 	 
2025-07-25 19:05:00.712222 test begin: paddle.tolist(Tensor([2, 1270],"int64"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([2, 1270],"int64"), ) 	 2540 	 1000 	 0.07487130165100098 	 0.08776021003723145 	 2.09808349609375e-05 	 4.2438507080078125e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:05:00.880388 test begin: paddle.tolist(Tensor([2, 25400],"float32"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([2, 25400],"float32"), ) 	 50800 	 1000 	 0.9317054748535156 	 1.0801191329956055 	 5.221366882324219e-05 	 8.749961853027344e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:05:02.900482 test begin: paddle.tolist(Tensor([8467, 3],"int64"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([8467, 3],"int64"), ) 	 25401 	 1000 	 5.563570976257324 	 9.697920322418213 	 7.748603820800781e-05 	 0.00011134147644042969 	 None 	 None 	 None 	 None 	 
2025-07-25 19:05:18.169360 test begin: paddle.topk(Tensor([138, 369303],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([138, 369303],"float32"), k=1, axis=0, ) 	 50963814 	 1000 	 2.4051945209503174 	 8.684943437576294 	 0.6133773326873779 	 8.642064332962036 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:05:42.217075 test begin: paddle.topk(Tensor([146, 349866],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([146, 349866],"float32"), k=1, axis=0, ) 	 51080436 	 1000 	 2.3430418968200684 	 10.802979707717896 	 0.5976150035858154 	 10.781399250030518 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:06:06.945128 test begin: paddle.topk(Tensor([148, 343728],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([148, 343728],"float32"), k=1, axis=0, ) 	 50871744 	 1000 	 2.117347478866577 	 9.308505058288574 	 0.5399291515350342 	 9.28394365310669 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:06:29.856248 test begin: paddle.topk(Tensor([49, 1036801],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([49, 1036801],"float32"), k=1, axis=0, ) 	 50803249 	 1000 	 2.2037160396575928 	 4.604071855545044 	 0.5618159770965576 	 4.140231132507324 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:06:50.118200 test begin: paddle.topk(Tensor([53, 958551],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([53, 958551],"float32"), k=1, axis=0, ) 	 50803203 	 1000 	 2.2007248401641846 	 4.268040657043457 	 0.5610175132751465 	 4.253406286239624 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:07:08.491202 test begin: paddle.topk(Tensor([55, 923695],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([55, 923695],"float32"), k=1, axis=0, ) 	 50803225 	 1000 	 2.183634042739868 	 4.510469913482666 	 0.5571300983428955 	 4.495879650115967 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:07:27.181770 test begin: paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.24241852760314941 	 0.08068442344665527 	 9.417533874511719e-05 	 0.05606436729431152 	 0.7624914646148682 	 0.24064207077026367 	 3.838539123535156e-05 	 0.12282896041870117 	 combined
2025-07-25 19:07:29.167978 test begin: paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401606 	 1000 	 0.06464099884033203 	 0.02008199691772461 	 4.291534423828125e-05 	 3.24249267578125e-05 	 0.7609841823577881 	 0.13852715492248535 	 2.8371810913085938e-05 	 0.053614139556884766 	 combined
2025-07-25 19:07:30.736837 test begin: paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401604 	 1000 	 0.06548476219177246 	 0.02549266815185547 	 3.719329833984375e-05 	 5.364418029785156e-05 	 0.7753622531890869 	 0.13843202590942383 	 3.8623809814453125e-05 	 0.05074667930603027 	 combined
2025-07-25 19:07:32.355292 test begin: paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401604 	 1000 	 0.2386021614074707 	 0.12119841575622559 	 7.724761962890625e-05 	 0.09600687026977539 	 0.7837002277374268 	 0.3345608711242676 	 2.9325485229492188e-05 	 0.17098069190979004 	 combined
2025-07-25 19:07:34.520038 test begin: paddle.trace(x=Tensor([3, 8467201],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([3, 8467201],"float64"), offset=0, axis1=0, axis2=1, ) 	 25401603 	 1000 	 0.06512117385864258 	 0.03020763397216797 	 2.0265579223632812e-05 	 6.771087646484375e-05 	 0.5963230133056641 	 0.13835930824279785 	 2.9087066650390625e-05 	 0.03188157081604004 	 combined
2025-07-25 19:07:37.970727 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.0654139518737793 	 0.02167367935180664 	 3.719329833984375e-05 	 5.91278076171875e-05 	 0.7577621936798096 	 0.1386551856994629 	 4.1961669921875e-05 	 0.051981449127197266 	 combined
2025-07-25 19:07:39.549104 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401606 	 1000 	 0.07544946670532227 	 0.030170679092407227 	 3.266334533691406e-05 	 4.291534423828125e-05 	 0.7778511047363281 	 0.14181113243103027 	 5.793571472167969e-05 	 0.02898383140563965 	 combined
2025-07-25 19:07:41.166403 test begin: paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, ) 	 25401604 	 1000 	 0.06497335433959961 	 0.019802093505859375 	 2.0742416381835938e-05 	 5.030632019042969e-05 	 0.6005773544311523 	 0.13832378387451172 	 3.647804260253906e-05 	 0.05621194839477539 	 combined
2025-07-25 19:07:42.581249 test begin: paddle.transpose(Tensor([2, 150, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([2, 150, 512, 512],"float32"), list[0,2,3,1,], ) 	 78643200 	 1000 	 0.003612995147705078 	 0.004572629928588867 	 8.344650268554688e-06 	 1.811981201171875e-05 	 0.04064583778381348 	 0.05703568458557129 	 2.2172927856445312e-05 	 3.4809112548828125e-05 	 
2025-07-25 19:07:45.288020 test begin: paddle.transpose(Tensor([2, 7168, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([2, 7168, 7168],"bfloat16"), list[0,2,1,], ) 	 102760448 	 1000 	 0.0035085678100585938 	 0.004397392272949219 	 8.821487426757812e-06 	 1.9788742065429688e-05 	 0.045440673828125 	 0.45880866050720215 	 3.790855407714844e-05 	 0.3759164810180664 	 
2025-07-25 19:07:50.718660 test begin: paddle.transpose(Tensor([4, 150, 166, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([4, 150, 166, 512],"float32"), list[0,2,3,1,], ) 	 50995200 	 1000 	 0.0035479068756103516 	 0.00456690788269043 	 5.9604644775390625e-06 	 1.9311904907226562e-05 	 0.04071664810180664 	 0.05668163299560547 	 3.361701965332031e-05 	 4.863739013671875e-05 	 
2025-07-25 19:07:52.562703 test begin: paddle.transpose(Tensor([4, 150, 512, 166],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([4, 150, 512, 166],"float32"), list[0,2,3,1,], ) 	 50995200 	 1000 	 0.008133411407470703 	 0.008350849151611328 	 3.0040740966796875e-05 	 2.47955322265625e-05 	 0.048888206481933594 	 0.05797243118286133 	 4.4345855712890625e-05 	 6.270408630371094e-05 	 
2025-07-25 19:07:54.440358 test begin: paddle.transpose(Tensor([4, 3584, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([4, 3584, 7168],"bfloat16"), list[0,2,1,], ) 	 102760448 	 1000 	 0.007483482360839844 	 0.008188247680664062 	 9.775161743164062e-06 	 2.1696090698242188e-05 	 0.053781986236572266 	 0.4587385654449463 	 3.218650817871094e-05 	 0.37122535705566406 	 
2025-07-25 19:07:58.359045 test begin: paddle.transpose(Tensor([4, 49, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([4, 49, 512, 512],"float32"), list[0,2,3,1,], ) 	 51380224 	 1000 	 0.0036056041717529297 	 0.004560708999633789 	 8.58306884765625e-06 	 1.71661376953125e-05 	 0.04143238067626953 	 0.06357693672180176 	 2.09808349609375e-05 	 5.269050598144531e-05 	 
2025-07-25 19:08:00.194367 test begin: paddle.transpose(Tensor([6, 2363, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([6, 2363, 7168],"bfloat16"), list[0,2,1,], ) 	 101627904 	 1000 	 0.003541707992553711 	 0.004506111145019531 	 7.152557373046875e-06 	 2.0503997802734375e-05 	 0.04841876029968262 	 0.4537968635559082 	 3.4809112548828125e-05 	 0.3725006580352783 	 
2025-07-25 19:08:04.011962 test begin: paddle.transpose(Tensor([6, 3584, 4726],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([6, 3584, 4726],"bfloat16"), list[0,2,1,], ) 	 101627904 	 1000 	 0.0035169124603271484 	 0.0045588016510009766 	 7.62939453125e-06 	 2.0265579223632812e-05 	 0.05155062675476074 	 0.4537923336029053 	 3.0994415283203125e-05 	 0.3701972961425781 	 
2025-07-25 19:08:07.979872 test begin: paddle.transpose(Tensor([6, 7168, 2363],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([6, 7168, 2363],"bfloat16"), list[0,2,1,], ) 	 101627904 	 1000 	 0.0035142898559570312 	 0.004442691802978516 	 6.67572021484375e-06 	 1.9311904907226562e-05 	 0.045897483825683594 	 0.45382142066955566 	 2.09808349609375e-05 	 0.353466272354126 	 
2025-07-25 19:08:11.821403 test begin: paddle.tril(Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.3082761764526367 	 0.2591536045074463 	 0.2998499870300293 	 0.247833251953125 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:08:14.185461 test begin: paddle.tril(Tensor([1, 1, 2048, 24807],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 2048, 24807],"float32"), ) 	 50804736 	 1000 	 0.31113624572753906 	 0.3331630229949951 	 0.30277442932128906 	 0.3186042308807373 	 0.3112156391143799 	 0.33304500579833984 	 0.26088905334472656 	 0.25760865211486816 	 
2025-07-25 19:08:17.173557 test begin: paddle.tril(Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.37814950942993164 	 0.2354564666748047 	 0.36925435066223145 	 0.21053624153137207 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:08:19.642960 test begin: paddle.tril(Tensor([1, 1, 24807, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 24807, 2048],"float32"), ) 	 50804736 	 1000 	 0.4162724018096924 	 0.3764069080352783 	 0.4074831008911133 	 0.3653907775878906 	 0.4161198139190674 	 0.37629270553588867 	 0.3634967803955078 	 0.3009471893310547 	 
2025-07-25 19:08:22.931396 test begin: paddle.tril(Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 13, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.3847239017486572 	 0.2509760856628418 	 0.37644457817077637 	 0.24001574516296387 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:08:25.497369 test begin: paddle.tril(Tensor([1, 13, 2048, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 13, 2048, 2048],"float32"), ) 	 54525952 	 1000 	 0.41629695892333984 	 0.3861410617828369 	 0.40781545639038086 	 0.370464563369751 	 0.4164438247680664 	 0.38141536712646484 	 0.366269588470459 	 0.3062934875488281 	 
2025-07-25 19:08:28.879035 test begin: paddle.tril(Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([13, 1, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.38474035263061523 	 0.25106239318847656 	 0.3763234615325928 	 0.24015402793884277 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:08:31.459707 test begin: paddle.tril(Tensor([13, 1, 2048, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([13, 1, 2048, 2048],"float32"), ) 	 54525952 	 1000 	 0.41626882553100586 	 0.3875007629394531 	 0.40134239196777344 	 0.364391565322876 	 0.4164395332336426 	 0.3816792964935303 	 0.3577156066894531 	 0.3009936809539795 	 
2025-07-25 19:08:34.869892 test begin: paddle.tril(Tensor([2048, 24807],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.3082597255706787 	 0.2618703842163086 	 0.2998533248901367 	 0.24706578254699707 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:08:39.406117 test begin: paddle.tril(Tensor([24807, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.37816810607910156 	 0.2361011505126953 	 0.3698263168334961 	 0.22503113746643066 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:08:41.860871 test begin: paddle.triu(Tensor([1, 1, 1024, 99226],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 1024, 99226],"float16"), diagonal=1, ) 	 101607424 	 1000 	 0.7793478965759277 	 0.5284340381622314 	 0.7639782428741455 	 0.5087263584136963 	 0.7788362503051758 	 0.5266094207763672 	 0.6975674629211426 	 0.45366907119750977 	 
2025-07-25 19:08:48.351460 test begin: paddle.triu(Tensor([1, 1, 12404, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 12404, 4096],"float32"), diagonal=1, ) 	 50806784 	 1000 	 0.32557225227355957 	 0.34906506538391113 	 0.3094656467437744 	 0.32135939598083496 	 0.3256809711456299 	 0.3390653133392334 	 0.2631261348724365 	 0.2659285068511963 	 
2025-07-25 19:08:53.126850 test begin: paddle.triu(Tensor([1, 1, 2048, 49613],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 2048, 49613],"float16"), ) 	 101607424 	 1000 	 0.7789654731750488 	 0.5250697135925293 	 0.7637851238250732 	 0.5075948238372803 	 0.7784056663513184 	 0.5249273777008057 	 0.7180204391479492 	 0.454437255859375 	 
2025-07-25 19:08:59.630435 test begin: paddle.triu(Tensor([1, 1, 4096, 12404],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 4096, 12404],"float32"), diagonal=1, ) 	 50806784 	 1000 	 0.41209936141967773 	 0.3717014789581299 	 0.4033653736114502 	 0.36029052734375 	 0.412095308303833 	 0.37131452560424805 	 0.352431058883667 	 0.3056600093841553 	 
2025-07-25 19:09:02.891179 test begin: paddle.triu(Tensor([1, 1, 49613, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 49613, 2048],"float16"), ) 	 101607424 	 1000 	 0.5893175601959229 	 0.3693082332611084 	 0.5807983875274658 	 0.3548903465270996 	 0.5894856452941895 	 0.36606907844543457 	 0.5389552116394043 	 0.296673059463501 	 
2025-07-25 19:09:08.750176 test begin: paddle.triu(Tensor([1, 1, 99226, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 99226, 1024],"float16"), diagonal=1, ) 	 101607424 	 1000 	 0.585458517074585 	 0.3803524971008301 	 0.5766510963439941 	 0.35356807708740234 	 0.5855212211608887 	 0.36522912979125977 	 0.5338516235351562 	 0.2987782955169678 	 
2025-07-25 19:09:14.496213 test begin: paddle.triu(Tensor([1, 25, 2048, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 25, 2048, 2048],"float16"), ) 	 104857600 	 1000 	 0.7461543083190918 	 0.4377627372741699 	 0.7291505336761475 	 0.4203176498413086 	 0.7483625411987305 	 0.4369628429412842 	 0.6894493103027344 	 0.34908127784729004 	 
2025-07-25 19:09:20.994521 test begin: paddle.triu(Tensor([1, 4, 4096, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 4, 4096, 4096],"float32"), diagonal=1, ) 	 67108864 	 1000 	 0.4975621700286865 	 0.46860265731811523 	 0.4887981414794922 	 0.4565868377685547 	 0.4978609085083008 	 0.4679412841796875 	 0.44382452964782715 	 0.39802098274230957 	 
2025-07-25 19:09:25.225642 test begin: paddle.triu(Tensor([1, 97, 1024, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 97, 1024, 1024],"float16"), diagonal=1, ) 	 101711872 	 1000 	 0.7437560558319092 	 0.4266929626464844 	 0.7349350452423096 	 0.4153285026550293 	 0.7438759803771973 	 0.42619800567626953 	 0.6860172748565674 	 0.3572807312011719 	 
2025-07-25 19:09:31.499897 test begin: paddle.triu(Tensor([25, 1, 2048, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([25, 1, 2048, 2048],"float16"), ) 	 104857600 	 1000 	 0.7461812496185303 	 0.450286865234375 	 0.7376708984375 	 0.4263632297515869 	 0.7483794689178467 	 0.43697071075439453 	 0.6969740390777588 	 0.36666083335876465 	 
2025-07-25 19:09:40.037313 test begin: paddle.triu(Tensor([4, 1, 4096, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([4, 1, 4096, 4096],"float32"), diagonal=1, ) 	 67108864 	 1000 	 0.49759554862976074 	 0.4707679748535156 	 0.4876413345336914 	 0.45694971084594727 	 0.49788451194763184 	 0.46814727783203125 	 0.44132304191589355 	 0.4018566608428955 	 
2025-07-25 19:09:44.199363 test begin: paddle.triu(Tensor([97, 1, 1024, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([97, 1, 1024, 1024],"float16"), diagonal=1, ) 	 101711872 	 1000 	 0.7438006401062012 	 0.4267616271972656 	 0.7350559234619141 	 0.41536664962768555 	 0.7438697814941406 	 0.42636919021606445 	 0.6935715675354004 	 0.36118531227111816 	 
2025-07-25 19:09:50.396666 test begin: paddle.trunc(Tensor([20, 2540161],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([20, 2540161],"float32"), ) 	 50803220 	 1000 	 0.00820612907409668 	 0.2979888916015625 	 1.1444091796875e-05 	 0.2873806953430176 	 0.050871849060058594 	 0.13434910774230957 	 2.6941299438476562e-05 	 0.06993699073791504 	 
2025-07-25 19:09:52.820732 test begin: paddle.trunc(Tensor([2540161, 20],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.008117914199829102 	 0.29793286323547363 	 8.344650268554688e-06 	 0.2873048782348633 	 0.05053257942199707 	 0.13423943519592285 	 2.8848648071289062e-05 	 0.06936764717102051 	 
2025-07-25 19:09:55.184480 test begin: paddle.trunc(input=Tensor([117601, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([117601, 6, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.008840084075927734 	 0.7603118419647217 	 2.6702880859375e-05 	 0.28720641136169434 	 0.050695180892944336 	 0.1347818374633789 	 2.9087066650390625e-05 	 0.0686490535736084 	 
2025-07-25 19:09:58.798910 test begin: paddle.trunc(input=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 25402896 	 1000 	 0.008553504943847656 	 0.5401103496551514 	 1.5020370483398438e-05 	 0.2872748374938965 	 0.06523776054382324 	 0.13466691970825195 	 5.030632019042969e-05 	 0.06369328498840332 	 
2025-07-25 19:10:01.397148 test begin: paddle.trunc(input=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 25402248 	 1000 	 0.008601665496826172 	 0.29848814010620117 	 1.5020370483398438e-05 	 0.287977933883667 	 0.0506441593170166 	 0.1346292495727539 	 3.409385681152344e-05 	 0.06424736976623535 	 
2025-07-25 19:10:03.063407 test begin: paddle.trunc(input=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 25402248 	 1000 	 0.015508890151977539 	 0.29845714569091797 	 2.2649765014648438e-05 	 0.2815067768096924 	 0.059659481048583984 	 0.1345837116241455 	 3.337860107421875e-05 	 0.061353206634521484 	 
2025-07-25 19:10:04.712020 test begin: paddle.trunc(input=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 25402248 	 1000 	 0.015433073043823242 	 0.2984597682952881 	 1.0013580322265625e-05 	 0.28157758712768555 	 0.05929899215698242 	 0.1345653533935547 	 1.9788742065429688e-05 	 0.0585169792175293 	 
2025-07-25 19:10:06.372859 test begin: paddle.trunc(input=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 25402248 	 1000 	 0.016106128692626953 	 0.29837989807128906 	 3.1948089599609375e-05 	 0.28141307830810547 	 0.060347557067871094 	 0.13463664054870605 	 3.24249267578125e-05 	 0.05907464027404785 	 
2025-07-25 19:10:08.053949 test begin: paddle.trunc(input=Tensor([6, 117601, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([6, 117601, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.015333175659179688 	 0.2985372543334961 	 1.0251998901367188e-05 	 0.2816751003265381 	 0.06150388717651367 	 0.13461041450500488 	 3.1948089599609375e-05 	 0.06083226203918457 	 
2025-07-25 19:10:09.698893 test begin: paddle.trunc(input=Tensor([6, 6, 117601, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([6, 6, 117601, 6],"float64"), ) 	 25401816 	 1000 	 0.01552891731262207 	 0.3020472526550293 	 1.0967254638671875e-05 	 0.2813999652862549 	 0.06151223182678223 	 0.13468599319458008 	 3.504753112792969e-05 	 0.05884814262390137 	 
2025-07-25 19:10:11.361262 test begin: paddle.trunc(input=Tensor([6, 6, 6, 117601],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([6, 6, 6, 117601],"float64"), ) 	 25401816 	 1000 	 0.015518665313720703 	 0.29841089248657227 	 1.3828277587890625e-05 	 0.2877843379974365 	 0.08173227310180664 	 0.13462114334106445 	 8.630752563476562e-05 	 0.06851053237915039 	 
2025-07-25 19:10:13.034906 test begin: paddle.unbind(Tensor([2, 3, 1058401, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([2, 3, 1058401, 8],"float32"), axis=0, ) 	 50803248 	 1000 	 0.012665271759033203 	 0.009452104568481445 	 1.049041748046875e-05 	 2.193450927734375e-05 	 0.3512403964996338 	 0.3101191520690918 	 0.287398099899292 	 0.22398042678833008 	 
2025-07-25 19:10:15.429751 test begin: paddle.unbind(Tensor([2, 3, 8, 1058401],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([2, 3, 8, 1058401],"float32"), axis=0, ) 	 50803248 	 1000 	 0.015252113342285156 	 0.009705543518066406 	 3.743171691894531e-05 	 5.4836273193359375e-05 	 0.3512609004974365 	 0.3100311756134033 	 0.2829127311706543 	 0.2176513671875 	 
2025-07-25 19:10:17.898053 test begin: paddle.unbind(Tensor([2, 396901, 8, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([2, 396901, 8, 8],"float32"), axis=0, ) 	 50803328 	 1000 	 0.007106304168701172 	 0.005550861358642578 	 8.58306884765625e-06 	 5.817413330078125e-05 	 0.34815406799316406 	 0.3071434497833252 	 0.29313039779663086 	 0.2244553565979004 	 
2025-07-25 19:10:20.297575 test begin: paddle.unbind(Tensor([3, 3386881, 5],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([3, 3386881, 5],"float32"), axis=0, ) 	 50803215 	 1000 	 0.010210037231445312 	 0.0062291622161865234 	 2.6226043701171875e-05 	 2.1219253540039062e-05 	 0.35115861892700195 	 0.3104097843170166 	 0.29392290115356445 	 0.2107987403869629 	 
2025-07-25 19:10:22.730628 test begin: paddle.unbind(Tensor([3, 9, 1881601],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([3, 9, 1881601],"float32"), axis=0, ) 	 50803227 	 1000 	 0.013480901718139648 	 0.014558076858520508 	 1.2874603271484375e-05 	 3.647804260253906e-05 	 0.3510603904724121 	 0.31018996238708496 	 0.28273797035217285 	 0.2050027847290039 	 
2025-07-25 19:10:25.165152 test begin: paddle.unbind(Tensor([4, 2116801, 6],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([4, 2116801, 6],"float32"), ) 	 50803224 	 1000 	 0.008713006973266602 	 0.007136344909667969 	 1.049041748046875e-05 	 4.38690185546875e-05 	 0.35059094429016113 	 0.3094792366027832 	 0.29178762435913086 	 0.2054126262664795 	 
2025-07-25 19:10:27.562970 test begin: paddle.unbind(Tensor([4, 5, 2540161],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([4, 5, 2540161],"float32"), ) 	 50803220 	 1000 	 0.00875711441040039 	 0.009471416473388672 	 8.344650268554688e-06 	 6.0558319091796875e-05 	 0.35062074661254883 	 0.30941247940063477 	 0.28736400604248047 	 0.21385741233825684 	 
2025-07-25 19:10:29.985226 test begin: paddle.unflatten(x=Tensor([4, 1587601, 16],"float16"), axis=0, shape=tuple(2,2,), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 1587601, 16],"float16"), axis=0, shape=tuple(2,2,), ) 	 101606464 	 1000 	 0.008810281753540039 	 0.0052797794342041016 	 2.1219253540039062e-05 	 1.9788742065429688e-05 	 0.042386770248413086 	 0.056465864181518555 	 2.1696090698242188e-05 	 3.838539123535156e-05 	 
2025-07-25 19:10:33.991690 test begin: paddle.unflatten(x=Tensor([4, 6, 2116801],"bool"), axis=0, shape=tuple(2,2,), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 6, 2116801],"bool"), axis=0, shape=tuple(2,2,), ) 	 50803224 	 1000 	 0.007714509963989258 	 0.005239725112915039 	 1.0967254638671875e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:10:37.381512 test begin: paddle.unflatten(x=Tensor([4, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 50803226 	 1000 	 0.09678292274475098 	 0.0051844120025634766 	 1.7404556274414062e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:10:39.563871 test begin: paddle.unflatten(x=Tensor([4, 6, 4233601],"float16"), axis=0, shape=tuple(2,2,), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 6, 4233601],"float16"), axis=0, shape=tuple(2,2,), ) 	 101606424 	 1000 	 0.007811546325683594 	 0.005651712417602539 	 1.4066696166992188e-05 	 5.459785461425781e-05 	 0.04987525939941406 	 0.05643820762634277 	 3.3855438232421875e-05 	 3.7670135498046875e-05 	 
2025-07-25 19:10:43.532451 test begin: paddle.unflatten(x=Tensor([4, 793801, 16],"bool"), axis=0, shape=tuple(2,2,), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 793801, 16],"bool"), axis=0, shape=tuple(2,2,), ) 	 50803264 	 1000 	 0.007717132568359375 	 0.005137443542480469 	 7.867813110351562e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:10:45.016757 test begin: paddle.unflatten(x=Tensor([4, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 50803266 	 1000 	 0.1082010269165039 	 0.005231142044067383 	 2.6941299438476562e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:10:46.876607 test begin: paddle.unflatten(x=Tensor([529201, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([529201, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 50803298 	 1000 	 0.09842991828918457 	 0.005187273025512695 	 1.7642974853515625e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:10:48.747078 test begin: paddle.unfold(Tensor([5, 10160641],"float32"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([5, 10160641],"float32"), 0, 5, 1, ) 	 50803205 	 1000 	 0.016197681427001953 	 0.004308462142944336 	 9.059906005859375e-06 	 1.811981201171875e-05 	 0.4626271724700928 	 1.23506760597229 	 0.39873814582824707 	 0.42099785804748535 	 
2025-07-25 19:10:52.199412 test begin: paddle.unfold(Tensor([5, 20321281],"float16"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([5, 20321281],"float16"), 0, 5, 1, ) 	 101606405 	 1000 	 0.016336441040039062 	 0.004402875900268555 	 8.344650268554688e-06 	 1.9073486328125e-05 	 0.8996613025665283 	 1.4004645347595215 	 0.8415250778198242 	 0.47744107246398926 	 
2025-07-25 19:10:58.320099 test begin: paddle.unfold(Tensor([5, 5080321],"float64"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([5, 5080321],"float64"), 0, 5, 1, ) 	 25401605 	 1000 	 0.01942157745361328 	 0.004261493682861328 	 2.7179718017578125e-05 	 1.7642974853515625e-05 	 0.3082716464996338 	 1.1619343757629395 	 0.24820399284362793 	 0.39606690406799316 	 
2025-07-25 19:11:00.929989 test begin: paddle.unique(Tensor([25401601],"int64"), )
[Prof] paddle.unique 	 paddle.unique(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 6.728542327880859 	 3.257970094680786 	 5.53131103515625e-05 	 0.00020432472229003906 	 None 	 None 	 None 	 None 	 
2025-07-25 19:11:13.058103 test begin: paddle.unique(Tensor([25401601],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", )
[Prof] paddle.unique 	 paddle.unique(Tensor([25401601],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", ) 	 25401601 	 1000 	 10.112011432647705 	 11.146571159362793 	 6.532669067382812e-05 	 0.0002143383026123047 	 None 	 None 	 None 	 None 	 
2025-07-25 19:11:34.783112 test begin: paddle.unique_consecutive(Tensor([25401601],"float64"), )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 1.6184241771697998 	 0.37388110160827637 	 4.2438507080078125e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:11:39.009242 test begin: paddle.unique_consecutive(Tensor([25401601],"float64"), return_inverse=True, return_counts=True, )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([25401601],"float64"), return_inverse=True, return_counts=True, ) 	 25401601 	 1000 	 3.247710943222046 	 1.011537790298462 	 4.363059997558594e-05 	 6.818771362304688e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:11:43.817761 test begin: paddle.unique_consecutive(Tensor([2540],"float64"), return_inverse=True, return_counts=True, axis=-1, )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([2540],"float64"), return_inverse=True, return_counts=True, axis=-1, ) 	 2540 	 1000 	 1.3468587398529053 	 0.1841576099395752 	 6.270408630371094e-05 	 7.05718994140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-25 19:11:45.396714 test begin: paddle.unsqueeze(Tensor([25, 1024, 1024],"int64"), 1, )
Warning: The core code of paddle.unsqueeze is too complex.
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([25, 1024, 1024],"int64"), 1, ) 	 26214400 	 1000 	 0.004174947738647461 	 0.0044536590576171875 	 7.867813110351562e-06 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:11:46.316296 test begin: paddle.unsqueeze(Tensor([3970, 50, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([3970, 50, 256],"float32"), axis=2, ) 	 50816000 	 1000 	 0.004435300827026367 	 0.003695964813232422 	 7.867813110351562e-06 	 1.5735626220703125e-05 	 0.044617414474487305 	 0.05713319778442383 	 2.5510787963867188e-05 	 5.316734313964844e-05 	 
2025-07-25 19:11:48.121711 test begin: paddle.unsqueeze(Tensor([4, 1024, 6202],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4, 1024, 6202],"int64"), 1, ) 	 25403392 	 1000 	 0.004256010055541992 	 0.0037631988525390625 	 1.5974044799804688e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:11:49.010512 test begin: paddle.unsqueeze(Tensor([4, 6202, 1024],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4, 6202, 1024],"int64"), 1, ) 	 25403392 	 1000 	 0.004258155822753906 	 0.003769397735595703 	 5.9604644775390625e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:11:49.903557 test begin: paddle.unsqueeze(Tensor([416, 478, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([416, 478, 256],"float32"), axis=2, ) 	 50905088 	 1000 	 0.004709482192993164 	 0.007008790969848633 	 0.0001659393310546875 	 1.7404556274414062e-05 	 0.05024385452270508 	 0.07833576202392578 	 2.5033950805664062e-05 	 8.249282836914062e-05 	 
2025-07-25 19:11:51.638464 test begin: paddle.unsqueeze(Tensor([416, 50, 2443],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([416, 50, 2443],"float32"), axis=2, ) 	 50814400 	 1000 	 0.004434823989868164 	 0.003689289093017578 	 6.67572021484375e-06 	 1.6689300537109375e-05 	 0.04332470893859863 	 0.057152509689331055 	 3.123283386230469e-05 	 4.291534423828125e-05 	 
2025-07-25 19:11:53.438091 test begin: paddle.unsqueeze(Tensor([512, 388, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([512, 388, 256],"float32"), axis=2, ) 	 50855936 	 1000 	 0.00445556640625 	 0.003660440444946289 	 6.67572021484375e-06 	 1.621246337890625e-05 	 0.042789459228515625 	 0.05756711959838867 	 1.7404556274414062e-05 	 6.580352783203125e-05 	 
2025-07-25 19:11:55.222758 test begin: paddle.unsqueeze(Tensor([512, 50, 1985],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([512, 50, 1985],"float32"), axis=2, ) 	 50816000 	 1000 	 0.004393577575683594 	 0.0037271976470947266 	 1.0728836059570312e-05 	 1.5497207641601562e-05 	 0.042841196060180664 	 0.056830644607543945 	 2.6226043701171875e-05 	 3.4332275390625e-05 	 
2025-07-25 19:11:57.083410 test begin: paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-1, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-1, ) 	 50803350 	 1000 	 0.328627347946167 	 0.018418312072753906 	 0.3024322986602783 	 3.075599670410156e-05 	 0.4710366725921631 	 4.459638595581055 	 0.36327433586120605 	 4.282977819442749 	 
2025-07-25 19:12:03.883011 test begin: paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-2, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-2, ) 	 50803350 	 1000 	 0.4040846824645996 	 0.01366734504699707 	 0.3815901279449463 	 4.506111145019531e-05 	 0.3619225025177002 	 1.2655861377716064 	 0.29072046279907227 	 1.1286649703979492 	 
2025-07-25 19:12:07.452648 test begin: paddle.unstack(Tensor([5, 10, 1016065],"float32"), axis=-2, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([5, 10, 1016065],"float32"), axis=-2, ) 	 50803250 	 1000 	 0.38933539390563965 	 0.013173341751098633 	 0.3683469295501709 	 2.0265579223632812e-05 	 0.32810235023498535 	 0.306654691696167 	 0.25741100311279297 	 0.16703295707702637 	 
2025-07-25 19:12:10.016708 test begin: paddle.unstack(Tensor([5, 677377, 15],"float32"), axis=-1, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([5, 677377, 15],"float32"), axis=-1, ) 	 50803275 	 1000 	 0.32862210273742676 	 0.025219440460205078 	 0.3024559020996094 	 3.528594970703125e-05 	 0.47023630142211914 	 4.4612767696380615 	 0.3940098285675049 	 4.275856018066406 	 
2025-07-25 19:12:18.012435 test begin: paddle.unstack(x=Tensor([2, 32, 793801],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([2, 32, 793801],"float32"), axis=0, ) 	 50803264 	 1000 	 0.38826465606689453 	 0.005358457565307617 	 0.3757791519165039 	 2.288818359375e-05 	 0.3459165096282959 	 0.3094348907470703 	 0.2918252944946289 	 0.21924591064453125 	 
2025-07-25 19:12:20.757431 test begin: paddle.unstack(x=Tensor([2, 49613, 512],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([2, 49613, 512],"float32"), axis=0, ) 	 50803712 	 1000 	 0.3881795406341553 	 0.005347013473510742 	 0.37564873695373535 	 1.7881393432617188e-05 	 0.3448500633239746 	 0.3055427074432373 	 0.2905282974243164 	 0.22186899185180664 	 
2025-07-25 19:12:23.457332 test begin: paddle.unstack(x=Tensor([3101, 32, 512],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([3101, 32, 512],"float32"), axis=0, ) 	 50806784 	 1000 	 3.7868967056274414 	 5.680837869644165 	 0.00010132789611816406 	 0.00011992454528808594 	 5.749293804168701 	 20.75430393218994 	 6.67572021484375e-05 	 0.00021266937255859375 	 
2025-07-25 19:13:01.429033 test begin: paddle.var(Tensor([264601, 192, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([264601, 192, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803392 	 1000 	 1.3081769943237305 	 0.2751016616821289 	 0.11104154586791992 	 0.2508809566497803 	 1.5766234397888184 	 0.776848316192627 	 0.26857805252075195 	 0.19838571548461914 	 
2025-07-25 19:13:06.208785 test begin: paddle.var(Tensor([384, 132301, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 132301, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803584 	 1000 	 1.032257318496704 	 0.1852867603302002 	 0.07524609565734863 	 0.09467411041259766 	 13.749229431152344 	 0.7736682891845703 	 2.0073769092559814 	 0.15807652473449707 	 
2025-07-25 19:13:23.179741 test begin: paddle.var(Tensor([384, 192, 1, 690],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 192, 1, 690],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50872320 	 1000 	 1.0225327014923096 	 0.1791543960571289 	 0.07448029518127441 	 0.09148907661437988 	 1.3746833801269531 	 0.7712476253509521 	 0.20072102546691895 	 0.15761637687683105 	 
2025-07-25 19:13:27.406462 test begin: paddle.var(Tensor([384, 192, 690, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 192, 690, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50872320 	 1000 	 1.0238242149353027 	 0.17914223670959473 	 0.07459211349487305 	 0.09153342247009277 	 13.51523470878601 	 0.7713675498962402 	 1.973264455795288 	 0.15764427185058594 	 
2025-07-25 19:13:43.781198 test begin: paddle.var(Tensor([384, 96, 1, 1379],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 96, 1, 1379],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50835456 	 1000 	 1.0259394645690918 	 0.18102383613586426 	 0.07480072975158691 	 0.09249472618103027 	 1.3742196559906006 	 0.773068904876709 	 0.20060372352600098 	 0.1579899787902832 	 
2025-07-25 19:13:47.973795 test begin: paddle.var(Tensor([384, 96, 1379, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 96, 1379, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50835456 	 1000 	 1.0245561599731445 	 0.18099331855773926 	 0.07462310791015625 	 0.09245085716247559 	 13.766762495040894 	 0.7743182182312012 	 2.009955883026123 	 0.15822196006774902 	 
2025-07-25 19:14:04.601744 test begin: paddle.var(Tensor([529201, 96, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([529201, 96, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803296 	 1000 	 1.2866284847259521 	 0.4530301094055176 	 0.10931587219238281 	 0.43624234199523926 	 1.588888168334961 	 0.8224000930786133 	 0.2706770896911621 	 0.209977388381958 	 
2025-07-25 19:14:09.620728 test begin: paddle.var(Tensor([58801, 96, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([58801, 96, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50804064 	 1000 	 0.9796013832092285 	 0.17709112167358398 	 0.08315110206604004 	 0.16052508354187012 	 1.358292818069458 	 0.7687134742736816 	 0.23144936561584473 	 0.19631338119506836 	 
2025-07-25 19:14:13.745255 test begin: paddle.var(Tensor([96, 58801, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 58801, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50804064 	 1000 	 0.99143385887146 	 0.21727514266967773 	 0.07228565216064453 	 0.11101841926574707 	 1.3456904888153076 	 0.7857699394226074 	 0.19644403457641602 	 0.1605682373046875 	 
2025-07-25 19:14:17.962653 test begin: paddle.var(Tensor([96, 96, 1838, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 96, 1838, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50817024 	 1000 	 0.9910173416137695 	 0.21284961700439453 	 0.0722661018371582 	 0.10874152183532715 	 1.34401273727417 	 0.7863218784332275 	 0.19618988037109375 	 0.1607208251953125 	 
2025-07-25 19:14:22.140171 test begin: paddle.var(Tensor([96, 96, 3, 1838],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 96, 3, 1838],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50817024 	 1000 	 0.9910025596618652 	 0.21279406547546387 	 0.07223796844482422 	 0.10872697830200195 	 1.3450369834899902 	 0.7850708961486816 	 0.19610953330993652 	 0.16041970252990723 	 
2025-07-25 19:14:27.326018 test begin: paddle.vecdot(Tensor([12700801, 4],"float32"), Tensor([12700801, 4],"float32"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([12700801, 4],"float32"), Tensor([12700801, 4],"float32"), axis=-1, ) 	 101606408 	 1000 	 1.1486496925354004 	 0.9317111968994141 	 0.3913757801055908 	 0.4761078357696533 	 1.641247034072876 	 0.6834716796875 	 0.5593762397766113 	 0.34912586212158203 	 combined
2025-07-25 19:14:33.596407 test begin: paddle.vecdot(Tensor([1270081, 4, 5],"float64"), Tensor([1270081, 4, 5],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([1270081, 4, 5],"float64"), Tensor([1270081, 4, 5],"float64"), axis=1, ) 	 50803240 	 1000 	 1.0295891761779785 	 1.3297851085662842 	 0.35076308250427246 	 0.32320427894592285 	 1.2436800003051758 	 0.6732311248779297 	 0.4238114356994629 	 0.3439218997955322 	 combined
2025-07-25 19:14:40.559425 test begin: paddle.vecdot(Tensor([2, 3, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2, 3, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), axis=-1, ) 	 50803212 	 1000 	 0.9931375980377197 	 0.5962469577789307 	 0.25354647636413574 	 0.2028813362121582 	 1.1784086227416992 	 0.6010472774505615 	 0.40166378021240234 	 0.3070838451385498 	 combined
2025-07-25 19:14:45.004312 test begin: paddle.vecdot(Tensor([2, 3175201, 4],"float64"), Tensor([2, 3175201, 4],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2, 3175201, 4],"float64"), Tensor([2, 3175201, 4],"float64"), axis=-1, ) 	 50803216 	 1000 	 0.9978592395782471 	 0.7154226303100586 	 0.33997130393981934 	 0.3643002510070801 	 1.243464708328247 	 0.6722965240478516 	 0.42376255989074707 	 0.34348535537719727 	 combined
2025-07-25 19:14:49.816291 test begin: paddle.vecdot(Tensor([2116801, 3, 4],"float64"), Tensor([2116801, 3, 4],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2116801, 3, 4],"float64"), Tensor([2116801, 3, 4],"float64"), axis=-1, ) 	 50803224 	 1000 	 0.9978382587432861 	 0.7129974365234375 	 0.3399543762207031 	 0.36433911323547363 	 1.2434048652648926 	 0.6722936630249023 	 0.4237792491912842 	 0.34346604347229004 	 combined
2025-07-25 19:14:54.636529 test begin: paddle.vecdot(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), axis=-1, ) 	 101606406 	 1000 	 0.9697260856628418 	 0.5988292694091797 	 0.2475275993347168 	 0.2037975788116455 	 1.5734806060791016 	 0.606696605682373 	 0.5363824367523193 	 0.30991172790527344 	 combined
2025-07-25 19:15:00.075902 test begin: paddle.vecdot(Tensor([3, 1693441, 5],"float64"), Tensor([3, 1693441, 5],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 1693441, 5],"float64"), Tensor([3, 1693441, 5],"float64"), axis=1, ) 	 50803230 	 1000 	 7.03679084777832 	 0.6001284122467041 	 1.8006975650787354 	 0.20421957969665527 	 1.1785523891448975 	 0.601660966873169 	 0.4017179012298584 	 0.3073692321777344 	 combined
2025-07-25 19:15:10.666556 test begin: paddle.vecdot(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), axis=1, ) 	 50803224 	 1000 	 0.930553674697876 	 0.6328125 	 0.3170278072357178 	 0.322399377822876 	 1.3357868194580078 	 0.8986341953277588 	 0.45518064498901367 	 0.4590883255004883 	 combined
2025-07-25 19:15:15.810481 test begin: paddle.view(Tensor([10, 10, 10, 50804],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([10, 10, 10, 50804],"float32"), list[-1,], ) 	 50804000 	 1000 	 0.014090776443481445 	 0.003865480422973633 	 2.5272369384765625e-05 	 1.6689300537109375e-05 	 0.048996686935424805 	 0.055083513259887695 	 2.8371810913085938e-05 	 4.506111145019531e-05 	 
2025-07-25 19:15:17.639516 test begin: paddle.view(Tensor([10, 10, 10, 50804],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([10, 10, 10, 50804],"float32"), list[10,100,-1,], ) 	 50804000 	 1000 	 0.013894081115722656 	 0.004227876663208008 	 1.0013580322265625e-05 	 3.743171691894531e-05 	 0.04259300231933594 	 0.05656766891479492 	 2.3365020751953125e-05 	 5.412101745605469e-05 	 
2025-07-25 19:15:19.448729 test begin: paddle.view(Tensor([10, 10, 25402, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([10, 10, 25402, 20],"float32"), list[-1,], ) 	 50804000 	 1000 	 0.013711214065551758 	 0.003907680511474609 	 1.1682510375976562e-05 	 1.71661376953125e-05 	 0.04273247718811035 	 0.05587625503540039 	 2.8848648071289062e-05 	 4.744529724121094e-05 	 
2025-07-25 19:15:21.223039 test begin: paddle.view(Tensor([10, 10, 25402, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([10, 10, 25402, 20],"float32"), list[10,100,-1,], ) 	 50804000 	 1000 	 0.01566600799560547 	 0.0040242671966552734 	 2.0742416381835938e-05 	 1.7642974853515625e-05 	 0.04259085655212402 	 0.056635379791259766 	 2.3126602172851562e-05 	 4.6253204345703125e-05 	 
2025-07-25 19:15:23.045639 test begin: paddle.view(Tensor([10, 25402, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([10, 25402, 10, 20],"float32"), list[-1,], ) 	 50804000 	 1000 	 0.013768911361694336 	 0.0040302276611328125 	 1.4066696166992188e-05 	 1.8835067749023438e-05 	 0.04668378829956055 	 0.055182456970214844 	 3.933906555175781e-05 	 5.7697296142578125e-05 	 
2025-07-25 19:15:24.928269 test begin: paddle.view(Tensor([10, 25402, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([10, 25402, 10, 20],"float32"), list[10,100,-1,], ) 	 50804000 	 1000 	 0.013844490051269531 	 0.00400090217590332 	 9.059906005859375e-06 	 2.3126602172851562e-05 	 0.0427851676940918 	 0.056928157806396484 	 1.9073486328125e-05 	 5.507469177246094e-05 	 
2025-07-25 19:15:26.730070 test begin: paddle.view(Tensor([25402, 10, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([25402, 10, 10, 20],"float32"), list[-1,], ) 	 50804000 	 1000 	 0.013794183731079102 	 0.003895998001098633 	 1.8358230590820312e-05 	 1.8596649169921875e-05 	 0.04423117637634277 	 0.05549955368041992 	 3.075599670410156e-05 	 4.482269287109375e-05 	 
2025-07-25 19:15:29.057489 test begin: paddle.view(Tensor([25402, 10, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([25402, 10, 10, 20],"float32"), list[10,100,-1,], ) 	 50804000 	 1000 	 0.013678789138793945 	 0.003988504409790039 	 8.58306884765625e-06 	 2.002716064453125e-05 	 0.04214191436767578 	 0.05672931671142578 	 3.0994415283203125e-05 	 5.8650970458984375e-05 	 
2025-07-25 19:15:31.135071 test begin: paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), )
[Prof] paddle.view_as 	 paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), ) 	 101608000 	 1000 	 0.014405488967895508 	 0.0034618377685546875 	 9.298324584960938e-06 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-25 19:15:34.124300 test begin: paddle.vsplit(Tensor([2116801, 4, 3],"int64"), list[-1,1,3,], )
W0725 19:15:35.226131 154726 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([2116801, 4, 3],"int64"), list[-1,1,3,], ) 	 25401612 	 1000 	 0.03252553939819336 	 0.009119987487792969 	 1.1920928955078125e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:37.618489 test begin: paddle.vsplit(Tensor([2116801, 4, 3],"int64"), list[-1,], )
W0725 19:15:38.395463 154753 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([2116801, 4, 3],"int64"), list[-1,], ) 	 25401612 	 1000 	 0.02808380126953125 	 0.0068628787994384766 	 1.33514404296875e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:40.148826 test begin: paddle.vsplit(Tensor([2116801, 4, 3],"int64"), list[2,4,], )
W0725 19:15:40.874634 154768 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([2116801, 4, 3],"int64"), list[2,4,], ) 	 25401612 	 1000 	 0.040700435638427734 	 0.012816429138183594 	 3.218650817871094e-05 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:41.001903 test begin: paddle.vsplit(Tensor([6, 1411201, 3],"int64"), list[-1,1,3,], )
W0725 19:15:41.941828 154782 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([6, 1411201, 3],"int64"), list[-1,1,3,], ) 	 25401618 	 1000 	 0.053142547607421875 	 0.014282941818237305 	 2.1457672119140625e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:42.089521 test begin: paddle.vsplit(Tensor([6, 1411201, 3],"int64"), list[-1,], )
W0725 19:15:42.786682 154786 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([6, 1411201, 3],"int64"), list[-1,], ) 	 25401618 	 1000 	 0.028893232345581055 	 0.014705181121826172 	 6.270408630371094e-05 	 0.0001010894775390625 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:42.889174 test begin: paddle.vsplit(Tensor([6, 1411201, 3],"int64"), list[2,4,], )
W0725 19:15:43.666532 154787 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([6, 1411201, 3],"int64"), list[2,4,], ) 	 25401618 	 1000 	 0.0338892936706543 	 0.008193492889404297 	 3.719329833984375e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:43.801473 test begin: paddle.vsplit(Tensor([6, 4, 1058401],"int64"), list[-1,1,3,], )
W0725 19:15:44.740620 154792 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([6, 4, 1058401],"int64"), list[-1,1,3,], ) 	 25401624 	 1000 	 0.05314517021179199 	 0.01440882682800293 	 1.0251998901367188e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:44.859310 test begin: paddle.vsplit(Tensor([6, 4, 1058401],"int64"), list[-1,], )
W0725 19:15:45.535853 154809 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([6, 4, 1058401],"int64"), list[-1,], ) 	 25401624 	 1000 	 0.02827167510986328 	 0.011404037475585938 	 2.0265579223632812e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:45.629920 test begin: paddle.vsplit(Tensor([6, 4, 1058401],"int64"), list[2,4,], )
W0725 19:15:46.382157 154813 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([6, 4, 1058401],"int64"), list[2,4,], ) 	 25401624 	 1000 	 0.040360212326049805 	 0.01285862922668457 	 1.4543533325195312e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-25 19:15:46.523329 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9550962448120117 	 0.9221067428588867 	 0.16267800331115723 	 0.9073402881622314 	 0.9382667541503906 	 0.10089945793151855 	 0.15983271598815918 	 7.653236389160156e-05 	 
2025-07-25 19:15:52.864271 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], name=None, ) 	 76204872 	 1000 	 0.9551546573638916 	 0.9221088886260986 	 0.16267967224121094 	 0.9003546237945557 	 0.9382011890411377 	 0.08258485794067383 	 0.15976428985595703 	 8.702278137207031e-05 	 
2025-07-25 19:15:59.099316 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.31607556343078613 	 0.3132634162902832 	 0.16150259971618652 	 0.1599891185760498 	 0.3159017562866211 	 0.05941295623779297 	 0.16129279136657715 	 8.106231689453125e-05 	 
2025-07-25 19:16:01.262322 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3219268321990967 	 0.32538318634033203 	 0.08239221572875977 	 0.3084094524383545 	 0.316788911819458 	 0.08092570304870605 	 0.08102798461914062 	 9.632110595703125e-05 	 
2025-07-25 19:16:03.380117 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.321972131729126 	 0.3237192630767822 	 0.08239150047302246 	 0.30908894538879395 	 0.31675100326538086 	 0.07693719863891602 	 0.08102130889892578 	 8.392333984375e-05 	 
2025-07-25 19:16:05.489668 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3262200355529785 	 0.32029294967651367 	 0.08319497108459473 	 0.3055257797241211 	 0.3163938522338867 	 0.09578204154968262 	 0.08062863349914551 	 5.53131103515625e-05 	 
2025-07-25 19:16:07.640412 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.32621288299560547 	 0.32011866569519043 	 0.08318758010864258 	 0.305830717086792 	 0.3163878917694092 	 0.08333516120910645 	 0.08064007759094238 	 8.869171142578125e-05 	 
2025-07-25 19:16:09.739448 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9465765953063965 	 0.9186158180236816 	 0.16124320030212402 	 0.903907060623169 	 0.945868968963623 	 0.0889747142791748 	 0.16109132766723633 	 5.173683166503906e-05 	 
2025-07-25 19:16:15.903720 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], name=None, ) 	 76204980 	 1000 	 0.9464335441589355 	 0.9188380241394043 	 0.16124320030212402 	 0.9043288230895996 	 0.9458250999450684 	 0.09141373634338379 	 0.16103148460388184 	 7.534027099609375e-05 	 
2025-07-25 19:16:22.038245 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.314896821975708 	 0.3132174015045166 	 0.16091203689575195 	 0.15995121002197266 	 0.31317734718322754 	 0.06670403480529785 	 0.15996026992797852 	 5.078315734863281e-05 	 
2025-07-25 19:16:24.103196 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9562721252441406 	 0.941094160079956 	 0.1629042625427246 	 0.91249680519104 	 0.9436097145080566 	 0.09488296508789062 	 0.1606919765472412 	 7.581710815429688e-05 	 
2025-07-25 19:16:30.318667 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], name=None, ) 	 76204890 	 1000 	 0.9563920497894287 	 0.9537789821624756 	 0.16289114952087402 	 0.9140856266021729 	 0.943551778793335 	 0.10086202621459961 	 0.16069555282592773 	 0.00019478797912597656 	 
2025-07-25 19:16:40.049872 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.31605052947998047 	 0.33142805099487305 	 0.1614694595336914 	 0.1599900722503662 	 0.31574201583862305 	 0.06560397148132324 	 0.16126298904418945 	 4.696846008300781e-05 	 
2025-07-25 19:16:43.075717 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3204841613769531 	 0.31091928482055664 	 0.08171319961547852 	 0.2967407703399658 	 0.31337738037109375 	 0.08640098571777344 	 0.07987093925476074 	 5.888938903808594e-05 	 
2025-07-25 19:16:45.166636 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.3204665184020996 	 0.3109438419342041 	 0.08172202110290527 	 0.29697418212890625 	 0.313373327255249 	 0.07623410224914551 	 0.07988929748535156 	 4.839897155761719e-05 	 
2025-07-25 19:16:47.269645 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9404616355895996 	 0.9224526882171631 	 0.16017818450927734 	 0.9078433513641357 	 0.9411056041717529 	 0.07819557189941406 	 0.16027545928955078 	 6.341934204101562e-05 	 
2025-07-25 19:16:53.353126 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, ) 	 76204920 	 1000 	 0.9405124187469482 	 0.9223272800445557 	 0.1602187156677246 	 0.9050579071044922 	 0.9411101341247559 	 0.07867741584777832 	 0.16025876998901367 	 6.008148193359375e-05 	 
2025-07-25 19:16:59.527451 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3149604797363281 	 0.3132588863372803 	 0.16092967987060547 	 0.1599750518798828 	 0.31322789192199707 	 0.058263301849365234 	 0.16000580787658691 	 4.57763671875e-05 	 
2025-07-25 19:17:01.614943 test begin: paddle.where(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"float32"), Tensor([1, 400, 127009],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"float32"), Tensor([1, 400, 127009],"float32"), ) 	 152410800 	 1000 	 0.4847524166107178 	 0.48421168327331543 	 0.46384119987487793 	 0.4705493450164795 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:06.352542 test begin: paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), ) 	 105369600 	 1000 	 0.9340229034423828 	 0.5166988372802734 	 0.3183910846710205 	 0.49503564834594727 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:11.203571 test begin: paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), ) 	 105369600 	 1000 	 0.9340760707855225 	 0.516620397567749 	 0.3183600902557373 	 0.49501991271972656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:16.068503 test begin: paddle.where(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"float32"), Tensor([1, 772, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"float32"), Tensor([1, 772, 65856],"float32"), ) 	 152522496 	 1000 	 0.48601508140563965 	 0.483112096786499 	 0.46614956855773926 	 0.46949195861816406 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:20.754716 test begin: paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), ) 	 105369600 	 1000 	 1.1144459247589111 	 0.5166645050048828 	 0.37971925735473633 	 0.5017025470733643 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:26.097862 test begin: paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), ) 	 158054400 	 1000 	 0.5022456645965576 	 0.5004119873046875 	 0.48349809646606445 	 0.4855923652648926 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:31.003674 test begin: paddle.where(Tensor([4, 125, 320, 320],"bool"), Tensor([4, 125, 320, 320],"float32"), Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 125, 320, 320],"bool"), Tensor([4, 125, 320, 320],"float32"), Tensor([4, 125, 320, 320],"float32"), ) 	 153600000 	 1000 	 0.48801255226135254 	 1.6952555179595947 	 0.46902918815612793 	 0.47039318084716797 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:40.145651 test begin: paddle.where(Tensor([4, 280, 376, 25, 5],"bool"), Tensor([4, 280, 376, 25, 5],"float32"), Tensor([4, 280, 376, 25, 5],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 376, 25, 5],"bool"), Tensor([4, 280, 376, 25, 5],"float32"), Tensor([4, 280, 376, 25, 5],"float32"), ) 	 157920000 	 1000 	 0.502152681350708 	 0.5166842937469482 	 0.4831209182739258 	 0.4787726402282715 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:45.676502 test begin: paddle.where(Tensor([4, 280, 376, 41, 3],"bool"), Tensor([4, 280, 376, 41, 3],"float32"), Tensor([4, 280, 376, 41, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 376, 41, 3],"bool"), Tensor([4, 280, 376, 41, 3],"float32"), Tensor([4, 280, 376, 41, 3],"float32"), ) 	 155393280 	 1000 	 0.49423861503601074 	 0.4929020404815674 	 0.47528815269470215 	 0.4786405563354492 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:50.621625 test begin: paddle.where(Tensor([4, 280, 605, 25, 3],"bool"), Tensor([4, 280, 605, 25, 3],"float32"), Tensor([4, 280, 605, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 605, 25, 3],"bool"), Tensor([4, 280, 605, 25, 3],"float32"), Tensor([4, 280, 605, 25, 3],"float32"), ) 	 152460000 	 1000 	 0.48514676094055176 	 0.4908874034881592 	 0.45009493827819824 	 0.4689605236053467 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:17:55.444760 test begin: paddle.where(Tensor([4, 451, 376, 25, 3],"bool"), Tensor([4, 451, 376, 25, 3],"float32"), Tensor([4, 451, 376, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 451, 376, 25, 3],"bool"), Tensor([4, 451, 376, 25, 3],"float32"), Tensor([4, 451, 376, 25, 3],"float32"), ) 	 152618400 	 1000 	 0.48531508445739746 	 0.4836242198944092 	 0.4664328098297119 	 0.46833372116088867 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:18:00.207137 test begin: paddle.where(Tensor([4, 64, 320, 621],"bool"), Tensor([4, 64, 320, 621],"float32"), Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 64, 320, 621],"bool"), Tensor([4, 64, 320, 621],"float32"), Tensor([4, 64, 320, 621],"float32"), ) 	 152616960 	 1000 	 0.48523855209350586 	 0.4833552837371826 	 0.4660336971282959 	 0.4690086841583252 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:18:04.964799 test begin: paddle.where(Tensor([4, 64, 621, 320],"bool"), Tensor([4, 64, 621, 320],"float32"), Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 64, 621, 320],"bool"), Tensor([4, 64, 621, 320],"float32"), Tensor([4, 64, 621, 320],"float32"), ) 	 152616960 	 1000 	 0.48508548736572266 	 0.4832899570465088 	 0.4654519557952881 	 0.46913814544677734 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:18:09.768879 test begin: paddle.where(Tensor([7, 280, 376, 25, 3],"bool"), Tensor([7, 280, 376, 25, 3],"float32"), Tensor([7, 280, 376, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([7, 280, 376, 25, 3],"bool"), Tensor([7, 280, 376, 25, 3],"float32"), Tensor([7, 280, 376, 25, 3],"float32"), ) 	 165816000 	 1000 	 0.5270578861236572 	 0.54219651222229 	 0.5080428123474121 	 0.503211259841919 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:18:14.915535 test begin: paddle.where(Tensor([8, 64, 320, 320],"bool"), Tensor([8, 64, 320, 320],"float32"), Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([8, 64, 320, 320],"bool"), Tensor([8, 64, 320, 320],"float32"), Tensor([8, 64, 320, 320],"float32"), ) 	 157286400 	 1000 	 0.4999043941497803 	 0.49797606468200684 	 0.4775426387786865 	 0.48358583450317383 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-25 19:18:19.851806 test begin: paddle.zeros_like(Tensor([16, 64, 320, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([16, 64, 320, 320],"float16"), ) 	 104857600 	 1000 	 0.1381089687347412 	 0.1384139060974121 	 0.1196146011352539 	 0.12014222145080566 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:22.142484 test begin: paddle.zeros_like(Tensor([4, 1051, 12096],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 1051, 12096],"float32"), ) 	 50851584 	 1000 	 0.13405585289001465 	 0.1343984603881836 	 0.12342023849487305 	 0.12303376197814941 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:23.266892 test begin: paddle.zeros_like(Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 125, 320, 320],"float32"), ) 	 51200000 	 1000 	 0.13507318496704102 	 0.1353306770324707 	 0.12439942359924316 	 0.12357735633850098 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:24.369306 test begin: paddle.zeros_like(Tensor([4, 249, 320, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 249, 320, 320],"float16"), ) 	 101990400 	 1000 	 0.13451719284057617 	 0.1441788673400879 	 0.12369942665100098 	 0.12275481224060059 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:26.602134 test begin: paddle.zeros_like(Tensor([4, 525, 24193],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 525, 24193],"float32"), ) 	 50805300 	 1000 	 0.13393926620483398 	 0.1343848705291748 	 0.1232607364654541 	 0.12282848358154297 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:27.723668 test begin: paddle.zeros_like(Tensor([4, 64, 1241, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 1241, 320],"float16"), ) 	 101662720 	 1000 	 0.13394474983215332 	 0.13419294357299805 	 0.12294220924377441 	 0.12062978744506836 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:29.938216 test begin: paddle.zeros_like(Tensor([4, 64, 320, 1241],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 320, 1241],"float16"), ) 	 101662720 	 1000 	 0.13400030136108398 	 0.13421845436096191 	 0.12330842018127441 	 0.12252092361450195 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:32.167593 test begin: paddle.zeros_like(Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 320, 621],"float32"), ) 	 50872320 	 1000 	 0.13420677185058594 	 0.13458776473999023 	 0.11515474319458008 	 0.11557793617248535 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:33.261845 test begin: paddle.zeros_like(Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 621, 320],"float32"), ) 	 50872320 	 1000 	 0.13415956497192383 	 0.14879131317138672 	 0.12345647811889648 	 0.11611509323120117 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:34.380138 test begin: paddle.zeros_like(Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([8, 64, 320, 320],"float32"), ) 	 52428800 	 1000 	 0.13816022872924805 	 0.3708791732788086 	 0.12699007987976074 	 0.12349677085876465 	 None 	 None 	 None 	 None 	 
2025-07-25 19:18:37.980382 test begin: paddle.zeros_like(Tensor([9, 525, 12096],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([9, 525, 12096],"float32"), ) 	 57153600 	 1000 	 0.1502997875213623 	 0.40064072608947754 	 0.13957500457763672 	 0.13231611251831055 	 None 	 None 	 None 	 None 	 
