2025-07-30 13:31:42.534265 test begin: paddle.abs(Tensor([13, 64, 256, 256],"float32"), )
W0730 13:31:43.558216  1957 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.abs 	 paddle.abs(Tensor([13, 64, 256, 256],"float32"), ) 	 54525952 	 1000 	 0.3187243938446045 	 0.3218832015991211 	 0.3085150718688965 	 0.3069031238555908 	 0.48308753967285156 	 0.7968640327453613 	 0.4284627437591553 	 0.4070425033569336 	 
2025-07-30 13:31:46.791499 test begin: paddle.abs(Tensor([16, 128, 128, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 128, 128, 194],"float32"), ) 	 50855936 	 1000 	 0.2965810298919678 	 0.2980790138244629 	 0.27940869331359863 	 0.27798891067504883 	 0.45079922676086426 	 0.7437758445739746 	 0.3866558074951172 	 0.3800535202026367 	 
2025-07-30 13:31:50.268987 test begin: paddle.abs(Tensor([16, 128, 194, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 128, 194, 128],"float32"), ) 	 50855936 	 1000 	 0.2971315383911133 	 0.30548954010009766 	 0.28751492500305176 	 0.2816801071166992 	 0.4510152339935303 	 0.7447683811187744 	 0.39590001106262207 	 0.38106536865234375 	 
2025-07-30 13:31:57.070184 test begin: paddle.abs(Tensor([16, 194, 128, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 194, 128, 128],"float32"), ) 	 50855936 	 1000 	 0.29637956619262695 	 0.2980508804321289 	 0.28741955757141113 	 0.2851407527923584 	 0.45179033279418945 	 0.7436952590942383 	 0.39742588996887207 	 0.3799757957458496 	 
2025-07-30 13:32:00.534344 test begin: paddle.abs(Tensor([16, 256, 194, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 256, 194, 64],"float32"), ) 	 50855936 	 1000 	 0.296398401260376 	 0.29810285568237305 	 0.2875370979309082 	 0.28484129905700684 	 0.45072484016418457 	 0.7436068058013916 	 0.3958156108856201 	 0.3799324035644531 	 
2025-07-30 13:32:03.992100 test begin: paddle.abs(Tensor([16, 256, 64, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 256, 64, 194],"float32"), ) 	 50855936 	 1000 	 0.2964134216308594 	 0.29807424545288086 	 0.2875699996948242 	 0.28517842292785645 	 0.45073533058166504 	 0.7436764240264893 	 0.39666175842285156 	 0.37995481491088867 	 
2025-07-30 13:32:07.443572 test begin: paddle.abs(Tensor([16, 49, 256, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 49, 256, 256],"float32"), ) 	 51380224 	 1000 	 0.29946327209472656 	 0.30124449729919434 	 0.2903754711151123 	 0.28058958053588867 	 0.45555734634399414 	 0.7513525485992432 	 0.4013557434082031 	 0.38393449783325195 	 
2025-07-30 13:32:10.919410 test begin: paddle.abs(Tensor([16, 64, 194, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 64, 194, 256],"float32"), ) 	 50855936 	 1000 	 0.2963249683380127 	 0.29805517196655273 	 0.28751134872436523 	 0.28517651557922363 	 0.45084333419799805 	 0.743619441986084 	 0.39627718925476074 	 0.3799152374267578 	 
2025-07-30 13:32:14.368038 test begin: paddle.abs(Tensor([16, 64, 256, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 64, 256, 194],"float32"), ) 	 50855936 	 1000 	 0.29639434814453125 	 0.2980470657348633 	 0.28753018379211426 	 0.2850167751312256 	 0.45053839683532715 	 0.7436113357543945 	 0.39628076553344727 	 0.3799405097961426 	 
2025-07-30 13:32:17.815565 test begin: paddle.abs(Tensor([16, 776, 64, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 776, 64, 64],"float32"), ) 	 50855936 	 1000 	 0.29637861251831055 	 0.29809069633483887 	 0.2803332805633545 	 0.27839183807373047 	 0.4508078098297119 	 0.74373459815979 	 0.3873147964477539 	 0.3800210952758789 	 
2025-07-30 13:32:21.309470 test begin: paddle.abs(Tensor([25, 128, 128, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([25, 128, 128, 128],"float32"), ) 	 52428800 	 1000 	 0.30550527572631836 	 0.3075993061065674 	 0.28892946243286133 	 0.2873497009277344 	 0.4648122787475586 	 0.766549825668335 	 0.4005444049835205 	 0.39159512519836426 	 
2025-07-30 13:32:24.992727 test begin: paddle.abs(Tensor([49, 256, 64, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([49, 256, 64, 64],"float32"), ) 	 51380224 	 1000 	 0.2995479106903076 	 0.30142688751220703 	 0.2833845615386963 	 0.2815415859222412 	 0.45545196533203125 	 0.7511937618255615 	 0.3916332721710205 	 0.38378453254699707 	 
2025-07-30 13:32:28.636097 test begin: paddle.acos(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2958972454071045 	 0.29780054092407227 	 0.28146934509277344 	 0.2808341979980469 	 0.45058274269104004 	 2.0801565647125244 	 0.3884165287017822 	 0.3543212413787842 	 
2025-07-30 13:32:33.465068 test begin: paddle.acos(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2968571186065674 	 0.3039133548736572 	 0.28740525245666504 	 0.2869455814361572 	 0.45066261291503906 	 2.0802676677703857 	 0.39614272117614746 	 0.35434484481811523 	 
2025-07-30 13:32:42.468508 test begin: paddle.acos(Tensor([10, 5080321],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29587221145629883 	 0.29762887954711914 	 0.28730154037475586 	 0.28626537322998047 	 0.4503037929534912 	 2.0800154209136963 	 0.3968210220336914 	 0.35433173179626465 	 
2025-07-30 13:32:47.235485 test begin: paddle.acos(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29584622383117676 	 0.29771924018859863 	 0.28736257553100586 	 0.2807300090789795 	 0.45047640800476074 	 2.0799765586853027 	 0.3884272575378418 	 0.3543579578399658 	 
2025-07-30 13:32:52.100856 test begin: paddle.acos(Tensor([5080321, 10],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([5080321, 10],"float32"), ) 	 50803210 	 1000 	 0.2958505153656006 	 0.29770684242248535 	 0.28743743896484375 	 0.28708863258361816 	 0.45023632049560547 	 2.0800790786743164 	 0.3881986141204834 	 0.3543117046356201 	 
2025-07-30 13:32:56.879139 test begin: paddle.acos(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 1.0350496768951416 	 0.3084533214569092 	 0.27989864349365234 	 0.27938222885131836 	 0.45037245750427246 	 2.0800223350524902 	 0.38681721687316895 	 0.35437655448913574 	 
2025-07-30 13:33:04.630478 test begin: paddle.acos(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.29600000381469727 	 0.30321717262268066 	 0.2825925350189209 	 0.2869298458099365 	 0.4504051208496094 	 2.0799858570098877 	 0.3972194194793701 	 0.35433030128479004 	 
2025-07-30 13:33:09.435959 test begin: paddle.acos(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.2958507537841797 	 0.2976648807525635 	 0.28710198402404785 	 0.28696608543395996 	 0.45038914680480957 	 2.080075263977051 	 0.39731335639953613 	 0.35432863235473633 	 
2025-07-30 13:33:14.229427 test begin: paddle.acosh(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29533886909484863 	 0.298966646194458 	 0.2867259979248047 	 0.28820133209228516 	 0.45197129249572754 	 1.3379201889038086 	 0.39925599098205566 	 0.34195971488952637 	 
2025-07-30 13:33:18.334501 test begin: paddle.acosh(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.296781063079834 	 0.2989003658294678 	 0.28695249557495117 	 0.2881629467010498 	 0.4520096778869629 	 1.3378336429595947 	 0.3967885971069336 	 0.34184813499450684 	 
2025-07-30 13:33:22.344611 test begin: paddle.acosh(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29536986351013184 	 0.2989215850830078 	 0.28673887252807617 	 0.28809618949890137 	 0.45202159881591797 	 1.3378243446350098 	 0.39864373207092285 	 0.3419342041015625 	 
2025-07-30 13:33:26.381830 test begin: paddle.add(x=Tensor([2, 256, 320, 352],"float32"), y=Tensor([2, 256, 320, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 320, 352],"float32"), y=Tensor([2, 256, 320, 352],"float32"), ) 	 115343360 	 1000 	 0.5107276439666748 	 0.5064153671264648 	 0.5008790493011475 	 0.49486422538757324 	 0.5481557846069336 	 0.054208993911743164 	 0.48929357528686523 	 5.078315734863281e-05 	 
2025-07-30 13:33:30.909755 test begin: paddle.add(x=Tensor([2, 256, 336, 336],"float32"), y=Tensor([2, 256, 336, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 336, 336],"float32"), y=Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.511833667755127 	 0.5075914859771729 	 0.50213623046875 	 0.495560884475708 	 0.5489284992218018 	 0.05937933921813965 	 0.49085307121276855 	 4.744529724121094e-05 	 
2025-07-30 13:33:37.214236 test begin: paddle.add(x=Tensor([2, 256, 352, 352],"float32"), y=Tensor([2, 256, 352, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 352, 352],"float32"), y=Tensor([2, 256, 352, 352],"float32"), ) 	 126877696 	 1000 	 0.5691745281219482 	 0.5566408634185791 	 0.5515415668487549 	 0.5447299480438232 	 0.6021344661712646 	 0.0710456371307373 	 0.5429813861846924 	 8.20159912109375e-05 	 
2025-07-30 13:33:42.741641 test begin: paddle.add(x=Tensor([8, 256, 320, 78],"float32"), y=Tensor([8, 256, 320, 78],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 320, 78],"float32"), y=Tensor([8, 256, 320, 78],"float32"), ) 	 102236160 	 1000 	 0.45323610305786133 	 0.458324670791626 	 0.44360899925231934 	 0.43748903274536133 	 0.4856424331665039 	 0.053403377532958984 	 0.4266221523284912 	 4.553794860839844e-05 	 
2025-07-30 13:33:46.653653 test begin: paddle.add(x=Tensor([8, 256, 336, 74],"float32"), y=Tensor([8, 256, 336, 74],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 336, 74],"float32"), y=Tensor([8, 256, 336, 74],"float32"), ) 	 101842944 	 1000 	 0.4515247344970703 	 0.4506096839904785 	 0.44176268577575684 	 0.4352271556854248 	 0.4839627742767334 	 0.07006716728210449 	 0.4246699810028076 	 6.270408630371094e-05 	 
2025-07-30 13:33:50.605544 test begin: paddle.add(x=Tensor([8, 256, 352, 71],"float32"), y=Tensor([8, 256, 352, 71],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 352, 71],"float32"), y=Tensor([8, 256, 352, 71],"float32"), ) 	 102367232 	 1000 	 0.4538447856903076 	 0.45380687713623047 	 0.4440927505493164 	 0.43709564208984375 	 0.4864487648010254 	 0.07033276557922363 	 0.4269437789916992 	 4.458427429199219e-05 	 
2025-07-30 13:33:54.547460 test begin: paddle.add(x=Tensor([8, 256, 71, 352],"float32"), y=Tensor([8, 256, 71, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 71, 352],"float32"), y=Tensor([8, 256, 71, 352],"float32"), ) 	 102367232 	 1000 	 0.4539036750793457 	 0.44987964630126953 	 0.4362509250640869 	 0.4381890296936035 	 0.48646092414855957 	 0.053687334060668945 	 0.42772603034973145 	 4.5299530029296875e-05 	 
2025-07-30 13:33:58.742365 test begin: paddle.add(x=Tensor([8, 256, 74, 336],"float32"), y=Tensor([8, 256, 74, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 74, 336],"float32"), y=Tensor([8, 256, 74, 336],"float32"), ) 	 101842944 	 1000 	 0.451613187789917 	 0.7601399421691895 	 0.43173646926879883 	 0.43546509742736816 	 0.4840095043182373 	 0.0533146858215332 	 0.41560912132263184 	 3.457069396972656e-05 	 
2025-07-30 13:34:04.343301 test begin: paddle.add(x=Tensor([8, 52, 352, 352],"float32"), y=Tensor([8, 52, 352, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 52, 352, 352],"float32"), y=Tensor([8, 52, 352, 352],"float32"), ) 	 103088128 	 1000 	 0.45700693130493164 	 0.45308780670166016 	 0.44710493087768555 	 0.4409141540527344 	 0.4898340702056885 	 0.05613994598388672 	 0.4307873249053955 	 5.435943603515625e-05 	 
2025-07-30 13:34:09.913904 test begin: paddle.add(x=Tensor([8, 57, 320, 352],"float32"), y=Tensor([8, 57, 320, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 57, 320, 352],"float32"), y=Tensor([8, 57, 320, 352],"float32"), ) 	 102727680 	 1000 	 0.45567941665649414 	 0.4514627456665039 	 0.44594907760620117 	 0.4397439956665039 	 0.4881248474121094 	 0.05343747138977051 	 0.42856574058532715 	 5.53131103515625e-05 	 
2025-07-30 13:34:14.113484 test begin: paddle.add(x=Tensor([8, 57, 336, 336],"float32"), y=Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 57, 336, 336],"float32"), y=Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.4564695358276367 	 0.4527161121368408 	 0.44672656059265137 	 0.44057679176330566 	 0.48919129371643066 	 0.05360078811645508 	 0.43007421493530273 	 3.4809112548828125e-05 	 
2025-07-30 13:34:18.112706 test begin: paddle.add_n(list[Tensor([194, 128, 64, 64],"float16"),Tensor([194, 128, 64, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([194, 128, 64, 64],"float16"),Tensor([194, 128, 64, 64],"float16"),], ) 	 203423744 	 1000 	 0.5729029178619385 	 1.5182209014892578 	 0.5617389678955078 	 0.7757666110992432 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:24.075630 test begin: paddle.add_n(list[Tensor([388, 256, 32, 32],"float16"),Tensor([388, 256, 32, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([388, 256, 32, 32],"float16"),Tensor([388, 256, 32, 32],"float16"),], ) 	 203423744 	 1000 	 0.5731418132781982 	 1.5177562236785889 	 0.5638689994812012 	 0.7755529880523682 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:29.885447 test begin: paddle.add_n(list[Tensor([64, 128, 194, 64],"float16"),Tensor([64, 128, 194, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 194, 64],"float16"),Tensor([64, 128, 194, 64],"float16"),], ) 	 203423744 	 1000 	 0.5738096237182617 	 1.517198085784912 	 0.5643742084503174 	 0.7752690315246582 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:37.249103 test begin: paddle.add_n(list[Tensor([64, 128, 64, 194],"float16"),Tensor([64, 128, 64, 194],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 64, 194],"float16"),Tensor([64, 128, 64, 194],"float16"),], ) 	 203423744 	 1000 	 0.5751280784606934 	 1.5165762901306152 	 0.5636780261993408 	 0.7749011516571045 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:43.058196 test begin: paddle.add_n(list[Tensor([64, 128, 64, 97],"float32"),Tensor([64, 128, 64, 97],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 64, 97],"float32"),Tensor([64, 128, 64, 97],"float32"),], ) 	 101711872 	 1000 	 0.47325634956359863 	 1.0583646297454834 	 0.4637563228607178 	 0.5407497882843018 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:46.217348 test begin: paddle.add_n(list[Tensor([64, 128, 97, 64],"float32"),Tensor([64, 128, 97, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 97, 64],"float32"),Tensor([64, 128, 97, 64],"float32"),], ) 	 101711872 	 1000 	 0.4728817939758301 	 1.0581800937652588 	 0.4633512496948242 	 0.5406718254089355 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:49.396957 test begin: paddle.add_n(list[Tensor([64, 1551, 32, 32],"float16"),Tensor([64, 1551, 32, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 1551, 32, 32],"float16"),Tensor([64, 1551, 32, 32],"float16"),], ) 	 203292672 	 1000 	 0.5743780136108398 	 1.5180230140686035 	 0.5578687191009521 	 0.7753720283508301 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:55.663541 test begin: paddle.add_n(list[Tensor([64, 194, 64, 64],"float32"),Tensor([64, 194, 64, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 194, 64, 64],"float32"),Tensor([64, 194, 64, 64],"float32"),], ) 	 101711872 	 1000 	 0.4728357791900635 	 1.058032751083374 	 0.4633028507232666 	 0.5406632423400879 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:58.808416 test begin: paddle.add_n(list[Tensor([64, 256, 194, 32],"float16"),Tensor([64, 256, 194, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 256, 194, 32],"float16"),Tensor([64, 256, 194, 32],"float16"),], ) 	 203423744 	 1000 	 0.5739803314208984 	 1.5179779529571533 	 0.5646216869354248 	 0.7755777835845947 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:35:04.613204 test begin: paddle.add_n(list[Tensor([64, 256, 32, 194],"float16"),Tensor([64, 256, 32, 194],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 256, 32, 194],"float16"),Tensor([64, 256, 32, 194],"float16"),], ) 	 203423744 	 1000 	 0.796375036239624 	 2.397514581680298 	 0.5636379718780518 	 0.7750072479248047 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:35:14.772169 test begin: paddle.add_n(list[Tensor([64, 388, 64, 64],"float16"),Tensor([64, 388, 64, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 388, 64, 64],"float16"),Tensor([64, 388, 64, 64],"float16"),], ) 	 203423744 	 1000 	 0.5732846260070801 	 1.5171871185302734 	 0.5637588500976562 	 0.7752013206481934 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:35:20.637337 test begin: paddle.add_n(list[Tensor([97, 128, 64, 64],"float32"),Tensor([97, 128, 64, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([97, 128, 64, 64],"float32"),Tensor([97, 128, 64, 64],"float32"),], ) 	 101711872 	 1000 	 0.47328805923461914 	 1.058152675628662 	 0.46333932876586914 	 0.5407416820526123 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:35:23.865006 test begin: paddle.addmm(Tensor([1016065, 50],"float32"), Tensor([1016065, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([1016065, 50],"float32"), Tensor([1016065, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, ) 	 132092450 	 1000 	 1.0228724479675293 	 0.9917356967926025 	 0.5217452049255371 	 0.33626818656921387 	 2.6764161586761475 	 1.8730394840240479 	 0.3907127380371094 	 0.47789597511291504 	 
2025-07-30 13:35:33.581678 test begin: paddle.addmm(Tensor([30, 1693441],"float32"), Tensor([30, 80],"float32"), Tensor([80, 1693441],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 1693441],"float32"), Tensor([30, 80],"float32"), Tensor([80, 1693441],"float32"), alpha=1.0, beta=2.0, ) 	 186280910 	 1000 	 1.4040732383728027 	 1.153733730316162 	 0.40200304985046387 	 0.29445981979370117 	 3.2182648181915283 	 2.0923454761505127 	 0.4112250804901123 	 0.42748379707336426 	 
2025-07-30 13:35:47.134075 test begin: paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1016065],"float32"), Tensor([1016065, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1016065],"float32"), Tensor([1016065, 50],"float32"), alpha=1.0, beta=2.0, ) 	 81286700 	 1000 	 0.3148488998413086 	 0.31281352043151855 	 0.1073617935180664 	 0.10660648345947266 	 1.090440034866333 	 0.6146683692932129 	 0.18597078323364258 	 0.20933151245117188 	 
2025-07-30 13:35:50.802965 test begin: paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1693441],"float32"), Tensor([1693441, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1693441],"float32"), Tensor([1693441, 50],"float32"), alpha=1.0, beta=2.0, ) 	 135476780 	 1000 	 0.500939130783081 	 0.49431300163269043 	 0.1708660125732422 	 0.16850948333740234 	 1.8294365406036377 	 1.0441901683807373 	 0.2341454029083252 	 0.21394062042236328 	 
2025-07-30 13:35:56.964001 test begin: paddle.addmm(Tensor([30, 635041],"float32"), Tensor([30, 80],"float32"), Tensor([80, 635041],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 635041],"float32"), Tensor([30, 80],"float32"), Tensor([80, 635041],"float32"), alpha=1.0, beta=2.0, ) 	 69856910 	 1000 	 0.42463088035583496 	 0.41643643379211426 	 0.2167961597442627 	 0.14182257652282715 	 1.2193796634674072 	 0.7925107479095459 	 0.17799091339111328 	 0.20250844955444336 	 
2025-07-30 13:36:01.309475 test begin: paddle.addmm(Tensor([635041, 50],"float32"), Tensor([635041, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([635041, 50],"float32"), Tensor([635041, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, ) 	 82559330 	 1000 	 0.6479105949401855 	 0.6300325393676758 	 0.33095431327819824 	 0.21456336975097656 	 1.6911163330078125 	 1.1819095611572266 	 0.24688267707824707 	 0.30150866508483887 	 
2025-07-30 13:36:07.312589 test begin: paddle.addmm(input=Tensor([5, 5],"float64"), x=Tensor([5, 5080321],"float64"), y=Tensor([5080321, 5],"float64"), )
[Prof] paddle.addmm 	 paddle.addmm(input=Tensor([5, 5],"float64"), x=Tensor([5, 5080321],"float64"), y=Tensor([5080321, 5],"float64"), ) 	 50803235 	 1000 	 0.6179285049438477 	 0.6213572025299072 	 0.21068811416625977 	 0.2118988037109375 	 3.0025620460510254 	 2.5319762229919434 	 0.21915364265441895 	 0.25876379013061523 	 
2025-07-30 13:36:15.533103 test begin: paddle.all(Tensor([423361, 6, 10],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([423361, 6, 10],"float64"), None, False, None, ) 	 25401660 	 1000 	 0.20050978660583496 	 0.15038394927978516 	 0.0681910514831543 	 0.07681536674499512 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:18.108376 test begin: paddle.all(Tensor([5, 508033, 10],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 508033, 10],"float64"), None, False, None, ) 	 25401650 	 1000 	 0.2004857063293457 	 0.15039849281311035 	 0.0681910514831543 	 0.07685232162475586 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:18.972892 test begin: paddle.all(Tensor([5, 6, 846721],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 6, 846721],"float64"), None, False, None, ) 	 25401630 	 1000 	 0.20194125175476074 	 0.1503608226776123 	 0.06869673728942871 	 0.07679963111877441 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:19.842297 test begin: paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, ) 	 508032500 	 1000 	 0.46431970596313477 	 0.507326602935791 	 0.2370738983154297 	 0.2592506408691406 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:27.975176 test begin: paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, ) 	 508032300 	 1000 	 0.46383142471313477 	 0.5071103572845459 	 0.2369709014892578 	 0.2591080665588379 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:37.472475 test begin: paddle.all(Tensor([508032010],"bool"), )
[Prof] paddle.all 	 paddle.all(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.4667353630065918 	 0.5071330070495605 	 0.23845458030700684 	 0.2591433525085449 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:45.360445 test begin: paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, ) 	 508032600 	 1000 	 0.4650299549102783 	 0.5083193778991699 	 0.23705053329467773 	 0.25974583625793457 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:54.961566 test begin: paddle.allclose(Tensor([1124, 45199],"float32"), Tensor([1124, 45199],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([1124, 45199],"float32"), Tensor([1124, 45199],"float32"), ) 	 101607352 	 1000 	 1.0326695442199707 	 3.411430835723877 	 1.0216071605682373 	 0.00019860267639160156 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:01.106816 test begin: paddle.allclose(Tensor([13, 32, 122124],"float32"), Tensor([13, 32, 122124],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([13, 32, 122124],"float32"), Tensor([13, 32, 122124],"float32"), rtol=0.0001, atol=0.0001, ) 	 101607168 	 1000 	 1.0476443767547607 	 3.413454294204712 	 1.035290241241455 	 0.00015044212341308594 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:07.177617 test begin: paddle.allclose(Tensor([13, 61062, 64],"float32"), Tensor([13, 61062, 64],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([13, 61062, 64],"float32"), Tensor([13, 61062, 64],"float32"), rtol=0.0001, atol=0.0001, ) 	 101607168 	 1000 	 1.0482521057128906 	 3.4129366874694824 	 1.0365467071533203 	 7.581710815429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:13.249637 test begin: paddle.allclose(Tensor([1587601, 32],"float32"), Tensor([1587601, 32],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([1587601, 32],"float32"), Tensor([1587601, 32],"float32"), ) 	 101606464 	 1000 	 1.0406908988952637 	 3.4252078533172607 	 1.0222203731536865 	 0.00026702880859375 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:21.034143 test begin: paddle.allclose(Tensor([24807, 32, 64],"float32"), Tensor([24807, 32, 64],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([24807, 32, 64],"float32"), Tensor([24807, 32, 64],"float32"), rtol=0.0001, atol=0.0001, ) 	 101609472 	 1000 	 1.0554149150848389 	 3.4074206352233887 	 1.0437159538269043 	 0.00024962425231933594 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:27.152696 test begin: paddle.allclose(Tensor([30522, 1665],"float32"), Tensor([30522, 1665],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([30522, 1665],"float32"), Tensor([30522, 1665],"float32"), ) 	 101638260 	 1000 	 1.0341107845306396 	 3.4043402671813965 	 1.0228066444396973 	 0.00010704994201660156 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:33.219569 test begin: paddle.allclose(Tensor([6350401, 8],"float32"), Tensor([6350401, 8],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([6350401, 8],"float32"), Tensor([6350401, 8],"float32"), ) 	 101606416 	 1000 	 1.0402507781982422 	 3.4061601161956787 	 1.0290579795837402 	 7.343292236328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:41.440932 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22696471214294434 	 0.17805957794189453 	 0.11596417427062988 	 0.09097075462341309 	 1.1106352806091309 	 1.3109967708587646 	 0.2271115779876709 	 0.22318434715270996 	 
2025-07-30 13:37:45.176230 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.24258685111999512 	 0.20054006576538086 	 0.12394285202026367 	 0.10243654251098633 	 1.1240417957305908 	 1.3558926582336426 	 0.22988271713256836 	 0.23080968856811523 	 
2025-07-30 13:37:48.917446 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 0.19698166847229004 	 0.16269183158874512 	 0.18575334548950195 	 0.14509201049804688 	 1.0920946598052979 	 1.287820816040039 	 0.27899742126464844 	 0.2630188465118408 	 
2025-07-30 13:37:52.489208 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22704148292541504 	 0.1780860424041748 	 0.11600852012634277 	 0.09102725982666016 	 1.1105422973632812 	 1.3109486103057861 	 0.22710537910461426 	 0.2231290340423584 	 
2025-07-30 13:37:56.118817 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.5704002380371094 	 0.4523031711578369 	 0.5578079223632812 	 0.43697333335876465 	 1.3091986179351807 	 1.4591152667999268 	 0.33443379402160645 	 0.2980067729949951 	 
2025-07-30 13:38:00.748172 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.950461387634277 	 0.1661674976348877 	 3.040658473968506 	 0.0849008560180664 	 5.894082069396973 	 1.2912135124206543 	 1.202949047088623 	 0.2197432518005371 	 
2025-07-30 13:38:14.908938 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.43940210342407227 	 0.2877166271209717 	 0.42774152755737305 	 0.2724153995513916 	 1.1772058010101318 	 1.3109796047210693 	 0.30074620246887207 	 0.26772093772888184 	 
2025-07-30 13:38:18.933883 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.25866270065307617 	 0.2155759334564209 	 0.1321697235107422 	 0.11022210121154785 	 1.135655164718628 	 1.4220762252807617 	 0.2322099208831787 	 0.24210476875305176 	 
2025-07-30 13:38:22.806204 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.9506449699401855 	 0.16614818572998047 	 3.040827751159668 	 0.08484506607055664 	 5.940761089324951 	 1.2914845943450928 	 1.249420166015625 	 0.21984004974365234 	 
2025-07-30 13:38:39.852317 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22704339027404785 	 0.17818307876586914 	 0.11599421501159668 	 0.09107160568237305 	 1.110718011856079 	 1.3111541271209717 	 0.22711777687072754 	 0.22329330444335938 	 
2025-07-30 13:38:43.577739 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.2424793243408203 	 0.20063376426696777 	 0.12387371063232422 	 0.10247659683227539 	 1.1241281032562256 	 1.356006145477295 	 0.22981524467468262 	 0.2307736873626709 	 
2025-07-30 13:38:47.307608 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 0.19693732261657715 	 0.16016674041748047 	 0.18548250198364258 	 0.14545130729675293 	 1.092221736907959 	 1.287890911102295 	 0.2791011333465576 	 0.26303672790527344 	 
2025-07-30 13:38:50.884452 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22698020935058594 	 0.1780390739440918 	 0.11596512794494629 	 0.09094119071960449 	 1.1106038093566895 	 1.3112788200378418 	 0.22714495658874512 	 0.22319650650024414 	 
2025-07-30 13:38:54.551331 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.5706133842468262 	 0.4524986743927002 	 0.5497641563415527 	 0.43021464347839355 	 1.3092982769012451 	 1.4593040943145752 	 0.33440089225769043 	 0.29804205894470215 	 
2025-07-30 13:38:59.163311 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.950754404067993 	 0.16620612144470215 	 3.040889024734497 	 0.08486270904541016 	 5.894318103790283 	 1.2911441326141357 	 1.2030389308929443 	 0.21975922584533691 	 
2025-07-30 13:39:13.333973 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.4394869804382324 	 0.28775501251220703 	 0.4194343090057373 	 0.2655506134033203 	 1.1773242950439453 	 1.3111882209777832 	 0.300736665725708 	 0.2678408622741699 	 
2025-07-30 13:39:17.387585 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.2586240768432617 	 0.21583032608032227 	 0.1321561336517334 	 0.11016249656677246 	 1.1356987953186035 	 1.4219086170196533 	 0.23219776153564453 	 0.2420520782470703 	 
2025-07-30 13:39:21.234988 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.950610876083374 	 0.16622114181518555 	 3.040822982788086 	 0.08490252494812012 	 5.894282341003418 	 1.2914831638336182 	 1.202970266342163 	 0.21990633010864258 	 
2025-07-30 13:39:37.579231 test begin: paddle.any(Tensor([10, 12404, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 12404, 4096],"bool"), ) 	 508067840 	 1000 	 0.4659271240234375 	 0.5287418365478516 	 0.23748254776000977 	 0.27016758918762207 	 None 	 None 	 None 	 None 	 
2025-07-30 13:39:46.116499 test begin: paddle.any(Tensor([10, 300, 169345],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 300, 169345],"bool"), ) 	 508035000 	 1000 	 0.4649977684020996 	 0.5285623073577881 	 0.23760056495666504 	 0.2700769901275635 	 None 	 None 	 None 	 None 	 
2025-07-30 13:39:54.132326 test begin: paddle.any(Tensor([11240, 45199],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([11240, 45199],"bool"), ) 	 508036760 	 1000 	 0.46338844299316406 	 0.528773307800293 	 0.23676180839538574 	 0.27021026611328125 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:01.973101 test begin: paddle.any(Tensor([15876010, 32],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.4666604995727539 	 0.5284950733184814 	 0.23848867416381836 	 0.2700228691101074 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:11.336805 test begin: paddle.any(Tensor([420, 300, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([420, 300, 4096],"bool"), ) 	 516096000 	 1000 	 0.47251057624816895 	 0.540156364440918 	 0.24087119102478027 	 0.27600884437561035 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:19.373795 test begin: paddle.any(Tensor([5120, 99226],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([5120, 99226],"bool"), ) 	 508037120 	 1000 	 0.4661736488342285 	 0.5279049873352051 	 0.2381880283355713 	 0.2697303295135498 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:27.191159 test begin: paddle.argmax(Tensor([15877, 100, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([15877, 100, 32],"float32"), axis=1, ) 	 50806400 	 1000 	 0.7608737945556641 	 0.1827857494354248 	 0.7505595684051514 	 0.16904520988464355 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:28.949222 test begin: paddle.argmax(Tensor([29151, 100, 18],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 100, 18],"float32"), axis=1, ) 	 52471800 	 1000 	 0.6403124332427979 	 0.17416977882385254 	 0.6300981044769287 	 0.16045236587524414 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:30.590721 test begin: paddle.argmax(Tensor([29151, 28, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 28, 64],"float32"), axis=1, ) 	 52238592 	 1000 	 1.5028843879699707 	 0.18255233764648438 	 1.4927129745483398 	 0.1620931625366211 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:33.146909 test begin: paddle.argmax(Tensor([29151, 55, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 55, 32],"float32"), axis=1, ) 	 51305760 	 1000 	 0.7544753551483154 	 0.17173981666564941 	 0.7442951202392578 	 0.15449166297912598 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:34.907346 test begin: paddle.argmax(Tensor([39691, 20, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([39691, 20, 64],"float32"), axis=1, ) 	 50804480 	 1000 	 2.0447468757629395 	 0.19013404846191406 	 2.0344929695129395 	 0.16237497329711914 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:38.111371 test begin: paddle.argmax(Tensor([7939, 100, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([7939, 100, 64],"float32"), axis=1, ) 	 50809600 	 1000 	 0.7593960762023926 	 0.18021941184997559 	 0.7492461204528809 	 0.1661996841430664 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:41.564314 test begin: paddle.argmax(Tensor([80239, 10, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([80239, 10, 64],"float32"), axis=1, ) 	 51352960 	 1000 	 4.1291749477386475 	 0.20070409774780273 	 4.111418008804321 	 0.1821727752685547 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:47.709126 test begin: paddle.argmax(Tensor([80239, 20, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([80239, 20, 32],"float32"), axis=1, ) 	 51352960 	 1000 	 2.0665886402130127 	 0.1775667667388916 	 2.0563955307006836 	 0.163726806640625 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:50.862571 test begin: paddle.argmin(Tensor([104534, 3, 3, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([104534, 3, 3, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 0.4769587516784668 	 0.16069602966308594 	 0.45856809616088867 	 0.08205723762512207 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:52.031852 test begin: paddle.argmin(Tensor([203213, 5, 5, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([203213, 5, 5, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 0.48177623748779297 	 0.16259407997131348 	 0.47142958641052246 	 0.08303141593933105 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:53.186328 test begin: paddle.argmin(Tensor([3, 104534, 3, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 104534, 3, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805697917938232 	 0.20352506637573242 	 6.795068979263306 	 0.18844985961914062 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:00.767674 test begin: paddle.argmin(Tensor([3, 3, 104534, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 104534, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805431365966797 	 1.1003267765045166 	 6.794414043426514 	 0.18851733207702637 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:10.328280 test begin: paddle.argmin(Tensor([3, 3, 3, 104534, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 104534, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805484056472778 	 0.2035384178161621 	 6.794983863830566 	 0.18862104415893555 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:17.915007 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 104534, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 3, 104534, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805670261383057 	 0.2035064697265625 	 6.795109033584595 	 0.18845629692077637 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:25.496550 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 3, 104534],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 3, 3, 104534],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805541753768921 	 0.21655821800231934 	 6.794990539550781 	 0.18857765197753906 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:33.085105 test begin: paddle.argmin(Tensor([4, 4, 4, 4, 99226],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 4, 4, 99226],"float64"), axis=0, ) 	 25401856 	 1000 	 5.105066299438477 	 1.055316686630249 	 5.094486713409424 	 0.1766066551208496 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:40.958517 test begin: paddle.argmin(Tensor([4, 4, 4, 99226, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 4, 99226, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.105095148086548 	 0.19445490837097168 	 5.094162940979004 	 0.17674827575683594 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:46.801588 test begin: paddle.argmin(Tensor([4, 4, 99226, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 99226, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.10496711730957 	 0.1986551284790039 	 5.094440221786499 	 0.17672038078308105 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:53.622672 test begin: paddle.argmin(Tensor([4, 99226, 4, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 99226, 4, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.105154991149902 	 0.191117525100708 	 5.094575881958008 	 0.1768169403076172 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:59.488079 test begin: paddle.argmin(Tensor([5, 203213, 5, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 203213, 5, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 4.084763288497925 	 0.20169425010681152 	 4.0662682056427 	 0.17516851425170898 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:04.561018 test begin: paddle.argmin(Tensor([5, 5, 203213, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 5, 203213, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 4.084873199462891 	 0.19632244110107422 	 4.074365854263306 	 0.18209147453308105 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:09.438856 test begin: paddle.argmin(Tensor([5, 5, 5, 203213],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 5, 5, 203213],"float64"), axis=0, ) 	 25401625 	 1000 	 4.084863662719727 	 0.1999375820159912 	 4.0736939907073975 	 0.1823430061340332 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:14.312435 test begin: paddle.argmin(Tensor([99226, 4, 4, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([99226, 4, 4, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 0.4404728412628174 	 0.32351112365722656 	 0.4301304817199707 	 0.1653604507446289 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:15.597833 test begin: paddle.argsort(Tensor([25401601],"float64"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([25401601],"float64"), stable=True, ) 	 25401601 	 1000 	 10.413621425628662 	 7.5010175704956055 	 8.726119995117188e-05 	 0.3342452049255371 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:42:40.434629 test begin: paddle.argsort(Tensor([50803201],"float32"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([50803201],"float32"), stable=True, ) 	 50803201 	 1000 	 20.171658515930176 	 7.859429597854614 	 9.894371032714844e-05 	 0.5361158847808838 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:43:18.878670 test begin: paddle.argsort(Tensor([50803201],"int32"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([50803201],"int32"), stable=True, ) 	 50803201 	 1000 	 20.549911737442017 	 7.215855121612549 	 9.942054748535156e-05 	 0.4919464588165283 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:43:56.646958 test begin: paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.003042459487915039 	 0.004391670227050781 	 1.2636184692382812e-05 	 1.8835067749023438e-05 	 0.039047956466674805 	 0.0589296817779541 	 1.6450881958007812e-05 	 3.62396240234375e-05 	 
2025-07-30 13:44:10.776847 test begin: paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.0030210018157958984 	 0.004590749740600586 	 1.0728836059570312e-05 	 4.076957702636719e-05 	 0.04049944877624512 	 0.06505250930786133 	 3.266334533691406e-05 	 4.9591064453125e-05 	 
2025-07-30 13:44:24.536707 test begin: paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), ) 	 508108800 	 1000 	 0.0030570030212402344 	 0.008306503295898438 	 1.0728836059570312e-05 	 2.193450927734375e-05 	 0.04639744758605957 	 0.06828594207763672 	 3.1948089599609375e-05 	 6.890296936035156e-05 	 
2025-07-30 13:44:40.868040 test begin: paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), ) 	 508559360 	 1000 	 0.0038123130798339844 	 0.004456996917724609 	 3.5762786865234375e-05 	 1.9073486328125e-05 	 0.03928375244140625 	 0.05876731872558594 	 2.09808349609375e-05 	 4.5299530029296875e-05 	 
2025-07-30 13:44:54.186476 test begin: paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), ) 	 508108800 	 1000 	 0.0029942989349365234 	 0.0045680999755859375 	 7.3909759521484375e-06 	 3.24249267578125e-05 	 0.0391535758972168 	 0.05825924873352051 	 1.8596649169921875e-05 	 3.504753112792969e-05 	 
2025-07-30 13:45:11.277462 test begin: paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.022374391555786133 	 0.010828733444213867 	 1.8835067749023438e-05 	 5.7697296142578125e-05 	 1.5023515224456787 	 1.3140618801116943 	 0.7672114372253418 	 0.6712925434112549 	 
2025-07-30 13:45:22.544314 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.017308712005615234 	 0.007962465286254883 	 1.33514404296875e-05 	 2.1696090698242188e-05 	 1.5136754512786865 	 1.3147640228271484 	 0.7730317115783691 	 0.6715817451477051 	 
2025-07-30 13:45:44.951892 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.01724863052368164 	 0.004567861557006836 	 1.2874603271484375e-05 	 2.002716064453125e-05 	 1.5142366886138916 	 1.3155488967895508 	 0.7733633518218994 	 0.6720154285430908 	 
2025-07-30 13:46:13.164401 test begin: paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.022367000579833984 	 0.00806283950805664 	 1.2159347534179688e-05 	 2.0742416381835938e-05 	 1.5006725788116455 	 1.3141310214996338 	 0.7671699523925781 	 0.6711831092834473 	 
2025-07-30 13:46:24.090462 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.01722431182861328 	 0.004523038864135742 	 1.3589859008789062e-05 	 2.2172927856445312e-05 	 1.513793706893921 	 1.3147046566009521 	 0.7735106945037842 	 0.6714198589324951 	 
2025-07-30 13:46:46.288386 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.02268362045288086 	 0.008155345916748047 	 1.239776611328125e-05 	 2.6941299438476562e-05 	 1.5121984481811523 	 1.3157284259796143 	 0.7732913494110107 	 0.6721601486206055 	 
2025-07-30 13:47:08.247332 test begin: paddle.asin(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2953453063964844 	 0.2976219654083252 	 0.2790205478668213 	 0.28692007064819336 	 0.45011448860168457 	 1.7828986644744873 	 0.39490389823913574 	 0.3644711971282959 	 
2025-07-30 13:47:12.797854 test begin: paddle.asin(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2954282760620117 	 0.2975127696990967 	 0.28691911697387695 	 0.2867581844329834 	 0.45041680335998535 	 1.782958984375 	 0.39644455909729004 	 0.36444592475891113 	 
2025-07-30 13:47:17.316069 test begin: paddle.asin(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29546427726745605 	 1.4874255657196045 	 0.28682804107666016 	 0.28653931617736816 	 0.4502995014190674 	 1.7832458019256592 	 0.3964242935180664 	 0.3645663261413574 	 
2025-07-30 13:47:25.061197 test begin: paddle.asinh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.3010077476501465 	 0.30042481422424316 	 0.2923624515533447 	 0.28908324241638184 	 0.45030856132507324 	 1.3379409313201904 	 0.3956003189086914 	 0.34183239936828613 	 
2025-07-30 13:47:29.100950 test begin: paddle.asinh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.3010871410369873 	 0.30040979385375977 	 0.29256629943847656 	 0.28960418701171875 	 0.4506103992462158 	 1.3377270698547363 	 0.39646196365356445 	 0.3418424129486084 	 
2025-07-30 13:47:33.028450 test begin: paddle.asinh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.30118870735168457 	 1.6992557048797607 	 0.29268360137939453 	 0.2883627414703369 	 0.4505276679992676 	 1.3378074169158936 	 0.39101386070251465 	 0.341841459274292 	 
2025-07-30 13:47:41.224413 test begin: paddle.atan(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29764413833618164 	 0.2976813316345215 	 0.2887260913848877 	 0.28659820556640625 	 0.45016956329345703 	 1.043091058731079 	 0.39664459228515625 	 0.35537075996398926 	 
2025-07-30 13:47:44.850164 test begin: paddle.atan(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29778504371643066 	 0.2975890636444092 	 0.28903651237487793 	 0.28695058822631836 	 0.4504997730255127 	 1.0430755615234375 	 0.39734673500061035 	 0.3554081916809082 	 
2025-07-30 13:47:48.556693 test begin: paddle.atan(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29781055450439453 	 0.29762887954711914 	 0.28896474838256836 	 0.2867708206176758 	 0.45038580894470215 	 1.043088674545288 	 0.3958625793457031 	 0.3553273677825928 	 
2025-07-30 13:47:52.215966 test begin: paddle.atan2(Tensor([100],"float64"), Tensor([254017, 100],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([100],"float64"), Tensor([254017, 100],"float64"), ) 	 25401800 	 1000 	 0.8809731006622314 	 0.31305551528930664 	 0.3002285957336426 	 0.30058908462524414 	 1.6831412315368652 	 2.743278980255127 	 0.34363460540771484 	 0.2547640800476074 	 
2025-07-30 13:47:58.801621 test begin: paddle.atan2(Tensor([111, 222, 1031],"float64"), Tensor([222, 1031],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([111, 222, 1031],"float64"), Tensor([222, 1031],"float64"), ) 	 25634784 	 1000 	 0.8820199966430664 	 0.31742024421691895 	 0.3005096912384033 	 0.29695844650268555 	 1.234055757522583 	 2.9871270656585693 	 0.31476688385009766 	 0.3052852153778076 	 
2025-07-30 13:48:05.278502 test begin: paddle.atan2(Tensor([111, 688, 333],"float64"), Tensor([688, 333],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([111, 688, 333],"float64"), Tensor([688, 333],"float64"), ) 	 25659648 	 1000 	 0.8829371929168701 	 0.3167438507080078 	 0.30072903633117676 	 0.2976844310760498 	 1.2281181812286377 	 2.993781328201294 	 0.31334710121154785 	 0.3059577941894531 	 
2025-07-30 13:48:11.787279 test begin: paddle.atan2(Tensor([344, 222, 333],"float64"), Tensor([222, 333],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([344, 222, 333],"float64"), Tensor([222, 333],"float64"), ) 	 25504470 	 1000 	 0.8801488876342773 	 0.3164541721343994 	 0.2998354434967041 	 0.3036000728607178 	 1.3137834072113037 	 2.985250473022461 	 0.33523035049438477 	 0.3050863742828369 	 
2025-07-30 13:48:18.321839 test begin: paddle.atan2(x=Tensor([19601, 6, 6, 6, 6],"float64"), y=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([19601, 6, 6, 6, 6],"float64"), y=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 50805792 	 1000 	 0.4455990791320801 	 0.45597314834594727 	 0.43562817573547363 	 0.44173097610473633 	 0.7327871322631836 	 3.409167766571045 	 0.6749429702758789 	 0.3872542381286621 	 
2025-07-30 13:48:24.990634 test begin: paddle.atan2(x=Tensor([3, 39201, 6, 6, 6],"float64"), y=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 39201, 6, 6, 6],"float64"), y=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 50804496 	 1000 	 0.4454686641693115 	 0.4562852382659912 	 0.42752623558044434 	 0.4353804588317871 	 0.7330048084259033 	 3.4080886840820312 	 0.6659162044525146 	 0.38712239265441895 	 
2025-07-30 13:48:34.844223 test begin: paddle.atan2(x=Tensor([3, 6, 39201, 6, 6],"float64"), y=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 39201, 6, 6],"float64"), y=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 50804496 	 1000 	 0.44544482231140137 	 0.46112608909606934 	 0.4351935386657715 	 0.4415707588195801 	 0.7330074310302734 	 3.4081642627716064 	 0.6744353771209717 	 0.38718533515930176 	 
2025-07-30 13:48:43.612235 test begin: paddle.atan2(x=Tensor([3, 6, 6, 39201, 6],"float64"), y=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 6, 39201, 6],"float64"), y=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 50804496 	 1000 	 0.4454987049102783 	 0.4536120891571045 	 0.4277973175048828 	 0.4354896545410156 	 0.7329831123352051 	 3.408182382583618 	 0.6662309169769287 	 0.38713717460632324 	 
2025-07-30 13:48:50.304276 test begin: paddle.atan2(x=Tensor([3, 6, 6, 6, 39201],"float64"), y=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 6, 6, 39201],"float64"), y=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 50804496 	 1000 	 0.4454653263092041 	 0.4536271095275879 	 0.4278852939605713 	 0.43557190895080566 	 0.7329678535461426 	 3.408142328262329 	 0.6641426086425781 	 0.38715505599975586 	 
2025-07-30 13:48:56.920726 test begin: paddle.atanh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2967956066131592 	 0.29824066162109375 	 0.28098273277282715 	 0.2810182571411133 	 0.4500589370727539 	 1.6222765445709229 	 0.3862135410308838 	 0.3317084312438965 	 
2025-07-30 13:49:01.205012 test begin: paddle.atanh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2969176769256592 	 0.29826903343200684 	 0.28109097480773926 	 0.28116798400878906 	 0.45018649101257324 	 1.6222097873687744 	 0.38726186752319336 	 0.3315901756286621 	 
2025-07-30 13:49:05.506486 test begin: paddle.atanh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2969343662261963 	 0.298220157623291 	 0.28038454055786133 	 0.2810962200164795 	 0.4503786563873291 	 1.622290849685669 	 0.38748621940612793 	 0.3316841125488281 	 
2025-07-30 13:50:02.410283 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
W0730 13:50:48.966913 10235 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003026723861694336 	 0.00862574577331543 	 2.3126602172851562e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:51:01.062006 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0028200149536132812 	 0.007351875305175781 	 7.62939453125e-06 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:51:54.583780 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0016856193542480469 	 0.006240367889404297 	 1.3113021850585938e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:53:47.269476 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
W0730 13:54:30.656672 11765 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.0029082298278808594 	 0.012462139129638672 	 1.3589859008789062e-05 	 6.532669067382812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:54:47.340084 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0028073787689208984 	 0.007531881332397461 	 1.2636184692382812e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:40.196205 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0028069019317626953 	 0.0096588134765625 	 1.3113021850585938e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:40.910157 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.002791881561279297 	 0.007498025894165039 	 1.8358230590820312e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:56:28.207885 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0027484893798828125 	 0.007571220397949219 	 8.821487426757812e-06 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:25.395163 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0028166770935058594 	 0.007541656494140625 	 5.9604644775390625e-06 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:26.096275 test begin: paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0027573108673095703 	 0.007622957229614258 	 7.152557373046875e-06 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:58:14.293542 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.002742767333984375 	 0.01276087760925293 	 1.0013580322265625e-05 	 8.0108642578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:59:25.864878 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0043103694915771484 	 0.0075626373291015625 	 2.765655517578125e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:00:38.976971 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.0027315616607666016 	 0.007956266403198242 	 7.867813110351562e-06 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:01:42.371627 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0027434825897216797 	 0.00811147689819336 	 7.152557373046875e-06 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:01:44.698359 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.002948284149169922 	 0.010386943817138672 	 9.5367431640625e-06 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:02:55.532688 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.002872467041015625 	 0.007337093353271484 	 1.0728836059570312e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:02:56.233284 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.001622915267944336 	 0.008508920669555664 	 6.4373016357421875e-06 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:09.254887 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0027968883514404297 	 0.007483720779418945 	 1.0967254638671875e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:57.755419 test begin: paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.002841472625732422 	 0.007483720779418945 	 7.62939453125e-06 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:05:46.291507 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0015902519226074219 	 0.00634455680847168 	 7.62939453125e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:06:34.948674 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.002879619598388672 	 0.0075626373291015625 	 7.62939453125e-06 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:23.530505 test begin: paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0028951168060302734 	 0.007539033889770508 	 1.3589859008789062e-05 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:24.162377 test begin: paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.002797365188598633 	 0.007600545883178711 	 8.344650268554688e-06 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:29.973353 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0028617382049560547 	 0.0074005126953125 	 7.152557373046875e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:30.604495 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0016429424285888672 	 0.006401538848876953 	 8.821487426757812e-06 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:09:34.333513 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.002865314483642578 	 0.0074880123138427734 	 1.0013580322265625e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:10:22.627855 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.003798961639404297 	 0.007364034652709961 	 8.58306884765625e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:11:11.308036 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0037679672241210938 	 0.0075414180755615234 	 7.62939453125e-06 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:04.702297 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003686666488647461 	 0.00748896598815918 	 1.0728836059570312e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:52.985009 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003690481185913086 	 0.00762939453125 	 1.0967254638671875e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:13:41.155597 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0019061565399169922 	 0.006520271301269531 	 6.9141387939453125e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:29.466063 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.0038309097290039062 	 0.0077855587005615234 	 1.049041748046875e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:15:17.670672 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.003879547119140625 	 0.00745391845703125 	 1.0967254638671875e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:16:19.779400 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.0038309097290039062 	 0.007569074630737305 	 1.0728836059570312e-05 	 3.218650817871094e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:10.558348 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.0038437843322753906 	 0.007562160491943359 	 7.62939453125e-06 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:59.508008 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.003823518753051758 	 0.007467508316040039 	 7.867813110351562e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:48.255948 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0037877559661865234 	 0.00749516487121582 	 6.67572021484375e-06 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:48.965821 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.003819704055786133 	 0.007556438446044922 	 8.821487426757812e-06 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:41.065632 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0038080215454101562 	 0.008547544479370117 	 5.7220458984375e-06 	 7.414817810058594e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:20:30.052154 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0038690567016601562 	 0.0075054168701171875 	 1.4543533325195312e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:20:30.746147 test begin: paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0037877559661865234 	 0.00757288932800293 	 1.049041748046875e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:21:18.737538 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0037965774536132812 	 0.007424831390380859 	 9.059906005859375e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:22:07.645418 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0037779808044433594 	 0.0074841976165771484 	 7.62939453125e-06 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:22:56.776311 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.004076719284057617 	 0.007511615753173828 	 2.0503997802734375e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:23:46.075834 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003785848617553711 	 0.0075168609619140625 	 5.9604644775390625e-06 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:23:46.785916 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.003828287124633789 	 0.007536649703979492 	 7.867813110351562e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:24:35.331001 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0037865638732910156 	 0.010484933853149414 	 1.1920928955078125e-05 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:24:37.285848 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.001890420913696289 	 0.006985902786254883 	 7.867813110351562e-06 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:25:25.306695 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0038077831268310547 	 0.007455348968505859 	 1.049041748046875e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:26:13.597842 test begin: paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0037620067596435547 	 0.007590770721435547 	 8.106231689453125e-06 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:27:16.071042 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.0018777847290039062 	 0.007015705108642578 	 1.049041748046875e-05 	 5.364418029785156e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:04.801703 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0038514137268066406 	 0.00746917724609375 	 7.62939453125e-06 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:52.903526 test begin: paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004157304763793945 	 0.007546186447143555 	 4.0531158447265625e-05 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:53.538364 test begin: paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003695249557495117 	 0.007687091827392578 	 1.1205673217773438e-05 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:42.129416 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.00380706787109375 	 0.0075342655181884766 	 8.344650268554688e-06 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:42.763439 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.001932382583618164 	 0.006380319595336914 	 1.1682510375976562e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:30.745405 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.005171537399291992 	 0.007429838180541992 	 2.6464462280273438e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:19.940938 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004754543304443359 	 0.0075206756591796875 	 1.239776611328125e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:32:08.243484 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004708290100097656 	 0.007532835006713867 	 9.059906005859375e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:32:56.163397 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.004634380340576172 	 0.007551431655883789 	 9.059906005859375e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:33:44.328962 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.004632234573364258 	 0.007670164108276367 	 7.3909759521484375e-06 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:34:35.241225 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0021822452545166016 	 0.0063495635986328125 	 9.5367431640625e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:35:23.620115 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.00475764274597168 	 0.007466316223144531 	 1.0013580322265625e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:36:12.142564 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.004792690277099609 	 0.007309675216674805 	 7.3909759521484375e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:37:00.886134 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.0047795772552490234 	 0.0075817108154296875 	 7.62939453125e-06 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:37:50.274974 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.004743099212646484 	 0.007384300231933594 	 7.152557373046875e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:38:42.328103 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004743814468383789 	 0.007371187210083008 	 6.4373016357421875e-06 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:39:31.209226 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0047795772552490234 	 0.007586956024169922 	 7.62939453125e-06 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:39:31.922808 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.004724740982055664 	 0.013458967208862305 	 9.059906005859375e-06 	 6.413459777832031e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:40:20.623365 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0048139095306396484 	 0.0074615478515625 	 1.049041748046875e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:41:11.196796 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004702091217041016 	 0.007521867752075195 	 1.0013580322265625e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:41:11.923597 test begin: paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.004705905914306641 	 0.0075070858001708984 	 7.152557373046875e-06 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:41:59.348116 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.005300760269165039 	 0.007310152053833008 	 2.7894973754882812e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:42:47.513475 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.006667613983154297 	 0.0075359344482421875 	 2.5510787963867188e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:43:38.778014 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.004724740982055664 	 0.007379293441772461 	 1.1444091796875e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:44:27.452824 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004649162292480469 	 0.008169174194335938 	 7.3909759521484375e-06 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:44:28.163466 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.004657268524169922 	 0.007580280303955078 	 6.198883056640625e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:45:16.311114 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0046346187591552734 	 0.007295846939086914 	 1.1205673217773438e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:45:17.032642 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.002409219741821289 	 0.00636601448059082 	 1.71661376953125e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:46:04.606576 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.004796028137207031 	 0.007387638092041016 	 1.0013580322265625e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:46:52.765995 test begin: paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0047032833099365234 	 0.007508277893066406 	 1.0251998901367188e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:47:43.535098 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.002188444137573242 	 0.006335735321044922 	 1.2159347534179688e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:32.331406 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004782199859619141 	 0.007746219635009766 	 7.152557373046875e-06 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:20.970725 test begin: paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004652261734008789 	 0.0074863433837890625 	 5.7220458984375e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:21.600834 test begin: paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0045626163482666016 	 0.0075588226318359375 	 1.1205673217773438e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:50:09.884739 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.00481414794921875 	 0.007530927658081055 	 1.1444091796875e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:50:10.516593 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.004487037658691406 	 0.0063550472259521484 	 5.054473876953125e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:50:58.928116 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004716634750366211 	 0.007548093795776367 	 9.775161743164062e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:51:46.941970 test begin: paddle.bincount(Tensor([25401601],"int64"), minlength=Tensor([1],"int32"), )
[Prof] paddle.bincount 	 paddle.bincount(Tensor([25401601],"int64"), minlength=Tensor([1],"int32"), ) 	 25401602 	 1000 	 0.9959826469421387 	 0.8314177989959717 	 0.0005123615264892578 	 0.0004696846008300781 	 None 	 None 	 None 	 None 	 
2025-07-30 14:51:49.348172 test begin: paddle.bincount(Tensor([50803201],"int32"), weights=Tensor([50803201],"float32"), )
[Prof] paddle.bincount 	 paddle.bincount(Tensor([50803201],"int32"), weights=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 1.8145592212677002 	 1.438338041305542 	 0.0010716915130615234 	 0.001073598861694336 	 None 	 None 	 None 	 None 	 
2025-07-30 14:51:54.021994 test begin: paddle.bincount(x=Tensor([50803201],"int32"), weights=Tensor([50803201],"int32"), )
[Prof] paddle.bincount 	 paddle.bincount(x=Tensor([50803201],"int32"), weights=Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.7913243770599365 	 1.8007071018218994 	 0.0010523796081542969 	 0.0009539127349853516 	 None 	 None 	 None 	 None 	 
2025-07-30 14:51:58.839036 test begin: paddle.bitwise_and(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44864511489868164 	 0.44992804527282715 	 0.43991541862487793 	 0.438091516494751 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:01.734923 test begin: paddle.bitwise_and(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44848179817199707 	 0.4499180316925049 	 0.43975353240966797 	 0.4380519390106201 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:04.602711 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44824671745300293 	 0.45045971870422363 	 0.43955326080322266 	 0.4358706474304199 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:07.411783 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.4487128257751465 	 0.449953556060791 	 0.4399406909942627 	 0.4361605644226074 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:10.297114 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11853766441345215 	 0.11975622177124023 	 0.10989737510681152 	 0.10463094711303711 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:11.995833 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.44978833198547363 	 0.4462134838104248 	 0.4410583972930908 	 0.4345409870147705 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:14.026055 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.44814491271972656 	 0.4499061107635498 	 0.4394562244415283 	 0.43798303604125977 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:16.897348 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.17789125442504883 	 0.22742104530334473 	 0.16817069053649902 	 0.21437335014343262 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:18.020609 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3154780864715576 	 0.47990846633911133 	 0.30591249465942383 	 0.4668395519256592 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:19.773971 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2961115837097168 	 0.30834436416625977 	 0.286271333694458 	 0.2955353260040283 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:20.955225 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11846804618835449 	 0.7379231452941895 	 0.10984015464782715 	 0.10417008399963379 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:24.610559 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.4498622417449951 	 0.45346570014953613 	 0.4409976005554199 	 0.4342772960662842 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:27.981997 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.44852137565612793 	 0.4498624801635742 	 0.43978214263916016 	 0.4381270408630371 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:30.845320 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.18442869186401367 	 0.22731566429138184 	 0.17473387718200684 	 0.2144298553466797 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:31.968265 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11854147911071777 	 0.1165008544921875 	 0.10961222648620605 	 0.10455775260925293 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:33.569756 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2957427501678467 	 0.308349609375 	 0.28595805168151855 	 0.294846773147583 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:34.719625 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.44983911514282227 	 0.45261526107788086 	 0.4409472942352295 	 0.43427014350891113 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:39.676116 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.34467530250549316 	 0.47852373123168945 	 0.3350198268890381 	 0.46552467346191406 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:41.455499 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.4486863613128662 	 0.4499094486236572 	 0.440065860748291 	 0.43815159797668457 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:44.332626 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11821365356445312 	 0.1286306381225586 	 0.10948491096496582 	 0.10347461700439453 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:46.004610 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.44986581802368164 	 0.4462924003601074 	 0.4410398006439209 	 0.43462157249450684 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:48.027651 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11823153495788574 	 0.11559224128723145 	 0.10898423194885254 	 0.10355091094970703 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:49.704105 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4498293399810791 	 0.44621872901916504 	 0.4409956932067871 	 0.4340524673461914 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:51.754204 test begin: paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11822366714477539 	 0.11556386947631836 	 0.10939168930053711 	 0.10359597206115723 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:53.392152 test begin: paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4498121738433838 	 0.4475736618041992 	 0.4399597644805908 	 0.43436360359191895 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:55.384620 test begin: paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11823749542236328 	 0.11554074287414551 	 0.10949039459228516 	 0.1034235954284668 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:57.093209 test begin: paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.449800968170166 	 0.4462425708770752 	 0.4409933090209961 	 0.43468618392944336 	 None 	 None 	 None 	 None 	 
2025-07-30 14:52:59.143881 test begin: paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11850929260253906 	 0.11639523506164551 	 0.10978221893310547 	 0.10397553443908691 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:00.801025 test begin: paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.44989824295043945 	 0.44626712799072266 	 0.4409599304199219 	 0.43440985679626465 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:02.828512 test begin: paddle.bitwise_and(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44823241233825684 	 0.44983696937561035 	 0.43933701515197754 	 0.43805718421936035 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:05.688114 test begin: paddle.bitwise_invert(Tensor([12700801, 4, 1],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([12700801, 4, 1],"int32"), ) 	 50803204 	 1000 	 0.29561424255371094 	 0.29798054695129395 	 0.2874114513397217 	 0.28682780265808105 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:06.891579 test begin: paddle.bitwise_invert(Tensor([2, 1270081, 4, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 1270081, 4, 5],"int32"), ) 	 50803240 	 1000 	 0.2956662178039551 	 0.29791879653930664 	 0.2876279354095459 	 0.28656792640686035 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:08.042825 test begin: paddle.bitwise_invert(Tensor([2, 3, 1693441, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 3, 1693441, 5],"int32"), ) 	 50803230 	 1000 	 0.29572224617004395 	 0.2985062599182129 	 0.2876620292663574 	 0.2864551544189453 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:09.228260 test begin: paddle.bitwise_invert(Tensor([2, 3, 4, 2116801],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 3, 4, 2116801],"int32"), ) 	 50803224 	 1000 	 0.2956845760345459 	 0.30562806129455566 	 0.2877237796783447 	 0.28679943084716797 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:10.381809 test begin: paddle.bitwise_invert(Tensor([3, 16934401, 1],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([3, 16934401, 1],"int32"), ) 	 50803203 	 1000 	 0.29564571380615234 	 0.29788923263549805 	 0.2875206470489502 	 0.28671813011169434 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:11.532509 test begin: paddle.bitwise_invert(Tensor([3, 4, 4233601],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([3, 4, 4233601],"int32"), ) 	 50803212 	 1000 	 0.2956693172454834 	 0.29793524742126465 	 0.2875537872314453 	 0.2868340015411377 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:12.684707 test begin: paddle.bitwise_invert(Tensor([846721, 3, 4, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([846721, 3, 4, 5],"int32"), ) 	 50803260 	 1000 	 0.29575419425964355 	 0.2978532314300537 	 0.28763437271118164 	 0.2865939140319824 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:13.838641 test begin: paddle.bitwise_left_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.4498481750488281 	 0.4463770389556885 	 0.44081592559814453 	 0.43480348587036133 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:15.890338 test begin: paddle.bitwise_left_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.4498434066772461 	 0.4462440013885498 	 0.4408845901489258 	 0.43479204177856445 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:17.904564 test begin: paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4479649066925049 	 0.44983673095703125 	 0.43878841400146484 	 0.4382967948913574 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:20.696668 test begin: paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.4476783275604248 	 0.4526996612548828 	 0.4385344982147217 	 0.4382286071777344 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:23.415110 test begin: paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.44784069061279297 	 0.4497642517089844 	 0.4385051727294922 	 0.4382927417755127 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:26.218151 test begin: paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.44799304008483887 	 0.45223379135131836 	 0.4388124942779541 	 0.43824219703674316 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:30.543514 test begin: paddle.bitwise_not(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.298220157623291 	 0.30582571029663086 	 0.2903118133544922 	 0.2849564552307129 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:32.934833 test begin: paddle.bitwise_not(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.2982628345489502 	 0.309650182723999 	 0.2903635501861572 	 0.2849900722503662 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:34.506707 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.2982804775238037 	 0.306964635848999 	 0.2904667854309082 	 0.2788565158843994 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:39.383860 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 101606940 	 1000 	 0.29762983322143555 	 0.29663705825805664 	 0.28971076011657715 	 0.2851884365081787 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:40.977467 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 50803632 	 1000 	 0.2955639362335205 	 0.2978932857513428 	 0.28757572174072266 	 0.2866487503051758 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:42.133733 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 101606832 	 1000 	 0.2982215881347656 	 0.29629969596862793 	 0.29024434089660645 	 0.28487277030944824 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:43.685297 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 50804280 	 1000 	 0.2957451343536377 	 0.2979543209075928 	 0.2878282070159912 	 0.2865912914276123 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:44.830416 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 101607480 	 1000 	 0.2974996566772461 	 0.29631996154785156 	 0.2895224094390869 	 0.28487396240234375 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:46.376115 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50805360 	 1000 	 0.29564929008483887 	 0.29793739318847656 	 0.2875962257385254 	 0.28465962409973145 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:47.523582 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101608560 	 1000 	 0.2975301742553711 	 0.2962677478790283 	 0.28965330123901367 	 0.2850203514099121 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:49.146473 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 50803740 	 1000 	 0.2957286834716797 	 0.2980034351348877 	 0.2877321243286133 	 0.28255224227905273 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:50.302631 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2957332134246826 	 0.2979726791381836 	 0.2877674102783203 	 0.2865424156188965 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:51.431399 test begin: paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2957944869995117 	 0.2979142665863037 	 0.28772449493408203 	 0.2867605686187744 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:52.548952 test begin: paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2956979274749756 	 0.2978837490081787 	 0.28773975372314453 	 0.28658533096313477 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:53.666333 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 508036320 	 1000 	 0.846337080001831 	 0.7471802234649658 	 0.8383455276489258 	 0.7353780269622803 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:01.982188 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 508042800 	 1000 	 0.8571851253509521 	 0.747687578201294 	 0.8490438461303711 	 0.7358160018920898 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:10.612948 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 508053600 	 1000 	 0.847491979598999 	 0.7471673488616943 	 0.8394241333007812 	 0.7353067398071289 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:19.246919 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 508037400 	 1000 	 0.8570075035095215 	 0.7474901676177979 	 0.8488945960998535 	 0.735435962677002 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:27.729176 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8474509716033936 	 0.7539699077606201 	 0.8394718170166016 	 0.7351469993591309 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:37.922325 test begin: paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8474526405334473 	 0.7472250461578369 	 0.8393354415893555 	 0.7353916168212891 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:46.502596 test begin: paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8474481105804443 	 0.7476646900177002 	 0.8393745422363281 	 0.7348349094390869 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:55.090277 test begin: paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50804280 	 1000 	 0.2958037853240967 	 0.29881763458251953 	 0.2877678871154785 	 0.2865307331085205 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:56.242841 test begin: paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508042800 	 1000 	 0.8571600914001465 	 0.747713565826416 	 0.8492045402526855 	 0.7359652519226074 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:04.717669 test begin: paddle.bitwise_not(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101607480 	 1000 	 0.29750895500183105 	 0.2982175350189209 	 0.2895174026489258 	 0.28490376472473145 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:06.229283 test begin: paddle.bitwise_or(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4482452869415283 	 0.44985151290893555 	 0.43962597846984863 	 0.43797850608825684 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:09.021675 test begin: paddle.bitwise_or(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44808363914489746 	 0.4499092102050781 	 0.43946170806884766 	 0.4379091262817383 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:11.744724 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4485774040222168 	 0.4527740478515625 	 0.44000887870788574 	 0.43746328353881836 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:14.658468 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.44877099990844727 	 0.4498865604400635 	 0.44011712074279785 	 0.43814849853515625 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:17.539481 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.1180579662322998 	 0.11729669570922852 	 0.1094820499420166 	 0.10537242889404297 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:19.231762 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.44982242584228516 	 0.4484858512878418 	 0.4402191638946533 	 0.4344482421875 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:21.324654 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.44817185401916504 	 0.4498710632324219 	 0.4390120506286621 	 0.4378814697265625 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:24.152550 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.15548491477966309 	 0.23005270957946777 	 0.14592957496643066 	 0.21408987045288086 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:25.246634 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.315460205078125 	 0.4797825813293457 	 0.30583667755126953 	 0.4669215679168701 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:27.002298 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2960937023162842 	 0.30840301513671875 	 0.28659486770629883 	 0.29565978050231934 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:28.166562 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11800694465637207 	 0.11609506607055664 	 0.10947275161743164 	 0.10435771942138672 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:29.825458 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.4498612880706787 	 0.4462418556213379 	 0.4413423538208008 	 0.4346630573272705 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:31.825172 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.4482302665710449 	 0.4557929039001465 	 0.43961262702941895 	 0.4378082752227783 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:34.631394 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.17346644401550293 	 0.24002432823181152 	 0.16379880905151367 	 0.2137765884399414 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:37.370761 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11804080009460449 	 0.11832213401794434 	 0.10942697525024414 	 0.10431790351867676 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:39.516601 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2957789897918701 	 0.30840563774108887 	 0.2865421772003174 	 0.29581451416015625 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:40.705695 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.4499166011810303 	 0.4463386535644531 	 0.4413888454437256 	 0.4322383403778076 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:42.713772 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3446831703186035 	 0.4827847480773926 	 0.33510375022888184 	 0.4653475284576416 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:46.290810 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.4482839107513428 	 0.4676520824432373 	 0.4396939277648926 	 0.4380221366882324 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:49.389008 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11769485473632812 	 0.11534976959228516 	 0.10906028747558594 	 0.10329198837280273 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:51.099778 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.4498934745788574 	 0.44623780250549316 	 0.44139862060546875 	 0.434659481048584 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:53.105735 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1177225112915039 	 0.11713552474975586 	 0.10916519165039062 	 0.10326552391052246 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:54.742856 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44980669021606445 	 0.44625258445739746 	 0.43996548652648926 	 0.4347076416015625 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:56.818420 test begin: paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11769843101501465 	 0.11522293090820312 	 0.10876297950744629 	 0.10330438613891602 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:58.540288 test begin: paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4497833251953125 	 0.4529142379760742 	 0.4411602020263672 	 0.4342625141143799 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:00.541039 test begin: paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1177058219909668 	 0.1165914535522461 	 0.10752224922180176 	 0.10290288925170898 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:02.187344 test begin: paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4498136043548584 	 0.4461698532104492 	 0.4413471221923828 	 0.43453049659729004 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:04.194880 test begin: paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.1180262565612793 	 0.11608028411865234 	 0.109405517578125 	 0.10413765907287598 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:05.881238 test begin: paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.44983863830566406 	 0.44621968269348145 	 0.44113874435424805 	 0.43378400802612305 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:07.875965 test begin: paddle.bitwise_or(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44846677780151367 	 0.4498171806335449 	 0.4397590160369873 	 0.4368915557861328 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:10.677793 test begin: paddle.bitwise_right_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.44977593421936035 	 0.4462001323699951 	 0.44081878662109375 	 0.43445253372192383 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:56:12.735672 test begin: paddle.bitwise_right_shift(Tensor([200, 127009],"int64"), Tensor([200, 127009],"int64"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 127009],"int64"), Tensor([200, 127009],"int64"), ) 	 50803600 	 1000 	 0.44817447662353516 	 0.4461710453033447 	 0.4393649101257324 	 0.4313933849334717 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:56:14.409057 test begin: paddle.bitwise_right_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.44983696937561035 	 0.4462277889251709 	 0.4408729076385498 	 0.43450140953063965 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:56:16.413527 test begin: paddle.bitwise_right_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4475526809692383 	 0.4497523307800293 	 0.43852758407592773 	 0.4378960132598877 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:56:19.276607 test begin: paddle.bitwise_right_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.44739437103271484 	 0.4498484134674072 	 0.4383692741394043 	 0.43786025047302246 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:56:22.112687 test begin: paddle.bitwise_right_shift(Tensor([84673, 300],"int64"), Tensor([84673, 300],"int64"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([84673, 300],"int64"), Tensor([84673, 300],"int64"), ) 	 50803800 	 1000 	 0.44837379455566406 	 0.4456765651702881 	 0.4397165775299072 	 0.43381428718566895 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:56:23.777329 test begin: paddle.bitwise_xor(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4484527111053467 	 0.449932336807251 	 0.4397904872894287 	 0.43810462951660156 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:26.626788 test begin: paddle.bitwise_xor(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4484984874725342 	 0.44988441467285156 	 0.43990111351013184 	 0.43811583518981934 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:29.417446 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4480752944946289 	 0.44988179206848145 	 0.43950748443603516 	 0.43810534477233887 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:32.293629 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.4487588405609131 	 0.4498929977416992 	 0.4400825500488281 	 0.43806004524230957 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:35.103306 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11803460121154785 	 0.12601089477539062 	 0.10933351516723633 	 0.10528445243835449 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:39.327613 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.44962501525878906 	 0.4513511657714844 	 0.4410536289215088 	 0.4344189167022705 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:41.402714 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.44815587997436523 	 0.44985151290893555 	 0.43958020210266113 	 0.4381723403930664 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:44.232447 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.16824126243591309 	 0.22739911079406738 	 0.15856146812438965 	 0.21439027786254883 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:45.333662 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.31542539596557617 	 0.4812936782836914 	 0.3060269355773926 	 0.46636104583740234 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:47.128962 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2961006164550781 	 0.31108951568603516 	 0.2864232063293457 	 0.2952754497528076 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:48.289260 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11800765991210938 	 0.13980531692504883 	 0.10936236381530762 	 0.10190749168395996 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:51.352245 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.449737548828125 	 0.45482492446899414 	 0.44112324714660645 	 0.43427467346191406 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:54.688242 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.448199987411499 	 0.4499359130859375 	 0.43939661979675293 	 0.4380466938018799 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:57.551898 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.17664623260498047 	 0.22731685638427734 	 0.16689801216125488 	 0.21425724029541016 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:58.638570 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.1180427074432373 	 0.11645913124084473 	 0.10928821563720703 	 0.10468339920043945 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:00.278181 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29573774337768555 	 0.3083500862121582 	 0.2860281467437744 	 0.2957189083099365 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:01.418598 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.44988560676574707 	 0.4464225769042969 	 0.44115233421325684 	 0.43448472023010254 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:03.425857 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.34464287757873535 	 0.47831082344055176 	 0.3351259231567383 	 0.46552610397338867 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:05.171917 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.44830965995788574 	 0.44991350173950195 	 0.43959975242614746 	 0.43813586235046387 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:07.954835 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.1177213191986084 	 0.11553239822387695 	 0.1090548038482666 	 0.10365509986877441 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:09.543441 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.44986510276794434 	 0.4475440979003906 	 0.44118547439575195 	 0.4343841075897217 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:11.516484 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11770868301391602 	 0.11686205863952637 	 0.10905051231384277 	 0.10368609428405762 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:13.176226 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4497663974761963 	 0.44619083404541016 	 0.4396672248840332 	 0.43458080291748047 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:15.140724 test begin: paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11771059036254883 	 0.1155848503112793 	 0.10904550552368164 	 0.10371279716491699 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:16.737766 test begin: paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4498145580291748 	 0.4461679458618164 	 0.4411599636077881 	 0.434520959854126 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:18.770488 test begin: paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1177206039428711 	 0.11557507514953613 	 0.10893464088439941 	 0.10373997688293457 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:20.420931 test begin: paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4498291015625 	 0.45040369033813477 	 0.4371805191040039 	 0.43450188636779785 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:22.372827 test begin: paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11804771423339844 	 0.11684346199035645 	 0.10925817489624023 	 0.10441088676452637 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:24.037033 test begin: paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.4498100280761719 	 0.44616246223449707 	 0.44002580642700195 	 0.4345128536224365 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:26.017070 test begin: paddle.bitwise_xor(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44878315925598145 	 0.4498484134674072 	 0.44014501571655273 	 0.43830013275146484 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:28.773415 test begin: paddle.bmm(Tensor([112, 1043, 435],"float32"), Tensor([112, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([112, 1043, 435],"float32"), Tensor([112, 435, 64],"float32"), ) 	 53933040 	 1000 	 0.8940248489379883 	 0.8942017555236816 	 0.8816218376159668 	 0.8776917457580566 	 1.6016435623168945 	 1.60302734375 	 0.8183622360229492 	 0.8196969032287598 	 
2025-07-30 14:57:35.875671 test begin: paddle.bmm(Tensor([112, 435, 435],"float32"), Tensor([112, 435, 1043],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([112, 435, 435],"float32"), Tensor([112, 435, 1043],"float32"), ) 	 72008160 	 1000 	 3.369856357574463 	 3.3703362941741943 	 3.3575551509857178 	 3.3546359539031982 	 6.949969291687012 	 6.949577331542969 	 3.5514113903045654 	 3.5511696338653564 	 
2025-07-30 14:58:00.009092 test begin: paddle.bmm(Tensor([14, 81, 7332],"float32"), Tensor([14, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([14, 81, 7332],"float32"), Tensor([14, 7332, 512],"float32"), ) 	 60870264 	 1000 	 1.467228651046753 	 1.4690468311309814 	 1.454960823059082 	 1.4506897926330566 	 1.4253497123718262 	 1.4252736568450928 	 0.728304386138916 	 0.7281417846679688 	 
2025-07-30 14:58:06.829206 test begin: paddle.bmm(Tensor([1825, 435, 435],"float32"), Tensor([1825, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([1825, 435, 435],"float32"), Tensor([1825, 435, 64],"float32"), ) 	 396143625 	 1000 	 6.017611503601074 	 6.3902740478515625 	 6.005293130874634 	 6.374528408050537 	 9.951611995697021 	 9.95119047164917 	 5.085210800170898 	 5.084926605224609 	 
2025-07-30 14:58:47.503928 test begin: paddle.bmm(Tensor([26, 1024, 1024],"float32"), Tensor([26, 1024, 1909],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([26, 1024, 1024],"float32"), Tensor([26, 1024, 1909],"float32"), ) 	 78088192 	 1000 	 5.942180395126343 	 5.9446165561676025 	 5.929919719696045 	 5.928531646728516 	 12.075960397720337 	 12.073638677597046 	 6.170685768127441 	 6.16945743560791 	 
2025-07-30 14:59:25.862808 test begin: paddle.bmm(Tensor([26, 1909, 1024],"float32"), Tensor([26, 1024, 12],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([26, 1909, 1024],"float32"), Tensor([26, 1024, 12],"float32"), ) 	 51144704 	 1000 	 0.827869176864624 	 0.8282270431518555 	 0.8153965473175049 	 0.8126492500305176 	 0.9365344047546387 	 0.9365489482879639 	 0.47849369049072266 	 0.4784977436065674 	 
2025-07-30 14:59:30.188391 test begin: paddle.bmm(Tensor([269, 435, 435],"float32"), Tensor([269, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([269, 435, 435],"float32"), Tensor([269, 435, 64],"float32"), ) 	 58390485 	 1000 	 0.895615816116333 	 0.8957574367523193 	 0.8832247257232666 	 0.8798398971557617 	 1.4855775833129883 	 1.4855096340179443 	 0.7590491771697998 	 0.7590053081512451 	 
2025-07-30 14:59:37.536932 test begin: paddle.bmm(Tensor([4, 1733, 7332],"float32"), Tensor([4, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 1733, 7332],"float32"), Tensor([4, 7332, 512],"float32"), ) 	 65841360 	 1000 	 4.386684894561768 	 4.386769771575928 	 4.374426364898682 	 4.370716094970703 	 6.33463716506958 	 6.332828521728516 	 3.236868381500244 	 3.2365622520446777 	 
2025-07-30 15:00:00.210792 test begin: paddle.bmm(Tensor([4, 81, 156801],"float32"), Tensor([4, 156801, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 156801],"float32"), Tensor([4, 156801, 512],"float32"), ) 	 371931972 	 1000 	 31.179917812347412 	 31.178696632385254 	 31.167691230773926 	 31.163345336914062 	 8.205556154251099 	 8.204551935195923 	 4.192568778991699 	 4.192182779312134 	 
2025-07-30 15:01:25.280127 test begin: paddle.bmm(Tensor([4, 81, 24807],"float32"), Tensor([4, 24807, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 24807],"float32"), Tensor([4, 24807, 512],"float32"), ) 	 58842204 	 1000 	 4.944153547286987 	 4.939664840698242 	 4.931827783584595 	 4.9243505001068115 	 1.390960454940796 	 1.3930048942565918 	 0.7106211185455322 	 0.7110316753387451 	 
2025-07-30 15:01:40.752034 test begin: paddle.bmm(Tensor([4, 81, 7332],"float32"), Tensor([4, 7332, 1733],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 7332],"float32"), Tensor([4, 7332, 1733],"float32"), ) 	 53200992 	 1000 	 1.468919038772583 	 1.4681980609893799 	 1.4565694332122803 	 1.4528017044067383 	 1.6454057693481445 	 1.6443488597869873 	 0.8412261009216309 	 0.8400466442108154 	 
2025-07-30 15:01:47.813281 test begin: paddle.bmm(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 12],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 12],"float32"), ) 	 51982336 	 1000 	 0.8299827575683594 	 0.8280179500579834 	 0.8176379203796387 	 0.8128821849822998 	 0.9929444789886475 	 0.9929795265197754 	 0.507605791091919 	 0.5075652599334717 	 
2025-07-30 15:01:52.278662 test begin: paddle.bmm(Tensor([86, 81, 7332],"float32"), Tensor([86, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([86, 81, 7332],"float32"), Tensor([86, 7332, 512],"float32"), ) 	 373917336 	 1000 	 5.8409295082092285 	 5.8399083614349365 	 5.8286659717559814 	 5.824275732040405 	 8.36269497871399 	 8.362748146057129 	 4.2732768058776855 	 4.273269414901733 	 
2025-07-30 15:02:27.206153 test begin: paddle.broadcast_tensors(list[Tensor([127009, 200],"float64"),Tensor([127009, 200],"float64"),], )
[Prof] paddle.broadcast_tensors 	 paddle.broadcast_tensors(list[Tensor([127009, 200],"float64"),Tensor([127009, 200],"float64"),], ) 	 50803600 	 1000 	 0.6146240234375 	 0.007734775543212891 	 0.3140273094177246 	 5.14984130859375e-05 	 0.624436616897583 	 0.06203627586364746 	 0.15953278541564941 	 8.058547973632812e-05 	 
2025-07-30 15:02:30.509656 test begin: paddle.broadcast_tensors(list[Tensor([200, 127009],"float64"),Tensor([200, 127009],"float64"),], )
[Prof] paddle.broadcast_tensors 	 paddle.broadcast_tensors(list[Tensor([200, 127009],"float64"),Tensor([200, 127009],"float64"),], ) 	 50803600 	 1000 	 0.6145355701446533 	 0.007427692413330078 	 0.31397032737731934 	 2.1219253540039062e-05 	 0.6244447231292725 	 0.06139397621154785 	 0.15952467918395996 	 5.7220458984375e-05 	 
2025-07-30 15:02:33.704813 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), ) 	 38102403 	 1000 	 1.341867446899414 	 1.077376365661621 	 1.3311424255371094 	 1.0563905239105225 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:40.107704 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), out_int32=True, ) 	 38102403 	 1000 	 1.3379361629486084 	 1.0351228713989258 	 1.3267850875854492 	 1.0204081535339355 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:43.243644 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), right=True, ) 	 38102403 	 1000 	 1.344942331314087 	 1.0406055450439453 	 1.3260033130645752 	 1.022796392440796 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:46.511964 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), ) 	 25401606 	 1000 	 0.3180882930755615 	 0.31536126136779785 	 0.3074350357055664 	 0.3042612075805664 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:47.681959 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), out_int32=True, ) 	 25401606 	 1000 	 0.2851119041442871 	 0.24600481986999512 	 0.27413511276245117 	 0.2331843376159668 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:48.695309 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), right=True, ) 	 25401606 	 1000 	 0.3182563781738281 	 0.3167450428009033 	 0.30727386474609375 	 0.30544400215148926 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:49.830978 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 76204803 	 1000 	 2.7774815559387207 	 2.148045539855957 	 2.7666399478912354 	 2.1332333087921143 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:56.238723 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 76204803 	 1000 	 2.7662789821624756 	 2.135439872741699 	 2.7552099227905273 	 2.1242010593414307 	 None 	 None 	 None 	 None 	 
2025-07-30 15:03:02.622912 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), right=True, ) 	 76204803 	 1000 	 2.7799227237701416 	 2.1565165519714355 	 2.768761396408081 	 2.1407697200775146 	 None 	 None 	 None 	 None 	 
2025-07-30 15:03:09.046195 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), ) 	 2540160109 	 1000 	 0.010443925857543945 	 0.01086878776550293 	 1.6689300537109375e-05 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:03:56.692393 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, ) 	 2540160109 	 1000 	 0.011760473251342773 	 0.010960817337036133 	 2.7894973754882812e-05 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:44.697447 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), ) 	 25402405 	 1000 	 0.011138677597045898 	 0.010794401168823242 	 2.1457672119140625e-05 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:45.216955 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 25402405 	 1000 	 0.011057853698730469 	 0.011059999465942383 	 1.621246337890625e-05 	 2.6226043701171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:45.766434 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, ) 	 25402405 	 1000 	 0.01103830337524414 	 0.011062145233154297 	 1.5497207641601562e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:46.272451 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), ) 	 25401608 	 1000 	 0.31792187690734863 	 0.31537413597106934 	 0.30733156204223633 	 0.30423951148986816 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:47.388114 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), out_int32=True, ) 	 25401608 	 1000 	 0.28476476669311523 	 0.24491000175476074 	 0.2738220691680908 	 0.23329544067382812 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:48.390203 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), right=True, ) 	 25401608 	 1000 	 0.3178856372833252 	 0.3182642459869385 	 0.306809663772583 	 0.30405330657958984 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:49.512289 test begin: paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], ) 	 5150 	 1000 	 0.5905861854553223 	 1.1238040924072266 	 0.08617806434631348 	 0.2852604389190674 	 110.61854839324951 	 0.5250036716461182 	 28.21725034713745 	 0.10725593566894531 	 
2025-07-30 15:06:46.540571 test begin: paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], ) 	 5140 	 1000 	 0.5327372550964355 	 1.0036365985870361 	 0.07776832580566406 	 0.25670313835144043 	 78.11735939979553 	 0.48105859756469727 	 19.93343710899353 	 0.09803175926208496 	 
2025-07-30 15:08:07.168248 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], ) 	 5150 	 1000 	 0.3622171878814697 	 0.5259687900543213 	 0.05283308029174805 	 0.13457942008972168 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:09:08.661527 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], ) 	 948 	 1000 	 0.4717752933502197 	 0.7035980224609375 	 0.06881141662597656 	 0.17995977401733398 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:10:27.062597 test begin: paddle.cast(Tensor([1, 1, 32768, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([1, 1, 32768, 32768],"float16"), dtype=Dtype(float16), ) 	 1073741824 	 1000 	 3.26535701751709 	 0.001959562301635742 	 1.6685829162597656 	 1.811981201171875e-05 	 3.266671657562256 	 0.044764041900634766 	 1.669264793395996 	 7.128715515136719e-05 	 combined
2025-07-30 15:11:14.417888 test begin: paddle.cast(Tensor([128256, 793],"bfloat16"), Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([128256, 793],"bfloat16"), Dtype(float16), ) 	 101707008 	 1000 	 0.2982456684112549 	 0.5105466842651367 	 0.2888479232788086 	 0.4977383613586426 	 0.29855895042419434 	 0.5073986053466797 	 0.24388599395751953 	 0.4456980228424072 	 combined
2025-07-30 15:11:19.449809 test begin: paddle.cast(Tensor([2, 1, 1551, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 1551, 32768],"float16"), dtype=Dtype(float16), ) 	 101646336 	 1000 	 0.313096284866333 	 0.0029931068420410156 	 0.30205631256103516 	 9.322166442871094e-05 	 0.3144698143005371 	 0.04405021667480469 	 0.2606501579284668 	 4.100799560546875e-05 	 combined
2025-07-30 15:11:23.898482 test begin: paddle.cast(Tensor([2, 1, 32768, 1551],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 32768, 1551],"float16"), dtype=Dtype(float16), ) 	 101646336 	 1000 	 0.31310367584228516 	 0.0020155906677246094 	 0.30204248428344727 	 1.6927719116210938e-05 	 0.3131527900695801 	 0.044347286224365234 	 0.2592463493347168 	 5.650520324707031e-05 	 combined
2025-07-30 15:11:28.287216 test begin: paddle.cast(Tensor([2, 1, 32768, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 32768, 32768],"float16"), dtype=Dtype(float16), ) 	 2147483648 	 1000 	 6.602104902267456 	 0.001987457275390625 	 3.418246269226074 	 1.71661376953125e-05 	 6.516335725784302 	 0.048030853271484375 	 3.329751491546631 	 6.723403930664062e-05 	 combined
2025-07-30 15:13:01.760145 test begin: paddle.cast(Tensor([2, 1024, 50304],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1024, 50304],"float16"), dtype="float32", ) 	 103022592 	 1000 	 0.4856271743774414 	 0.5575101375579834 	 0.47376084327697754 	 0.5446412563323975 	 0.45583033561706543 	 0.4607734680175781 	 0.40426039695739746 	 0.39670848846435547 	 combined
2025-07-30 15:13:07.291319 test begin: paddle.cast(Tensor([33076, 3072],"bfloat16"), Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([33076, 3072],"bfloat16"), Dtype(float16), ) 	 101609472 	 1000 	 0.2979283332824707 	 0.509929895401001 	 0.2885007858276367 	 0.49672412872314453 	 0.2995893955230713 	 0.5055420398712158 	 0.2451162338256836 	 0.4420633316040039 	 combined
2025-07-30 15:13:12.408409 test begin: paddle.cast(Tensor([8, 1024, 12404],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([8, 1024, 12404],"float16"), dtype="float32", ) 	 101613568 	 1000 	 0.4794197082519531 	 1.0066709518432617 	 0.46796417236328125 	 0.5367457866668701 	 0.44956445693969727 	 0.45339035987854004 	 0.3966391086578369 	 0.390826940536499 	 combined
2025-07-30 15:13:20.944834 test begin: paddle.cast(Tensor([8, 253, 50304],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([8, 253, 50304],"float16"), dtype="float32", ) 	 101815296 	 1000 	 0.48027896881103516 	 0.5511202812194824 	 0.4686086177825928 	 0.5379531383514404 	 0.45063161849975586 	 0.4542655944824219 	 0.3987550735473633 	 0.3905768394470215 	 combined
2025-07-30 15:13:26.368225 test begin: paddle.cdist(Tensor([12700801, 4],"float32"), Tensor([1, 4],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([12700801, 4],"float32"), Tensor([1, 4],"float32"), p=1, ) 	 50803208 	 1000 	 0.6907260417938232 	 26.79559636116028 	 0.3528780937194824 	 26.740926265716553 	 8.353920698165894 	 14.20496916770935 	 2.846114158630371 	 2.8971500396728516 	 
2025-07-30 15:14:18.253642 test begin: paddle.cdist(Tensor([6380, 7963],"float32"), Tensor([1, 7963],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([6380, 7963],"float32"), Tensor([1, 7963],"float32"), p=1, ) 	 50811903 	 1000 	 0.45027852058410645 	 0.19416379928588867 	 0.2300577163696289 	 0.17080330848693848 	 2.184349775314331 	 1.179382562637329 	 0.7424445152282715 	 0.24069523811340332 	 
2025-07-30 15:14:26.334564 test begin: paddle.cdist(Tensor([8550, 5942],"float32"), Tensor([1, 5942],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([8550, 5942],"float32"), Tensor([1, 5942],"float32"), p=1, ) 	 50810042 	 1000 	 0.4506204128265381 	 0.19329047203063965 	 0.23024725914001465 	 0.17172598838806152 	 2.194485664367676 	 1.1623990535736084 	 0.7458910942077637 	 0.23727726936340332 	 
2025-07-30 15:14:31.239831 test begin: paddle.cdist(Tensor([900, 56449],"float32"), Tensor([1, 56449],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([900, 56449],"float32"), Tensor([1, 56449],"float32"), p=1, ) 	 50860549 	 1000 	 0.480057954788208 	 0.29082798957824707 	 0.16424107551574707 	 0.26909589767456055 	 2.1515414714813232 	 1.2279438972473145 	 0.7318172454833984 	 0.3136560916900635 	 
2025-07-30 15:14:37.361530 test begin: paddle.ceil(Tensor([12404, 32, 128],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([12404, 32, 128],"float32"), ) 	 50806784 	 1000 	 0.29566025733947754 	 0.3094658851623535 	 0.2868154048919678 	 0.28673744201660156 	 0.1343827247619629 	 0.13431191444396973 	 0.08461499214172363 	 0.07322263717651367 	 
2025-07-30 15:14:40.313754 test begin: paddle.ceil(Tensor([141121, 6, 3, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([141121, 6, 3, 1, 2, 5],"float64"), ) 	 25401780 	 1000 	 0.2980687618255615 	 0.2989463806152344 	 0.2889213562011719 	 0.2875652313232422 	 0.13424944877624512 	 0.13470125198364258 	 0.08525586128234863 	 0.07202410697937012 	 
2025-07-30 15:14:42.204364 test begin: paddle.ceil(Tensor([3, 141121, 3, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 141121, 3, 4, 1, 5],"float64"), ) 	 25401780 	 1000 	 0.29804253578186035 	 0.29897189140319824 	 0.2891120910644531 	 0.28394579887390137 	 0.13405203819274902 	 0.13467717170715332 	 0.08525919914245605 	 0.07198596000671387 	 
2025-07-30 15:14:44.119277 test begin: paddle.ceil(Tensor([3, 282241, 3, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 282241, 3, 1, 2, 5],"float64"), ) 	 25401690 	 1000 	 0.2994074821472168 	 0.29897236824035645 	 0.29053664207458496 	 0.287811279296875 	 0.13542389869689941 	 0.13478493690490723 	 0.08667945861816406 	 0.07217907905578613 	 
2025-07-30 15:14:45.982146 test begin: paddle.ceil(Tensor([3, 6, 141121, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 141121, 1, 2, 5],"float64"), ) 	 25401780 	 1000 	 0.29801130294799805 	 0.29897546768188477 	 0.28910255432128906 	 0.2877814769744873 	 0.1340959072113037 	 0.13466095924377441 	 0.08530020713806152 	 0.07168960571289062 	 
2025-07-30 15:14:47.813864 test begin: paddle.ceil(Tensor([3, 6, 3, 1, 2, 235201],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 1, 2, 235201],"float64"), ) 	 25401708 	 1000 	 0.29802727699279785 	 0.3134756088256836 	 0.2891228199005127 	 0.28760623931884766 	 0.13418960571289062 	 0.1347353458404541 	 0.0832979679107666 	 0.07199382781982422 	 
2025-07-30 15:14:49.738772 test begin: paddle.ceil(Tensor([3, 6, 3, 1, 94081, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 1, 94081, 5],"float64"), ) 	 25401870 	 1000 	 0.29730892181396484 	 0.3015754222869873 	 0.2884495258331299 	 0.2873537540435791 	 0.13427329063415527 	 0.13466429710388184 	 0.08497214317321777 	 0.07275223731994629 	 
2025-07-30 15:14:51.609123 test begin: paddle.ceil(Tensor([3, 6, 3, 4, 1, 117601],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 4, 1, 117601],"float64"), ) 	 25401816 	 1000 	 0.2980837821960449 	 0.2989795207977295 	 0.2893350124359131 	 0.28767943382263184 	 0.1341397762298584 	 0.13475632667541504 	 0.08533239364624023 	 0.07008004188537598 	 
2025-07-30 15:14:53.575744 test begin: paddle.ceil(Tensor([3, 6, 3, 4, 23521, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 4, 23521, 5],"float64"), ) 	 25402680 	 1000 	 0.29802823066711426 	 0.3119678497314453 	 0.28924083709716797 	 0.2877969741821289 	 0.13419294357299805 	 0.1346907615661621 	 0.08528423309326172 	 0.07196044921875 	 
2025-07-30 15:14:55.432747 test begin: paddle.ceil(Tensor([3, 6, 3, 47041, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 47041, 2, 5],"float64"), ) 	 25402140 	 1000 	 0.2972843647003174 	 0.29903650283813477 	 0.28836798667907715 	 0.2878134250640869 	 0.13409757614135742 	 0.1346728801727295 	 0.08459234237670898 	 0.06920719146728516 	 
2025-07-30 15:14:57.260877 test begin: paddle.ceil(Tensor([3, 6, 3, 94081, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 94081, 1, 5],"float64"), ) 	 25401870 	 1000 	 0.29729390144348145 	 0.2989513874053955 	 0.2884197235107422 	 0.28765368461608887 	 0.13406705856323242 	 0.13477325439453125 	 0.08498811721801758 	 0.0718238353729248 	 
2025-07-30 15:14:59.144328 test begin: paddle.ceil(Tensor([3, 6, 70561, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 70561, 4, 1, 5],"float64"), ) 	 25401960 	 1000 	 0.29809999465942383 	 0.298933744430542 	 0.2887232303619385 	 0.2877614498138428 	 0.13412928581237793 	 0.1347794532775879 	 0.08499979972839355 	 0.07020163536071777 	 
2025-07-30 15:15:00.998511 test begin: paddle.ceil(Tensor([32, 12404, 128],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([32, 12404, 128],"float32"), ) 	 50806784 	 1000 	 0.29561567306518555 	 0.30048155784606934 	 0.2868003845214844 	 0.2868971824645996 	 0.1355433464050293 	 0.13423418998718262 	 0.08649349212646484 	 0.07214760780334473 	 
2025-07-30 15:15:03.417342 test begin: paddle.ceil(Tensor([32, 32, 49613],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([32, 32, 49613],"float32"), ) 	 50803712 	 1000 	 0.29569435119628906 	 0.2978060245513916 	 0.2868833541870117 	 0.28679776191711426 	 0.1342635154724121 	 0.1341993808746338 	 0.08504009246826172 	 0.07304716110229492 	 
2025-07-30 15:15:05.787566 test begin: paddle.ceil(Tensor([70561, 6, 3, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([70561, 6, 3, 4, 1, 5],"float64"), ) 	 25401960 	 1000 	 0.2981076240539551 	 0.30329227447509766 	 0.2893557548522949 	 0.287142276763916 	 0.13416433334350586 	 0.1347334384918213 	 0.08530759811401367 	 0.07181024551391602 	 
2025-07-30 15:15:07.705512 test begin: paddle.chunk(Tensor([115, 216, 64, 64],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([115, 216, 64, 64],"float16"), 3, axis=1, ) 	 101744640 	 1000 	 0.4358491897583008 	 0.00764775276184082 	 0.42031192779541016 	 2.2411346435546875e-05 	 0.3116440773010254 	 0.5074191093444824 	 0.2543365955352783 	 0.41927123069763184 	 
2025-07-30 15:15:12.750393 test begin: paddle.chunk(Tensor([16, 128, 24807],"float32"), 2, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([16, 128, 24807],"float32"), 2, axis=1, ) 	 50804736 	 1000 	 0.3380258083343506 	 0.006566762924194336 	 0.32383060455322266 	 3.314018249511719e-05 	 0.3146851062774658 	 0.3079395294189453 	 0.2607762813568115 	 0.23250126838684082 	 
2025-07-30 15:15:15.307398 test begin: paddle.chunk(Tensor([16, 128, 25500],"float32"), 2, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([16, 128, 25500],"float32"), 2, axis=1, ) 	 52224000 	 1000 	 0.35797882080078125 	 0.00642704963684082 	 0.3437035083770752 	 1.9550323486328125e-05 	 0.3217792510986328 	 0.3157460689544678 	 0.2675042152404785 	 0.23862051963806152 	 
2025-07-30 15:15:17.881394 test begin: paddle.chunk(Tensor([4, 216, 1838, 64],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 1838, 64],"float16"), 3, axis=1, ) 	 101634048 	 1000 	 0.4338653087615967 	 0.007513284683227539 	 0.4183502197265625 	 2.47955322265625e-05 	 0.310086727142334 	 0.5048439502716064 	 0.2528665065765381 	 0.38660645484924316 	 
2025-07-30 15:15:22.950534 test begin: paddle.chunk(Tensor([4, 216, 64, 1838],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 64, 1838],"float16"), 3, axis=1, ) 	 101634048 	 1000 	 0.433826208114624 	 0.007630825042724609 	 0.41838860511779785 	 2.1457672119140625e-05 	 0.3100013732910156 	 0.5044949054718018 	 0.2526555061340332 	 0.41747212409973145 	 
2025-07-30 15:15:31.375046 test begin: paddle.chunk(Tensor([4, 216, 64, 919],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 64, 919],"float32"), 3, axis=1, ) 	 50817024 	 1000 	 0.3384082317352295 	 0.00759577751159668 	 0.32306337356567383 	 2.0503997802734375e-05 	 0.309950590133667 	 0.30562424659729004 	 0.2523996829986572 	 0.2199258804321289 	 
2025-07-30 15:15:34.025770 test begin: paddle.chunk(Tensor([4, 216, 919, 64],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 919, 64],"float32"), 3, axis=1, ) 	 50817024 	 1000 	 0.338421106338501 	 0.007639408111572266 	 0.32311248779296875 	 2.3365020751953125e-05 	 0.309814453125 	 0.3065063953399658 	 0.2519218921661377 	 0.21488714218139648 	 
2025-07-30 15:15:39.722667 test begin: paddle.chunk(Tensor([58, 216, 64, 64],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([58, 216, 64, 64],"float32"), 3, axis=1, ) 	 51314688 	 1000 	 0.34944915771484375 	 0.00773167610168457 	 0.33437609672546387 	 3.147125244140625e-05 	 0.3142378330230713 	 0.30831098556518555 	 0.2572627067565918 	 0.22289443016052246 	 
2025-07-30 15:15:42.306183 test begin: paddle.clip(Tensor([1408, 36082],"float32"), min=-2, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([1408, 36082],"float32"), min=-2, max=2, ) 	 50803456 	 1000 	 0.2954237461090088 	 0.2979891300201416 	 0.2780005931854248 	 0.28505635261535645 	 0.449737548828125 	 0.7382752895355225 	 0.3984363079071045 	 0.15181231498718262 	 
2025-07-30 15:15:45.838210 test begin: paddle.clip(Tensor([2, 3840, 10240],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([2, 3840, 10240],"float32"), 0, 255, ) 	 78643200 	 1000 	 0.45476651191711426 	 0.45790863037109375 	 0.4383201599121094 	 0.4450676441192627 	 0.6929686069488525 	 1.123642921447754 	 0.6417467594146729 	 0.2292037010192871 	 
2025-07-30 15:15:51.055790 test begin: paddle.clip(Tensor([23, 17, 256, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([23, 17, 256, 256],"float64"), min=0, max=2, ) 	 25624576 	 1000 	 0.3012552261352539 	 0.3011894226074219 	 0.2841033935546875 	 0.2884490489959717 	 0.45150327682495117 	 0.7259774208068848 	 0.3997764587402344 	 0.14842891693115234 	 
2025-07-30 15:15:53.847804 test begin: paddle.clip(Tensor([24, 17, 244, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 244, 256],"float64"), min=0, max=2, ) 	 25485312 	 1000 	 0.3009316921234131 	 0.2996180057525635 	 0.28389668464660645 	 0.2864384651184082 	 0.4494903087615967 	 0.7221426963806152 	 0.3980069160461426 	 0.14767670631408691 	 
2025-07-30 15:15:56.637919 test begin: paddle.clip(Tensor([24, 17, 256, 244],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 256, 244],"float64"), min=0, max=2, ) 	 25485312 	 1000 	 0.29958343505859375 	 0.2996480464935303 	 0.2749748229980469 	 0.2863316535949707 	 0.4496572017669678 	 0.7233350276947021 	 0.3984391689300537 	 0.14765143394470215 	 
2025-07-30 15:15:59.478824 test begin: paddle.clip(Tensor([24, 17, 256, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 256, 256],"float64"), min=0, max=2, ) 	 26738688 	 1000 	 0.3142096996307373 	 0.31434059143066406 	 0.29731059074401855 	 0.3015272617340088 	 0.4713163375854492 	 0.7559924125671387 	 0.41901254653930664 	 0.1546320915222168 	 
2025-07-30 15:16:02.383269 test begin: paddle.clip(Tensor([3, 1654, 10240],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([3, 1654, 10240],"float32"), 0, 255, ) 	 50810880 	 1000 	 0.29529786109924316 	 0.29789066314697266 	 0.27789759635925293 	 0.28486156463623047 	 0.45095133781433105 	 0.7346858978271484 	 0.39934587478637695 	 0.15020990371704102 	 
2025-07-30 15:16:05.768221 test begin: paddle.clip(Tensor([3, 3840, 4411],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([3, 3840, 4411],"float32"), 0, 255, ) 	 50814720 	 1000 	 0.2954576015472412 	 0.2979898452758789 	 0.2789919376373291 	 0.28519225120544434 	 0.44968438148498535 	 0.7375636100769043 	 0.3826632499694824 	 0.1504824161529541 	 
2025-07-30 15:16:09.133935 test begin: paddle.clip(Tensor([8269, 6144],"float32"), min=-2, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([8269, 6144],"float32"), min=-2, max=2, ) 	 50804736 	 1000 	 0.29527711868286133 	 0.2979114055633545 	 0.2780945301055908 	 0.2842676639556885 	 0.4497342109680176 	 0.7347362041473389 	 0.39809322357177734 	 0.15019845962524414 	 
2025-07-30 15:16:12.491978 test begin: paddle.clone(Tensor([145, 12, 112, 261],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 12, 112, 261],"float32"), ) 	 50863680 	 1000 	 0.31493067741394043 	 0.3139665126800537 	 0.16092824935913086 	 0.16035223007202148 	 0.30855798721313477 	 0.04868960380554199 	 0.1576251983642578 	 6.413459777832031e-05 	 
2025-07-30 15:16:15.058335 test begin: paddle.clone(Tensor([145, 12, 261, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 12, 261, 112],"float32"), ) 	 50863680 	 1000 	 0.31496715545654297 	 0.31510210037231445 	 0.16095566749572754 	 0.16147065162658691 	 0.3085792064666748 	 0.04801630973815918 	 0.1576392650604248 	 4.506111145019531e-05 	 
2025-07-30 15:16:17.605344 test begin: paddle.clone(Tensor([145, 28, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 28, 112, 112],"float32"), ) 	 50928640 	 1000 	 0.31403398513793945 	 0.311307430267334 	 0.3047778606414795 	 0.2980356216430664 	 0.3137679100036621 	 0.048004150390625 	 0.2622067928314209 	 5.269050598144531e-05 	 
2025-07-30 15:16:20.238710 test begin: paddle.clone(Tensor([22, 185, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 185, 112, 112],"float32"), ) 	 51054080 	 1000 	 0.3174855709075928 	 0.3149571418762207 	 0.16223573684692383 	 0.1608595848083496 	 0.31893062591552734 	 0.047304630279541016 	 0.16357684135437012 	 3.0517578125e-05 	 
2025-07-30 15:16:22.825419 test begin: paddle.clone(Tensor([22, 64, 112, 323],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 64, 112, 323],"float32"), ) 	 50935808 	 1000 	 0.31406235694885254 	 0.31139254570007324 	 0.30478811264038086 	 0.2977943420410156 	 0.3138153553009033 	 0.04805350303649902 	 0.2620246410369873 	 4.2438507080078125e-05 	 
2025-07-30 15:16:25.422867 test begin: paddle.clone(Tensor([22, 64, 323, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 64, 323, 112],"float32"), ) 	 50935808 	 1000 	 0.31543993949890137 	 0.3113367557525635 	 0.3061857223510742 	 0.297914981842041 	 0.31382179260253906 	 0.04833984375 	 0.26153039932250977 	 3.933906555175781e-05 	 
2025-07-30 15:16:28.067191 test begin: paddle.clone(Tensor([338, 12, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([338, 12, 112, 112],"float32"), ) 	 50878464 	 1000 	 0.3135254383087158 	 0.3110353946685791 	 0.3041837215423584 	 0.29742980003356934 	 0.31342482566833496 	 0.04831838607788086 	 0.26161623001098633 	 5.53131103515625e-05 	 
2025-07-30 15:16:30.757320 test begin: paddle.clone(Tensor([43, 256, 56, 83],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 256, 56, 83],"float32"), ) 	 51165184 	 1000 	 0.31529831886291504 	 0.7601096630096436 	 0.30602073669433594 	 0.2996389865875244 	 0.315321683883667 	 0.04822039604187012 	 0.2636075019836426 	 5.14984130859375e-05 	 
2025-07-30 15:16:34.554487 test begin: paddle.clone(Tensor([43, 256, 83, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 256, 83, 56],"float32"), ) 	 51165184 	 1000 	 0.31528496742248535 	 0.32506346702575684 	 0.30097508430480957 	 0.2977874279022217 	 0.3153402805328369 	 0.050421714782714844 	 0.2637622356414795 	 4.553794860839844e-05 	 
2025-07-30 15:16:37.450739 test begin: paddle.clone(Tensor([43, 377, 56, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 377, 56, 56],"float32"), ) 	 50837696 	 1000 	 0.30832982063293457 	 1.6411433219909668 	 0.15757060050964355 	 0.16015100479125977 	 0.31531643867492676 	 0.05261969566345215 	 0.16107988357543945 	 5.2928924560546875e-05 	 
2025-07-30 15:16:42.733075 test begin: paddle.clone(Tensor([64, 256, 56, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([64, 256, 56, 56],"float32"), ) 	 51380224 	 1000 	 0.3167102336883545 	 0.31412267684936523 	 0.3073902130126953 	 0.29201388359069824 	 0.3167858123779297 	 0.048184871673583984 	 0.255969762802124 	 6.198883056640625e-05 	 
2025-07-30 15:16:45.551074 test begin: paddle.clone(Tensor([64, 64, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([64, 64, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.31671762466430664 	 0.31395816802978516 	 0.30745983123779297 	 0.30066442489624023 	 0.31670308113098145 	 0.0474858283996582 	 0.26491856575012207 	 3.123283386230469e-05 	 
2025-07-30 15:16:48.144863 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9307830333709717 	 0.924919843673706 	 0.9152684211730957 	 0.9103982448577881 	 0.9302365779876709 	 0.07622098922729492 	 0.8637068271636963 	 7.867813110351562e-05 	 
2025-07-30 15:16:53.989701 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3166983127593994 	 0.3367767333984375 	 0.3038816452026367 	 0.16022777557373047 	 0.3106718063354492 	 0.05305743217468262 	 0.2563302516937256 	 3.743171691894531e-05 	 
2025-07-30 15:16:56.076361 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3175179958343506 	 0.3223388195037842 	 0.3020918369293213 	 0.30680251121520996 	 0.3123514652252197 	 0.06775116920471191 	 0.24595260620117188 	 3.2901763916015625e-05 	 
2025-07-30 15:16:58.081935 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3180077075958252 	 0.3229491710662842 	 0.302518367767334 	 0.30866289138793945 	 0.31287527084350586 	 0.0674893856048584 	 0.24681425094604492 	 4.839897155761719e-05 	 
2025-07-30 15:17:00.113741 test begin: paddle.column_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9289693832397461 	 0.9235517978668213 	 0.9135153293609619 	 0.9059216976165771 	 0.9317634105682373 	 0.06640934944152832 	 0.865246057510376 	 4.8160552978515625e-05 	 
2025-07-30 15:17:06.049307 test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 25401654 	 1000 	 0.3183274269104004 	 0.3196532726287842 	 0.3029301166534424 	 0.3058178424835205 	 0.3126976490020752 	 0.06669092178344727 	 0.24621200561523438 	 4.696846008300781e-05 	 
2025-07-30 15:17:08.112926 test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.31984519958496094 	 0.31946325302124023 	 0.304490327835083 	 0.30559277534484863 	 0.31269168853759766 	 0.08080577850341797 	 0.19861173629760742 	 7.605552673339844e-05 	 
2025-07-30 15:17:10.115793 test begin: paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9301207065582275 	 0.9368062019348145 	 0.9144055843353271 	 0.9118072986602783 	 0.9313032627105713 	 0.0674886703491211 	 0.8645987510681152 	 6.341934204101562e-05 	 
2025-07-30 15:17:15.808809 test begin: paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3159940242767334 	 0.31378698348999023 	 0.30287957191467285 	 0.1602311134338379 	 0.31159496307373047 	 0.05290699005126953 	 0.2571396827697754 	 5.0067901611328125e-05 	 
2025-07-30 15:17:17.806517 test begin: paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.3173832893371582 	 0.31809306144714355 	 0.2951805591583252 	 0.29829883575439453 	 0.31259846687316895 	 0.0667734146118164 	 0.24537396430969238 	 5.245208740234375e-05 	 
2025-07-30 15:17:19.781865 test begin: paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9342498779296875 	 0.9289939403533936 	 0.9186382293701172 	 0.9145722389221191 	 0.9463510513305664 	 0.08142471313476562 	 0.8804216384887695 	 7.724761962890625e-05 	 
2025-07-30 15:17:25.485687 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31732678413391113 	 0.32671499252319336 	 0.3016977310180664 	 0.3033027648925781 	 0.31229615211486816 	 0.068817138671875 	 0.2429361343383789 	 7.390975952148438e-05 	 
2025-07-30 15:17:27.554670 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9358847141265869 	 0.9390254020690918 	 0.9203054904937744 	 0.9233500957489014 	 0.9436275959014893 	 0.06765365600585938 	 0.8771476745605469 	 5.364418029785156e-05 	 
2025-07-30 15:17:33.490806 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3175480365753174 	 0.3175535202026367 	 0.3046231269836426 	 0.16023516654968262 	 0.3119697570800781 	 0.05308723449707031 	 0.257293701171875 	 4.696846008300781e-05 	 
2025-07-30 15:17:37.496050 test begin: paddle.column_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.9759707450866699 	 1.418370246887207 	 0.9604027271270752 	 1.3826172351837158 	 0.9608345031738281 	 0.06647872924804688 	 0.8935544490814209 	 3.9577484130859375e-05 	 
2025-07-30 15:17:46.245164 test begin: paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9321033954620361 	 1.0302660465240479 	 0.9162404537200928 	 1.015014410018921 	 0.9399082660675049 	 0.07116317749023438 	 0.8732876777648926 	 6.413459777832031e-05 	 
2025-07-30 15:17:52.219614 test begin: paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3082766532897949 	 0.32813334465026855 	 0.29535579681396484 	 0.16022181510925293 	 0.32767224311828613 	 0.06538510322570801 	 0.2735106945037842 	 7.128715515136719e-05 	 
2025-07-30 15:17:54.260763 test begin: paddle.combinations(Tensor([2540160101],"int64"), 0, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([2540160101],"int64"), 0, True, ) 	 2540160101 	 1000 	 0.012434959411621094 	 0.004070281982421875 	 9.059906005859375e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:18:30.171751 test begin: paddle.combinations(Tensor([50803201],"int32"), 1, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([50803201],"int32"), 1, True, ) 	 50803201 	 1000 	 5.464588403701782 	 2.199767589569092 	 0.0031859874725341797 	 0.0013167858123779297 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:18:44.290245 test begin: paddle.complex(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), ) 	 101606528 	 1000 	 0.5921316146850586 	 0.596168041229248 	 0.5831081867218018 	 0.5759913921356201 	 0.5908715724945068 	 0.06717300415039062 	 0.5339457988739014 	 5.7697296142578125e-05 	 
2025-07-30 15:18:52.073723 test begin: paddle.complex(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), ) 	 101613568 	 1000 	 0.5929572582244873 	 0.5896778106689453 	 0.5840826034545898 	 0.5766332149505615 	 0.591876745223999 	 0.07097411155700684 	 0.5351204872131348 	 7.343292236328125e-05 	 
2025-07-30 15:18:56.632793 test begin: paddle.complex(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 51380224 	 1000 	 0.504692554473877 	 0.47438859939575195 	 0.4950273036956787 	 0.4605855941772461 	 0.5155985355377197 	 0.2874128818511963 	 0.4566614627838135 	 0.19733762741088867 	 
2025-07-30 15:19:00.173070 test begin: paddle.complex(Tensor([20, 2417, 1051],"float32"), Tensor([20, 2417, 1051],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 2417, 1051],"float32"), Tensor([20, 2417, 1051],"float32"), ) 	 101610680 	 1000 	 0.5929388999938965 	 0.5895874500274658 	 0.5838577747344971 	 0.5766341686248779 	 0.5928447246551514 	 0.06848812103271484 	 0.5342504978179932 	 7.414817810058594e-05 	 
2025-07-30 15:19:04.519229 test begin: paddle.complex(Tensor([20, 2538, 1001],"float32"), Tensor([20, 2538, 1001],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 2538, 1001],"float32"), Tensor([20, 2538, 1001],"float32"), ) 	 101621520 	 1000 	 0.5931684970855713 	 0.5896916389465332 	 0.5843241214752197 	 0.5762894153594971 	 0.5923042297363281 	 0.08203363418579102 	 0.5345797538757324 	 5.626678466796875e-05 	 
2025-07-30 15:19:08.883913 test begin: paddle.complex(Tensor([20, 64, 39691],"float32"), Tensor([20, 64, 39691],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 64, 39691],"float32"), Tensor([20, 64, 39691],"float32"), ) 	 101608960 	 1000 	 0.592911958694458 	 0.6066677570343018 	 0.5838794708251953 	 0.5758848190307617 	 0.5919497013092041 	 0.0679924488067627 	 0.5349719524383545 	 8.654594421386719e-05 	 
2025-07-30 15:19:13.348955 test begin: paddle.complex(Tensor([756, 64, 1051],"float32"), Tensor([756, 64, 1051],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([756, 64, 1051],"float32"), Tensor([756, 64, 1051],"float32"), ) 	 101703168 	 1000 	 0.593419075012207 	 0.5922360420227051 	 0.5845005512237549 	 0.577927827835083 	 0.5923902988433838 	 0.06744194030761719 	 0.5356531143188477 	 6.961822509765625e-05 	 
2025-07-30 15:19:17.628652 test begin: paddle.complex(Tensor([794, 64, 1001],"float32"), Tensor([794, 64, 1001],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([794, 64, 1001],"float32"), Tensor([794, 64, 1001],"float32"), ) 	 101733632 	 1000 	 0.5947763919830322 	 0.5910453796386719 	 0.5858194828033447 	 0.5775494575500488 	 0.5920207500457764 	 0.06738829612731934 	 0.5081067085266113 	 7.462501525878906e-05 	 
2025-07-30 15:19:21.977396 test begin: paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), ) 	 51380224 	 1000 	 0.4837803840637207 	 0.47417426109313965 	 0.4741077423095703 	 0.460277795791626 	 0.5112640857696533 	 0.28746724128723145 	 0.45271921157836914 	 0.20075607299804688 	 
2025-07-30 15:19:25.502242 test begin: paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 101711872 	 1000 	 0.5935125350952148 	 0.590101957321167 	 0.5844786167144775 	 0.57680344581604 	 0.5922329425811768 	 0.06827878952026367 	 0.5363295078277588 	 6.914138793945312e-05 	 
2025-07-30 15:19:29.848636 test begin: paddle.concat(list[Tensor([101606401],"bfloat16"),], )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([101606401],"bfloat16"),], ) 	 101606401 	 1000 	 0.31593894958496094 	 0.3206312656402588 	 0.16141986846923828 	 0.16025662422180176 	 0.6093432903289795 	 0.45321130752563477 	 0.3113059997558594 	 0.3725097179412842 	 
2025-07-30 15:19:34.732740 test begin: paddle.concat(list[Tensor([254, 32, 112, 112],"float16"),Tensor([254, 32, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([254, 32, 112, 112],"float16"),Tensor([254, 32, 112, 112],"float16"),], axis=1, ) 	 203915264 	 1000 	 0.6136643886566162 	 0.9060168266296387 	 0.6010212898254395 	 0.8919682502746582 	 0.9428155422210693 	 0.07033848762512207 	 0.883150577545166 	 5.2928924560546875e-05 	 
2025-07-30 15:19:44.799629 test begin: paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6176893711090088 	 0.9191598892211914 	 0.6049613952636719 	 0.8984026908874512 	 0.9419641494750977 	 0.06069159507751465 	 0.8818159103393555 	 4.8160552978515625e-05 	 
2025-07-30 15:19:57.675610 test begin: paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 32, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 32, 112, 112],"float16"),], axis=1, ) 	 308281344 	 1000 	 0.9281432628631592 	 1.6148805618286133 	 0.9153435230255127 	 1.6007201671600342 	 1.4293203353881836 	 0.0738835334777832 	 1.3692281246185303 	 5.1021575927734375e-05 	 
2025-07-30 15:20:13.174259 test begin: paddle.concat(list[Tensor([512, 32, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, ) 	 308281344 	 1000 	 0.9295759201049805 	 1.5589663982391357 	 0.9169247150421143 	 1.527895450592041 	 1.435250997543335 	 0.061873674392700195 	 1.3751139640808105 	 3.838539123535156e-05 	 
2025-07-30 15:20:28.569058 test begin: paddle.concat(list[Tensor([512, 32, 112, 56],"float16"),Tensor([512, 32, 112, 56],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 112, 56],"float16"),Tensor([512, 32, 112, 56],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6176543235778809 	 1.1569819450378418 	 0.6049256324768066 	 0.9012069702148438 	 0.9419786930084229 	 0.06341433525085449 	 0.8822436332702637 	 6.699562072753906e-05 	 
2025-07-30 15:20:40.429925 test begin: paddle.concat(list[Tensor([512, 32, 56, 112],"float16"),Tensor([512, 32, 56, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 56, 112],"float16"),Tensor([512, 32, 56, 112],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6193039417266846 	 0.916297435760498 	 0.6066195964813232 	 0.9024369716644287 	 0.9432492256164551 	 0.061330556869506836 	 0.8830523490905762 	 4.029273986816406e-05 	 
2025-07-30 15:20:50.655848 test begin: paddle.conj(Tensor([2, 20, 2, 635041],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 20, 2, 635041],"float32"), ) 	 50803280 	 1000 	 0.30950140953063965 	 0.0017747879028320312 	 0.301408052444458 	 1.4781951904296875e-05 	 0.31006741523742676 	 0.045931100845336914 	 0.261533260345459 	 6.747245788574219e-05 	 
2025-07-30 15:20:52.935678 test begin: paddle.conj(Tensor([2, 20, 423361, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 20, 423361, 3],"float32"), ) 	 50803320 	 1000 	 0.3106389045715332 	 0.0017714500427246094 	 0.30243921279907227 	 1.6927719116210938e-05 	 0.3113729953765869 	 0.045089006423950195 	 0.262833833694458 	 3.814697265625e-05 	 
2025-07-30 15:20:55.162820 test begin: paddle.conj(Tensor([2, 4233601, 2, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 4233601, 2, 3],"float32"), ) 	 50803212 	 1000 	 0.30690717697143555 	 0.0018036365509033203 	 0.2987782955169678 	 1.7404556274414062e-05 	 0.30953121185302734 	 0.04515790939331055 	 0.2612786293029785 	 8.726119995117188e-05 	 
2025-07-30 15:20:57.436441 test begin: paddle.conj(Tensor([423361, 20, 2, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([423361, 20, 2, 3],"float32"), ) 	 50803320 	 1000 	 0.30950450897216797 	 0.00176239013671875 	 0.3014044761657715 	 1.5735626220703125e-05 	 0.3100624084472656 	 0.04454231262207031 	 0.2612128257751465 	 3.910064697265625e-05 	 
2025-07-30 15:21:00.114871 test begin: paddle.copysign(Tensor([12, 1058401, 2],"float64"), Tensor([12, 1058401, 2],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 1058401, 2],"float64"), Tensor([12, 1058401, 2],"float64"), ) 	 50803248 	 1000 	 0.44883179664611816 	 0.4463481903076172 	 0.4360349178314209 	 0.4312756061553955 	 0.7403199672698975 	 1.5198016166687012 	 0.6816158294677734 	 0.3114802837371826 	 
2025-07-30 15:21:05.611098 test begin: paddle.copysign(Tensor([12, 20, 105841],"float64"), Tensor([12, 20, 105841],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 20, 105841],"float64"), Tensor([12, 20, 105841],"float64"), ) 	 50803680 	 1000 	 0.448378324508667 	 0.45545125007629395 	 0.4360618591308594 	 0.43080639839172363 	 0.7403395175933838 	 1.5195040702819824 	 0.6821396350860596 	 0.31024885177612305 	 
2025-07-30 15:21:13.365595 test begin: paddle.copysign(Tensor([12, 20, 211681],"float32"), Tensor([12, 20, 211681],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 20, 211681],"float32"), Tensor([12, 20, 211681],"float32"), ) 	 101606880 	 1000 	 0.4498140811920166 	 0.4462008476257324 	 0.4370279312133789 	 0.43488335609436035 	 1.1843583583831787 	 1.5557982921600342 	 1.1255567073822021 	 0.31758928298950195 	 
2025-07-30 15:21:19.452695 test begin: paddle.copysign(Tensor([12, 2116801, 2],"float32"), Tensor([12, 2116801, 2],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 2116801, 2],"float32"), Tensor([12, 2116801, 2],"float32"), ) 	 101606448 	 1000 	 0.44979429244995117 	 0.4608290195465088 	 0.4366462230682373 	 0.43474817276000977 	 1.1840708255767822 	 1.5541834831237793 	 1.1223230361938477 	 0.3175201416015625 	 
2025-07-30 15:21:25.458438 test begin: paddle.copysign(Tensor([1270081, 20, 2],"float32"), Tensor([1270081, 20, 2],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([1270081, 20, 2],"float32"), Tensor([1270081, 20, 2],"float32"), ) 	 101606480 	 1000 	 0.44992756843566895 	 0.4461939334869385 	 0.4371337890625 	 0.43492674827575684 	 1.184250831604004 	 1.5529966354370117 	 1.125229835510254 	 0.31755733489990234 	 
2025-07-30 15:21:31.494808 test begin: paddle.copysign(Tensor([635041, 20, 2],"float64"), Tensor([635041, 20, 2],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([635041, 20, 2],"float64"), Tensor([635041, 20, 2],"float64"), ) 	 50803280 	 1000 	 0.4496941566467285 	 0.4759397506713867 	 0.43718743324279785 	 0.4313068389892578 	 0.7403075695037842 	 1.5180463790893555 	 0.6809096336364746 	 0.31038355827331543 	 
2025-07-30 15:21:40.370026 test begin: paddle.cos(Tensor([1587601, 32],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 0.2954697608947754 	 0.2980828285217285 	 0.28678131103515625 	 0.2872593402862549 	 0.44985032081604004 	 1.0404689311981201 	 0.398327112197876 	 0.35445237159729004 	 
2025-07-30 15:21:44.114305 test begin: paddle.cos(Tensor([198451, 256],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([198451, 256],"float32"), ) 	 50803456 	 1000 	 0.2955789566040039 	 0.30167508125305176 	 0.2870016098022461 	 0.28827500343322754 	 0.45116162300109863 	 1.040461540222168 	 0.3994276523590088 	 0.35444116592407227 	 
2025-07-30 15:21:47.830208 test begin: paddle.cos(Tensor([32768, 1551],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.29571533203125 	 0.3044300079345703 	 0.2869832515716553 	 0.28731250762939453 	 0.4515111446380615 	 1.0433571338653564 	 0.39136600494384766 	 0.3545863628387451 	 
2025-07-30 15:21:51.556007 test begin: paddle.cos(Tensor([396901, 128],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2956366539001465 	 0.3009345531463623 	 0.2869429588317871 	 0.2870955467224121 	 0.4499936103820801 	 1.041579008102417 	 0.39803338050842285 	 0.3544292449951172 	 
2025-07-30 15:21:55.264798 test begin: paddle.cos(Tensor([5000, 10161],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([5000, 10161],"float32"), ) 	 50805000 	 1000 	 0.2954742908477783 	 0.2980384826660156 	 0.28687357902526855 	 0.2872049808502197 	 0.4497969150543213 	 1.0404369831085205 	 0.3980679512023926 	 0.3544638156890869 	 
2025-07-30 15:21:58.904685 test begin: paddle.cos(Tensor([8192, 6202],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.29565930366516113 	 0.2981078624725342 	 0.28702425956726074 	 0.28716444969177246 	 0.44991540908813477 	 1.040574312210083 	 0.396334171295166 	 0.35448598861694336 	 
2025-07-30 15:22:02.588233 test begin: paddle.cosh(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2948029041290283 	 0.3019533157348633 	 0.28618597984313965 	 0.28751134872436523 	 0.4497079849243164 	 0.7450981140136719 	 0.3977532386779785 	 0.381817102432251 	 
2025-07-30 15:22:08.720718 test begin: paddle.cosh(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.294769287109375 	 0.2985262870788574 	 0.28606343269348145 	 0.28756141662597656 	 0.44974303245544434 	 0.7450587749481201 	 0.39772653579711914 	 0.3794689178466797 	 
2025-07-30 15:22:12.105771 test begin: paddle.cosh(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2947847843170166 	 0.3007528781890869 	 0.2860708236694336 	 0.28743958473205566 	 0.4496896266937256 	 0.74271559715271 	 0.3982725143432617 	 0.3794434070587158 	 
2025-07-30 15:22:15.502716 test begin: paddle.cosh(Tensor([28, 32, 241, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([28, 32, 241, 241],"float32"), ) 	 52040576 	 1000 	 0.3044919967651367 	 0.30573177337646484 	 0.2958226203918457 	 0.29448890686035156 	 0.4606316089630127 	 0.7604944705963135 	 0.40860819816589355 	 0.38849496841430664 	 
2025-07-30 15:22:18.987191 test begin: paddle.cosh(Tensor([8, 110, 241, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 110, 241, 241],"float32"), ) 	 51111280 	 1000 	 0.29648566246032715 	 0.3149855136871338 	 0.28792381286621094 	 0.2891275882720947 	 0.4550318717956543 	 0.7471158504486084 	 0.4031352996826172 	 0.38170909881591797 	 
2025-07-30 15:22:22.391195 test begin: paddle.cosh(Tensor([8, 32, 241, 824],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 32, 241, 824],"float32"), ) 	 50837504 	 1000 	 0.2950296401977539 	 0.2987546920776367 	 0.28621864318847656 	 0.2877180576324463 	 0.4499971866607666 	 0.7457501888275146 	 0.39794278144836426 	 0.3822519779205322 	 
2025-07-30 15:22:25.898073 test begin: paddle.cosh(Tensor([8, 32, 824, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 32, 824, 241],"float32"), ) 	 50837504 	 1000 	 0.2950124740600586 	 0.2987182140350342 	 0.2864212989807129 	 0.2876298427581787 	 0.44998884201049805 	 0.7431640625 	 0.3978440761566162 	 0.37972259521484375 	 
2025-07-30 15:22:29.189237 test begin: paddle.cosh(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.29615354537963867 	 0.2985875606536865 	 0.2871885299682617 	 0.2871997356414795 	 0.4497356414794922 	 0.7427148818969727 	 0.39742493629455566 	 0.37946367263793945 	 
2025-07-30 15:22:32.577665 test begin: paddle.cosh(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.29475927352905273 	 0.3058784008026123 	 0.2858750820159912 	 0.2886335849761963 	 0.45088720321655273 	 0.7427916526794434 	 0.39902496337890625 	 0.3794994354248047 	 
2025-07-30 15:22:37.797412 test begin: paddle.cosh(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.2947721481323242 	 0.31348443031311035 	 0.28588294982910156 	 0.2875862121582031 	 0.4497084617614746 	 0.7439312934875488 	 0.39774394035339355 	 0.3794572353363037 	 
2025-07-30 15:22:41.199962 test begin: paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401796 	 1000 	 0.6024541854858398 	 0.527595043182373 	 0.20479154586791992 	 0.1797938346862793 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:22:43.373774 test begin: paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401796 	 1000 	 0.600980281829834 	 0.528862476348877 	 0.204756498336792 	 0.17974305152893066 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 129601, 1]) and output[0] has a shape of torch.Size([1, 129601]).
2025-07-30 15:22:45.484564 test begin: paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401670 	 1000 	 0.6151602268218994 	 0.5453615188598633 	 0.1565265655517578 	 0.1393263339996338 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:22:47.617504 test begin: paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401670 	 1000 	 0.6127719879150391 	 0.5452680587768555 	 0.15655875205993652 	 0.13928771018981934 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 5, 1]) and output[0] has a shape of torch.Size([1, 5]).
2025-07-30 15:22:49.916227 test begin: paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401670 	 1000 	 0.6122105121612549 	 0.5543665885925293 	 0.15743470191955566 	 0.14154338836669922 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:22:52.060685 test begin: paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401670 	 1000 	 0.6108353137969971 	 0.5544884204864502 	 0.15607023239135742 	 0.14169621467590332 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 5, 1]) and output[0] has a shape of torch.Size([1, 5]).
2025-07-30 15:22:54.187913 test begin: paddle.count_nonzero(Tensor([2, 1270081, 4, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 1270081, 4, 5],"float32"), axis=-1, keepdim=False, ) 	 50803240 	 1000 	 0.9741334915161133 	 1.062230110168457 	 0.3323514461517334 	 0.3620333671569824 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:22:58.202247 test begin: paddle.count_nonzero(Tensor([2, 3, 1693441, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 3, 1693441, 5],"float32"), axis=-1, keepdim=False, ) 	 50803230 	 1000 	 0.9723918437957764 	 1.0622522830963135 	 0.33231019973754883 	 0.3620171546936035 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:23:02.116362 test begin: paddle.count_nonzero(Tensor([2, 3, 4, 2116801],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 3, 4, 2116801],"float32"), axis=-1, keepdim=False, ) 	 50803224 	 1000 	 0.8719985485076904 	 0.8695714473724365 	 0.2223505973815918 	 0.22176361083984375 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:23:05.514195 test begin: paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25402580 	 1000 	 0.5925884246826172 	 0.5295600891113281 	 0.2019035816192627 	 0.18041634559631348 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:23:07.633065 test begin: paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25402580 	 1000 	 0.5952873229980469 	 0.5405077934265137 	 0.2031388282775879 	 0.18183588981628418 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([25921, 1, 5, 1]) and output[0] has a shape of torch.Size([25921, 5]).
2025-07-30 15:23:11.649403 test begin: paddle.count_nonzero(Tensor([846721, 3, 4, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([846721, 3, 4, 5],"float32"), axis=-1, keepdim=False, ) 	 50803260 	 1000 	 0.9718160629272461 	 1.0649807453155518 	 0.3311591148376465 	 0.36201024055480957 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:23:15.620217 test begin: paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.018733501434326172 	 0.020226001739501953 	 1.6927719116210938e-05 	 5.435943603515625e-05 	 0.14828181266784668 	 0.16303133964538574 	 0.09728097915649414 	 0.0152587890625 	 combined
2025-07-30 15:23:16.454053 test begin: paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.018367290496826172 	 0.01934075355529785 	 1.9073486328125e-05 	 2.3126602172851562e-05 	 0.15320444107055664 	 0.16873574256896973 	 0.10249853134155273 	 0.019159555435180664 	 combined
2025-07-30 15:23:17.298067 test begin: paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.018278121948242188 	 0.01950836181640625 	 1.5974044799804688e-05 	 2.7894973754882812e-05 	 0.14652204513549805 	 0.16750550270080566 	 0.09583640098571777 	 0.019025325775146484 	 combined
2025-07-30 15:23:18.165869 test begin: paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], ) 	 25486272 	 1000 	 0.019726276397705078 	 0.01309823989868164 	 2.1457672119140625e-05 	 2.0265579223632812e-05 	 0.15027570724487305 	 0.15080475807189941 	 0.09832596778869629 	 0.030704021453857422 	 combined
2025-07-30 15:23:18.983949 test begin: paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], ) 	 25401603 	 1000 	 0.018702983856201172 	 0.013413190841674805 	 1.6689300537109375e-05 	 2.6464462280273438e-05 	 0.1476597785949707 	 0.14338994026184082 	 0.09690117835998535 	 0.03664374351501465 	 combined
2025-07-30 15:23:19.809083 test begin: paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=1, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=1, ) 	 50803218 	 1000 	 0.4501519203186035 	 0.4495816230773926 	 0.43933796882629395 	 0.4357035160064697 	 0.7498311996459961 	 0.8998985290527344 	 0.6914808750152588 	 0.4592115879058838 	 
2025-07-30 15:23:23.964433 test begin: paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=2, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=2, ) 	 50803218 	 1000 	 0.4513587951660156 	 0.45066022872924805 	 0.4409325122833252 	 0.43665075302124023 	 0.7569260597229004 	 0.9021866321563721 	 0.6994202136993408 	 0.4615168571472168 	 
2025-07-30 15:23:27.984020 test begin: paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=0, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=0, ) 	 50803218 	 1000 	 0.4473609924316406 	 0.4483020305633545 	 0.4367711544036865 	 0.4342799186706543 	 0.7414743900299072 	 0.8965795040130615 	 0.6835424900054932 	 0.4580726623535156 	 
2025-07-30 15:23:32.148489 test begin: paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=2, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=2, ) 	 50803218 	 1000 	 0.45136594772338867 	 0.4507331848144531 	 0.44088006019592285 	 0.43676185607910156 	 0.7570993900299072 	 0.9009945392608643 	 0.6989724636077881 	 0.46022772789001465 	 
2025-07-30 15:23:37.338849 test begin: paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=0, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=0, ) 	 50803218 	 1000 	 0.44736433029174805 	 0.4601175785064697 	 0.43683791160583496 	 0.42844319343566895 	 0.7414207458496094 	 0.8993675708770752 	 0.6830615997314453 	 0.4581279754638672 	 
2025-07-30 15:23:41.601655 test begin: paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=1, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=1, ) 	 50803218 	 1000 	 0.4472537040710449 	 0.4474658966064453 	 0.43650102615356445 	 0.43346214294433594 	 0.7418501377105713 	 0.8965737819671631 	 0.6836042404174805 	 0.45880126953125 	 
2025-07-30 15:23:45.567557 test begin: paddle.cummax(Tensor([100, 2080],"float32"), )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), ) 	 208000 	 1000 	 11.338615894317627 	 0.8110661506652832 	 11.319637537002563 	 0.7964227199554443 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:23:58.050780 test begin: paddle.cummax(Tensor([100, 2080],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), axis=-1, ) 	 208000 	 1000 	 0.1798570156097412 	 0.03364086151123047 	 0.1646285057067871 	 0.01899266242980957 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:23:58.333524 test begin: paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, ) 	 20802080 	 1000 	 5.702130079269409 	 5.712794780731201 	 5.689348220825195 	 5.697818040847778 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:24:11.388304 test begin: paddle.cummax(Tensor([2080, 100],"float32"), )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), ) 	 208000 	 1000 	 11.336153745651245 	 0.813342809677124 	 11.317447900772095 	 0.7963838577270508 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/base/libpaddle.so

2025-07-30 13:31:45.484994 test begin: paddle.cummax(Tensor([2080, 100],"float32"), axis=-2, )
W0730 13:31:45.780959  2087 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), axis=-2, ) 	 208000 	 1000 	 0.43382716178894043 	 0.409970760345459 	 0.4175999164581299 	 0.3923380374908447 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:31:47.096979 test begin: paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, ) 	 20800100 	 1000 	 0.553091287612915 	 3.534853935241699 	 0.5396499633789062 	 3.514152765274048 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:31:54.010018 test begin: paddle.cummin(Tensor([100, 508033],"float32"), axis=-1, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([100, 508033],"float32"), axis=-1, ) 	 50803300 	 1000 	 58.803982973098755 	 2.542922019958496 	 58.78254580497742 	 2.519430160522461 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:00.625693 test begin: paddle.cummin(Tensor([100, 508033],"float32"), axis=-2, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([100, 508033],"float32"), axis=-2, ) 	 50803300 	 1000 	 0.7916629314422607 	 0.7915523052215576 	 0.7785623073577881 	 0.7684285640716553 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:11.233306 test begin: paddle.cummin(Tensor([508033, 100],"float32"), axis=-1, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([508033, 100],"float32"), axis=-1, ) 	 50803300 	 1000 	 1.334357500076294 	 8.545865058898926 	 1.3179466724395752 	 8.52112102508545 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:25.698702 test begin: paddle.cummin(Tensor([508033, 100],"float32"), axis=-2, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([508033, 100],"float32"), axis=-2, ) 	 50803300 	 1000 	 250.1394317150116 	 249.94837951660156 	 250.12609791755676 	 249.93293046951294 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:42:52.747974 test begin: paddle.cumprod(Tensor([2, 127009, 10, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 127009, 10, 10],"float64"), 1, ) 	 25401800 	 1000 	 65.89965224266052 	 64.02215385437012 	 65.88769459724426 	 64.00906348228455 	 257.05939626693726 	 65.79163980484009 	 0.06560206413269043 	 0.0649874210357666 	 
2025-07-30 13:50:27.374229 test begin: paddle.cumprod(Tensor([2, 3, 10, 423361],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 10, 423361],"float64"), 1, ) 	 25401660 	 1000 	 0.3024866580963135 	 0.30290842056274414 	 0.2933804988861084 	 0.2920501232147217 	 2.8497138023376465 	 2.0410521030426025 	 0.0003540515899658203 	 0.0012927055358886719 	 
2025-07-30 13:50:34.082660 test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=0, ) 	 50803272 	 1000 	 0.32959461212158203 	 1.715918779373169 	 0.3204231262207031 	 0.29734134674072266 	 3.425832986831665 	 2.1170246601104736 	 0.00044155120849609375 	 0.0013103485107421875 	 
2025-07-30 13:50:48.316103 test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=1, ) 	 50803272 	 1000 	 0.32822155952453613 	 0.3214104175567627 	 0.31250429153442383 	 0.30609798431396484 	 3.2672441005706787 	 2.1303598880767822 	 0.0004303455352783203 	 0.0013098716735839844 	 
2025-07-30 13:50:55.980548 test begin: paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=0, ) 	 50803290 	 1000 	 0.3295431137084961 	 0.31166934967041016 	 0.32018208503723145 	 0.3003575801849365 	 3.410330295562744 	 2.115060567855835 	 0.00047588348388671875 	 0.0013179779052734375 	 
2025-07-30 13:51:03.823075 test begin: paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=1, ) 	 50803290 	 1000 	 0.3223130702972412 	 0.3227393627166748 	 0.31302881240844727 	 0.3065035343170166 	 3.269648313522339 	 2.129727363586426 	 0.00041937828063964844 	 0.0013308525085449219 	 
2025-07-30 13:51:14.112493 test begin: paddle.cumprod(Tensor([2, 3, 423361, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 10],"float64"), 1, ) 	 25401660 	 1000 	 0.3063180446624756 	 0.30291128158569336 	 0.2933480739593506 	 0.2916069030761719 	 2.848783493041992 	 2.04178524017334 	 0.00035190582275390625 	 0.0012979507446289062 	 
2025-07-30 13:51:20.624233 test begin: paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=0, ) 	 50803320 	 1000 	 0.3295574188232422 	 0.3117337226867676 	 0.3137192726135254 	 0.29380106925964355 	 3.4178051948547363 	 2.1154239177703857 	 0.0004127025604248047 	 0.001308441162109375 	 
2025-07-30 13:51:28.564212 test begin: paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=1, ) 	 50803320 	 1000 	 0.3217484951019287 	 0.31909632682800293 	 0.3125452995300293 	 0.30623459815979004 	 3.2653486728668213 	 2.130716323852539 	 0.000431060791015625 	 0.0013346672058105469 	 
2025-07-30 13:51:37.715789 test begin: paddle.cumprod(Tensor([2, 423361, 3, 4, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 423361, 3, 4, 5],"float32"), dim=0, ) 	 50803320 	 1000 	 0.342602014541626 	 0.31345415115356445 	 0.31784844398498535 	 0.300264835357666 	 3.4189112186431885 	 2.1171815395355225 	 0.00047397613525390625 	 0.001313924789428711 	 
2025-07-30 13:51:47.590341 test begin: paddle.cumprod(Tensor([282241, 3, 3, 4, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([282241, 3, 3, 4, 5],"float32"), dim=1, ) 	 50803380 	 1000 	 0.32773661613464355 	 0.348860502243042 	 0.31183838844299316 	 0.30452585220336914 	 3.2720396518707275 	 2.1425657272338867 	 0.0004260540008544922 	 0.001329660415649414 	 
2025-07-30 13:51:56.648169 test begin: paddle.cumprod(Tensor([84673, 3, 10, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([84673, 3, 10, 10],"float64"), 1, ) 	 25401900 	 1000 	 0.30431032180786133 	 0.30408167839050293 	 0.2930724620819092 	 0.2929229736328125 	 2.8435046672821045 	 2.044915199279785 	 0.0003514289855957031 	 0.0012862682342529297 	 
2025-07-30 13:52:03.240775 test begin: paddle.cumsum(Tensor([50803201],"float32"), axis=0, )
[Prof] paddle.cumsum 	 paddle.cumsum(Tensor([50803201],"float32"), axis=0, ) 	 50803201 	 1000 	 0.3476104736328125 	 0.3292887210845947 	 4.744529724121094e-05 	 0.16815781593322754 	 0.4010963439941406 	 0.9454550743103027 	 3.4809112548828125e-05 	 0.24161744117736816 	 
2025-07-30 13:52:06.873221 test begin: paddle.deg2rad(Tensor([25401601],"int64"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 0.38088345527648926 	 0.23280978202819824 	 0.1937863826751709 	 0.2180337905883789 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:52:08.663349 test begin: paddle.deg2rad(Tensor([50803201],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2962064743041992 	 0.29794979095458984 	 0.28119897842407227 	 0.28328561782836914 	 0.296281099319458 	 0.29778194427490234 	 0.24481701850891113 	 0.20883774757385254 	 
2025-07-30 13:52:11.405238 test begin: paddle.deg2rad(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2963242530822754 	 0.2978813648223877 	 0.2813427448272705 	 0.2831707000732422 	 0.296220064163208 	 0.29775381088256836 	 0.24352502822875977 	 0.21381711959838867 	 
2025-07-30 13:52:14.216953 test begin: paddle.deg2rad(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2961125373840332 	 0.297954797744751 	 0.2725234031677246 	 0.27599358558654785 	 0.29625749588012695 	 0.29778456687927246 	 0.2324690818786621 	 0.2059650421142578 	 
2025-07-30 13:52:17.007289 test begin: paddle.deg2rad(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29610180854797363 	 0.29788827896118164 	 0.2810831069946289 	 0.2834131717681885 	 0.29622817039489746 	 0.29775428771972656 	 0.24448156356811523 	 0.2151660919189453 	 
2025-07-30 13:52:19.873728 test begin: paddle.diag(Tensor([20000, 25402],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), ) 	 508040000 	 1000 	 0.009361505508422852 	 0.030378103256225586 	 1.5497207641601562e-05 	 7.62939453125e-05 	 1.5185370445251465 	 1.326909065246582 	 0.7756409645080566 	 0.6779906749725342 	 
2025-07-30 13:52:37.682683 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.009745359420776367 	 0.017917156219482422 	 1.33514404296875e-05 	 4.506111145019531e-05 	 1.518434762954712 	 1.3270580768585205 	 0.7755136489868164 	 0.678015947341919 	 
2025-07-30 13:52:48.580125 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=1, ) 	 508040000 	 1000 	 0.009710311889648438 	 0.019407987594604492 	 1.7642974853515625e-05 	 7.367134094238281e-05 	 1.5208780765533447 	 1.3267419338226318 	 0.7769880294799805 	 0.6779019832611084 	 
2025-07-30 13:53:01.396769 test begin: paddle.diag(Tensor([254020, 2000],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), ) 	 508040000 	 1000 	 0.009402990341186523 	 0.018041133880615234 	 2.5987625122070312e-05 	 4.410743713378906e-05 	 1.5020580291748047 	 1.3187286853790283 	 0.7668581008911133 	 0.673778772354126 	 
2025-07-30 13:53:12.099711 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.009704113006591797 	 0.017763853073120117 	 1.2636184692382812e-05 	 3.719329833984375e-05 	 1.5033819675445557 	 1.3186569213867188 	 0.7679736614227295 	 0.673731803894043 	 
2025-07-30 13:53:22.908771 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=1, ) 	 508040000 	 1000 	 0.009607791900634766 	 0.017891407012939453 	 1.71661376953125e-05 	 4.792213439941406e-05 	 1.5022635459899902 	 1.318723201751709 	 0.7672276496887207 	 0.6737508773803711 	 
2025-07-30 13:53:33.645566 test begin: paddle.diag_embed(Tensor([1058401, 3, 8],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([1058401, 3, 8],"float64"), ) 	 25401624 	 1000 	 8.489738702774048 	 2.6120197772979736 	 8.797645568847656e-05 	 1.3353142738342285 	 None 	 None 	 None 	 None 	 
2025-07-30 13:53:45.316953 test begin: paddle.diag_embed(Tensor([1411201, 3, 6],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([1411201, 3, 6],"float64"), ) 	 25401618 	 1000 	 2.773383140563965 	 2.1947124004364014 	 0.00012111663818359375 	 1.1212422847747803 	 None 	 None 	 None 	 None 	 
2025-07-30 13:53:50.893639 test begin: paddle.diag_embed(Tensor([2, 1058401, 12],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 1058401, 12],"float64"), ) 	 25401624 	 1000 	 4.24254035949707 	 3.832003116607666 	 9.250640869140625e-05 	 0.9791779518127441 	 None 	 None 	 None 	 None 	 
2025-07-30 13:53:59.566826 test begin: paddle.diag_embed(Tensor([2, 1587601, 8],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 1587601, 8],"float64"), ) 	 25401616 	 1000 	 6.829041242599487 	 2.6101739406585693 	 8.511543273925781e-05 	 1.3336036205291748 	 None 	 None 	 None 	 None 	 
2025-07-30 13:54:10.995748 test begin: paddle.diag_embed(Tensor([2, 2116801, 6],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 2116801, 6],"float64"), ) 	 25401612 	 1000 	 2.73093581199646 	 2.195993185043335 	 9.751319885253906e-05 	 1.1210658550262451 	 None 	 None 	 None 	 None 	 
2025-07-30 13:54:16.423266 test begin: paddle.diag_embed(Tensor([705601, 3, 12],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([705601, 3, 12],"float64"), ) 	 25401636 	 1000 	 3.96926212310791 	 3.831575870513916 	 8.606910705566406e-05 	 0.9792213439941406 	 None 	 None 	 None 	 None 	 
2025-07-30 13:54:24.786484 test begin: paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.003873109817504883 	 0.004505634307861328 	 8.344650268554688e-06 	 1.811981201171875e-05 	 0.15082955360412598 	 0.1387641429901123 	 0.07691264152526855 	 0.047997236251831055 	 
2025-07-30 13:54:25.626210 test begin: paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), ) 	 25401744 	 1000 	 0.003727436065673828 	 0.0044345855712890625 	 7.867813110351562e-06 	 1.811981201171875e-05 	 0.15137743949890137 	 0.13876676559448242 	 0.07728815078735352 	 0.0417628288269043 	 
2025-07-30 13:54:26.409352 test begin: paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), ) 	 25443936 	 1000 	 0.003854513168334961 	 0.0044634342193603516 	 7.867813110351562e-06 	 2.0503997802734375e-05 	 0.151688814163208 	 0.1398451328277588 	 0.07747554779052734 	 0.048715829849243164 	 
2025-07-30 13:54:27.206281 test begin: paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), ) 	 25443936 	 1000 	 0.0038657188415527344 	 0.00442051887512207 	 7.152557373046875e-06 	 1.8358230590820312e-05 	 0.1526486873626709 	 0.13982057571411133 	 0.07793331146240234 	 0.046741485595703125 	 
2025-07-30 13:54:28.021571 test begin: paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), ) 	 25443936 	 1000 	 0.003898143768310547 	 0.0043487548828125 	 1.6450881958007812e-05 	 1.7404556274414062e-05 	 0.1501448154449463 	 0.14035892486572266 	 0.07670068740844727 	 0.049550771713256836 	 
2025-07-30 13:54:28.820047 test begin: paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.004038572311401367 	 0.004665851593017578 	 6.9141387939453125e-06 	 1.8358230590820312e-05 	 0.15371990203857422 	 0.14255976676940918 	 0.07853484153747559 	 0.050386667251586914 	 
2025-07-30 13:54:29.614558 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), ) 	 25443936 	 1000 	 0.00391387939453125 	 0.0044095516204833984 	 7.152557373046875e-06 	 1.8358230590820312e-05 	 0.15015172958374023 	 0.14034557342529297 	 0.07664299011230469 	 0.04655766487121582 	 
2025-07-30 13:54:30.425576 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), ) 	 25443936 	 1000 	 0.0037882328033447266 	 0.004391670227050781 	 1.71661376953125e-05 	 1.9311904907226562e-05 	 0.15038418769836426 	 0.14099478721618652 	 0.07673072814941406 	 0.047823429107666016 	 
2025-07-30 13:54:31.234769 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.0040547847747802734 	 0.004886627197265625 	 7.62939453125e-06 	 3.838539123535156e-05 	 0.16623353958129883 	 0.15488433837890625 	 0.0848836898803711 	 0.06199502944946289 	 
2025-07-30 13:54:32.057861 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), ) 	 25443936 	 1000 	 0.003843545913696289 	 0.004359245300292969 	 1.7404556274414062e-05 	 1.9311904907226562e-05 	 0.15041613578796387 	 0.14091110229492188 	 0.07684683799743652 	 0.04897809028625488 	 
2025-07-30 13:54:32.859327 test begin: paddle.diagonal_scatter(Tensor([10, 10160641],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 10160641],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 	 101606420 	 1000 	 0.3220505714416504 	 0.32692670822143555 	 0.08209800720214844 	 0.10751581192016602 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:54:39.850517 test begin: paddle.diagonal_scatter(Tensor([10, 5080321],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 5080321],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.3216893672943115 	 0.3165416717529297 	 0.0820317268371582 	 0.1075594425201416 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:54:41.926008 test begin: paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032200 	 1000 	 0.7782468795776367 	 0.7742679119110107 	 0.1984555721282959 	 0.2631874084472656 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:54:58.417821 test begin: paddle.diagonal_scatter(Tensor([10160641, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10160641, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 	 101606420 	 1000 	 0.32134127616882324 	 0.3164694309234619 	 0.08192300796508789 	 0.10752511024475098 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:55:01.314314 test begin: paddle.diagonal_scatter(Tensor([5080321, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([5080321, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.3213059902191162 	 0.3164234161376953 	 0.08193492889404297 	 0.1074979305267334 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:55:03.396433 test begin: paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032110 	 1000 	 0.777951717376709 	 0.7740099430084229 	 0.19837164878845215 	 0.26311445236206055 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:55:19.836753 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.9449243545532227 	 0.2616689205169678 	 0.321882963180542 	 0.24249839782714844 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:21.618864 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.9446923732757568 	 0.26178574562072754 	 0.3218221664428711 	 0.24224185943603516 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:23.334407 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.9446587562561035 	 0.2615969181060791 	 0.32180333137512207 	 0.24224424362182617 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:25.029864 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.8712537288665771 	 0.26163220405578613 	 0.2968170642852783 	 0.24262762069702148 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:26.648770 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8712234497070312 	 0.2616250514984131 	 0.29679250717163086 	 0.24187207221984863 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:28.325093 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8712341785430908 	 0.2616405487060547 	 0.29683566093444824 	 0.24214601516723633 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:29.949537 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.8713235855102539 	 0.2616136074066162 	 0.29680514335632324 	 0.24269938468933105 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:31.574509 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 1.0714263916015625 	 0.2998020648956299 	 0.3650953769683838 	 0.2804710865020752 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:33.460993 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 1.0716192722320557 	 0.31319236755371094 	 0.36499762535095215 	 0.2797114849090576 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:37.303592 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 1.0707123279571533 	 0.5376250743865967 	 0.3647322654724121 	 0.2723872661590576 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:40.168161 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8073246479034424 	 0.262864351272583 	 0.27501702308654785 	 0.23566198348999023 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:41.749821 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8072137832641602 	 0.2628927230834961 	 0.2749917507171631 	 0.24368643760681152 	 None 	 None 	 None 	 None 	 
2025-07-30 13:55:43.399506 test begin: paddle.digamma(Tensor([16538, 3, 32, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([16538, 3, 32, 32],"float32"), ) 	 50804736 	 1000 	 0.9611489772796631 	 1.062312364578247 	 0.9438996315002441 	 1.0450613498687744 	 4.488079786300659 	 1.0722813606262207 	 4.426127910614014 	 0.5478463172912598 	 
2025-07-30 13:55:52.751005 test begin: paddle.digamma(Tensor([8, 3, 32, 33076],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 32, 33076],"float64"), ) 	 25402368 	 1000 	 1.1689550876617432 	 1.1410865783691406 	 1.153282642364502 	 1.1243667602539062 	 8.551486253738403 	 1.0844733715057373 	 8.48888635635376 	 0.5540547370910645 	 
2025-07-30 13:56:05.809766 test begin: paddle.digamma(Tensor([8, 3, 32, 66151],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 32, 66151],"float32"), ) 	 50803968 	 1000 	 0.9611032009124756 	 1.0680084228515625 	 0.9454658031463623 	 1.045896053314209 	 4.489673137664795 	 1.073164463043213 	 4.428637742996216 	 0.5482022762298584 	 
2025-07-30 13:56:15.982006 test begin: paddle.digamma(Tensor([8, 3, 33076, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 33076, 32],"float64"), ) 	 25402368 	 1000 	 1.169189214706421 	 1.150646448135376 	 1.153489112854004 	 1.1240007877349854 	 8.551503896713257 	 1.0844306945800781 	 8.490512132644653 	 0.5540680885314941 	 
2025-07-30 13:56:29.042408 test begin: paddle.digamma(Tensor([8, 3, 66151, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 66151, 32],"float32"), ) 	 50803968 	 1000 	 0.9616007804870605 	 1.1208617687225342 	 0.9527909755706787 	 1.1005947589874268 	 4.486649751663208 	 1.0724856853485107 	 4.434800148010254 	 0.5478489398956299 	 
2025-07-30 13:56:40.438235 test begin: paddle.digamma(Tensor([8, 3101, 32, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3101, 32, 32],"float64"), ) 	 25403392 	 1000 	 1.1695828437805176 	 1.1409657001495361 	 1.1604533195495605 	 1.1239769458770752 	 8.550729751586914 	 1.0844664573669434 	 8.498356580734253 	 0.554135799407959 	 
2025-07-30 13:56:53.461895 test begin: paddle.digamma(Tensor([8, 6202, 32, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 6202, 32, 32],"float32"), ) 	 50806784 	 1000 	 0.9605612754821777 	 1.062267780303955 	 0.9518158435821533 	 1.0515291690826416 	 4.486832618713379 	 1.072986364364624 	 4.434494733810425 	 0.5482304096221924 	 
2025-07-30 13:57:02.713464 test begin: paddle.digamma(Tensor([8269, 3, 32, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8269, 3, 32, 32],"float64"), ) 	 25402368 	 1000 	 1.167862892150879 	 1.1413822174072266 	 1.158949613571167 	 1.124619722366333 	 8.550772190093994 	 1.0844390392303467 	 8.468278884887695 	 0.5540676116943359 	 
2025-07-30 13:57:15.787343 test begin: paddle.digamma(x=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 25402896 	 1000 	 1.3964266777038574 	 1.141571283340454 	 1.3873748779296875 	 1.1306800842285156 	 8.544570207595825 	 1.0844626426696777 	 8.492957830429077 	 0.5540766716003418 	 
2025-07-30 13:57:29.035190 test begin: paddle.digamma(x=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 25402248 	 1000 	 1.168637752532959 	 1.1446278095245361 	 1.1594607830047607 	 1.1296000480651855 	 8.548985958099365 	 1.084533929824829 	 8.493878364562988 	 0.5541527271270752 	 
2025-07-30 13:57:42.102858 test begin: paddle.digamma(x=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 25402248 	 1000 	 1.1677398681640625 	 1.1408917903900146 	 1.1585681438446045 	 1.128673791885376 	 8.548981189727783 	 1.0844991207122803 	 8.497084856033325 	 0.5540876388549805 	 
2025-07-30 13:57:55.174594 test begin: paddle.digamma(x=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 25402248 	 1000 	 1.1677815914154053 	 1.1427361965179443 	 1.158531665802002 	 1.129305124282837 	 8.549010992050171 	 1.0844812393188477 	 8.49658751487732 	 0.5540914535522461 	 
2025-07-30 13:58:08.212516 test begin: paddle.digamma(x=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 25402248 	 1000 	 1.167895793914795 	 1.1413633823394775 	 1.1588413715362549 	 1.1307997703552246 	 8.548954963684082 	 1.084538221359253 	 8.495736837387085 	 0.5541186332702637 	 
2025-07-30 13:58:23.417631 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([2540161, 10],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([10],"float64"), y=Tensor([2540161, 10],"float64"), ) 	 25401620 	 1000 	 0.45467662811279297 	 0.45534849166870117 	 0.1159510612487793 	 0.15497159957885742 	 6.738679647445679 	 2.874896287918091 	 1.3793811798095703 	 0.2258470058441162 	 
2025-07-30 13:58:35.053483 test begin: paddle.dist(x=Tensor([113401, 1, 1, 4, 4],"float64"), y=Tensor([113401, 8, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([113401, 1, 1, 4, 4],"float64"), y=Tensor([113401, 8, 7, 1, 4],"float64"), ) 	 27216240 	 1000 	 1.377394199371338 	 1.4048140048980713 	 0.35120439529418945 	 0.4781947135925293 	 8.512354612350464 	 11.310075998306274 	 1.7388718128204346 	 0.889047384262085 	 
2025-07-30 13:58:58.618943 test begin: paddle.dist(x=Tensor([1587601, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([1587601, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 	 25401644 	 1000 	 2.2155661582946777 	 2.29691743850708 	 0.5649080276489258 	 0.7820920944213867 	 15.205422639846802 	 19.245655298233032 	 2.587216854095459 	 1.4049146175384521 	 
2025-07-30 13:59:39.716366 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 453601, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 453601, 7, 1, 4],"float64"), ) 	 25401688 	 1000 	 1.3623487949371338 	 1.3947923183441162 	 0.3473472595214844 	 0.4749143123626709 	 9.91818356513977 	 11.314893245697021 	 1.6884078979492188 	 0.825953483581543 	 
2025-07-30 14:00:04.263067 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 396901, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 396901, 1, 4],"float64"), ) 	 25401696 	 1000 	 1.3618347644805908 	 1.393887996673584 	 0.34726977348327637 	 0.4745042324066162 	 9.934023380279541 	 11.314366102218628 	 1.6911346912384033 	 0.8260154724121094 	 
2025-07-30 14:00:28.837387 test begin: paddle.dist(x=Tensor([2, 1, 3175201, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 3175201, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 	 25401636 	 1000 	 3.044029474258423 	 3.065068006515503 	 0.7762959003448486 	 1.0431368350982666 	 16.179638624191284 	 20.8316388130188 	 2.753037929534912 	 1.5207152366638184 	 
2025-07-30 14:01:14.010992 test begin: paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([6350401, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([6350401, 1, 4],"float64"), ) 	 25401636 	 1000 	 2.708411931991577 	 2.7538743019104004 	 0.6907074451446533 	 0.9373750686645508 	 17.579403162002563 	 22.35592222213745 	 2.992241621017456 	 1.6318986415863037 	 
2025-07-30 14:02:00.324170 test begin: paddle.dist(x=Tensor([2, 1, 793801, 4, 4],"float64"), y=Tensor([2, 8, 793801, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 793801, 4, 4],"float64"), y=Tensor([2, 8, 793801, 1, 4],"float64"), ) 	 76204896 	 1000 	 3.7543275356292725 	 3.7490885257720947 	 0.9573736190795898 	 1.2758312225341797 	 18.12451720237732 	 24.645309686660767 	 3.7020552158355713 	 1.9371931552886963 	 
2025-07-30 14:02:54.345062 test begin: paddle.dist(x=Tensor([2, 793801, 1, 4, 4],"float64"), y=Tensor([2, 793801, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 793801, 1, 4, 4],"float64"), y=Tensor([2, 793801, 7, 1, 4],"float64"), ) 	 69854488 	 1000 	 2.5265045166015625 	 2.5553014278411865 	 0.6442892551422119 	 0.8698709011077881 	 15.252694845199585 	 20.081175088882446 	 3.115595579147339 	 1.5786786079406738 	 
2025-07-30 14:03:38.145731 test begin: paddle.dist(x=Tensor([25401601],"float64"), y=Tensor([4, 25401601],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([25401601],"float64"), y=Tensor([4, 25401601],"float64"), ) 	 127008005 	 1000 	 2.3461623191833496 	 2.3551671504974365 	 0.598283052444458 	 0.8013253211975098 	 8.473139762878418 	 12.600419282913208 	 2.162506341934204 	 1.0728943347930908 	 
2025-07-30 14:04:06.617731 test begin: paddle.dist(x=Tensor([6350401],"float64"), y=Tensor([4, 6350401],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([6350401],"float64"), y=Tensor([4, 6350401],"float64"), ) 	 31752005 	 1000 	 0.6025736331939697 	 0.5994493961334229 	 0.15368151664733887 	 0.2040112018585205 	 2.144066333770752 	 3.190995693206787 	 0.547229528427124 	 0.27172064781188965 	 
2025-07-30 14:04:13.857590 test begin: paddle.divide(Tensor([128, 396901],"float32"), Tensor([1, 396901],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([128, 396901],"float32"), Tensor([1, 396901],"float32"), ) 	 51200229 	 1000 	 0.2998068332672119 	 0.31148195266723633 	 0.28873205184936523 	 0.29888224601745605 	 0.8021032810211182 	 1.8378138542175293 	 0.4097447395324707 	 0.31285715103149414 	 
2025-07-30 14:04:18.786668 test begin: paddle.divide(Tensor([51059, 995],"float32"), Tensor([1, 995],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([51059, 995],"float32"), Tensor([1, 995],"float32"), ) 	 50804700 	 1000 	 0.29738354682922363 	 0.309795618057251 	 0.28640031814575195 	 0.2972249984741211 	 0.904543399810791 	 1.8615787029266357 	 0.30783534049987793 	 0.271742582321167 	 
2025-07-30 14:04:23.777731 test begin: paddle.divide(Tensor([51059, 995],"float32"), Tensor([51059, 995],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([51059, 995],"float32"), Tensor([51059, 995],"float32"), ) 	 101607410 	 1000 	 0.4503211975097656 	 0.44982051849365234 	 0.44030284881591797 	 0.43802452087402344 	 1.1297388076782227 	 2.0921852588653564 	 1.067551851272583 	 0.4276740550994873 	 
2025-07-30 14:04:30.256382 test begin: paddle.divide(Tensor([512, 99226],"float32"), Tensor([1, 99226],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([512, 99226],"float32"), Tensor([1, 99226],"float32"), ) 	 50902938 	 1000 	 0.2955758571624756 	 0.31054091453552246 	 0.2842104434967041 	 0.2981147766113281 	 0.8425471782684326 	 1.8328135013580322 	 0.28656911849975586 	 0.3120236396789551 	 
2025-07-30 14:04:35.182306 test begin: paddle.divide(Tensor([544, 93431],"float32"), Tensor([1, 93431],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([544, 93431],"float32"), Tensor([1, 93431],"float32"), ) 	 50919895 	 1000 	 0.2958235740661621 	 1.5655672550201416 	 0.28484249114990234 	 0.29769277572631836 	 0.8934192657470703 	 1.8389232158660889 	 0.3040628433227539 	 0.3130524158477783 	 
2025-07-30 14:04:42.311072 test begin: paddle.divide(Tensor([544, 93431],"float32"), Tensor([544, 93431],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([544, 93431],"float32"), Tensor([544, 93431],"float32"), ) 	 101652928 	 1000 	 0.45047712326049805 	 0.4500863552093506 	 0.4404604434967041 	 0.4383876323699951 	 1.1302788257598877 	 2.0931928157806396 	 1.068234920501709 	 0.42790842056274414 	 
2025-07-30 14:04:48.916080 test begin: paddle.divide(x=Tensor([16934401, 3],"float32"), y=Tensor([3],"float32"), )
[Prof] paddle.divide 	 paddle.divide(x=Tensor([16934401, 3],"float32"), y=Tensor([3],"float32"), ) 	 50803206 	 1000 	 0.2968583106994629 	 0.31027889251708984 	 0.2853357791900635 	 0.29786086082458496 	 5.6583168506622314 	 1.8550961017608643 	 1.9288182258605957 	 0.27077674865722656 	 
2025-07-30 14:04:58.697908 test begin: paddle.divide(x=Tensor([187679, 271],"float32"), y=Tensor([271],"float32"), )
[Prof] paddle.divide 	 paddle.divide(x=Tensor([187679, 271],"float32"), y=Tensor([271],"float32"), ) 	 50861280 	 1000 	 0.2973959445953369 	 0.3217935562133789 	 0.2860872745513916 	 0.2974119186401367 	 1.0063157081604004 	 1.838536262512207 	 0.34252023696899414 	 0.2684285640716553 	 
2025-07-30 14:05:06.765379 test begin: paddle.dot(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
Warning: The core code of paddle.dot is too complex.
[Prof] paddle.dot 	 paddle.dot(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 6.144553184509277 	 0.29349184036254883 	 6.134613752365112 	 0.14994120597839355 	 0.6263973712921143 	 0.6004180908203125 	 0.31999635696411133 	 0.3067445755004883 	 
2025-07-30 14:05:15.533767 test begin: paddle.dot(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), )
[Prof] paddle.dot 	 paddle.dot(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.29702115058898926 	 0.2929544448852539 	 0.28746509552001953 	 0.14966821670532227 	 0.7102022171020508 	 0.6040518283843994 	 0.36278796195983887 	 0.30861377716064453 	 
2025-07-30 14:05:18.970183 test begin: paddle.dot(x=Tensor([5080320],"int32"), y=Tensor([5080320],"int32"), )
[Prof] paddle.dot 	 paddle.dot(x=Tensor([5080320],"int32"), y=Tensor([5080320],"int32"), ) 	 10160640 	 1000 	 213.06394863128662 	 0.038532257080078125 	 213.05414056777954 	 0.0196685791015625 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:08:52.481296 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], )
W0730 14:09:01.141508 17270 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.0315251350402832 	 0.009393692016601562 	 1.430511474609375e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:02.376039 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], )
W0730 14:09:09.145519 17704 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.017008543014526367 	 0.011617183685302734 	 1.1920928955078125e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:10.964050 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], )
W0730 14:09:17.477571 17732 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.0238950252532959 	 0.010996103286743164 	 1.2159347534179688e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:18.163660 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], )
W0730 14:09:27.657874 17750 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.05260014533996582 	 0.014876604080200195 	 1.4781951904296875e-05 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:29.441710 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], )
W0730 14:09:37.073365 17779 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.02793574333190918 	 0.011684894561767578 	 1.5974044799804688e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:39.279445 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], )
W0730 14:09:46.053639 17806 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.023900270462036133 	 0.013286352157592773 	 1.4543533325195312e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:47.943129 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], )
W0730 14:09:57.610947 17831 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.032448530197143555 	 0.009400367736816406 	 3.0040740966796875e-05 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:09:58.971009 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], )
W0730 14:10:05.692906 17860 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.017208576202392578 	 0.007078647613525391 	 1.0967254638671875e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:10:08.325331 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], )
W0730 14:10:14.747977 17881 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.024318933486938477 	 0.00809168815612793 	 1.5497207641601562e-05 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:10:15.559134 test begin: paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9427340030670166 	 0.9397037029266357 	 0.9141252040863037 	 0.917863130569458 	 0.9530034065246582 	 0.08951687812805176 	 0.8737797737121582 	 7.033348083496094e-05 	 
2025-07-30 14:10:21.997127 test begin: paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3199756145477295 	 0.3133704662322998 	 0.3044438362121582 	 0.1600172519683838 	 0.31955480575561523 	 0.05957221984863281 	 0.26250243186950684 	 3.695487976074219e-05 	 
2025-07-30 14:10:24.047315 test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401900 	 1000 	 0.3216969966888428 	 0.3229944705963135 	 0.3018512725830078 	 0.30864381790161133 	 0.32254934310913086 	 0.07808208465576172 	 0.25278592109680176 	 3.504753112792969e-05 	 
2025-07-30 14:10:26.089055 test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401900 	 1000 	 0.3219466209411621 	 0.3373878002166748 	 0.30214667320251465 	 0.3145580291748047 	 0.32228946685791016 	 0.08368802070617676 	 0.2528262138366699 	 5.626678466796875e-05 	 
2025-07-30 14:10:29.254896 test begin: paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9728367328643799 	 0.9394629001617432 	 0.9446935653686523 	 0.9182455539703369 	 0.9653534889221191 	 0.08389854431152344 	 0.8862004280090332 	 4.291534423828125e-05 	 
2025-07-30 14:10:37.406210 test begin: paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401660 	 1000 	 0.3220343589782715 	 0.3310060501098633 	 0.30254650115966797 	 0.30133628845214844 	 0.32134246826171875 	 0.11503028869628906 	 0.25215816497802734 	 0.00011944770812988281 	 
2025-07-30 14:10:40.198237 test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401660 	 1000 	 0.3220033645629883 	 0.32579493522644043 	 0.3016321659088135 	 0.31174325942993164 	 0.32208752632141113 	 0.07719612121582031 	 0.24810791015625 	 4.38690185546875e-05 	 
2025-07-30 14:10:42.262555 test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 25401660 	 1000 	 0.32166552543640137 	 0.3203153610229492 	 0.30176234245300293 	 0.3037681579589844 	 0.32235145568847656 	 0.07669949531555176 	 0.25250840187072754 	 4.00543212890625e-05 	 
2025-07-30 14:10:44.258997 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401900 	 1000 	 0.32195425033569336 	 0.3193213939666748 	 0.30214500427246094 	 0.30501627922058105 	 0.3216249942779541 	 0.07810139656066895 	 0.252544641494751 	 3.552436828613281e-05 	 
2025-07-30 14:10:46.281196 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9689936637878418 	 0.9464616775512695 	 0.9490129947662354 	 0.9301605224609375 	 0.9682369232177734 	 0.07869577407836914 	 0.8996386528015137 	 7.486343383789062e-05 	 
2025-07-30 14:10:52.199432 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3218228816986084 	 0.3155202865600586 	 0.2983577251434326 	 0.16028332710266113 	 0.3217942714691162 	 0.08241415023803711 	 0.25374841690063477 	 8.153915405273438e-05 	 
2025-07-30 14:10:54.423820 test begin: paddle.dstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 1.552685022354126 	 2.402466058731079 	 1.532778263092041 	 2.3873727321624756 	 2.598440408706665 	 0.0772864818572998 	 2.528641939163208 	 7.033348083496094e-05 	 
2025-07-30 14:11:04.111499 test begin: paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9624578952789307 	 2.5329015254974365 	 0.9424653053283691 	 2.506803035736084 	 1.0667028427124023 	 0.07803559303283691 	 0.9968116283416748 	 3.981590270996094e-05 	 
2025-07-30 14:11:13.327363 test begin: paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.390094518661499 	 0.31336092948913574 	 0.37453150749206543 	 0.15999841690063477 	 0.39556431770324707 	 0.06537032127380371 	 0.3385317325592041 	 5.7697296142578125e-05 	 
2025-07-30 14:11:15.515742 test begin: paddle.dstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 1.5526204109191895 	 2.4021008014678955 	 1.5328128337860107 	 2.380753517150879 	 2.5996601581573486 	 0.08449363708496094 	 2.519890546798706 	 7.748603820800781e-05 	 
2025-07-30 14:11:25.479770 test begin: paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9627039432525635 	 2.5225775241851807 	 0.9425783157348633 	 2.507718801498413 	 1.0711143016815186 	 0.07906293869018555 	 1.0018093585968018 	 4.291534423828125e-05 	 
2025-07-30 14:11:34.077536 test begin: paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3899662494659424 	 0.5486321449279785 	 0.3744525909423828 	 0.1600332260131836 	 0.39586973190307617 	 0.0600132942199707 	 0.3381001949310303 	 0.00011992454528808594 	 
2025-07-30 14:11:36.965792 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([200, 8, 498, 498],"float32"), Tensor([200, 8, 498, 64],"float32"), )
Warning: The core code of paddle.einsum is too complex.
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([200, 8, 498, 498],"float32"), Tensor([200, 8, 498, 64],"float32"), ) 	 447801600 	 1000 	 6.0746307373046875 	 6.073637247085571 	 6.006959915161133 	 5.998157978057861 	 12.323455333709717 	 9.483379364013672 	 2.5201354026794434 	 4.845454692840576 	 
2025-07-30 14:12:19.798860 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([209, 8, 477, 477],"float32"), Tensor([209, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([209, 8, 477, 477],"float32"), Tensor([209, 8, 477, 64],"float32"), ) 	 431471304 	 1000 	 5.98567008972168 	 5.993654012680054 	 5.900342226028442 	 5.910808563232422 	 12.298922538757324 	 9.550282955169678 	 2.5150997638702393 	 4.879092693328857 	 
2025-07-30 14:13:03.407569 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([218, 8, 457, 457],"float32"), Tensor([218, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([218, 8, 457, 457],"float32"), Tensor([218, 8, 457, 64],"float32"), ) 	 415241168 	 1000 	 6.062144756317139 	 6.186597108840942 	 6.004270076751709 	 6.131524085998535 	 12.401075839996338 	 9.990998983383179 	 2.536078691482544 	 5.198410272598267 	 
2025-07-30 14:13:48.852432 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([26, 8, 498, 498],"float32"), Tensor([26, 8, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([26, 8, 498, 498],"float32"), Tensor([26, 8, 498, 64],"float32"), ) 	 58214208 	 1000 	 0.820514440536499 	 0.8208861351013184 	 0.7624595165252686 	 0.7671098709106445 	 1.6523373126983643 	 1.2757799625396729 	 0.3379020690917969 	 0.6517198085784912 	 
2025-07-30 14:13:54.466510 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([28, 8, 477, 477],"float32"), Tensor([28, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([28, 8, 477, 477],"float32"), Tensor([28, 8, 477, 64],"float32"), ) 	 57804768 	 1000 	 0.8772063255310059 	 0.877357006072998 	 0.8188581466674805 	 0.8196113109588623 	 1.7451965808868408 	 1.3671455383300781 	 0.3569004535675049 	 0.6984691619873047 	 
2025-07-30 14:14:00.432515 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 54, 498, 498],"float32"), Tensor([30, 54, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 54, 498, 498],"float32"), Tensor([30, 54, 498, 64],"float32"), ) 	 453399120 	 1000 	 6.077773332595825 	 6.077639102935791 	 6.02044153213501 	 6.023365497589111 	 12.40161681175232 	 9.529342889785767 	 2.536233425140381 	 4.869264841079712 	 
2025-07-30 14:14:42.761131 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 56, 477, 477],"float32"), Tensor([30, 56, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 56, 477, 477],"float32"), Tensor([30, 56, 477, 64],"float32"), ) 	 433535760 	 1000 	 6.076050519943237 	 6.076109886169434 	 6.018569707870483 	 6.021510362625122 	 12.42040753364563 	 9.663049936294556 	 2.5400588512420654 	 4.937623500823975 	 
2025-07-30 14:15:25.694629 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 58, 457, 457],"float32"), Tensor([30, 58, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 58, 457, 457],"float32"), Tensor([30, 58, 457, 64],"float32"), ) 	 414288780 	 1000 	 6.061627388000488 	 6.0618462562561035 	 6.003955125808716 	 6.0069921016693115 	 12.387336015701294 	 9.793783187866211 	 2.5332906246185303 	 5.004251956939697 	 
2025-07-30 14:16:08.636493 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 7, 498, 498],"float32"), Tensor([30, 7, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 7, 498, 498],"float32"), Tensor([30, 7, 498, 64],"float32"), ) 	 58773960 	 1000 	 0.8208925724029541 	 0.8212010860443115 	 0.7626512050628662 	 0.766507625579834 	 1.665989637374878 	 1.2812087535858154 	 0.34065842628479004 	 0.6545629501342773 	 
2025-07-30 14:16:14.304706 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 426, 498],"float32"), Tensor([30, 8, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 426, 498],"float32"), Tensor([30, 8, 498, 64],"float32"), ) 	 58564800 	 1000 	 0.9217195510864258 	 0.922637939453125 	 0.8637926578521729 	 0.8535115718841553 	 1.6923718452453613 	 1.3195443153381348 	 0.3459744453430176 	 0.6741812229156494 	 
2025-07-30 14:16:20.266683 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 444, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 444, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), ) 	 58155840 	 1000 	 0.8792808055877686 	 0.879342794418335 	 0.8046486377716064 	 0.8237619400024414 	 1.7210242748260498 	 1.3472802639007568 	 0.35190629959106445 	 0.68831467628479 	 
2025-07-30 14:16:26.206707 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 457, 457],"float32"), Tensor([30, 8, 457, 464],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 457, 457],"float32"), Tensor([30, 8, 457, 464],"float32"), ) 	 101015280 	 1000 	 3.364415168762207 	 3.379974126815796 	 3.3070273399353027 	 3.3064568042755127 	 7.617819309234619 	 6.742410659790039 	 1.5576305389404297 	 3.4452481269836426 	 
2025-07-30 14:16:50.276960 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 464, 457],"float32"), Tensor([30, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 464, 457],"float32"), Tensor([30, 8, 457, 64],"float32"), ) 	 57911040 	 1000 	 0.850470781326294 	 0.8505373001098633 	 0.7914962768554688 	 0.7969233989715576 	 1.7449102401733398 	 1.3755462169647217 	 0.3567957878112793 	 0.7026984691619873 	 
2025-07-30 14:16:56.150723 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 444],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 444],"float32"), ) 	 105436080 	 1000 	 3.4813995361328125 	 3.500356435775757 	 3.423719882965088 	 3.4279446601867676 	 7.656172037124634 	 6.744851112365723 	 1.5656497478485107 	 3.4464404582977295 	 
2025-07-30 14:17:20.162506 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), ) 	 61933680 	 1000 	 0.8792972564697266 	 0.8799188137054443 	 0.812300443649292 	 0.8115487098693848 	 1.8055601119995117 	 1.4034924507141113 	 0.3692488670349121 	 0.717010498046875 	 
2025-07-30 14:17:26.224355 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 498, 498],"float32"), Tensor([30, 8, 498, 426],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 498, 498],"float32"), Tensor([30, 8, 498, 426],"float32"), ) 	 110436480 	 1000 	 3.6538360118865967 	 3.653489828109741 	 3.5859732627868652 	 3.596465826034546 	 7.740377187728882 	 6.800098657608032 	 1.5828630924224854 	 3.474271059036255 	 
2025-07-30 14:17:50.821359 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 9, 457, 457],"float32"), Tensor([30, 9, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 9, 457, 457],"float32"), Tensor([30, 9, 457, 64],"float32"), ) 	 64286190 	 1000 	 0.9437494277954102 	 0.9441726207733154 	 0.8685534000396729 	 0.8745296001434326 	 1.9454007148742676 	 1.5339980125427246 	 0.39786815643310547 	 0.7837495803833008 	 
2025-07-30 14:17:57.386200 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([31, 8, 457, 457],"float32"), Tensor([31, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([31, 8, 457, 457],"float32"), Tensor([31, 8, 457, 64],"float32"), ) 	 59048056 	 1000 	 0.941758394241333 	 0.9412903785705566 	 0.8746337890625 	 0.8726067543029785 	 1.8625922203063965 	 1.4847116470336914 	 0.38082194328308105 	 0.7585206031799316 	 
2025-07-30 14:18:03.641846 test begin: paddle.empty_like(Tensor([1016064010],"uint8"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([1016064010],"uint8"), ) 	 1016064010 	 1000 	 0.019290447235107422 	 0.01357889175415039 	 1.6927719116210938e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:12.343297 test begin: paddle.empty_like(Tensor([40960, 12404],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"bool"), ) 	 508067840 	 1000 	 0.019389867782592773 	 0.009993791580200195 	 1.1444091796875e-05 	 4.363059997558594e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:19.259133 test begin: paddle.empty_like(Tensor([40960, 12404],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"float32"), ) 	 508067840 	 1000 	 0.0143890380859375 	 0.006353139877319336 	 1.2874603271484375e-05 	 4.00543212890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:27.290488 test begin: paddle.empty_like(Tensor([7938010, 64],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"bool"), ) 	 508032640 	 1000 	 0.01928853988647461 	 0.011721372604370117 	 1.049041748046875e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:34.219546 test begin: paddle.empty_like(Tensor([7938010, 64],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"float32"), ) 	 508032640 	 1000 	 0.02241683006286621 	 0.010356426239013672 	 1.4543533325195312e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:42.314196 test begin: paddle.equal(Tensor([4148, 6124],"int64"), Tensor([4148, 6124],"int64"), )
[Prof] paddle.equal 	 paddle.equal(Tensor([4148, 6124],"int64"), Tensor([4148, 6124],"int64"), ) 	 50804704 	 1000 	 0.31150293350219727 	 0.3132808208465576 	 0.2929956912994385 	 0.2951490879058838 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:43.760702 test begin: paddle.equal(Tensor([416, 61062],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([416, 61062],"int64"), 0, ) 	 25401792 	 1000 	 0.1783912181854248 	 0.1684107780456543 	 0.09113764762878418 	 0.15356874465942383 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:44.511509 test begin: paddle.equal(Tensor([512, 49613],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([512, 49613],"int64"), 0, ) 	 25401856 	 1000 	 0.17856454849243164 	 0.16838765144348145 	 0.09117627143859863 	 0.15450787544250488 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:45.306352 test begin: paddle.equal(Tensor([846721, 30],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([846721, 30],"int64"), 0, ) 	 25401630 	 1000 	 0.17778706550598145 	 0.16932940483093262 	 0.09081196784973145 	 0.1469273567199707 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:46.098139 test begin: paddle.equal(Tensor([846721, 30],"int64"), Tensor([846721, 30],"int64"), )
[Prof] paddle.equal 	 paddle.equal(Tensor([846721, 30],"int64"), Tensor([846721, 30],"int64"), ) 	 50803260 	 1000 	 0.3102583885192871 	 0.31328701972961426 	 0.2992393970489502 	 0.3015885353088379 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:47.493348 test begin: paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 2540161],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 2540161],"bool"), ) 	 101606440 	 1000 	 0.1699223518371582 	 0.20549321174621582 	 0.057810068130493164 	 6.771087646484375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:49.317691 test begin: paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), ) 	 101606464 	 1000 	 0.16991090774536133 	 0.20517992973327637 	 0.057822227478027344 	 6.556510925292969e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:51.094639 test begin: paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), ) 	 101606720 	 1000 	 0.16989755630493164 	 0.20630884170532227 	 0.05780625343322754 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:52.891402 test begin: paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.024669170379638672 	 0.00513148307800293 	 1.9550323486328125e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:53.612025 test begin: paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), ) 	 50816002 	 1000 	 0.027822494506835938 	 0.0045452117919921875 	 1.9788742065429688e-05 	 2.6702880859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:54.429402 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.01810908317565918 	 0.0025818347930908203 	 1.3589859008789062e-05 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:55.143235 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 101607040 	 1000 	 0.1700913906097412 	 0.2056429386138916 	 0.057880401611328125 	 6.699562072753906e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:56.892832 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 3175201],"float32"), ) 	 101606432 	 1000 	 0.3802659511566162 	 0.4210245609283447 	 0.12935924530029297 	 0.00019979476928710938 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:59.244602 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.018008708953857422 	 0.0025517940521240234 	 1.0251998901367188e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:00.065737 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), ) 	 50828832 	 1000 	 0.018224239349365234 	 0.0033702850341796875 	 9.5367431640625e-06 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:00.878373 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 50828832 	 1000 	 0.024662017822265625 	 0.004418373107910156 	 2.0265579223632812e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:01.734798 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.018073320388793945 	 0.0025565624237060547 	 2.002716064453125e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:02.526659 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 101606432 	 1000 	 0.3802299499511719 	 0.4194376468658447 	 0.12931203842163086 	 7.891654968261719e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:04.887026 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), ) 	 50816002 	 1000 	 0.01802659034729004 	 0.002573728561401367 	 1.5974044799804688e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:05.671689 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.38022375106811523 	 0.41704392433166504 	 0.12930750846862793 	 7.677078247070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:08.012364 test begin: paddle.erf(Tensor([11, 2309237],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([11, 2309237],"float64"), ) 	 25401607 	 1000 	 0.3379991054534912 	 0.3038785457611084 	 0.32883596420288086 	 0.2925591468811035 	 0.4482865333557129 	 1.6384119987487793 	 0.39487409591674805 	 0.33493709564208984 	 
2025-07-30 14:19:11.825259 test begin: paddle.erf(Tensor([1494212, 17],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([1494212, 17],"float64"), ) 	 25401604 	 1000 	 0.33809995651245117 	 0.3141622543334961 	 0.3287997245788574 	 0.2921919822692871 	 0.4483215808868408 	 1.6382818222045898 	 0.3912849426269531 	 0.3349158763885498 	 
2025-07-30 14:19:17.527753 test begin: paddle.erf(Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.33757948875427246 	 0.30379676818847656 	 0.32835960388183594 	 0.2922372817993164 	 0.4478950500488281 	 1.6381301879882812 	 0.3946232795715332 	 0.33493685722351074 	 
2025-07-30 14:19:21.250749 test begin: paddle.erf(Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3377256393432617 	 0.3053774833679199 	 0.3284447193145752 	 0.29226255416870117 	 0.4479560852050781 	 1.6380417346954346 	 0.394620418548584 	 0.33487653732299805 	 
2025-07-30 14:19:24.935128 test begin: paddle.erf(Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.33786725997924805 	 0.30384373664855957 	 0.321397066116333 	 0.2859535217285156 	 0.4479405879974365 	 1.6381702423095703 	 0.3856480121612549 	 0.3349168300628662 	 
2025-07-30 14:19:28.708324 test begin: paddle.erf(Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.3379240036010742 	 0.3038043975830078 	 0.3287038803100586 	 0.2923109531402588 	 0.44823503494262695 	 1.6382296085357666 	 0.3948507308959961 	 0.33493494987487793 	 
2025-07-30 14:19:32.413113 test begin: paddle.erf(Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.33742642402648926 	 0.30681681632995605 	 0.32805538177490234 	 0.28575611114501953 	 0.4477386474609375 	 1.638561725616455 	 0.38007116317749023 	 0.3349788188934326 	 
2025-07-30 14:19:37.787655 test begin: paddle.erf(Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.33768224716186523 	 0.3191874027252197 	 0.3215291500091553 	 0.29224348068237305 	 0.44784116744995117 	 1.6381809711456299 	 0.38537073135375977 	 0.3348701000213623 	 
2025-07-30 14:19:42.108944 test begin: paddle.erf(Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3377711772918701 	 0.3079047203063965 	 0.321671724319458 	 0.2859156131744385 	 0.44803309440612793 	 1.6381752490997314 	 0.3671410083770752 	 0.3349757194519043 	 
2025-07-30 14:19:45.903792 test begin: paddle.erf(Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.33765530586242676 	 0.307159423828125 	 0.3284475803375244 	 0.29221224784851074 	 0.4479036331176758 	 1.6381423473358154 	 0.39493322372436523 	 0.33492183685302734 	 
2025-07-30 14:19:49.617476 test begin: paddle.erf(Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.33803391456604004 	 0.3038005828857422 	 0.328704833984375 	 0.292311429977417 	 0.4482157230377197 	 1.6379873752593994 	 0.38819456100463867 	 0.33489322662353516 	 
2025-07-30 14:19:53.359122 test begin: paddle.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.33470773696899414 	 0.30925869941711426 	 0.3252270221710205 	 0.2960550785064697 	 0.4473857879638672 	 1.6424140930175781 	 0.39400529861450195 	 0.33579015731811523 	 
2025-07-30 14:19:57.101122 test begin: paddle.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3349754810333252 	 0.31072020530700684 	 0.3256521224975586 	 0.29984521865844727 	 0.4473714828491211 	 1.6424620151519775 	 0.3942859172821045 	 0.33576226234436035 	 
2025-07-30 14:20:00.801504 test begin: paddle.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.33464527130126953 	 0.3111610412597656 	 0.3251919746398926 	 0.3003673553466797 	 0.4476048946380615 	 1.6423900127410889 	 0.3947145938873291 	 0.33576488494873047 	 
2025-07-30 14:20:04.576619 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.33475685119628906 	 0.31173181533813477 	 0.32532787322998047 	 0.3009004592895508 	 0.4479508399963379 	 1.6422524452209473 	 0.3948678970336914 	 0.335756778717041 	 
2025-07-30 14:20:08.282580 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.3349883556365967 	 0.3114807605743408 	 0.32576608657836914 	 0.3006441593170166 	 0.4472525119781494 	 1.6424894332885742 	 0.39447975158691406 	 0.3357541561126709 	 
2025-07-30 14:20:12.039688 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.33513474464416504 	 0.3115839958190918 	 0.32570695877075195 	 0.300778865814209 	 0.4473702907562256 	 1.6422557830810547 	 0.39414429664611816 	 0.33580565452575684 	 
2025-07-30 14:20:15.739368 test begin: paddle.erfinv(x=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3175201],"float64"), ) 	 25401608 	 1000 	 0.3348548412322998 	 0.3107266426086426 	 0.3255176544189453 	 0.2999687194824219 	 0.44802069664001465 	 1.642871379852295 	 0.39495372772216797 	 0.33582258224487305 	 
2025-07-30 14:20:22.770077 test begin: paddle.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.33487701416015625 	 0.31146669387817383 	 0.3185567855834961 	 0.2946486473083496 	 0.44733190536499023 	 1.6431987285614014 	 0.3853316307067871 	 0.33588123321533203 	 
2025-07-30 14:20:26.509831 test begin: paddle.erfinv(x=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2116801, 3],"float64"), ) 	 25401612 	 1000 	 0.3351759910583496 	 0.3118927478790283 	 0.3187696933746338 	 0.29503893852233887 	 0.44797825813293457 	 1.6426513195037842 	 0.38614511489868164 	 0.3357858657836914 	 
2025-07-30 14:20:30.252072 test begin: paddle.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.3357234001159668 	 0.3113679885864258 	 0.31935858726501465 	 0.2945072650909424 	 0.44739675521850586 	 1.6423883438110352 	 0.3850846290588379 	 0.3357887268066406 	 
2025-07-30 14:20:34.018929 test begin: paddle.erfinv(x=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.3368711471557617 	 0.7805521488189697 	 0.3205759525299072 	 0.2940826416015625 	 0.44803905487060547 	 1.6428673267364502 	 0.38284826278686523 	 0.33587074279785156 	 
2025-07-30 14:20:41.035090 test begin: paddle.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.33561110496520996 	 0.31148409843444824 	 0.32542943954467773 	 0.30050086975097656 	 0.447986364364624 	 1.6424691677093506 	 0.39212942123413086 	 0.3357117176055908 	 
2025-07-30 14:20:44.765162 test begin: paddle.exp(Tensor([125, 1, 640, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([125, 1, 640, 640],"float32"), ) 	 51200000 	 1000 	 0.297849178314209 	 0.3002138137817383 	 0.2890036106109619 	 0.2888789176940918 	 0.45354628562927246 	 0.450115442276001 	 0.3990898132324219 	 0.38144850730895996 	 
2025-07-30 14:20:47.915149 test begin: paddle.exp(Tensor([13, 243, 1007, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 243, 1007, 16],"float32"), ) 	 50897808 	 1000 	 0.29624462127685547 	 0.29847002029418945 	 0.28711438179016113 	 0.28681349754333496 	 0.4509603977203369 	 0.4476032257080078 	 0.3977079391479492 	 0.37793517112731934 	 
2025-07-30 14:20:50.979621 test begin: paddle.exp(Tensor([13, 64, 1007, 61],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 64, 1007, 61],"float32"), ) 	 51107264 	 1000 	 0.29729175567626953 	 0.2996339797973633 	 0.28823018074035645 	 0.28816938400268555 	 0.4527871608734131 	 0.4493062496185303 	 0.3987293243408203 	 0.3754692077636719 	 
2025-07-30 14:20:54.104392 test begin: paddle.exp(Tensor([13, 64, 3817, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 64, 3817, 16],"float32"), ) 	 50811904 	 1000 	 0.29583215713500977 	 0.29789066314697266 	 0.2869117259979248 	 0.28653597831726074 	 0.4500761032104492 	 0.4468050003051758 	 0.37530088424682617 	 0.37851405143737793 	 
2025-07-30 14:20:57.184773 test begin: paddle.exp(Tensor([16, 1, 4962, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 1, 4962, 640],"float32"), ) 	 50810880 	 1000 	 0.29567694664001465 	 0.2979128360748291 	 0.2868177890777588 	 0.2867758274078369 	 0.45014286041259766 	 0.4468719959259033 	 0.3964049816131592 	 0.3724830150604248 	 
2025-07-30 14:21:00.209628 test begin: paddle.exp(Tensor([16, 1, 640, 4962],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 1, 640, 4962],"float32"), ) 	 50810880 	 1000 	 0.2956876754760742 	 0.2979412078857422 	 0.286693811416626 	 0.28659677505493164 	 0.4501030445098877 	 0.446779727935791 	 0.3963005542755127 	 0.37781763076782227 	 
2025-07-30 14:21:03.300473 test begin: paddle.exp(Tensor([16, 8, 640, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 8, 640, 640],"float32"), ) 	 52428800 	 1000 	 0.305095911026001 	 1.2290072441101074 	 0.29615187644958496 	 0.29590916633605957 	 0.4643528461456299 	 0.46080780029296875 	 0.41057825088500977 	 0.39077162742614746 	 
2025-07-30 14:21:08.971153 test begin: paddle.exp(Tensor([50, 64, 1007, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([50, 64, 1007, 16],"float32"), ) 	 51558400 	 1000 	 0.2999227046966553 	 0.30221104621887207 	 0.2909364700317383 	 0.2908031940460205 	 0.45676207542419434 	 0.45332932472229004 	 0.40304994583129883 	 0.38429880142211914 	 
2025-07-30 14:21:12.045854 test begin: paddle.exp(Tensor([56, 1, 960, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([56, 1, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3003096580505371 	 0.303696870803833 	 0.29140329360961914 	 0.28587937355041504 	 0.4572451114654541 	 0.45395970344543457 	 0.40335655212402344 	 0.384321928024292 	 
2025-07-30 14:21:15.198577 test begin: paddle.exp(Tensor([8, 1, 6616, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 1, 6616, 960],"float32"), ) 	 50810880 	 1000 	 0.29586172103881836 	 0.2980177402496338 	 0.28635334968566895 	 0.2867264747619629 	 0.450284481048584 	 0.4468994140625 	 0.3943352699279785 	 0.3756988048553467 	 
2025-07-30 14:21:18.302499 test begin: paddle.exp(Tensor([8, 1, 960, 6616],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 1, 960, 6616],"float32"), ) 	 50810880 	 1000 	 0.2957115173339844 	 0.29787635803222656 	 0.277925968170166 	 0.28023242950439453 	 0.45008158683776855 	 0.44678401947021484 	 0.3870718479156494 	 0.3708024024963379 	 
2025-07-30 14:21:21.457932 test begin: paddle.exp(Tensor([8, 7, 960, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 7, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3002626895904541 	 0.9977984428405762 	 0.29134202003479004 	 0.2840390205383301 	 0.45716357231140137 	 0.4537827968597412 	 0.40353941917419434 	 0.3804588317871094 	 
2025-07-30 14:21:27.551852 test begin: paddle.expand_as(Tensor([1621, 80, 1, 1],"float32"), Tensor([1621, 80, 28, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([1621, 80, 1, 1],"float32"), Tensor([1621, 80, 28, 28],"float16"), ) 	 101798800 	 1000 	 0.270214319229126 	 0.0037806034088134766 	 0.2584495544433594 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:21:31.575194 test begin: paddle.expand_as(Tensor([511, 127, 1, 1],"float32"), Tensor([511, 127, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 127, 1, 1],"float32"), Tensor([511, 127, 28, 28],"float32"), ) 	 50944145 	 1000 	 0.13750910758972168 	 0.006122112274169922 	 0.12585687637329102 	 7.939338684082031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:21:33.438737 test begin: paddle.expand_as(Tensor([511, 80, 1, 1243],"float32"), Tensor([511, 80, 28, 1243],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1243],"float32"), Tensor([511, 80, 28, 1243],"float32"), ) 	 1473601360 	 1000 	 4.059687376022339 	 0.0037543773651123047 	 4.047879934310913 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:22:26.949746 test begin: paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 28, 45],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 28, 45],"float32"), ) 	 51549680 	 1000 	 0.14017558097839355 	 0.003726482391357422 	 0.12854862213134766 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:22:29.991254 test begin: paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 45, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 45, 28],"float32"), ) 	 51549680 	 1000 	 0.13945555686950684 	 0.003807544708251953 	 0.12776684761047363 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:22:32.513388 test begin: paddle.expand_as(Tensor([511, 80, 1243, 1],"float32"), Tensor([511, 80, 1243, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1243, 1],"float32"), Tensor([511, 80, 1243, 28],"float32"), ) 	 1473601360 	 1000 	 4.31782078742981 	 0.003745555877685547 	 4.306005001068115 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:23:29.009935 test begin: paddle.expand_as(Tensor([512, 127, 1, 1],"float32"), Tensor([512, 127, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 127, 1, 1],"float32"), Tensor([512, 127, 28, 28],"float32"), ) 	 51043840 	 1000 	 0.13914942741394043 	 0.0037484169006347656 	 0.12740445137023926 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:23:30.966580 test begin: paddle.expand_as(Tensor([512, 254, 1, 1],"float32"), Tensor([512, 254, 28, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 254, 1, 1],"float32"), Tensor([512, 254, 28, 28],"float16"), ) 	 102087680 	 1000 	 0.271099328994751 	 0.0039675235748291016 	 0.25902557373046875 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:23:35.348305 test begin: paddle.expand_as(Tensor([512, 80, 1, 1241],"float32"), Tensor([512, 80, 28, 1241],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1241],"float32"), Tensor([512, 80, 28, 1241],"float32"), ) 	 1474109440 	 1000 	 4.059109210968018 	 0.007063627243041992 	 4.039483547210693 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:24:29.249718 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 45],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 45],"float32"), ) 	 51650560 	 1000 	 0.14203834533691406 	 0.0037229061126708984 	 0.13039016723632812 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:24:31.219613 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 89],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 89],"float16"), ) 	 102113280 	 1000 	 0.270611047744751 	 0.00377655029296875 	 0.25882863998413086 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:24:35.208738 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 45, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 45, 28],"float32"), ) 	 51650560 	 1000 	 0.13900327682495117 	 0.003776073455810547 	 0.12738513946533203 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:24:37.286758 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 89, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 89, 28],"float16"), ) 	 102113280 	 1000 	 0.27057409286499023 	 0.003785848617553711 	 0.25888633728027344 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:24:41.301952 test begin: paddle.expand_as(Tensor([512, 80, 1241, 1],"float32"), Tensor([512, 80, 1241, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1241, 1],"float32"), Tensor([512, 80, 1241, 28],"float32"), ) 	 1474109440 	 1000 	 4.319730520248413 	 0.0037796497344970703 	 4.3061676025390625 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:25:39.698881 test begin: paddle.expand_as(Tensor([811, 80, 1, 1],"float32"), Tensor([811, 80, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([811, 80, 1, 1],"float32"), Tensor([811, 80, 28, 28],"float32"), ) 	 50930800 	 1000 	 0.1388845443725586 	 0.006967306137084961 	 0.11949372291564941 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:25:41.701003 test begin: paddle.expm1(Tensor([198451, 16, 32],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([198451, 16, 32],"float16"), ) 	 101606912 	 1000 	 0.33484578132629395 	 0.3042001724243164 	 0.3255326747894287 	 0.2933211326599121 	 0.4484565258026123 	 0.7456362247467041 	 0.39448070526123047 	 0.380918025970459 	 
2025-07-30 14:25:49.109408 test begin: paddle.expm1(Tensor([8, 16, 793801],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([8, 16, 793801],"float16"), ) 	 101606528 	 1000 	 0.3353397846221924 	 0.30422091484069824 	 0.3263356685638428 	 0.28844237327575684 	 0.4482920169830322 	 0.7456517219543457 	 0.38808584213256836 	 0.38096189498901367 	 
2025-07-30 14:25:54.742900 test begin: paddle.expm1(Tensor([8, 396901, 32],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([8, 396901, 32],"float16"), ) 	 101606656 	 1000 	 0.3349127769470215 	 0.3041508197784424 	 0.3257014751434326 	 0.29300546646118164 	 0.44829273223876953 	 0.7457177639007568 	 0.3947713375091553 	 0.38103294372558594 	 
2025-07-30 14:26:00.278895 test begin: paddle.fft.fftn(Tensor([226801, 7, 32],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([226801, 7, 32],"float32"), ) 	 50803424 	 1000 	 11.155422925949097 	 15.96718168258667 	 5.650520324707031e-05 	 1.81370210647583 	 19.583194494247437 	 15.47823166847229 	 1.539191484451294 	 1.9767773151397705 	 
2025-07-30 14:27:04.727845 test begin: paddle.fft.fftn(Tensor([39, 40708, 32],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([39, 40708, 32],"float32"), ) 	 50803584 	 1000 	 9.380882740020752 	 10.570474624633789 	 5.6743621826171875e-05 	 1.119384765625 	 11.963916063308716 	 10.19101357460022 	 1.017928123474121 	 1.1581284999847412 	 
2025-07-30 14:27:48.845775 test begin: paddle.fft.fftn(Tensor([39, 7, 186093],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([39, 7, 186093],"float32"), ) 	 50803389 	 1000 	 6.956233501434326 	 6.042055606842041 	 7.176399230957031e-05 	 0.7719528675079346 	 7.546029329299927 	 5.5872015953063965 	 0.7706742286682129 	 0.8160600662231445 	 
2025-07-30 14:28:17.787192 test begin: paddle.fft.fftn(Tensor([7, 32, 481, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([7, 32, 481, 481],"float32"), axes=list[2,3,], ) 	 51824864 	 1000 	 5.970120429992676 	 4.381018161773682 	 4.6253204345703125e-05 	 0.8969011306762695 	 5.5167951583862305 	 3.9512453079223633 	 0.8056116104125977 	 1.0105643272399902 	 
2025-07-30 14:28:39.604310 test begin: paddle.fft.fftn(Tensor([8, 28, 481, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 28, 481, 481],"float32"), axes=list[2,3,], ) 	 51824864 	 1000 	 5.969383478164673 	 4.369126081466675 	 3.218650817871094e-05 	 0.8942151069641113 	 5.514695882797241 	 3.942375898361206 	 0.8051152229309082 	 1.0089936256408691 	 
2025-07-30 14:29:01.317794 test begin: paddle.fft.fftn(Tensor([8, 32, 413, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 32, 413, 481],"float32"), axes=list[2,3,], ) 	 50855168 	 1000 	 6.545067548751831 	 4.231356382369995 	 4.9591064453125e-05 	 0.8651213645935059 	 5.59679388999939 	 3.7924914360046387 	 0.8171200752258301 	 0.9703330993652344 	 
2025-07-30 14:29:23.840586 test begin: paddle.fft.fftn(Tensor([8, 32, 481, 413],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 32, 481, 413],"float32"), axes=list[2,3,], ) 	 50855168 	 1000 	 5.952789306640625 	 4.21816086769104 	 3.266334533691406e-05 	 0.8620026111602783 	 5.613305330276489 	 3.7684099674224854 	 0.8195629119873047 	 0.9653847217559814 	 
2025-07-30 14:29:45.570872 test begin: paddle.fft.fftn(x=Tensor([50, 133, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 133, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50832600 	 1000 	 6.02455472946167 	 2.973198890686035 	 3.3855438232421875e-05 	 0.607764482498169 	 4.377101421356201 	 2.4911837577819824 	 0.6389575004577637 	 0.6364092826843262 	 
2025-07-30 14:30:03.330189 test begin: paddle.fft.fftn(x=Tensor([50, 8, 39, 14, 233],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 39, 14, 233],"float32"), axes=list[-3,-2,-1,], ) 	 50887200 	 1000 	 6.795364141464233 	 3.688753843307495 	 2.6464462280273438e-05 	 0.7545166015625 	 5.955053091049194 	 3.215393304824829 	 0.8692739009857178 	 0.8227214813232422 	 
2025-07-30 14:30:24.893166 test begin: paddle.fft.fftn(x=Tensor([50, 8, 39, 233, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 39, 233, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50887200 	 1000 	 7.203523635864258 	 4.131475925445557 	 5.221366882324219e-05 	 0.8449857234954834 	 6.522039890289307 	 3.647502899169922 	 0.9521949291229248 	 0.9323999881744385 	 
2025-07-30 14:30:48.502169 test begin: paddle.fft.fftn(x=Tensor([50, 8, 649, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 649, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50881600 	 1000 	 6.361688852310181 	 3.551888942718506 	 3.552436828613281e-05 	 0.7258157730102539 	 4.957251787185669 	 3.0697972774505615 	 0.7236533164978027 	 0.784207820892334 	 
2025-07-30 14:31:09.994073 test begin: paddle.fft.fftn(x=Tensor([831, 8, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([831, 8, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50817312 	 1000 	 6.02851128578186 	 2.972421407699585 	 5.125999450683594e-05 	 0.6075994968414307 	 4.375706195831299 	 2.4911439418792725 	 0.6387488842010498 	 0.6366889476776123 	 
2025-07-30 14:31:27.722964 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 6, 264601],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 4, 6, 264601],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401696 	 1000 	 3.0053515434265137 	 1.3912322521209717 	 3.838539123535156e-05 	 0.3554389476776123 	 2.861982822418213 	 1.9012079238891602 	 0.365739107131958 	 0.388822078704834 	 
2025-07-30 14:31:39.696954 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 793801, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 4, 793801, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401632 	 1000 	 2.8423221111297607 	 1.3910984992980957 	 2.0742416381835938e-05 	 0.35530543327331543 	 2.5979833602905273 	 1.9008171558380127 	 0.33174943923950195 	 0.3887495994567871 	 
2025-07-30 14:31:49.319860 test begin: paddle.fft.ifftn(x=Tensor([4, 529201, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 529201, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401648 	 1000 	 0.2576134204864502 	 0.49350452423095703 	 1.7404556274414062e-05 	 0.12583374977111816 	 0.1688990592956543 	 0.7277438640594482 	 0.021581411361694336 	 0.09305500984191895 	 
2025-07-30 14:31:51.460001 test begin: paddle.fft.ifftn(x=Tensor([529201, 4, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([529201, 4, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401648 	 1000 	 0.24187159538269043 	 0.4933626651763916 	 1.9550323486328125e-05 	 0.12580657005310059 	 0.16910076141357422 	 0.28047800064086914 	 0.021642208099365234 	 0.0573883056640625 	 
2025-07-30 14:31:53.143497 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), ) 	 25401618 	 1000 	 1.8635592460632324 	 0.7594430446624756 	 0.3810107707977295 	 0.38802576065063477 	 3.4388134479522705 	 2.6261212825775146 	 0.5855522155761719 	 0.5368883609771729 	 
2025-07-30 14:32:02.857236 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, ) 	 25401618 	 1000 	 1.9740056991577148 	 0.7638216018676758 	 0.33637380599975586 	 0.3901703357696533 	 2.8833863735198975 	 1.8300843238830566 	 0.3682260513305664 	 0.37400174140930176 	 
2025-07-30 14:32:11.239609 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), ) 	 25401624 	 1000 	 1.8633806705474854 	 0.9867603778839111 	 0.38093137741088867 	 0.3891429901123047 	 3.4387614727020264 	 2.6262166500091553 	 0.5856165885925293 	 0.5369350910186768 	 
2025-07-30 14:32:23.526436 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, ) 	 25401624 	 1000 	 1.97397780418396 	 0.7638871669769287 	 0.33633947372436523 	 0.39025115966796875 	 2.883176803588867 	 1.830333948135376 	 0.3682057857513428 	 0.37398505210876465 	 
2025-07-30 14:32:31.880101 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, axis=1, ) 	 25401624 	 1000 	 1.7397291660308838 	 0.6993136405944824 	 0.2965388298034668 	 0.23609519004821777 	 2.477836847305298 	 1.7017638683319092 	 0.3161582946777344 	 0.2897980213165283 	 
2025-07-30 14:32:41.374865 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 6.977645635604858 	 6.106148719787598 	 0.5092992782592773 	 0.5676219463348389 	 13.042006731033325 	 11.805648565292358 	 1.025620937347412 	 1.005286693572998 	 
2025-07-30 14:33:20.274122 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, axis=1, ) 	 25401624 	 1000 	 1.8579559326171875 	 0.9302699565887451 	 0.31688809394836426 	 0.23604965209960938 	 2.461984395980835 	 1.701268196105957 	 0.3145434856414795 	 0.2896735668182373 	 
2025-07-30 14:33:29.550514 test begin: paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, ) 	 25528608 	 1000 	 0.07509422302246094 	 0.05304241180419922 	 2.288818359375e-05 	 5.1021575927734375e-05 	 0.17485404014587402 	 0.1727592945098877 	 0.02234625816345215 	 0.00011324882507324219 	 
2025-07-30 14:33:30.512306 test begin: paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, ) 	 25528608 	 1000 	 0.0751950740814209 	 0.03917407989501953 	 1.5020370483398438e-05 	 4.9114227294921875e-05 	 0.17366266250610352 	 0.15499043464660645 	 0.022197961807250977 	 0.00011944770812988281 	 
2025-07-30 14:33:31.435302 test begin: paddle.fft.ihfft(x=Tensor([705601, 4, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([705601, 4, 3, 3],"float64"), ) 	 25401636 	 1000 	 1.8622016906738281 	 0.785067081451416 	 0.3807179927825928 	 0.38799095153808594 	 3.4360971450805664 	 2.6265087127685547 	 0.5851194858551025 	 0.5368659496307373 	 
2025-07-30 14:33:43.410803 test begin: paddle.fft.ihfft2(x=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([1270081, 4, 5],"float64"), ) 	 25401620 	 1000 	 2.0954668521881104 	 2.1304500102996826 	 0.356900691986084 	 0.3629305362701416 	 3.99723482131958 	 3.5165045261383057 	 0.5835580825805664 	 0.4491870403289795 	 
2025-07-30 14:33:56.074992 test begin: paddle.fft.ihfft2(x=Tensor([2822401, 3, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([2822401, 3, 3],"float64"), s=tuple(1,2,), ) 	 25401609 	 1000 	 0.7743568420410156 	 0.6314351558685303 	 0.13186240196228027 	 0.16124939918518066 	 1.147979497909546 	 1.1616146564483643 	 0.14661312103271484 	 0.14841938018798828 	 
2025-07-30 14:34:00.428907 test begin: paddle.fft.ihfft2(x=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([3, 1693441, 5],"float64"), ) 	 25401615 	 1000 	 8.844581127166748 	 7.386616468429565 	 0.6954553127288818 	 0.686650276184082 	 15.543034791946411 	 8.784123420715332 	 1.134589433670044 	 0.6897518634796143 	 
2025-07-30 14:34:42.143765 test begin: paddle.fft.ihfft2(x=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([3, 4, 2116801],"float64"), ) 	 25401612 	 1000 	 9.108853578567505 	 7.3147313594818115 	 0.619898796081543 	 0.4979696273803711 	 13.643405437469482 	 13.13627576828003 	 0.9959373474121094 	 0.8950016498565674 	 
2025-07-30 14:35:26.348078 test begin: paddle.fft.ihfft2(x=Tensor([4, 2116801, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 2116801, 3],"float64"), s=tuple(1,2,), ) 	 25401612 	 1000 	 0.11425423622131348 	 0.06852269172668457 	 2.0742416381835938e-05 	 6.198883056640625e-05 	 0.16741585731506348 	 0.20714235305786133 	 0.021421432495117188 	 8.7738037109375e-05 	 
2025-07-30 14:35:27.386471 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 3, 705601],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 3, 705601],"float64"), ) 	 25401636 	 1000 	 7.28328537940979 	 7.307875871658325 	 0.4959268569946289 	 0.4975886344909668 	 13.622918605804443 	 12.746299266815186 	 0.9943277835845947 	 0.8685424327850342 	 
2025-07-30 14:36:11.284403 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 705601, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 705601, 3],"float64"), ) 	 25401636 	 1000 	 9.464433670043945 	 9.000490665435791 	 0.744359016418457 	 0.7078487873077393 	 15.26795768737793 	 10.49039101600647 	 1.2581021785736084 	 0.7146618366241455 	 
2025-07-30 14:36:57.703340 test begin: paddle.fft.ihfft2(x=Tensor([4, 705601, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 705601, 3, 3],"float64"), ) 	 25401636 	 1000 	 2.269310474395752 	 2.379051685333252 	 0.38669872283935547 	 0.4052762985229492 	 4.045346975326538 	 3.8576149940490723 	 0.5907213687896729 	 0.4928855895996094 	 
2025-07-30 14:37:11.327256 test begin: paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), ) 	 25465104 	 1000 	 0.1000528335571289 	 0.0663909912109375 	 1.621246337890625e-05 	 4.9114227294921875e-05 	 0.16952967643737793 	 0.2143549919128418 	 0.021642446517944336 	 0.00011444091796875 	 
2025-07-30 14:37:12.364976 test begin: paddle.fft.ihfft2(x=Tensor([940801, 3, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([940801, 3, 3, 3],"float64"), ) 	 25401627 	 1000 	 2.2706961631774902 	 2.3797452449798584 	 0.3867802619934082 	 0.40531158447265625 	 4.045219421386719 	 3.854785203933716 	 0.5905666351318359 	 0.4926412105560303 	 
2025-07-30 14:37:25.883578 test begin: paddle.fft.ihfftn(Tensor([1270081, 4, 5],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([1270081, 4, 5],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401620 	 1000 	 2.0954082012176514 	 2.1304848194122314 	 0.3569371700286865 	 0.3628685474395752 	 3.9965274333953857 	 3.516944408416748 	 0.5834903717041016 	 0.449354887008667 	 
2025-07-30 14:37:40.891205 test begin: paddle.fft.ihfftn(Tensor([3, 1693441, 5],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([3, 1693441, 5],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401615 	 1000 	 8.849844694137573 	 7.37851619720459 	 0.6955792903900146 	 0.6858994960784912 	 15.543343305587769 	 8.775373220443726 	 1.134704351425171 	 0.6888308525085449 	 
2025-07-30 14:38:22.461450 test begin: paddle.fft.ihfftn(Tensor([3, 4, 2116801],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([3, 4, 2116801],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401612 	 1000 	 9.10917592048645 	 7.319231986999512 	 0.6199901103973389 	 0.4981508255004883 	 13.644357204437256 	 13.136547803878784 	 0.9959902763366699 	 0.8951563835144043 	 
2025-07-30 14:39:08.514147 test begin: paddle.fft.ihfftn(Tensor([4, 3, 3, 705601],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 3, 3, 705601],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 7.284862995147705 	 7.305699586868286 	 0.495913028717041 	 0.4974207878112793 	 13.623808860778809 	 12.745996236801147 	 0.9946897029876709 	 0.8685085773468018 	 
2025-07-30 14:39:51.342035 test begin: paddle.fft.ihfftn(Tensor([4, 3, 705601, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 3, 705601, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 9.464583158493042 	 8.992152452468872 	 0.7444932460784912 	 0.707813024520874 	 15.113343715667725 	 10.489696264266968 	 1.1032915115356445 	 0.7146327495574951 	 
2025-07-30 14:40:37.861255 test begin: paddle.fft.ihfftn(Tensor([4, 705601, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 705601, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 2.2691218852996826 	 2.3789167404174805 	 0.38658714294433594 	 0.4052920341491699 	 4.046918153762817 	 3.857875108718872 	 0.5906674861907959 	 0.49286627769470215 	 
2025-07-30 14:40:51.515638 test begin: paddle.fft.ihfftn(Tensor([940801, 3, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([940801, 3, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401627 	 1000 	 2.2706031799316406 	 2.379772424697876 	 0.38681459426879883 	 0.405487060546875 	 4.045373439788818 	 3.8554437160491943 	 0.5906238555908203 	 0.49282121658325195 	 
2025-07-30 14:41:05.118346 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 1058401, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 3, 1058401, 2],"float64"), ) 	 25401624 	 1000 	 15.22781491279602 	 14.120468139648438 	 0.9146838188171387 	 1.0305402278900146 	 18.419435024261475 	 14.266801595687866 	 1.0465683937072754 	 1.0414729118347168 	 
2025-07-30 14:42:10.309772 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 5, 423361],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 3, 5, 423361],"float64"), ) 	 25401660 	 1000 	 7.3023247718811035 	 6.402438163757324 	 0.4386138916015625 	 0.46719932556152344 	 15.37445330619812 	 10.883687257766724 	 0.9828026294708252 	 0.7944581508636475 	 
2025-07-30 14:42:51.656794 test begin: paddle.fft.ihfftn(x=Tensor([4, 635041, 5, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 635041, 5, 2],"float64"), ) 	 25401640 	 1000 	 16.848997592926025 	 15.654529809951782 	 1.0121641159057617 	 1.142502784729004 	 19.99778461456299 	 15.79049563407898 	 1.1356420516967773 	 1.1532456874847412 	 
2025-07-30 14:44:02.571189 test begin: paddle.fft.ihfftn(x=Tensor([846721, 3, 5, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([846721, 3, 5, 2],"float64"), ) 	 25401630 	 1000 	 18.93724775314331 	 15.565489530563354 	 1.137279987335205 	 1.3237347602844238 	 17.163952112197876 	 15.696402311325073 	 0.9758713245391846 	 1.3354618549346924 	 
2025-07-30 14:45:12.370167 test begin: paddle.fft.rfft(Tensor([20, 1210, 2101],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 1210, 2101],"float32"), ) 	 50844200 	 1000 	 2.6018447875976562 	 2.0097477436065674 	 0.5313341617584229 	 0.6849842071533203 	 4.900859594345093 	 3.3735694885253906 	 1.000878095626831 	 1.1501083374023438 	 
2025-07-30 14:45:26.603618 test begin: paddle.fft.rfft(Tensor([20, 1270, 2001],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 1270, 2001],"float32"), ) 	 50825400 	 1000 	 1.9770817756652832 	 1.3277926445007324 	 0.403975248336792 	 0.45244479179382324 	 3.679771661758423 	 2.020521640777588 	 0.7516272068023682 	 0.6885230541229248 	 
2025-07-30 14:45:37.469836 test begin: paddle.fft.rfft(Tensor([20, 64, 39691],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 64, 39691],"float32"), ) 	 50804480 	 1000 	 4.731484889984131 	 4.123178243637085 	 0.4832773208618164 	 0.5272059440612793 	 9.0922269821167 	 7.526698589324951 	 0.9285728931427002 	 0.9625182151794434 	 
2025-07-30 14:46:06.079806 test begin: paddle.fft.rfft(Tensor([378, 64, 2101],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([378, 64, 2101],"float32"), ) 	 50827392 	 1000 	 2.6026313304901123 	 2.0050249099731445 	 0.5315370559692383 	 0.6833343505859375 	 4.888859748840332 	 3.368469715118408 	 0.996755838394165 	 1.1483170986175537 	 
2025-07-30 14:46:20.333618 test begin: paddle.fft.rfft(Tensor([397, 64, 2001],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([397, 64, 2001],"float32"), ) 	 50841408 	 1000 	 1.9802546501159668 	 1.3286035060882568 	 0.4045882225036621 	 0.45265817642211914 	 3.6511006355285645 	 2.015883684158325 	 0.7459142208099365 	 0.6870737075805664 	 
2025-07-30 14:46:30.675755 test begin: paddle.fft.rfft(Tensor([4, 32, 32, 12404],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 32, 32, 12404],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 4.898503303527832 	 4.317905426025391 	 0.5002224445343018 	 0.5519540309906006 	 10.125887632369995 	 8.724600791931152 	 0.9411320686340332 	 0.9919514656066895 	 
2025-07-30 14:47:00.852484 test begin: paddle.fft.rfft(Tensor([4, 32, 6202, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 32, 6202, 64],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 1.2777972221374512 	 0.6272587776184082 	 0.32642316818237305 	 0.3197751045227051 	 3.509416103363037 	 1.8381266593933105 	 0.5975615978240967 	 0.4698648452758789 	 
2025-07-30 14:47:09.449702 test begin: paddle.fft.rfft(Tensor([4, 6202, 32, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 6202, 32, 64],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 1.2776644229888916 	 0.6261036396026611 	 0.3264133930206299 	 0.31984519958496094 	 3.5101871490478516 	 1.837904691696167 	 0.5976364612579346 	 0.46988606452941895 	 
2025-07-30 14:47:18.026486 test begin: paddle.fft.rfft(Tensor([776, 32, 32, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([776, 32, 32, 64],"float32"), axis=-1, norm="forward", ) 	 50855936 	 1000 	 1.2794654369354248 	 0.62664794921875 	 0.32689356803894043 	 0.32012391090393066 	 3.5121498107910156 	 1.8399126529693604 	 0.5980896949768066 	 0.4703705310821533 	 
2025-07-30 14:47:26.601875 test begin: paddle.fft.rfft2(Tensor([26, 32, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([26, 32, 250, 250],"float32"), ) 	 52000000 	 1000 	 1.478452444076538 	 0.8367288112640381 	 0.3776726722717285 	 0.4297301769256592 	 3.595644950866699 	 1.9212934970855713 	 0.6123590469360352 	 0.4915010929107666 	 
2025-07-30 14:47:37.467850 test begin: paddle.fft.rfft2(Tensor([32, 26, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 26, 250, 250],"float32"), ) 	 52000000 	 1000 	 1.4781591892242432 	 0.8351166248321533 	 0.37756776809692383 	 0.4288904666900635 	 3.6015357971191406 	 1.9206197261810303 	 0.6123378276824951 	 0.4909982681274414 	 
2025-07-30 14:47:46.837865 test begin: paddle.fft.rfft2(Tensor([32, 32, 199, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 32, 199, 250],"float32"), ) 	 50944000 	 1000 	 2.6922385692596436 	 1.4976999759674072 	 0.6884291172027588 	 0.7707867622375488 	 5.948341369628906 	 3.250417947769165 	 1.012376070022583 	 0.8313438892364502 	 
2025-07-30 14:48:02.249918 test begin: paddle.fft.rfft2(Tensor([32, 32, 250, 199],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 32, 250, 199],"float32"), ) 	 50944000 	 1000 	 2.7353618144989014 	 1.6392459869384766 	 0.4656374454498291 	 0.4186863899230957 	 5.2296223640441895 	 2.7049076557159424 	 0.8902003765106201 	 0.691809892654419 	 
2025-07-30 14:48:16.447536 test begin: paddle.fft.rfft2(Tensor([8, 102, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 102, 250, 250],"float32"), ) 	 51000000 	 1000 	 1.4493598937988281 	 0.8169081211090088 	 0.37027621269226074 	 0.4187135696411133 	 3.5278828144073486 	 1.8850808143615723 	 0.6007959842681885 	 0.481900691986084 	 
2025-07-30 14:48:25.374514 test begin: paddle.fft.rfft2(Tensor([8, 32, 250, 794],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 32, 250, 794],"float32"), ) 	 50816000 	 1000 	 2.1049060821533203 	 1.4640018939971924 	 0.42995786666870117 	 0.4983029365539551 	 4.382817506790161 	 2.730222463607788 	 0.7461550235748291 	 0.6982223987579346 	 
2025-07-30 14:48:37.680471 test begin: paddle.fft.rfft2(Tensor([8, 32, 794, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 32, 794, 250],"float32"), ) 	 50816000 	 1000 	 2.320507526397705 	 1.6245601177215576 	 0.5931823253631592 	 0.830033540725708 	 5.2405290603637695 	 3.5073111057281494 	 0.8919966220855713 	 0.8972823619842529 	 
2025-07-30 14:48:52.045067 test begin: paddle.fft.rfft2(x=Tensor([32, 15, 15, 7057],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 15, 15, 7057],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50810400 	 1000 	 1.6005589962005615 	 1.5865447521209717 	 0.32715344429016113 	 0.4052460193634033 	 3.9262824058532715 	 3.045668601989746 	 0.6685140132904053 	 0.6229453086853027 	 
2025-07-30 14:49:03.547202 test begin: paddle.fft.rfft2(x=Tensor([32, 15, 414, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 15, 414, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50872320 	 1000 	 2.3204705715179443 	 1.8441705703735352 	 0.33878278732299805 	 0.37679314613342285 	 4.267324686050415 	 3.126878023147583 	 0.6230533123016357 	 0.532783031463623 	 
2025-07-30 14:49:16.970398 test begin: paddle.fft.rfft2(x=Tensor([32, 414, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 414, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50872320 	 1000 	 1.671867847442627 	 1.670227289199829 	 0.34171342849731445 	 0.42664384841918945 	 4.297205209732056 	 3.431154251098633 	 0.6272215843200684 	 0.5845403671264648 	 
2025-07-30 14:49:29.457574 test begin: paddle.fft.rfft2(x=Tensor([883, 15, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([883, 15, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50860800 	 1000 	 1.5669889450073242 	 1.5707714557647705 	 0.3202977180480957 	 0.39960145950317383 	 3.891930103302002 	 3.022639274597168 	 0.6627023220062256 	 0.6182360649108887 	 
2025-07-30 14:49:42.852039 test begin: paddle.fft.rfftn(Tensor([26, 32, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([26, 32, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 52000000 	 1000 	 1.4782769680023193 	 0.8318908214569092 	 0.3775928020477295 	 0.4259462356567383 	 3.5955734252929688 	 1.9205176830291748 	 0.6123802661895752 	 0.49089717864990234 	 
2025-07-30 14:49:52.047336 test begin: paddle.fft.rfftn(Tensor([32, 15, 15, 7057],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 15, 15, 7057],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50810400 	 1000 	 1.6005520820617676 	 1.586639404296875 	 0.327089786529541 	 0.4052557945251465 	 3.926299810409546 	 3.0457475185394287 	 0.6684746742248535 	 0.6230344772338867 	 
2025-07-30 14:50:03.559686 test begin: paddle.fft.rfftn(Tensor([32, 15, 414, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 15, 414, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50872320 	 1000 	 2.320680856704712 	 1.8573927879333496 	 0.3388335704803467 	 0.37682008743286133 	 4.26760721206665 	 3.1270899772644043 	 0.6230053901672363 	 0.5327339172363281 	 
2025-07-30 14:50:20.078849 test begin: paddle.fft.rfftn(Tensor([32, 26, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 26, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 52000000 	 1000 	 1.4781954288482666 	 0.8306083679199219 	 0.37754344940185547 	 0.4258730411529541 	 3.595522880554199 	 1.9206852912902832 	 0.6123850345611572 	 0.49104928970336914 	 
2025-07-30 14:50:29.228333 test begin: paddle.fft.rfftn(Tensor([32, 32, 199, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 32, 199, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50944000 	 1000 	 2.692761182785034 	 1.5000026226043701 	 0.688617467880249 	 0.7667255401611328 	 6.053498029708862 	 3.2502238750457764 	 1.1165976524353027 	 0.8314259052276611 	 
2025-07-30 14:50:44.296903 test begin: paddle.fft.rfftn(Tensor([32, 32, 250, 199],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 32, 250, 199],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50944000 	 1000 	 2.7353856563568115 	 1.639538288116455 	 0.4656658172607422 	 0.4188227653503418 	 5.229774713516235 	 2.705159902572632 	 0.8901183605194092 	 0.6917896270751953 	 
2025-07-30 14:50:57.942888 test begin: paddle.fft.rfftn(Tensor([32, 414, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 414, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50872320 	 1000 	 1.6710364818572998 	 1.6701831817626953 	 0.3415505886077881 	 0.42667055130004883 	 4.297176361083984 	 3.432513475418091 	 0.6273677349090576 	 0.584510087966919 	 
2025-07-30 14:51:11.782780 test begin: paddle.fft.rfftn(Tensor([8, 102, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 102, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 51000000 	 1000 	 1.4492757320404053 	 1.0346317291259766 	 0.37018465995788574 	 0.41836977005004883 	 3.527750015258789 	 1.8847465515136719 	 0.6006665229797363 	 0.4818534851074219 	 
2025-07-30 14:51:23.802143 test begin: paddle.fft.rfftn(Tensor([8, 32, 250, 794],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 32, 250, 794],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50816000 	 1000 	 2.104761838912964 	 1.4639735221862793 	 0.4300117492675781 	 0.49832940101623535 	 4.383200168609619 	 2.7303178310394287 	 0.7461686134338379 	 0.6985855102539062 	 
2025-07-30 14:51:37.678826 test begin: paddle.fft.rfftn(Tensor([8, 32, 794, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 32, 794, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50816000 	 1000 	 2.32051944732666 	 1.630417823791504 	 0.5932562351226807 	 0.8300156593322754 	 5.241013765335083 	 3.507474422454834 	 0.8920087814331055 	 0.8972251415252686 	 
2025-07-30 14:51:51.712781 test begin: paddle.fft.rfftn(Tensor([883, 15, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([883, 15, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50860800 	 1000 	 1.5671911239624023 	 1.5643343925476074 	 0.3203256130218506 	 0.3995857238769531 	 3.8925178050994873 	 3.0223162174224854 	 0.6626074314117432 	 0.6181156635284424 	 
2025-07-30 14:52:03.138533 test begin: paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 508157440 	 1000 	 0.006089210510253906 	 0.006951570510864258 	 1.1682510375976562e-05 	 0.00011754035949707031 	 0.0456387996673584 	 0.0818490982055664 	 3.24249267578125e-05 	 5.4836273193359375e-05 	 
2025-07-30 14:52:19.956375 test begin: paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 509788160 	 1000 	 0.010794401168823242 	 0.007540702819824219 	 1.3113021850585938e-05 	 2.09808349609375e-05 	 0.04943656921386719 	 0.06608414649963379 	 6.175041198730469e-05 	 7.724761962890625e-05 	 
2025-07-30 14:52:37.185526 test begin: paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 513802240 	 1000 	 0.01081538200378418 	 0.007567882537841797 	 1.1444091796875e-05 	 2.1457672119140625e-05 	 0.049015045166015625 	 0.06335091590881348 	 4.124641418457031e-05 	 5.435943603515625e-05 	 
2025-07-30 14:52:52.741856 test begin: paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, ) 	 532480000 	 1000 	 0.005757331848144531 	 0.004143476486206055 	 9.298324584960938e-06 	 2.193450927734375e-05 	 0.04213738441467285 	 0.057891130447387695 	 2.3126602172851562e-05 	 6.580352783203125e-05 	 
2025-07-30 14:53:09.581618 test begin: paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, ) 	 508144000 	 1000 	 0.0063588619232177734 	 0.00414586067199707 	 2.7894973754882812e-05 	 1.9311904907226562e-05 	 0.04267311096191406 	 0.060346126556396484 	 3.814697265625e-05 	 8.273124694824219e-05 	 
2025-07-30 14:53:25.484276 test begin: paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, ) 	 514375680 	 1000 	 0.005955696105957031 	 0.004163026809692383 	 2.5272369384765625e-05 	 1.9788742065429688e-05 	 0.04199576377868652 	 0.0606844425201416 	 3.4809112548828125e-05 	 5.555152893066406e-05 	 
2025-07-30 14:53:41.156499 test begin: paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.0058307647705078125 	 0.004171133041381836 	 9.5367431640625e-06 	 1.7642974853515625e-05 	 0.04167938232421875 	 0.05692696571350098 	 2.2411346435546875e-05 	 5.340576171875e-05 	 
2025-07-30 14:53:56.499878 test begin: paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, ) 	 524288000 	 1000 	 0.005755901336669922 	 0.004132986068725586 	 9.298324584960938e-06 	 1.7404556274414062e-05 	 0.04146146774291992 	 0.05683326721191406 	 4.1484832763671875e-05 	 4.863739013671875e-05 	 
2025-07-30 14:54:12.662437 test begin: paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, ) 	 513802240 	 1000 	 0.005739927291870117 	 0.004102230072021484 	 1.0251998901367188e-05 	 1.9311904907226562e-05 	 0.041615962982177734 	 0.05707430839538574 	 5.459785461425781e-05 	 5.53131103515625e-05 	 
2025-07-30 14:54:28.452458 test begin: paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.005809307098388672 	 0.007406473159790039 	 1.2636184692382812e-05 	 2.5510787963867188e-05 	 0.049429893493652344 	 0.0825200080871582 	 3.0994415283203125e-05 	 5.698204040527344e-05 	 
2025-07-30 14:54:45.730589 test begin: paddle.flip(Tensor([127, 8, 224, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([127, 8, 224, 224],"float32"), axis=list[3,], ) 	 50978816 	 1000 	 0.9649035930633545 	 0.31321072578430176 	 0.9481358528137207 	 0.2913069725036621 	 0.9649665355682373 	 0.3132152557373047 	 0.9047672748565674 	 0.22812891006469727 	 
2025-07-30 14:54:49.940639 test begin: paddle.flip(Tensor([1351, 3, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([1351, 3, 112, 112],"float32"), axis=-1, ) 	 50840832 	 1000 	 0.9648449420928955 	 0.3124706745147705 	 0.9550557136535645 	 0.2974586486816406 	 0.9651813507080078 	 0.31215405464172363 	 0.911135196685791 	 0.24286890029907227 	 
2025-07-30 14:54:54.099202 test begin: paddle.flip(Tensor([3, 338, 224, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 338, 224, 224],"float32"), axis=list[3,], ) 	 50878464 	 1000 	 0.9631621837615967 	 0.3126378059387207 	 0.953671932220459 	 0.2975449562072754 	 0.9627115726470947 	 0.3127105236053467 	 0.9117515087127686 	 0.24245786666870117 	 
2025-07-30 14:54:58.278307 test begin: paddle.flip(Tensor([3, 8, 224, 9451],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 8, 224, 9451],"float32"), axis=list[3,], ) 	 50808576 	 1000 	 0.961907148361206 	 0.31255102157592773 	 0.952390193939209 	 0.29778385162353516 	 0.9615423679351807 	 0.31237292289733887 	 0.9067089557647705 	 0.24058294296264648 	 
2025-07-30 14:55:02.544683 test begin: paddle.flip(Tensor([3, 8, 9451, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 8, 9451, 224],"float32"), axis=list[3,], ) 	 50808576 	 1000 	 0.9614322185516357 	 0.31378674507141113 	 0.9518296718597412 	 0.29739928245544434 	 0.9612851142883301 	 0.312014102935791 	 0.9104278087615967 	 0.23737478256225586 	 
2025-07-30 14:55:06.679832 test begin: paddle.flip(Tensor([52, 3, 112, 2908],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 3, 112, 2908],"float32"), axis=-1, ) 	 50808576 	 1000 	 0.9621577262878418 	 0.312518835067749 	 0.9524435997009277 	 0.29766082763671875 	 0.96160888671875 	 0.312363862991333 	 0.9085776805877686 	 0.24265146255493164 	 
2025-07-30 14:55:10.845121 test begin: paddle.flip(Tensor([52, 3, 2908, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 3, 2908, 112],"float32"), axis=-1, ) 	 50808576 	 1000 	 0.9641480445861816 	 0.3245055675506592 	 0.9545364379882812 	 0.2975337505340576 	 0.9642462730407715 	 0.3119375705718994 	 0.9133753776550293 	 0.24129152297973633 	 
2025-07-30 14:55:14.991211 test begin: paddle.flip(Tensor([52, 78, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 78, 112, 112],"float32"), axis=-1, ) 	 50878464 	 1000 	 0.9660313129425049 	 0.3128242492675781 	 0.956634521484375 	 0.2978208065032959 	 0.9656579494476318 	 0.3128373622894287 	 0.9143133163452148 	 0.2197885513305664 	 
2025-07-30 14:55:19.313046 test begin: paddle.flip(Tensor([64, 3, 112, 2363],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 3, 112, 2363],"float32"), axis=-1, ) 	 50813952 	 1000 	 0.9620997905731201 	 0.3125736713409424 	 0.952566385269165 	 0.2978239059448242 	 0.961787223815918 	 0.3124728202819824 	 0.9105103015899658 	 0.23583555221557617 	 
2025-07-30 14:55:23.462076 test begin: paddle.flip(Tensor([64, 3, 2363, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 3, 2363, 112],"float32"), axis=-1, ) 	 50813952 	 1000 	 0.9646258354187012 	 0.3125426769256592 	 0.9551482200622559 	 0.2972095012664795 	 0.9643876552581787 	 0.31200289726257324 	 0.9134221076965332 	 0.24179434776306152 	 
2025-07-30 14:55:27.607753 test begin: paddle.flip(Tensor([64, 64, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 64, 112, 112],"float32"), axis=-1, ) 	 51380224 	 1000 	 0.9756524562835693 	 0.3157944679260254 	 0.9625244140625 	 0.3011035919189453 	 0.9751675128936768 	 0.3158414363861084 	 0.923952579498291 	 0.24629497528076172 	 
2025-07-30 14:55:31.827343 test begin: paddle.floor(Tensor([100000, 170, 3],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([100000, 170, 3],"float32"), ) 	 51000000 	 1000 	 0.2970550060272217 	 0.30467844009399414 	 0.28775620460510254 	 0.28763246536254883 	 0.13468146324157715 	 0.13477063179016113 	 0.08345437049865723 	 0.06728863716125488 	 
2025-07-30 14:55:34.287143 test begin: paddle.floor(Tensor([100000, 2, 255],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([100000, 2, 255],"float32"), ) 	 51000000 	 1000 	 0.2970733642578125 	 0.3017923831939697 	 0.2808346748352051 	 0.2812771797180176 	 0.13468098640441895 	 0.13507890701293945 	 0.07399940490722656 	 0.038520097732543945 	 
2025-07-30 14:55:39.365972 test begin: paddle.floor(Tensor([322, 157920],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([322, 157920],"float32"), ) 	 50850240 	 1000 	 0.29599952697753906 	 0.2982022762298584 	 0.28594970703125 	 0.28662538528442383 	 0.13419890403747559 	 0.1342909336090088 	 0.0826575756072998 	 0.06574583053588867 	 
2025-07-30 14:55:41.804893 test begin: paddle.floor(Tensor([4, 12700801],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([4, 12700801],"float32"), ) 	 50803204 	 1000 	 0.2959282398223877 	 0.2979738712310791 	 0.2866055965423584 	 0.2869260311126709 	 0.13419508934020996 	 0.1343367099761963 	 0.08146524429321289 	 0.06757092475891113 	 
2025-07-30 14:55:46.060288 test begin: paddle.floor(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.29596972465515137 	 0.3083469867706299 	 0.28685832023620605 	 0.28670811653137207 	 0.1341700553894043 	 0.13427734375 	 0.08274078369140625 	 0.06638956069946289 	 
2025-07-30 14:55:49.317136 test begin: paddle.floor(x=Tensor([100, 352, 38, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 352, 38, 38],"float32"), ) 	 50828800 	 1000 	 0.2959737777709961 	 0.2980632781982422 	 0.2864189147949219 	 0.2868356704711914 	 0.13420438766479492 	 0.13420867919921875 	 0.08061337471008301 	 0.06606245040893555 	 
2025-07-30 14:55:51.736010 test begin: paddle.floor(x=Tensor([100, 4, 3343, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 4, 3343, 38],"float32"), ) 	 50813600 	 1000 	 0.295886754989624 	 0.3050873279571533 	 0.2863609790802002 	 0.2867152690887451 	 0.13410210609436035 	 0.13421869277954102 	 0.08251070976257324 	 0.06583547592163086 	 
2025-07-30 14:55:54.539047 test begin: paddle.floor(x=Tensor([100, 4, 38, 3343],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 4, 38, 3343],"float32"), ) 	 50813600 	 1000 	 0.2958216667175293 	 0.29800868034362793 	 0.28613853454589844 	 0.28674864768981934 	 0.13416767120361328 	 0.13425755500793457 	 0.08219122886657715 	 0.06625485420227051 	 
2025-07-30 14:55:56.957172 test begin: paddle.floor(x=Tensor([8796, 4, 38, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([8796, 4, 38, 38],"float32"), ) 	 50805696 	 1000 	 0.29572105407714844 	 0.3029782772064209 	 0.2792353630065918 	 0.28059816360473633 	 0.13422417640686035 	 0.13417267799377441 	 0.07350564002990723 	 0.056069135665893555 	 
2025-07-30 14:55:59.477448 test begin: paddle.floor_divide(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.4258992671966553 	 0.49216771125793457 	 0.40821123123168945 	 0.47182607650756836 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:01.193179 test begin: paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.4268300533294678 	 0.4929471015930176 	 0.40920257568359375 	 0.472933292388916 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:02.898069 test begin: paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.4522099494934082 	 0.4554407596588135 	 0.4428131580352783 	 0.44101810455322266 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:05.438234 test begin: paddle.floor_divide(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.44776344299316406 	 0.4479389190673828 	 0.43845248222351074 	 0.4331352710723877 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:07.056377 test begin: paddle.floor_divide(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.4521169662475586 	 0.45778870582580566 	 0.44268226623535156 	 0.44222378730773926 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:09.528404 test begin: paddle.floor_divide(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4476008415222168 	 0.44793224334716797 	 0.43807220458984375 	 0.4355146884918213 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:11.162067 test begin: paddle.floor_divide(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.45204877853393555 	 0.45547008514404297 	 0.4425930976867676 	 0.44299936294555664 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:13.622002 test begin: paddle.fmax(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 558835211 	 1000 	 4.4448277950286865 	 4.406040668487549 	 4.432535409927368 	 4.393067121505737 	 45.18435215950012 	 27.18567395210266 	 45.124939918518066 	 1.984501838684082 	 
2025-07-30 14:57:52.396577 test begin: paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.4502406120300293 	 0.4509999752044678 	 0.44014668464660645 	 0.43503761291503906 	 0.7359755039215088 	 2.643173933029175 	 0.6770780086517334 	 0.20781970024108887 	 
2025-07-30 14:58:00.021677 test begin: paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), ) 	 55883531 	 1000 	 0.4513726234436035 	 0.44584226608276367 	 0.4400668144226074 	 0.43375158309936523 	 4.518639326095581 	 2.7468841075897217 	 4.457655429840088 	 0.20046591758728027 	 
2025-07-30 14:58:09.876850 test begin: paddle.fmax(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), ) 	 101616000 	 1000 	 0.45026707649230957 	 0.4468684196472168 	 0.4402027130126953 	 0.4353451728820801 	 0.7360284328460693 	 2.6404225826263428 	 0.6769623756408691 	 0.2076401710510254 	 
2025-07-30 14:58:16.479505 test begin: paddle.fmax(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), ) 	 101608800 	 1000 	 0.450211763381958 	 0.4468975067138672 	 0.4401059150695801 	 0.4352724552154541 	 0.7359814643859863 	 2.6453709602355957 	 0.6767838001251221 	 0.2079930305480957 	 
2025-07-30 14:58:23.178246 test begin: paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), ) 	 50803230 	 1000 	 0.2967870235443115 	 0.3032989501953125 	 0.28569507598876953 	 0.29105114936828613 	 8.329228401184082 	 2.472515106201172 	 8.269071817398071 	 0.1682720184326172 	 
2025-07-30 14:58:37.789279 test begin: paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), ) 	 101606430 	 1000 	 0.45018839836120605 	 0.449918270111084 	 0.4327254295349121 	 0.4287755489349365 	 0.7359592914581299 	 2.6431169509887695 	 0.6677515506744385 	 0.20779705047607422 	 
2025-07-30 14:58:44.407486 test begin: paddle.fmax(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), ) 	 101616000 	 1000 	 0.45029735565185547 	 0.45614051818847656 	 0.4322013854980469 	 0.42881083488464355 	 0.7360711097717285 	 2.640483856201172 	 0.6680908203125 	 0.2076125144958496 	 
2025-07-30 14:58:51.108722 test begin: paddle.fmin(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 558835211 	 1000 	 4.444990634918213 	 4.413665533065796 	 4.433603525161743 	 4.3906569480896 	 45.17069888114929 	 27.198529481887817 	 45.10832452774048 	 1.9863090515136719 	 
2025-07-30 15:00:29.563640 test begin: paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.4502425193786621 	 0.44682765007019043 	 0.43995141983032227 	 0.4351189136505127 	 0.7359709739685059 	 2.6431214809417725 	 0.6646585464477539 	 0.20784902572631836 	 
2025-07-30 15:00:37.800272 test begin: paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), ) 	 55883531 	 1000 	 0.45151495933532715 	 0.4458448886871338 	 0.44025111198425293 	 0.4335958957672119 	 4.51860499382019 	 2.7484352588653564 	 4.459246397018433 	 0.20049214363098145 	 
2025-07-30 15:00:47.692155 test begin: paddle.fmin(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), ) 	 101616000 	 1000 	 0.45163679122924805 	 0.4519827365875244 	 0.44141721725463867 	 0.43502354621887207 	 0.7359826564788818 	 2.641549825668335 	 0.6772377490997314 	 0.20763707160949707 	 
2025-07-30 15:00:54.328322 test begin: paddle.fmin(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), ) 	 101608800 	 1000 	 0.450228214263916 	 0.4468522071838379 	 0.43994903564453125 	 0.43509578704833984 	 0.7360267639160156 	 2.6466572284698486 	 0.6773674488067627 	 0.20800542831420898 	 
2025-07-30 15:01:00.917912 test begin: paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), ) 	 50803230 	 1000 	 0.2968113422393799 	 0.3032689094543457 	 0.2854952812194824 	 0.2846963405609131 	 8.327131032943726 	 2.477691650390625 	 8.267337799072266 	 0.16861200332641602 	 
2025-07-30 15:01:14.049605 test begin: paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), ) 	 101606430 	 1000 	 0.4503140449523926 	 0.4468424320220947 	 0.4329407215118408 	 0.42891526222229004 	 0.7373359203338623 	 2.64318585395813 	 0.6698076725006104 	 0.20786619186401367 	 
2025-07-30 15:01:20.748173 test begin: paddle.fmin(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), ) 	 101616000 	 1000 	 0.4502744674682617 	 0.4469003677368164 	 0.4329512119293213 	 0.4289076328277588 	 0.736008882522583 	 2.641958475112915 	 0.6679258346557617 	 0.20766687393188477 	 
2025-07-30 15:01:27.320190 test begin: paddle.frac(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.8062868118286133 	 0.2985403537750244 	 0.7694952487945557 	 0.2867298126220703 	 1.1840558052062988 	 0.05238962173461914 	 0.6056203842163086 	 3.3855438232421875e-05 	 
2025-07-30 15:01:31.279315 test begin: paddle.frac(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.8041372299194336 	 0.2979850769042969 	 0.767324686050415 	 0.2807495594024658 	 1.1829771995544434 	 0.06049609184265137 	 0.6044621467590332 	 6.103515625e-05 	 
2025-07-30 15:01:35.239487 test begin: paddle.frac(Tensor([16934401, 3],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.8041400909423828 	 0.32637643814086914 	 0.7808949947357178 	 0.28698158264160156 	 1.1828603744506836 	 0.07207369804382324 	 0.604332685470581 	 0.00010752677917480469 	 
2025-07-30 15:01:40.230193 test begin: paddle.frac(Tensor([2, 12700801],"float64"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.7478554248809814 	 0.2982661724090576 	 0.7239396572113037 	 0.2808706760406494 	 1.0648298263549805 	 0.06085920333862305 	 0.5441279411315918 	 7.200241088867188e-05 	 
2025-07-30 15:01:43.509266 test begin: paddle.frac(Tensor([2, 25401601],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.8041517734527588 	 0.2980179786682129 	 0.7672262191772461 	 0.2801682949066162 	 1.183011770248413 	 0.06437468528747559 	 0.6044471263885498 	 4.8160552978515625e-05 	 
2025-07-30 15:01:47.480742 test begin: paddle.frac(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.8055469989776611 	 0.29999804496765137 	 0.782102108001709 	 0.28638744354248047 	 1.1829845905303955 	 0.05296492576599121 	 0.6044514179229736 	 4.506111145019531e-05 	 
2025-07-30 15:01:51.491893 test begin: paddle.frac(Tensor([8467201, 3],"float64"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.7478916645050049 	 0.31653833389282227 	 0.7240841388702393 	 0.28697657585144043 	 1.0660090446472168 	 0.052199602127075195 	 0.5440700054168701 	 3.743171691894531e-05 	 
2025-07-30 15:01:54.632512 test begin: paddle.full_like(Tensor([1, 300, 169345],"float32"), 1, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([1, 300, 169345],"float32"), 1, ) 	 50803500 	 1000 	 0.13410329818725586 	 0.13427376747131348 	 0.12316226959228516 	 0.121734619140625 	 None 	 None 	 None 	 None 	 
2025-07-30 15:01:55.670253 test begin: paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6580235958099365 	 0.6577959060668945 	 0.6468138694763184 	 0.6444694995880127 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:04.096595 test begin: paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6603178977966309 	 0.6577844619750977 	 0.6485130786895752 	 0.6443495750427246 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:12.461050 test begin: paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 545259520 	 1000 	 1.5909337997436523 	 0.7058751583099365 	 0.6960463523864746 	 0.6926894187927246 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:23.195708 test begin: paddle.full_like(Tensor([199, 256000],"float32"), 0.0, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([199, 256000],"float32"), 0.0, ) 	 50944000 	 1000 	 0.13447785377502441 	 0.13479208946228027 	 0.12360310554504395 	 0.12181234359741211 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:24.239687 test begin: paddle.full_like(Tensor([42, 300, 4096],"float32"), 1, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([42, 300, 4096],"float32"), 1, ) 	 51609600 	 1000 	 0.1361842155456543 	 0.13651490211486816 	 0.12534761428833008 	 0.12361669540405273 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:25.306095 test begin: paddle.full_like(Tensor([6, 8467201],"float32"), 0.0, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([6, 8467201],"float32"), 0.0, ) 	 50803206 	 1000 	 0.13413596153259277 	 0.1367659568786621 	 0.12340497970581055 	 0.12314605712890625 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:26.413360 test begin: paddle.gammainc(Tensor([1270081, 40],"float32"), y=Tensor([1270081, 40],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([1270081, 40],"float32"), y=Tensor([1270081, 40],"float32"), ) 	 101606480 	 1000 	 4.207614183425903 	 2.2618393898010254 	 0.0030312538146972656 	 2.2422091960906982 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 15:02:37.351568 test begin: paddle.gammainc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 4.208717107772827 	 2.2618138790130615 	 0.0030307769775390625 	 2.249753952026367 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 15:02:47.697561 test begin: paddle.gammainc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 4.2357635498046875 	 2.2621331214904785 	 0.003032684326171875 	 2.2499711513519287 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 15:02:58.096358 test begin: paddle.gammainc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 4.206029415130615 	 2.266535758972168 	 0.003020048141479492 	 2.254552125930786 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 15:03:08.432604 test begin: paddle.gammainc(Tensor([3, 16934401],"float32"), y=Tensor([3, 16934401],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([3, 16934401],"float32"), y=Tensor([3, 16934401],"float32"), ) 	 101606406 	 1000 	 4.209219932556152 	 2.267163038253784 	 0.003030538558959961 	 2.2552008628845215 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 15:03:18.750744 test begin: paddle.gammainc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 4.204668283462524 	 2.2658255100250244 	 0.0030279159545898438 	 2.2489240169525146 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 15:03:29.613038 test begin: paddle.gammaincc(Tensor([1270081, 40],"float32"), Tensor([1270081, 40],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([1270081, 40],"float32"), Tensor([1270081, 40],"float32"), ) 	 101606480 	 1000 	 3.913262128829956 	 7.108069896697998 	 0.002759695053100586 	 7.083200931549072 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 15:03:46.289934 test begin: paddle.gammaincc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 3.9152634143829346 	 7.10190749168396 	 0.0027627944946289062 	 7.0874857902526855 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 15:04:00.945139 test begin: paddle.gammaincc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 3.9315996170043945 	 7.096404790878296 	 0.002772808074951172 	 7.084166765213013 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 15:04:15.662430 test begin: paddle.gammaincc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 3.937776803970337 	 7.096855878829956 	 0.0027649402618408203 	 7.084330797195435 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 15:04:32.117167 test begin: paddle.gammaincc(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), ) 	 101606406 	 1000 	 3.9320921897888184 	 7.100305795669556 	 0.0027582645416259766 	 7.076026678085327 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 15:04:47.703464 test begin: paddle.gammaincc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 3.9184458255767822 	 7.096688985824585 	 0.0027604103088378906 	 7.084516525268555 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 15:05:02.419646 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08725190162658691 	 21.477349758148193 	 0.07705068588256836 	 0.00024819374084472656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:25.583404 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.08998703956604004 	 18.61986804008484 	 0.07939028739929199 	 0.0002353191375732422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:45.839379 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09213447570800781 	 16.871532678604126 	 0.08190393447875977 	 0.0001621246337890625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:06:04.370715 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08712506294250488 	 19.762683391571045 	 0.07705354690551758 	 0.0002167224884033203 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:06:25.754950 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.08965373039245605 	 16.7070095539093 	 0.07942461967468262 	 0.00021314620971679688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:06:46.520115 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09256768226623535 	 16.89086675643921 	 0.0821692943572998 	 0.00018739700317382812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:05.074836 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([482, 1],"int64"), ) 	 50878946 	 1000 	 0.1194620132446289 	 15.831227779388428 	 0.10936927795410156 	 0.00021147727966308594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:22.340421 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([496, 1],"int64"), ) 	 50878960 	 1000 	 0.12051939964294434 	 16.618786811828613 	 0.11031937599182129 	 0.00021648406982421875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:40.447672 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([512, 1],"int64"), ) 	 50878976 	 1000 	 0.12404942512512207 	 17.03550910949707 	 0.11378049850463867 	 0.0002181529998779297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:58.950306 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([482, 1],"int64"), ) 	 50878946 	 1000 	 0.2831718921661377 	 15.926825523376465 	 0.2729525566101074 	 0.0002453327178955078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:17.595621 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([496, 1],"int64"), ) 	 50878960 	 1000 	 0.2889845371246338 	 16.35029935836792 	 0.27884364128112793 	 0.00023508071899414062 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:40.230835 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([512, 1],"int64"), ) 	 50878976 	 1000 	 0.29677724838256836 	 16.857927560806274 	 0.2867565155029297 	 0.00024509429931640625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:59.944425 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 52918864 	 1000 	 0.011629104614257812 	 80.9752426147461 	 1.239776611328125e-05 	 0.00021314620971679688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:10:21.999383 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), ) 	 52917364 	 1000 	 0.011260271072387695 	 20.25994348526001 	 1.1444091796875e-05 	 0.00020432472229003906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:10:43.283094 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102473328 	 1000 	 0.011161088943481445 	 65.23415279388428 	 1.3113021850585938e-05 	 0.00023889541625976562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:50.486717 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102473404 	 1000 	 0.011300802230834961 	 65.68274092674255 	 1.33514404296875e-05 	 0.00021791458129882812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:12:58.165690 test begin: paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102573116 	 1000 	 0.01167607307434082 	 68.09780502319336 	 0.0006132125854492188 	 0.00023055076599121094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:08.362094 test begin: paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102598240 	 1000 	 0.011111736297607422 	 65.6451301574707 	 1.1920928955078125e-05 	 0.0002219676971435547 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:16.039406 test begin: paddle.gcd(Tensor([10, 50803],"int32"), Tensor([10, 50803],"int32"), )
W0730 15:15:22.478973 58359 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(Tensor([10, 50803],"int32"), Tensor([10, 50803],"int32"), ) 	 1016060 	 1000 	 6.415359258651733 	 0.026180744171142578 	 3.4332275390625e-05 	 0.015379905700683594 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:15:22.510239 test begin: paddle.gcd(Tensor([25401, 20],"int32"), Tensor([25401, 20],"int32"), )
W0730 15:15:29.004335 58531 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(Tensor([25401, 20],"int32"), Tensor([25401, 20],"int32"), ) 	 1016040 	 1000 	 6.474452257156372 	 0.026315689086914062 	 3.62396240234375e-05 	 0.015668392181396484 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:15:29.037417 test begin: paddle.gcd(x=Tensor([12700, 2, 4, 5],"int32"), y=Tensor([12700, 2, 4, 5],"int32"), )
W0730 15:15:35.622835 58775 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([12700, 2, 4, 5],"int32"), y=Tensor([12700, 2, 4, 5],"int32"), ) 	 1016000 	 1000 	 6.565260171890259 	 0.026540279388427734 	 4.076957702636719e-05 	 0.015688657760620117 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:15:37.258736 test begin: paddle.gcd(x=Tensor([25401, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0730 15:15:43.825755 58952 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([25401, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 508030 	 1000 	 6.541327953338623 	 0.05637049674987793 	 4.9114227294921875e-05 	 0.04473304748535156 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:15:43.888898 test begin: paddle.gcd(x=Tensor([6, 1, 16934, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0730 15:15:50.205780 59046 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 1, 16934, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 508030 	 1000 	 6.295582056045532 	 0.05664372444152832 	 4.458427429199219e-05 	 0.044934749603271484 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:15:50.277132 test begin: paddle.gcd(x=Tensor([6, 1, 4, 21168],"int32"), y=Tensor([2, 1, 21168],"int32"), )
W0730 15:15:56.859674 59361 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 1, 4, 21168],"int32"), y=Tensor([2, 1, 21168],"int32"), ) 	 550368 	 1000 	 6.56230902671814 	 0.05610013008117676 	 4.506111145019531e-05 	 0.04320096969604492 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:15:56.923952 test begin: paddle.gcd(x=Tensor([6, 2, 4, 10584],"int32"), y=Tensor([6, 2, 4, 10584],"int32"), )
W0730 15:16:03.439199 59529 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 2, 4, 10584],"int32"), y=Tensor([6, 2, 4, 10584],"int32"), ) 	 1016064 	 1000 	 6.4955384731292725 	 0.026165246963500977 	 4.649162292480469e-05 	 0.015397071838378906 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:16:03.470937 test begin: paddle.gcd(x=Tensor([6, 2, 8467, 5],"int32"), y=Tensor([6, 2, 8467, 5],"int32"), )
W0730 15:16:10.410146 59835 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 2, 8467, 5],"int32"), y=Tensor([6, 2, 8467, 5],"int32"), ) 	 1016040 	 1000 	 6.9199347496032715 	 0.02628803253173828 	 3.504753112792969e-05 	 0.015429973602294922 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:16:10.441910 test begin: paddle.gcd(x=Tensor([6, 4233, 4, 5],"int32"), y=Tensor([6, 4233, 4, 5],"int32"), )
W0730 15:16:18.813973 60007 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 4233, 4, 5],"int32"), y=Tensor([6, 4233, 4, 5],"int32"), ) 	 1015920 	 1000 	 8.351951360702515 	 0.026211261749267578 	 4.5299530029296875e-05 	 0.009078025817871094 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:16:18.847386 test begin: paddle.geometric.segment_max(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.7365691661834717 	 10.347249031066895 	 0.0007164478302001953 	 0.0002257823944091797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:16:34.254592 test begin: paddle.geometric.segment_max(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), ) 	 101606480 	 1000 	 1.1452584266662598 	 11.951193809509277 	 0.001125335693359375 	 0.0006630420684814453 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:16:54.248794 test begin: paddle.geometric.segment_max(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.5150642395019531 	 12.702482461929321 	 0.00048470497131347656 	 0.0003185272216796875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:17:09.225672 test begin: paddle.geometric.segment_mean(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), ) 	 26671701 	 1000 	 0.4647693634033203 	 0.8254737854003906 	 0.0004246234893798828 	 0.00012683868408203125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:17:13.688191 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 8.90981936454773 	 11.719218015670776 	 0.008859634399414062 	 0.001598358154296875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:18:21.878757 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 4.909715414047241 	 8.621506214141846 	 0.0048792362213134766 	 0.0011174678802490234 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:19:12.981770 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 7.126439332962036 	 9.95576810836792 	 0.007056236267089844 	 0.001264810562133789 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:20:09.979889 test begin: paddle.geometric.segment_mean(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), ) 	 53343381 	 1000 	 0.5920839309692383 	 1.203629970550537 	 0.0005600452423095703 	 0.00019598007202148438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:20:17.210018 test begin: paddle.geometric.segment_mean(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.45357751846313477 	 0.9357857704162598 	 0.0004146099090576172 	 0.00015211105346679688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:23:19.280553 test begin: paddle.geometric.segment_mean(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.3566572666168213 	 0.6298902034759521 	 0.00031304359436035156 	 0.0006372928619384766 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:24:19.789992 test begin: paddle.geometric.segment_mean(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), ) 	 106686741 	 1000 	 1.7501718997955322 	 2.1512768268585205 	 0.001718759536743164 	 0.0002524852752685547 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:24:31.002907 test begin: paddle.geometric.segment_min(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), ) 	 26671701 	 1000 	 0.6587042808532715 	 1.1607074737548828 	 0.0006315708160400391 	 0.0002269744873046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:24:34.512733 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 10.7227942943573 	 24.90842056274414 	 0.010670661926269531 	 0.0016689300537109375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:25:31.224741 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 9.326812982559204 	 15.364581108093262 	 0.009235620498657227 	 0.0016467571258544922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:26:20.211529 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 11.768176555633545 	 20.421177625656128 	 0.0117034912109375 	 0.0035552978515625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:27:25.381887 test begin: paddle.geometric.segment_min(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), ) 	 53343381 	 1000 	 1.0456221103668213 	 1.661214828491211 	 0.001008749008178711 	 0.000278472900390625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:27:33.711343 test begin: paddle.geometric.segment_min(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.8457691669464111 	 1.140681266784668 	 0.0008127689361572266 	 0.0002722740173339844 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:27:40.147356 test begin: paddle.geometric.segment_min(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), ) 	 101606480 	 1000 	 1.8420875072479248 	 2.581493854522705 	 0.0018100738525390625 	 0.0005323886871337891 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:27:49.231813 test begin: paddle.geometric.segment_min(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.3504221439361572 	 0.5336248874664307 	 0.0003256797790527344 	 6.413459777832031e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:27:51.244467 test begin: paddle.geometric.segment_min(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), ) 	 106686741 	 1000 	 2.1811904907226562 	 5.005126953125 	 0.0021486282348632812 	 0.00036525726318359375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:28:02.784285 test begin: paddle.geometric.segment_sum(Tensor([25401601, 15],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([25401601, 15],"float16"), Tensor([25401601],"int64"), ) 	 406425616 	 1000 	 6.0795814990997314 	 4.787505865097046 	 0.0060138702392578125 	 2.4476935863494873 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:28:28.361827 test begin: paddle.geometric.segment_sum(Tensor([25401601, 15],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([25401601, 15],"float32"), Tensor([25401601],"int64"), ) 	 406425616 	 1000 	 5.525656700134277 	 3.882143259048462 	 0.004814863204956055 	 1.9858181476593018 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:28:54.901255 test begin: paddle.geometric.segment_sum(Tensor([2540161, 20],"float32"), Tensor([2540161],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([2540161, 20],"float32"), Tensor([2540161],"int32"), ) 	 53343381 	 1000 	 0.6668391227722168 	 0.5315930843353271 	 0.0006453990936279297 	 0.2708158493041992 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:28:58.259319 test begin: paddle.geometric.segment_sum(Tensor([30, 1693441],"float32"), Tensor([30],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([30, 1693441],"float32"), Tensor([30],"int64"), ) 	 50803260 	 1000 	 0.6418812274932861 	 0.46372389793395996 	 0.0006127357482910156 	 0.236527681350708 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:29:01.479113 test begin: paddle.geometric.segment_sum(Tensor([30, 3386881],"float16"), Tensor([30],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([30, 3386881],"float16"), Tensor([30],"int64"), ) 	 101606460 	 1000 	 1.4540505409240723 	 1.1451268196105957 	 0.0014224052429199219 	 0.5857923030853271 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:29:08.629985 test begin: paddle.geometric.segment_sum(Tensor([3386881, 15],"float32"), Tensor([3386881],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([3386881, 15],"float32"), Tensor([3386881],"int64"), ) 	 54190096 	 1000 	 0.6012883186340332 	 0.47744131088256836 	 0.0005731582641601562 	 0.24317026138305664 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:29:11.608756 test begin: paddle.geometric.segment_sum(Tensor([40, 1270081],"float32"), Tensor([40],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([40, 1270081],"float32"), Tensor([40],"int32"), ) 	 50803280 	 1000 	 0.499739408493042 	 0.3580009937286377 	 0.00047516822814941406 	 0.18185663223266602 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:29:14.174430 test begin: paddle.geometric.segment_sum(Tensor([50803201, 20],"float32"), Tensor([50803201],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([50803201, 20],"float32"), Tensor([50803201],"int32"), ) 	 1066867221 	 1000 	 11.639747619628906 	 9.153220653533936 	 0.011603355407714844 	 3.1194448471069336 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:08.515269 test begin: paddle.geometric.segment_sum(Tensor([6773761, 15],"float16"), Tensor([6773761],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([6773761, 15],"float16"), Tensor([6773761],"int64"), ) 	 108380176 	 1000 	 1.8332767486572266 	 1.440626859664917 	 0.0017516613006591797 	 0.7367992401123047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:16.767954 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, ) 	 25401640 	 1000 	 1.0250682830810547 	 3.76189923286438 	 0.3493790626525879 	 0.0004725456237792969 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:23.880773 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, ) 	 25401640 	 1000 	 1.0872550010681152 	 4.418846607208252 	 0.22208476066589355 	 0.000217437744140625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:31.246210 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, ) 	 25401640 	 1000 	 1.0335514545440674 	 3.74703311920166 	 0.35265159606933594 	 0.00046133995056152344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:40.044070 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, ) 	 25401650 	 1000 	 0.4496884346008301 	 2.2665016651153564 	 0.15316319465637207 	 0.00046372413635253906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:43.907664 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, ) 	 25401650 	 1000 	 0.3598361015319824 	 2.661158323287964 	 0.0736088752746582 	 0.00025582313537597656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:48.070624 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, ) 	 25401650 	 1000 	 0.4509403705596924 	 2.6931025981903076 	 0.15322661399841309 	 0.00045680999755859375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:30:54.687110 test begin: paddle.geometric.send_ue_recv(Tensor([10, 1693441],"float64"), Tensor([15, 1693441],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 1693441],"float64"), Tensor([15, 1693441],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 42336055 	 1000 	 0.8662126064300537 	 2.783517360687256 	 0.17685484886169434 	 0.0001697540283203125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:31:00.621334 test begin: paddle.geometric.send_ue_recv(Tensor([10, 2540161],"float64"), Tensor([15, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 2540161],"float64"), Tensor([15, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 63504055 	 1000 	 1.2951009273529053 	 3.5879695415496826 	 0.26413488388061523 	 0.000244140625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:31:10.559724 test begin: paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 33022175 	 1000 	 61.84856414794922 	 3.479556083679199 	 0.0002224445343017578 	 0.0005028247833251953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:33:32.143662 test begin: paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 33022175 	 1000 	 77.2276771068573 	 2.6557421684265137 	 0.00010585784912109375 	 9.226799011230469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:37:07.582038 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 25401830 	 1000 	 63.88746094703674 	 3.4394538402557373 	 9.894371032714844e-05 	 0.0005161762237548828 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:41:21.373619 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 25401830 	 1000 	 57.52412223815918 	 2.4254250526428223 	 0.00015354156494140625 	 0.0005431175231933594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:46:08.577476 test begin: paddle.geometric.send_ue_recv(Tensor([1270081, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([1270081, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 25401950 	 1000 	 0.36017680168151855 	 1.7019331455230713 	 0.07385778427124023 	 0.00029850006103515625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:46:12.851678 test begin: paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 25401790 	 1000 	 0.5410594940185547 	 1.698319911956787 	 3.838539123535156e-05 	 0.00047206878662109375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:46:16.543384 test begin: paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 25401790 	 1000 	 0.24548077583312988 	 1.4317002296447754 	 3.0994415283203125e-05 	 9.083747863769531e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:46:19.535712 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", ) 	 50805302 	 1000 	 7.941662788391113 	 6.069736003875732 	 8.106231689453125e-05 	 3.10275936126709 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:47:13.482357 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "mul", ) 	 50805302 	 1000 	 8.39777660369873 	 6.067030429840088 	 9.083747863769531e-05 	 3.1012046337127686 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:48:09.085309 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401830 	 1000 	 3.4566001892089844 	 0.051622867584228516 	 5.555152893066406e-05 	 0.038439035415649414 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:48:15.004314 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 25401830 	 1000 	 8.60565996170044 	 0.0504148006439209 	 8.916854858398438e-05 	 0.038133859634399414 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:48:28.323230 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401750 	 1000 	 0.0957341194152832 	 0.011567115783691406 	 3.0279159545898438e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:48:29.065451 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 25401750 	 1000 	 0.1148521900177002 	 0.0187835693359375 	 4.172325134277344e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:48:30.033889 test begin: paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([100, 1],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([100, 1],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", ) 	 50805302 	 1000 	 7.937035083770752 	 6.069444894790649 	 8.320808410644531e-05 	 3.1021182537078857 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:49:21.963110 test begin: paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25403631 	 1000 	 0.0957942008972168 	 0.02207636833190918 	 1.5974044799804688e-05 	 7.700920104980469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:49:30.930603 test begin: paddle.geometric.send_uv(Tensor([100, 254017],"float64"), Tensor([100, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 254017],"float64"), Tensor([100, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401830 	 1000 	 10.68804144859314 	 0.05076193809509277 	 8.606910705566406e-05 	 0.0344395637512207 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:49:43.942327 test begin: paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 26671731 	 1000 	 0.09770917892456055 	 0.011541128158569336 	 3.409385681152344e-05 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:49:45.113513 test begin: paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 26671731 	 1000 	 0.09740567207336426 	 0.015964269638061523 	 3.886222839355469e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:49:46.438912 test begin: paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 26674703 	 1000 	 0.09930777549743652 	 0.011645078659057617 	 3.6716461181640625e-05 	 2.8133392333984375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:49:47.620021 test begin: paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", ) 	 533436623 	 1000 	 0.09734177589416504 	 0.011955738067626953 	 4.00543212890625e-05 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:50:09.097321 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 533436623 	 1000 	 0.0971682071685791 	 0.011639833450317383 	 3.5762786865234375e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:50:30.634532 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 533433651 	 1000 	 0.10004377365112305 	 0.011638164520263672 	 3.0517578125e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:50:56.531102 test begin: paddle.greater_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), ) 	 38103936 	 1000 	 0.5613448619842529 	 0.5027210712432861 	 0.5512194633483887 	 0.48999881744384766 	 None 	 None 	 None 	 None 	 
2025-07-30 15:50:58.341212 test begin: paddle.greater_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), ) 	 38102688 	 1000 	 0.5534939765930176 	 0.5063612461090088 	 0.5361206531524658 	 0.4850893020629883 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:00.048442 test begin: paddle.greater_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), ) 	 31753280 	 1000 	 0.2145998477935791 	 0.21934962272644043 	 0.2044992446899414 	 0.20669865608215332 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:00.957482 test begin: paddle.greater_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), ) 	 25403456 	 1000 	 0.5634095668792725 	 0.44571352005004883 	 0.5460398197174072 	 0.423844575881958 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:02.375649 test begin: paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), ) 	 25405120 	 1000 	 1.0587751865386963 	 0.9110219478607178 	 1.0486152172088623 	 0.8987252712249756 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:04.757980 test begin: paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), ) 	 228616128 	 1000 	 1.8177287578582764 	 1.5905184745788574 	 1.7985889911651611 	 1.5548555850982666 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:11.730501 test begin: paddle.greater_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), ) 	 76205064 	 1000 	 1.112823724746704 	 0.9999055862426758 	 1.1026527881622314 	 0.9766535758972168 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:15.679135 test begin: paddle.greater_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), ) 	 76205376 	 1000 	 1.1161689758300781 	 0.995924711227417 	 1.1056039333343506 	 0.9836876392364502 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:18.902876 test begin: paddle.greater_equal(Tensor([16935, 10, 15, 20],"float32"), Tensor([16935, 10, 15, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([16935, 10, 15, 20],"float32"), Tensor([16935, 10, 15, 20],"float32"), ) 	 101610000 	 1000 	 0.32854580879211426 	 0.32804012298583984 	 0.31913256645202637 	 0.3164041042327881 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:21.192201 test begin: paddle.greater_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), ) 	 76205184 	 1000 	 1.1161785125732422 	 0.9973502159118652 	 1.1059885025024414 	 0.9850335121154785 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:24.475157 test begin: paddle.greater_equal(Tensor([49613, 1024, 1, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([49613, 1024, 1, 1],"float32"), Tensor([1],"float32"), ) 	 50803713 	 1000 	 0.18900465965270996 	 0.24694228172302246 	 0.17861509323120117 	 0.21836519241333008 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:25.698364 test begin: paddle.greater_equal(Tensor([5, 10, 15, 67738],"float32"), Tensor([5, 10, 15, 67738],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 10, 15, 67738],"float32"), Tensor([5, 10, 15, 67738],"float32"), ) 	 101607000 	 1000 	 0.3271970748901367 	 0.32796645164489746 	 0.31774377822875977 	 0.3161332607269287 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:27.951078 test begin: paddle.greater_equal(Tensor([5, 10, 50804, 20],"float32"), Tensor([5, 10, 50804, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 10, 50804, 20],"float32"), Tensor([5, 10, 50804, 20],"float32"), ) 	 101608000 	 1000 	 0.32723069190979004 	 0.34145283699035645 	 0.3179776668548584 	 0.31611108779907227 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:30.201148 test begin: paddle.greater_equal(Tensor([5, 33869, 15, 20],"float32"), Tensor([5, 33869, 15, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 33869, 15, 20],"float32"), Tensor([5, 33869, 15, 20],"float32"), ) 	 101607000 	 1000 	 0.3272433280944824 	 0.3307619094848633 	 0.317584753036499 	 0.3162269592285156 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:32.402666 test begin: paddle.greater_equal(Tensor([8, 1024, 1, 6202],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 1024, 1, 6202],"float32"), Tensor([1],"float32"), ) 	 50806785 	 1000 	 0.18952202796936035 	 0.23096847534179688 	 0.17438435554504395 	 0.21845793724060059 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:33.618417 test begin: paddle.greater_equal(Tensor([8, 1024, 6202, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 1024, 6202, 1],"float32"), Tensor([1],"float32"), ) 	 50806785 	 1000 	 0.18822598457336426 	 0.24367928504943848 	 0.17806243896484375 	 0.2185840606689453 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:36.373785 test begin: paddle.greater_equal(Tensor([8, 6350401, 1, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 6350401, 1, 1],"float32"), Tensor([1],"float32"), ) 	 50803209 	 1000 	 0.18780207633972168 	 1.1256656646728516 	 0.17741656303405762 	 0.21557283401489258 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:43.528768 test begin: paddle.greater_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), ) 	 38102784 	 1000 	 0.5612549781799316 	 0.5056765079498291 	 0.5510549545288086 	 0.4896559715270996 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:45.224857 test begin: paddle.greater_than(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19124221801757812 	 0.24866247177124023 	 0.18117594718933105 	 0.23645520210266113 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:46.434897 test begin: paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18851327896118164 	 0.24920105934143066 	 0.17830538749694824 	 0.23692750930786133 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:47.647889 test begin: paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.32807159423828125 	 0.32796239852905273 	 0.3186032772064209 	 0.31634998321533203 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:49.874520 test begin: paddle.greater_than(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.3269157409667969 	 0.3280308246612549 	 0.3174419403076172 	 0.3156723976135254 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:52.182009 test begin: paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), )
W0730 15:51:55.420356 25606 dygraph_functions.cc:90428] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), ) 	 203212812 	 1000 	 1.1295194625854492 	 0.7200188636779785 	 0.577228307723999 	 0.7081873416900635 	 None 	 None 	 None 	 None 	 
2025-07-30 15:51:57.381953 test begin: paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float64"), ) 	 203212812 	 1000 	 2.035261869430542 	 0.9918091297149658 	 1.03983473777771 	 0.9664084911346436 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:04.301502 test begin: paddle.greater_than(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3268921375274658 	 0.341494083404541 	 0.3104715347290039 	 0.31601762771606445 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:06.796138 test begin: paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), ) 	 203212816 	 1000 	 1.1309151649475098 	 0.7318577766418457 	 0.5785923004150391 	 0.7062397003173828 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:12.113057 test begin: paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float64"), ) 	 203212816 	 1000 	 2.03669810295105 	 0.9781816005706787 	 1.0414173603057861 	 0.9652915000915527 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:18.931001 test begin: paddle.greater_than(Tensor([4, 3, 2116801],"float16"), Tensor([4, 3, 2116801],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 2116801],"float16"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 0.5184223651885986 	 0.2547488212585449 	 0.2648952007293701 	 0.2402338981628418 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:20.663596 test begin: paddle.greater_than(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 0.5709714889526367 	 0.3629610538482666 	 0.2910919189453125 	 0.3512532711029053 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:23.319669 test begin: paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), ) 	 203212824 	 1000 	 1.13077712059021 	 0.7200114727020264 	 0.577131986618042 	 0.7060263156890869 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:28.655704 test begin: paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float64"), ) 	 203212824 	 1000 	 2.033984661102295 	 0.9834637641906738 	 1.0387351512908936 	 0.9655671119689941 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:37.243892 test begin: paddle.greater_than(Tensor([4, 3175201, 2],"float16"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3175201, 2],"float16"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 0.5184116363525391 	 0.2587392330169678 	 0.2648906707763672 	 0.23878788948059082 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:39.505542 test begin: paddle.greater_than(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 0.5695517063140869 	 0.36302733421325684 	 0.29099035263061523 	 0.3451716899871826 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:42.187634 test begin: paddle.greater_than(Tensor([4233601, 3, 2],"float16"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4233601, 3, 2],"float16"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 0.518369197845459 	 0.25081825256347656 	 0.2648935317993164 	 0.23280739784240723 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:45.789387 test begin: paddle.greater_than(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 0.5695552825927734 	 0.37912511825561523 	 0.2910175323486328 	 0.3462367057800293 	 None 	 None 	 None 	 None 	 
2025-07-30 15:52:49.017729 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([1],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([1],"float32"), ) 	 50804737 	 1000 	 0.2965829372406006 	 0.3158280849456787 	 0.2860560417175293 	 0.2842864990234375 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 15:53:26.171252 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([2048],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([2048],"float32"), ) 	 50806784 	 1000 	 0.2986781597137451 	 0.30777883529663086 	 0.286895751953125 	 0.29507017135620117 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 15:53:29.668488 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([24807, 2048],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([24807, 2048],"float32"), ) 	 101609472 	 1000 	 0.45153093338012695 	 0.4463803768157959 	 0.43481898307800293 	 0.42789292335510254 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 15:53:33.633304 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([169345],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([169345],"float32"), ) 	 50972845 	 1000 	 0.2958543300628662 	 0.5316717624664307 	 0.2777409553527832 	 0.28505706787109375 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 15:53:39.499870 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([1],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([1],"float32"), ) 	 50803501 	 1000 	 0.29675722122192383 	 0.3057732582092285 	 0.2786388397216797 	 0.29073286056518555 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 15:54:16.341904 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), ) 	 101607000 	 1000 	 0.4498164653778076 	 0.4463365077972412 	 0.43995094299316406 	 0.43438005447387695 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 15:54:20.248499 test begin: paddle.histogram(input=Tensor([4, 6350401],"int64"), )
[Prof] paddle.histogram 	 paddle.histogram(input=Tensor([4, 6350401],"int64"), ) 	 25401604 	 1000 	 6.475969552993774 	 0.7909934520721436 	 0.00039839744567871094 	 0.00040459632873535156 	 None 	 None 	 None 	 None 	 
2025-07-30 15:54:28.035255 test begin: paddle.histogram(input=Tensor([6350401, 4],"int64"), )
[Prof] paddle.histogram 	 paddle.histogram(input=Tensor([6350401, 4],"int64"), ) 	 25401604 	 1000 	 6.47562313079834 	 0.7631824016571045 	 0.0003981590270996094 	 0.0004124641418457031 	 None 	 None 	 None 	 None 	 
2025-07-30 15:54:36.015679 test begin: paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0, max=1, ) 	 50803220 	 1000 	 0.10108184814453125 	 0.016563892364501953 	 1.2636184692382812e-05 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:54:37.373504 test begin: paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=1, max=1, ) 	 50803205 	 1000 	 0.12501168251037598 	 0.016775131225585938 	 2.5272369384765625e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:54:39.318447 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, ) 	 508032050 	 1000 	 0.12590765953063965 	 0.0244901180267334 	 2.8371810913085938e-05 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:54:47.834063 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, ) 	 508032050 	 1000 	 0.10350346565246582 	 0.01685643196105957 	 1.71661376953125e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:54:56.979734 test begin: paddle.histogramdd(Tensor([1270, 2, 2],"float64"), bins=5, weights=Tensor([1270, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, )
/usr/local/lib/python3.10/dist-packages/paddle/tensor/linalg.py:5741: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  edge = paddle.to_tensor(edge)
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([1270, 2, 2],"float64"), bins=5, weights=Tensor([1270, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, ) 	 7620 	 1000 	 1.8737342357635498 	 0.07851910591125488 	 1.5020370483398438e-05 	 6.961822509765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:54:59.234689 test begin: paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=False, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=False, ) 	 317520 	 1000 	 3.7176411151885986 	 1.100358247756958 	 2.5033950805664062e-05 	 0.00012612342834472656 	 None 	 None 	 None 	 None 	 
2025-07-30 15:55:04.074214 test begin: paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=True, ) 	 317520 	 1000 	 3.91654109954834 	 1.271777868270874 	 1.430511474609375e-05 	 0.0001862049102783203 	 None 	 None 	 None 	 None 	 
2025-07-30 15:55:09.280797 test begin: paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=False, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=False, ) 	 1270080 	 1000 	 20.086699724197388 	 4.438604354858398 	 5.221366882324219e-05 	 0.00013566017150878906 	 None 	 None 	 None 	 None 	 
2025-07-30 15:55:33.897831 test begin: paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=True, ) 	 1270080 	 1000 	 20.2090744972229 	 4.6507728099823 	 2.765655517578125e-05 	 0.00028586387634277344 	 None 	 None 	 None 	 None 	 
2025-07-30 15:55:58.815597 test begin: paddle.histogramdd(Tensor([63504, 2, 2],"float64"), bins=5, weights=Tensor([63504, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([63504, 2, 2],"float64"), bins=5, weights=Tensor([63504, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, ) 	 381024 	 1000 	 3.127933979034424 	 0.13832855224609375 	 0.0001780986785888672 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:56:02.099204 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], )
W0730 15:56:11.692090 62020 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.03137993812561035 	 0.009284019470214844 	 1.5497207641601562e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:56:13.631501 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], )
W0730 15:56:20.204222 62772 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.01727461814880371 	 0.006902217864990234 	 1.4066696166992188e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:56:20.862249 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], )
W0730 15:56:27.314165 63254 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.024386167526245117 	 0.008088827133178711 	 1.6450881958007812e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:56:28.133725 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], )
W0730 15:56:39.370954 63855 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.03136897087097168 	 0.00927281379699707 	 1.5497207641601562e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:56:41.361062 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], )
W0730 15:56:48.962327 64494 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.017462730407714844 	 0.008765459060668945 	 1.6689300537109375e-05 	 5.054473876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:56:50.633871 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], )
W0730 15:56:57.103125 65112 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.02457904815673828 	 0.008153438568115234 	 1.2874603271484375e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:56:57.761726 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], )
W0730 15:57:07.264385 65582 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.031256914138793945 	 0.009285449981689453 	 1.239776611328125e-05 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:57:10.176355 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], )
W0730 15:57:18.537778 66752 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.029669761657714844 	 0.01163029670715332 	 4.601478576660156e-05 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:57:20.131949 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], )
W0730 15:57:27.125751 67376 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.04145646095275879 	 0.008111953735351562 	 2.8371810913085938e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:57:29.265234 test begin: paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9294302463531494 	 0.9334428310394287 	 0.9026572704315186 	 0.9051468372344971 	 0.9294052124023438 	 0.08560872077941895 	 0.8497204780578613 	 6.008148193359375e-05 	 
2025-07-30 15:57:35.213655 test begin: paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3140842914581299 	 0.32249927520751953 	 0.29059934616088867 	 0.16030526161193848 	 0.3111295700073242 	 0.07631778717041016 	 0.2438971996307373 	 0.00011324882507324219 	 
2025-07-30 15:57:39.752979 test begin: paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3185272216796875 	 0.34883689880371094 	 0.29148316383361816 	 0.29921722412109375 	 0.31384944915771484 	 0.08599615097045898 	 0.23356294631958008 	 5.459785461425781e-05 	 
2025-07-30 15:57:41.816944 test begin: paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3159821033477783 	 0.3217804431915283 	 0.2975635528564453 	 0.30724048614501953 	 0.31305575370788574 	 0.07813453674316406 	 0.24283623695373535 	 3.266334533691406e-05 	 
2025-07-30 15:57:43.817515 test begin: paddle.hstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.927504301071167 	 0.9305510520935059 	 0.9090609550476074 	 0.9094228744506836 	 0.931248664855957 	 0.08111834526062012 	 0.8612668514251709 	 6.0558319091796875e-05 	 
2025-07-30 15:57:49.689324 test begin: paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 25401654 	 1000 	 0.31778502464294434 	 0.31978869438171387 	 0.2910315990447998 	 0.2986149787902832 	 0.31399989128112793 	 0.08460474014282227 	 0.2338275909423828 	 5.269050598144531e-05 	 
2025-07-30 15:57:51.753362 test begin: paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.31661510467529297 	 0.31955575942993164 	 0.29814982414245605 	 0.30542731285095215 	 0.3126511573791504 	 0.07739686965942383 	 0.2424156665802002 	 4.863739013671875e-05 	 
2025-07-30 15:57:53.969840 test begin: paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9265596866607666 	 0.9306662082672119 	 0.9083781242370605 	 0.9098808765411377 	 0.9311378002166748 	 0.07822155952453613 	 0.8618321418762207 	 6.103515625e-05 	 
2025-07-30 15:57:59.802677 test begin: paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3140702247619629 	 0.3137826919555664 	 0.2989323139190674 	 0.1602025032043457 	 0.31113481521606445 	 0.07967686653137207 	 0.2534935474395752 	 0.00010514259338378906 	 
2025-07-30 15:58:01.855250 test begin: paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.3156294822692871 	 0.3131561279296875 	 0.2973496913909912 	 0.29887866973876953 	 0.3137502670288086 	 0.07737231254577637 	 0.24331021308898926 	 5.0067901611328125e-05 	 
2025-07-30 15:58:03.881173 test begin: paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9320518970489502 	 0.9321329593658447 	 0.9134840965270996 	 0.9172937870025635 	 0.9462013244628906 	 0.07744002342224121 	 0.8724365234375 	 5.626678466796875e-05 	 
2025-07-30 15:58:12.186811 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3157205581665039 	 0.32750487327575684 	 0.29718589782714844 	 0.29440999031066895 	 0.3124659061431885 	 0.10386013984680176 	 0.2419893741607666 	 7.104873657226562e-05 	 
2025-07-30 15:58:15.137790 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9346878528594971 	 0.9414408206939697 	 0.9161133766174316 	 0.9266490936279297 	 0.942251443862915 	 0.0989072322845459 	 0.8722426891326904 	 5.7220458984375e-05 	 
2025-07-30 15:58:20.924904 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3152201175689697 	 0.3137085437774658 	 0.2999565601348877 	 0.16019105911254883 	 0.3128471374511719 	 0.059281349182128906 	 0.25530099868774414 	 3.457069396972656e-05 	 
2025-07-30 15:58:22.880964 test begin: paddle.hstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.9786965847015381 	 1.3992929458618164 	 0.9602904319763184 	 1.3809423446655273 	 0.9609918594360352 	 0.07716822624206543 	 0.8868634700775146 	 6.4849853515625e-05 	 
2025-07-30 15:58:29.325779 test begin: paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9286351203918457 	 1.039907455444336 	 0.910226583480835 	 1.0175814628601074 	 0.9389638900756836 	 0.10192537307739258 	 0.8685634136199951 	 5.91278076171875e-05 	 
2025-07-30 15:58:36.523818 test begin: paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.30840277671813965 	 0.3300340175628662 	 0.29332494735717773 	 0.16022086143493652 	 0.3272063732147217 	 0.06899380683898926 	 0.2667961120605469 	 0.00016260147094726562 	 
2025-07-30 15:58:39.899775 test begin: paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 1],"float32"), ) 	 50803220 	 1000 	 0.9636297225952148 	 0.3215484619140625 	 0.24565935134887695 	 0.3087582588195801 	 1.11324143409729 	 1.8325021266937256 	 0.22751998901367188 	 0.31136393547058105 	 
2025-07-30 15:58:45.806604 test begin: paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 1.4792139530181885 	 0.4551231861114502 	 0.37792468070983887 	 0.4383234977722168 	 1.6629447937011719 	 1.7904236316680908 	 0.3396282196044922 	 0.45741724967956543 	 
2025-07-30 15:58:53.597092 test begin: paddle.hypot(Tensor([2540161, 20],"float32"), Tensor([2540161, 20],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([2540161, 20],"float32"), Tensor([2540161, 20],"float32"), ) 	 101606440 	 1000 	 1.4834942817687988 	 0.44793272018432617 	 0.3779122829437256 	 0.42980265617370605 	 1.661867380142212 	 1.7953860759735107 	 0.3396172523498535 	 0.45735979080200195 	 
2025-07-30 15:59:01.435366 test begin: paddle.hypot(Tensor([50803201],"float32"), Tensor([1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([50803201],"float32"), Tensor([1],"float32"), ) 	 50803202 	 1000 	 0.9627408981323242 	 0.31846165657043457 	 0.24570918083190918 	 0.2966887950897217 	 1.061283826828003 	 1.804654836654663 	 0.21633124351501465 	 0.30668044090270996 	 
2025-07-30 15:59:07.291217 test begin: paddle.hypot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 1.484337329864502 	 0.4478936195373535 	 0.38024449348449707 	 0.4360992908477783 	 1.6617603302001953 	 1.7941808700561523 	 0.33962535858154297 	 0.4587235450744629 	 
2025-07-30 15:59:15.196117 test begin: paddle.hypot(Tensor([5080321, 10],"float32"), Tensor([5080321, 1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([5080321, 10],"float32"), Tensor([5080321, 1],"float32"), ) 	 55883531 	 1000 	 1.0142507553100586 	 0.3407480716705322 	 0.25925779342651367 	 0.31633615493774414 	 1.298520803451538 	 2.1003270149230957 	 0.33160996437072754 	 0.4279134273529053 	 
2025-07-30 15:59:22.736967 test begin: paddle.i0(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.4671669006347656 	 0.41324305534362793 	 0.45793652534484863 	 0.39949655532836914 	 0.44467949867248535 	 0.8583130836486816 	 0.3914039134979248 	 0.4389348030090332 	 
2025-07-30 15:59:26.522059 test begin: paddle.i0(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.46552252769470215 	 0.4096207618713379 	 0.4562201499938965 	 0.396881103515625 	 0.44608473777770996 	 0.8571271896362305 	 0.39315009117126465 	 0.43793153762817383 	 
2025-07-30 15:59:30.232774 test begin: paddle.i0(Tensor([25401601],"float64"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.4963366985321045 	 0.4643576145172119 	 0.4874267578125 	 0.45365333557128906 	 0.5120151042938232 	 0.9156756401062012 	 0.4589345455169678 	 0.4678463935852051 	 
2025-07-30 15:59:33.596517 test begin: paddle.i0(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.46685075759887695 	 1.0760927200317383 	 0.45755887031555176 	 0.39662837982177734 	 0.44622254371643066 	 0.8548183441162109 	 0.3932483196258545 	 0.4367210865020752 	 
2025-07-30 15:59:39.818545 test begin: paddle.i0(Tensor([50803201],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.4655184745788574 	 0.4075663089752197 	 0.456226110458374 	 0.39688539505004883 	 0.447296142578125 	 0.8543076515197754 	 0.3938412666320801 	 0.43649983406066895 	 
2025-07-30 15:59:43.549945 test begin: paddle.i0e(Tensor([25401601],"float64"), )
[Prof] paddle.i0e 	 paddle.i0e(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.39396214485168457 	 0.3652374744415283 	 0.3849818706512451 	 0.3545970916748047 	 0.5998589992523193 	 2.0049800872802734 	 0.5434930324554443 	 0.4093661308288574 	 
2025-07-30 15:59:47.945286 test begin: paddle.i0e(Tensor([50803201],"float32"), )
[Prof] paddle.i0e 	 paddle.i0e(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.428330659866333 	 0.36881589889526367 	 0.41905784606933594 	 0.35839343070983887 	 0.5881142616271973 	 1.9313085079193115 	 0.5341963768005371 	 0.39452123641967773 	 
2025-07-30 13:31:47.923281 test begin: paddle.i1(Tensor([25401601],"float64"), )
W0730 13:31:48.605715  2200 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.i1 	 paddle.i1(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.5016558170318604 	 0.47557759284973145 	 0.4933590888977051 	 0.4574923515319824 	 0.599790096282959 	 3.210184097290039 	 0.5350830554962158 	 0.29822421073913574 	 
2025-07-30 13:31:54.597910 test begin: paddle.i1(Tensor([50803201],"float32"), )
[Prof] paddle.i1 	 paddle.i1(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 1.005387544631958 	 0.4140665531158447 	 0.32805633544921875 	 0.4018123149871826 	 0.5905301570892334 	 3.341041326522827 	 0.5344748497009277 	 0.3102755546569824 	 
2025-07-30 13:32:02.201208 test begin: paddle.i1e(Tensor([25401601],"float64"), )
[Prof] paddle.i1e 	 paddle.i1e(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.3963429927825928 	 0.37442708015441895 	 0.3881373405456543 	 0.3641211986541748 	 0.5896656513214111 	 3.8477256298065186 	 0.5304131507873535 	 0.30287981033325195 	 
2025-07-30 13:32:08.502856 test begin: paddle.i1e(Tensor([50803201],"float32"), )
[Prof] paddle.i1e 	 paddle.i1e(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.3144955635070801 	 0.29738521575927734 	 0.3063623905181885 	 0.28731250762939453 	 0.5873417854309082 	 4.043575286865234 	 0.5291018486022949 	 0.31824278831481934 	 
2025-07-30 13:32:15.385542 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([7576, 13412],"bfloat16"), Tensor([7576, 13412],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
/usr/local/lib/python3.10/dist-packages/paddle/incubate/nn/functional/fused_dropout_add.py:100: UserWarning: Currently, fused_dropout_add maybe has precision problem, so it falls back to dropout + add. 
  warnings.warn(
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([7576, 13412],"bfloat16"), Tensor([7576, 13412],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203218624 	 1000 	 0.44943904876708984 	 0.45033860206604004 	 0.43808579444885254 	 0.427448034286499 	 0.9633839130401611 	 0.4537200927734375 	 0.8932716846466064 	 0.3747134208679199 	 combined
2025-07-30 13:32:22.799077 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([7712, 13176],"bfloat16"), Tensor([7712, 13176],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([7712, 13176],"bfloat16"), Tensor([7712, 13176],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203226624 	 1000 	 0.44931554794311523 	 0.4503445625305176 	 0.4379434585571289 	 0.42784667015075684 	 0.9629578590393066 	 0.45376038551330566 	 0.8951506614685059 	 0.3674275875091553 	 combined
2025-07-30 13:32:30.123948 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([79381, 1280],"bfloat16"), Tensor([79381, 1280],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([79381, 1280],"bfloat16"), Tensor([79381, 1280],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203215360 	 1000 	 0.44898462295532227 	 2.0202925205230713 	 0.43759894371032715 	 0.41890430450439453 	 0.9632396697998047 	 0.4536774158477783 	 0.894747257232666 	 0.3658182621002197 	 combined
2025-07-30 13:32:41.547902 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([8168, 12440],"bfloat16"), Tensor([8168, 12440],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([8168, 12440],"bfloat16"), Tensor([8168, 12440],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203219840 	 1000 	 0.4491891860961914 	 0.45035386085510254 	 0.43766307830810547 	 0.427581787109375 	 0.963106632232666 	 0.45363688468933105 	 0.8946764469146729 	 0.3715519905090332 	 combined
2025-07-30 13:32:48.836396 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 14176, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0730 13:33:05.339428  3023 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 14176, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 193376768 	 1000 	 10.66670298576355 	 10.739945411682129 	 10.644134998321533 	 10.701773881912231 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:33:39.456333 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 12404],"bfloat16"), Tensor([12404, 8192],"bfloat16"), None, False, None, )
W0730 13:33:47.537758  3748 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 12404],"bfloat16"), Tensor([12404, 8192],"bfloat16"), None, False, None, ) 	 152420352 	 1000 	 5.200464725494385 	 5.302635431289673 	 2.6621549129486084 	 2.7130184173583984 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:04.348718 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 16384],"bfloat16"), Tensor([16384, 6202],"bfloat16"), None, False, None, )
W0730 13:34:13.610400  3849 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 16384],"bfloat16"), Tensor([16384, 6202],"bfloat16"), None, False, None, ) 	 168722432 	 1000 	 5.798524379730225 	 5.814395189285278 	 2.961841106414795 	 2.969482183456421 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:34:31.907054 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 24807],"bfloat16"), Tensor([24807, 8192],"bfloat16"), None, False, None, )
W0730 13:34:58.745226  3949 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 24807],"bfloat16"), Tensor([24807, 8192],"bfloat16"), None, False, None, ) 	 304828416 	 1000 	 18.864869594573975 	 21.26335883140564 	 9.63779592514038 	 10.865502834320068 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:08.080167 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 8192],"bfloat16"), Tensor([8192, 12404],"bfloat16"), None, transpose_weight=False, )
W0730 13:36:17.025605  4786 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 8192],"bfloat16"), Tensor([8192, 12404],"bfloat16"), None, transpose_weight=False, ) 	 135168000 	 1000 	 5.579945087432861 	 5.626718997955322 	 5.564166784286499 	 5.580019950866699 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:37.532710 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 6202, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, )
W0730 13:36:48.796813  4876 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 6202, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, ) 	 235831296 	 1000 	 6.93373441696167 	 6.927018642425537 	 6.917346477508545 	 6.896944999694824 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:37:10.308636 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 12404],"bfloat16"), Tensor([12404, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0730 13:37:31.767160  5373 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 12404],"bfloat16"), Tensor([12404, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 260397568 	 1000 	 16.0509991645813 	 16.35761070251465 	 16.033827781677246 	 16.325204610824585 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:38:20.933393 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 7168],"bfloat16"), Tensor([7168, 14176],"bfloat16"), Tensor([14176],"bfloat16"), )
W0730 13:38:32.060041  5591 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 7168],"bfloat16"), Tensor([7168, 14176],"bfloat16"), Tensor([14176],"bfloat16"), ) 	 160348000 	 1000 	 7.027799844741821 	 7.031518220901489 	 7.009166955947876 	 6.987598657608032 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:38:54.474438 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([2, 4096, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, )
W0730 13:39:08.462448  5704 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([2, 4096, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, ) 	 268435456 	 1000 	 8.868781089782715 	 8.865851879119873 	 8.853607416152954 	 8.834086179733276 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:39:37.647888 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([2, 8192, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0730 13:39:56.566876  6247 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([2, 8192, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 209203712 	 1000 	 12.370853185653687 	 12.335451602935791 	 12.348713636398315 	 12.298282146453857 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:40:35.172061 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([4, 4096, 8192],"bfloat16"), Tensor([8192, 100352],"bfloat16"), None, transpose_weight=False, )
W0730 13:43:11.020124  6419 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([4, 4096, 8192],"bfloat16"), Tensor([8192, 100352],"bfloat16"), None, transpose_weight=False, ) 	 956301312 	 1000 	 111.49509382247925 	 112.80703330039978 	 111.43607068061829 	 112.73693108558655 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:49:03.770286 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([40, 50],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([40, 50],"float32"), None, False, True, ) 	 50805250 	 1000 	 0.47304201126098633 	 0.4779205322265625 	 0.4599332809448242 	 0.44890666007995605 	 0.9046609401702881 	 0.9028677940368652 	 0.30808019638061523 	 0.3082449436187744 	 
2025-07-30 13:49:08.112186 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([50, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([50, 40],"float32"), None, False, False, ) 	 50805250 	 1000 	 0.4685361385345459 	 0.4697303771972656 	 0.451779842376709 	 0.449857234954834 	 0.9101986885070801 	 0.9090793132781982 	 0.3099493980407715 	 0.3100907802581787 	 
2025-07-30 13:49:12.325526 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1270081, 30],"float32"), Tensor([40, 1270081],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1270081, 30],"float32"), Tensor([40, 1270081],"float32"), None, True, True, ) 	 88905670 	 1000 	 0.39618420600891113 	 0.39402341842651367 	 0.20241641998291016 	 0.20124006271362305 	 0.6936459541320801 	 0.6978592872619629 	 0.17763495445251465 	 0.17863798141479492 	 
2025-07-30 13:49:15.984200 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1693441, 30],"float32"), Tensor([40, 1693441],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1693441, 30],"float32"), Tensor([40, 1693441],"float32"), None, True, True, ) 	 118540870 	 1000 	 0.5200848579406738 	 0.5175087451934814 	 0.26570677757263184 	 0.2644460201263428 	 0.9240241050720215 	 0.9263396263122559 	 0.2385110855102539 	 0.23941707611083984 	 
2025-07-30 13:49:20.740134 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([1270081, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([1270081, 40],"float32"), None, False, False, ) 	 88905670 	 1000 	 0.4185476303100586 	 0.4141194820404053 	 0.2138657569885254 	 0.21161913871765137 	 0.7251710891723633 	 0.7286996841430664 	 0.18528175354003906 	 0.18613910675048828 	 
2025-07-30 13:49:24.506141 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([40, 1270081],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([40, 1270081],"float32"), None, False, True, ) 	 88905670 	 1000 	 0.4044508934020996 	 0.40237951278686523 	 0.20664453506469727 	 0.2055802345275879 	 0.6803388595581055 	 0.6871843338012695 	 0.1737966537475586 	 0.17549419403076172 	 
2025-07-30 13:49:28.173491 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([1693441, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([1693441, 40],"float32"), None, False, False, ) 	 118540870 	 1000 	 0.5423417091369629 	 0.5371966361999512 	 0.27704405784606934 	 0.2744619846343994 	 0.9573585987091064 	 0.9545865058898926 	 0.24457907676696777 	 0.24378561973571777 	 
2025-07-30 13:49:34.918527 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([40, 1693441],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([40, 1693441],"float32"), None, False, True, ) 	 118540870 	 1000 	 0.5308239459991455 	 0.5286374092102051 	 0.27120304107666016 	 0.2700812816619873 	 0.9034099578857422 	 0.9066600799560547 	 0.23079228401184082 	 0.2315680980682373 	 
2025-07-30 13:49:43.800051 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([1016065, 50],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([1016065, 50],"float32"), None, False, True, ) 	 50804750 	 1000 	 0.3018033504486084 	 0.30210256576538086 	 0.27573466300964355 	 0.2577941417694092 	 0.6276662349700928 	 0.630856990814209 	 0.21373963356018066 	 0.21462798118591309 	 
2025-07-30 13:49:47.073911 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([50, 1016065],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([50, 1016065],"float32"), None, False, False, ) 	 50804750 	 1000 	 0.2962813377380371 	 0.29331445693969727 	 0.2706480026245117 	 0.2623097896575928 	 0.6485631465911865 	 0.6501312255859375 	 0.22077178955078125 	 0.22133374214172363 	 
2025-07-30 13:49:50.266212 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 1016065],"float32"), Tensor([40, 50],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 1016065],"float32"), Tensor([40, 50],"float32"), None, True, True, ) 	 50805250 	 1000 	 0.4607388973236084 	 0.46096158027648926 	 0.43596553802490234 	 0.41416430473327637 	 0.888864278793335 	 0.8844449520111084 	 0.30272507667541504 	 0.3010590076446533 	 
2025-07-30 13:49:54.460836 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 30],"float32"), Tensor([1016065, 50],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 30],"float32"), Tensor([1016065, 50],"float32"), None, True, True, ) 	 50804750 	 1000 	 0.3005492687225342 	 0.30199623107910156 	 0.28469085693359375 	 0.2684619426727295 	 0.6549022197723389 	 0.6540751457214355 	 0.22292852401733398 	 0.22264766693115234 	 
2025-07-30 13:49:57.766665 test begin: paddle.incubate.nn.functional.swiglu(Tensor([14176, 7168],"bfloat16"), )
W0730 13:50:00.292282 10137 backward.cc:462] While running Node (SwigluGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.swiglu 	 paddle.incubate.nn.functional.swiglu(Tensor([14176, 7168],"bfloat16"), ) 	 101613568 	 1000 	 0.22980594635009766 	 0.5223419666290283 	 0.2204129695892334 	 0.26686811447143555 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:50:02.438613 test begin: paddle.incubate.segment_max(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_max" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_max" instead.
    Reason: paddle.incubate.segment_max will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_max" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_max" instead.
    Reason: paddle.incubate.segment_max will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_max 	 paddle.incubate.segment_max(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 1.004256248474121 	 1.0275328159332275 	 0.0009732246398925781 	 0.00022482872009277344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:50:06.749530 test begin: paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_mean 	 paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), ) 	 5097435 	 1000 	 0.06606650352478027 	 0.2747681140899658 	 3.62396240234375e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:50:10.909344 test begin: paddle.incubate.segment_min(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_min" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_min" instead.
    Reason: paddle.incubate.segment_min will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_min" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_min" instead.
    Reason: paddle.incubate.segment_min will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_min 	 paddle.incubate.segment_min(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 1.1638939380645752 	 1.2435948848724365 	 0.0011284351348876953 	 0.0003342628479003906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:50:15.831216 test begin: paddle.incubate.segment_sum(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_sum" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_sum" instead.
    Reason: paddle.incubate.segment_sum will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_sum" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_sum" instead.
    Reason: paddle.incubate.segment_sum will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_sum 	 paddle.incubate.segment_sum(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 0.6237306594848633 	 0.5541245937347412 	 0.0005815029144287109 	 0.2830357551574707 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:50:19.150662 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([1013, 1, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([1013, 1, 224, 224],"float32"), ) 	 50828288 	 1000 	 0.2636387348175049 	 0.6126296520233154 	 0.25461268424987793 	 0.15600132942199707 	 0.32645487785339355 	 0.8938720226287842 	 0.27374863624572754 	 0.4566624164581299 	 combined
2025-07-30 13:50:22.980680 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([145, 7, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([145, 7, 224, 224],"float32"), ) 	 50928640 	 1000 	 0.2622494697570801 	 0.6104812622070312 	 0.2534458637237549 	 0.1561727523803711 	 0.3265562057495117 	 0.895564079284668 	 0.27053141593933105 	 0.4575533866882324 	 combined
2025-07-30 13:50:26.787226 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([3, 338, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([3, 338, 224, 224],"float32"), ) 	 50878464 	 1000 	 0.26228785514831543 	 0.6099948883056641 	 0.254042387008667 	 0.15610241889953613 	 0.3308107852935791 	 0.8947193622589111 	 0.27718544006347656 	 0.45712900161743164 	 combined
2025-07-30 13:50:30.579499 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([4511, 11, 32, 32],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([4511, 11, 32, 32],"float32"), ) 	 50811904 	 1000 	 0.7480316162109375 	 0.6759982109069824 	 0.7392094135284424 	 0.17299199104309082 	 0.44906067848205566 	 0.8941338062286377 	 0.39641761779785156 	 0.4568037986755371 	 combined
2025-07-30 13:50:35.029277 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([5, 203, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([5, 203, 224, 224],"float32"), ) 	 50928640 	 1000 	 0.7851846218109131 	 0.620769739151001 	 0.25197482109069824 	 0.1562519073486328 	 0.33121418952941895 	 0.8956677913665771 	 0.2784895896911621 	 0.457674503326416 	 combined
2025-07-30 13:50:44.217100 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 7088, 32, 32],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 7088, 32, 32],"float32"), ) 	 50806784 	 1000 	 0.7507228851318359 	 0.6939995288848877 	 0.7392294406890869 	 0.17299199104309082 	 0.449047327041626 	 0.8940203189849854 	 0.39609551429748535 	 0.4567830562591553 	 combined
2025-07-30 13:50:49.989806 test begin: paddle.index_add(Tensor([100, 100, 25402],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 25402],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 25402],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 25402],"float32"), ) 	 304824020 	 1000 	 2.0155460834503174 	 3.4555182456970215 	 0.6832537651062012 	 0.00019073486328125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:51:08.246942 test begin: paddle.index_add(Tensor([100, 100, 25],"float32"), Tensor([5081],"int32"), 2, Tensor([100, 100, 5081],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 25],"float32"), Tensor([5081],"int32"), 2, Tensor([100, 100, 5081],"float32"), ) 	 51065081 	 1000 	 1.7535984516143799 	 368.714280128479 	 0.8960151672363281 	 0.0002949237823486328 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:57:22.781915 test begin: paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5081],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5081],"float32"), ) 	 60972020 	 1000 	 0.4118945598602295 	 1.791731357574463 	 0.14010000228881836 	 6.723403930664062e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:57:27.271311 test begin: paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 2, Tensor([100, 100, 20],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 2, Tensor([100, 100, 20],"float32"), ) 	 51010020 	 1000 	 0.3426647186279297 	 1.9013535976409912 	 0.11646890640258789 	 9.703636169433594e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:57:31.530998 test begin: paddle.index_add(Tensor([100, 101607, 5],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 101607, 5],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5],"float32"), ) 	 50813520 	 1000 	 0.31123828887939453 	 1.7745847702026367 	 0.1057744026184082 	 7.390975952148438e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:57:37.119753 test begin: paddle.index_add(Tensor([100, 2540161],"float32"), Tensor([20],"int32"), 0, Tensor([20, 2540161],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 2540161],"float32"), Tensor([20],"int32"), 0, Tensor([20, 2540161],"float32"), ) 	 304819340 	 1000 	 1.995635986328125 	 3.7587759494781494 	 0.6788864135742188 	 9.083747863769531e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:57:54.543641 test begin: paddle.index_add(Tensor([100, 508033],"float32"), Tensor([20],"int32"), 0, Tensor([20, 508033],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 508033],"float32"), Tensor([20],"int32"), 0, Tensor([20, 508033],"float32"), ) 	 60963980 	 1000 	 0.4018588066101074 	 1.771592140197754 	 0.13670706748962402 	 8.940696716308594e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:57:59.024403 test begin: paddle.index_add(Tensor([10160641, 5],"float32"), Tensor([20],"int32"), 0, Tensor([20, 5],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([10160641, 5],"float32"), Tensor([20],"int32"), 0, Tensor([20, 5],"float32"), ) 	 50803325 	 1000 	 0.31801533699035645 	 2.3503618240356445 	 0.10813641548156738 	 9.250640869140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:03.779354 test begin: paddle.index_fill(Tensor([10, 1016065, 10],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 1016065, 10],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606505 	 1000 	 0.829866886138916 	 0.3170137405395508 	 0.0006442070007324219 	 0.1076810359954834 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:09.819823 test begin: paddle.index_fill(Tensor([10, 15, 169345],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 169345],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401755 	 1000 	 1.0006694793701172 	 0.3686671257019043 	 0.06368899345397949 	 0.12532973289489746 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:13.288003 test begin: paddle.index_fill(Tensor([10, 15, 338689],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 338689],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803355 	 1000 	 0.9147834777832031 	 0.17071986198425293 	 0.0007798671722412109 	 0.05806398391723633 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:16.649865 test begin: paddle.index_fill(Tensor([10, 15, 677377],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 677377],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606555 	 1000 	 2.0362353324890137 	 0.49790167808532715 	 0.0018963813781738281 	 0.1649470329284668 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:26.499999 test begin: paddle.index_fill(Tensor([10, 254017, 10],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 254017, 10],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401705 	 1000 	 0.6665527820587158 	 0.31699705123901367 	 0.044788360595703125 	 0.10773515701293945 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:28.975463 test begin: paddle.index_fill(Tensor([10, 508033, 10],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 508033, 10],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803305 	 1000 	 0.3356435298919678 	 0.08767271041870117 	 0.0002040863037109375 	 0.02972579002380371 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:31.134437 test begin: paddle.index_fill(Tensor([169345, 15, 10],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([169345, 15, 10],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401755 	 1000 	 1.0983481407165527 	 0.4998786449432373 	 0.0698549747467041 	 0.16954588890075684 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:34.667530 test begin: paddle.index_fill(Tensor([338689, 15, 10],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([338689, 15, 10],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803355 	 1000 	 1.0918080806732178 	 0.17733120918273926 	 0.0009348392486572266 	 0.0557246208190918 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:39.854455 test begin: paddle.index_fill(Tensor([677377, 15, 10],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([677377, 15, 10],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606555 	 1000 	 2.4523510932922363 	 0.5427792072296143 	 0.002292156219482422 	 0.17754817008972168 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:49.214042 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25628144 	 1000 	 0.36530041694641113 	 0.45064496994018555 	 0.021930217742919922 	 0.01218414306640625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:51.882093 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, ) 	 25628144 	 1000 	 0.35715770721435547 	 0.32917237281799316 	 0.026067733764648438 	 0.0839078426361084 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:53.982681 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25628144 	 1000 	 0.3571455478668213 	 0.44010472297668457 	 0.02606678009033203 	 0.013098001480102539 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:56.202261 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25541904 	 1000 	 0.35761451721191406 	 0.4496147632598877 	 0.02144789695739746 	 0.012171745300292969 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:58:58.475469 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, ) 	 25541904 	 1000 	 0.34896373748779297 	 0.3278696537017822 	 0.02546215057373047 	 0.0835418701171875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:00.565926 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25541904 	 1000 	 0.3490002155303955 	 0.4391963481903076 	 0.0254671573638916 	 0.013066291809082031 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:02.783403 test begin: paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25435280 	 1000 	 0.3561279773712158 	 0.4481213092803955 	 0.02136540412902832 	 0.012142419815063477 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:05.024186 test begin: paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25435280 	 1000 	 0.3476126194000244 	 0.4378838539123535 	 0.025357484817504883 	 0.013033628463745117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:07.289546 test begin: paddle.index_sample(Tensor([1865664, 100],"float32"), Tensor([1865664, 14],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 100],"float32"), Tensor([1865664, 14],"int64"), ) 	 212685696 	 1000 	 0.7489237785339355 	 1.139070987701416 	 0.7404873371124268 	 0.38828063011169434 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:14.597412 test begin: paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 14],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 14],"int64"), ) 	 78357888 	 1000 	 0.5240323543548584 	 0.802645206451416 	 0.5155670642852783 	 0.2735929489135742 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:18.252583 test begin: paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 1],"int64"), ) 	 54104256 	 1000 	 0.41467809677124023 	 0.15460801124572754 	 0.3992130756378174 	 0.06331229209899902 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:59:20.278295 test begin: paddle.index_sample(Tensor([25401601, 100],"float32"), Tensor([25401601, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([25401601, 100],"float32"), Tensor([25401601, 1],"int64"), ) 	 2565561701 	 1000 	 4.539221286773682 	 2.094304084777832 	 4.523983001708984 	 1.070072889328003 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:00:22.486050 test begin: paddle.index_sample(Tensor([25401601, 20],"float32"), Tensor([25401601, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([25401601, 20],"float32"), Tensor([25401601, 1],"int64"), ) 	 533433621 	 1000 	 4.3297483921051025 	 2.0285675525665283 	 4.313593149185181 	 0.9174807071685791 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:00:45.205525 test begin: paddle.index_sample(Tensor([2540161, 20],"float32"), Tensor([2540161, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([2540161, 20],"float32"), Tensor([2540161, 1],"int64"), ) 	 53343381 	 1000 	 0.5382778644561768 	 0.19840192794799805 	 0.5294864177703857 	 0.10122203826904297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:00:47.413107 test begin: paddle.index_sample(Tensor([508033, 100],"float32"), Tensor([508033, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([508033, 100],"float32"), Tensor([508033, 1],"int64"), ) 	 51311333 	 1000 	 0.1193549633026123 	 0.052428245544433594 	 0.11079120635986328 	 0.006096601486206055 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:00:48.672357 test begin: paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 1],"int64"), ) 	 56488256 	 1000 	 0.9573357105255127 	 0.3169827461242676 	 0.9487252235412598 	 0.16178369522094727 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:00:52.053811 test begin: paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 5],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 5],"int64"), ) 	 77029440 	 1000 	 1.0648910999298096 	 0.8604934215545654 	 1.0560896396636963 	 0.2933032512664795 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:00:56.683414 test begin: paddle.index_sample(Tensor([5135296, 20],"float32"), Tensor([5135296, 5],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 20],"float32"), Tensor([5135296, 5],"int64"), ) 	 128382400 	 1000 	 1.1134047508239746 	 0.9892759323120117 	 1.104844570159912 	 0.33720970153808594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:02.585589 test begin: paddle.index_sample(Tensor([932832, 100],"float32"), Tensor([932832, 28],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 100],"float32"), Tensor([932832, 28],"int64"), ) 	 119402496 	 1000 	 0.5063896179199219 	 0.8791770935058594 	 0.4908864498138428 	 0.29973745346069336 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:10.096985 test begin: paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 1],"int64"), ) 	 52238592 	 1000 	 0.21259546279907227 	 0.3188893795013428 	 0.20401906967163086 	 0.04105734825134277 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:13.611564 test begin: paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 28],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 28],"int64"), ) 	 77425056 	 1000 	 0.3896157741546631 	 0.7779579162597656 	 0.3811073303222656 	 0.26526355743408203 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:17.044919 test begin: paddle.index_select(Tensor([16, 11109, 286],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 11109, 286],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50834864 	 1000 	 0.20259737968444824 	 0.22207045555114746 	 0.193526029586792 	 0.20820403099060059 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:19.066766 test begin: paddle.index_select(Tensor([16, 12096, 263],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 12096, 263],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50900048 	 1000 	 0.21301913261413574 	 0.23155784606933594 	 0.20411276817321777 	 0.21822071075439453 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:21.101353 test begin: paddle.index_select(Tensor([16, 39201, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 39201, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50804576 	 1000 	 0.6338317394256592 	 0.5601041316986084 	 0.6249465942382812 	 0.5465829372406006 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:24.722246 test begin: paddle.index_select(Tensor([205, 3060, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([205, 3060, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50811380 	 1000 	 0.6329762935638428 	 0.5596201419830322 	 0.6239278316497803 	 0.546299934387207 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:28.404281 test begin: paddle.index_select(Tensor([52, 12096, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([52, 12096, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50948432 	 1000 	 0.6349554061889648 	 0.5609428882598877 	 0.6260650157928467 	 0.5476064682006836 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:32.024091 test begin: paddle.index_select(Tensor([57, 11109, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([57, 11109, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 51290333 	 1000 	 0.6397099494934082 	 0.5726749897003174 	 0.6308557987213135 	 0.5538456439971924 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:37.931533 test begin: paddle.index_select(Tensor([64, 3060, 260],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([64, 3060, 260],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50918480 	 1000 	 0.21566438674926758 	 0.2397477626800537 	 0.19922184944152832 	 0.21828031539916992 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:41.118126 test begin: paddle.index_select(Tensor([64, 9801, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([64, 9801, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50808464 	 1000 	 0.633507251739502 	 0.5694851875305176 	 0.6245691776275635 	 0.5412592887878418 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:01:45.369294 test begin: paddle.inner(Tensor([20, 1270081],"float64"), Tensor([1270081],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([20, 1270081],"float64"), Tensor([1270081],"float64"), ) 	 26671701 	 1000 	 0.16434931755065918 	 0.16429758071899414 	 0.08388090133666992 	 0.0838005542755127 	 0.36226820945739746 	 0.3635399341583252 	 0.1233212947845459 	 0.12367463111877441 	 
2025-07-30 14:01:48.585606 test begin: paddle.inner(Tensor([20, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([20, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 533433621 	 1000 	 3.0378458499908447 	 3.0337109565734863 	 1.552332878112793 	 1.5502169132232666 	 6.899680137634277 	 6.849858999252319 	 0.2732679843902588 	 0.26816248893737793 	 
2025-07-30 14:02:19.914197 test begin: paddle.inner(Tensor([508033, 50],"float64"), Tensor([50],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([508033, 50],"float64"), Tensor([50],"float64"), ) 	 25401700 	 1000 	 0.16053509712219238 	 0.15837693214416504 	 0.09870481491088867 	 0.13489723205566406 	 0.38432741165161133 	 0.377791166305542 	 0.13084697723388672 	 0.12808728218078613 	 
2025-07-30 14:02:21.497494 test begin: paddle.is_complex(Tensor([1003520, 507],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([1003520, 507],"float32"), ) 	 508784640 	 1000 	 0.0035905838012695312 	 0.0016536712646484375 	 8.821487426757812e-06 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:02:29.651582 test begin: paddle.is_complex(Tensor([5070, 100352],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([5070, 100352],"float32"), ) 	 508784640 	 1000 	 0.00456547737121582 	 0.0021865367889404297 	 1.4781951904296875e-05 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:02:39.439239 test begin: paddle.is_complex(Tensor([62020, 8192],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([62020, 8192],"float32"), ) 	 508067840 	 1000 	 0.0045375823974609375 	 0.0021915435791015625 	 1.1444091796875e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:02:48.172449 test begin: paddle.is_complex(Tensor([81920, 6202],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([81920, 6202],"float32"), ) 	 508067840 	 1000 	 0.004586696624755859 	 0.0017316341400146484 	 7.867813110351562e-06 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:02:56.425306 test begin: paddle.is_complex(Tensor([8860, 57344],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([8860, 57344],"float32"), ) 	 508067840 	 1000 	 0.003528118133544922 	 0.0019087791442871094 	 7.3909759521484375e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:03:04.770150 test begin: paddle.is_empty(Tensor([101606410, 5],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([101606410, 5],"float32"), ) 	 508032050 	 1000 	 0.003455638885498047 	 0.0015399456024169922 	 1.0967254638671875e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:03:13.176216 test begin: paddle.is_empty(Tensor([169344010, 3],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([169344010, 3],"float32"), ) 	 508032030 	 1000 	 0.0034630298614501953 	 0.0015649795532226562 	 1.0013580322265625e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:03:21.338321 test begin: paddle.is_empty(Tensor([20, 25401601],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([20, 25401601],"float32"), ) 	 508032020 	 1000 	 0.0034384727478027344 	 0.0015625953674316406 	 1.1682510375976562e-05 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:03:29.372764 test begin: paddle.is_empty(Tensor([30, 16934401],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([30, 16934401],"float32"), ) 	 508032030 	 1000 	 0.003385782241821289 	 0.0015671253204345703 	 8.344650268554688e-06 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:03:39.164273 test begin: paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), ) 	 508033280 	 1000 	 0.0037212371826171875 	 0.0015461444854736328 	 1.71661376953125e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:03:47.229933 test begin: paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), ) 	 508033280 	 1000 	 0.0035517215728759766 	 0.0015575885772705078 	 1.0013580322265625e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:03:57.442971 test begin: paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), ) 	 508037120 	 1000 	 0.003542184829711914 	 0.0015401840209960938 	 7.152557373046875e-06 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:04:05.383077 test begin: paddle.isclose(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), rtol=1e-05, atol=1e-08, )
[Prof] paddle.isclose 	 paddle.isclose(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), rtol=1e-05, atol=1e-08, ) 	 50803220 	 1000 	 0.3637564182281494 	 3.0821731090545654 	 0.3437540531158447 	 0.24184799194335938 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:09.918643 test begin: paddle.isclose(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), rtol=1e-05, atol=1e-08, )
[Prof] paddle.isclose 	 paddle.isclose(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), rtol=1e-05, atol=1e-08, ) 	 50803220 	 1000 	 0.3637828826904297 	 3.082015037536621 	 0.3512229919433594 	 0.24177002906799316 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:14.440373 test begin: paddle.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), ) 	 50803240 	 1000 	 0.3635990619659424 	 3.082200765609741 	 0.35138583183288574 	 0.2418367862701416 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:18.998796 test begin: paddle.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 0.3638436794281006 	 3.0841293334960938 	 0.35144543647766113 	 0.2437431812286377 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:23.496108 test begin: paddle.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), ) 	 50803230 	 1000 	 0.3637704849243164 	 3.0821590423583984 	 0.3511500358581543 	 0.24187803268432617 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:27.993096 test begin: paddle.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), ) 	 50803224 	 1000 	 0.36367297172546387 	 3.082078218460083 	 0.3512856960296631 	 0.2418067455291748 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:32.534980 test begin: paddle.isfinite(Tensor([1738, 94, 311],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([1738, 94, 311],"float32"), ) 	 50808692 	 1000 	 0.2338104248046875 	 0.7885682582855225 	 0.22001123428344727 	 0.20135807991027832 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:34.531681 test begin: paddle.isfinite(Tensor([28462, 17, 5, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([28462, 17, 5, 6, 7],"float16"), ) 	 101609340 	 1000 	 0.39552855491638184 	 0.9799928665161133 	 0.38836097717285156 	 0.2484118938446045 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:40.428462 test begin: paddle.isfinite(Tensor([4, 280, 376, 25, 5],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 376, 25, 5],"float32"), ) 	 52640000 	 1000 	 0.2423865795135498 	 0.8166437149047852 	 0.23376107215881348 	 0.20788788795471191 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:42.334861 test begin: paddle.isfinite(Tensor([4, 280, 376, 41, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 376, 41, 3],"float32"), ) 	 51797760 	 1000 	 0.2390761375427246 	 0.8026056289672852 	 0.22529292106628418 	 0.20498347282409668 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:44.254963 test begin: paddle.isfinite(Tensor([4, 280, 605, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 605, 25, 3],"float32"), ) 	 50820000 	 1000 	 0.2343764305114746 	 0.788654088973999 	 0.22702407836914062 	 0.20138764381408691 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:46.137801 test begin: paddle.isfinite(Tensor([4, 40839, 311],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 40839, 311],"float32"), ) 	 50803716 	 1000 	 0.23408007621765137 	 0.7925982475280762 	 0.22673678398132324 	 0.20091700553894043 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:48.052428 test begin: paddle.isfinite(Tensor([4, 451, 376, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 451, 376, 25, 3],"float32"), ) 	 50872800 	 1000 	 0.234879732131958 	 0.7881875038146973 	 0.2211902141571045 	 0.20128130912780762 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:49.908403 test begin: paddle.isfinite(Tensor([4, 94, 135115],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 94, 135115],"float32"), ) 	 50803240 	 1000 	 0.23447585105895996 	 0.791684627532959 	 0.22045421600341797 	 0.20108270645141602 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:51.760461 test begin: paddle.isfinite(Tensor([7, 280, 376, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([7, 280, 376, 25, 3],"float32"), ) 	 55272000 	 1000 	 0.2552051544189453 	 0.8562219142913818 	 0.24150753021240234 	 0.21807026863098145 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:53.795938 test begin: paddle.isfinite(Tensor([8, 17, 17789, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 17789, 6, 7],"float16"), ) 	 101610768 	 1000 	 0.3953883647918701 	 0.970557451248169 	 0.381655216217041 	 0.2479548454284668 	 None 	 None 	 None 	 None 	 
2025-07-30 14:04:57.021739 test begin: paddle.isfinite(Tensor([8, 17, 5, 21346, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 5, 21346, 7],"float16"), ) 	 101606960 	 1000 	 0.39552927017211914 	 0.9712100028991699 	 0.38178324699401855 	 0.24816107749938965 	 None 	 None 	 None 	 None 	 
2025-07-30 14:05:00.290198 test begin: paddle.isfinite(Tensor([8, 17, 5, 6, 24904],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 5, 6, 24904],"float16"), ) 	 101608320 	 1000 	 0.3954579830169678 	 0.9762153625488281 	 0.38174009323120117 	 0.24849939346313477 	 None 	 None 	 None 	 None 	 
2025-07-30 14:05:06.748894 test begin: paddle.isfinite(Tensor([8, 60481, 5, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 60481, 5, 6, 7],"float16"), ) 	 101608080 	 1000 	 0.3911569118499756 	 0.9717249870300293 	 0.3773460388183594 	 0.24822115898132324 	 None 	 None 	 None 	 None 	 
2025-07-30 14:05:10.096436 test begin: paddle.isin(Tensor([396901, 64],"float64"), Tensor([4, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([396901, 64],"float64"), Tensor([4, 256],"float64"), False, False, ) 	 25402688 	 1000 	 2.7236790657043457 	 21.32585644721985 	 0.0024869441986083984 	 0.0008747577667236328 	 None 	 None 	 None 	 None 	 
2025-07-30 14:05:34.752285 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, False, ) 	 50804288 	 1000 	 4.4522716999053955 	 25.291642904281616 	 0.004235267639160156 	 0.002033233642578125 	 None 	 None 	 None 	 None 	 
2025-07-30 14:06:06.500757 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, True, ) 	 50804288 	 1000 	 4.538852691650391 	 25.302108764648438 	 0.004237174987792969 	 0.0020096302032470703 	 None 	 None 	 None 	 None 	 
2025-07-30 14:06:38.346897 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, False, ) 	 254016320 	 1000 	 83.96331024169922 	 45.25783681869507 	 0.052503108978271484 	 0.002554655075073242 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:51.928543 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, True, ) 	 254016320 	 1000 	 84.10136699676514 	 45.194698095321655 	 0.05253434181213379 	 0.002577543258666992 	 None 	 None 	 None 	 None 	 
2025-07-30 14:11:07.696926 test begin: paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 256],"float64"), False, False, ) 	 25402632 	 1000 	 2.7245137691497803 	 21.307958841323853 	 0.0024950504302978516 	 0.0008723735809326172 	 None 	 None 	 None 	 None 	 
2025-07-30 14:11:34.034850 test begin: paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 3175201],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 3175201],"float64"), False, False, ) 	 38102412 	 1000 	 27.90197515487671 	 27.216482162475586 	 0.01774001121520996 	 0.0009520053863525391 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:30.891822 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, False, ) 	 50804232 	 1000 	 4.447729825973511 	 25.279091358184814 	 0.004222869873046875 	 0.0020322799682617188 	 None 	 None 	 None 	 None 	 
2025-07-30 14:13:02.735811 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, True, ) 	 50804232 	 1000 	 4.52959680557251 	 25.277994394302368 	 0.004274129867553711 	 0.0020356178283691406 	 None 	 None 	 None 	 None 	 
2025-07-30 14:13:33.426799 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, False, ) 	 76204812 	 1000 	 50.19625234603882 	 29.965867519378662 	 0.03630185127258301 	 0.0022089481353759766 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:56.637841 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, True, ) 	 76204812 	 1000 	 44.962975025177 	 29.969140768051147 	 0.03637576103210449 	 0.0022161006927490234 	 None 	 None 	 None 	 None 	 
2025-07-30 14:16:12.962718 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, False, ) 	 50803968 	 1000 	 16.521636486053467 	 8.312755823135376 	 6.532669067382812e-05 	 0.0002770423889160156 	 None 	 None 	 None 	 None 	 
2025-07-30 14:16:39.724647 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, True, ) 	 50803968 	 1000 	 16.52187466621399 	 8.299248933792114 	 5.9604644775390625e-05 	 0.00027298927307128906 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:07.392726 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, False, ) 	 50803716 	 1000 	 16.523505926132202 	 8.302764415740967 	 6.604194641113281e-05 	 0.00028228759765625 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:33.161954 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, True, ) 	 50803716 	 1000 	 19.562400102615356 	 8.306056261062622 	 6.246566772460938e-05 	 0.00028014183044433594 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:02.042196 test begin: paddle.isin(Tensor([8, 64],"float64"), Tensor([4, 6350401],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float64"), Tensor([4, 6350401],"float64"), False, False, ) 	 25402116 	 1000 	 13.51575231552124 	 12.01225733757019 	 5.936622619628906e-05 	 0.00026345252990722656 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:28.204677 test begin: paddle.isin(Tensor([8, 64],"float64"), Tensor([99226, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float64"), Tensor([99226, 256],"float64"), False, False, ) 	 25402368 	 1000 	 13.766147136688232 	 12.016812086105347 	 5.841255187988281e-05 	 0.0002524852752685547 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:54.624999 test begin: paddle.isinf(Tensor([14, 226801, 16],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 226801, 16],"float32"), ) 	 50803424 	 1000 	 0.23417234420776367 	 0.48548460006713867 	 0.22667932510375977 	 0.24806475639343262 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:56.162256 test begin: paddle.isinf(Tensor([14, 36655, 99],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 36655, 99],"float32"), ) 	 50803830 	 1000 	 0.2328474521636963 	 0.48555421829223633 	 0.22555160522460938 	 0.24810290336608887 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:57.696523 test begin: paddle.isinf(Tensor([14, 64, 56701],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 64, 56701],"float32"), ) 	 50804096 	 1000 	 0.233597993850708 	 0.485581636428833 	 0.22616243362426758 	 0.24810433387756348 	 None 	 None 	 None 	 None 	 
2025-07-30 14:18:59.265930 test begin: paddle.isinf(Tensor([14, 7, 518401],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 7, 518401],"float32"), ) 	 50803298 	 1000 	 0.2334766387939453 	 0.48554205894470215 	 0.22603654861450195 	 0.24808907508850098 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:00.823557 test begin: paddle.isinf(Tensor([28462, 17, 5, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([28462, 17, 5, 6, 7],"float16"), ) 	 101609340 	 1000 	 0.3898441791534424 	 0.5205650329589844 	 0.3762044906616211 	 0.265977144241333 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:03.665831 test begin: paddle.isinf(Tensor([49613, 64, 16],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([49613, 64, 16],"float32"), ) 	 50803712 	 1000 	 0.23395061492919922 	 0.48554229736328125 	 0.22636961936950684 	 0.2481064796447754 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:05.197892 test begin: paddle.isinf(Tensor([73310, 7, 99],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([73310, 7, 99],"float32"), ) 	 50803830 	 1000 	 0.23282408714294434 	 0.48552727699279785 	 0.2253401279449463 	 0.24807333946228027 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:06.731660 test begin: paddle.isinf(Tensor([8, 17, 17789, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 17789, 6, 7],"float16"), ) 	 101610768 	 1000 	 0.38942623138427734 	 0.5204999446868896 	 0.3819150924682617 	 0.26596689224243164 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:09.535270 test begin: paddle.isinf(Tensor([8, 17, 5, 21346, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 5, 21346, 7],"float16"), ) 	 101606960 	 1000 	 0.39034271240234375 	 0.5204429626464844 	 0.3828616142272949 	 0.265913724899292 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:14.266852 test begin: paddle.isinf(Tensor([8, 17, 5, 6, 24904],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 5, 6, 24904],"float16"), ) 	 101608320 	 1000 	 0.38988780975341797 	 0.7618021965026855 	 0.37616848945617676 	 0.26607370376586914 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:18.049673 test begin: paddle.isinf(Tensor([8, 60481, 5, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 60481, 5, 6, 7],"float16"), ) 	 101608080 	 1000 	 0.3859522342681885 	 0.5203869342803955 	 0.3784036636352539 	 0.26591038703918457 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:20.861187 test begin: paddle.isnan(Tensor([10445, 4864],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([10445, 4864],"float32"), ) 	 50804480 	 1000 	 0.23419857025146484 	 0.1969294548034668 	 0.22714519500732422 	 0.17490649223327637 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:22.104328 test begin: paddle.isnan(Tensor([16, 64, 320, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([16, 64, 320, 320],"float16"), ) 	 104857600 	 1000 	 0.40549135208129883 	 0.2319033145904541 	 0.39846277236938477 	 0.22111177444458008 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:24.641284 test begin: paddle.isnan(Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 125, 320, 320],"float32"), ) 	 51200000 	 1000 	 0.23641657829284668 	 0.1875152587890625 	 0.22945809364318848 	 0.17632699012756348 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:25.891368 test begin: paddle.isnan(Tensor([4, 249, 320, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 249, 320, 320],"float16"), ) 	 101990400 	 1000 	 0.39403629302978516 	 0.22582125663757324 	 0.386991024017334 	 0.21483969688415527 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:28.368945 test begin: paddle.isnan(Tensor([4, 64, 1241, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 1241, 320],"float16"), ) 	 101662720 	 1000 	 0.39198851585388184 	 0.22500872611999512 	 0.3847928047180176 	 0.2137601375579834 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:30.866600 test begin: paddle.isnan(Tensor([4, 64, 320, 1241],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 320, 1241],"float16"), ) 	 101662720 	 1000 	 0.392000675201416 	 0.22504162788391113 	 0.38492703437805176 	 0.2133653163909912 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:33.333822 test begin: paddle.isnan(Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 320, 621],"float32"), ) 	 50872320 	 1000 	 0.2345736026763916 	 0.18962597846984863 	 0.22620439529418945 	 0.17508769035339355 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:34.613065 test begin: paddle.isnan(Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 621, 320],"float32"), ) 	 50872320 	 1000 	 0.23454880714416504 	 0.6553926467895508 	 0.2275381088256836 	 0.17516112327575684 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:39.571344 test begin: paddle.isnan(Tensor([4864, 10445],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4864, 10445],"float32"), ) 	 50804480 	 1000 	 0.23421287536621094 	 0.19403386116027832 	 0.22717857360839844 	 0.17474102973937988 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:40.819735 test begin: paddle.isnan(Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([8, 64, 320, 320],"float32"), ) 	 52428800 	 1000 	 0.2417910099029541 	 0.1979527473449707 	 0.23480439186096191 	 0.18086504936218262 	 None 	 None 	 None 	 None 	 
2025-07-30 14:19:42.109075 test begin: paddle.isneginf(Tensor([11, 17, 2716],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 17, 2716],"int32"), ) 	 507892 	 1000 	 20.056787729263306 	 0.010844230651855469 	 5.602836608886719e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:20:02.215441 test begin: paddle.isneginf(Tensor([11, 17, 5433],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 17, 5433],"int16"), ) 	 1015971 	 1000 	 40.15557312965393 	 0.011381149291992188 	 6.008148193359375e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:20:42.435669 test begin: paddle.isneginf(Tensor([11, 4618, 10],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 4618, 10],"int32"), ) 	 507980 	 1000 	 19.99547028541565 	 0.010896444320678711 	 5.340576171875e-05 	 3.266334533691406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:21:02.469909 test begin: paddle.isneginf(Tensor([11, 46184],"float32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 46184],"float32"), ) 	 508024 	 1000 	 20.19347071647644 	 0.010051727294921875 	 6.127357482910156e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:21:22.703960 test begin: paddle.isneginf(Tensor([11, 9236, 10],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 9236, 10],"int16"), ) 	 1015960 	 1000 	 40.727343797683716 	 0.011345148086547852 	 5.602836608886719e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:22:03.493674 test begin: paddle.isneginf(Tensor([2988, 17, 10],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([2988, 17, 10],"int32"), ) 	 507960 	 1000 	 20.70566153526306 	 0.010872602462768555 	 5.817413330078125e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:22:24.238078 test begin: paddle.isneginf(Tensor([29884, 17],"float32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([29884, 17],"float32"), ) 	 508028 	 1000 	 20.2964608669281 	 0.009983301162719727 	 5.269050598144531e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:22:44.574060 test begin: paddle.isneginf(Tensor([5976, 17, 10],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([5976, 17, 10],"int16"), ) 	 1015920 	 1000 	 40.85357165336609 	 0.011351346969604492 	 5.7697296142578125e-05 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:23:25.493157 test begin: paddle.isposinf(Tensor([11, 17, 2716],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 17, 2716],"int32"), ) 	 507892 	 1000 	 20.634048223495483 	 0.010889530181884766 	 5.1975250244140625e-05 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:23:46.169330 test begin: paddle.isposinf(Tensor([11, 17, 5433],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 17, 5433],"int16"), ) 	 1015971 	 1000 	 40.47778272628784 	 0.011338472366333008 	 5.650520324707031e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:24:26.712650 test begin: paddle.isposinf(Tensor([11, 4618, 10],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 4618, 10],"int32"), ) 	 507980 	 1000 	 20.399837493896484 	 0.011082172393798828 	 5.5789947509765625e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:24:47.151774 test begin: paddle.isposinf(Tensor([11, 46184],"float32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 46184],"float32"), ) 	 508024 	 1000 	 20.271027326583862 	 0.009955644607543945 	 5.6743621826171875e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:25:07.462680 test begin: paddle.isposinf(Tensor([11, 9236, 10],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 9236, 10],"int16"), ) 	 1015960 	 1000 	 40.35171627998352 	 0.4701087474822998 	 5.0067901611328125e-05 	 6.628036499023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:25:49.103432 test begin: paddle.isposinf(Tensor([2988, 17, 10],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([2988, 17, 10],"int32"), ) 	 507960 	 1000 	 20.327592849731445 	 0.010875940322875977 	 6.246566772460938e-05 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:26:09.472075 test begin: paddle.isposinf(Tensor([29884, 17],"float32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([29884, 17],"float32"), ) 	 508028 	 1000 	 20.134405851364136 	 0.010296821594238281 	 5.888938903808594e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:26:29.647980 test begin: paddle.isposinf(Tensor([5976, 17, 10],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([5976, 17, 10],"int16"), ) 	 1015920 	 1000 	 40.05519652366638 	 0.01123666763305664 	 5.5789947509765625e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:27:09.783111 test begin: paddle.isreal(Tensor([15876010, 32],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.38547468185424805 	 0.33050012588500977 	 0.3689701557159424 	 0.31906867027282715 	 None 	 None 	 None 	 None 	 
2025-07-30 14:27:17.535010 test begin: paddle.isreal(Tensor([31752010, 32],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"bfloat16"), ) 	 1016064320 	 1000 	 0.7690370082855225 	 0.6581437587738037 	 0.7527341842651367 	 0.6450073719024658 	 None 	 None 	 None 	 None 	 
2025-07-30 14:27:37.348166 test begin: paddle.isreal(Tensor([31752010, 32],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"float16"), ) 	 1016064320 	 1000 	 0.7691044807434082 	 1.5607919692993164 	 0.7525627613067627 	 0.644752025604248 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:02.260962 test begin: paddle.isreal(Tensor([640, 1587601],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"bfloat16"), ) 	 1016064640 	 1000 	 0.76918625831604 	 0.6580030918121338 	 0.7367959022521973 	 0.6395847797393799 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:21.643341 test begin: paddle.isreal(Tensor([640, 1587601],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"float16"), ) 	 1016064640 	 1000 	 0.7685894966125488 	 0.6620080471038818 	 0.7521817684173584 	 0.645700216293335 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:41.933351 test begin: paddle.isreal(Tensor([640, 793801],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 793801],"bool"), ) 	 508032640 	 1000 	 0.38629651069641113 	 0.3305041790008545 	 0.36966419219970703 	 0.31888532638549805 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:49.568744 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([22336, 5, 4, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([22336, 5, 4, 3, 2],"float32"), ) 	 2680420 	 1000 	 9.750046014785767 	 1.3669764995574951 	 9.965896606445312e-05 	 1.3501744270324707 	 14.999629020690918 	 5.912718296051025 	 6.842613220214844e-05 	 1.2091975212097168 	 
2025-07-30 14:29:26.150978 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 22336, 4, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 22336, 4, 3, 2],"float32"), ) 	 2680420 	 1000 	 9.754976987838745 	 1.3679821491241455 	 0.00010609626770019531 	 1.3486804962158203 	 14.989632844924927 	 5.914051532745361 	 7.367134094238281e-05 	 1.2091927528381348 	 
2025-07-30 14:30:02.729495 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 13868, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 13868, 3, 2],"float32"), ) 	 2080300 	 1000 	 7.623546361923218 	 1.0616660118103027 	 0.00010657310485839844 	 1.0378234386444092 	 11.676537036895752 	 4.856444358825684 	 7.581710815429688e-05 	 0.9929821491241455 	 
2025-07-30 14:30:31.513182 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 15401, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 15401, 2],"float32"), ) 	 3080300 	 1000 	 11.146288871765137 	 1.5730037689208984 	 9.965896606445312e-05 	 1.5564556121826172 	 16.96385884284973 	 6.5172717571258545 	 7.367134094238281e-05 	 1.3332574367523193 	 
2025-07-30 14:31:13.958918 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 8934],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 8934],"float32"), ) 	 2680300 	 1000 	 9.71108078956604 	 1.3732244968414307 	 0.00011277198791503906 	 1.3502280712127686 	 17.2856183052063 	 4.998202085494995 	 7.224082946777344e-05 	 1.0211851596832275 	 
2025-07-30 14:31:51.853646 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, ) 	 50808000 	 1000 	 4.018911838531494 	 4.143483877182007 	 1.0248053073883057 	 4.1240622997283936 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:01.147623 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, keepdim=True, ) 	 50808000 	 1000 	 4.021105766296387 	 4.144087076187134 	 1.025352954864502 	 4.126608848571777 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:10.425897 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=2, ) 	 50808000 	 1000 	 3.0954504013061523 	 2.495737075805664 	 3.085922956466675 	 2.476945638656616 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:17.067395 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, ) 	 50804400 	 1000 	 4.458076000213623 	 10.932177305221558 	 1.1363420486450195 	 10.91348385810852 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:34.186467 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, keepdim=True, ) 	 50804400 	 1000 	 4.466312408447266 	 11.09669542312622 	 1.138620376586914 	 11.079632043838501 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:51.521467 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=2, ) 	 50804400 	 1000 	 5.236455202102661 	 5.1520092487335205 	 5.223441123962402 	 5.1326985359191895 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:03.289107 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, ) 	 50808000 	 1000 	 3.988551139831543 	 4.149207592010498 	 1.0170629024505615 	 4.128424167633057 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:12.485846 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, keepdim=True, ) 	 50808000 	 1000 	 3.989549160003662 	 4.149674892425537 	 1.0172531604766846 	 4.132436275482178 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:21.674457 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=2, ) 	 50808000 	 1000 	 5.23274040222168 	 5.1487743854522705 	 5.223072528839111 	 5.129597425460815 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:33.378619 test begin: paddle.lcm(Tensor([1],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([1],"int64"), Tensor([25401601],"int64"), ) 	 25401602 	 1000 	 92.32904553413391 	 5.7552571296691895 	 0.002256631851196289 	 0.0009100437164306641 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:35:12.489385 test begin: paddle.lcm(Tensor([25401601],"int64"), Tensor([1],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([25401601],"int64"), Tensor([1],"int64"), ) 	 25401602 	 1000 	 73.6750214099884 	 5.620162487030029 	 0.002270221710205078 	 0.0009176731109619141 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:36:32.750808 test begin: paddle.lcm(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 106.49892711639404 	 5.869038343429565 	 0.002404451370239258 	 0.0009157657623291016 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:38:26.548256 test begin: paddle.lcm(Tensor([50803201],"int32"), Tensor([1],"int32"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([50803201],"int32"), Tensor([1],"int32"), ) 	 50803202 	 1000 	 81.54658818244934 	 7.971240997314453 	 0.0023195743560791016 	 0.0013027191162109375 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:39:57.431477 test begin: paddle.ldexp(Tensor([25401601],"float64"), Tensor([25401601],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([25401601],"float64"), Tensor([25401601],"int32"), ) 	 50803202 	 1000 	 1.2816410064697266 	 1.0863888263702393 	 0.3278367519378662 	 0.3698887825012207 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:41:26.109106 test begin: paddle.ldexp(Tensor([25401601],"int64"), Tensor([25401601],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([25401601],"int64"), Tensor([25401601],"int32"), ) 	 50803202 	 1000 	 0.8255395889282227 	 0.6440629959106445 	 0.16881823539733887 	 0.2187654972076416 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:42:00.617762 test begin: paddle.ldexp(Tensor([50803201],"float64"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"float64"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 2.5535788536071777 	 2.1535818576812744 	 0.6531901359558105 	 0.7342662811279297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:44:57.768374 test begin: paddle.ldexp(Tensor([50803201],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"int32"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.4716801643371582 	 1.1328840255737305 	 0.3010733127593994 	 0.386293888092041 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:05.953744 test begin: paddle.ldexp(Tensor([50803201],"int64"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"int64"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.6291403770446777 	 1.276412010192871 	 0.3332188129425049 	 0.43523120880126953 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:47:14.887334 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 604801],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 604801],"float32"), 0.36, ) 	 50803285 	 1000 	 0.29866838455200195 	 0.3024623394012451 	 0.15255308151245117 	 0.28861236572265625 	 0.6294147968292236 	 0.748990535736084 	 0.21412038803100586 	 0.1910991668701172 	 
2025-07-30 14:47:18.509740 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 604801, 28],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 604801, 28],"float32"), 0.36, ) 	 50803285 	 1000 	 0.29862189292907715 	 0.3044779300689697 	 0.15256118774414062 	 0.2887153625488281 	 0.6293706893920898 	 0.7490551471710205 	 0.21410655975341797 	 0.19112229347229004 	 
2025-07-30 14:47:22.187938 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([64801, 28, 28],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([64801, 28, 28],"float32"), 0.36, ) 	 50803985 	 1000 	 0.29878807067871094 	 0.3024866580963135 	 0.15263128280639648 	 0.28879475593566895 	 0.6319317817687988 	 0.7490837574005127 	 0.21495556831359863 	 0.19117188453674316 	 
2025-07-30 14:47:25.810013 test begin: paddle.lerp(Tensor([1, 1814401, 28],"float32"), Tensor([3, 1814401, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1814401, 28],"float32"), Tensor([3, 1814401, 28],"float32"), 1.0, ) 	 203212912 	 1000 	 1.3398475646972656 	 1.4070050716400146 	 0.6845998764038086 	 1.3927133083343506 	 2.2031822204589844 	 2.3540804386138916 	 1.1257424354553223 	 0.8017799854278564 	 
2025-07-30 14:47:40.333777 test begin: paddle.lerp(Tensor([1, 28, 1814401],"float32"), Tensor([3, 28, 1814401],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 28, 1814401],"float32"), Tensor([3, 28, 1814401],"float32"), 1.0, ) 	 203212912 	 1000 	 1.3400599956512451 	 1.3259544372558594 	 0.6847054958343506 	 1.30472993850708 	 2.2032783031463623 	 2.3538413047790527 	 1.1257274150848389 	 0.8017361164093018 	 
2025-07-30 14:47:53.375880 test begin: paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, ) 	 50804768 	 1000 	 0.29825758934020996 	 0.30461716651916504 	 0.15240025520324707 	 0.29078125953674316 	 0.7929122447967529 	 0.7817695140838623 	 0.2698516845703125 	 0.1995394229888916 	 
2025-07-30 14:47:57.236387 test begin: paddle.lerp(Tensor([3, 28, 604801],"float32"), Tensor([3, 28, 604801],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([3, 28, 604801],"float32"), Tensor([3, 28, 604801],"float32"), 1.2, ) 	 101606568 	 1000 	 0.4522266387939453 	 0.8981034755706787 	 0.23104643821716309 	 0.4340684413909912 	 0.4727606773376465 	 0.5954077243804932 	 0.41125059127807617 	 0.30417680740356445 	 
2025-07-30 14:48:04.703429 test begin: paddle.lerp(Tensor([3, 604801, 28],"float32"), Tensor([3, 604801, 28],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([3, 604801, 28],"float32"), Tensor([3, 604801, 28],"float32"), 1.2, ) 	 101606568 	 1000 	 0.4522867202758789 	 0.44689226150512695 	 0.23107266426086426 	 0.43415188789367676 	 0.4727442264556885 	 0.5953989028930664 	 0.4111154079437256 	 0.3042025566101074 	 
2025-07-30 14:48:09.188182 test begin: paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, ) 	 101607968 	 1000 	 0.4524838924407959 	 0.44689249992370605 	 0.23119425773620605 	 0.43400096893310547 	 0.47223782539367676 	 0.5955410003662109 	 0.40958666801452637 	 0.3041718006134033 	 
2025-07-30 14:48:13.489242 test begin: paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.2, ) 	 101607968 	 1000 	 0.45247769355773926 	 0.446927547454834 	 0.2312452793121338 	 0.4342942237854004 	 0.4722435474395752 	 0.5953857898712158 	 0.4107832908630371 	 0.304166316986084 	 
2025-07-30 14:48:17.972984 test begin: paddle.less(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19074416160583496 	 0.24561476707458496 	 0.18086791038513184 	 0.23157620429992676 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:19.213838 test begin: paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18855786323547363 	 0.24434900283813477 	 0.178847074508667 	 0.2313368320465088 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:20.467384 test begin: paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3265409469604492 	 0.32781386375427246 	 0.31760215759277344 	 0.3166782855987549 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:22.763792 test begin: paddle.less(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.3265113830566406 	 0.3277761936187744 	 0.31749677658081055 	 0.31652283668518066 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:25.089890 test begin: paddle.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.32657670974731445 	 0.32784152030944824 	 0.3103916645050049 	 0.31064653396606445 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:27.434134 test begin: paddle.less(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.32654285430908203 	 0.3278472423553467 	 0.3175206184387207 	 0.31312084197998047 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:29.766973 test begin: paddle.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), ) 	 101607424 	 1000 	 0.3262460231781006 	 0.32778429985046387 	 0.3172879219055176 	 0.3166651725769043 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:32.093263 test begin: paddle.less(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.3265073299407959 	 0.33127760887145996 	 0.3176095485687256 	 0.31667542457580566 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:34.417832 test begin: paddle.less_equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19072508811950684 	 0.26006174087524414 	 0.18128275871276855 	 0.23139071464538574 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:39.956909 test begin: paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18854999542236328 	 0.2503652572631836 	 0.17918992042541504 	 0.2319798469543457 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:41.290417 test begin: paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3265397548675537 	 0.3278803825378418 	 0.3180727958679199 	 0.3164510726928711 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:43.550226 test begin: paddle.less_equal(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.32653307914733887 	 0.32778334617614746 	 0.31786322593688965 	 0.31650376319885254 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:45.872426 test begin: paddle.less_equal(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), )
W0730 14:48:49.351681 32844 dygraph_functions.cc:90806] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), ) 	 203212812 	 1000 	 1.1282033920288086 	 0.719731330871582 	 0.576446533203125 	 0.7082827091217041 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:51.375442 test begin: paddle.less_equal(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.32654643058776855 	 0.3279132843017578 	 0.31075000762939453 	 0.31070590019226074 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:53.716447 test begin: paddle.less_equal(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), ) 	 203212816 	 1000 	 1.128159523010254 	 0.7197318077087402 	 0.5764775276184082 	 0.7018194198608398 	 None 	 None 	 None 	 None 	 
2025-07-30 14:48:59.150977 test begin: paddle.less_equal(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 0.5694961547851562 	 0.36367082595825195 	 0.2910037040710449 	 0.3459970951080322 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:01.858138 test begin: paddle.less_equal(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), ) 	 203212824 	 1000 	 1.128124713897705 	 1.1836371421813965 	 0.5764315128326416 	 0.7054769992828369 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:10.989998 test begin: paddle.less_equal(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 0.569535493850708 	 0.36365270614624023 	 0.29101037979125977 	 0.35216450691223145 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:13.674523 test begin: paddle.less_equal(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 0.569502592086792 	 0.36365437507629395 	 0.2909998893737793 	 0.352189302444458 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:16.391775 test begin: paddle.less_than(Tensor([1, 128, 198451],"int64"), Tensor([1, 128, 198451],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 198451],"int64"), Tensor([1, 128, 198451],"int64"), ) 	 50803456 	 1000 	 0.30997300148010254 	 0.3132295608520508 	 0.300717830657959 	 0.30196213722229004 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:17.911995 test begin: paddle.less_than(Tensor([1, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), ) 	 50855936 	 1000 	 0.1915440559387207 	 0.2512326240539551 	 0.18169331550598145 	 0.23181438446044922 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:19.196982 test begin: paddle.less_than(Tensor([1, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), ) 	 25460736 	 1000 	 0.20666766166687012 	 0.18170809745788574 	 0.1970658302307129 	 0.16843366622924805 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:20.008669 test begin: paddle.less_than(Tensor([1, 128, 396901],"float32"), Tensor([1, 128, 396901],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 396901],"float32"), Tensor([1, 128, 396901],"float32"), ) 	 101606656 	 1000 	 0.3267533779144287 	 0.32779765129089355 	 0.317889928817749 	 0.3165111541748047 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:22.334668 test begin: paddle.less_than(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 256],"float32"), ) 	 101606912 	 1000 	 0.3265566825866699 	 0.3278079032897949 	 0.31749939918518066 	 0.31652116775512695 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:24.642935 test begin: paddle.less_than(Tensor([1, 99226, 256],"int64"), Tensor([1, 99226, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 99226, 256],"int64"), Tensor([1, 99226, 256],"int64"), ) 	 50803712 	 1000 	 0.3101496696472168 	 0.3131835460662842 	 0.3012557029724121 	 0.30188655853271484 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:26.087020 test begin: paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1, 128, 256],"float32"), ) 	 50855936 	 1000 	 0.18963265419006348 	 0.24456334114074707 	 0.17973971366882324 	 0.23176336288452148 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:27.338154 test begin: paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), ) 	 101646336 	 1000 	 0.32629847526550293 	 0.3279380798339844 	 0.3174002170562744 	 0.3167591094970703 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:29.618668 test begin: paddle.less_than(Tensor([3101, 1, 128, 128],"float32"), Tensor([3101, 1, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([3101, 1, 128, 128],"float32"), Tensor([3101, 1, 128, 128],"float32"), ) 	 101613568 	 1000 	 0.3261899948120117 	 0.32782745361328125 	 0.31729817390441895 	 0.31674790382385254 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:31.951319 test begin: paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([1, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([1, 128, 256],"int64"), ) 	 25460736 	 1000 	 0.17602944374084473 	 0.18161225318908691 	 0.16637277603149414 	 0.1694011688232422 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:32.722775 test begin: paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), ) 	 50855936 	 1000 	 0.31059741973876953 	 0.3135075569152832 	 0.3016533851623535 	 0.3020448684692383 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:34.205513 test begin: paddle.less_than(Tensor([8, 1, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), ) 	 50987008 	 1000 	 0.19402575492858887 	 1.2689785957336426 	 0.1843709945678711 	 0.24713778495788574 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:39.807076 test begin: paddle.less_than(Tensor([8, 1, 128, 49613],"float32"), Tensor([8, 1, 128, 49613],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 128, 49613],"float32"), Tensor([8, 1, 128, 49613],"float32"), ) 	 101607424 	 1000 	 0.32618093490600586 	 0.32785940170288086 	 0.31702089309692383 	 0.31671738624572754 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:42.094874 test begin: paddle.less_than(Tensor([8, 1, 49613, 128],"float32"), Tensor([8, 1, 49613, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 49613, 128],"float32"), Tensor([8, 1, 49613, 128],"float32"), ) 	 101607424 	 1000 	 0.32622694969177246 	 0.32779717445373535 	 0.31713318824768066 	 0.3166651725769043 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:44.392250 test begin: paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 1, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 1, 128, 128],"float32"), ) 	 50987008 	 1000 	 0.19151592254638672 	 0.25954389572143555 	 0.18140769004821777 	 0.24753546714782715 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:45.720531 test begin: paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), ) 	 101711872 	 1000 	 0.32654356956481934 	 0.3281569480895996 	 0.31728029251098633 	 0.31677985191345215 	 None 	 None 	 None 	 None 	 
2025-07-30 14:49:48.037038 test begin: paddle.lgamma(Tensor([10, 10, 10, 25402],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 10, 10, 25402],"float64"), ) 	 25402000 	 1000 	 0.7152976989746094 	 0.692896842956543 	 0.7071630954742432 	 0.679624080657959 	 1.3879384994506836 	 1.5912837982177734 	 1.3346221446990967 	 0.8131296634674072 	 
2025-07-30 14:49:53.489664 test begin: paddle.lgamma(Tensor([10, 10, 127009, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 10, 127009, 2],"float64"), ) 	 25401800 	 1000 	 0.7152247428894043 	 0.6930849552154541 	 0.7068610191345215 	 0.6829414367675781 	 1.3858880996704102 	 1.591907024383545 	 1.3331105709075928 	 0.8134026527404785 	 
2025-07-30 14:49:58.962185 test begin: paddle.lgamma(Tensor([10, 127009, 10, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 127009, 10, 2],"float64"), ) 	 25401800 	 1000 	 0.7151839733123779 	 0.6931045055389404 	 0.7069392204284668 	 0.6828603744506836 	 1.3859353065490723 	 1.5914440155029297 	 1.332742691040039 	 0.8131623268127441 	 
2025-07-30 14:50:04.448365 test begin: paddle.lgamma(Tensor([100, 254017],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([100, 254017],"float64"), ) 	 25401700 	 1000 	 0.7151007652282715 	 0.6928930282592773 	 0.706810712814331 	 0.6826035976409912 	 1.3859755992889404 	 1.5914127826690674 	 1.327812671661377 	 0.8131260871887207 	 
2025-07-30 14:50:09.935672 test begin: paddle.lgamma(Tensor([127009, 10, 10, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([127009, 10, 10, 2],"float64"), ) 	 25401800 	 1000 	 0.7151658535003662 	 0.7022604942321777 	 0.7069687843322754 	 0.6820409297943115 	 1.501293420791626 	 1.5911729335784912 	 1.445016860961914 	 0.8130671977996826 	 
2025-07-30 14:50:17.165065 test begin: paddle.lgamma(Tensor([1948, 26080],"float32"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([1948, 26080],"float32"), ) 	 50803840 	 1000 	 0.39881396293640137 	 0.38077831268310547 	 0.3906245231628418 	 0.37070631980895996 	 0.9645304679870605 	 1.513854742050171 	 0.9119086265563965 	 0.7735006809234619 	 
2025-07-30 14:50:22.063288 test begin: paddle.lgamma(Tensor([254017, 100],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([254017, 100],"float64"), ) 	 25401700 	 1000 	 0.7150673866271973 	 0.6928286552429199 	 0.7068493366241455 	 0.6826708316802979 	 1.386021614074707 	 1.5911219120025635 	 1.3333745002746582 	 0.8130371570587158 	 
2025-07-30 14:50:27.601176 test begin: paddle.lgamma(Tensor([50803201, 1],"float32"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([50803201, 1],"float32"), ) 	 50803201 	 1000 	 0.3998119831085205 	 0.38080859184265137 	 0.3915581703186035 	 0.3705317974090576 	 0.9652566909790039 	 1.5136995315551758 	 0.9125363826751709 	 0.7733907699584961 	 
2025-07-30 14:50:32.513102 test begin: paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-1, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-1, ) 	 25401664 	 1000 	 89.5233097076416 	 3.4938488006591797 	 0.001171112060546875 	 0.05355477333068848 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [4, 396901, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 14:52:28.098435 test begin: paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-math.inf, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-math.inf, ) 	 25401664 	 1000 	 78.10218214988708 	 3.473134994506836 	 0.0011432170867919922 	 0.05328798294067383 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [4, 396901, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 14:54:10.720265 test begin: paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-1, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-1, ) 	 25401632 	 1000 	 78.08983111381531 	 3.4890153408050537 	 0.0012066364288330078 	 0.053525686264038086 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [793801, 2, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 14:55:53.324983 test begin: paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-math.inf, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-math.inf, ) 	 25401632 	 1000 	 78.02532052993774 	 3.4728734493255615 	 0.0011112689971923828 	 0.05328083038330078 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [793801, 2, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 14:57:37.363452 test begin: paddle.linalg.corrcoef(Tensor([4, 12700801],"float32"), )
[Prof] paddle.linalg.corrcoef 	 paddle.linalg.corrcoef(Tensor([4, 12700801],"float32"), ) 	 50803204 	 1000 	 2.8938138484954834 	 2.3349647521972656 	 0.16469478607177734 	 0.002054452896118164 	 4.537266731262207 	 3.4431138038635254 	 0.10407900810241699 	 0.06364989280700684 	 
2025-07-30 14:57:51.526101 test begin: paddle.linalg.corrcoef(Tensor([4, 6350401],"float64"), )
[Prof] paddle.linalg.corrcoef 	 paddle.linalg.corrcoef(Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 1.9663887023925781 	 1.2725727558135986 	 0.11181139945983887 	 0.0009834766387939453 	 4.953158140182495 	 3.3507533073425293 	 0.15352487564086914 	 0.07862567901611328 	 
2025-07-30 14:58:04.645916 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([50803201],"int32"), )
W0730 14:58:05.193212 36566 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([50803201],"int32"), ) 	 50803401 	 1000 	 0.5409345626831055 	 0.3479881286621094 	 1.71661376953125e-05 	 7.796287536621094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:05.545015 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([25401601],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([25401601],"float64"), ) 	 25401811 	 1000 	 0.7973716259002686 	 0.40332698822021484 	 1.7881393432617188e-05 	 7.534027099609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:07.222412 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([10],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([10],"float64"), ) 	 25401811 	 1000 	 1.0033388137817383 	 0.5409431457519531 	 2.1219253540039062e-05 	 7.724761962890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:09.388877 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([50803201],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([50803201],"int32"), aweights=None, ) 	 50803401 	 1000 	 0.6188755035400391 	 0.3343014717102051 	 1.7404556274414062e-05 	 7.700920104980469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:10.717446 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([10],"int32"), )
W0730 14:58:13.809093 36585 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([10],"int32"), ) 	 25401630 	 1000 	 2.1369788646698 	 1.7173237800598145 	 0.0016515254974365234 	 0.0009186267852783203 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:15.606423 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([1270081],"int32"), )
W0730 14:58:18.690008 36599 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([1270081],"int32"), ) 	 26671701 	 1000 	 2.144747018814087 	 1.678412914276123 	 0.0016543865203857422 	 0.0009250640869140625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:20.473659 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int32"), aweights=None, ) 	 25401630 	 1000 	 2.256646156311035 	 1.6720693111419678 	 0.0016777515411376953 	 0.0009162425994873047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:29.128926 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([10],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([10],"float64"), ) 	 25401640 	 1000 	 2.4532575607299805 	 1.7719383239746094 	 0.00165557861328125 	 0.0009200572967529297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:40.253674 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int32"), aweights=None, ) 	 26671701 	 1000 	 2.262697458267212 	 1.6718595027923584 	 0.0016829967498779297 	 0.0009236335754394531 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:48.977852 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int64"), aweights=Tensor([1270081],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int64"), aweights=Tensor([1270081],"float64"), ) 	 27941782 	 1000 	 2.5316481590270996 	 1.8229155540466309 	 0.0015604496002197266 	 0.0009076595306396484 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:58:58.283932 test begin: paddle.linalg.det(Tensor([12737, 3, 5, 5],"float32"), )
[Prof] paddle.linalg.det 	 paddle.linalg.det(Tensor([12737, 3, 5, 5],"float32"), ) 	 955275 	 1000 	 11.567762613296509 	 0.12662982940673828 	 0.00010824203491210938 	 0.00010156631469726562 	 2.079514741897583 	 0.23510193824768066 	 4.458427429199219e-05 	 7.152557373046875e-05 	 
2025-07-30 14:59:12.357986 test begin: paddle.linalg.det(Tensor([3, 12737, 5, 5],"float32"), )
[Prof] paddle.linalg.det 	 paddle.linalg.det(Tensor([3, 12737, 5, 5],"float32"), ) 	 955275 	 1000 	 11.5398850440979 	 0.12543535232543945 	 0.00011134147644042969 	 7.534027099609375e-05 	 2.0928587913513184 	 0.22805404663085938 	 4.2438507080078125e-05 	 5.936622619628906e-05 	 
2025-07-30 14:59:26.399133 test begin: paddle.linalg.inv(x=Tensor([5, 31752, 4, 4],"float64"), )
[Prof] paddle.linalg.inv 	 paddle.linalg.inv(x=Tensor([5, 31752, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.562693119049072 	 0.36108946800231934 	 0.000118255615234375 	 7.843971252441406e-05 	 5.406140565872192 	 1.9669501781463623 	 0.9218001365661621 	 0.28715038299560547 	 
2025-07-30 14:59:42.241270 test begin: paddle.linalg.inv(x=Tensor([52920, 3, 4, 4],"float64"), )
[Prof] paddle.linalg.inv 	 paddle.linalg.inv(x=Tensor([52920, 3, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.637308835983276 	 0.34159207344055176 	 0.00010991096496582031 	 7.271766662597656e-05 	 4.305424928665161 	 1.9671461582183838 	 0.3363633155822754 	 0.28717732429504395 	 
2025-07-30 14:59:56.606071 test begin: paddle.linalg.lu(Tensor([103, 5, 5, 5],"float64"), )
/usr/local/lib/python3.10/dist-packages/torch/functional.py:2162: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([103, 5, 5, 5],"float64"), ) 	 12875 	 1000 	 12.641901731491089 	 0.039697885513305664 	 0.00010466575622558594 	 4.00543212890625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:00:13.387217 test begin: paddle.linalg.lu(Tensor([106, 5, 5, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([106, 5, 5, 5],"float32"), ) 	 13250 	 1000 	 12.739921808242798 	 0.04254007339477539 	 0.00010466575622558594 	 6.67572021484375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:00:30.377441 test begin: paddle.linalg.lu(Tensor([3, 138, 5, 5],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 138, 5, 5],"float64"), ) 	 10350 	 1000 	 10.218806505203247 	 0.03932929039001465 	 0.00010776519775390625 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:00:44.018203 test begin: paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), ) 	 13275 	 1000 	 12.776903629302979 	 0.04400515556335449 	 0.000110626220703125 	 8.606910705566406e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:01.083339 test begin: paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 12.810537815093994 	 0.0391538143157959 	 0.00010180473327636719 	 4.8160552978515625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:18.155152 test begin: paddle.linalg.lu(Tensor([3, 5, 138, 5],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 138, 5],"float64"), ) 	 10350 	 1000 	 0.47327494621276855 	 0.12070512771606445 	 3.743171691894531e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:19.233991 test begin: paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), ) 	 13275 	 1000 	 0.45089054107666016 	 0.12055754661560059 	 4.410743713378906e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:20.317896 test begin: paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 0.48810577392578125 	 0.13214826583862305 	 4.792213439941406e-05 	 6.270408630371094e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:21.488459 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 138],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 138],"float64"), ) 	 10350 	 1000 	 0.553624153137207 	 0.15710139274597168 	 4.76837158203125e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:22.674881 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), ) 	 13275 	 1000 	 0.5454418659210205 	 0.1578218936920166 	 4.673004150390625e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:23.847739 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 0.5495908260345459 	 0.20203638076782227 	 3.4809112548828125e-05 	 6.008148193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:25.073920 test begin: paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float32"), Tensor([203, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float32"), Tensor([203, 5, 5],"int32"), ) 	 2545200 	 1000 	 8.328467607498169 	 0.10985016822814941 	 7.867813110351562e-05 	 0.013936281204223633 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([203, 5, 5, 5]) and output[0] has a shape of torch.Size([20321, 5, 5, 5]).
2025-07-30 15:01:33.829372 test begin: paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float64"), Tensor([203, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float64"), Tensor([203, 5, 5],"int32"), ) 	 2545200 	 1000 	 8.296159505844116 	 0.14776110649108887 	 9.393692016601562e-05 	 0.018758773803710938 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([203, 5, 5, 5]) and output[0] has a shape of torch.Size([20321, 5, 5, 5]).
2025-07-30 15:01:42.779764 test begin: paddle.linalg.lu_unpack(Tensor([3, 5, 5, 338689],"float64"), Tensor([3, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([3, 5, 5, 338689],"float64"), Tensor([3, 5, 5],"int32"), ) 	 25401750 	 1000 	 0.9288709163665771 	 0.36089396476745605 	 5.14984130859375e-05 	 0.04613637924194336 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:46.615936 test begin: paddle.linalg.lu_unpack(Tensor([3, 5, 5, 677377],"float32"), Tensor([3, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([3, 5, 5, 677377],"float32"), Tensor([3, 5, 5],"int32"), ) 	 50803350 	 1000 	 1.1876099109649658 	 0.4098544120788574 	 5.7220458984375e-05 	 0.051506996154785156 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:01:51.504914 test begin: paddle.linalg.lu_unpack(Tensor([4064, 5, 5, 5],"float32"), Tensor([406, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([4064, 5, 5, 5],"float32"), Tensor([406, 5, 5],"int32"), ) 	 518150 	 1000 	 15.224335193634033 	 0.07789230346679688 	 0.00010800361633300781 	 7.915496826171875e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([406, 5, 5, 5]) and output[0] has a shape of torch.Size([4064, 5, 5, 5]).
2025-07-30 15:02:06.979725 test begin: paddle.linalg.lu_unpack(Tensor([6773, 5, 5, 3],"float32"), Tensor([277, 5, 3],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([6773, 5, 5, 3],"float32"), Tensor([277, 5, 3],"int32"), ) 	 512130 	 1000 	 10.44975757598877 	 0.06755185127258301 	 0.00010848045349121094 	 7.653236389160156e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([277, 5, 5, 5]) and output[0] has a shape of torch.Size([6773, 5, 5, 5]).
2025-07-30 15:02:18.757078 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4233601],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 4233601],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401606 	 1000 	 0.2356877326965332 	 0.18144774436950684 	 0.12040567398071289 	 0.15795612335205078 	 1.2948338985443115 	 1.2558271884918213 	 0.4411201477050781 	 0.32065248489379883 	 
2025-07-30 15:02:23.097314 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 	 25401630 	 1000 	 17.37601089477539 	 17.505279541015625 	 8.606910705566406e-05 	 0.0002510547637939453 	 1.3003456592559814 	 1.702876091003418 	 0.0701451301574707 	 0.2485520839691162 	 
2025-07-30 15:03:01.614744 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 	 25401630 	 1000 	 17.810407638549805 	 17.76672601699829 	 9.179115295410156e-05 	 0.00025153160095214844 	 1.3033649921417236 	 1.703984022140503 	 0.06701993942260742 	 0.2485349178314209 	 
2025-07-30 15:03:40.830596 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3175201, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3175201, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401608 	 1000 	 5.260982513427734 	 0.15903306007385254 	 1.7933063507080078 	 0.08124446868896484 	 1.082186222076416 	 0.9074771404266357 	 0.3686208724975586 	 0.23193955421447754 	 
2025-07-30 15:03:48.779634 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 	 25401640 	 1000 	 17.646599054336548 	 16.19768786430359 	 0.0002493858337402344 	 0.00024580955505371094 	 2.56789493560791 	 1.7637474536895752 	 0.13851022720336914 	 0.25742363929748535 	 
2025-07-30 15:04:29.563569 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 	 25401640 	 1000 	 17.741922616958618 	 16.26938033103943 	 0.0002338886260986328 	 0.0002562999725341797 	 2.5711193084716797 	 1.7647485733032227 	 0.13314509391784668 	 0.25742650032043457 	 
2025-07-30 15:05:08.634703 test begin: paddle.linalg.matrix_norm(x=Tensor([2116801, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2116801, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401612 	 1000 	 5.261413097381592 	 0.15890836715698242 	 1.7947447299957275 	 0.08119082450866699 	 1.0824811458587646 	 0.9074044227600098 	 0.3688180446624756 	 0.2319352626800537 	 
2025-07-30 15:05:16.596836 test begin: paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-10, ) 	 25411584 	 1000 	 7.1670613288879395 	 6.31949257850647 	 0.003201723098754883 	 0.0015141963958740234 	 20.574816703796387 	 6.772526979446411 	 0.01642584800720215 	 0.46102237701416016 	 
2025-07-30 15:05:58.675346 test begin: paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-2, ) 	 25411584 	 1000 	 4.740081787109375 	 5.037153482437134 	 0.0003306865692138672 	 0.0003771781921386719 	 6.185237646102905 	 2.6157331466674805 	 0.002214670181274414 	 0.4453573226928711 	 
2025-07-30 15:06:18.355874 test begin: paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-10, ) 	 25417728 	 1000 	 7.1697163581848145 	 6.270677804946899 	 0.0031964778900146484 	 0.0015385150909423828 	 20.578214406967163 	 6.772456645965576 	 0.016415119171142578 	 0.4611935615539551 	 
2025-07-30 15:07:00.344657 test begin: paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-2, ) 	 25417728 	 1000 	 4.749921560287476 	 5.030580520629883 	 0.0003314018249511719 	 0.000377655029296875 	 6.183450698852539 	 2.617453098297119 	 0.0022161006927490234 	 0.4454953670501709 	 
2025-07-30 15:07:20.081839 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 2005, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 2005, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25407360 	 1000 	 17.44103240966797 	 17.067579984664917 	 0.3435094356536865 	 0.34970831871032715 	 46.44083380699158 	 42.70121192932129 	 0.36502647399902344 	 0.4283421039581299 	 
2025-07-30 15:09:24.988839 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 1719, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 1719, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.453694820404053 	 17.080585479736328 	 0.34376955032348633 	 0.3498382568359375 	 46.54857063293457 	 42.70303654670715 	 0.3640761375427246 	 0.42759013175964355 	 
2025-07-30 15:11:30.089064 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 3151, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 3151, 4, 4],"float64"), n=3, ) 	 25409664 	 1000 	 17.44389057159424 	 17.08307433128357 	 0.3435328006744385 	 0.3498649597167969 	 46.46730279922485 	 42.697168588638306 	 0.3639705181121826 	 0.42737627029418945 	 
2025-07-30 15:13:35.063189 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 287, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 287, 11, 4, 4],"float64"), n=3, ) 	 25458048 	 1000 	 17.460790634155273 	 17.14563512802124 	 0.34505271911621094 	 0.3508570194244385 	 46.58765983581543 	 42.76343059539795 	 0.36449670791625977 	 0.42792510986328125 	 
2025-07-30 15:15:41.050905 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-10, ) 	 25411584 	 1000 	 7.168689966201782 	 6.277338266372681 	 0.003163576126098633 	 0.0015368461608886719 	 20.593044996261597 	 6.7749717235565186 	 0.016405582427978516 	 0.4610140323638916 	 
2025-07-30 15:16:23.064256 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-2, ) 	 25411584 	 1000 	 4.7430760860443115 	 5.042662620544434 	 0.00032973289489746094 	 0.0003688335418701172 	 6.1819915771484375 	 2.618314027786255 	 0.002213716506958008 	 0.44542860984802246 	 
2025-07-30 15:16:44.745505 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-10, ) 	 25417728 	 1000 	 7.17827582359314 	 6.306128025054932 	 0.003197908401489258 	 0.0015103816986083984 	 20.585652828216553 	 6.774086236953735 	 0.01642298698425293 	 0.46114611625671387 	 
2025-07-30 15:17:26.845169 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-2, ) 	 25417728 	 1000 	 4.771961688995361 	 5.096706867218018 	 0.00032520294189453125 	 0.0003616809844970703 	 6.183482885360718 	 2.616358518600464 	 0.002218961715698242 	 0.4454624652862549 	 
2025-07-30 15:17:47.989883 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-10, ) 	 25436160 	 1000 	 7.172786712646484 	 6.294655799865723 	 0.003187417984008789 	 0.001546621322631836 	 20.60961127281189 	 6.787858724594116 	 0.016453027725219727 	 0.46204566955566406 	 
2025-07-30 15:18:30.151482 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-2, ) 	 25436160 	 1000 	 4.770201683044434 	 5.089969158172607 	 0.0003273487091064453 	 0.0003781318664550781 	 6.182523012161255 	 2.6220624446868896 	 0.0022208690643310547 	 0.44625306129455566 	 
2025-07-30 15:18:52.037540 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 573, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 573, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.455955743789673 	 17.08315896987915 	 0.34374427795410156 	 0.34984469413757324 	 46.521546602249146 	 42.820534229278564 	 0.3639047145843506 	 0.42774224281311035 	 
2025-07-30 15:20:57.823199 test begin: paddle.linalg.matrix_power(x=Tensor([3, 573, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 573, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.46768307685852 	 17.094202280044556 	 0.34528493881225586 	 0.3500852584838867 	 46.60283660888672 	 42.73779892921448 	 0.36435675621032715 	 0.4280209541320801 	 
2025-07-30 15:23:02.996812 test begin: paddle.linalg.matrix_power(x=Tensor([860, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([860, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25428480 	 1000 	 17.462280988693237 	 17.129494190216064 	 0.3507723808288574 	 0.3507969379425049 	 46.679012298583984 	 42.841843128204346 	 0.37058019638061523 	 0.4288208484649658 	 
2025-07-30 15:25:08.427621 test begin: paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.004319667816162109 	 0.0036330223083496094 	 1.1444091796875e-05 	 1.811981201171875e-05 	 0.04139113426208496 	 0.05766129493713379 	 1.8358230590820312e-05 	 4.291534423828125e-05 	 combined
2025-07-30 15:25:24.858946 test begin: paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.0042781829833984375 	 0.006939888000488281 	 1.1444091796875e-05 	 2.193450927734375e-05 	 0.04825901985168457 	 0.083526611328125 	 6.222724914550781e-05 	 8.153915405273438e-05 	 combined
2025-07-30 15:25:42.119076 test begin: paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.004339933395385742 	 0.0070531368255615234 	 1.2874603271484375e-05 	 3.24249267578125e-05 	 0.049646615982055664 	 0.06698083877563477 	 6.556510925292969e-05 	 6.413459777832031e-05 	 combined
2025-07-30 15:25:59.741067 test begin: paddle.linalg.multi_dot(list[Tensor([25401601],"float64"),Tensor([25401601, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([25401601],"float64"),Tensor([25401601, 31],"float64"),], ) 	 812851232 	 1000 	 6.249823093414307 	 6.249532461166382 	 3.193056106567383 	 3.1917808055877686 	 12.582195520401001 	 12.571842432022095 	 0.4992496967315674 	 0.4985525608062744 	 
2025-07-30 15:26:58.894352 test begin: paddle.linalg.multi_dot(list[Tensor([4, 4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4, 4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401620 	 1000 	 0.7779016494750977 	 0.7747046947479248 	 0.1134035587310791 	 0.11309671401977539 	 2.0325424671173096 	 2.0526773929595947 	 0.23071932792663574 	 0.23384690284729004 	 
2025-07-30 15:27:05.652414 test begin: paddle.linalg.multi_dot(list[Tensor([4233601, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4233601, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 25401656 	 1000 	 0.9874148368835449 	 1.051851749420166 	 0.14416289329528809 	 0.15353012084960938 	 2.899946451187134 	 2.02984881401062 	 0.15146827697753906 	 0.18799281120300293 	 
2025-07-30 15:27:13.614589 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401608 	 1000 	 0.19413399696350098 	 0.19390320777893066 	 0.17126202583312988 	 0.15906810760498047 	 0.5764985084533691 	 0.567314624786377 	 0.06535601615905762 	 0.06440567970275879 	 
2025-07-30 15:27:15.853432 test begin: paddle.linalg.multi_dot(list[Tensor([6350401, 4],"float64"),Tensor([4, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([6350401, 4],"float64"),Tensor([4, 31],"float64"),], ) 	 25401728 	 1000 	 1.7796919345855713 	 1.8014039993286133 	 0.26079320907592773 	 0.2627902030944824 	 3.4298391342163086 	 3.7562122344970703 	 0.3885354995727539 	 0.42578983306884766 	 
2025-07-30 15:27:31.240221 test begin: paddle.linalg.multi_dot(list[Tensor([8, 3175201],"float64"),Tensor([3175201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 3175201],"float64"),Tensor([3175201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 34927243 	 1000 	 0.40233945846557617 	 0.40885496139526367 	 0.10257840156555176 	 0.10395240783691406 	 1.9591107368469238 	 1.6163561344146729 	 0.11122894287109375 	 0.13717103004455566 	 
2025-07-30 15:27:37.608100 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401682 	 1000 	 1.3635427951812744 	 1.4087049961090088 	 0.15499067306518555 	 0.1612389087677002 	 3.4752650260925293 	 2.131899833679199 	 0.14760565757751465 	 0.1669754981994629 	 
2025-07-30 15:27:47.573186 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 5080321],"float64"),Tensor([5080321, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 5080321],"float64"),Tensor([5080321, 5],"float64"),], ) 	 40642634 	 1000 	 0.6503279209136963 	 0.6355743408203125 	 0.16582846641540527 	 0.1620948314666748 	 3.062769651412964 	 2.5053515434265137 	 0.15631103515625 	 0.1839897632598877 	 
2025-07-30 15:27:55.347258 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 8467201],"float64"),Tensor([8467201, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 8467201],"float64"),Tensor([8467201, 5],"float64"),], ) 	 67737674 	 1000 	 1.048398494720459 	 1.0301685333251953 	 0.26732754707336426 	 0.2637004852294922 	 5.051727533340454 	 4.164286375045776 	 0.18456244468688965 	 0.19321894645690918 	 
2025-07-30 15:28:08.075528 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 4233601],"float64"),Tensor([4233601, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 4233601],"float64"),Tensor([4233601, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 42336078 	 1000 	 0.5287985801696777 	 0.5302824974060059 	 0.13450336456298828 	 0.1352062225341797 	 2.5877344608306885 	 2.142381429672241 	 0.1321425437927246 	 0.15597224235534668 	 
2025-07-30 15:28:14.822934 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 6350401],"float64"),Tensor([6350401, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 6350401],"float64"),Tensor([6350401, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 63504078 	 1000 	 0.7740919589996338 	 0.7774102687835693 	 0.1973121166229248 	 0.19824671745300293 	 3.853602886199951 	 3.199719190597534 	 0.16460442543029785 	 0.18203330039978027 	 
2025-07-30 15:28:24.848387 test begin: paddle.linalg.multi_dot(list[Tensor([8, 8467201],"float64"),Tensor([8467201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 8467201],"float64"),Tensor([8467201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 93139243 	 1000 	 1.0227439403533936 	 1.0284810066223145 	 0.26007556915283203 	 0.26222681999206543 	 5.117356061935425 	 4.256202220916748 	 0.18622946739196777 	 0.19745564460754395 	 
2025-07-30 15:28:40.975948 test begin: paddle.linalg.multi_dot(list[Tensor([819407],"float64"),Tensor([819407, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([819407],"float64"),Tensor([819407, 31],"float64"),], ) 	 26221024 	 1000 	 0.16577696800231934 	 0.16774439811706543 	 0.08466768264770508 	 0.0863196849822998 	 0.4497199058532715 	 0.33782458305358887 	 0.22969269752502441 	 0.1717667579650879 	 
2025-07-30 15:28:44.327283 test begin: paddle.linalg.norm(Tensor([12700801, 1, 4],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([12700801, 1, 4],"float32"), p=1.0, axis=-1, ) 	 50803204 	 1000 	 0.4058108329772949 	 0.4888572692871094 	 0.3866078853607178 	 0.4694399833679199 	 1.990722894668579 	 0.6424152851104736 	 1.9344940185546875 	 0.32819652557373047 	 
2025-07-30 15:28:49.023340 test begin: paddle.linalg.norm(Tensor([25402, 50, 20],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([25402, 50, 20],"float64"), p=2.0, axis=-1, ) 	 25402000 	 1000 	 0.3200211524963379 	 0.2674860954284668 	 0.16348910331726074 	 0.2399435043334961 	 1.4692940711975098 	 0.9351873397827148 	 1.403550386428833 	 0.23905658721923828 	 
2025-07-30 15:28:52.756344 test begin: paddle.linalg.norm(Tensor([50, 25402, 20],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50, 25402, 20],"float64"), p=2.0, axis=-1, ) 	 25402000 	 1000 	 0.32139158248901367 	 0.26744937896728516 	 0.1648721694946289 	 0.24785995483398438 	 1.469217300415039 	 0.9351658821105957 	 1.4129838943481445 	 0.23905420303344727 	 
2025-07-30 15:28:56.311142 test begin: paddle.linalg.norm(Tensor([50, 50, 10161],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50, 50, 10161],"float64"), p=2.0, axis=-1, ) 	 25402500 	 1000 	 0.1576368808746338 	 0.1518871784210205 	 0.08053469657897949 	 0.13250303268432617 	 1.4807684421539307 	 0.9115931987762451 	 1.4234397411346436 	 0.23272299766540527 	 
2025-07-30 15:28:59.629291 test begin: paddle.linalg.norm(Tensor([50803201],"float32"), p=2, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50803201],"float32"), p=2, ) 	 50803201 	 1000 	 0.15258264541625977 	 0.15347814559936523 	 0.05186057090759277 	 0.07774853706359863 	 0.9990324974060059 	 0.9128031730651855 	 0.9354276657104492 	 0.23388147354125977 	 
2025-07-30 15:29:02.747781 test begin: paddle.linalg.norm(Tensor([8550, 1, 5942],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([8550, 1, 5942],"float32"), p=1.0, axis=-1, ) 	 50804100 	 1000 	 0.1504230499267578 	 0.15718913078308105 	 0.13151001930236816 	 0.1381242275238037 	 1.9232614040374756 	 0.6057827472686768 	 1.86712646484375 	 0.30950427055358887 	 
2025-07-30 15:29:06.513608 test begin: paddle.linalg.norm(Tensor([8550, 1486, 4],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([8550, 1486, 4],"float32"), p=1.0, axis=-1, ) 	 50821200 	 1000 	 0.40506839752197266 	 0.48888373374938965 	 0.38603687286376953 	 0.46928858757019043 	 1.9892334938049316 	 0.6409974098205566 	 1.9330377578735352 	 0.328183650970459 	 
2025-07-30 15:29:11.085032 test begin: paddle.linalg.pinv(Tensor([21, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([21, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 	 2520 	 1000 	 54.900590896606445 	 0.4183046817779541 	 4.8160552978515625e-05 	 8.058547973632812e-05 	 0.47396039962768555 	 0.3101074695587158 	 3.62396240234375e-05 	 7.534027099609375e-05 	 
2025-07-30 15:30:07.280359 test begin: paddle.linalg.pinv(Tensor([22, 20, 3],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([22, 20, 3],"float64"), rcond=1e-15, hermitian=False, ) 	 1320 	 1000 	 9.304740905761719 	 0.3675570487976074 	 4.601478576660156e-05 	 7.104873657226562e-05 	 0.4749751091003418 	 0.2969841957092285 	 3.2901763916015625e-05 	 7.987022399902344e-05 	 
2025-07-30 15:30:17.743069 test begin: paddle.linalg.pinv(Tensor([3, 22, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([3, 22, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 	 1320 	 1000 	 29.987552642822266 	 0.38045454025268555 	 4.458427429199219e-05 	 0.00010228157043457031 	 0.47211337089538574 	 0.31487321853637695 	 3.218650817871094e-05 	 7.390975952148438e-05 	 
2025-07-30 15:30:48.937129 test begin: paddle.linalg.pinv(x=Tensor([58, 4, 4],"float64"), )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(x=Tensor([58, 4, 4],"float64"), ) 	 928 	 1000 	 25.342854738235474 	 0.3777780532836914 	 4.76837158203125e-05 	 7.534027099609375e-05 	 0.4311563968658447 	 0.31401968002319336 	 4.839897155761719e-05 	 7.82012939453125e-05 	 
2025-07-30 15:31:15.439531 test begin: paddle.linalg.qr(Tensor([105, 3, 50, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([105, 3, 50, 8],"float64"), ) 	 126000 	 1000 	 29.685588359832764 	 10.775923252105713 	 0.00010800361633300781 	 0.0038094520568847656 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:31:57.134339 test begin: paddle.linalg.qr(Tensor([112, 3, 20, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([112, 3, 20, 6],"float64"), ) 	 40320 	 1000 	 28.871615409851074 	 10.446140050888062 	 0.00011086463928222656 	 0.0034584999084472656 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:32:37.105394 test begin: paddle.linalg.qr(Tensor([2, 105, 100, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 105, 100, 12],"float64"), ) 	 252000 	 1000 	 30.2013738155365 	 7.7560505867004395 	 0.00011134147644042969 	 0.004073619842529297 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:33:15.201937 test begin: paddle.linalg.qr(Tensor([2, 158, 100, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 158, 100, 8],"float64"), ) 	 252800 	 1000 	 30.79166316986084 	 11.009778022766113 	 0.00011229515075683594 	 0.003877878189086914 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:33:57.055434 test begin: paddle.linalg.qr(Tensor([2, 211, 100, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 211, 100, 6],"float64"), ) 	 253200 	 1000 	 39.77354669570923 	 14.188323259353638 	 0.00011515617370605469 	 0.0037436485290527344 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:34:51.279380 test begin: paddle.linalg.qr(Tensor([2, 3, 100, 423],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 100, 423],"float64"), ) 	 253800 	 1000 	 4.410927772521973 	 47.410367488861084 	 4.410743713378906e-05 	 0.5684950351715088 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:35:43.162792 test begin: paddle.linalg.qr(Tensor([2, 3, 3528, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 3528, 12],"float64"), ) 	 254016 	 1000 	 1.8116135597229004 	 1.5210967063903809 	 3.504753112792969e-05 	 0.020075321197509766 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:35:46.556582 test begin: paddle.linalg.qr(Tensor([2, 3, 529201, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 529201, 8],"float64"), ) 	 25401648 	 1000 	 12.758435487747192 	 11.256808757781982 	 0.0008921623229980469 	 0.13903498649597168 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:36:11.196506 test begin: paddle.linalg.qr(Tensor([2, 3, 705601, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 705601, 6],"float64"), ) 	 25401636 	 1000 	 13.779542446136475 	 12.132102727890015 	 0.0008976459503173828 	 0.150834321975708 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:36:40.265753 test begin: paddle.linalg.qr(Tensor([70, 3, 50, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([70, 3, 50, 12],"float64"), ) 	 126000 	 1000 	 23.514246463775635 	 7.704340934753418 	 0.00011348724365234375 	 0.0040645599365234375 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:37:11.525590 test begin: paddle.linalg.slogdet(Tensor([3, 6773, 5, 5],"float32"), )
[Prof] paddle.linalg.slogdet 	 paddle.linalg.slogdet(Tensor([3, 6773, 5, 5],"float32"), ) 	 507975 	 1000 	 6.500270366668701 	 0.17173433303833008 	 5.364418029785156e-05 	 8.654594421386719e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 3, 6773]) and output[0] has a shape of torch.Size([3, 6773]).
2025-07-30 15:37:19.545975 test begin: paddle.linalg.slogdet(Tensor([6773, 3, 5, 5],"float32"), )
[Prof] paddle.linalg.slogdet 	 paddle.linalg.slogdet(Tensor([6773, 3, 5, 5],"float32"), ) 	 507975 	 1000 	 6.5465192794799805 	 0.15856337547302246 	 6.532669067382812e-05 	 7.748603820800781e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 6773, 3]) and output[0] has a shape of torch.Size([6773, 3]).
2025-07-30 15:37:27.480646 test begin: paddle.linalg.solve(x=Tensor([129601, 14, 14],"float64"), y=Tensor([129601, 14, 2],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([129601, 14, 14],"float64"), y=Tensor([129601, 14, 2],"float64"), ) 	 29030624 	 1000 	 3.682424545288086 	 2.3774638175964355 	 0.0012311935424804688 	 6.914138793945312e-05 	 5.985062599182129 	 2.7767224311828613 	 0.002687692642211914 	 0.2593092918395996 	 
2025-07-30 15:37:45.259664 test begin: paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 1814401],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 1814401],"float64"), ) 	 25401810 	 1000 	 5.035809755325317 	 3.972475051879883 	 0.003937959671020508 	 8.440017700195312e-05 	 6.028357267379761 	 4.004748344421387 	 0.004523277282714844 	 0.456132173538208 	 
2025-07-30 15:38:05.467186 test begin: paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 453601],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 453601],"float64"), ) 	 25402440 	 1000 	 4.184483289718628 	 2.9133141040802 	 0.0030155181884765625 	 8.678436279296875e-05 	 11.007864952087402 	 10.27957272529602 	 0.009459972381591797 	 0.58644700050354 	 
2025-07-30 15:38:39.745871 test begin: paddle.linalg.solve(x=Tensor([907201, 14, 14],"float64"), y=Tensor([907201, 14, 2],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([907201, 14, 14],"float64"), y=Tensor([907201, 14, 2],"float64"), ) 	 203213024 	 1000 	 28.00890564918518 	 15.500324964523315 	 0.008291482925415039 	 0.0002551078796386719 	 43.84955072402954 	 18.99256658554077 	 0.018673181533813477 	 0.41446375846862793 	 
2025-07-30 15:40:31.427986 test begin: paddle.linalg.svdvals(Tensor([10, 3, 8467],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 3, 8467],"float64"), ) 	 254010 	 1000 	 6.939521789550781 	 6.805842161178589 	 4.76837158203125e-05 	 0.00030684471130371094 	 15.06910753250122 	 0.10786867141723633 	 9.131431579589844e-05 	 7.581710815429688e-05 	 
2025-07-30 15:41:01.221073 test begin: paddle.linalg.svdvals(Tensor([10, 4233, 6],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 4233, 6],"float64"), ) 	 253980 	 1000 	 7.921173810958862 	 7.737634658813477 	 4.3392181396484375e-05 	 9.250640869140625e-05 	 19.278345346450806 	 0.09761357307434082 	 8.7738037109375e-05 	 6.771087646484375e-05 	 
2025-07-30 15:41:37.123974 test begin: paddle.linalg.svdvals(Tensor([10, 5080],"float32"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 5080],"float32"), ) 	 50800 	 1000 	 2.411569833755493 	 0.8159084320068359 	 4.363059997558594e-05 	 7.843971252441406e-05 	 6.426874399185181 	 0.08916521072387695 	 8.034706115722656e-05 	 0.0001251697540283203 	 
2025-07-30 15:41:49.581122 test begin: paddle.linalg.svdvals(Tensor([40, 6350],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([40, 6350],"float64"), ) 	 254000 	 1000 	 35.79516649246216 	 2.99202299118042 	 0.0001049041748046875 	 9.202957153320312e-05 	 103.49688291549683 	 0.11407780647277832 	 9.036064147949219e-05 	 8.106231689453125e-05 	 
2025-07-30 15:44:12.151982 test begin: paddle.linalg.svdvals(Tensor([611, 3, 6],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([611, 3, 6],"float64"), ) 	 10998 	 1000 	 4.437604904174805 	 0.514087438583374 	 4.553794860839844e-05 	 0.000118255615234375 	 5.502537727355957 	 0.1390242576599121 	 6.0558319091796875e-05 	 0.0011341571807861328 	 
2025-07-30 15:44:22.861979 test begin: paddle.linalg.svdvals(Tensor([623, 12],"float32"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([623, 12],"float32"), ) 	 7476 	 1000 	 0.4622955322265625 	 0.8255405426025391 	 3.838539123535156e-05 	 7.224082946777344e-05 	 1.4108912944793701 	 0.08513712882995605 	 4.601478576660156e-05 	 6.29425048828125e-05 	 
2025-07-30 15:44:25.660825 test begin: paddle.linalg.svdvals(Tensor([635, 40],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([635, 40],"float64"), ) 	 25400 	 1000 	 3.6942780017852783 	 2.8980770111083984 	 4.553794860839844e-05 	 0.00010776519775390625 	 11.792956352233887 	 0.08717608451843262 	 8.249282836914062e-05 	 7.224082946777344e-05 	 
2025-07-30 15:44:44.161546 test begin: paddle.log(Tensor([192, 40, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([192, 40, 6625],"float32"), ) 	 50880000 	 1000 	 0.2972118854522705 	 0.29799580574035645 	 0.28893351554870605 	 0.286806583404541 	 0.45171022415161133 	 0.4502856731414795 	 0.39641523361206055 	 0.3850224018096924 	 
2025-07-30 15:44:47.317286 test begin: paddle.log(Tensor([307, 25, 6626],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([307, 25, 6626],"float32"), ) 	 50854550 	 1000 	 0.29599833488464355 	 0.30077695846557617 	 0.27599453926086426 	 0.28191637992858887 	 0.45026731491088867 	 0.4527153968811035 	 0.38588809967041016 	 0.3797643184661865 	 
2025-07-30 15:44:50.577246 test begin: paddle.log(Tensor([64, 120, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 120, 6625],"float32"), ) 	 50880000 	 1000 	 0.29596900939941406 	 0.298018217086792 	 0.28775620460510254 	 0.286832332611084 	 0.45053577423095703 	 0.4503180980682373 	 0.3946969509124756 	 0.38183093070983887 	 
2025-07-30 15:44:53.707416 test begin: paddle.log(Tensor([64, 120, 6626],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 120, 6626],"float32"), ) 	 50887680 	 1000 	 0.2961885929107666 	 0.29801082611083984 	 0.2806403636932373 	 0.28056836128234863 	 0.45049118995666504 	 0.4503612518310547 	 0.3862464427947998 	 0.38000035285949707 	 
2025-07-30 15:44:56.923263 test begin: paddle.log(Tensor([64, 25, 31753],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 25, 31753],"float32"), ) 	 50804800 	 1000 	 0.2954885959625244 	 0.2975587844848633 	 0.2869997024536133 	 0.2839174270629883 	 0.45111680030822754 	 0.4509880542755127 	 0.3948483467102051 	 0.35941004753112793 	 
2025-07-30 15:45:00.224889 test begin: paddle.log(Tensor([64, 40, 19846],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 40, 19846],"float32"), ) 	 50805760 	 1000 	 0.2954843044281006 	 0.30185651779174805 	 0.2871818542480469 	 0.286684513092041 	 0.44968438148498535 	 0.4496943950653076 	 0.3946533203125 	 0.38654136657714844 	 
2025-07-30 15:45:05.336765 test begin: paddle.log(Tensor([64, 80, 9923],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 80, 9923],"float32"), ) 	 50805760 	 1000 	 0.29553985595703125 	 0.3112616539001465 	 0.2872326374053955 	 0.2867312431335449 	 0.4496893882751465 	 0.44956469535827637 	 0.3941938877105713 	 0.38311052322387695 	 
2025-07-30 15:45:08.512516 test begin: paddle.log(Tensor([96, 80, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([96, 80, 6625],"float32"), ) 	 50880000 	 1000 	 0.2960212230682373 	 0.2980203628540039 	 0.2877519130706787 	 0.2868499755859375 	 0.4505271911621094 	 0.4516427516937256 	 0.3952820301055908 	 0.38178586959838867 	 
2025-07-30 15:45:11.837867 test begin: paddle.log10(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29543328285217285 	 0.3005051612854004 	 0.28731417655944824 	 0.28646206855773926 	 0.44919466972351074 	 0.7458224296569824 	 0.39438581466674805 	 0.3811054229736328 	 
2025-07-30 15:45:15.292569 test begin: paddle.log10(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29805946350097656 	 0.29752659797668457 	 0.2823467254638672 	 0.2862372398376465 	 0.4495394229888916 	 0.7458057403564453 	 0.39416050910949707 	 0.381000280380249 	 
2025-07-30 15:45:18.809008 test begin: paddle.log10(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29552483558654785 	 0.3143424987792969 	 0.28735971450805664 	 0.2890641689300537 	 0.4508228302001953 	 0.747025728225708 	 0.3961918354034424 	 0.3810572624206543 	 
2025-07-30 15:45:22.247087 test begin: paddle.log10(x=Tensor([12700801, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.30614519119262695 	 0.3070070743560791 	 0.2977478504180908 	 0.2960786819458008 	 0.44748711585998535 	 0.745060920715332 	 0.39345479011535645 	 0.38071107864379883 	 
2025-07-30 15:45:25.095978 test begin: paddle.log10(x=Tensor([2, 12700801],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.3075122833251953 	 0.30758070945739746 	 0.2991185188293457 	 0.29583144187927246 	 0.44745731353759766 	 0.7450037002563477 	 0.39324402809143066 	 0.38057661056518555 	 
2025-07-30 15:45:28.006885 test begin: paddle.log10(x=Tensor([2, 3, 2, 2116801],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3, 2, 2116801],"float64"), ) 	 25401612 	 1000 	 0.3061995506286621 	 0.30678439140319824 	 0.2902090549468994 	 0.29581236839294434 	 0.44879579544067383 	 0.7476198673248291 	 0.3942296504974365 	 0.38186097145080566 	 
2025-07-30 15:45:31.021219 test begin: paddle.log10(x=Tensor([2, 3, 2116801, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3, 2116801, 2],"float64"), ) 	 25401612 	 1000 	 0.3061356544494629 	 0.3066518306732178 	 0.2978358268737793 	 0.29572176933288574 	 0.44747161865234375 	 0.7448649406433105 	 0.3934919834136963 	 0.3805410861968994 	 
2025-07-30 15:45:33.882304 test begin: paddle.log10(x=Tensor([2, 3175201, 2, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3175201, 2, 2],"float64"), ) 	 25401608 	 1000 	 0.30735254287719727 	 0.756781816482544 	 0.2991061210632324 	 0.29566431045532227 	 0.4474318027496338 	 0.7450032234191895 	 0.39281535148620605 	 0.3805887699127197 	 
2025-07-30 15:45:39.582360 test begin: paddle.log10(x=Tensor([2116801, 3, 2, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2116801, 3, 2, 2],"float64"), ) 	 25401612 	 1000 	 0.3073616027832031 	 0.3170769214630127 	 0.2918212413787842 	 0.2956557273864746 	 0.44863200187683105 	 0.7450070381164551 	 0.38550472259521484 	 0.38059258460998535 	 
2025-07-30 15:45:42.620588 test begin: paddle.log1p(Tensor([10, 16935, 300],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([10, 16935, 300],"float32"), ) 	 50805000 	 1000 	 0.2955753803253174 	 0.3073434829711914 	 0.2871816158294678 	 0.28914451599121094 	 0.45084714889526367 	 0.7471020221710205 	 0.3954782485961914 	 0.3810591697692871 	 
2025-07-30 15:45:46.068510 test begin: paddle.log1p(Tensor([10, 200, 25402],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([10, 200, 25402],"float32"), ) 	 50804000 	 1000 	 0.2956416606903076 	 0.2990384101867676 	 0.2872622013092041 	 0.2881124019622803 	 0.4494917392730713 	 0.7483851909637451 	 0.3941984176635742 	 0.3836367130279541 	 
2025-07-30 15:45:49.675137 test begin: paddle.log1p(Tensor([1016065, 5, 5],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([1016065, 5, 5],"float64"), ) 	 25401625 	 1000 	 0.3053774833679199 	 0.3366847038269043 	 0.2896273136138916 	 0.3193840980529785 	 0.4487488269805908 	 0.7450408935546875 	 0.38452911376953125 	 0.380643367767334 	 
2025-07-30 15:45:52.593146 test begin: paddle.log1p(Tensor([108, 157920, 3],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([108, 157920, 3],"float32"), ) 	 51166080 	 1000 	 0.29900050163269043 	 0.30092740058898926 	 0.290677547454834 	 0.29027581214904785 	 0.4538695812225342 	 0.7524645328521729 	 0.39885616302490234 	 0.38510560989379883 	 
2025-07-30 15:45:56.055103 test begin: paddle.log1p(Tensor([4, 157920, 81],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([4, 157920, 81],"float32"), ) 	 51166080 	 1000 	 0.2978088855743408 	 0.3009772300720215 	 0.28943634033203125 	 0.29029321670532227 	 0.4541280269622803 	 0.7539410591125488 	 0.39876651763916016 	 0.3851487636566162 	 
2025-07-30 15:45:59.540363 test begin: paddle.log1p(Tensor([4, 4233601, 3],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([4, 4233601, 3],"float32"), ) 	 50803212 	 1000 	 0.29558229446411133 	 0.30057621002197266 	 0.2797698974609375 	 0.28147172927856445 	 0.44956254959106445 	 0.7460074424743652 	 0.38370609283447266 	 0.3811371326446533 	 
2025-07-30 15:46:03.083917 test begin: paddle.log1p(Tensor([50000, 102, 5],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([50000, 102, 5],"float64"), ) 	 25500000 	 1000 	 0.30625247955322266 	 0.34740328788757324 	 0.2978987693786621 	 0.32796168327331543 	 0.44910120964050293 	 0.7477536201477051 	 0.394634485244751 	 0.3820011615753174 	 
2025-07-30 15:46:06.042905 test begin: paddle.log1p(Tensor([50000, 5, 102],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([50000, 5, 102],"float64"), ) 	 25500000 	 1000 	 0.3062746524810791 	 0.34351420402526855 	 0.297868013381958 	 0.3264596462249756 	 0.44901514053344727 	 0.7477390766143799 	 0.39388036727905273 	 0.3820223808288574 	 
2025-07-30 15:46:10.977417 test begin: paddle.log1p(Tensor([847, 200, 300],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([847, 200, 300],"float32"), ) 	 50820000 	 1000 	 0.297102689743042 	 0.2989339828491211 	 0.28879308700561523 	 0.28818655014038086 	 0.44965505599975586 	 0.746025800704956 	 0.39391589164733887 	 0.381181001663208 	 
2025-07-30 15:46:14.405864 test begin: paddle.log2(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29546570777893066 	 0.3024001121520996 	 0.2868020534515381 	 0.287980318069458 	 0.45058274269104004 	 0.7458114624023438 	 0.3952317237854004 	 0.3810431957244873 	 
2025-07-30 15:46:17.840281 test begin: paddle.log2(Tensor([10, 2540161],"float64"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 2540161],"float64"), ) 	 25401610 	 1000 	 0.3061385154724121 	 0.3077733516693115 	 0.29792141914367676 	 0.2958407402038574 	 0.4475688934326172 	 0.7462480068206787 	 0.39052557945251465 	 0.3818645477294922 	 
2025-07-30 15:46:20.745714 test begin: paddle.log2(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2981867790222168 	 0.29754209518432617 	 0.2896556854248047 	 0.2866525650024414 	 0.449540376663208 	 0.74580979347229 	 0.39378786087036133 	 0.3810861110687256 	 
2025-07-30 15:46:24.209414 test begin: paddle.log2(Tensor([10, 5080321],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2955286502838135 	 0.3133716583251953 	 0.28695011138916016 	 0.2879049777984619 	 0.4509847164154053 	 0.7457661628723145 	 0.39500951766967773 	 0.3809807300567627 	 
2025-07-30 15:46:27.671826 test begin: paddle.log2(Tensor([2116801, 12],"float64"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([2116801, 12],"float64"), ) 	 25401612 	 1000 	 0.30616092681884766 	 0.3067460060119629 	 0.2979006767272949 	 0.2959749698638916 	 0.4475879669189453 	 0.7474071979522705 	 0.39272069931030273 	 0.38182640075683594 	 
2025-07-30 15:46:30.601656 test begin: paddle.log2(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29700207710266113 	 0.29757070541381836 	 0.28861045837402344 	 0.2866947650909424 	 0.44957637786865234 	 0.7458291053771973 	 0.39269065856933594 	 0.38106250762939453 	 
2025-07-30 15:46:34.055590 test begin: paddle.log2(Tensor([4233601, 12],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([4233601, 12],"float32"), ) 	 50803212 	 1000 	 0.29677748680114746 	 0.30896735191345215 	 0.288316011428833 	 0.2866702079772949 	 0.44951772689819336 	 0.7459235191345215 	 0.39397573471069336 	 0.3810572624206543 	 
2025-07-30 15:46:39.427668 test begin: paddle.logaddexp(Tensor([10, 16935, 300],"float32"), Tensor([10, 16935, 300],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 16935, 300],"float32"), Tensor([10, 16935, 300],"float32"), ) 	 101610000 	 1000 	 2.5325076580047607 	 0.4603688716888428 	 0.36956167221069336 	 0.432755708694458 	 4.627765893936157 	 2.9805474281311035 	 0.5244221687316895 	 0.38041043281555176 	 
2025-07-30 15:46:52.718592 test begin: paddle.logaddexp(Tensor([10, 16935, 300],"int32"), Tensor([10, 16935, 300],"int32"), )
W0730 15:46:57.418313  5441 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 16935, 300],"int32"), Tensor([10, 16935, 300],"int32"), ) 	 101610000 	 1000 	 2.8290469646453857 	 0.45054006576538086 	 0.3609285354614258 	 0.4394857883453369 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:46:58.301819 test begin: paddle.logaddexp(Tensor([10, 200, 12701],"int64"), Tensor([10, 200, 12701],"int64"), )
W0730 15:47:01.738863  5851 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 12701],"int64"), Tensor([10, 200, 12701],"int64"), ) 	 50804000 	 1000 	 2.324493646621704 	 0.23116493225097656 	 0.296328067779541 	 0.21838998794555664 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:47:02.179091 test begin: paddle.logaddexp(Tensor([10, 200, 25402],"float32"), Tensor([10, 200, 25402],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 25402],"float32"), Tensor([10, 200, 25402],"float32"), ) 	 101608000 	 1000 	 2.5351603031158447 	 0.4680449962615967 	 0.36960530281066895 	 0.4391653537750244 	 4.626372814178467 	 2.978118658065796 	 0.5242853164672852 	 0.3804771900177002 	 
2025-07-30 15:47:16.819342 test begin: paddle.logaddexp(Tensor([10, 200, 25402],"int32"), Tensor([10, 200, 25402],"int32"), )
W0730 15:47:21.498442  7349 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 25402],"int32"), Tensor([10, 200, 25402],"int32"), ) 	 101608000 	 1000 	 2.827751874923706 	 0.4517967700958252 	 0.3609278202056885 	 0.4407773017883301 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:47:22.213576 test begin: paddle.logaddexp(Tensor([10, 8468, 300],"int64"), Tensor([10, 8468, 300],"int64"), )
W0730 15:47:25.622897  7726 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 8468, 300],"int64"), Tensor([10, 8468, 300],"int64"), ) 	 50808000 	 1000 	 2.3214900493621826 	 0.22975778579711914 	 0.2964210510253906 	 0.21843791007995605 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:47:26.061549 test begin: paddle.logaddexp(Tensor([424, 200, 300],"int64"), Tensor([424, 200, 300],"int64"), )
W0730 15:47:29.463341  7971 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([424, 200, 300],"int64"), Tensor([424, 200, 300],"int64"), ) 	 50880000 	 1000 	 2.329322576522827 	 0.23006749153137207 	 0.2969372272491455 	 0.21906280517578125 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:47:29.848144 test begin: paddle.logaddexp(Tensor([847, 200, 300],"float32"), Tensor([847, 200, 300],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([847, 200, 300],"float32"), Tensor([847, 200, 300],"float32"), ) 	 101640000 	 1000 	 2.53497052192688 	 0.46448326110839844 	 0.3695998191833496 	 0.43878889083862305 	 4.621939182281494 	 2.984374761581421 	 0.524282693862915 	 0.38057637214660645 	 
2025-07-30 15:47:43.842707 test begin: paddle.logaddexp(Tensor([847, 200, 300],"int32"), Tensor([847, 200, 300],"int32"), )
W0730 15:47:48.533192  8695 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([847, 200, 300],"int32"), Tensor([847, 200, 300],"int32"), ) 	 101640000 	 1000 	 2.8312718868255615 	 0.4507710933685303 	 0.3610198497772217 	 0.43974804878234863 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:47:49.165367 test begin: paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=-1, ) 	 50803300 	 1000 	 3.383795976638794 	 2.4838523864746094 	 3.3745687007904053 	 2.464874029159546 	 10.905410051345825 	 10.83295464515686 	 1.0137791633605957 	 0.5526320934295654 	 
2025-07-30 15:48:19.247008 test begin: paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=0, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=0, ) 	 50803300 	 1000 	 23.7774715423584 	 0.3690803050994873 	 8.109113216400146 	 0.3369455337524414 	 192.48386001586914 	 6.570204496383667 	 13.09219741821289 	 0.33685827255249023 	 
2025-07-30 15:52:04.539333 test begin: paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=-1, ) 	 50803300 	 1000 	 22.91796326637268 	 103.94192433357239 	 22.908939123153687 	 103.91654062271118 	 190.6078746318817 	 213.79958081245422 	 17.733315229415894 	 10.910564422607422 	 
2025-07-30 16:00:58.090164 test begin: paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=0, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=0, ) 	 50803300 	 1000 	 23.777031660079956 	 0.3575000762939453 	 8.114264488220215 	 0.3355381488800049 	 192.79330277442932 	 6.576111078262329 	 13.114052057266235 	 0.33817005157470703 	 
2025-07-30 16:04:45.666768 test begin: paddle.logcumsumexp(Tensor([508033, 10, 10],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([508033, 10, 10],"float32"), axis=-1, ) 	 50803300 	 1000 	 22.86144757270813 	 103.94073176383972 	 22.85244917869568 	 103.92648673057556 	 190.79020023345947 	 213.709712266922 	 17.738392114639282 	 10.894962787628174 	 
2025-07-30 16:13:39.479874 test begin: paddle.logical_and(Tensor([138, 369303],"bool"), Tensor([138, 369303],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([138, 369303],"bool"), Tensor([138, 369303],"bool"), ) 	 101927628 	 1000 	 0.11821722984313965 	 0.12305021286010742 	 0.09994173049926758 	 0.09733271598815918 	 None 	 None 	 None 	 None 	 
2025-07-30 16:13:41.621968 test begin: paddle.logical_and(Tensor([146, 349866],"bool"), Tensor([146, 349866],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([146, 349866],"bool"), Tensor([146, 349866],"bool"), ) 	 102160872 	 1000 	 0.11849641799926758 	 0.11602187156677246 	 0.10959744453430176 	 0.10301351547241211 	 None 	 None 	 None 	 None 	 
2025-07-30 16:13:43.286311 test begin: paddle.logical_and(Tensor([49, 1036801],"bool"), Tensor([49, 1036801],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([49, 1036801],"bool"), Tensor([49, 1036801],"bool"), ) 	 101606498 	 1000 	 0.11807966232299805 	 0.11844015121459961 	 0.10919785499572754 	 0.1012423038482666 	 None 	 None 	 None 	 None 	 
2025-07-30 16:13:45.040082 test begin: paddle.logical_and(Tensor([53, 958551],"bool"), Tensor([53, 958551],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([53, 958551],"bool"), Tensor([53, 958551],"bool"), ) 	 101606406 	 1000 	 0.11807584762573242 	 0.11629247665405273 	 0.10931801795959473 	 0.10315680503845215 	 None 	 None 	 None 	 None 	 
2025-07-30 16:13:46.739818 test begin: paddle.logical_and(Tensor([55, 923695],"bool"), Tensor([55, 923695],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([55, 923695],"bool"), Tensor([55, 923695],"bool"), ) 	 101606450 	 1000 	 0.11809682846069336 	 0.1201486587524414 	 0.10928702354431152 	 0.1031959056854248 	 None 	 None 	 None 	 None 	 
2025-07-30 16:13:48.427994 test begin: paddle.logical_not(Tensor([2150400, 237],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2150400, 237],"bool"), ) 	 509644800 	 1000 	 0.7879931926727295 	 0.7495036125183105 	 0.7797255516052246 	 0.7367486953735352 	 None 	 None 	 None 	 None 	 
2025-07-30 16:13:56.960529 test begin: paddle.logical_not(Tensor([2204160, 231],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2204160, 231],"bool"), ) 	 509160960 	 1000 	 0.786724328994751 	 0.750485897064209 	 0.7784667015075684 	 0.7382283210754395 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:05.445097 test begin: paddle.logical_not(Tensor([2257920, 226],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2257920, 226],"bool"), ) 	 510289920 	 1000 	 0.7907309532165527 	 0.7551174163818359 	 0.7755293846130371 	 0.7387237548828125 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:15.138519 test begin: paddle.logical_not(Tensor([6350410, 80],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([6350410, 80],"bool"), ) 	 508032800 	 1000 	 0.7856349945068359 	 0.749929666519165 	 0.770383358001709 	 0.7286691665649414 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:24.949237 test begin: paddle.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11760878562927246 	 0.1175382137298584 	 0.10891008377075195 	 0.10419082641601562 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:26.722435 test begin: paddle.logical_or(Tensor([640, 79381],"bool"), Tensor([640, 79381],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([640, 79381],"bool"), Tensor([640, 79381],"bool"), ) 	 101607680 	 1000 	 0.11760902404785156 	 0.11507248878479004 	 0.10888075828552246 	 0.10207128524780273 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:28.386997 test begin: paddle.logical_or(Tensor([79381, 640],"bool"), Tensor([79381, 640],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([79381, 640],"bool"), Tensor([79381, 640],"bool"), ) 	 101607680 	 1000 	 0.11761784553527832 	 0.11774778366088867 	 0.10883951187133789 	 0.10171270370483398 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:30.037220 test begin: paddle.logical_xor(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19092845916748047 	 0.24533534049987793 	 0.1811356544494629 	 0.22569513320922852 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:31.309815 test begin: paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.189056396484375 	 0.9123401641845703 	 0.1793076992034912 	 0.22444725036621094 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:34.094627 test begin: paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3265256881713867 	 0.33252453804016113 	 0.31766819953918457 	 0.31414270401000977 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:37.092004 test begin: paddle.logical_xor(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.3264744281768799 	 1.4713423252105713 	 0.31768178939819336 	 0.3091471195220947 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:41.452254 test begin: paddle.logical_xor(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3265249729156494 	 0.32781982421875 	 0.31759214401245117 	 0.3146188259124756 	 None 	 None 	 None 	 None 	 
2025-07-30 16:14:43.824501 test begin: paddle.logit(Tensor([10, 20, 254017],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([10, 20, 254017],"float32"), 0.001, ) 	 50803400 	 1000 	 0.2975478172302246 	 0.2998819351196289 	 0.2888805866241455 	 0.28737306594848633 	 0.44948506355285645 	 0.4526679515838623 	 0.39484262466430664 	 0.3903224468231201 	 
2025-07-30 16:14:47.220500 test begin: paddle.logit(Tensor([10, 5080321, 1],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([10, 5080321, 1],"float32"), 0.001, ) 	 50803210 	 1000 	 0.2984335422515869 	 0.29976868629455566 	 0.2892582416534424 	 0.2867109775543213 	 0.44948697090148926 	 0.45133066177368164 	 0.39024996757507324 	 0.3680403232574463 	 
2025-07-30 16:14:50.432368 test begin: paddle.logit(Tensor([2540161, 20, 1],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([2540161, 20, 1],"float32"), 0.001, ) 	 50803220 	 1000 	 0.2996976375579834 	 0.30196714401245117 	 0.28818678855895996 	 0.2871682643890381 	 0.44968676567077637 	 0.4499509334564209 	 0.3928098678588867 	 0.38738298416137695 	 
2025-07-30 16:14:53.814852 test begin: paddle.logit(Tensor([50803201],"float32"), 1e-08, )
[Prof] paddle.logit 	 paddle.logit(Tensor([50803201],"float32"), 1e-08, ) 	 50803201 	 1000 	 0.29965782165527344 	 0.3147883415222168 	 0.28287553787231445 	 0.28846096992492676 	 0.4495832920074463 	 0.4514167308807373 	 0.394550085067749 	 0.3903937339782715 	 
2025-07-30 16:14:57.171452 test begin: paddle.logit(x=Tensor([4, 3, 2, 1058401],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 3, 2, 1058401],"float64"), eps=0.2, ) 	 25401624 	 1000 	 0.32914018630981445 	 0.30550479888916016 	 0.32028746604919434 	 0.2915208339691162 	 0.4441366195678711 	 0.4488699436187744 	 0.3897716999053955 	 0.3726363182067871 	 
2025-07-30 16:14:59.802236 test begin: paddle.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, ) 	 25401660 	 1000 	 0.3267700672149658 	 0.30579614639282227 	 0.31037282943725586 	 0.28455662727355957 	 0.44541096687316895 	 0.44884586334228516 	 0.38187575340270996 	 0.3794436454772949 	 
2025-07-30 16:15:02.492967 test begin: paddle.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, ) 	 25401640 	 1000 	 0.32529640197753906 	 0.302767276763916 	 0.3087472915649414 	 0.2834930419921875 	 0.44278860092163086 	 0.4501006603240967 	 0.37940454483032227 	 0.3685493469238281 	 
2025-07-30 16:15:05.177925 test begin: paddle.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, ) 	 25401630 	 1000 	 0.32680726051330566 	 0.30283260345458984 	 0.3102591037750244 	 0.28356170654296875 	 0.44405126571655273 	 0.4488365650177002 	 0.3805568218231201 	 0.3813145160675049 	 
2025-07-30 16:15:07.771804 test begin: paddle.logsumexp(Tensor([1024, 49613],"float32"), axis=1, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([1024, 49613],"float32"), axis=1, ) 	 50803712 	 1000 	 0.7120895385742188 	 0.9364352226257324 	 0.10393810272216797 	 0.10739254951477051 	 0.8151218891143799 	 0.905383825302124 	 0.7509799003601074 	 0.30838704109191895 	 
2025-07-30 16:15:11.996606 test begin: paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=-1, keepdim=False, ) 	 50808000 	 1000 	 0.6362209320068359 	 0.9392580986022949 	 0.1295170783996582 	 0.10797905921936035 	 1.2152364253997803 	 0.9122228622436523 	 1.1590864658355713 	 0.30985474586486816 	 
2025-07-30 16:15:16.610010 test begin: paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=list[0,2,], keepdim=False, ) 	 50808000 	 1000 	 0.7334179878234863 	 0.9839413166046143 	 0.10706543922424316 	 0.09147453308105469 	 1.2121002674102783 	 0.916346549987793 	 1.1552934646606445 	 0.3120400905609131 	 
2025-07-30 16:15:21.292119 test begin: paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=-1, keepdim=False, ) 	 50804400 	 1000 	 0.6660330295562744 	 1.6339740753173828 	 0.3403306007385254 	 0.1866464614868164 	 1.2372522354125977 	 0.9204301834106445 	 1.1807208061218262 	 0.31450963020324707 	 
2025-07-30 16:15:26.703515 test begin: paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=list[0,2,], keepdim=False, ) 	 50804400 	 1000 	 0.725316047668457 	 0.9523024559020996 	 0.147691011428833 	 0.10806536674499512 	 1.2182457447052002 	 0.9145605564117432 	 1.1622035503387451 	 0.31247544288635254 	 
2025-07-30 16:15:31.507525 test begin: paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=-1, keepdim=False, ) 	 50808000 	 1000 	 0.666022777557373 	 1.6345851421356201 	 0.3409435749053955 	 0.18530917167663574 	 1.236302375793457 	 0.9190845489501953 	 1.1801741123199463 	 0.31301283836364746 	 
2025-07-30 16:15:39.582256 test begin: paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=list[0,2,], keepdim=False, ) 	 50808000 	 1000 	 0.7392592430114746 	 0.9914777278900146 	 0.10791635513305664 	 0.09193849563598633 	 1.209810495376587 	 0.9139723777770996 	 1.1399319171905518 	 0.31215381622314453 	 
2025-07-30 16:15:46.208453 test begin: paddle.masked_fill(Tensor([20, 127009, 20],"int32"), Tensor([20, 127009, 20],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([20, 127009, 20],"int32"), Tensor([20, 127009, 20],"bool"), 0, ) 	 101607200 	 1000 	 0.38408708572387695 	 0.6527516841888428 	 0.09787154197692871 	 0.22174572944641113 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:15:49.448634 test begin: paddle.masked_fill(Tensor([20, 60, 42337],"int32"), Tensor([20, 60, 42337],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([20, 60, 42337],"int32"), Tensor([20, 60, 42337],"bool"), 0, ) 	 101608800 	 1000 	 0.380108118057251 	 0.6537411212921143 	 0.09689497947692871 	 0.22310805320739746 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:15:52.698605 test begin: paddle.masked_fill(Tensor([28225, 60, 30],"int32"), Tensor([28225, 60, 30],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([28225, 60, 30],"int32"), Tensor([28225, 60, 30],"bool"), 0, ) 	 101610000 	 1000 	 0.3842155933380127 	 0.6588211059570312 	 0.09917783737182617 	 0.22146129608154297 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:15:55.960823 test begin: paddle.masked_fill(Tensor([30, 56449, 30],"int32"), Tensor([30, 56449, 30],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([30, 56449, 30],"int32"), Tensor([30, 56449, 30],"bool"), 0, ) 	 101608200 	 1000 	 0.3830220699310303 	 0.6519985198974609 	 0.09794449806213379 	 0.22148466110229492 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:15:59.233099 test begin: paddle.masked_fill(Tensor([30, 60, 28225],"int32"), Tensor([30, 60, 28225],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([30, 60, 28225],"int32"), Tensor([30, 60, 28225],"bool"), 0, ) 	 101610000 	 1000 	 0.3830244541168213 	 0.6537985801696777 	 0.09795093536376953 	 0.22148990631103516 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:16:02.512903 test begin: paddle.masked_fill(Tensor([42337, 60, 20],"int32"), Tensor([42337, 60, 20],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([42337, 60, 20],"int32"), Tensor([42337, 60, 20],"bool"), 0, ) 	 101608800 	 1000 	 0.37891387939453125 	 0.6510565280914307 	 0.09689474105834961 	 0.22163963317871094 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:16:05.726351 test begin: paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([169345, 300],"float32"), ) 	 50839620 	 1000 	 0.4856452941894531 	 0.035620927810668945 	 2.8371810913085938e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:07.305888 test begin: paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([300, 169345],"float32"), ) 	 50839620 	 1000 	 0.6130919456481934 	 0.05005788803100586 	 3.457069396972656e-05 	 6.747245788574219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:09.074570 test begin: paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([169345, 300],"float32"), ) 	 50815540 	 1000 	 0.46206068992614746 	 0.04791879653930664 	 3.7670135498046875e-05 	 8.869171142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:10.585201 test begin: paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([300, 169345],"float32"), ) 	 50815540 	 1000 	 0.5397484302520752 	 0.045699357986450195 	 1.9311904907226562e-05 	 7.510185241699219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:12.268191 test begin: paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([169345, 300],"float32"), ) 	 50819052 	 1000 	 0.4712984561920166 	 0.03492546081542969 	 1.8835067749023438e-05 	 3.743171691894531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:13.834880 test begin: paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([300, 169345],"float32"), ) 	 50819052 	 1000 	 0.4418635368347168 	 0.03463935852050781 	 2.0503997802734375e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:15.318800 test begin: paddle.masked_select(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"bool"), ) 	 101802624 	 1000 	 1.4000098705291748 	 3.138909101486206 	 0.0008697509765625 	 0.003019094467163086 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:23.671390 test begin: paddle.masked_select(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"bool"), ) 	 101669568 	 1000 	 1.4022560119628906 	 3.1333298683166504 	 0.0008635520935058594 	 0.0030219554901123047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:32.139807 test begin: paddle.masked_select(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"bool"), ) 	 101799936 	 1000 	 1.3917808532714844 	 3.1548428535461426 	 0.0008475780487060547 	 0.003011941909790039 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:42.379967 test begin: paddle.masked_select(Tensor([16, 46695, 68],"float32"), Tensor([16, 46695, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 46695, 68],"float32"), Tensor([16, 46695, 68],"bool"), ) 	 101608320 	 1000 	 1.3976490497589111 	 3.127049684524536 	 0.0008668899536132812 	 0.003009319305419922 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:16:51.613450 test begin: paddle.masked_select(Tensor([62, 12096, 68],"float32"), Tensor([62, 12096, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([62, 12096, 68],"float32"), Tensor([62, 12096, 68],"bool"), ) 	 101993472 	 1000 	 1.393263339996338 	 3.1584646701812744 	 0.0008513927459716797 	 0.0030138492584228516 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:17:00.296142 test begin: paddle.masked_select(Tensor([68, 11109, 68],"float32"), Tensor([68, 11109, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([68, 11109, 68],"float32"), Tensor([68, 11109, 68],"bool"), ) 	 102736032 	 1000 	 1.4106724262237549 	 3.189633846282959 	 0.0008766651153564453 	 0.003066539764404297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:17:08.934783 test begin: paddle.masked_select(Tensor([74, 10164, 68],"float32"), Tensor([74, 10164, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([74, 10164, 68],"float32"), Tensor([74, 10164, 68],"bool"), ) 	 102290496 	 1000 	 1.4124653339385986 	 3.161586046218872 	 0.0008630752563476562 	 0.003030061721801758 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:17:17.666519 test begin: paddle.matmul(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), ) 	 67633152 	 1000 	 1.6543231010437012 	 1.6499648094177246 	 1.6416919231414795 	 1.626127004623413 	 1.8454034328460693 	 1.841186285018921 	 0.9429044723510742 	 0.9393010139465332 	 
2025-07-30 16:17:25.795523 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), ) 	 553648128 	 1000 	 8.201957941055298 	 8.20292592048645 	 8.1885826587677 	 8.179723262786865 	 16.404237985610962 	 16.41162872314453 	 8.378936529159546 	 8.384988069534302 	 
2025-07-30 16:18:25.012697 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 388],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 388],"float32"), ) 	 587726848 	 1000 	 31.22489023208618 	 31.187544345855713 	 31.212137937545776 	 31.158602237701416 	 55.39531493186951 	 55.37084484100342 	 28.29573702812195 	 28.29343271255493 	 
2025-07-30 16:21:30.172946 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), ) 	 603979776 	 1000 	 31.3396098613739 	 43.5736448764801 	 0.00010538101196289062 	 8.920917749404907 	 71.88691210746765 	 81.15842294692993 	 0.007719516754150391 	 13.803870677947998 	 
2025-07-30 16:25:31.436990 test begin: paddle.matmul(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 128],"float32"), ) 	 69206016 	 1000 	 1.6440832614898682 	 1.650627613067627 	 1.6311049461364746 	 1.6218655109405518 	 2.6801955699920654 	 2.6769163608551025 	 1.3688881397247314 	 1.369016170501709 	 
2025-07-30 16:25:41.684971 test begin: paddle.matmul(Tensor([1, 97, 4096, 4096],"float32"), Tensor([1, 97, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 97, 4096, 4096],"float32"), Tensor([1, 97, 4096, 128],"float32"), ) 	 1678245888 	 1000 	 23.77951955795288 	 23.771167755126953 	 23.76671314239502 	 23.748115301132202 	 48.577972650527954 	 48.60486698150635 	 24.825717210769653 	 24.840468406677246 	 
2025-07-30 16:28:37.347038 test begin: paddle.matmul(Tensor([10, 23, 499, 3600],"float32"), Tensor([10, 23, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 23, 499, 3600],"float32"), Tensor([10, 23, 3600, 64],"float32"), ) 	 466164000 	 1000 	 6.480929613113403 	 6.491082429885864 	 6.458771467208862 	 6.455338478088379 	 9.909553527832031 	 9.92046570777893 	 5.067920923233032 	 5.0685389041900635 	 
2025-07-30 16:29:18.943109 test begin: paddle.matmul(Tensor([10, 3, 499, 3600],"float32"), Tensor([10, 3, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 3, 499, 3600],"float32"), Tensor([10, 3, 3600, 64],"float32"), ) 	 60804000 	 1000 	 1.4539756774902344 	 1.4498119354248047 	 1.4412472248077393 	 1.4259569644927979 	 1.4047486782073975 	 1.4081614017486572 	 0.7163705825805664 	 0.7193775177001953 	 
2025-07-30 16:29:25.726272 test begin: paddle.matmul(Tensor([10, 8, 177, 3600],"float32"), Tensor([10, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 177, 3600],"float32"), Tensor([10, 8, 3600, 64],"float32"), ) 	 69408000 	 1000 	 1.449293851852417 	 1.4536118507385254 	 1.428433895111084 	 1.4208049774169922 	 1.4787747859954834 	 1.476696491241455 	 0.7569432258605957 	 0.7544057369232178 	 
2025-07-30 16:29:32.703094 test begin: paddle.matmul(Tensor([10, 8, 499, 1273],"float32"), Tensor([10, 8, 1273, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 1273],"float32"), Tensor([10, 8, 1273, 64],"float32"), ) 	 57335920 	 1000 	 0.7823684215545654 	 1.2246897220611572 	 0.7692890167236328 	 0.7485697269439697 	 1.2669172286987305 	 1.2640199661254883 	 0.6479833126068115 	 0.6462626457214355 	 
2025-07-30 16:29:40.319298 test begin: paddle.matmul(Tensor([10, 8, 499, 3600],"float32"), Tensor([10, 8, 3600, 177],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 3600],"float32"), Tensor([10, 8, 3600, 177],"float32"), ) 	 194688000 	 1000 	 4.339256048202515 	 4.334758996963501 	 4.326490879058838 	 4.308581352233887 	 7.677714586257935 	 7.68193793296814 	 3.9237072467803955 	 3.9253427982330322 	 
2025-07-30 16:30:08.928036 test begin: paddle.matmul(Tensor([10, 8, 499, 9923],"float32"), Tensor([10, 8, 9923, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 9923],"float32"), Tensor([10, 8, 9923, 64],"float32"), ) 	 446931920 	 1000 	 5.9769978523254395 	 5.967352628707886 	 5.9642674922943115 	 5.943861722946167 	 9.312081098556519 	 9.306239128112793 	 4.758520603179932 	 4.7547101974487305 	 
2025-07-30 16:30:48.012311 test begin: paddle.matmul(Tensor([1379, 4, 256, 256],"float32"), Tensor([1379, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1379, 4, 256, 256],"float32"), Tensor([1379, 4, 256, 36],"float32"), ) 	 412332032 	 1000 	 5.362022161483765 	 5.367294073104858 	 5.340368032455444 	 5.3314735889434814 	 7.307143449783325 	 7.304211854934692 	 3.7370963096618652 	 3.731485366821289 	 
2025-07-30 16:31:22.503302 test begin: paddle.matmul(Tensor([194, 4, 256, 256],"float32"), Tensor([194, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([194, 4, 256, 256],"float32"), Tensor([194, 4, 256, 36],"float32"), ) 	 58007552 	 1000 	 0.7939462661743164 	 0.7913022041320801 	 0.7813436985015869 	 0.7682745456695557 	 1.0736477375030518 	 1.072556495666504 	 0.548560619354248 	 0.5479378700256348 	 
2025-07-30 16:31:27.381552 test begin: paddle.matmul(Tensor([28, 8, 499, 3600],"float32"), Tensor([28, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([28, 8, 499, 3600],"float32"), Tensor([28, 8, 3600, 64],"float32"), ) 	 454003200 	 1000 	 6.473292350769043 	 6.477461814880371 	 6.460237503051758 	 6.4540581703186035 	 9.703247785568237 	 9.703114748001099 	 4.959001779556274 	 4.958196401596069 	 
2025-07-30 16:32:08.793996 test begin: paddle.matmul(Tensor([4, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([4, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), ) 	 2214592512 	 1000 	 31.29145312309265 	 31.252158164978027 	 31.278581857681274 	 31.228684186935425 	 64.03122305870056 	 64.02979636192322 	 32.72035479545593 	 32.7078275680542 	 
2025-07-30 16:35:59.375242 test begin: paddle.matmul(Tensor([4, 8, 499, 3600],"float32"), Tensor([4, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([4, 8, 499, 3600],"float32"), Tensor([4, 8, 3600, 64],"float32"), ) 	 64857600 	 1000 	 1.4508042335510254 	 1.4506847858428955 	 1.4380474090576172 	 1.4278590679168701 	 1.4375801086425781 	 1.4384055137634277 	 0.7359030246734619 	 0.7335195541381836 	 
2025-07-30 16:36:06.320238 test begin: paddle.matmul(Tensor([512, 11, 256, 256],"float32"), Tensor([512, 11, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 11, 256, 256],"float32"), Tensor([512, 11, 256, 36],"float32"), ) 	 421003264 	 1000 	 5.467395544052124 	 5.463914155960083 	 5.454491853713989 	 5.436217308044434 	 7.453238010406494 	 7.449024677276611 	 3.809699296951294 	 3.8046278953552246 	 
2025-07-30 16:36:40.609940 test begin: paddle.matmul(Tensor([512, 2, 256, 256],"float32"), Tensor([512, 2, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 2, 256, 256],"float32"), Tensor([512, 2, 256, 36],"float32"), ) 	 76546048 	 1000 	 1.0020909309387207 	 1.0044829845428467 	 0.9893519878387451 	 0.9814093112945557 	 1.3710486888885498 	 1.3737893104553223 	 0.7011446952819824 	 0.6999824047088623 	 
2025-07-30 16:36:46.808519 test begin: paddle.matmul(Tensor([512, 4, 256, 256],"float32"), Tensor([512, 4, 256, 97],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 4, 256, 256],"float32"), Tensor([512, 4, 256, 97],"float32"), ) 	 185073664 	 1000 	 2.0091967582702637 	 2.004801034927368 	 1.996450662612915 	 1.981386423110962 	 3.712017059326172 	 3.7089405059814453 	 1.89794921875 	 1.8937206268310547 	 
2025-07-30 16:37:02.180892 test begin: paddle.matmul(Tensor([512, 4, 97, 256],"float32"), Tensor([512, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 4, 97, 256],"float32"), Tensor([512, 4, 256, 36],"float32"), ) 	 69730304 	 1000 	 0.9995989799499512 	 0.9984941482543945 	 0.9867832660675049 	 0.9754037857055664 	 1.2280316352844238 	 1.2265355587005615 	 0.626807451248169 	 0.6279010772705078 	 
2025-07-30 16:37:07.947352 test begin: paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), ) 	 1016064080 	 1000 	 0.01302480697631836 	 0.0036127567291259766 	 5.602836608886719e-05 	 1.9073486328125e-05 	 0.041294097900390625 	 0.05284404754638672 	 4.5299530029296875e-05 	 7.486343383789062e-05 	 combined
2025-07-30 16:37:50.282595 test begin: paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), ) 	 1016064060 	 1000 	 0.004280567169189453 	 0.0036079883575439453 	 9.5367431640625e-06 	 1.8596649169921875e-05 	 0.04094099998474121 	 0.05253148078918457 	 3.218650817871094e-05 	 6.842613220214844e-05 	 combined
2025-07-30 16:38:33.763770 test begin: paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), ) 	 254016060 	 1000 	 0.004275321960449219 	 0.0037238597869873047 	 7.152557373046875e-06 	 1.7404556274414062e-05 	 0.040747880935668945 	 0.052689552307128906 	 2.4318695068359375e-05 	 6.008148193359375e-05 	 combined
2025-07-30 16:38:46.606992 test begin: paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.0042362213134765625 	 0.007032632827758789 	 9.059906005859375e-06 	 2.0742416381835938e-05 	 0.050145626068115234 	 0.052557945251464844 	 9.369850158691406e-05 	 5.7697296142578125e-05 	 combined
2025-07-30 16:39:03.787826 test begin: paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), ) 	 254016080 	 1000 	 0.004305601119995117 	 0.003679037094116211 	 1.0251998901367188e-05 	 1.8835067749023438e-05 	 0.041135549545288086 	 0.05228161811828613 	 3.9577484130859375e-05 	 5.91278076171875e-05 	 combined
2025-07-30 16:39:16.269853 test begin: paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.004715681076049805 	 0.003702402114868164 	 3.62396240234375e-05 	 1.9073486328125e-05 	 0.04090738296508789 	 0.06875300407409668 	 3.695487976074219e-05 	 5.91278076171875e-05 	 combined
2025-07-30 16:39:32.922708 test begin: paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), ) 	 254016120 	 1000 	 0.004508495330810547 	 0.0037114620208740234 	 2.5987625122070312e-05 	 1.7881393432617188e-05 	 0.0411679744720459 	 0.05416107177734375 	 3.910064697265625e-05 	 7.2479248046875e-05 	 combined
2025-07-30 16:39:43.584453 test begin: paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.0042688846588134766 	 0.00394129753112793 	 8.58306884765625e-06 	 7.05718994140625e-05 	 0.041612863540649414 	 0.05203437805175781 	 4.792213439941406e-05 	 5.3882598876953125e-05 	 combined
2025-07-30 16:40:00.504616 test begin: paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), ) 	 1016064120 	 1000 	 0.004305601119995117 	 0.0069653987884521484 	 9.5367431640625e-06 	 2.0503997802734375e-05 	 0.0477297306060791 	 0.06105184555053711 	 4.363059997558594e-05 	 6.961822509765625e-05 	 combined
2025-07-30 16:40:45.090381 test begin: paddle.max(Tensor([416, 50, 10, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 50, 10, 256],"float32"), axis=1, ) 	 53248000 	 1000 	 0.19529080390930176 	 0.16023039817810059 	 0.1835498809814453 	 0.1455376148223877 	 1.1425423622131348 	 1.3946146965026855 	 0.2916731834411621 	 0.2860374450683594 	 
2025-07-30 16:40:48.919441 test begin: paddle.max(Tensor([416, 50, 7, 349],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 50, 7, 349],"float32"), axis=1, ) 	 50814400 	 1000 	 0.198167085647583 	 0.1625816822052002 	 0.18661856651306152 	 0.14624547958374023 	 1.1112449169158936 	 1.3348400592803955 	 0.28330540657043457 	 0.2727165222167969 	 
2025-07-30 16:40:53.966697 test begin: paddle.max(Tensor([416, 69, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 69, 7, 256],"float32"), axis=1, ) 	 51437568 	 1000 	 0.1928844451904297 	 0.16559219360351562 	 0.18120503425598145 	 0.14010381698608398 	 1.09559965133667 	 1.3460557460784912 	 0.27991461753845215 	 0.2763330936431885 	 
2025-07-30 16:40:58.584777 test begin: paddle.max(Tensor([49, 1024, 1024],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([49, 1024, 1024],"float32"), axis=-1, keepdim=True, ) 	 51380224 	 1000 	 0.15544342994689941 	 0.14956116676330566 	 0.1433424949645996 	 0.13590192794799805 	 1.0573623180389404 	 1.2887845039367676 	 0.2701849937438965 	 0.2631995677947998 	 
2025-07-30 16:41:02.068393 test begin: paddle.max(Tensor([512, 50, 7, 284],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 50, 7, 284],"float32"), axis=1, ) 	 50892800 	 1000 	 0.2038261890411377 	 0.15595054626464844 	 0.19213318824768066 	 0.14117670059204102 	 1.1213724613189697 	 1.3353934288024902 	 0.28554725646972656 	 0.27278685569763184 	 
2025-07-30 16:41:07.597928 test begin: paddle.max(Tensor([512, 50, 8, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 50, 8, 256],"float32"), axis=1, ) 	 52428800 	 1000 	 0.19258880615234375 	 0.15725207328796387 	 0.18094611167907715 	 0.1424088478088379 	 1.126739740371704 	 1.381535291671753 	 0.28792238235473633 	 0.28331589698791504 	 
2025-07-30 16:41:11.588132 test begin: paddle.max(Tensor([512, 56, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 56, 7, 256],"float32"), axis=1, ) 	 51380224 	 1000 	 0.19655108451843262 	 0.15392231941223145 	 0.18493938446044922 	 0.13872861862182617 	 1.099184513092041 	 1.3398759365081787 	 0.2809152603149414 	 0.2736790180206299 	 
2025-07-30 16:41:15.248505 test begin: paddle.max(Tensor([568, 50, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([568, 50, 7, 256],"float32"), axis=1, ) 	 50892800 	 1000 	 0.18931031227111816 	 0.15360426902770996 	 0.1775050163269043 	 0.13883185386657715 	 1.0978610515594482 	 1.3329060077667236 	 0.2798326015472412 	 0.2722480297088623 	 
2025-07-30 16:41:18.879269 test begin: paddle.max(Tensor([8, 1024, 6202],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([8, 1024, 6202],"float32"), axis=-1, keepdim=True, ) 	 50806784 	 1000 	 0.15176796913146973 	 0.16372942924499512 	 0.13965320587158203 	 0.15007281303405762 	 1.0544545650482178 	 1.2930817604064941 	 0.27083611488342285 	 0.2634873390197754 	 
2025-07-30 16:41:22.463674 test begin: paddle.max(Tensor([8, 6202, 1024],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([8, 6202, 1024],"float32"), axis=-1, keepdim=True, ) 	 50806784 	 1000 	 0.15402793884277344 	 0.14797592163085938 	 0.13911104202270508 	 0.13420391082763672 	 1.0457563400268555 	 1.280634880065918 	 0.26724696159362793 	 0.2619962692260742 	 
2025-07-30 16:41:26.302733 test begin: paddle.maximum(Tensor([11585, 4386],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([11585, 4386],"float32"), Tensor([1],"float32"), ) 	 50811811 	 1000 	 0.2969081401824951 	 0.30590152740478516 	 0.28646421432495117 	 0.29395008087158203 	 0.740828275680542 	 3.311041831970215 	 0.2519690990447998 	 0.2809934616088867 	 
2025-07-30 16:41:32.655262 test begin: paddle.maximum(Tensor([120961, 420],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([120961, 420],"float32"), Tensor([1],"float32"), ) 	 50803621 	 1000 	 0.2968449592590332 	 0.32308006286621094 	 0.2786526679992676 	 0.2806239128112793 	 0.7424335479736328 	 3.313309669494629 	 0.2520918846130371 	 0.28102946281433105 	 
2025-07-30 16:41:42.586008 test begin: paddle.maximum(Tensor([121539, 418],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([121539, 418],"float32"), Tensor([1],"float32"), ) 	 50803303 	 1000 	 0.29674553871154785 	 0.30594587326049805 	 0.28633642196655273 	 0.2939164638519287 	 0.7421505451202393 	 3.3045527935028076 	 0.25202012062072754 	 0.28213024139404297 	 
2025-07-30 16:41:49.136704 test begin: paddle.maximum(Tensor([14877, 3415],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([14877, 3415],"float32"), Tensor([1],"float32"), ) 	 50804956 	 1000 	 0.29650044441223145 	 0.30445384979248047 	 0.2860739231109619 	 0.2924637794494629 	 0.7407727241516113 	 3.301811933517456 	 0.2519710063934326 	 0.2804694175720215 	 
2025-07-30 16:41:55.747929 test begin: paddle.maximum(Tensor([16121, 3152],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([16121, 3152],"float32"), Tensor([1],"float32"), ) 	 50813393 	 1000 	 0.2965879440307617 	 0.30639052391052246 	 0.2861793041229248 	 0.2909054756164551 	 0.7405819892883301 	 3.3014400005340576 	 0.25191235542297363 	 0.28063201904296875 	 
2025-07-30 16:42:03.254430 test begin: paddle.maximum(Tensor([62643, 811],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([62643, 811],"float32"), Tensor([1],"float32"), ) 	 50803474 	 1000 	 0.29823732376098633 	 0.30469822883605957 	 0.2801826000213623 	 0.2924075126647949 	 0.7420787811279297 	 3.3105788230895996 	 0.2519967555999756 	 0.2809782028198242 	 
2025-07-30 16:42:09.622940 test begin: paddle.mean(Tensor([7573, 11, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7573, 11, 1280],"bfloat16"), axis=1, ) 	 106627840 	 1000 	 0.21017980575561523 	 0.1977529525756836 	 0.1986374855041504 	 0.18092727661132812 	 0.34355926513671875 	 0.45081162452697754 	 0.27356529235839844 	 0.23029708862304688 	 
2025-07-30 16:42:12.828153 test begin: paddle.mean(Tensor([7573, 8, 1678],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7573, 8, 1678],"bfloat16"), axis=1, ) 	 101659952 	 1000 	 0.18507695198059082 	 0.18270206451416016 	 0.17367935180664062 	 0.16738271713256836 	 0.34900498390197754 	 0.44414806365966797 	 0.2847781181335449 	 0.2268834114074707 	 
2025-07-30 16:42:15.922416 test begin: paddle.mean(Tensor([7710, 11, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7710, 11, 1280],"bfloat16"), axis=1, ) 	 108556800 	 1000 	 0.21652841567993164 	 0.21041035652160645 	 0.20515894889831543 	 0.17850351333618164 	 0.3533022403717041 	 0.4589226245880127 	 0.29053592681884766 	 0.23442769050598145 	 
2025-07-30 16:42:19.119515 test begin: paddle.mean(Tensor([7710, 8, 1648],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7710, 8, 1648],"bfloat16"), axis=1, ) 	 101648640 	 1000 	 0.18547511100769043 	 0.17874932289123535 	 0.1737980842590332 	 0.16312623023986816 	 0.3473176956176758 	 0.44634294509887695 	 0.28423452377319336 	 0.22802329063415527 	 
2025-07-30 16:42:22.129874 test begin: paddle.mean(Tensor([8162, 10, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([8162, 10, 1280],"bfloat16"), axis=1, ) 	 104473600 	 1000 	 0.20427823066711426 	 0.1921708583831787 	 0.19274020195007324 	 0.17714309692382812 	 0.344912052154541 	 0.44855737686157227 	 0.2806203365325928 	 0.22916364669799805 	 
2025-07-30 16:42:25.211099 test begin: paddle.mean(Tensor([8162, 8, 1557],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([8162, 8, 1557],"bfloat16"), axis=1, ) 	 101665872 	 1000 	 0.1867198944091797 	 0.22115230560302734 	 0.17528676986694336 	 0.19839715957641602 	 0.3510417938232422 	 0.4626579284667969 	 0.2878868579864502 	 0.2370898723602295 	 
2025-07-30 16:42:28.371203 test begin: paddle.mean(Tensor([9923, 8, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([9923, 8, 1280],"bfloat16"), axis=1, ) 	 101611520 	 1000 	 0.1823117733001709 	 0.1763763427734375 	 0.17074036598205566 	 0.1608881950378418 	 0.35695719718933105 	 0.4536399841308594 	 0.25075387954711914 	 0.23168659210205078 	 
2025-07-30 16:42:31.499652 test begin: paddle.median(Tensor([2, 254016],"float32"), axis=1, mode="min", )
[Prof] paddle.median 	 paddle.median(Tensor([2, 254016],"float32"), axis=1, mode="min", ) 	 508032 	 1000 	 9.929789304733276 	 1.0761725902557373 	 0.20051145553588867 	 1.0573666095733643 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:42:42.858538 test begin: paddle.median(Tensor([254016],"int64"), )
W0730 16:42:48.799752 154884 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.median 	 paddle.median(Tensor([254016],"int64"), ) 	 254016 	 1000 	 5.929084777832031 	 0.17721867561340332 	 0.24977397918701172 	 0.0071523189544677734 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:42:49.027262 test begin: paddle.median(Tensor([5080, 100],"float32"), axis=1, mode="min", )
[Prof] paddle.median 	 paddle.median(Tensor([5080, 100],"float32"), axis=1, mode="min", ) 	 508000 	 1000 	 2.716935396194458 	 0.04344606399536133 	 0.07041716575622559 	 0.02460169792175293 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 16:42:52.017917 test begin: paddle.median(Tensor([508032],"float32"), )
[Prof] paddle.median 	 paddle.median(Tensor([508032],"float32"), ) 	 508032 	 1000 	 6.89480447769165 	 0.16343998908996582 	 0.3887777328491211 	 0.008507966995239258 	 0.5198888778686523 	 0.15844082832336426 	 0.0442502498626709 	 7.295608520507812e-05 	 combined
2025-07-30 16:42:59.775757 test begin: paddle.min(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.2924051284790039 	 0.15437650680541992 	 0.00018215179443359375 	 0.13935518264770508 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:01.891488 test begin: paddle.min(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.3419332504272461 	 0.1547865867614746 	 0.00024580955505371094 	 0.0791022777557373 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:05.296310 test begin: paddle.min(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402412 	 1000 	 1.1874196529388428 	 0.1609804630279541 	 0.0011446475982666016 	 0.08226776123046875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:08.870993 test begin: paddle.min(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 8.223243474960327 	 0.15941452980041504 	 0.008083105087280273 	 0.08077859878540039 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:24.423558 test begin: paddle.min(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.42548632621765137 	 0.3362691402435303 	 0.0003936290740966797 	 0.3209977149963379 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:26.979150 test begin: paddle.min(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.19893741607666016 	 0.15434789657592773 	 0.00016927719116210938 	 0.1393272876739502 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:29.007313 test begin: paddle.min(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 8.204999208450317 	 0.15955138206481934 	 0.008078336715698242 	 0.08213496208190918 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:44.354942 test begin: paddle.min(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402007 	 1000 	 0.2212390899658203 	 0.21046686172485352 	 0.00018715858459472656 	 0.10754561424255371 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 16:43:46.457316 test begin: paddle.min(Tensor([64, 1, 28, 28351],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1, 28, 28351],"float32"), ) 	 50804992 	 1000 	 0.15201711654663086 	 0.15327215194702148 	 0.07766032218933105 	 0.07830142974853516 	 1.0451455116271973 	 1.2549843788146973 	 0.21375632286071777 	 0.21415925025939941 	 
2025-07-30 16:43:49.933459 test begin: paddle.min(Tensor([64, 1, 28351, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1, 28351, 28],"float32"), ) 	 50804992 	 1000 	 0.1520674228668213 	 0.15309643745422363 	 0.07768368721008301 	 0.07821035385131836 	 1.0464575290679932 	 1.249410629272461 	 0.2137613296508789 	 0.2127552032470703 	 
2025-07-30 16:43:53.464129 test begin: paddle.min(Tensor([64, 1013, 28, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1013, 28, 28],"float32"), ) 	 50828288 	 1000 	 0.1519777774810791 	 0.15447306632995605 	 0.07764363288879395 	 0.07950806617736816 	 1.0481376647949219 	 1.2497007846832275 	 0.21384167671203613 	 0.21275067329406738 	 
2025-07-30 16:43:56.955903 test begin: paddle.min(Tensor([64801, 1, 28, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64801, 1, 28, 28],"float32"), ) 	 50803984 	 1000 	 0.15203261375427246 	 0.15320920944213867 	 0.07761979103088379 	 0.0782477855682373 	 1.047682523727417 	 1.2531697750091553 	 0.21376919746398926 	 0.21389436721801758 	 
2025-07-30 16:44:00.459915 test begin: paddle.minimum(Tensor([13, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([13, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980628 	 1000 	 3.796388626098633 	 4.239539861679077 	 3.7859280109405518 	 2.2263569831848145 	 18.950071573257446 	 47.20072150230408 	 4.833686828613281 	 2.188544750213623 	 
2025-07-30 16:45:26.880770 test begin: paddle.minimum(Tensor([13, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([13, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803228 	 1000 	 3.776472806930542 	 4.087692499160767 	 3.7661619186401367 	 2.0907440185546875 	 32.41301774978638 	 46.75102758407593 	 8.271257162094116 	 2.1695096492767334 	 
2025-07-30 16:47:05.934896 test begin: paddle.minimum(Tensor([16, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([16, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980967 	 1000 	 4.668126106262207 	 5.043819189071655 	 4.657721757888794 	 2.579782724380493 	 23.01933979988098 	 57.39606499671936 	 5.8774333000183105 	 2.6589229106903076 	 
2025-07-30 16:48:50.872842 test begin: paddle.minimum(Tensor([16, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([16, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803234 	 1000 	 4.649025917053223 	 5.031965255737305 	 4.638662338256836 	 2.568878650665283 	 38.67599582672119 	 58.8220489025116 	 9.868175745010376 	 2.7288594245910645 	 
2025-07-30 16:50:53.809923 test begin: paddle.minimum(Tensor([9, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([9, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980176 	 1000 	 2.6279215812683105 	 2.8605880737304688 	 2.609874963760376 	 2.819852113723755 	 13.341840505599976 	 32.09639072418213 	 3.4056332111358643 	 2.5228731632232666 	 
2025-07-30 16:51:55.056069 test begin: paddle.minimum(Tensor([9, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([9, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803220 	 1000 	 2.612353563308716 	 2.8254432678222656 	 2.6020097732543945 	 2.8080265522003174 	 23.623815536499023 	 32.02677083015442 	 6.031759262084961 	 2.513544797897339 	 
2025-07-30 16:53:05.391276 test begin: paddle.mm(Tensor([1838, 6, 144, 144],"float32"), Tensor([1838, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([1838, 6, 144, 144],"float32"), Tensor([1838, 6, 144, 32],"float32"), ) 	 279493632 	 1000 	 6.073594093322754 	 6.073434352874756 	 6.060718774795532 	 6.0497729778289795 	 9.513261556625366 	 9.510019063949585 	 4.8609619140625 	 4.860686779022217 	 
2025-07-30 16:53:42.186759 test begin: paddle.mm(Tensor([2048, 2, 144, 144],"float32"), Tensor([2048, 2, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 2, 144, 144],"float32"), Tensor([2048, 2, 144, 32],"float32"), ) 	 103809024 	 1000 	 2.2689638137817383 	 2.2634711265563965 	 2.2563083171844482 	 2.2303709983825684 	 3.548013925552368 	 3.5516915321350098 	 1.8149571418762207 	 1.8159205913543701 	 
2025-07-30 16:53:56.312332 test begin: paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 29],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 29],"float32"), ) 	 306118656 	 1000 	 6.7559216022491455 	 6.771490097045898 	 6.735391855239868 	 6.737540245056152 	 10.328431606292725 	 10.329972982406616 	 5.277555465698242 	 5.278528213500977 	 
2025-07-30 16:54:39.611474 test begin: paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), ) 	 311427072 	 1000 	 6.7622764110565186 	 6.758727550506592 	 6.749216318130493 	 6.735494375228882 	 10.590350866317749 	 10.589725255966187 	 5.411292552947998 	 5.410722255706787 	 
2025-07-30 16:55:21.129918 test begin: paddle.mm(Tensor([2048, 6, 29, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 29, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), ) 	 107937792 	 1000 	 3.3861310482025146 	 3.3888254165649414 	 3.3733673095703125 	 3.3649585247039795 	 3.745957136154175 	 3.741363763809204 	 1.914046049118042 	 1.9110257625579834 	 
2025-07-30 16:55:39.326954 test begin: paddle.mm(Tensor([2757, 4, 144, 144],"float32"), Tensor([2757, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2757, 4, 144, 144],"float32"), Tensor([2757, 4, 144, 32],"float32"), ) 	 279493632 	 1000 	 6.076300382614136 	 6.072261810302734 	 6.063326597213745 	 6.049148082733154 	 9.515742778778076 	 9.51504373550415 	 4.86355447769165 	 4.862060546875 	 
2025-07-30 16:56:17.165095 test begin: paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 1, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 1, 144, 32],"float32"), ) 	 97320960 	 1000 	 2.1423444747924805 	 2.143458843231201 	 2.129586935043335 	 2.1192288398742676 	 3.3403639793395996 	 3.34519362449646 	 1.7060887813568115 	 1.7112069129943848 	 
2025-07-30 16:56:30.170156 test begin: paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), ) 	 150405120 	 1000 	 9.570922136306763 	 9.924953937530518 	 8.58306884765625e-05 	 5.069915294647217 	 14.671624898910522 	 14.378217935562134 	 0.0011799335479736328 	 4.890362977981567 	 
2025-07-30 16:57:24.415730 test begin: paddle.mm(Tensor([3840, 3, 144, 144],"float32"), Tensor([3840, 3, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 3, 144, 144],"float32"), Tensor([3840, 3, 144, 32],"float32"), ) 	 291962880 	 1000 	 6.343012094497681 	 6.343759775161743 	 6.329927682876587 	 6.314395427703857 	 9.931753635406494 	 9.936201572418213 	 5.077053070068359 	 5.076249837875366 	 
2025-07-30 16:58:02.960999 test begin: paddle.mm(Tensor([3840, 4, 144, 144],"float32"), Tensor([3840, 4, 144, 23],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 4, 144, 144],"float32"), Tensor([3840, 4, 144, 23],"float32"), ) 	 369377280 	 1000 	 8.447403907775879 	 8.443120956420898 	 8.434513568878174 	 8.407382488250732 	 11.959934949874878 	 11.968075037002563 	 6.109036684036255 	 6.117456912994385 	 
2025-07-30 16:58:51.500683 test begin: paddle.mm(Tensor([3840, 4, 23, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 4, 23, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), ) 	 121651200 	 1000 	 4.233299016952515 	 4.234529972076416 	 4.220504999160767 	 4.211272239685059 	 4.232479095458984 	 4.231917858123779 	 2.162642478942871 	 2.1636884212493896 	 
2025-07-30 16:59:10.710644 test begin: paddle.mm(Tensor([409, 6, 144, 144],"float32"), Tensor([409, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([409, 6, 144, 144],"float32"), Tensor([409, 6, 144, 32],"float32"), ) 	 62194176 	 1000 	 1.3691847324371338 	 1.3707420825958252 	 1.3486034870147705 	 1.3378303050994873 	 2.1469168663024902 	 2.1468265056610107 	 1.0969321727752686 	 1.0981945991516113 	 
2025-07-30 16:59:19.117693 test begin: paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 1, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 1, 144, 32],"float32"), ) 	 103809024 	 1000 	 2.266918420791626 	 2.284527063369751 	 2.2536332607269287 	 2.2410523891448975 	 3.5496065616607666 	 3.5453362464904785 	 1.8131122589111328 	 1.81239652633667 	 
2025-07-30 16:59:34.229453 test begin: paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), ) 	 160432128 	 1000 	 10.230182886123657 	 10.59678030014038 	 7.796287536621094e-05 	 5.409922361373901 	 15.62099575996399 	 15.339914560317993 	 0.0012695789337158203 	 5.221424579620361 	 
2025-07-30 17:00:30.095590 test begin: paddle.mm(Tensor([4096, 3, 144, 144],"float32"), Tensor([4096, 3, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 3, 144, 144],"float32"), Tensor([4096, 3, 144, 32],"float32"), ) 	 311427072 	 1000 	 6.751924991607666 	 6.760388374328613 	 6.738935947418213 	 6.727321624755859 	 10.59678316116333 	 10.587697267532349 	 5.4168994426727295 	 5.408000946044922 	 
2025-07-30 13:31:50.402340 test begin: paddle.mm(Tensor([4096, 4, 144, 144],"float32"), Tensor([4096, 4, 144, 22],"float32"), )
W0730 13:31:57.941622  2316 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 4, 144, 144],"float32"), Tensor([4096, 4, 144, 22],"float32"), ) 	 391643136 	 1000 	 8.984151601791382 	 8.982959747314453 	 8.966453075408936 	 8.958125829696655 	 12.725361347198486 	 12.725522994995117 	 6.502660751342773 	 6.502558469772339 	 
2025-07-30 13:32:43.600093 test begin: paddle.mm(Tensor([4096, 4, 22, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 4, 22, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), ) 	 127401984 	 1000 	 4.491099119186401 	 4.493491172790527 	 4.477586507797241 	 4.4635045528411865 	 4.490689754486084 	 4.490498781204224 	 2.294626474380493 	 2.2944583892822266 	 
2025-07-30 13:33:03.982592 test begin: paddle.mm(Tensor([613, 4, 144, 144],"float32"), Tensor([613, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([613, 4, 144, 144],"float32"), Tensor([613, 4, 144, 32],"float32"), ) 	 62143488 	 1000 	 1.3678860664367676 	 1.3674185276031494 	 1.354074478149414 	 1.3438496589660645 	 2.1372904777526855 	 2.1372604370117188 	 1.0920603275299072 	 1.0920023918151855 	 
2025-07-30 13:33:12.261272 test begin: paddle.mod(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4487605094909668 	 0.44811058044433594 	 0.43853211402893066 	 0.43563079833984375 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:15.270388 test begin: paddle.mod(Tensor([10, 5080321],"int32"), Tensor([10, 5080321],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([10, 5080321],"int32"), Tensor([10, 5080321],"int32"), ) 	 101606420 	 1000 	 0.4510843753814697 	 0.44954681396484375 	 0.4408271312713623 	 0.43807363510131836 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:19.043906 test begin: paddle.mod(Tensor([1270081, 2, 4, 5],"int32"), Tensor([1270081, 2, 4, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([1270081, 2, 4, 5],"int32"), Tensor([1270081, 2, 4, 5],"int32"), ) 	 101606480 	 1000 	 0.45099496841430664 	 0.44950079917907715 	 0.44095611572265625 	 0.4380781650543213 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:22.874569 test begin: paddle.mod(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.44851207733154297 	 0.4470655918121338 	 0.4317355155944824 	 0.4294872283935547 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:25.829066 test begin: paddle.mod(Tensor([2540161, 20],"int32"), Tensor([2540161, 20],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([2540161, 20],"int32"), Tensor([2540161, 20],"int32"), ) 	 101606440 	 1000 	 0.4517993927001953 	 0.4494612216949463 	 0.4306948184967041 	 0.43727707862854004 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:29.613063 test begin: paddle.mod(Tensor([6, 2, 4, 1058401],"int32"), Tensor([6, 2, 4, 1058401],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 2, 4, 1058401],"int32"), Tensor([6, 2, 4, 1058401],"int32"), ) 	 101606496 	 1000 	 0.45099878311157227 	 0.4495973587036133 	 0.4337739944458008 	 0.4319264888763428 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:33.529609 test begin: paddle.mod(Tensor([6, 2, 846721, 5],"int32"), Tensor([6, 2, 846721, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 2, 846721, 5],"int32"), Tensor([6, 2, 846721, 5],"int32"), ) 	 101606520 	 1000 	 0.4510166645050049 	 0.6891524791717529 	 0.43378114700317383 	 0.4374372959136963 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:39.982780 test begin: paddle.mod(Tensor([6, 423361, 4, 5],"int32"), Tensor([6, 423361, 4, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 423361, 4, 5],"int32"), Tensor([6, 423361, 4, 5],"int32"), ) 	 101606640 	 1000 	 0.45304036140441895 	 0.44951295852661133 	 0.44060206413269043 	 0.43731021881103516 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:43.798514 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), -1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), -1, ) 	 240 	 1000 	 8.554078578948975 	 0.019349336624145508 	 0.00016021728515625 	 6.365776062011719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:33:52.475422 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), -1, keepdim=True, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), -1, keepdim=True, ) 	 240 	 1000 	 8.550428867340088 	 0.01747584342956543 	 0.00022101402282714844 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:01.115384 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), 1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), 1, ) 	 240 	 1000 	 11.011033058166504 	 0.04381394386291504 	 0.00010395050048828125 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:12.274633 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), -1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), -1, ) 	 240 	 1000 	 10.911310195922852 	 0.02714395523071289 	 0.00012373924255371094 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:23.292334 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), -1, keepdim=True, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), -1, keepdim=True, ) 	 240 	 1000 	 10.801371574401855 	 0.025863170623779297 	 0.00012111663818359375 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:34.199093 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), 1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), 1, ) 	 240 	 1000 	 8.701234579086304 	 0.043630361557006836 	 0.00013899803161621094 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:43.019712 test begin: paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018100 	 1000 	 0.009025096893310547 	 0.005950927734375 	 1.71661376953125e-05 	 2.09808349609375e-05 	 0.04037904739379883 	 0.05406999588012695 	 5.3882598876953125e-05 	 5.984306335449219e-05 	 
2025-07-30 13:34:53.681255 test begin: paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017680 	 1000 	 0.008521318435668945 	 0.005915403366088867 	 2.3365020751953125e-05 	 2.0503997802734375e-05 	 0.04023241996765137 	 0.0540468692779541 	 4.410743713378906e-05 	 6.270408630371094e-05 	 
2025-07-30 13:35:04.262635 test begin: paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017200 	 1000 	 0.00824284553527832 	 0.006022930145263672 	 2.8133392333984375e-05 	 2.2411346435546875e-05 	 0.04044842720031738 	 0.05656766891479492 	 5.602836608886719e-05 	 7.915496826171875e-05 	 
2025-07-30 13:35:16.217046 test begin: paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018800 	 1000 	 0.008391618728637695 	 0.006056308746337891 	 1.2159347534179688e-05 	 2.5033950805664062e-05 	 0.040119171142578125 	 0.05490517616271973 	 5.7697296142578125e-05 	 7.033348083496094e-05 	 
2025-07-30 13:35:26.550142 test begin: paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254020200 	 1000 	 0.008278608322143555 	 0.010083436965942383 	 8.821487426757812e-06 	 2.765655517578125e-05 	 0.04763054847717285 	 0.07846736907958984 	 3.147125244140625e-05 	 6.365776062011719e-05 	 
2025-07-30 13:35:39.697525 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.0072786808013916016 	 0.004689455032348633 	 9.298324584960938e-06 	 2.2411346435546875e-05 	 0.04022359848022461 	 0.053804874420166016 	 3.1948089599609375e-05 	 4.124641418457031e-05 	 
2025-07-30 13:35:50.227959 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.0077266693115234375 	 0.0058596134185791016 	 1.0967254638671875e-05 	 2.3126602172851562e-05 	 0.0398406982421875 	 0.05428194999694824 	 4.124641418457031e-05 	 5.698204040527344e-05 	 
2025-07-30 13:36:01.051141 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.0073239803314208984 	 0.0046558380126953125 	 1.7642974853515625e-05 	 2.1696090698242188e-05 	 0.04015326499938965 	 0.054113149642944336 	 3.0994415283203125e-05 	 5.1021575927734375e-05 	 
2025-07-30 13:36:11.778444 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.013018369674682617 	 0.010038375854492188 	 4.076957702636719e-05 	 2.1457672119140625e-05 	 0.047067880630493164 	 0.05874204635620117 	 4.5299530029296875e-05 	 8.702278137207031e-05 	 
2025-07-30 13:36:24.075742 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.007232666015625 	 0.0046443939208984375 	 1.0251998901367188e-05 	 1.9788742065429688e-05 	 0.040087223052978516 	 0.05465126037597656 	 2.9802322387695312e-05 	 6.508827209472656e-05 	 
2025-07-30 13:36:37.564613 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.012854814529418945 	 0.010014057159423828 	 1.4066696166992188e-05 	 2.2172927856445312e-05 	 0.05008244514465332 	 0.06044816970825195 	 6.270408630371094e-05 	 5.602836608886719e-05 	 
2025-07-30 13:36:48.972736 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.007168769836425781 	 0.004618406295776367 	 9.298324584960938e-06 	 1.9550323486328125e-05 	 0.04011106491088867 	 0.05380582809448242 	 3.0517578125e-05 	 5.555152893066406e-05 	 
2025-07-30 13:36:59.503133 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.012939453125 	 0.01008915901184082 	 4.100799560546875e-05 	 2.09808349609375e-05 	 0.04722118377685547 	 0.06165337562561035 	 2.384185791015625e-05 	 5.698204040527344e-05 	 
2025-07-30 13:37:12.549901 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.0074160099029541016 	 0.005134105682373047 	 2.2411346435546875e-05 	 9.608268737792969e-05 	 0.05821943283081055 	 0.05977225303649902 	 5.125999450683594e-05 	 0.00010228157043457031 	 
2025-07-30 13:37:25.197160 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007718801498413086 	 0.005841493606567383 	 1.5735626220703125e-05 	 2.4080276489257812e-05 	 0.04044198989868164 	 0.05381464958190918 	 5.4836273193359375e-05 	 5.507469177246094e-05 	 
2025-07-30 13:37:36.566295 test begin: paddle.multigammaln(Tensor([10, 2540161],"float64"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([10, 2540161],"float64"), 2, ) 	 25401610 	 1000 	 2.9572508335113525 	 2.803571939468384 	 0.5035192966461182 	 0.5727705955505371 	 4.037620306015015 	 3.6732137203216553 	 1.032658576965332 	 0.7502963542938232 	 
2025-07-30 13:37:51.232181 test begin: paddle.multigammaln(Tensor([10, 5080321],"float32"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([10, 5080321],"float32"), 2, ) 	 50803210 	 1000 	 2.405705213546753 	 2.584019422531128 	 0.40999603271484375 	 0.5284781455993652 	 3.4612648487091064 	 3.987142562866211 	 0.8850476741790771 	 0.8147737979888916 	 
2025-07-30 13:38:05.437056 test begin: paddle.multigammaln(Tensor([1270081, 20],"float64"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([1270081, 20],"float64"), 2, ) 	 25401620 	 1000 	 2.954575538635254 	 2.801739454269409 	 0.5029909610748291 	 0.5727269649505615 	 4.035274505615234 	 3.671009063720703 	 1.0319535732269287 	 0.7499532699584961 	 
2025-07-30 13:38:20.080061 test begin: paddle.multigammaln(Tensor([2540161, 20],"float32"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([2540161, 20],"float32"), 2, ) 	 50803220 	 1000 	 2.4039249420166016 	 2.5856964588165283 	 0.4097418785095215 	 0.5283684730529785 	 3.458982229232788 	 3.9866466522216797 	 0.8846385478973389 	 0.8146755695343018 	 
2025-07-30 13:38:35.068646 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([127, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([127, 1],"int32"), ) 	 101606535 	 1000 	 0.4663863182067871 	 5.1581196784973145 	 5.0067901611328125e-05 	 0.0001513957977294922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:38:44.089004 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), ) 	 101607009 	 1000 	 2.0833022594451904 	 16.77417826652527 	 0.0001304149627685547 	 0.00022268295288085938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:39:06.866121 test begin: paddle.multiplex(inputs=list[Tensor([7, 7257601],"float32"),Tensor([7, 7257601],"float32"),], index=Tensor([6, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([7, 7257601],"float32"),Tensor([7, 7257601],"float32"),], index=Tensor([6, 1],"int32"), ) 	 101606420 	 1000 	 0.3356020450592041 	 0.4610595703125 	 0.00028634071350097656 	 0.0002894401550292969 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:39:10.581192 test begin: paddle.multiply(Tensor([298, 872, 14, 14],"float32"), Tensor([298, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([298, 872, 14, 14],"float32"), Tensor([298, 872, 1, 1],"float32"), ) 	 51191632 	 1000 	 0.296597957611084 	 0.3071727752685547 	 0.28568577766418457 	 0.2945713996887207 	 0.8798463344573975 	 0.9118227958679199 	 0.44951391220092773 	 0.3104560375213623 	 
2025-07-30 13:39:14.570141 test begin: paddle.multiply(Tensor([512, 507, 14, 14],"float32"), Tensor([512, 507, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 507, 14, 14],"float32"), Tensor([512, 507, 1, 1],"float32"), ) 	 51138048 	 1000 	 0.2963404655456543 	 0.3068108558654785 	 0.28545570373535156 	 0.2942330837249756 	 0.8794806003570557 	 0.9111590385437012 	 0.44946813583374023 	 0.31017017364501953 	 
2025-07-30 13:39:18.573414 test begin: paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 1],"float32"), ) 	 56700928 	 1000 	 0.32775378227233887 	 0.3398256301879883 	 0.31700897216796875 	 0.3272879123687744 	 0.896613597869873 	 1.0296647548675537 	 0.45818090438842773 	 0.35059356689453125 	 
2025-07-30 13:39:22.958748 test begin: paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 9],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 9],"float32"), ) 	 60272640 	 1000 	 0.3380405902862549 	 0.35623669624328613 	 0.3272366523742676 	 0.3424232006072998 	 0.8713834285736084 	 1.0395874977111816 	 0.44525575637817383 	 0.35399627685546875 	 
2025-07-30 13:39:27.401844 test begin: paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 1, 1],"float32"), ) 	 56700928 	 1000 	 0.32776308059692383 	 0.33998775482177734 	 0.31704282760620117 	 0.3237454891204834 	 0.8967864513397217 	 1.029808759689331 	 0.4582650661468506 	 0.3506429195404053 	 
2025-07-30 13:39:33.747513 test begin: paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 9, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 9, 1],"float32"), ) 	 60272640 	 1000 	 0.338090181350708 	 0.5935060977935791 	 0.3273482322692871 	 0.3360157012939453 	 0.933006763458252 	 1.1880552768707275 	 0.4767165184020996 	 0.40456652641296387 	 
2025-07-30 13:39:40.348664 test begin: paddle.multiply(x=Tensor([128, 127, 56, 56],"float32"), y=Tensor([128, 127, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 127, 56, 56],"float32"), y=Tensor([128, 127, 1, 1],"float32"), ) 	 50995072 	 1000 	 0.29580020904541016 	 0.3104426860809326 	 0.2848086357116699 	 0.296398401260376 	 0.7415487766265869 	 0.9042410850524902 	 0.3788597583770752 	 0.30788207054138184 	 
2025-07-30 13:39:44.184109 test begin: paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 1, 1],"float32"), ) 	 51408896 	 1000 	 0.2985093593597412 	 0.3128998279571533 	 0.2874565124511719 	 0.30078768730163574 	 0.7461185455322266 	 0.9123876094818115 	 0.38120055198669434 	 0.3106365203857422 	 
2025-07-30 13:39:48.090925 test begin: paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 32, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 32, 1],"float32"), ) 	 52297728 	 1000 	 0.3015117645263672 	 0.31579136848449707 	 0.29042935371398926 	 0.3001854419708252 	 0.8615133762359619 	 1.0900647640228271 	 0.44005775451660156 	 0.3712930679321289 	 
2025-07-30 13:39:52.365939 test begin: paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 1],"float32"), ) 	 51408896 	 1000 	 0.29856085777282715 	 0.31293559074401855 	 0.2873702049255371 	 0.30077552795410156 	 0.7461519241333008 	 0.9123976230621338 	 0.3812570571899414 	 0.31064271926879883 	 
2025-07-30 13:39:56.265192 test begin: paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 32],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 32],"float32"), ) 	 52297728 	 1000 	 0.30127382278442383 	 0.31731176376342773 	 0.2903587818145752 	 0.30342841148376465 	 0.785059928894043 	 0.918492317199707 	 0.40111207962036133 	 0.3127448558807373 	 
2025-07-30 13:40:00.210760 test begin: paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 1, 1],"float32"), ) 	 51412992 	 1000 	 0.2985825538635254 	 0.311948299407959 	 0.2876403331756592 	 0.2998087406158447 	 0.7487688064575195 	 0.9129760265350342 	 0.3825702667236328 	 0.31082630157470703 	 
2025-07-30 13:40:04.076158 test begin: paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 28, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 28, 1],"float32"), ) 	 52297728 	 1000 	 0.3015129566192627 	 0.31226229667663574 	 0.2905545234680176 	 0.30022716522216797 	 0.8610038757324219 	 1.0889911651611328 	 0.43991518020629883 	 0.37081289291381836 	 
2025-07-30 13:40:08.310872 test begin: paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 1],"float32"), ) 	 51412992 	 1000 	 0.2985990047454834 	 0.31482720375061035 	 0.2875649929046631 	 0.2953619956970215 	 0.7489123344421387 	 0.9130065441131592 	 0.38261961936950684 	 0.3108823299407959 	 
2025-07-30 13:40:12.177490 test begin: paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 28],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 28],"float32"), ) 	 52297728 	 1000 	 0.3013782501220703 	 0.317824125289917 	 0.29036974906921387 	 0.3043496608734131 	 1.0076425075531006 	 0.9228301048278809 	 0.5148334503173828 	 0.31418609619140625 	 
2025-07-30 13:40:16.351878 test begin: paddle.multiply(x=Tensor([64, 256, 56, 56],"float32"), y=Tensor([64, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([64, 256, 56, 56],"float32"), y=Tensor([64, 256, 1, 1],"float32"), ) 	 51396608 	 1000 	 0.2985711097717285 	 0.3114497661590576 	 0.287487268447876 	 0.299346923828125 	 0.7470464706420898 	 0.9109797477722168 	 0.38167810440063477 	 0.31014442443847656 	 
2025-07-30 13:40:20.268940 test begin: paddle.multiply(x=Tensor([73, 224, 56, 56],"float32"), y=Tensor([73, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([73, 224, 56, 56],"float32"), y=Tensor([73, 224, 1, 1],"float32"), ) 	 51296224 	 1000 	 0.2980926036834717 	 0.3108830451965332 	 0.28713250160217285 	 0.2985193729400635 	 0.7459731101989746 	 0.9093883037567139 	 0.38117527961730957 	 0.3096022605895996 	 
2025-07-30 13:40:24.405933 test begin: paddle.mv(Tensor([1411201, 36],"float32"), Tensor([36],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([1411201, 36],"float32"), Tensor([36],"float32"), ) 	 50803272 	 1000 	 0.19820952415466309 	 0.1947627067565918 	 0.18629765510559082 	 0.17630910873413086 	 0.49584460258483887 	 0.4170553684234619 	 0.16862869262695312 	 0.1418929100036621 	 
2025-07-30 13:40:26.579416 test begin: paddle.mv(Tensor([254017, 100],"float64"), Tensor([100],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([254017, 100],"float64"), Tensor([100],"float64"), ) 	 25401800 	 1000 	 0.15976333618164062 	 0.15594887733459473 	 0.14798974990844727 	 0.13964486122131348 	 0.335970401763916 	 0.33003973960876465 	 0.11432147026062012 	 0.1123342514038086 	 
2025-07-30 13:40:28.128661 test begin: paddle.mv(Tensor([3, 16934401],"float32"), Tensor([16934401],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([3, 16934401],"float32"), Tensor([16934401],"float32"), ) 	 67737604 	 1000 	 0.2375199794769287 	 0.23465633392333984 	 0.12135744094848633 	 0.11987590789794922 	 0.629960298538208 	 0.6087310314178467 	 0.3220338821411133 	 0.3108656406402588 	 
2025-07-30 13:40:30.998446 test begin: paddle.mv(Tensor([3, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([3, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 203212804 	 1000 	 0.676400899887085 	 0.6771712303161621 	 0.3455841541290283 	 0.34606504440307617 	 1.8698506355285645 	 1.8017849922180176 	 0.9554998874664307 	 0.9206175804138184 	 
2025-07-30 13:40:44.207059 test begin: paddle.mv(Tensor([5, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([5, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 152409606 	 1000 	 0.9537656307220459 	 0.9348969459533691 	 0.4873666763305664 	 0.4776787757873535 	 2.408522605895996 	 2.4087984561920166 	 1.2306313514709473 	 1.230896234512329 	 
2025-07-30 13:40:54.687335 test begin: paddle.mv(Tensor([5, 5080321],"float64"), Tensor([5080321],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([5, 5080321],"float64"), Tensor([5080321],"float64"), ) 	 30481926 	 1000 	 0.23194408416748047 	 0.22381067276000977 	 0.11864399909973145 	 0.11431622505187988 	 0.49170470237731934 	 0.49236011505126953 	 0.25113844871520996 	 0.251539945602417 	 
2025-07-30 13:40:56.754494 test begin: paddle.mv(Tensor([64, 396901],"float64"), Tensor([396901],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([64, 396901],"float64"), Tensor([396901],"float64"), ) 	 25798565 	 1000 	 0.1561722755432129 	 0.15529608726501465 	 0.07974553108215332 	 0.07931375503540039 	 0.32604122161865234 	 0.3298192024230957 	 0.1665339469909668 	 0.1684741973876953 	 
2025-07-30 13:40:58.299118 test begin: paddle.mv(Tensor([793801, 32],"float64"), Tensor([32],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([793801, 32],"float64"), Tensor([32],"float64"), ) 	 25401664 	 1000 	 0.17270159721374512 	 0.16240453720092773 	 0.16107940673828125 	 0.14286351203918457 	 0.3354377746582031 	 0.3356950283050537 	 0.11420917510986328 	 0.11423349380493164 	 
2025-07-30 13:40:59.843885 test begin: paddle.nan_to_num(Tensor([148, 114422, 3],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([148, 114422, 3],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803368 	 1000 	 3.006802797317505 	 0.29885149002075195 	 0.2794985771179199 	 0.28432393074035645 	 1.2720446586608887 	 1.159799575805664 	 0.4333162307739258 	 0.2370455265045166 	 
2025-07-30 13:41:10.140039 test begin: paddle.nan_to_num(Tensor([148, 5, 68653],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([148, 5, 68653],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803220 	 1000 	 3.007085084915161 	 0.29781293869018555 	 0.2794067859649658 	 0.28456544876098633 	 1.2721226215362549 	 1.1591966152191162 	 0.433347225189209 	 0.23693299293518066 	 
2025-07-30 13:41:17.652153 test begin: paddle.nan_to_num(Tensor([1948, 26080],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([1948, 26080],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803840 	 1000 	 3.0057878494262695 	 0.2977774143218994 	 0.2794070243835449 	 0.2846081256866455 	 1.2652084827423096 	 1.1583540439605713 	 0.4309964179992676 	 0.23677897453308105 	 
2025-07-30 13:41:25.070224 test begin: paddle.nan_to_num(Tensor([25401601, 1],"float64"), neginf=-2.220446049250313e-16, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([25401601, 1],"float64"), neginf=-2.220446049250313e-16, ) 	 25401601 	 1000 	 2.8817365169525146 	 0.29884767532348633 	 0.26784801483154297 	 0.2858297824859619 	 0.9849729537963867 	 1.0290865898132324 	 0.3355240821838379 	 0.21032476425170898 	 
2025-07-30 13:41:31.352064 test begin: paddle.nan_to_num(Tensor([25401601, 2],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([25401601, 2],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803202 	 1000 	 3.0062949657440186 	 0.9145145416259766 	 0.27950167655944824 	 0.28451991081237793 	 1.2720518112182617 	 1.1594603061676025 	 0.43334054946899414 	 0.2369682788848877 	 
2025-07-30 13:41:41.742140 test begin: paddle.nan_to_num(Tensor([3386881, 5, 3],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([3386881, 5, 3],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803215 	 1000 	 3.0061075687408447 	 0.30306029319763184 	 0.27946996688842773 	 0.28458070755004883 	 1.2719764709472656 	 1.1593308448791504 	 0.4333317279815674 	 0.2369377613067627 	 
2025-07-30 13:41:53.422744 test begin: paddle.nan_to_num(Tensor([400, 63505],"float64"), neginf=-2.220446049250313e-16, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([400, 63505],"float64"), neginf=-2.220446049250313e-16, ) 	 25402000 	 1000 	 2.8825016021728516 	 0.29895734786987305 	 0.26782679557800293 	 0.27873730659484863 	 0.9859552383422852 	 1.0302906036376953 	 0.3358268737792969 	 0.2105393409729004 	 
2025-07-30 13:41:59.902846 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), -1, False, ) 	 50803240 	 1000 	 2.487281560897827 	 1.690716028213501 	 0.25379395484924316 	 0.28801584243774414 	 0.7136590480804443 	 0.7389841079711914 	 0.24329113960266113 	 0.18881988525390625 	 
2025-07-30 13:42:06.604766 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), 2, True, ) 	 50803240 	 1000 	 2.8251309394836426 	 1.3766577243804932 	 0.28821754455566406 	 0.23438072204589844 	 0.7455697059631348 	 0.7860629558563232 	 0.25409865379333496 	 0.20087218284606934 	 
2025-07-30 13:42:13.409079 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), None, False, ) 	 50803240 	 1000 	 1.983001947402954 	 1.1005513668060303 	 0.168503999710083 	 0.14060592651367188 	 0.561241865158081 	 0.5936069488525391 	 0.19132304191589355 	 0.15173125267028809 	 
2025-07-30 13:42:18.477766 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), -1, False, ) 	 50803230 	 1000 	 2.4848814010620117 	 1.6897258758544922 	 0.25363922119140625 	 0.2877981662750244 	 0.7134888172149658 	 0.7391440868377686 	 0.24318909645080566 	 0.18903779983520508 	 
2025-07-30 13:42:25.157472 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), 2, True, ) 	 50803230 	 1000 	 14.131793022155762 	 1.1296236515045166 	 1.2015304565429688 	 0.14434361457824707 	 0.5659010410308838 	 0.6300029754638672 	 0.1930372714996338 	 0.16098880767822266 	 
2025-07-30 13:42:42.499947 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), None, False, ) 	 50803230 	 1000 	 1.9832701683044434 	 1.1008641719818115 	 0.16858124732971191 	 0.1405949592590332 	 0.5613775253295898 	 0.5937092304229736 	 0.19132685661315918 	 0.15177226066589355 	 
2025-07-30 13:42:47.555811 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), -1, False, ) 	 50803224 	 1000 	 2.041891574859619 	 1.1008000373840332 	 0.17357373237609863 	 0.1406548023223877 	 0.5623857975006104 	 0.6113028526306152 	 0.1916975975036621 	 0.1561737060546875 	 
2025-07-30 13:42:52.721441 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), 2, True, ) 	 50803224 	 1000 	 2.331111431121826 	 1.3777661323547363 	 0.23794007301330566 	 0.23416829109191895 	 0.7615268230438232 	 0.7904922962188721 	 0.2595534324645996 	 0.20198774337768555 	 
2025-07-30 13:42:59.975243 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), None, False, ) 	 50803224 	 1000 	 1.9832918643951416 	 1.1008408069610596 	 0.16858696937561035 	 0.140669584274292 	 0.56138014793396 	 0.5938997268676758 	 0.19132709503173828 	 0.15172624588012695 	 
2025-07-30 13:43:05.051908 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), -1, False, ) 	 50803260 	 1000 	 2.4856817722320557 	 1.689995288848877 	 0.2536656856536865 	 0.28781652450561523 	 0.7135429382324219 	 0.7390480041503906 	 0.24319148063659668 	 0.18886637687683105 	 
2025-07-30 13:43:11.674669 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), 2, True, ) 	 50803260 	 1000 	 2.8244950771331787 	 1.3766613006591797 	 0.2881805896759033 	 0.234375 	 0.7455596923828125 	 0.7861864566802979 	 0.2540767192840576 	 0.20103907585144043 	 
2025-07-30 13:43:18.479716 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), None, False, ) 	 50803260 	 1000 	 1.983295202255249 	 1.1007463932037354 	 0.1685636043548584 	 0.14068078994750977 	 0.5613548755645752 	 0.5946335792541504 	 0.19132423400878906 	 0.15193700790405273 	 
2025-07-30 13:43:23.616965 test begin: paddle.nanmedian(Tensor([2, 254016],"float32"), axis=1, mode="min", )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([2, 254016],"float32"), axis=1, mode="min", ) 	 508032 	 1000 	 3.5256097316741943 	 1.0365302562713623 	 0.0034132003784179688 	 1.0173659324645996 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:43:28.289864 test begin: paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, ) 	 508032 	 1000 	 6.883806228637695 	 0.31374335289001465 	 0.006764888763427734 	 0.00017142295837402344 	 0.06734156608581543 	 0.537360429763794 	 4.696846008300781e-05 	 0.0003342628479003906 	 combined
2025-07-30 13:43:37.616186 test begin: paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, mode="min", )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, mode="min", ) 	 508032 	 1000 	 6.88137149810791 	 0.275388240814209 	 0.006781339645385742 	 7.867813110351562e-05 	 0.057581186294555664 	 0.14474892616271973 	 1.9788742065429688e-05 	 7.271766662597656e-05 	 combined
2025-07-30 13:43:45.034085 test begin: paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0, axis=1, )
W0730 13:43:45.046482  7853 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 0.49408888816833496 	 0.329301118850708 	 0.013501405715942383 	 0.006594419479370117 	 0.20548439025878906 	 0.2287435531616211 	 4.315376281738281e-05 	 7.534027099609375e-05 	 
2025-07-30 13:43:46.412230 test begin: paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 18.972851753234863 	 0.2926468849182129 	 0.5879275798797607 	 7.581710815429688e-05 	 0.21950888633728027 	 0.21709799766540527 	 4.076957702636719e-05 	 6.222724914550781e-05 	 
2025-07-30 13:44:06.176156 test begin: paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0, axis=1, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 16.312232971191406 	 0.30738234519958496 	 0.4566824436187744 	 0.00010037422180175781 	 0.2617015838623047 	 0.22686076164245605 	 5.412101745605469e-05 	 5.6743621826171875e-05 	 
2025-07-30 13:44:23.315407 test begin: paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 0.41008830070495605 	 0.3002591133117676 	 0.0001392364501953125 	 0.006577968597412109 	 0.19260835647583008 	 0.22413015365600586 	 3.695487976074219e-05 	 6.461143493652344e-05 	 
2025-07-30 13:44:24.457206 test begin: paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0, axis=1, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 16.32048225402832 	 0.2247776985168457 	 0.4569220542907715 	 7.867813110351562e-05 	 0.2004401683807373 	 0.22579169273376465 	 6.437301635742188e-05 	 6.67572021484375e-05 	 
2025-07-30 13:44:41.490922 test begin: paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 18.971949100494385 	 0.30219268798828125 	 0.5877735614776611 	 0.00012183189392089844 	 0.2190709114074707 	 0.2161417007446289 	 6.175041198730469e-05 	 7.510185241699219e-05 	 
2025-07-30 13:45:01.233247 test begin: paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803240 	 1000 	 1.0089783668518066 	 0.1528167724609375 	 0.20600128173828125 	 0.07805132865905762 	 0.5599985122680664 	 0.5903677940368652 	 0.28611063957214355 	 0.20107555389404297 	 
2025-07-30 13:45:04.358807 test begin: paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803240 	 1000 	 1.0089364051818848 	 0.1530776023864746 	 0.20596885681152344 	 0.07816958427429199 	 0.5606896877288818 	 0.5903315544128418 	 0.2864573001861572 	 0.2010505199432373 	 
2025-07-30 13:45:11.167224 test begin: paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803230 	 1000 	 1.0089478492736816 	 0.15282940864562988 	 0.2060070037841797 	 0.07807016372680664 	 0.5600190162658691 	 0.5902972221374512 	 0.28610849380493164 	 0.20107674598693848 	 
2025-07-30 13:45:14.345145 test begin: paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803230 	 1000 	 1.0088932514190674 	 0.15278911590576172 	 0.20598626136779785 	 0.07806921005249023 	 0.5599761009216309 	 0.5903017520904541 	 0.28610920906066895 	 0.20103907585144043 	 
2025-07-30 13:45:17.486353 test begin: paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=False, name=None, ) 	 50803224 	 1000 	 1.0090515613555908 	 0.15282106399536133 	 0.20601391792297363 	 0.07805800437927246 	 0.5599651336669922 	 0.590296745300293 	 0.28609561920166016 	 0.20102405548095703 	 
2025-07-30 13:45:20.628350 test begin: paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=True, name=None, ) 	 50803224 	 1000 	 1.0088257789611816 	 0.15280890464782715 	 0.20595121383666992 	 0.07807064056396484 	 0.5599780082702637 	 0.5903241634368896 	 0.286113977432251 	 0.20104312896728516 	 
2025-07-30 13:45:23.762788 test begin: paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803260 	 1000 	 1.008922815322876 	 0.1528759002685547 	 0.2059938907623291 	 0.07813549041748047 	 0.5600266456604004 	 0.5903513431549072 	 0.28612852096557617 	 0.20113301277160645 	 
2025-07-30 13:45:26.970388 test begin: paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803260 	 1000 	 1.0089068412780762 	 0.15283703804016113 	 0.205963134765625 	 0.07809138298034668 	 0.5600149631500244 	 0.5902113914489746 	 0.28609800338745117 	 0.20101022720336914 	 
2025-07-30 13:45:30.099919 test begin: paddle.nansum(x=Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.065145492553711 	 0.18939590454101562 	 0.27235960960388184 	 0.17375564575195312 	 0.5273730754852295 	 0.44119811058044434 	 0.2694380283355713 	 0.15022873878479004 	 
2025-07-30 13:45:32.962470 test begin: paddle.nansum(x=Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0652871131896973 	 1.4217538833618164 	 0.27237725257873535 	 0.17364192008972168 	 0.5273611545562744 	 0.4412517547607422 	 0.2694547176361084 	 0.1502082347869873 	 
2025-07-30 13:45:39.222700 test begin: paddle.nansum(x=Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401780 	 1000 	 5.622397422790527 	 0.17408180236816406 	 1.1518967151641846 	 0.08896541595458984 	 0.46539831161499023 	 0.4175570011138916 	 0.23775529861450195 	 0.1421658992767334 	 
2025-07-30 13:45:46.486450 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401744 	 1000 	 0.9732224941253662 	 0.189985990524292 	 0.2488417625427246 	 0.17432522773742676 	 0.5111072063446045 	 0.4432849884033203 	 0.2611374855041504 	 0.15090489387512207 	 
2025-07-30 13:45:49.252896 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 0.9742960929870605 	 0.19030547142028809 	 0.24911952018737793 	 0.17293429374694824 	 0.5115017890930176 	 0.44367122650146484 	 0.2613050937652588 	 0.15107107162475586 	 
2025-07-30 13:45:52.033690 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, ) 	 25402320 	 1000 	 0.9733905792236328 	 0.19018077850341797 	 0.24888110160827637 	 0.16562414169311523 	 0.5113694667816162 	 0.44522738456726074 	 0.26129722595214844 	 0.1515958309173584 	 
2025-07-30 13:45:54.886281 test begin: paddle.nansum(x=Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 1.0645086765289307 	 0.18935298919677734 	 0.2721993923187256 	 0.17331981658935547 	 0.5298659801483154 	 0.44146203994750977 	 0.2707023620605469 	 0.15029025077819824 	 
2025-07-30 13:45:57.790987 test begin: paddle.neg(Tensor([3175201, 8],"float64"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([3175201, 8],"float64"), ) 	 25401608 	 1000 	 0.29799938201904297 	 0.29820704460144043 	 0.28099775314331055 	 0.28116726875305176 	 0.29793691635131836 	 0.29807543754577637 	 0.23766374588012695 	 0.2262859344482422 	 
2025-07-30 13:46:00.034899 test begin: paddle.neg(Tensor([32, 1587601],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 0.29555749893188477 	 0.29781532287597656 	 0.27841854095458984 	 0.2807002067565918 	 0.2955901622772217 	 0.29767751693725586 	 0.23438191413879395 	 0.21378016471862793 	 
2025-07-30 13:46:02.909296 test begin: paddle.neg(Tensor([32, 793801],"float64"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([32, 793801],"float64"), ) 	 25401632 	 1000 	 0.2980031967163086 	 0.2982480525970459 	 0.2811856269836426 	 0.2811853885650635 	 0.2979164123535156 	 0.29805970191955566 	 0.23646306991577148 	 0.21416449546813965 	 
2025-07-30 13:46:05.139257 test begin: paddle.neg(Tensor([6350401, 8],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([6350401, 8],"float32"), ) 	 50803208 	 1000 	 0.2955958843231201 	 0.2978191375732422 	 0.28516507148742676 	 0.2866783142089844 	 0.29561829566955566 	 0.29773616790771484 	 0.24372148513793945 	 0.21254825592041016 	 
2025-07-30 13:46:07.977091 test begin: paddle.neg(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2954251766204834 	 0.29782843589782715 	 0.28550291061401367 	 0.28592562675476074 	 0.29540443420410156 	 0.29779624938964844 	 0.24320292472839355 	 0.2098388671875 	 
2025-07-30 13:46:10.766897 test begin: paddle.neg(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29571986198425293 	 0.3207228183746338 	 0.2859206199645996 	 0.2871241569519043 	 0.29561710357666016 	 0.29770421981811523 	 0.24356651306152344 	 0.22677183151245117 	 
2025-07-30 13:46:14.818583 test begin: paddle.neg(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2957417964935303 	 0.303546667098999 	 0.28598690032958984 	 0.28698015213012695 	 0.2957494258880615 	 0.2977480888366699 	 0.24352312088012695 	 0.231856107711792 	 
2025-07-30 13:46:18.457290 test begin: paddle.negative(Tensor([1693441, 3, 4, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([1693441, 3, 4, 5],"float16"), ) 	 101606460 	 1000 	 0.2984738349914551 	 0.2975616455078125 	 0.2779276371002197 	 0.2787179946899414 	 0.29842495918273926 	 0.2960996627807617 	 0.23776888847351074 	 0.22099947929382324 	 
2025-07-30 13:46:23.740691 test begin: paddle.negative(Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 1270081, 4, 5],"float32"), ) 	 50803240 	 1000 	 0.2955656051635742 	 0.2999882698059082 	 0.28359365463256836 	 0.28678178787231445 	 0.2956407070159912 	 0.2976646423339844 	 0.2442028522491455 	 0.23070359230041504 	 
2025-07-30 13:46:26.577404 test begin: paddle.negative(Tensor([2, 2540161, 4, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 2540161, 4, 5],"float16"), ) 	 101606440 	 1000 	 0.29856443405151367 	 0.29622554779052734 	 0.282576322555542 	 0.2786235809326172 	 0.29842209815979004 	 0.29610419273376465 	 0.23755335807800293 	 0.22273612022399902 	 
2025-07-30 13:46:31.565718 test begin: paddle.negative(Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 1693441, 5],"float32"), ) 	 50803230 	 1000 	 0.2955596446990967 	 0.2977635860443115 	 0.2836780548095703 	 0.28690576553344727 	 0.29560136795043945 	 0.2982950210571289 	 0.24382710456848145 	 0.22058796882629395 	 
2025-07-30 13:46:34.372342 test begin: paddle.negative(Tensor([2, 3, 3386881, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 3386881, 5],"float16"), ) 	 101606430 	 1000 	 0.2985191345214844 	 0.3057541847229004 	 0.28652334213256836 	 0.28507089614868164 	 0.298445463180542 	 0.29612278938293457 	 0.2436971664428711 	 0.229172945022583 	 
2025-07-30 13:46:40.353804 test begin: paddle.negative(Tensor([2, 3, 4, 1058401],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 1058401],"float64"), ) 	 25401624 	 1000 	 0.29798078536987305 	 0.29958271980285645 	 0.28609299659729004 	 0.28699541091918945 	 0.2979307174682617 	 0.29819798469543457 	 0.24603962898254395 	 0.2312161922454834 	 
2025-07-30 13:46:42.595428 test begin: paddle.negative(Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 2116801],"float32"), ) 	 50803224 	 1000 	 0.29558634757995605 	 0.2978017330169678 	 0.28360676765441895 	 0.2867574691772461 	 0.2956709861755371 	 0.2977480888366699 	 0.24366068840026855 	 0.23063039779663086 	 
2025-07-30 13:46:45.382675 test begin: paddle.negative(Tensor([2, 3, 4, 4233601],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 4233601],"float16"), ) 	 101606424 	 1000 	 0.29846715927124023 	 0.29625439643859863 	 0.2863118648529053 	 0.2850666046142578 	 0.2986161708831787 	 0.29614925384521484 	 0.24683928489685059 	 0.2298717498779297 	 
2025-07-30 13:46:50.308259 test begin: paddle.negative(Tensor([2, 3, 846721, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 846721, 5],"float64"), ) 	 25401630 	 1000 	 0.29799461364746094 	 0.3000960350036621 	 0.28615570068359375 	 0.28685808181762695 	 0.29789304733276367 	 0.2980504035949707 	 0.24617910385131836 	 0.2282850742340088 	 
2025-07-30 13:46:52.557632 test begin: paddle.negative(Tensor([2, 635041, 4, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 635041, 4, 5],"float64"), ) 	 25401640 	 1000 	 0.2979090213775635 	 0.30110788345336914 	 0.28565359115600586 	 0.2870755195617676 	 0.2979917526245117 	 0.3007385730743408 	 0.24608683586120605 	 0.22906851768493652 	 
2025-07-30 13:46:55.022321 test begin: paddle.negative(Tensor([423361, 3, 4, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([423361, 3, 4, 5],"float64"), ) 	 25401660 	 1000 	 0.2979013919830322 	 0.298187255859375 	 0.28601980209350586 	 0.28710436820983887 	 0.29791951179504395 	 0.29808688163757324 	 0.24585914611816406 	 0.23154306411743164 	 
2025-07-30 13:46:57.233271 test begin: paddle.negative(Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([846721, 3, 4, 5],"float32"), ) 	 50803260 	 1000 	 0.29557275772094727 	 0.2978506088256836 	 0.2834491729736328 	 0.2868163585662842 	 0.29561877250671387 	 0.2977125644683838 	 0.243818998336792 	 0.2275223731994629 	 
2025-07-30 13:47:00.004569 test begin: paddle.nextafter(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 0.4506373405456543 	 0.4488697052001953 	 0.44150638580322266 	 0.4374558925628662 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:02.514941 test begin: paddle.nextafter(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 0.45061826705932617 	 0.4488046169281006 	 0.44161486625671387 	 0.4375436305999756 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:05.006986 test begin: paddle.nextafter(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 0.450716495513916 	 0.44888758659362793 	 0.4416539669036865 	 0.43752098083496094 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:07.679284 test begin: paddle.nextafter(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), )
W0730 13:47:08.587235  9213 dygraph_functions.cc:57914] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 0.683624267578125 	 0.3877127170562744 	 0.3493998050689697 	 0.3672201633453369 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:09.794872 test begin: paddle.nextafter(Tensor([4, 3, 2116801],"float64"), Tensor([4, 3, 2116801],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 2116801],"float64"), Tensor([4, 3, 2116801],"float32"), ) 	 50803224 	 1000 	 0.682504415512085 	 0.38362646102905273 	 0.34877800941467285 	 0.3720591068267822 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:11.797674 test begin: paddle.nextafter(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), ) 	 101606424 	 1000 	 1.360905408859253 	 0.766460657119751 	 0.6954152584075928 	 0.7542245388031006 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:15.765780 test begin: paddle.nextafter(Tensor([4, 3, 4233601],"float64"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 4233601],"float64"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 1.3581109046936035 	 1.501368522644043 	 0.6940522193908691 	 0.739509105682373 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:25.044851 test begin: paddle.nextafter(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 0.683323860168457 	 0.3876457214355469 	 0.3491811752319336 	 0.3760354518890381 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:27.045906 test begin: paddle.nextafter(Tensor([4, 3175201, 2],"float64"), Tensor([4, 3175201, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3175201, 2],"float64"), Tensor([4, 3175201, 2],"float32"), ) 	 50803216 	 1000 	 0.6824908256530762 	 0.3836214542388916 	 0.3486793041229248 	 0.37205982208251953 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:29.061292 test begin: paddle.nextafter(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), ) 	 101606416 	 1000 	 1.3610703945159912 	 0.7663273811340332 	 0.6955251693725586 	 0.754568338394165 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:33.032508 test begin: paddle.nextafter(Tensor([4, 6350401, 2],"float64"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 6350401, 2],"float64"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 1.3582839965820312 	 0.7604141235351562 	 0.6940803527832031 	 0.7468259334564209 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:39.863868 test begin: paddle.nextafter(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 0.6833286285400391 	 0.39061689376831055 	 0.349149227142334 	 0.3756072521209717 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:41.894389 test begin: paddle.nextafter(Tensor([4233601, 3, 2],"float64"), Tensor([4233601, 3, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4233601, 3, 2],"float64"), Tensor([4233601, 3, 2],"float32"), ) 	 50803212 	 1000 	 0.6824905872344971 	 0.3836190700531006 	 0.3487567901611328 	 0.3719899654388428 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:43.876976 test begin: paddle.nextafter(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), ) 	 101606412 	 1000 	 1.3608133792877197 	 0.7662081718444824 	 0.6953999996185303 	 0.7544641494750977 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:47.945707 test begin: paddle.nextafter(Tensor([8467201, 3, 2],"float64"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([8467201, 3, 2],"float64"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 1.3582000732421875 	 0.758685827255249 	 0.6941187381744385 	 0.7469346523284912 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:51.907107 test begin: paddle.nextafter(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 0.4506680965423584 	 0.45346903800964355 	 0.44170308113098145 	 0.4371066093444824 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:54.439045 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 1536, 267],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 1536, 267],"float32"), 1, None, ) 	 50853888 	 1000 	 0.3015897274017334 	 0.1754908561706543 	 0.25626444816589355 	 0.15547609329223633 	 0.839606761932373 	 0.1698756217956543 	 0.42891359329223633 	 0.06432080268859863 	 
2025-07-30 13:47:56.791265 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 8362, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 8362, 49],"float32"), 1, None, ) 	 50807512 	 1000 	 0.35494041442871094 	 0.37694478034973145 	 0.30991673469543457 	 0.3586115837097168 	 0.8660244941711426 	 0.17418909072875977 	 0.44245052337646484 	 0.08389043807983398 	 
2025-07-30 13:47:59.387481 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 1536, 259],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 1536, 259],"float32"), 1, None, ) 	 50921472 	 1000 	 0.2852635383605957 	 0.15364503860473633 	 0.23917794227600098 	 0.1349475383758545 	 0.840721845626831 	 0.17033958435058594 	 0.42955780029296875 	 0.07945609092712402 	 
2025-07-30 13:48:01.649908 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 8101, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 8101, 49],"float32"), 1, None, ) 	 50809472 	 1000 	 0.3551826477050781 	 0.376950740814209 	 0.30992555618286133 	 0.3586001396179199 	 0.866703987121582 	 0.17419123649597168 	 0.44286227226257324 	 0.08266711235046387 	 
2025-07-30 13:48:04.249154 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([345, 1024, 144],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([345, 1024, 144],"float32"), 1, None, ) 	 50872320 	 1000 	 0.45908045768737793 	 0.21901822090148926 	 0.4139847755432129 	 0.2005155086517334 	 0.8477644920349121 	 0.17061328887939453 	 0.43312883377075195 	 0.07932782173156738 	 
2025-07-30 13:48:06.755445 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 1024, 776],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 1024, 776],"float32"), 1, None, ) 	 50855936 	 1000 	 0.18935418128967285 	 0.15391993522644043 	 0.1441664695739746 	 0.13584399223327637 	 0.8244173526763916 	 0.17167258262634277 	 0.42102932929992676 	 0.08173942565917969 	 
2025-07-30 13:48:08.916332 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 5513, 144],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 5513, 144],"float32"), 1, None, ) 	 50807808 	 1000 	 0.4585716724395752 	 0.21889114379882812 	 0.4133267402648926 	 0.19691085815429688 	 0.8507084846496582 	 0.1701805591583252 	 0.43472743034362793 	 0.05698108673095703 	 
2025-07-30 13:48:11.640139 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([676, 1536, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([676, 1536, 49],"float32"), 1, None, ) 	 50878464 	 1000 	 0.3557577133178711 	 0.37758612632751465 	 0.29372072219848633 	 0.35920286178588867 	 0.8685619831085205 	 0.17450308799743652 	 0.44377803802490234 	 0.08176684379577637 	 
2025-07-30 13:48:14.241314 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 2, 7],"float32"), output_size=1, ) 	 58404864 	 1000 	 0.3001883029937744 	 0.36455750465393066 	 0.2667520046234131 	 0.34511232376098633 	 1.0284011363983154 	 0.22425389289855957 	 0.5254414081573486 	 0.15105605125427246 	 
2025-07-30 13:48:17.202747 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 7, 2],"float32"), output_size=1, ) 	 58404864 	 1000 	 0.30037879943847656 	 0.3642559051513672 	 0.2689816951751709 	 0.3450586795806885 	 1.028200626373291 	 0.22420692443847656 	 0.5253357887268066 	 0.15037965774536133 	 
2025-07-30 13:48:20.115006 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 509, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 509, 7, 7],"float32"), output_size=1, ) 	 50804817 	 1000 	 0.35508084297180176 	 0.376924991607666 	 0.3235788345336914 	 0.3501594066619873 	 0.8669071197509766 	 0.17415904998779297 	 0.4430086612701416 	 0.07566046714782715 	 
2025-07-30 13:48:22.767981 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 2, 7],"float32"), output_size=1, ) 	 58634240 	 1000 	 0.3013627529144287 	 0.36685967445373535 	 0.26996874809265137 	 0.34757256507873535 	 1.0324177742004395 	 0.2257997989654541 	 0.5275566577911377 	 0.14980530738830566 	 
2025-07-30 13:48:27.638626 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 7, 2],"float32"), output_size=1, ) 	 58634240 	 1000 	 0.30152320861816406 	 0.3952901363372803 	 0.2701873779296875 	 0.3377225399017334 	 1.0325987339019775 	 0.2256641387939453 	 0.5274856090545654 	 0.14365768432617188 	 
2025-07-30 13:48:32.053783 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 507, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 507, 7, 7],"float32"), output_size=1, ) 	 50803935 	 1000 	 0.355710506439209 	 0.3776438236236572 	 0.32413625717163086 	 0.3563504219055176 	 0.8679888248443604 	 0.1742258071899414 	 0.4435124397277832 	 0.09981250762939453 	 
2025-07-30 13:48:34.700132 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 2, 7],"float32"), output_size=1, ) 	 58720256 	 1000 	 0.30206775665283203 	 0.3667597770690918 	 0.27051329612731934 	 0.34757089614868164 	 1.0337984561920166 	 0.2259676456451416 	 0.5280787944793701 	 0.14946246147155762 	 
2025-07-30 13:48:40.175858 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 7, 2],"float32"), output_size=1, ) 	 58720256 	 1000 	 0.30236053466796875 	 0.3661041259765625 	 0.2709510326385498 	 0.3465864658355713 	 1.0335748195648193 	 0.22542071342468262 	 0.5281121730804443 	 0.15251898765563965 	 
2025-07-30 13:48:43.191420 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 507, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 507, 7, 7],"float32"), output_size=1, ) 	 50878464 	 1000 	 0.35579633712768555 	 0.3782525062561035 	 0.32402896881103516 	 0.35924220085144043 	 0.8685967922210693 	 0.17445111274719238 	 0.4437859058380127 	 0.10103631019592285 	 
2025-07-30 13:48:45.820892 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([507, 2048, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([507, 2048, 7, 7],"float32"), output_size=1, ) 	 50878464 	 1000 	 0.3557703495025635 	 0.3775022029876709 	 0.3242990970611572 	 0.35852646827697754 	 0.8685553073883057 	 0.1744859218597412 	 0.4438190460205078 	 0.10169577598571777 	 
2025-07-30 13:48:48.417377 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 45361, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 45361, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804320 	 1000 	 0.8976483345031738 	 0.14876532554626465 	 0.863328218460083 	 0.12704205513000488 	 2.232410192489624 	 0.1728498935699463 	 1.1405961513519287 	 0.09962773323059082 	 
2025-07-30 13:48:52.677504 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804208 	 1000 	 0.50649094581604 	 0.1514911651611328 	 0.48160600662231445 	 0.12965965270996094 	 2.265334367752075 	 0.1726360321044922 	 1.1573090553283691 	 0.08911252021789551 	 
2025-07-30 13:48:56.620579 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804208 	 1000 	 0.5463714599609375 	 0.15145254135131836 	 0.5209660530090332 	 0.12982940673828125 	 2.26507568359375 	 0.17254137992858887 	 1.1571240425109863 	 0.09884238243103027 	 
2025-07-30 13:49:00.562899 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50851584 	 1000 	 15.966588973999023 	 0.15041756629943848 	 15.941342830657959 	 0.12082290649414062 	 2.263838529586792 	 0.16516470909118652 	 1.1565592288970947 	 0.09056615829467773 	 
2025-07-30 13:49:19.974347 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50851584 	 1000 	 19.324068307876587 	 0.150604248046875 	 19.298516273498535 	 0.12091493606567383 	 2.2670693397521973 	 0.16560649871826172 	 1.1582362651824951 	 0.061011314392089844 	 
2025-07-30 13:49:42.796103 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 414, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 414, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.36680722236633 	 0.14945697784423828 	 39.34112191200256 	 0.12797951698303223 	 2.226405143737793 	 0.16547131538391113 	 1.1374948024749756 	 0.09171938896179199 	 
2025-07-30 13:50:25.656819 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 460, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 460, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.26795554161072 	 0.1495063304901123 	 39.24228596687317 	 0.11956572532653809 	 2.2269768714904785 	 0.16570377349853516 	 1.1375389099121094 	 0.061174869537353516 	 
2025-07-30 13:51:08.673315 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 591, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 591, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50835456 	 1000 	 24.484938621520996 	 0.14983606338500977 	 24.459376335144043 	 0.12834811210632324 	 2.277151107788086 	 0.16537761688232422 	 1.1892690658569336 	 0.09025025367736816 	 
2025-07-30 13:51:39.930473 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 591],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 591],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50835456 	 1000 	 23.25038456916809 	 0.14981865882873535 	 23.224432706832886 	 0.12009119987487793 	 2.165296792984009 	 0.165391206741333 	 1.1063613891601562 	 0.09134054183959961 	 
2025-07-30 13:52:06.920980 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 9, 460],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 9, 460],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.14661526679993 	 0.14944815635681152 	 39.11196327209473 	 0.11889290809631348 	 2.1672327518463135 	 0.16556715965270996 	 1.1074137687683105 	 0.08520126342773438 	 
2025-07-30 13:52:49.455177 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 946, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 946, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50856960 	 1000 	 17.444963693618774 	 0.14952301979064941 	 17.410772800445557 	 0.11976003646850586 	 2.227778434753418 	 0.16574835777282715 	 1.1383304595947266 	 0.0844733715057373 	 
2025-07-30 13:53:10.332942 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([60, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([60, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51609600 	 1000 	 0.9005637168884277 	 0.15096616744995117 	 0.8663561344146729 	 0.12092161178588867 	 2.2709972858428955 	 0.1756885051727295 	 1.1601760387420654 	 0.07409167289733887 	 
2025-07-30 13:53:14.715411 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51093504 	 1000 	 0.5082051753997803 	 0.15218520164489746 	 0.474045991897583 	 0.1226959228515625 	 2.2813475131988525 	 0.17387080192565918 	 1.1656067371368408 	 0.09377741813659668 	 
2025-07-30 13:53:18.697969 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51093504 	 1000 	 0.5446305274963379 	 0.15219688415527344 	 0.5102205276489258 	 0.1224510669708252 	 2.280881881713867 	 0.17359137535095215 	 1.1653094291687012 	 0.09286999702453613 	 
2025-07-30 13:53:22.693633 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 3175201],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
W0730 13:53:23.455211 11608 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 3175201],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 50805392 	 1000 	 12.980122089385986 	 8.56692361831665 	 0.009411096572875977 	 0.006591320037841797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:54:05.557710 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([25401601, 16],"float32"), Tensor([25401601],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([25401601, 16],"float32"), Tensor([25401601],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 431827345 	 1000 	 50.0916633605957 	 20.996759176254272 	 0.007189750671386719 	 0.006203889846801758 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:56:02.368124 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([3175201, 16],"float32"), Tensor([3175201],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([3175201, 16],"float32"), Tensor([3175201],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 53978545 	 1000 	 6.8055360317230225 	 3.364424228668213 	 0.0007963180541992188 	 0.0005588531494140625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:56:19.297307 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 4233601],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 4233601],"float64"), 8, False, None, ) 	 25401606 	 1000 	 62.46074843406677 	 61.33885669708252 	 62.43499779701233 	 61.306819438934326 	 0.44963908195495605 	 0.13768529891967773 	 0.2294144630432129 	 0.04019927978515625 	 
2025-07-30 13:58:25.890287 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), 16, False, None, ) 	 50803206 	 1000 	 48.69015645980835 	 41.166542053222656 	 48.650750160217285 	 41.144449949264526 	 0.7626323699951172 	 0.13729047775268555 	 0.3894155025482178 	 0.04842662811279297 	 
2025-07-30 13:59:57.585814 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), output_size=16, ) 	 50803206 	 1000 	 48.653061866760254 	 41.15991163253784 	 48.62746715545654 	 41.12822437286377 	 0.7623116970062256 	 0.13719820976257324 	 0.3895130157470703 	 0.04650139808654785 	 
2025-07-30 14:01:29.296152 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 396901, 32],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 396901, 32],"float64"), 8, False, None, ) 	 25401664 	 1000 	 0.20810914039611816 	 0.8642899990081787 	 0.18332290649414062 	 0.8402600288391113 	 0.5266289710998535 	 0.776465654373169 	 0.26903247833251953 	 0.3966984748840332 	 
2025-07-30 14:01:32.363164 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), 16, False, None, ) 	 50803264 	 1000 	 0.4091911315917969 	 1.7132785320281982 	 0.3662080764770508 	 1.6781518459320068 	 0.89552903175354 	 1.4100205898284912 	 0.45746660232543945 	 0.720423698425293 	 
2025-07-30 14:01:40.811635 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), output_size=16, ) 	 50803264 	 1000 	 0.4092891216278076 	 1.7317640781402588 	 0.3835022449493408 	 1.6871647834777832 	 0.895627498626709 	 1.4102210998535156 	 0.4578382968902588 	 0.7203848361968994 	 
2025-07-30 14:01:48.010225 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([264601, 3, 32],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([264601, 3, 32],"float64"), 8, False, None, ) 	 25401696 	 1000 	 0.20812463760375977 	 3.4235095977783203 	 0.1834108829498291 	 3.387305498123169 	 0.5244324207305908 	 3.326415538787842 	 0.26786041259765625 	 1.699737548828125 	 
2025-07-30 14:01:56.214115 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), 16, False, None, ) 	 50803296 	 1000 	 0.40904736518859863 	 6.811348915100098 	 0.3839423656463623 	 6.788680791854858 	 0.8943934440612793 	 6.510188341140747 	 0.45700979232788086 	 3.3266139030456543 	 
2025-07-30 14:02:12.104350 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), output_size=16, ) 	 50803296 	 1000 	 0.4090731143951416 	 6.8115394115448 	 0.3835585117340088 	 6.778894424438477 	 0.8942453861236572 	 6.510126829147339 	 0.4569227695465088 	 3.3265678882598877 	 
2025-07-30 14:02:27.975813 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 1209601, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 1209601, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803242 	 1000 	 328.4493327140808 	 136.33336114883423 	 328.4356505870819 	 136.30761551856995 	 0.7814104557037354 	 0.13724637031555176 	 0.3991963863372803 	 0.06290507316589355 	 
2025-07-30 14:10:15.003403 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803242 	 1000 	 113.28253173828125 	 56.17145609855652 	 113.26896166801453 	 56.15378737449646 	 0.8051047325134277 	 0.13723969459533691 	 0.41124796867370605 	 0.06600713729858398 	 
2025-07-30 14:13:06.434277 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 	 50803242 	 1000 	 178.34221196174622 	 78.65270137786865 	 178.32880854606628 	 78.63248491287231 	 0.7720367908477783 	 0.13716936111450195 	 0.3943362236022949 	 0.05887174606323242 	 
2025-07-30 14:17:25.453594 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 	 50803242 	 1000 	 222.84957647323608 	 94.67225456237793 	 222.83417439460754 	 94.64413332939148 	 0.7824232578277588 	 0.13731932640075684 	 0.39974260330200195 	 0.06719374656677246 	 
2025-07-30 14:22:45.108297 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803298 	 1000 	 0.5824611186981201 	 4.687318801879883 	 0.5689058303833008 	 4.668941974639893 	 1.0922091007232666 	 1.181899070739746 	 0.5580215454101562 	 0.6038568019866943 	 
2025-07-30 14:22:53.911573 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 	 50803298 	 1000 	 0.43808746337890625 	 2.637296676635742 	 0.4248080253601074 	 2.616321325302124 	 1.0134778022766113 	 0.9677772521972656 	 0.5177671909332275 	 0.49449753761291504 	 
2025-07-30 14:22:59.973188 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 	 50803298 	 1000 	 0.38716793060302734 	 3.2835142612457275 	 0.37255001068115234 	 3.2596073150634766 	 1.0396358966827393 	 1.0013353824615479 	 0.5312404632568359 	 0.5116055011749268 	 
2025-07-30 14:23:06.723425 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803690 	 1000 	 1.9653444290161133 	 10.297956228256226 	 1.9513425827026367 	 0.6578407287597656 	 1.2641396522521973 	 1.4910626411437988 	 0.6459743976593018 	 0.08962464332580566 	 
2025-07-30 14:23:23.015939 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803690 	 1000 	 1.5630717277526855 	 5.542304754257202 	 1.5493175983428955 	 0.809157133102417 	 0.47659778594970703 	 0.5955467224121094 	 0.24349761009216309 	 0.0759890079498291 	 
2025-07-30 14:23:32.119643 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803690 	 1000 	 1.9165418148040771 	 6.874079465866089 	 1.9021737575531006 	 0.7017383575439453 	 0.5798397064208984 	 0.8125972747802734 	 0.2962770462036133 	 0.07541489601135254 	 
2025-07-30 14:23:43.254825 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803494 	 1000 	 30.484432697296143 	 39.98743510246277 	 30.47054409980774 	 39.969672203063965 	 0.15168142318725586 	 0.1375279426574707 	 0.0774223804473877 	 0.06495141983032227 	 
2025-07-30 14:24:54.945194 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803494 	 1000 	 102.74748182296753 	 135.65591406822205 	 102.7333972454071 	 135.631178855896 	 0.15189027786254883 	 0.1373434066772461 	 0.07753300666809082 	 0.06601786613464355 	 
2025-07-30 14:28:55.565419 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803494 	 1000 	 72.14211177825928 	 91.1709258556366 	 72.12835502624512 	 91.1497049331665 	 0.15182828903198242 	 0.13763856887817383 	 0.0775461196899414 	 0.06242251396179199 	 
2025-07-30 14:31:40.240293 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803410 	 1000 	 23.908390283584595 	 30.034863233566284 	 23.892940044403076 	 30.009584426879883 	 0.15169072151184082 	 0.13753771781921387 	 0.07746434211730957 	 0.06643319129943848 	 
2025-07-30 14:32:37.785371 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803410 	 1000 	 106.08996915817261 	 136.62051033973694 	 106.06830358505249 	 136.5969376564026 	 0.1524488925933838 	 0.13741493225097656 	 0.07793235778808594 	 0.06303119659423828 	 
2025-07-30 14:36:42.042496 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803410 	 1000 	 109.28022336959839 	 134.42599749565125 	 109.2663848400116 	 134.40586829185486 	 0.15272736549377441 	 0.13734054565429688 	 0.07797074317932129 	 0.06638526916503906 	 
2025-07-30 14:40:47.306686 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803410 	 1000 	 10.159011602401733 	 11.835972785949707 	 10.144858837127686 	 11.817861557006836 	 0.15157532691955566 	 0.13786029815673828 	 0.07742500305175781 	 0.030074357986450195 	 
2025-07-30 14:41:10.740751 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803410 	 1000 	 31.131317615509033 	 35.933037996292114 	 31.109801054000854 	 35.91247224807739 	 0.15233755111694336 	 0.13736295700073242 	 0.07786750793457031 	 0.06691241264343262 	 
2025-07-30 14:42:19.126283 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803410 	 1000 	 48.32667541503906 	 58.997886657714844 	 48.31283950805664 	 58.977298974990845 	 0.15248370170593262 	 0.13736486434936523 	 0.07782340049743652 	 0.06652379035949707 	 
2025-07-30 14:44:07.720185 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803935 	 1000 	 1.965369462966919 	 10.29744005203247 	 1.9514079093933105 	 0.657684326171875 	 1.2635767459869385 	 1.4908690452575684 	 0.6456878185272217 	 0.08958220481872559 	 
2025-07-30 14:44:24.013613 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803935 	 1000 	 1.5629372596740723 	 5.541869401931763 	 1.5492053031921387 	 0.8091814517974854 	 0.47867774963378906 	 0.595461368560791 	 0.24463391304016113 	 0.07599616050720215 	 
2025-07-30 14:44:33.116396 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803935 	 1000 	 1.916468620300293 	 6.883471250534058 	 1.9026033878326416 	 0.701636552810669 	 0.578916072845459 	 0.8123910427093506 	 0.2958412170410156 	 0.07539629936218262 	 
2025-07-30 14:44:47.644838 test begin: paddle.nn.functional.avg_pool1d(Tensor([13, 1, 3907939],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([13, 1, 3907939],"float32"), 25, 1, 0, True, False, None, ) 	 50803207 	 1000 	 36.744627714157104 	 1.5815343856811523 	 36.693968057632446 	 1.5658624172210693 	 45.76222777366638 	 3.7297611236572266 	 45.68106985092163 	 3.6375627517700195 	 
2025-07-30 14:46:17.412953 test begin: paddle.nn.functional.avg_pool1d(Tensor([13, 32567, 120],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([13, 32567, 120],"float32"), 25, 1, 0, True, False, None, ) 	 50804520 	 1000 	 7.488391160964966 	 1.6176002025604248 	 7.438853740692139 	 1.3538289070129395 	 11.39789867401123 	 3.847616195678711 	 11.301559686660767 	 3.7541110515594482 	 
2025-07-30 14:46:45.319276 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 1, 3175201],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 1, 3175201],"float32"), 25, 1, 0, True, False, None, ) 	 50803216 	 1000 	 36.699485301971436 	 1.580939531326294 	 36.66449689865112 	 1.5651309490203857 	 45.74774670600891 	 3.730318069458008 	 45.66354990005493 	 3.643259286880493 	 
2025-07-30 14:48:14.934185 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 2, 1587601],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 2, 1587601],"float32"), 25, 1, 0, True, False, None, ) 	 50803232 	 1000 	 18.435696601867676 	 1.5817604064941406 	 18.401049852371216 	 1.5622808933258057 	 22.899376153945923 	 3.7304024696350098 	 22.817763566970825 	 3.6293485164642334 	 
2025-07-30 14:49:03.383208 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 26461, 120],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 26461, 120],"float32"), 25, 1, 0, True, False, None, ) 	 50805120 	 1000 	 7.488099098205566 	 1.3810126781463623 	 7.453695058822632 	 1.3652031421661377 	 11.398616790771484 	 3.846308946609497 	 11.313837766647339 	 3.7625086307525635 	 
2025-07-30 14:49:29.099904 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 127, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 127, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50978816 	 1000 	 0.1943364143371582 	 0.4169290065765381 	 0.17435884475708008 	 0.40474438667297363 	 0.3547384738922119 	 1.569429874420166 	 0.2927396297454834 	 1.5010101795196533 	 
2025-07-30 14:49:32.679177 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 256, 28, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 256, 28, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.1986997127532959 	 0.4206111431121826 	 0.178497314453125 	 0.4087088108062744 	 0.33443522453308105 	 1.577934980392456 	 0.26936817169189453 	 1.510385513305664 	 
2025-07-30 14:49:37.436514 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 256, 56, 28],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 256, 56, 28],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.1998276710510254 	 0.4349400997161865 	 0.17982006072998047 	 0.4073014259338379 	 0.33547472953796387 	 1.579815149307251 	 0.2735171318054199 	 1.5122756958007812 	 
2025-07-30 14:49:41.835339 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 128, 256, 97],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 128, 256, 97],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50855936 	 1000 	 0.1922769546508789 	 0.4107203483581543 	 0.16964411735534668 	 0.3989529609680176 	 0.3309316635131836 	 1.5625381469726562 	 0.2688562870025635 	 1.495474100112915 	 
2025-07-30 14:49:45.375651 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 128, 97, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 128, 97, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50855936 	 1000 	 0.19033598899841309 	 0.4081845283508301 	 0.16782617568969727 	 0.3944563865661621 	 0.33017611503601074 	 1.5502431392669678 	 0.267956018447876 	 1.482748031616211 	 
2025-07-30 14:49:48.915802 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 49, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 49, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.19620180130004883 	 0.414766788482666 	 0.17353129386901855 	 0.4030172824859619 	 0.354414701461792 	 1.5676658153533936 	 0.2894613742828369 	 1.5008132457733154 	 
2025-07-30 14:49:52.514478 test begin: paddle.nn.functional.avg_pool2d(Tensor([4, 256, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([4, 256, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 58982400 	 1000 	 0.2229447364807129 	 0.4829831123352051 	 0.20289897918701172 	 0.46771764755249023 	 0.3836188316345215 	 1.8096652030944824 	 0.32046055793762207 	 1.7321183681488037 	 
2025-07-30 14:49:56.665548 test begin: paddle.nn.functional.avg_pool2d(Tensor([64, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([64, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.1955869197845459 	 0.41951847076416016 	 0.1757364273071289 	 0.4076976776123047 	 0.3537876605987549 	 1.5814933776855469 	 0.29196667671203613 	 1.5148274898529053 	 
2025-07-30 14:50:00.257055 test begin: paddle.nn.functional.avg_pool2d(Tensor([7, 128, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([7, 128, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 58720256 	 1000 	 0.2207317352294922 	 0.47269511222839355 	 0.19665932655334473 	 0.4609344005584717 	 0.3813197612762451 	 1.790351390838623 	 0.31742334365844727 	 1.7247653007507324 	 
2025-07-30 14:50:04.368612 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 111, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 111, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51148800 	 1000 	 0.19446229934692383 	 0.4194655418395996 	 0.173964262008667 	 0.404979944229126 	 0.3354337215423584 	 1.5696513652801514 	 0.273637056350708 	 1.5007562637329102 	 
2025-07-30 14:50:07.961458 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 256, 104, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 256, 104, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51118080 	 1000 	 0.19425344467163086 	 0.4170825481414795 	 0.17421865463256836 	 0.4049983024597168 	 0.3340146541595459 	 1.5689232349395752 	 0.2717869281768799 	 1.4968440532684326 	 
2025-07-30 14:50:13.668710 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 256, 240, 104],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 256, 240, 104],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51118080 	 1000 	 0.19332027435302734 	 1.4935002326965332 	 0.17321276664733887 	 0.4043130874633789 	 0.33393216133117676 	 1.5745773315429688 	 0.2716367244720459 	 1.5055713653564453 	 
2025-07-30 14:50:19.179295 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 776, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(Tensor([2, 776, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", ) 	 50855936 	 1000 	 0.17682647705078125 	 0.4238431453704834 	 0.15765881538391113 	 0.4097938537597656 	 0.4265148639678955 	 0.4984128475189209 	 0.36452507972717285 	 0.25480151176452637 	 
2025-07-30 14:50:21.622510 test begin: paddle.nn.functional.avg_pool3d(Tensor([517, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(Tensor([517, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", ) 	 50823168 	 1000 	 0.17833256721496582 	 0.42340993881225586 	 0.1594398021697998 	 0.40940165519714355 	 0.5589907169342041 	 0.498028039932251 	 0.4972560405731201 	 0.25432538986206055 	 
2025-07-30 14:50:24.191586 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([127, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([127, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50978816 	 1000 	 0.24044227600097656 	 2.246518611907959 	 0.21784400939941406 	 0.5739364624023438 	 3.144352912902832 	 2.8941397666931152 	 3.0817949771881104 	 0.1739494800567627 	 
2025-07-30 14:50:33.596146 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([127, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([127, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50978816 	 1000 	 0.2630891799926758 	 1.992856740951538 	 0.24058270454406738 	 1.9790129661560059 	 2.8906469345092773 	 2.8754584789276123 	 2.8284504413604736 	 0.17284893989562988 	 
2025-07-30 14:50:43.064241 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 111, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 111, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.34122347831726074 	 10.92674207687378 	 0.31853818893432617 	 10.913239479064941 	 4.431781053543091 	 4.749603033065796 	 4.369502067565918 	 1.6194450855255127 	 
2025-07-30 14:51:04.381557 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 111],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 111],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.3852710723876953 	 0.7705540657043457 	 0.362640380859375 	 0.7499806880950928 	 3.0761096477508545 	 0.9822423458099365 	 3.014045000076294 	 0.3347630500793457 	 
2025-07-30 14:51:10.996865 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 64, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 64, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 51380224 	 1000 	 0.31789159774780273 	 7.9067559242248535 	 0.29533910751342773 	 0.5050432682037354 	 4.29202675819397 	 4.358408451080322 	 4.228268146514893 	 0.24748635292053223 	 
2025-07-30 14:51:28.788289 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 111, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 111, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.35762500762939453 	 10.578633069992065 	 0.3346734046936035 	 10.562761068344116 	 4.428026437759399 	 4.748108625411987 	 4.365702867507935 	 1.6189045906066895 	 
2025-07-30 14:51:49.764125 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 111],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 111],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.4149129390716553 	 0.983633279800415 	 0.39226317405700684 	 0.9698679447174072 	 3.067695379257202 	 0.9607224464416504 	 3.002680540084839 	 0.3274192810058594 	 
2025-07-30 14:51:56.049528 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 507, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 507, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50878464 	 1000 	 2.216388702392578 	 50.528690814971924 	 2.1938023567199707 	 3.442176342010498 	 15.10237741470337 	 17.597060203552246 	 15.03986382484436 	 1.0578382015228271 	 
2025-07-30 14:53:22.460999 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 32401, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 32401, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50804768 	 1000 	 0.24029755592346191 	 2.2396090030670166 	 0.20942974090576172 	 0.5721080303192139 	 3.133843421936035 	 2.8853542804718018 	 3.062307119369507 	 0.17338943481445312 	 
2025-07-30 14:53:32.826506 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 4051, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 4051, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50815744 	 1000 	 0.2695581912994385 	 1.986619234085083 	 0.24686741828918457 	 1.9725823402404785 	 2.882819652557373 	 2.867126941680908 	 2.8207685947418213 	 0.17230224609375 	 
2025-07-30 14:53:42.273186 test begin: paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50823388 	 1000 	 0.3743598461151123 	 0.37268495559692383 	 0.3555018901824951 	 0.3442502021789551 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 40, 50, 847]) and output[0] has a shape of torch.Size([30, 847, 40, 50]).
2025-07-30 14:53:48.947871 test begin: paddle.nn.functional.batch_norm(Tensor([30, 40, 706, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 40, 706, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50832240 	 1000 	 0.3714737892150879 	 0.36802053451538086 	 0.35240888595581055 	 0.3398756980895996 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 40, 706, 60]) and output[0] has a shape of torch.Size([30, 60, 40, 706]).
2025-07-30 14:53:54.859041 test begin: paddle.nn.functional.batch_norm(Tensor([30, 565, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 565, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50850240 	 1000 	 0.37201619148254395 	 0.3728318214416504 	 0.353029727935791 	 0.344576358795166 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 565, 50, 60]) and output[0] has a shape of torch.Size([30, 60, 565, 50]).
2025-07-30 14:54:00.974491 test begin: paddle.nn.functional.batch_norm(Tensor([424, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([424, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50880240 	 1000 	 0.3388857841491699 	 0.3388199806213379 	 0.318011999130249 	 0.30980992317199707 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([424, 40, 50, 60]) and output[0] has a shape of torch.Size([424, 60, 40, 50]).
2025-07-30 14:54:06.640418 test begin: paddle.nn.functional.bilinear(Tensor([25401601, 1],"float32"), Tensor([25401601, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([25401601, 1],"float32"), Tensor([25401601, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, ) 	 76204815 	 1000 	 15.036997079849243 	 118.76264500617981 	 0.14659428596496582 	 0.07311034202575684 	 30.261101245880127 	 125.3945665359497 	 0.24956393241882324 	 0.07919764518737793 	 
2025-07-30 14:58:59.402672 test begin: paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 12700801],"float32"), Tensor([4, 1, 12700801],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 12700801],"float32"), Tensor([4, 1, 12700801],"float32"), Tensor([1, 4],"float32"), None, ) 	 88905614 	 1000 	 3.39554762840271 	 45.26003980636597 	 0.0533597469329834 	 0.7467482089996338 	 6.645917654037476 	 50.04211449623108 	 0.09038805961608887 	 0.5549149513244629 	 
2025-07-30 15:00:46.383681 test begin: paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 16934401],"float32"), Tensor([4, 1, 16934401],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 16934401],"float32"), Tensor([4, 1, 16934401],"float32"), Tensor([1, 4],"float32"), None, ) 	 118540814 	 1000 	 4.585873126983643 	 60.57136631011963 	 0.0578157901763916 	 0.8029201030731201 	 8.81551456451416 	 66.87234902381897 	 0.09838747978210449 	 0.6096625328063965 	 
2025-07-30 15:03:09.403627 test begin: paddle.nn.functional.bilinear(Tensor([5, 5],"float32"), Tensor([5, 10161],"float32"), Tensor([1000, 5, 10161],"float32"), Tensor([1, 1000],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([5, 5],"float32"), Tensor([5, 10161],"float32"), Tensor([1000, 5, 10161],"float32"), Tensor([1, 1000],"float32"), None, ) 	 50856830 	 1000 	 30.80248999595642 	 49.44959855079651 	 0.007848262786865234 	 0.00027680397033691406 	 39.32979726791382 	 112.09687042236328 	 0.00010919570922851562 	 0.00023651123046875 	 
2025-07-30 15:07:02.258558 test begin: paddle.nn.functional.bilinear(Tensor([50803201, 1],"float32"), Tensor([50803201, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([50803201, 1],"float32"), Tensor([50803201, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, ) 	 152409615 	 1000 	 30.002405881881714 	 237.24424743652344 	 0.15509605407714844 	 0.07449817657470703 	 60.327643632888794 	 250.51465272903442 	 0.27955150604248047 	 0.09049272537231445 	 
2025-07-30 15:16:49.120026 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"float32"), weight=Tensor([16, 10164, 313],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"float32"), weight=Tensor([16, 10164, 313],"float32"), reduction="sum", ) 	 152703936 	 1000 	 1.0495104789733887 	 1.0576810836791992 	 0.26746511459350586 	 0.21538758277893066 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:16:55.696482 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"float32"), weight=Tensor([16, 11109, 286],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"float32"), weight=Tensor([16, 11109, 286],"float32"), reduction="sum", ) 	 152504352 	 1000 	 1.047126054763794 	 1.0627691745758057 	 0.2671818733215332 	 0.21515560150146484 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:02.149950 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"float32"), weight=Tensor([16, 12096, 263],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"float32"), weight=Tensor([16, 12096, 263],"float32"), reduction="sum", ) 	 152699904 	 1000 	 1.04937744140625 	 1.0552079677581787 	 0.26743102073669434 	 0.215407133102417 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:08.512722 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="sum", ) 	 152413440 	 1000 	 1.0465795993804932 	 1.0573697090148926 	 0.26701951026916504 	 0.21628856658935547 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:15.046234 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([53, 12096, 80],"float32"), Tensor([53, 12096, 80],"float32"), weight=Tensor([53, 12096, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([53, 12096, 80],"float32"), Tensor([53, 12096, 80],"float32"), weight=Tensor([53, 12096, 80],"float32"), reduction="sum", ) 	 153861120 	 1000 	 1.0575668811798096 	 1.0629360675811768 	 0.2695493698120117 	 0.2169189453125 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:21.433925 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([58, 11109, 80],"float32"), Tensor([58, 11109, 80],"float32"), weight=Tensor([58, 11109, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([58, 11109, 80],"float32"), Tensor([58, 11109, 80],"float32"), weight=Tensor([58, 11109, 80],"float32"), reduction="sum", ) 	 154637280 	 1000 	 1.0629205703735352 	 1.0698025226593018 	 0.2708439826965332 	 0.21808838844299316 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:27.921427 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([63, 10164, 80],"float32"), Tensor([63, 10164, 80],"float32"), weight=Tensor([63, 10164, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([63, 10164, 80],"float32"), Tensor([63, 10164, 80],"float32"), weight=Tensor([63, 10164, 80],"float32"), reduction="sum", ) 	 153679680 	 1000 	 1.0549347400665283 	 1.0648646354675293 	 0.26911211013793945 	 0.21669840812683105 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:34.384694 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 300, 10585],"float32"), Tensor([16, 300, 10585],"float32"), weight=Tensor([16, 300, 10585],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 300, 10585],"float32"), Tensor([16, 300, 10585],"float32"), weight=Tensor([16, 300, 10585],"float32"), reduction="none", ) 	 152424000 	 1000 	 1.6638140678405762 	 2.2343525886535645 	 0.35391712188720703 	 0.3771812915802002 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:46.229190 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="none", ) 	 152413440 	 1000 	 1.0389983654022217 	 2.216336965560913 	 0.35411787033081055 	 0.37718677520751953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:17:54.763562 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2117, 300, 80],"float32"), Tensor([2117, 300, 80],"float32"), weight=Tensor([2117, 300, 80],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2117, 300, 80],"float32"), Tensor([2117, 300, 80],"float32"), weight=Tensor([2117, 300, 80],"float32"), reduction="none", ) 	 152424000 	 1000 	 1.038100242614746 	 2.218174457550049 	 0.3538248538970947 	 0.3772153854370117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:18:03.392595 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), weight=Tensor([300, 169345],"float32"), reduction="none", pos_weight=None, )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), weight=Tensor([300, 169345],"float32"), reduction="none", pos_weight=None, ) 	 152410500 	 1000 	 1.0396728515625 	 2.214827060699463 	 0.35404276847839355 	 0.3771548271179199 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:18:11.940440 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([50804, 1000],"float32"), Tensor([50804, 1000],"float32"), weight=Tensor([50804, 1000],"float32"), reduction="none", pos_weight=None, )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([50804, 1000],"float32"), Tensor([50804, 1000],"float32"), weight=Tensor([50804, 1000],"float32"), reduction="none", pos_weight=None, ) 	 152412000 	 1000 	 1.038137435913086 	 2.214656114578247 	 0.3539755344390869 	 0.378450870513916 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:18:20.520227 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 28, 3544],"float32"), Tensor([512, 28, 3544],"float32"), weight=Tensor([512, 1, 3544],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 28, 3544],"float32"), Tensor([512, 28, 3544],"float32"), weight=Tensor([512, 1, 3544],"float32"), reduction="mean", ) 	 103428096 	 1000 	 1.04296875 	 2.2422597408294678 	 0.21263670921325684 	 0.28780364990234375 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:18:27.248451 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 3544, 28],"float32"), Tensor([512, 3544, 28],"float32"), weight=Tensor([512, 3544, 1],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 3544, 28],"float32"), Tensor([512, 3544, 28],"float32"), weight=Tensor([512, 3544, 1],"float32"), reduction="mean", ) 	 103428096 	 1000 	 1.0422234535217285 	 2.2376275062561035 	 0.21253108978271484 	 0.28741002082824707 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:18:34.004331 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), weight=Tensor([64801, 1, 1],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), weight=Tensor([64801, 1, 1],"float32"), reduction="mean", ) 	 101672769 	 1000 	 1.0366764068603516 	 2.2301416397094727 	 0.2116537094116211 	 0.2850027084350586 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:18:41.336959 test begin: paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 0.2, None, ) 	 25401616 	 1000 	 0.3083028793334961 	 0.30711889266967773 	 0.29181790351867676 	 0.2800579071044922 	 0.44813966751098633 	 0.4493741989135742 	 0.383772611618042 	 0.3816564083099365 	 
2025-07-30 15:18:44.066992 test begin: paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 1.0, None, ) 	 25401616 	 1000 	 0.30819201469421387 	 0.30924129486083984 	 0.2918238639831543 	 0.287306547164917 	 0.44796156883239746 	 0.4493248462677002 	 0.38521313667297363 	 0.380753755569458 	 
2025-07-30 15:18:47.833637 test begin: paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 0.2, None, ) 	 25401608 	 1000 	 0.30822277069091797 	 0.31946754455566406 	 0.2918877601623535 	 0.28029823303222656 	 0.44797658920288086 	 0.44930386543273926 	 0.3855130672454834 	 0.37590503692626953 	 
2025-07-30 15:18:52.019228 test begin: paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 1.0, None, ) 	 25401608 	 1000 	 0.3081932067871094 	 0.3052699565887451 	 0.29753708839416504 	 0.2851858139038086 	 0.4478938579559326 	 0.44936203956604004 	 0.3945164680480957 	 0.3795039653778076 	 
2025-07-30 15:18:54.742778 test begin: paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 0.2, None, ) 	 25401608 	 1000 	 0.3082613945007324 	 0.3207051753997803 	 0.29880309104919434 	 0.2816147804260254 	 0.4479353427886963 	 0.449329137802124 	 0.3950235843658447 	 0.375629186630249 	 
2025-07-30 15:18:57.390453 test begin: paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 1.0, None, ) 	 25401608 	 1000 	 0.30824851989746094 	 0.30384135246276855 	 0.29558730125427246 	 0.28766727447509766 	 0.4479494094848633 	 0.4493827819824219 	 0.39366650581359863 	 0.38251161575317383 	 
2025-07-30 15:19:00.041231 test begin: paddle.nn.functional.celu(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.30818843841552734 	 0.3038609027862549 	 0.29845595359802246 	 0.28732848167419434 	 0.4479544162750244 	 0.4493288993835449 	 0.39499378204345703 	 0.38172316551208496 	 
2025-07-30 15:19:02.630274 test begin: paddle.nn.functional.celu(x=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([2, 3175201, 4],"float64"), ) 	 25401608 	 1000 	 0.3082115650177002 	 0.3039379119873047 	 0.2971229553222656 	 0.2874472141265869 	 0.4479398727416992 	 0.4493262767791748 	 0.3946983814239502 	 0.37606287002563477 	 
2025-07-30 15:19:05.255662 test begin: paddle.nn.functional.celu(x=Tensor([2, 4, 3175201],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([2, 4, 3175201],"float64"), ) 	 25401608 	 1000 	 0.3082425594329834 	 0.3060178756713867 	 0.2985966205596924 	 0.28748416900634766 	 0.4480013847351074 	 0.44930148124694824 	 0.39293456077575684 	 0.3828544616699219 	 
2025-07-30 15:19:08.071343 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", ) 	 25401744 	 1000 	 0.31479907035827637 	 0.29743194580078125 	 0.30387425422668457 	 0.2784566879272461 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([176401, 4, 4, 9]) and output[0] has a shape of torch.Size([176401, 9, 4, 4]).
2025-07-30 15:19:10.273752 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", None, ) 	 25401744 	 1000 	 0.31482982635498047 	 0.2985227108001709 	 0.30388951301574707 	 0.27826857566833496 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([176401, 4, 4, 9]) and output[0] has a shape of torch.Size([176401, 9, 4, 4]).
2025-07-30 15:19:12.283709 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 9, 4, 4],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 9, 4, 4],"float64"), 3, "NCHW", ) 	 25401744 	 1000 	 0.31334567070007324 	 0.30433082580566406 	 0.30252599716186523 	 0.2838153839111328 	 0.3135712146759033 	 0.30278611183166504 	 0.26175594329833984 	 0.1884622573852539 	 
2025-07-30 15:19:14.630639 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", ) 	 25401672 	 1000 	 0.3147854804992676 	 1.305241584777832 	 0.30391907691955566 	 1.2852847576141357 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 352801, 4, 9]) and output[0] has a shape of torch.Size([2, 9, 352801, 4]).
2025-07-30 15:19:17.672877 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", None, ) 	 25401672 	 1000 	 0.31478333473205566 	 1.3248717784881592 	 0.30373692512512207 	 1.2838671207427979 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 352801, 4, 9]) and output[0] has a shape of torch.Size([2, 9, 352801, 4]).
2025-07-30 15:19:20.726823 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", ) 	 25401672 	 1000 	 0.31485414505004883 	 1.3039946556091309 	 0.30376553535461426 	 1.2849757671356201 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 4, 352801, 9]) and output[0] has a shape of torch.Size([2, 9, 4, 352801]).
2025-07-30 15:19:23.754298 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", None, ) 	 25401672 	 1000 	 0.3147752285003662 	 1.3052151203155518 	 0.3037679195404053 	 1.2860662937164307 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 4, 352801, 9]) and output[0] has a shape of torch.Size([2, 9, 4, 352801]).
2025-07-30 15:19:26.802784 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 9, 352801, 4],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 9, 352801, 4],"float64"), 3, "NCHW", ) 	 25401672 	 1000 	 0.3141794204711914 	 0.31908082962036133 	 0.3034071922302246 	 0.2847590446472168 	 0.3142726421356201 	 0.3024435043334961 	 0.2558562755584717 	 0.22794055938720703 	 
2025-07-30 15:19:29.129360 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 352801],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 352801],"float64"), 3, "NCHW", ) 	 25401672 	 1000 	 0.3141043186187744 	 0.30587196350097656 	 0.3030257225036621 	 0.28510594367980957 	 0.3143343925476074 	 0.30243349075317383 	 0.26239919662475586 	 0.22868824005126953 	 
2025-07-30 15:19:31.441805 test begin: paddle.nn.functional.conv1d(Tensor([16, 125, 25500],"float32"), Tensor([1, 125, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([16, 125, 25500],"float32"), Tensor([1, 125, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51000126 	 1000 	 0.32439088821411133 	 0.16268515586853027 	 0.07791829109191895 	 0.08298277854919434 	 0.8308043479919434 	 0.3364531993865967 	 0.14109301567077637 	 0.06871175765991211 	 
2025-07-30 15:19:34.084989 test begin: paddle.nn.functional.conv1d(Tensor([16, 64, 49613],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([16, 64, 49613],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50803777 	 1000 	 0.3383002281188965 	 0.5882222652435303 	 0.10782814025878906 	 0.08586335182189941 	 0.7352705001831055 	 0.3617594242095947 	 0.12518978118896484 	 0.0737919807434082 	 
2025-07-30 15:19:39.632399 test begin: paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52040609 	 1000 	 0.39669060707092285 	 0.18469643592834473 	 0.11519455909729004 	 0.09433674812316895 	 0.7711331844329834 	 0.3984377384185791 	 0.131333589553833 	 0.08126354217529297 	 
2025-07-30 15:19:42.252275 test begin: paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52041632 	 1000 	 0.6790771484375 	 0.9965364933013916 	 0.1736745834350586 	 0.5090773105621338 	 1.2968828678131104 	 12.835355281829834 	 0.16525936126708984 	 2.620244026184082 	 
2025-07-30 15:19:59.915484 test begin: paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50803745 	 1000 	 0.3857285976409912 	 0.178086519241333 	 0.1310415267944336 	 0.09098124504089355 	 0.739220142364502 	 0.37058138847351074 	 0.12588739395141602 	 0.07556915283203125 	 
2025-07-30 15:20:02.467888 test begin: paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50804768 	 1000 	 0.6587522029876709 	 0.9476501941680908 	 0.16816020011901855 	 0.48418593406677246 	 1.2603909969329834 	 11.11982774734497 	 0.16087818145751953 	 2.2690958976745605 	 
2025-07-30 15:20:18.211231 test begin: paddle.nn.functional.conv1d(Tensor([32, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52224065 	 1000 	 0.3471097946166992 	 0.1710495948791504 	 0.10978889465332031 	 0.08722758293151855 	 0.640000581741333 	 0.3479187488555908 	 0.08179426193237305 	 0.07086730003356934 	 
2025-07-30 15:20:20.602510 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50978641 	 1000 	 2.262082815170288 	 2.3748042583465576 	 0.7704579830169678 	 0.8098206520080566 	 1.3290278911590576 	 1.0712525844573975 	 0.27252769470214844 	 0.27365756034851074 	 
2025-07-30 15:20:28.585301 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50822772 	 1000 	 0.26598310470581055 	 0.2695598602294922 	 0.09057784080505371 	 0.09187698364257812 	 21.007312059402466 	 9.5967857837677 	 4.287134170532227 	 2.4476726055145264 	 
2025-07-30 15:21:00.787532 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50859776 	 1000 	 0.26400065422058105 	 0.26743292808532715 	 0.08991384506225586 	 0.09057903289794922 	 21.060035943984985 	 20.01731586456299 	 4.29729962348938 	 4.085422515869141 	 
2025-07-30 15:21:43.347393 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 99226],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 99226],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51852544 	 1000 	 14.552159070968628 	 14.675699234008789 	 4.959996700286865 	 5.000246286392212 	 40.05563282966614 	 26.766032457351685 	 6.818959474563599 	 4.550692558288574 	 
2025-07-30 15:23:22.218321 test begin: paddle.nn.functional.conv1d_transpose(Tensor([14176, 512, 7],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([14176, 512, 7],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51855616 	 1000 	 62.86449980735779 	 63.972087144851685 	 21.43343687057495 	 21.571892261505127 	 128.564879655838 	 128.7300033569336 	 21.969958066940308 	 21.879748344421387 	 
2025-07-30 15:29:50.271684 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51152290 	 1000 	 2.232773542404175 	 2.3464479446411133 	 0.7608034610748291 	 0.8005161285400391 	 1.325744867324829 	 1.6022019386291504 	 0.2700650691986084 	 0.41159510612487793 	 
2025-07-30 15:29:58.689995 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 128, 1551],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 128, 1551],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50837632 	 1000 	 0.49535417556762695 	 0.4977223873138428 	 0.1693120002746582 	 0.1692667007446289 	 18.07146382331848 	 38.47530460357666 	 3.687037229537964 	 7.8537397384643555 	 
2025-07-30 15:30:57.463940 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 24807, 8],"float32"), bias=Tensor([24807],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 24807, 8],"float32"), bias=Tensor([24807],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50843879 	 1000 	 0.544119119644165 	 1.0432682037353516 	 0.18581151962280273 	 0.35504889488220215 	 44.1389582157135 	 20.54475712776184 	 7.511700630187988 	 5.241267919540405 	 
2025-07-30 15:32:04.854936 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 99226],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 99226],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51065984 	 1000 	 7.904325246810913 	 7.9884631633758545 	 2.693511962890625 	 2.7248167991638184 	 17.142977237701416 	 13.638399124145508 	 2.9208755493164062 	 2.3190629482269287 	 
2025-07-30 15:32:54.477934 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 49613, 28],"float32"), Tensor([49613, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 49613, 28],"float32"), Tensor([49613, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 53582168 	 1000 	 4.446173191070557 	 4.590934991836548 	 1.5180964469909668 	 1.568732500076294 	 1.834491491317749 	 1.885049819946289 	 0.3122823238372803 	 0.48162078857421875 	 
2025-07-30 15:33:08.967682 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 49613],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 49613],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51852544 	 1000 	 14.567184448242188 	 14.683059930801392 	 4.9657886028289795 	 5.002721071243286 	 29.554525136947632 	 26.769060134887695 	 5.0380964279174805 	 4.5514075756073 	 
2025-07-30 15:34:39.296893 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50826356 	 1000 	 0.4750244617462158 	 0.8841004371643066 	 0.16174578666687012 	 0.3012831211090088 	 21.053975820541382 	 9.612585544586182 	 4.296320199966431 	 2.4490160942077637 	 
2025-07-30 15:35:12.268002 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50863360 	 1000 	 0.4716823101043701 	 0.4780113697052002 	 0.16113853454589844 	 0.16366124153137207 	 20.813716888427734 	 20.053909301757812 	 3.5361123085021973 	 4.094761371612549 	 
2025-07-30 15:35:55.065729 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 907201, 28],"float32"), Tensor([907201, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 907201, 28],"float32"), Tensor([907201, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 979777208 	 1000 	 80.79346323013306 	 84.64534401893616 	 27.551599264144897 	 28.86513590812683 	 35.73148036003113 	 36.048091173172 	 6.097424745559692 	 7.374561309814453 	 
2025-07-30 15:40:10.990094 test begin: paddle.nn.functional.conv1d_transpose(Tensor([7088, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([7088, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51069056 	 1000 	 8.889476776123047 	 8.983028173446655 	 3.029763698577881 	 3.0616862773895264 	 23.377221822738647 	 22.070247411727905 	 3.9905552864074707 	 3.7533798217773438 	 
2025-07-30 15:41:17.012751 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 191, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 191, 4],"float32"), ) 	 50852604 	 1000 	 0.37595701217651367 	 0.376575231552124 	 0.3293886184692383 	 0.3559901714324951 	 70.06986951828003 	 4.027339696884155 	 23.821640014648438 	 1.029541254043579 	 
2025-07-30 15:42:32.851065 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50851856 	 1000 	 1.0993309020996094 	 1.1055803298950195 	 1.0529289245605469 	 1.0846514701843262 	 11.890363216400146 	 13.113396406173706 	 4.062480688095093 	 4.469794750213623 	 
2025-07-30 15:43:01.911430 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 192, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 192, 4],"float32"), ) 	 50922240 	 1000 	 0.9610762596130371 	 1.1876554489135742 	 0.49065732955932617 	 1.1657905578613281 	 70.36381554603577 	 70.88954663276672 	 23.94899845123291 	 24.106308460235596 	 
2025-07-30 15:45:26.332952 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50921488 	 1000 	 1.1001365184783936 	 1.1124753952026367 	 1.0526807308197021 	 1.087446689605713 	 11.832092523574829 	 13.128470182418823 	 4.032429456710815 	 4.474978446960449 	 
2025-07-30 15:45:55.273564 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 193, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 193, 4],"float32"), ) 	 50989828 	 1000 	 0.9819872379302979 	 0.3760240077972412 	 0.5016579627990723 	 0.35566282272338867 	 70.84038472175598 	 71.28994512557983 	 24.089898109436035 	 24.24320077896118 	 
2025-07-30 15:48:19.782841 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50989072 	 1000 	 1.2861571311950684 	 1.2235844135284424 	 1.239699363708496 	 1.1985538005828857 	 11.842419862747192 	 13.143348455429077 	 4.029993772506714 	 4.481534481048584 	 
2025-07-30 15:48:49.479621 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 193],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 193],"float32"), ) 	 50989828 	 1000 	 1.365077257156372 	 2.864802598953247 	 0.695807695388794 	 2.8306150436401367 	 58.77763557434082 	 58.797844886779785 	 19.983906269073486 	 19.99082374572754 	 
2025-07-30 15:50:52.326685 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50989072 	 1000 	 1.1091513633728027 	 1.510483980178833 	 1.0559141635894775 	 1.4817070960998535 	 11.95703911781311 	 13.161447525024414 	 4.076765298843384 	 4.485977411270142 	 
2025-07-30 15:51:23.009315 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 68161552 	 1000 	 1.4800803661346436 	 1.5109291076660156 	 1.431525707244873 	 1.4579505920410156 	 16.043980836868286 	 17.62981367111206 	 5.4804840087890625 	 6.010634422302246 	 
2025-07-30 15:52:02.648298 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 192],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 192],"float32"), ) 	 50922240 	 1000 	 2.3225107192993164 	 2.262749195098877 	 1.1858510971069336 	 2.2414631843566895 	 58.457284688949585 	 58.47706127166748 	 19.878485679626465 	 19.88059401512146 	 
2025-07-30 15:54:05.310219 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50921488 	 1000 	 1.1069612503051758 	 1.1150434017181396 	 1.0514814853668213 	 1.0936918258666992 	 12.046931743621826 	 13.134758949279785 	 4.099597215652466 	 4.477150201797485 	 
2025-07-30 15:54:34.528194 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 68690960 	 1000 	 1.485060691833496 	 1.5136463642120361 	 1.4310266971588135 	 1.4781172275543213 	 16.148919343948364 	 17.778578519821167 	 5.4880077838897705 	 6.060788154602051 	 
2025-07-30 15:55:14.585696 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 191],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 191],"float32"), ) 	 50852604 	 1000 	 2.806713104248047 	 2.978468179702759 	 2.7599523067474365 	 2.957426071166992 	 57.74195647239685 	 3.269785165786743 	 19.631972312927246 	 0.8334028720855713 	 
2025-07-30 15:56:22.340339 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50851856 	 1000 	 1.105888843536377 	 1.1132702827453613 	 1.0581238269805908 	 1.0891649723052979 	 11.921390295028687 	 13.12981390953064 	 4.070527791976929 	 4.475308656692505 	 
2025-07-30 15:56:51.847837 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 69222416 	 1000 	 1.4987850189208984 	 1.5070371627807617 	 1.451963186264038 	 1.4860856533050537 	 16.18634533882141 	 17.92468500137329 	 5.525633335113525 	 6.108640432357788 	 
2025-07-30 15:57:31.412976 test begin: paddle.nn.functional.conv2d(Tensor([752, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([752, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50835216 	 1000 	 1.1016693115234375 	 1.1094863414764404 	 1.0541222095489502 	 1.076298713684082 	 12.64744520187378 	 12.74704647064209 	 4.311777591705322 	 4.345311641693115 	 
2025-07-30 15:58:00.873859 test begin: paddle.nn.functional.conv2d(Tensor([758, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([758, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50847414 	 1000 	 1.1020748615264893 	 1.1263587474822998 	 1.0534312725067139 	 1.0902554988861084 	 12.60750937461853 	 12.699005365371704 	 4.296839475631714 	 4.327133417129517 	 
2025-07-30 15:58:30.289650 test begin: paddle.nn.functional.conv2d(Tensor([764, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([764, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50854912 	 1000 	 1.1027863025665283 	 1.1146438121795654 	 1.0528252124786377 	 1.0943140983581543 	 12.512627363204956 	 12.651308536529541 	 4.265618562698364 	 4.3120973110198975 	 
2025-07-30 15:58:59.455266 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 32, 320, 320],"float32"), Tensor([32, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 32, 320, 320],"float32"), Tensor([32, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 52428929 	 1000 	 0.6279218196868896 	 0.6291475296020508 	 0.21335625648498535 	 0.21425843238830566 	 0.6695506572723389 	 0.6215353012084961 	 0.09767317771911621 	 0.10680222511291504 	 
2025-07-30 15:59:02.969865 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 156, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 156, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51118337 	 1000 	 0.5175812244415283 	 0.5231189727783203 	 0.1762404441833496 	 0.17878937721252441 	 0.5629973411560059 	 0.5404632091522217 	 0.08168363571166992 	 0.09185481071472168 	 
2025-07-30 15:59:06.068058 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 320, 156],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 320, 156],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51118337 	 1000 	 0.5174970626831055 	 0.5205581188201904 	 0.17624688148498535 	 0.17743444442749023 	 0.5503625869750977 	 0.5411112308502197 	 0.08008408546447754 	 0.09306192398071289 	 
2025-07-30 15:59:09.087534 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 56, 480, 480],"float32"), Tensor([56, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 56, 480, 480],"float32"), Tensor([56, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51609825 	 1000 	 0.5371758937835693 	 0.537705659866333 	 0.1832880973815918 	 0.18327689170837402 	 0.6114487648010254 	 0.6082911491394043 	 0.08920145034790039 	 0.10315132141113281 	 
2025-07-30 15:59:12.273709 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 414, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 414, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5155167579650879 	 0.5221540927886963 	 0.17627882957458496 	 0.17773151397705078 	 0.5827639102935791 	 0.5714216232299805 	 0.08594727516174316 	 0.09687423706054688 	 
2025-07-30 15:59:17.200081 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 414],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 414],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5137879848480225 	 0.5274820327758789 	 0.1749422550201416 	 0.17641758918762207 	 0.5825152397155762 	 0.5757105350494385 	 0.08496499061584473 	 0.09719324111938477 	 
2025-07-30 15:59:21.292602 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 58982657 	 1000 	 0.5938785076141357 	 0.5962467193603516 	 0.20229387283325195 	 0.20325160026550293 	 0.6643381118774414 	 0.6562585830688477 	 0.09688973426818848 	 0.11155581474304199 	 
2025-07-30 15:59:24.823837 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 28, 480, 480],"float32"), Tensor([28, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 28, 480, 480],"float32"), Tensor([28, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51609713 	 1000 	 0.7031588554382324 	 0.703803300857544 	 0.23983335494995117 	 0.23993492126464844 	 0.6979084014892578 	 0.6633620262145996 	 0.10174369812011719 	 0.11272144317626953 	 
2025-07-30 15:59:28.621392 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 207, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 207, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5155887603759766 	 0.5188753604888916 	 0.17501091957092285 	 0.17638754844665527 	 0.5643892288208008 	 0.5541694164276123 	 0.08189916610717773 	 0.0939490795135498 	 
2025-07-30 15:59:31.685417 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 320, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 320, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 52429057 	 1000 	 0.5298404693603516 	 0.5333611965179443 	 0.18052172660827637 	 0.18179631233215332 	 0.5684187412261963 	 0.5635631084442139 	 0.08289027214050293 	 0.09680342674255371 	 
2025-07-30 15:59:34.845586 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 480, 207],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 480, 207],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5139386653900146 	 0.5248034000396729 	 0.17502593994140625 	 0.17638206481933594 	 0.5551152229309082 	 0.5540785789489746 	 0.08094978332519531 	 0.09413909912109375 	 
2025-07-30 15:59:39.828910 test begin: paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 6.41107439994812 	 1.4820590019226074 	 6.294410705566406 	 1.4643666744232178 	 44.27866744995117 	 18.336750507354736 	 22.62856435775757 	 9.372352600097656 	 
2025-07-30 16:00:52.050087 test begin: paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.056556940078735 	 12.112444400787354 	 11.955384731292725 	 12.047595024108887 	 81.27735090255737 	 22.99472713470459 	 20.807260990142822 	 5.873138904571533 	 
2025-07-30 16:03:02.733011 test begin: paddle.nn.functional.conv3d(Tensor([33076, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([33076, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50805146 	 1000 	 19.0275981426239 	 26.39593482017517 	 9.722522974014282 	 13.491096019744873 	 241.58892488479614 	 47.27782082557678 	 35.29330563545227 	 6.8996193408966064 	 
2025-07-30 16:08:40.598379 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 66151, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 66151, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 19.286675214767456 	 19.234090566635132 	 9.855950355529785 	 9.821552276611328 	 263.2529866695404 	 278.7994737625122 	 45.017207622528076 	 47.36117434501648 	 
2025-07-30 16:18:25.082219 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 8, 66151, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 8, 66151, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 15.290262937545776 	 15.479236125946045 	 7.812055826187134 	 7.909898042678833 	 215.35156273841858 	 224.83707737922668 	 36.966800689697266 	 38.266104221343994 	 
2025-07-30 16:26:19.379355 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 66151],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 66151],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 14.976726531982422 	 15.447270393371582 	 7.65275502204895 	 7.895487070083618 	 197.90135192871094 	 222.37590312957764 	 33.87436270713806 	 37.81678867340088 	 
2025-07-30 16:33:53.238675 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.493316888809204 	 1.9648213386535645 	 8.392223596572876 	 1.9417674541473389 	 59.159273624420166 	 22.240373849868774 	 30.227391958236694 	 11.361505031585693 	 
2025-07-30 16:35:27.226105 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.222970724105835 	 12.273557901382446 	 12.12144136428833 	 12.230354070663452 	 89.34963035583496 	 87.34341049194336 	 18.319814443588257 	 22.278071880340576 	 
2025-07-30 16:38:50.713982 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.580985069274902 	 1.9654417037963867 	 8.45566177368164 	 1.9474163055419922 	 58.55247902870178 	 12.236304998397827 	 29.915751457214355 	 6.249619007110596 	 
2025-07-30 16:40:14.305537 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.064690113067627 	 12.080573320388794 	 11.962611198425293 	 12.036215782165527 	 88.51794576644897 	 92.77273774147034 	 18.151137828826904 	 31.544596910476685 	 
2025-07-30 16:43:42.019834 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.49899411201477 	 2.011410713195801 	 8.393052816390991 	 1.9907302856445312 	 59.780925989151 	 13.238344669342041 	 30.54985284805298 	 6.760869979858398 	 
2025-07-30 16:45:07.492951 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 11.952701568603516 	 12.009278297424316 	 11.850563764572144 	 11.963877201080322 	 92.22496438026428 	 102.43768644332886 	 18.90396237373352 	 34.83147048950195 	 
2025-07-30 16:48:48.745709 test begin: paddle.nn.functional.conv3d_transpose(Tensor([2, 2451, 2, 2, 2],"float32"), Tensor([2451, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([2, 2451, 2, 2, 2],"float32"), Tensor([2451, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", ) 	 50863164 	 1000 	 3.1208243370056152 	 0.6361188888549805 	 1.06396484375 	 0.21845412254333496 	 4.524264335632324 	 4.527242660522461 	 0.770240068435669 	 1.1542391777038574 	 
2025-07-30 16:49:02.699713 test begin: paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805066 	 1000 	 15.73860239982605 	 26.993707180023193 	 8.043145656585693 	 13.790873765945435 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([24807, 6, 8, 6, 8]) and output[0] has a shape of torch.Size([24807, 6, 10, 10, 10]).
2025-07-30 16:51:48.159463 test begin: paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", ) 	 50805172 	 1000 	 20.948667526245117 	 20.096673488616943 	 7.147729396820068 	 6.8532021045684814 	 135.11437964439392 	 25.63938879966736 	 23.113956451416016 	 5.225784063339233 	 
2025-07-30 16:55:14.460478 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 49613, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 49613, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 5.701703071594238 	 31.461945295333862 	 2.913634777069092 	 16.075996160507202 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 49613, 6, 8]) and output[0] has a shape of torch.Size([4, 6, 49615, 10, 10]).
2025-07-30 16:58:11.428689 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 49613, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 49613, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 7.418224334716797 	 28.64107656478882 	 3.790942907333374 	 14.630690813064575 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 8, 49611, 8]) and output[0] has a shape of torch.Size([4, 6, 10, 49615, 10]).
2025-07-30 17:01:11.486123 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 49613],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 49613],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 5.623572587966919 	 30.654168844223022 	 2.8753302097320557 	 15.661890745162964 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 8, 6, 49613]) and output[0] has a shape of torch.Size([4, 6, 10, 10, 49615]).
2025-07-30 17:03:50.084304 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), Tensor([10],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), Tensor([10],"int64"), margin=0.5, reduction="mean", name=None, ) 	 101606430 	 1000 	 1.730468988418579 	 1.6368300914764404 	 0.06737184524536133 	 0.06615304946899414 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:03:59.726636 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([16934401, 3],"float32"), Tensor([16934401, 3],"float32"), Tensor([16934401],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([16934401, 3],"float32"), Tensor([16934401, 3],"float32"), Tensor([16934401],"int64"), margin=0.5, reduction="mean", name=None, ) 	 118540807 	 1000 	 3.964412212371826 	 3.920260429382324 	 0.1678318977355957 	 0.17336606979370117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:04:15.268725 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([25401601, 3],"float32"), Tensor([25401601, 3],"float32"), Tensor([25401601],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([25401601, 3],"float32"), Tensor([25401601, 3],"float32"), Tensor([25401601],"int64"), margin=0.5, reduction="mean", name=None, ) 	 177811207 	 1000 	 5.915819406509399 	 5.83029842376709 	 0.2495870590209961 	 0.25802111625671387 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:04:39.885735 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="mean", ) 	 50803215 	 1000 	 1.8267443180084229 	 1.584646463394165 	 0.07096576690673828 	 0.0641472339630127 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:04:47.452710 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="none", ) 	 50803215 	 1000 	 1.8196682929992676 	 1.5749144554138184 	 0.07384204864501953 	 0.06613898277282715 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:04:54.954040 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="mean", ) 	 355622407 	 1000 	 19.434888124465942 	 19.443973779678345 	 0.8226802349090576 	 0.8596129417419434 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:06:11.682632 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="none", ) 	 355622407 	 1000 	 19.148450136184692 	 19.163012504577637 	 0.8847534656524658 	 0.931896448135376 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:07:30.245715 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="mean", ) 	 59270407 	 1000 	 3.3380472660064697 	 3.380282402038574 	 0.14241909980773926 	 0.14791440963745117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:07:43.693527 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="none", ) 	 59270407 	 1000 	 3.2803943157196045 	 3.284400701522827 	 0.15150690078735352 	 0.15883421897888184 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:07:56.663677 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 12, 423361],"float32"), Tensor([10, 1, 423361],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 12, 423361],"float32"), Tensor([10, 1, 423361],"float32"), axis=2, eps=1e-06, ) 	 55036930 	 1000 	 1.0576426982879639 	 1.4091830253601074 	 0.08244109153747559 	 0.11097288131713867 	 3.174470901489258 	 7.075343132019043 	 0.20370817184448242 	 0.2670783996582031 	 
2025-07-30 17:08:10.352324 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, ) 	 50803400 	 1000 	 1.406313180923462 	 2.108842372894287 	 0.14416217803955078 	 0.18109512329101562 	 7.7139270305633545 	 7.862530469894409 	 0.4408144950866699 	 0.30957579612731934 	 
2025-07-30 17:08:30.706149 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 508033, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 508033, 10],"float32"), axis=2, eps=1e-06, ) 	 101606600 	 1000 	 2.208319664001465 	 2.5831427574157715 	 0.22516441345214844 	 0.21863460540771484 	 5.843068361282349 	 7.811420917510986 	 0.4261744022369385 	 0.33190226554870605 	 
2025-07-30 17:08:51.180620 test begin: paddle.nn.functional.cosine_similarity(Tensor([210, 241921],"float32"), Tensor([210, 241921],"float32"), axis=-1, eps=1e-08, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([210, 241921],"float32"), Tensor([210, 241921],"float32"), axis=-1, eps=1e-08, ) 	 101606820 	 1000 	 1.5885405540466309 	 1.5783514976501465 	 0.12558603286743164 	 0.12276697158813477 	 5.389542579650879 	 7.0183939933776855 	 0.39399170875549316 	 0.2770051956176758 	 
2025-07-30 17:09:08.738416 test begin: paddle.nn.functional.cosine_similarity(Tensor([32, 1587601],"float32"), Tensor([32, 1587601],"float32"), )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([32, 1587601],"float32"), Tensor([32, 1587601],"float32"), ) 	 101606464 	 1000 	 1.5296940803527832 	 1.618906021118164 	 0.11956238746643066 	 0.12738442420959473 	 5.389677047729492 	 7.05616569519043 	 0.39397549629211426 	 0.2798335552215576 	 
2025-07-30 17:09:26.668390 test begin: paddle.nn.functional.cosine_similarity(Tensor([396901, 128],"float32"), Tensor([396901, 128],"float32"), )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([396901, 128],"float32"), Tensor([396901, 128],"float32"), ) 	 101606656 	 1000 	 2.3444478511810303 	 1.6089129447937012 	 0.24159526824951172 	 0.1369791030883789 	 5.435681343078613 	 7.061516761779785 	 0.39608335494995117 	 0.29994988441467285 	 
2025-07-30 17:09:47.890828 test begin: paddle.nn.functional.cosine_similarity(Tensor([423361, 12, 10],"float32"), Tensor([423361, 1, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([423361, 12, 10],"float32"), Tensor([423361, 1, 10],"float32"), axis=2, eps=1e-06, ) 	 55036930 	 1000 	 1.4686338901519775 	 2.138974189758301 	 0.14932799339294434 	 0.18111085891723633 	 3.569457530975342 	 7.86210823059082 	 0.2277529239654541 	 0.32082533836364746 	 
2025-07-30 17:10:04.169902 test begin: paddle.nn.functional.cosine_similarity(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), axis=-1, eps=1e-08, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), axis=-1, eps=1e-08, ) 	 101607424 	 1000 	 1.4980158805847168 	 1.5321660041809082 	 0.1541576385498047 	 0.15652179718017578 	 5.395426988601685 	 7.031320810317993 	 0.39318227767944336 	 0.30005741119384766 	 
2025-07-30 17:10:21.436546 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 1024, 50304],"float32"), Tensor([1, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 1024, 50304],"float32"), Tensor([1, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 51512320 	 1000 	 0.6515889167785645 	 86.20358061790466 	 0.13422155380249023 	 29.395466327667236 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1024, 1]) and output[0] has a shape of torch.Size([1, 1024]).
2025-07-30 17:11:49.823539 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2048, 151936],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 2048, 151936],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 311166976 	 1000 	 3.8048834800720215 	 270.8978786468506 	 0.7806811332702637 	 92.35686254501343 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 2048, 1]) and output[0] has a shape of torch.Size([1, 2048]).
2025-07-30 17:16:33.972538 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2048, 24807],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 2048, 24807],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50806784 	 1000 	 0.47428321838378906 	 43.20103192329407 	 0.09663748741149902 	 14.667758464813232 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 2048, 1]) and output[0] has a shape of torch.Size([1, 2048]).
2025-07-30 17:17:20.299391 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 335, 151936],"float32"), Tensor([1, 335, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 335, 151936],"float32"), Tensor([1, 335, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50898895 	 1000 	 0.6761250495910645 	 239.12194085121155 	 0.13798165321350098 	 81.52658128738403 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 335, 1]) and output[0] has a shape of torch.Size([1, 335]).
2025-07-30 17:21:22.527602 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 4096, 100352],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 4096, 100352],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 411045888 	 1000 	 4.961332082748413 	 190.54014682769775 	 1.014632225036621 	 64.97026205062866 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 4096, 1]) and output[0] has a shape of torch.Size([1, 4096]).
2025-07-30 17:24:50.141897 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 4096, 12404],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 4096, 12404],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50810880 	 1000 	 0.3919064998626709 	 22.23939847946167 	 0.08029055595397949 	 7.580075740814209 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 4096, 1]) and output[0] has a shape of torch.Size([1, 4096]).
2025-07-30 17:25:14.238012 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 507, 100352],"float32"), Tensor([1, 507, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 507, 100352],"float32"), Tensor([1, 507, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50878971 	 1000 	 0.6531004905700684 	 161.3304316997528 	 0.13333916664123535 	 54.99221611022949 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 507, 1]) and output[0] has a shape of torch.Size([1, 507]).
2025-07-30 17:27:58.214930 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 1024, 6202],"float32"), Tensor([8, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([8, 1024, 6202],"float32"), Tensor([8, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50814976 	 1000 	 0.4348468780517578 	 11.64769172668457 	 0.08909201622009277 	 3.96439528465271 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 1024, 1]) and output[0] has a shape of torch.Size([8, 1024]).
2025-07-30 17:28:12.065740 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 127, 50304],"float32"), Tensor([8, 127, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([8, 127, 50304],"float32"), Tensor([8, 127, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 51109880 	 1000 	 0.6463963985443115 	 72.60791754722595 	 0.13245248794555664 	 24.762282848358154 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 127, 1]) and output[0] has a shape of torch.Size([8, 127]).
2025-07-30 17:29:26.697740 test begin: paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016093120 	 1000 	 0.0010824203491210938 	 0.007092714309692383 	 7.867813110351562e-06 	 2.6941299438476562e-05 	 0.03174614906311035 	 4.492639064788818 	 3.933906555175781e-05 	 2.2991533279418945 	 combined
2025-07-30 17:30:17.978610 test begin: paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016133120 	 1000 	 0.0019333362579345703 	 0.007066965103149414 	 1.2874603271484375e-05 	 2.86102294921875e-05 	 0.03175687789916992 	 4.49567985534668 	 4.792213439941406e-05 	 2.2961578369140625 	 combined
2025-07-30 17:31:04.057736 test begin: paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016076800 	 1000 	 0.0009920597076416016 	 0.009046316146850586 	 8.58306884765625e-06 	 8.296966552734375e-05 	 0.03245735168457031 	 4.498145341873169 	 5.53131103515625e-05 	 2.297849178314209 	 combined
2025-07-30 17:31:43.391389 test begin: paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016099200 	 1000 	 0.0010008811950683594 	 0.007071733474731445 	 7.62939453125e-06 	 3.814697265625e-05 	 0.03424191474914551 	 4.488947153091431 	 5.1975250244140625e-05 	 2.294543504714966 	 combined
2025-07-30 17:32:27.503928 test begin: paddle.nn.functional.elu(Tensor([1, 21504, 2363],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1, 21504, 2363],"float32"), ) 	 50813952 	 1000 	 0.2970616817474365 	 0.30061864852905273 	 0.2804739475250244 	 0.2719714641571045 	 0.45030975341796875 	 0.4485816955566406 	 0.38626623153686523 	 0.37589359283447266 	 
2025-07-30 17:32:30.843487 test begin: paddle.nn.functional.elu(Tensor([1, 25401601, 2],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1, 25401601, 2],"float32"), ) 	 50803202 	 1000 	 0.2969551086425781 	 0.31578636169433594 	 0.28746604919433594 	 0.2838292121887207 	 0.45001673698425293 	 0.44843602180480957 	 0.39551806449890137 	 0.3811953067779541 	 
2025-07-30 17:32:34.030092 test begin: paddle.nn.functional.elu(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29566407203674316 	 0.3004579544067383 	 0.28615570068359375 	 0.28262758255004883 	 0.45030808448791504 	 0.4484262466430664 	 0.39576196670532227 	 0.3784372806549072 	 
2025-07-30 17:32:39.514944 test begin: paddle.nn.functional.elu(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2955801486968994 	 0.29980921745300293 	 0.2791414260864258 	 0.2718994617462158 	 0.45140790939331055 	 0.4483940601348877 	 0.3871605396270752 	 0.3740108013153076 	 
2025-07-30 17:32:42.686384 test begin: paddle.nn.functional.elu(Tensor([1182, 21504, 2],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1182, 21504, 2],"float32"), ) 	 50835456 	 1000 	 0.2956664562225342 	 0.31299400329589844 	 0.28606534004211426 	 0.2822904586791992 	 0.45044565200805664 	 0.4513204097747803 	 0.3950216770172119 	 0.38416147232055664 	 
2025-07-30 17:32:46.050390 test begin: paddle.nn.functional.elu(Tensor([15, 3386881],"float32"), 1.0, )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([15, 3386881],"float32"), 1.0, ) 	 50803215 	 1000 	 0.29555273056030273 	 0.2992873191833496 	 0.2789788246154785 	 0.2754936218261719 	 0.45006656646728516 	 0.44982481002807617 	 0.38543200492858887 	 0.37619948387145996 	 
2025-07-30 17:32:49.277291 test begin: paddle.nn.functional.elu(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2969388961791992 	 0.29921936988830566 	 0.28751301765441895 	 0.282581090927124 	 0.4515805244445801 	 0.448392391204834 	 0.39601826667785645 	 0.3821234703063965 	 
2025-07-30 17:32:52.468288 test begin: paddle.nn.functional.elu(Tensor([2540161, 20],"float32"), 1.0, )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([2540161, 20],"float32"), 1.0, ) 	 50803220 	 1000 	 0.2954905033111572 	 0.3028552532196045 	 0.2860541343688965 	 0.2833092212677002 	 0.45116281509399414 	 0.4509587287902832 	 0.3966817855834961 	 0.38308143615722656 	 
2025-07-30 17:32:55.673530 test begin: paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([12404, 8192],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 17:32:57.845014 135521 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([12404, 8192],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101617665 	 1000 	 0.15311050415039062 	 0.4058670997619629 	 0.14105916023254395 	 0.3766660690307617 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:32:58.416497 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 17:33:01.417186 135816 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101748608 	 1000 	 0.37273454666137695 	 0.9202840328216553 	 0.36071300506591797 	 0.8994979858398438 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:33:02.574246 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 17:33:13.012379 136666 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101712896 	 1000 	 1.7900595664978027 	 5.529271364212036 	 1.775928258895874 	 5.504789352416992 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:33:19.581053 test begin: paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 17:33:29.427727 138579 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 102070373 	 1000 	 1.8871550559997559 	 5.544300079345703 	 1.8734428882598877 	 5.522961854934692 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:33:37.254164 test begin: paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([24807, 4096],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([24807, 4096],"float16"), padding_idx=None, sparse=False, name=None, ) 	 101617664 	 1000 	 0.15081429481506348 	 0.4641847610473633 	 0.13925981521606445 	 0.422135591506958 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:33:41.152916 test begin: paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, ) 	 102434304 	 1000 	 7.209973096847534 	 22.340692281723022 	 7.19629168510437 	 22.30971074104309 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 17:34:55.564159 test begin: paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), ) 	 6400 	 1000 	 0.018343210220336914 	 214.8277018070221 	 2.09808349609375e-05 	 0.0002834796905517578 	 None 	 None 	 None 	 None 	 combined
2025-07-30 17:38:30.771745 test begin: paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), ) 	 6400 	 1000 	 0.01830124855041504 	 213.79978013038635 	 1.811981201171875e-05 	 0.00029921531677246094 	 None 	 None 	 None 	 None 	 combined
2025-07-30 17:42:04.926873 test begin: paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), ) 	 8960 	 1000 	 0.01104116439819336 	 300.1011118888855 	 1.7881393432617188e-05 	 0.0002827644348144531 	 None 	 None 	 None 	 None 	 combined
2025-07-30 17:47:05.423631 test begin: paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), ) 	 4800 	 1000 	 0.015288352966308594 	 158.37331366539001 	 2.6702880859375e-05 	 0.0002892017364501953 	 None 	 None 	 None 	 None 	 combined
2025-07-30 17:49:45.178307 test begin: paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), ) 	 9120 	 1000 	 0.011152029037475586 	 295.8264100551605 	 1.8358230590820312e-05 	 0.0002903938293457031 	 None 	 None 	 None 	 None 	 combined
2025-07-30 17:54:41.326220 test begin: paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), ) 	 9120 	 1000 	 0.011097431182861328 	 296.940060377121 	 2.6941299438476562e-05 	 0.00028228759765625 	 None 	 None 	 None 	 None 	 combined
2025-07-30 17:59:39.341634 test begin: paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), ) 	 4800 	 1000 	 0.013056278228759766 	 154.6873815059662 	 5.245208740234375e-05 	 0.0002949237823486328 	 None 	 None 	 None 	 None 	 combined
2025-07-30 18:02:14.218697 test begin: paddle.nn.functional.gather_tree(Tensor([200, 4, 4],"int64"), Tensor([200, 4, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([200, 4, 4],"int64"), Tensor([200, 4, 4],"int64"), ) 	 6400 	 1000 	 0.011390447616577148 	 212.57518982887268 	 2.47955322265625e-05 	 0.00032973289489746094 	 None 	 None 	 None 	 None 	 combined
2025-07-30 18:05:47.111135 test begin: paddle.nn.functional.gelu(Tensor([11, 96, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([11, 96, 96, 512],"float32"), False, None, ) 	 51904512 	 1000 	 0.34763026237487793 	 0.321103572845459 	 0.33853983879089355 	 0.29057836532592773 	 0.45795345306396484 	 0.46058130264282227 	 0.40157008171081543 	 0.39321231842041016 	 
2025-07-30 18:05:50.475969 test begin: paddle.nn.functional.gelu(Tensor([124, 9, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 9, 96, 512],"float32"), False, None, ) 	 54853632 	 1000 	 0.36664581298828125 	 0.33556485176086426 	 0.3575863838195801 	 0.3075590133666992 	 0.4833188056945801 	 0.48511171340942383 	 0.42984533309936523 	 0.41774797439575195 	 
2025-07-30 18:05:53.925316 test begin: paddle.nn.functional.gelu(Tensor([124, 96, 9, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 96, 9, 512],"float32"), False, None, ) 	 54853632 	 1000 	 0.3682544231414795 	 0.3212707042694092 	 0.3592085838317871 	 0.3101344108581543 	 0.48520541191101074 	 0.4851689338684082 	 0.4314117431640625 	 0.41718506813049316 	 
2025-07-30 18:05:57.375024 test begin: paddle.nn.functional.gelu(Tensor([124, 96, 96, 45],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 96, 96, 45],"float32"), False, None, ) 	 51425280 	 1000 	 0.344285249710083 	 0.3017153739929199 	 0.3349432945251465 	 0.28395867347717285 	 0.4560203552246094 	 0.4563148021697998 	 0.39290499687194824 	 0.3802833557128906 	 
2025-07-30 18:06:02.853577 test begin: paddle.nn.functional.gelu(Tensor([128, 6, 96, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 6, 96, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.37847328186035156 	 0.3375542163848877 	 0.36934781074523926 	 0.320253849029541 	 0.4987325668334961 	 0.5046083927154541 	 0.4450724124908447 	 0.4358675479888916 	 
2025-07-30 18:06:06.817365 test begin: paddle.nn.functional.gelu(Tensor([128, 9, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 9, 96, 512],"float32"), False, None, ) 	 56623104 	 1000 	 0.37965893745422363 	 0.3316314220428467 	 0.37051892280578613 	 0.3204789161682129 	 0.4987354278564453 	 0.5006270408630371 	 0.44337010383605957 	 0.43273067474365234 	 
2025-07-30 18:06:10.409254 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 6, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 6, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.3811478614807129 	 0.3315756320953369 	 0.37207603454589844 	 0.32050228118896484 	 0.5001862049102783 	 0.5006582736968994 	 0.4464569091796875 	 0.4337790012359619 	 
2025-07-30 18:06:14.043618 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 9, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 9, 512],"float32"), False, None, ) 	 56623104 	 1000 	 0.3812699317932129 	 0.33332204818725586 	 0.36971497535705566 	 0.3197319507598877 	 0.5015606880187988 	 0.5020058155059814 	 0.414015531539917 	 0.43338680267333984 	 
2025-07-30 18:06:17.806688 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 96, 44],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 96, 44],"float32"), False, None, ) 	 51904512 	 1000 	 0.34752821922302246 	 0.31880664825439453 	 0.33130788803100586 	 0.28823161125183105 	 0.45865535736083984 	 0.46059608459472656 	 0.3954892158508301 	 0.3852074146270752 	 
2025-07-30 18:06:21.124013 test begin: paddle.nn.functional.gelu(Tensor([8, 96, 96, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([8, 96, 96, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.37987661361694336 	 0.33158087730407715 	 0.3708608150482178 	 0.32053470611572266 	 0.49978160858154297 	 0.5020058155059814 	 0.4462549686431885 	 0.43384766578674316 	 
2025-07-30 18:06:24.759575 test begin: paddle.nn.functional.glu(Tensor([200, 498, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([200, 498, 512],"float32"), -1, None, ) 	 50995200 	 1000 	 0.7212929725646973 	 0.24860668182373047 	 0.24605011940002441 	 0.2253427505493164 	 1.1135239601135254 	 0.38146471977233887 	 0.3785746097564697 	 0.30960965156555176 	 
2025-07-30 18:06:28.592382 test begin: paddle.nn.functional.glu(Tensor([209, 477, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([209, 477, 512],"float32"), -1, None, ) 	 51042816 	 1000 	 0.7217881679534912 	 0.24689602851867676 	 0.24538207054138184 	 0.22600555419921875 	 1.1159923076629639 	 0.3804783821105957 	 0.3802909851074219 	 0.31031107902526855 	 
2025-07-30 18:06:32.332879 test begin: paddle.nn.functional.glu(Tensor([218, 457, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([218, 457, 512],"float32"), -1, None, ) 	 51008512 	 1000 	 0.7217023372650146 	 1.1457383632659912 	 0.24533724784851074 	 0.2257852554321289 	 1.1137685775756836 	 0.38028860092163086 	 0.3787057399749756 	 0.30815911293029785 	 
2025-07-30 18:06:39.507217 test begin: paddle.nn.functional.glu(Tensor([30, 3308, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([30, 3308, 512],"float32"), -1, None, ) 	 50810880 	 1000 	 0.7189493179321289 	 0.24631595611572266 	 0.24521708488464355 	 0.22551393508911133 	 1.1090211868286133 	 0.37873220443725586 	 0.37714099884033203 	 0.29642295837402344 	 
2025-07-30 18:06:43.204166 test begin: paddle.nn.functional.glu(Tensor([30, 457, 3706],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([30, 457, 3706],"float32"), -1, None, ) 	 50809260 	 1000 	 0.7452831268310547 	 0.2593042850494385 	 0.2545809745788574 	 0.22997188568115234 	 1.175715446472168 	 0.3825235366821289 	 0.4002242088317871 	 0.31348633766174316 	 
2025-07-30 18:06:47.030931 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 254017, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 254017, 2],"float32"), align_corners=False, ) 	 109785800 	 1000 	 0.7027418613433838 	 0.7256202697753906 	 0.6900720596313477 	 0.7070102691650391 	 2.7028636932373047 	 2.748012065887451 	 1.3789646625518799 	 1.4040672779083252 	 
2025-07-30 18:06:56.277444 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, ) 	 111667200 	 1000 	 0.7285184860229492 	 0.7525742053985596 	 0.7160670757293701 	 0.7341735363006592 	 2.808720350265503 	 2.8549461364746094 	 1.4331226348876953 	 1.4586942195892334 	 
2025-07-30 18:07:07.325857 test begin: paddle.nn.functional.grid_sample(Tensor([100, 21, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 21, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, ) 	 1291315200 	 1000 	 17.210222721099854 	 15.048407554626465 	 17.18924617767334 	 15.00764513015747 	 58.341880559921265 	 58.27872133255005 	 29.808995962142944 	 11.946560621261597 	 
2025-07-30 18:10:09.182973 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.5580346584320068 	 0.567786455154419 	 0.5455489158630371 	 0.5345830917358398 	 3.311326503753662 	 3.095301866531372 	 1.6901769638061523 	 1.5813727378845215 	 
2025-07-30 18:10:27.745773 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, ) 	 509740000 	 1000 	 0.1021726131439209 	 0.09842514991760254 	 0.08967971801757812 	 0.08060312271118164 	 1.794473648071289 	 1.6000089645385742 	 0.9162631034851074 	 0.8193700313568115 	 
2025-07-30 18:10:41.404863 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.5711879730224609 	 0.5864384174346924 	 0.5586435794830322 	 0.5542507171630859 	 3.375969886779785 	 3.1799609661102295 	 1.725135326385498 	 1.62343168258667 	 
2025-07-30 18:10:58.204731 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 614912000 	 1000 	 0.600318193435669 	 0.5886111259460449 	 0.5855116844177246 	 0.5550062656402588 	 3.6461310386657715 	 3.3632090091705322 	 1.8638725280761719 	 1.1441361904144287 	 
2025-07-30 18:11:17.900348 test begin: paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, ) 	 552161280 	 1000 	 0.7205212116241455 	 0.7396583557128906 	 0.7002525329589844 	 0.7129974365234375 	 4.02791428565979 	 3.844670295715332 	 2.0605576038360596 	 1.9647507667541504 	 
2025-07-30 18:11:39.868256 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 127009, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 127009, 2],"float32"), align_corners=False, ) 	 109990800 	 1000 	 0.668267011642456 	 0.7076554298400879 	 0.6481466293334961 	 0.6773068904876709 	 2.6507256031036377 	 2.686976909637451 	 1.3556890487670898 	 1.3723139762878418 	 
2025-07-30 18:11:49.080209 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, ) 	 114380800 	 1000 	 0.722332239151001 	 0.7486300468444824 	 0.7096986770629883 	 0.7291586399078369 	 2.875586748123169 	 2.926248550415039 	 1.4713737964630127 	 1.4952526092529297 	 
2025-07-30 18:11:58.954161 test begin: paddle.nn.functional.grid_sample(Tensor([200, 11, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 11, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, ) 	 706252800 	 1000 	 8.737156867980957 	 8.057579278945923 	 8.723225831985474 	 8.038259983062744 	 28.7909836769104 	 28.672283172607422 	 14.716947078704834 	 9.776021003723145 	 
2025-07-30 18:13:30.908323 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7894375324249268 	 0.8171284198760986 	 0.7746634483337402 	 0.7846593856811523 	 4.29903507232666 	 4.123076915740967 	 2.193732261657715 	 2.1046578884124756 	 
2025-07-30 18:13:51.274189 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, ) 	 509964000 	 1000 	 0.13550758361816406 	 0.12821102142333984 	 0.1230013370513916 	 0.11024165153503418 	 1.894036054611206 	 1.6848163604736328 	 0.9684419631958008 	 0.8600144386291504 	 
2025-07-30 18:14:03.783495 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7908344268798828 	 0.816460371017456 	 0.7783677577972412 	 0.7984340190887451 	 4.350786447525024 	 4.165291786193848 	 2.22214937210083 	 2.127596139907837 	 
2025-07-30 18:14:23.593198 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 642048000 	 1000 	 0.8375065326690674 	 0.8799006938934326 	 0.8248846530914307 	 0.8435389995574951 	 4.669652938842773 	 4.474452257156372 	 2.3857333660125732 	 1.5261540412902832 	 
2025-07-30 18:14:45.661648 test begin: paddle.nn.functional.grid_sample(Tensor([2026, 1, 544, 544],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2026, 1, 544, 544],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, ) 	 650394624 	 1000 	 0.8493781089782715 	 0.8741483688354492 	 0.8292312622070312 	 0.8439323902130127 	 4.734943866729736 	 4.53227162361145 	 2.422853469848633 	 1.5423848628997803 	 
2025-07-30 18:15:07.646724 test begin: paddle.nn.functional.grid_sample(Tensor([2026, 1, 768, 768],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2026, 1, 768, 768],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, ) 	 1245811712 	 1000 	 1.2092726230621338 	 2.2961251735687256 	 1.1966068744659424 	 1.1568248271942139 	 7.436767816543579 	 6.78583550453186 	 3.80124568939209 	 1.3904924392700195 	 
2025-07-30 18:15:47.104571 test begin: paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, ) 	 534973440 	 1000 	 0.5219380855560303 	 0.5130939483642578 	 0.5092527866363525 	 0.4930567741394043 	 3.1736366748809814 	 2.9208385944366455 	 1.6217944622039795 	 1.4929172992706299 	 
2025-07-30 18:16:03.948663 test begin: paddle.nn.functional.grid_sample(x=Tensor([1, 64, 80, 94, 311],"float32"), grid=Tensor([1, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([1, 64, 80, 94, 311],"float32"), grid=Tensor([1, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 157574080 	 1000 	 14.691325902938843 	 11.55864143371582 	 14.678523063659668 	 11.539113998413086 	 97.17176842689514 	 96.94987463951111 	 49.54715013504028 	 49.531068086624146 	 
2025-07-30 18:19:50.305690 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 87713280 	 1000 	 5.367187976837158 	 3.6630585193634033 	 5.354495286941528 	 3.6426053047180176 	 11.131163597106934 	 12.040806531906128 	 5.689656972885132 	 6.155006170272827 	 
2025-07-30 18:20:25.334973 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 6, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 6, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 56806080 	 1000 	 0.14031195640563965 	 0.0987401008605957 	 0.1273975372314453 	 0.0804905891418457 	 0.45760107040405273 	 0.4609098434448242 	 0.23370671272277832 	 0.23611044883728027 	 
2025-07-30 18:20:27.475273 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 83971328 	 1000 	 35.21354413032532 	 34.22668695449829 	 35.19510102272034 	 34.206594944000244 	 109.57293462753296 	 119.3664939403534 	 55.99207901954651 	 60.99004340171814 	 
2025-07-30 18:25:39.418939 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 7, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 7, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 52975328 	 1000 	 0.8162558078765869 	 0.7193326950073242 	 0.7975897789001465 	 0.6936876773834229 	 2.4396214485168457 	 2.676393747329712 	 1.2459075450897217 	 1.3682034015655518 	 
2025-07-30 18:25:49.590984 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 82538240 	 1000 	 36.36721467971802 	 33.99240446090698 	 36.34242057800293 	 33.97233200073242 	 109.30959582328796 	 119.16850543022156 	 55.855167865753174 	 60.88796019554138 	 
2025-07-30 18:31:01.826245 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 8, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 8, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 61061120 	 1000 	 12.402427196502686 	 10.886438131332397 	 12.389558553695679 	 10.8552086353302 	 35.38016486167908 	 38.075690031051636 	 18.079367637634277 	 19.45408344268799 	 
2025-07-30 18:32:43.427080 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 27],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 27],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 83562240 	 1000 	 38.97658848762512 	 35.24048948287964 	 38.96075654029846 	 35.21241998672485 	 115.38586902618408 	 125.71448588371277 	 58.97014856338501 	 64.2331473827362 	 
2025-07-30 18:38:11.957371 test begin: paddle.nn.functional.label_smooth(label=Tensor([48, 32, 33712],"float32"), epsilon=0.1, )
[Prof] paddle.nn.functional.label_smooth 	 paddle.nn.functional.label_smooth(label=Tensor([48, 32, 33712],"float32"), epsilon=0.1, ) 	 51781632 	 1000 	 0.3015308380126953 	 0.618035078048706 	 0.2912414073944092 	 0.20972728729248047 	 0.30278587341308594 	 0.30332446098327637 	 0.2516148090362549 	 0.19860339164733887 	 combined
2025-07-30 18:38:15.200932 test begin: paddle.nn.functional.label_smooth(label=Tensor([76, 20, 33712],"float32"), epsilon=0.1, )
[Prof] paddle.nn.functional.label_smooth 	 paddle.nn.functional.label_smooth(label=Tensor([76, 20, 33712],"float32"), epsilon=0.1, ) 	 51242240 	 1000 	 0.2981600761413574 	 0.6257269382476807 	 0.2877931594848633 	 0.2088305950164795 	 0.2982499599456787 	 0.30021095275878906 	 0.24522066116333008 	 0.22575855255126953 	 combined
2025-07-30 18:38:18.514522 test begin: paddle.nn.functional.layer_norm(Tensor([115, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([115, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 51227648 	 1000 	 0.30204319953918457 	 0.316359281539917 	 0.2859828472137451 	 0.29381275177001953 	 0.4731166362762451 	 1.0174956321716309 	 0.2409191131591797 	 0.5204372406005859 	 
2025-07-30 18:38:22.631357 test begin: paddle.nn.functional.layer_norm(Tensor([174, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([174, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50960384 	 1000 	 0.30187296867370605 	 0.3158254623413086 	 0.2775101661682129 	 0.29297399520874023 	 0.47077083587646484 	 1.0108957290649414 	 0.24108600616455078 	 0.5165047645568848 	 
2025-07-30 18:38:26.431642 test begin: paddle.nn.functional.layer_norm(Tensor([226, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([226, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50915328 	 1000 	 0.3026010990142822 	 0.31438612937927246 	 0.2857186794281006 	 0.29175329208374023 	 0.4688992500305176 	 1.0129296779632568 	 0.23954558372497559 	 0.5173585414886475 	 
2025-07-30 18:38:30.167909 test begin: paddle.nn.functional.layer_norm(Tensor([7, 7088, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([7, 7088, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50808832 	 1000 	 0.30100369453430176 	 0.31501078605651855 	 0.2853083610534668 	 0.2926044464111328 	 0.4688446521759033 	 1.0079891681671143 	 0.2388606071472168 	 0.5149874687194824 	 
2025-07-30 18:38:34.157191 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 26, 304, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 26, 304, 544],"float32"), 0.1, ) 	 51597312 	 1000 	 0.30037546157836914 	 0.3109092712402344 	 0.28375673294067383 	 0.2835569381713867 	 0.45680785179138184 	 0.45358729362487793 	 0.39212894439697266 	 0.3785130977630615 	 
2025-07-30 18:38:39.742094 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 32, 122, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 32, 122, 1088],"float32"), 0.1, ) 	 50970624 	 1000 	 0.2980961799621582 	 0.29885029792785645 	 0.28878283500671387 	 0.2820727825164795 	 0.4512605667114258 	 0.4481217861175537 	 0.39694762229919434 	 0.3800218105316162 	 
2025-07-30 18:38:42.968443 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 32, 608, 218],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 32, 608, 218],"float32"), 0.1, ) 	 50896896 	 1000 	 0.2977018356323242 	 0.30335426330566406 	 0.2882835865020752 	 0.27574753761291504 	 0.4520399570465088 	 0.44879746437072754 	 0.3889274597167969 	 0.3804314136505127 	 
2025-07-30 18:38:46.386325 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 64, 122, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 64, 122, 544],"float32"), 0.1, ) 	 50970624 	 1000 	 0.29677844047546387 	 0.30011582374572754 	 0.28737759590148926 	 0.28200626373291016 	 0.45264434814453125 	 0.4495375156402588 	 0.39875102043151855 	 0.3809218406677246 	 
2025-07-30 18:38:49.534102 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 64, 304, 218],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 64, 304, 218],"float32"), 0.1, ) 	 50896896 	 1000 	 0.2975447177886963 	 0.2991020679473877 	 0.2881453037261963 	 0.28158068656921387 	 0.45064210891723633 	 0.44754815101623535 	 0.3964207172393799 	 0.36939501762390137 	 
2025-07-30 18:38:52.886198 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 7, 608, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 7, 608, 1088],"float32"), 0.1, ) 	 55566336 	 1000 	 0.32313990592956543 	 0.32921648025512695 	 0.3139181137084961 	 0.3030416965484619 	 0.4915130138397217 	 0.48926591873168945 	 0.43786144256591797 	 0.4212653636932373 	 
2025-07-30 18:38:56.498742 test begin: paddle.nn.functional.leaky_relu(Tensor([13, 64, 256, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([13, 64, 256, 256],"float32"), 0.1, None, ) 	 54525952 	 1000 	 0.3171882629394531 	 0.33532285690307617 	 0.30778050422668457 	 0.3041341304779053 	 0.48258543014526367 	 0.48164820671081543 	 0.4286623001098633 	 0.4145643711090088 	 
2025-07-30 18:39:00.226351 test begin: paddle.nn.functional.leaky_relu(Tensor([3, 32, 608, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([3, 32, 608, 1088],"float32"), 0.1, ) 	 63504384 	 1000 	 0.3699965476989746 	 0.3711271286010742 	 0.36066150665283203 	 0.3488497734069824 	 0.5609607696533203 	 0.5586409568786621 	 0.5072791576385498 	 0.4794893264770508 	 
2025-07-30 18:39:04.148755 test begin: paddle.nn.functional.leaky_relu(Tensor([5, 64, 304, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([5, 64, 304, 544],"float32"), 0.1, ) 	 52920320 	 1000 	 0.3090517520904541 	 0.31008291244506836 	 0.2997398376464844 	 0.293853759765625 	 0.46970200538635254 	 0.46511077880859375 	 0.4130239486694336 	 0.39363765716552734 	 
2025-07-30 18:39:07.424121 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 13, 256, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 13, 256, 256],"float32"), 0.1, None, ) 	 54525952 	 1000 	 0.31731319427490234 	 0.32806897163391113 	 0.3012869358062744 	 0.30268383026123047 	 0.48389172554016113 	 0.4804251194000244 	 0.43015623092651367 	 0.41288137435913086 	 
2025-07-30 18:39:11.140301 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 64, 256, 49],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 64, 256, 49],"float32"), 0.1, None, ) 	 51380224 	 1000 	 0.2989647388458252 	 0.3041563034057617 	 0.28971242904663086 	 0.28574490547180176 	 0.4565458297729492 	 0.45171451568603516 	 0.4018712043762207 	 0.3596780300140381 	 
2025-07-30 18:39:14.349846 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 64, 49, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 64, 49, 256],"float32"), 0.1, None, ) 	 51380224 	 1000 	 0.30019354820251465 	 0.3011741638183594 	 0.29076242446899414 	 0.2848076820373535 	 0.4546973705291748 	 0.45166945457458496 	 0.40062880516052246 	 0.382462739944458 	 
2025-07-30 18:39:17.605080 test begin: paddle.nn.functional.linear(x=Tensor([1, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
Warning: The core code of paddle.nn.functional.linear is too complex.
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([1, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 50823284 	 1000 	 0.15916728973388672 	 0.15394186973571777 	 0.05414581298828125 	 0.1329362392425537 	 0.3168668746948242 	 0.32039499282836914 	 0.08103609085083008 	 0.10943388938903809 	 
2025-07-30 18:39:19.446598 test begin: paddle.nn.functional.linear(x=Tensor([1, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([1, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, ) 	 50855402 	 1000 	 0.16758489608764648 	 0.15553760528564453 	 0.056966543197631836 	 0.1299123764038086 	 0.32125091552734375 	 0.3215627670288086 	 0.08180999755859375 	 0.10945630073547363 	 
2025-07-30 18:39:21.295916 test begin: paddle.nn.functional.linear(x=Tensor([2, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 50835688 	 1000 	 0.21567773818969727 	 0.24653983116149902 	 0.0730133056640625 	 0.06270551681518555 	 0.43106555938720703 	 0.4237782955169678 	 0.0734400749206543 	 0.08651876449584961 	 
2025-07-30 18:39:23.469411 test begin: paddle.nn.functional.linear(x=Tensor([2, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, ) 	 50880490 	 1000 	 0.22909760475158691 	 0.31324243545532227 	 0.07788705825805664 	 0.08018064498901367 	 0.3372840881347656 	 0.33559513092041016 	 0.08656144142150879 	 0.11375999450683594 	 
2025-07-30 18:39:25.539206 test begin: paddle.nn.functional.linear(x=Tensor([2026, 25088],"float32"), weight=Tensor([25088, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2026, 25088],"float32"), weight=Tensor([25088, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 153592832 	 1000 	 23.892446994781494 	 24.8446147441864 	 12.21155309677124 	 24.796583652496338 	 48.0685396194458 	 47.95819449424744 	 9.850125074386597 	 12.229952573776245 	 
2025-07-30 18:41:54.512159 test begin: paddle.nn.functional.linear(x=Tensor([4051, 12544],"float32"), weight=Tensor([12544, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4051, 12544],"float32"), weight=Tensor([12544, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 63661824 	 1000 	 6.26868748664856 	 6.2633843421936035 	 3.2043569087982178 	 6.226470232009888 	 12.481044054031372 	 12.137078046798706 	 2.5544795989990234 	 3.0950815677642822 	 
2025-07-30 18:42:32.877790 test begin: paddle.nn.functional.linear(x=Tensor([4096, 12404],"float32"), weight=Tensor([12404, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 12404],"float32"), weight=Tensor([12404, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 63509504 	 1000 	 6.2059736251831055 	 6.197849988937378 	 3.1705706119537354 	 6.173569917678833 	 12.091780424118042 	 12.058427333831787 	 2.479560136795044 	 3.0759034156799316 	 
2025-07-30 18:43:10.620263 test begin: paddle.nn.functional.linear(x=Tensor([4096, 12544],"float32"), weight=Tensor([12544, 4051],"float32"), bias=Tensor([4051],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 12544],"float32"), weight=Tensor([12544, 4051],"float32"), bias=Tensor([4051],"float32"), name=None, ) 	 102200019 	 1000 	 25.085753202438354 	 23.974587202072144 	 12.817421197891235 	 23.928454637527466 	 48.02127981185913 	 47.865915060043335 	 9.84461522102356 	 12.196892976760864 	 
2025-07-30 18:45:39.822017 test begin: paddle.nn.functional.linear(x=Tensor([4096, 49613],"float32"), weight=Tensor([49613, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 49613],"float32"), weight=Tensor([49613, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 254019584 	 1000 	 24.774442672729492 	 24.77535057067871 	 12.657942056655884 	 24.748620986938477 	 47.918084144592285 	 47.84880995750427 	 9.825193881988525 	 12.202054500579834 	 
2025-07-30 18:48:09.670132 test begin: paddle.nn.functional.local_response_norm(Tensor([10585, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([10585, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50808000 	 1000 	 4.262104272842407 	 5.106316328048706 	 0.7263216972351074 	 0.6530277729034424 	 8.936639785766602 	 8.661226034164429 	 1.0124800205230713 	 0.519874095916748 	 
2025-07-30 18:48:40.176201 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 10585, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 10585, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50808000 	 1000 	 3.4376707077026367 	 4.792982339859009 	 0.5847976207733154 	 0.6099872589111328 	 7.2480573654174805 	 7.58897066116333 	 0.8242888450622559 	 0.4865882396697998 	 
2025-07-30 18:49:06.673376 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 3, 141121, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 3, 141121, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50803560 	 1000 	 4.3336098194122314 	 5.272296190261841 	 0.7372214794158936 	 0.673969030380249 	 9.021902322769165 	 8.874276161193848 	 1.0230827331542969 	 0.5661396980285645 	 
2025-07-30 18:49:39.228079 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 3, 40, 141121],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 3, 40, 141121],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50803560 	 1000 	 4.332079887390137 	 4.334411382675171 	 0.7372074127197266 	 0.549419641494751 	 8.991385221481323 	 7.924859523773193 	 1.0179548263549805 	 0.5076680183410645 	 
2025-07-30 18:50:07.263919 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 40, 47041],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 40, 47041],"float32"), size=5, data_format="NCDHW", ) 	 50804280 	 1000 	 4.332276344299316 	 4.6997458934783936 	 0.738286018371582 	 0.6025466918945312 	 8.939318656921387 	 8.593761205673218 	 1.0153536796569824 	 0.5481505393981934 	 
2025-07-30 18:50:37.159222 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 47041, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 47041, 40],"float32"), size=5, data_format="NCDHW", ) 	 50804280 	 1000 	 4.340289831161499 	 4.701160669326782 	 0.7355403900146484 	 0.6000211238861084 	 8.937362432479858 	 8.587506294250488 	 1.0103585720062256 	 0.5481963157653809 	 
2025-07-30 18:51:06.084533 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3529, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3529, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 4.326694011688232 	 4.26468825340271 	 0.7348904609680176 	 0.5440623760223389 	 9.015994548797607 	 7.8546741008758545 	 1.0188181400299072 	 0.5034940242767334 	 
2025-07-30 18:51:33.449545 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 40, 3529],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 40, 3529],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.121819257736206 	 4.823723793029785 	 1.2149450778961182 	 0.6171114444732666 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 40, 40, 3529]) and output[0] has a shape of torch.Size([3, 3529, 3, 40, 40]).
2025-07-30 18:52:00.913428 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 47041, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 47041, 3],"float32"), size=5, data_format="NDHWC", ) 	 50804280 	 1000 	 7.918813943862915 	 5.017526388168335 	 1.3465206623077393 	 0.6405065059661865 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 40, 47041, 3]) and output[0] has a shape of torch.Size([3, 3, 3, 40, 47041]).
2025-07-30 18:52:42.273605 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 47041, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 47041, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50804280 	 1000 	 7.925503969192505 	 5.024420738220215 	 1.350625991821289 	 0.6430103778839111 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 47041, 40, 3]) and output[0] has a shape of torch.Size([3, 3, 3, 47041, 40]).
2025-07-30 18:53:22.617358 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 3, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 3.434062957763672 	 4.249403953552246 	 0.5873887538909912 	 0.5424520969390869 	 7.2117369174957275 	 7.357990741729736 	 0.8165993690490723 	 0.4688146114349365 	 
2025-07-30 18:53:47.367349 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 40, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.929861068725586 	 4.5670013427734375 	 1.3522005081176758 	 0.586860179901123 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3529, 40, 40, 3]) and output[0] has a shape of torch.Size([3, 3, 3529, 40, 40]).
2025-07-30 18:54:27.703769 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 4.256591081619263 	 4.549152612686157 	 0.7252342700958252 	 0.5799665451049805 	 8.826505899429321 	 8.572738409042358 	 1.0046050548553467 	 0.5506255626678467 	 
2025-07-30 18:54:55.715780 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.924492359161377 	 4.55489182472229 	 1.3486132621765137 	 0.5803155899047852 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3529, 3, 40, 40, 3]) and output[0] has a shape of torch.Size([3529, 3, 3, 40, 40]).
2025-07-30 18:55:38.989275 test begin: paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), )
[Prof] paddle.nn.functional.log_loss 	 paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), ) 	 101606402 	 1000 	 0.49837589263916016 	 3.427520513534546 	 0.48174118995666504 	 0.35080885887145996 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 18:55:46.376003 test begin: paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), epsilon=1e-07, )
[Prof] paddle.nn.functional.log_loss 	 paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), epsilon=1e-07, ) 	 101606402 	 1000 	 0.49558162689208984 	 3.4238109588623047 	 0.48541712760925293 	 0.3496284484863281 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 18:55:53.848552 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 10, 254017],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 10, 254017],"float64"), None, ) 	 25401700 	 1000 	 0.44243621826171875 	 0.45830583572387695 	 0.43340325355529785 	 0.44132089614868164 	 0.45307064056396484 	 0.4508645534515381 	 0.3995473384857178 	 0.38209033012390137 	 
2025-07-30 18:55:56.791802 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 10, 508033],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 10, 508033],"float32"), None, ) 	 50803300 	 1000 	 0.3006250858306885 	 0.3020191192626953 	 0.29132509231567383 	 0.2846827507019043 	 0.45172739028930664 	 0.4502286911010742 	 0.3982093334197998 	 0.3831207752227783 	 
2025-07-30 18:56:00.355952 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 254017, 10],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 254017, 10],"float64"), None, ) 	 25401700 	 1000 	 0.44100499153137207 	 0.4570736885070801 	 0.4319639205932617 	 0.4438905715942383 	 0.4503946304321289 	 0.4508826732635498 	 0.39682650566101074 	 0.38306403160095215 	 
2025-07-30 18:56:03.234457 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 508033, 10],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 508033, 10],"float32"), None, ) 	 50803300 	 1000 	 0.30203890800476074 	 0.29837727546691895 	 0.29285359382629395 	 0.28513097763061523 	 0.4512503147125244 	 0.4502272605895996 	 0.3973572254180908 	 0.37889957427978516 	 
2025-07-30 18:56:06.369678 test begin: paddle.nn.functional.log_sigmoid(Tensor([254017, 10, 10],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([254017, 10, 10],"float64"), None, ) 	 25401700 	 1000 	 0.44188570976257324 	 0.45995116233825684 	 0.43276429176330566 	 0.4450645446777344 	 0.45177173614501953 	 0.4508247375488281 	 0.3983619213104248 	 0.3825230598449707 	 
2025-07-30 18:56:09.305926 test begin: paddle.nn.functional.log_sigmoid(Tensor([508033, 10, 10],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([508033, 10, 10],"float32"), None, ) 	 50803300 	 1000 	 0.3006267547607422 	 0.301715612411499 	 0.2913999557495117 	 0.286221981048584 	 0.4502537250518799 	 0.4502451419830322 	 0.3960258960723877 	 0.35954785346984863 	 
2025-07-30 18:56:12.443480 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([10, 10, 508033],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([10, 10, 508033],"float32"), ) 	 50803300 	 1000 	 0.3034169673919678 	 0.30239439010620117 	 0.29390382766723633 	 0.28653669357299805 	 0.45288848876953125 	 0.4502129554748535 	 0.39801454544067383 	 0.38045525550842285 	 
2025-07-30 18:56:15.635390 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([10, 508033, 10],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([10, 508033, 10],"float32"), ) 	 50803300 	 1000 	 0.3006870746612549 	 0.30898547172546387 	 0.29114770889282227 	 0.28778076171875 	 0.45040321350097656 	 0.45015525817871094 	 0.3963348865509033 	 0.38163280487060547 	 
2025-07-30 18:56:18.901359 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([508033, 10, 10],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([508033, 10, 10],"float32"), ) 	 50803300 	 1000 	 0.3018310070037842 	 0.29837727546691895 	 0.29219532012939453 	 0.28511786460876465 	 0.45126914978027344 	 0.4501607418060303 	 0.39721179008483887 	 0.38168811798095703 	 
2025-07-30 18:56:22.057221 test begin: paddle.nn.functional.log_softmax(Tensor([128, 396901],"float32"), axis=-1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([128, 396901],"float32"), axis=-1, ) 	 50803328 	 1000 	 0.707655668258667 	 0.6292843818664551 	 0.6985313892364502 	 0.6139686107635498 	 1.3957529067993164 	 0.6517200469970703 	 1.3389499187469482 	 0.5855510234832764 	 
2025-07-30 18:56:27.209426 test begin: paddle.nn.functional.log_softmax(Tensor([264, 192612],"float32"), axis=-1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([264, 192612],"float32"), axis=-1, ) 	 50849568 	 1000 	 0.6183974742889404 	 0.6500637531280518 	 0.6090524196624756 	 0.6310250759124756 	 0.8627486228942871 	 0.6644470691680908 	 0.8059453964233398 	 0.5991189479827881 	 
2025-07-30 18:56:32.606856 test begin: paddle.nn.functional.log_softmax(Tensor([2944, 17257],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([2944, 17257],"float32"), axis=1, ) 	 50804608 	 1000 	 0.3314664363861084 	 1.0143029689788818 	 0.31344056129455566 	 0.3231794834136963 	 0.6466090679168701 	 0.5219907760620117 	 0.5890181064605713 	 0.4525597095489502 	 
2025-07-30 18:56:39.615508 test begin: paddle.nn.functional.log_softmax(Tensor([4224, 12028],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([4224, 12028],"float32"), axis=1, ) 	 50806272 	 1000 	 0.30687403678894043 	 0.30770301818847656 	 0.2960994243621826 	 0.2932558059692383 	 0.6301355361938477 	 0.4546022415161133 	 0.5728332996368408 	 0.3860893249511719 	 
2025-07-30 18:56:42.949441 test begin: paddle.nn.functional.log_softmax(Tensor([7664, 6629],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([7664, 6629],"float32"), axis=1, ) 	 50804656 	 1000 	 0.30461907386779785 	 0.3032560348510742 	 0.29390764236450195 	 0.28577518463134766 	 0.59804368019104 	 0.517728328704834 	 0.5400536060333252 	 0.45236921310424805 	 
2025-07-30 18:56:46.379604 test begin: paddle.nn.functional.lp_pool1d(Tensor([2, 3, 8467201],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([2, 3, 8467201],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803206 	 1000 	 0.9315388202667236 	 1.9306087493896484 	 0.9019393920898438 	 0.24442672729492188 	 1.4290063381195068 	 4.9632861614227295 	 0.730180025100708 	 0.3168160915374756 	 
2025-07-30 18:56:56.979402 test begin: paddle.nn.functional.lp_pool1d(Tensor([2, 793801, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([2, 793801, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803264 	 1000 	 0.9343740940093994 	 1.939218521118164 	 0.9048993587493896 	 0.2471785545349121 	 1.4325721263885498 	 5.158233880996704 	 0.7315940856933594 	 0.33034420013427734 	 
2025-07-30 18:57:07.826291 test begin: paddle.nn.functional.lp_pool1d(Tensor([529201, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([529201, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803296 	 1000 	 0.9343218803405762 	 1.944969654083252 	 0.9048686027526855 	 0.2484595775604248 	 1.4251365661621094 	 5.158403396606445 	 0.727853536605835 	 0.329174280166626 	 
2025-07-30 18:57:18.590236 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50804736 	 1000 	 2.1052865982055664 	 3.5066916942596436 	 2.0886924266815186 	 0.44632744789123535 	 2.261173725128174 	 6.820554733276367 	 1.1548197269439697 	 0.4639291763305664 	 
2025-07-30 18:57:35.402605 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50804736 	 1000 	 0.5552468299865723 	 1.215008020401001 	 0.5393021106719971 	 0.15376949310302734 	 0.9964654445648193 	 3.669735908508301 	 0.5090382099151611 	 0.24966740608215332 	 
2025-07-30 18:57:46.119377 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, ) 	 50804736 	 1000 	 0.9445421695709229 	 0.7894392013549805 	 0.9282166957855225 	 0.10040974617004395 	 1.9257488250732422 	 3.298261880874634 	 0.9832348823547363 	 0.22445106506347656 	 
2025-07-30 18:57:54.087202 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50804736 	 1000 	 2.104570150375366 	 3.5076076984405518 	 2.0882835388183594 	 0.446317195892334 	 2.260092258453369 	 6.821765661239624 	 1.153477668762207 	 0.4651825428009033 	 
2025-07-30 18:58:10.441682 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50804736 	 1000 	 0.558631420135498 	 1.2091822624206543 	 0.5422146320343018 	 0.15358614921569824 	 0.9977636337280273 	 3.664102554321289 	 0.5090954303741455 	 0.249284029006958 	 
2025-07-30 18:58:17.957006 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, ) 	 50804736 	 1000 	 0.9404704570770264 	 0.7925901412963867 	 0.9241857528686523 	 0.1004178524017334 	 1.9288418292999268 	 3.3044593334198 	 0.9847755432128906 	 0.2249147891998291 	 
2025-07-30 18:58:25.928302 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50803392 	 1000 	 2.168978452682495 	 3.5256803035736084 	 2.1525135040283203 	 0.44867801666259766 	 2.3029706478118896 	 6.961200475692749 	 1.1777443885803223 	 0.444195032119751 	 
2025-07-30 18:58:45.440481 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50803392 	 1000 	 0.5558454990386963 	 1.2293927669525146 	 0.5395941734313965 	 0.15515470504760742 	 0.9990625381469727 	 3.664475202560425 	 0.5104963779449463 	 0.2341597080230713 	 
2025-07-30 18:58:53.043513 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50803392 	 1000 	 2.0967857837677 	 3.59071683883667 	 2.076430559158325 	 0.4587430953979492 	 2.3046321868896484 	 6.95348334312439 	 1.1798789501190186 	 0.4447150230407715 	 
2025-07-30 18:59:09.789739 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50803392 	 1000 	 0.5552213191986084 	 1.2176661491394043 	 0.5391385555267334 	 0.15569353103637695 	 0.9989244937896729 	 3.619178295135498 	 0.5102038383483887 	 0.23125243186950684 	 
2025-07-30 18:59:17.261484 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([1373060, 37],"float32"), Tensor([1373060],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([1373060, 37],"float32"), Tensor([1373060],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 52176280 	 1000 	 2.9869742393493652 	 1.6584668159484863 	 0.3383657932281494 	 0.11252546310424805 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 18:59:23.480466 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float16"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float16"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 965260838 	 1000 	 52.638877153396606 	 19.46865153312683 	 5.975489377975464 	 1.3264312744140625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:01:12.998065 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float32"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float32"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 965260838 	 1000 	 55.209410667419434 	 30.22096037864685 	 6.264027833938599 	 1.818847417831421 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:03:12.622968 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([2746119, 37],"float16"), Tensor([2746119],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([2746119, 37],"float16"), Tensor([2746119],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 104352522 	 1000 	 5.868504047393799 	 2.1526918411254883 	 0.6677842140197754 	 0.14759612083435059 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:03:24.749447 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([5, 10160641],"float32"), Tensor([5],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([5, 10160641],"float32"), Tensor([5],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 50803210 	 1000 	 70.31574511528015 	 6.193416595458984 	 6.53986120223999 	 0.42606186866760254 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:04:43.551966 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", ) 	 25401610 	 1000 	 42.10939431190491 	 15.924592733383179 	 3.6161270141601562 	 1.0879721641540527 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:05:43.443962 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([686530, 37],"float64"), Tensor([686530],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([686530, 37],"float64"), Tensor([686530],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", ) 	 26088140 	 1000 	 2.5220425128936768 	 25.8220477104187 	 0.2337024211883545 	 1.780806064605713 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:06:13.947962 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", ) 	 76204830 	 1000 	 1.3395380973815918 	 1.9394521713256836 	 0.27317094802856445 	 0.28267383575439453 	 1.8109643459320068 	 2.1095774173736572 	 0.4633331298828125 	 0.2697901725769043 	 
2025-07-30 19:06:23.375632 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", None, ) 	 76204830 	 1000 	 1.3382809162139893 	 1.937492847442627 	 0.27323126792907715 	 0.2827010154724121 	 1.815370798110962 	 2.1155881881713867 	 0.4619874954223633 	 0.2709920406341553 	 
2025-07-30 19:06:32.539448 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", ) 	 76204830 	 1000 	 1.338104486465454 	 1.9522066116333008 	 0.27314257621765137 	 0.2827329635620117 	 1.8072383403778076 	 2.1120195388793945 	 0.4619619846343994 	 0.2698404788970947 	 
2025-07-30 19:06:42.794538 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", None, ) 	 76204830 	 1000 	 1.3381166458129883 	 1.9361977577209473 	 0.27314257621765137 	 0.2826869487762451 	 1.8155672550201416 	 2.113433837890625 	 0.46482086181640625 	 0.2712059020996094 	 
2025-07-30 19:06:51.789215 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([50803201],"float32"), Tensor([50803201],"float32"), Tensor([50803201],"float32"), 0.5, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([50803201],"float32"), Tensor([50803201],"float32"), Tensor([50803201],"float32"), 0.5, "mean", None, ) 	 152409603 	 1000 	 1.6449198722839355 	 1.9421401023864746 	 0.23981785774230957 	 0.283369779586792 	 2.215573787689209 	 2.2564167976379395 	 0.5647118091583252 	 0.28905177116394043 	 
2025-07-30 19:07:02.381835 test begin: paddle.nn.functional.max_pool1d(Tensor([2, 3, 8467201],"float32"), 2, None, 0, False, False, None, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([2, 3, 8467201],"float32"), 2, None, 0, False, False, None, ) 	 50803206 	 1000 	 0.2698183059692383 	 0.41754651069641113 	 0.2378537654876709 	 0.3894679546356201 	 0.7879347801208496 	 1.310945749282837 	 0.40253162384033203 	 0.6704745292663574 	 
2025-07-30 19:07:06.568317 test begin: paddle.nn.functional.max_pool1d(Tensor([226801, 32, 7],"float32"), 7, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([226801, 32, 7],"float32"), 7, ) 	 50803424 	 1000 	 0.31346940994262695 	 0.21595430374145508 	 0.281322717666626 	 0.18425226211547852 	 18.251786947250366 	 4.5325798988342285 	 18.171016454696655 	 2.373842716217041 	 
2025-07-30 19:07:31.955771 test begin: paddle.nn.functional.max_pool1d(Tensor([91, 32, 17447],"float32"), 7, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([91, 32, 17447],"float32"), 7, ) 	 50805664 	 1000 	 0.31322574615478516 	 0.21601414680480957 	 0.2813906669616699 	 0.1900920867919922 	 0.746671199798584 	 1.2740116119384766 	 0.38131022453308105 	 0.6521368026733398 	 
2025-07-30 19:07:39.667867 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 128, 480, 83],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 128, 480, 83],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50995200 	 1000 	 0.21155071258544922 	 0.2993283271789551 	 0.19299578666687012 	 0.2565028667449951 	 0.6738402843475342 	 1.3436899185180664 	 0.34498143196105957 	 0.6858744621276855 	 
2025-07-30 19:07:43.307426 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 128, 83, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 128, 83, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50995200 	 1000 	 0.19664740562438965 	 0.2829549312591553 	 0.1781628131866455 	 0.2539331912994385 	 0.6675865650177002 	 1.3526561260223389 	 0.34230923652648926 	 0.6898438930511475 	 
2025-07-30 19:07:46.914287 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 23, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 23, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 52992000 	 1000 	 0.20943355560302734 	 0.28972530364990234 	 0.19060683250427246 	 0.26207900047302246 	 0.6988403797149658 	 1.4077279567718506 	 0.35709619522094727 	 0.7206113338470459 	 
2025-07-30 19:07:50.832756 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 24, 112, 13],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 24, 112, 13],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 53673984 	 1000 	 0.3643820285797119 	 0.38242268562316895 	 0.33785438537597656 	 0.352341890335083 	 0.4998207092285156 	 1.4656620025634766 	 0.4265463352203369 	 0.749584436416626 	 
2025-07-30 19:07:54.779532 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 24, 13, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 24, 13, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 53673984 	 1000 	 0.33896398544311523 	 0.36701107025146484 	 0.3206338882446289 	 0.3479011058807373 	 0.49213194847106934 	 1.4454948902130127 	 0.428882360458374 	 0.7386159896850586 	 
2025-07-30 19:07:58.687487 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 3, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 3, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 57802752 	 1000 	 0.4047253131866455 	 0.37847375869750977 	 0.37779664993286133 	 0.35884833335876465 	 0.9168322086334229 	 1.5625410079956055 	 0.467740535736084 	 0.79837965965271 	 
2025-07-30 19:08:03.555883 test begin: paddle.nn.functional.max_pool2d(Tensor([169, 24, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([169, 24, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50878464 	 1000 	 0.30208468437194824 	 0.33446431159973145 	 0.2834339141845703 	 0.31618547439575195 	 0.8105158805847168 	 1.3785226345062256 	 0.4146442413330078 	 0.7043752670288086 	 
2025-07-30 19:08:07.441997 test begin: paddle.nn.functional.max_pool2d(Tensor([2, 128, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([2, 128, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 58982400 	 1000 	 0.22981500625610352 	 0.3200666904449463 	 0.21132349967956543 	 0.30136704444885254 	 0.7770092487335205 	 1.5638840198516846 	 0.3968348503112793 	 0.7969157695770264 	 
2025-07-30 19:08:11.624048 test begin: paddle.nn.functional.max_pool2d(Tensor([2, 64, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([2, 64, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 63438848 	 1000 	 0.38414978981018066 	 0.427112340927124 	 0.36656832695007324 	 0.3995239734649658 	 1.0093352794647217 	 1.7533185482025146 	 0.5156841278076172 	 0.8940627574920654 	 
2025-07-30 19:08:16.526296 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 13, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 13, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 51544064 	 1000 	 0.35435056686401367 	 0.34131956100463867 	 0.3362905979156494 	 0.3215761184692383 	 0.8257031440734863 	 1.4277303218841553 	 0.4227261543273926 	 0.7288186550140381 	 
2025-07-30 19:08:20.581470 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 64, 141, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 64, 141, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 50823168 	 1000 	 0.30800294876098633 	 0.33684229850769043 	 0.29045844078063965 	 0.31854891777038574 	 0.810042142868042 	 1.408423900604248 	 0.41237545013427734 	 0.7195687294006348 	 
2025-07-30 19:08:24.627787 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 64, 704, 141],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 64, 704, 141],"float32"), kernel_size=3, stride=2, padding=1, ) 	 50823168 	 1000 	 0.3092365264892578 	 0.3429584503173828 	 0.2915642261505127 	 0.32134294509887695 	 0.8085076808929443 	 1.3864638805389404 	 0.4130704402923584 	 0.7083859443664551 	 
2025-07-30 19:08:28.551366 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 101606406 	 1000 	 2.220226764678955 	 2.3644726276397705 	 1.1340558528900146 	 1.21712327003479 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:08:40.082671 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606406 	 1000 	 2.2156014442443848 	 2.3332695960998535 	 1.132755994796753 	 1.1922862529754639 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:08:51.047774 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 76204806 	 1000 	 1.1206645965576172 	 1.2028398513793945 	 0.5728309154510498 	 0.6027302742004395 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:08:56.583702 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204806 	 1000 	 1.121701717376709 	 1.1801426410675049 	 0.5739614963531494 	 0.6009926795959473 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:01.862808 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, ) 	 50803206 	 1000 	 1.1217339038848877 	 1.1758747100830078 	 0.572401762008667 	 0.6013274192810059 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:07.131562 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803206 	 1000 	 1.1227092742919922 	 1.1824469566345215 	 0.5734736919403076 	 0.5998320579528809 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:12.643779 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401627 	 1000 	 1.1244988441467285 	 1.177802324295044 	 0.5751891136169434 	 0.6012792587280273 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:18.277307 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401627 	 1000 	 1.1240837574005127 	 1.1808714866638184 	 0.5750222206115723 	 0.5998828411102295 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:23.696039 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2540162448 	 1000 	 0.04597592353820801 	 0.04088568687438965 	 2.8133392333984375e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:23.999910 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 5080322448 	 1000 	 0.03708148002624512 	 0.03835558891296387 	 1.5497207641601562e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:24.188558 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5080322448 	 1000 	 0.03860354423522949 	 0.05269122123718262 	 4.00543212890625e-05 	 0.00010013580322265625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:24.365198 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401632 	 1000 	 1.1202561855316162 	 1.1910104751586914 	 0.5724005699157715 	 0.6023342609405518 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:30.191708 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401632 	 1000 	 1.1227753162384033 	 1.1934258937835693 	 0.5723385810852051 	 0.5999042987823486 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:37.249435 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, ) 	 50803216 	 1000 	 1.1228950023651123 	 1.1802189350128174 	 0.5750675201416016 	 0.5998363494873047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:42.585762 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803216 	 1000 	 1.1242823600769043 	 1.1750023365020752 	 0.5751371383666992 	 0.599829912185669 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:50.850614 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 76204816 	 1000 	 1.1229312419891357 	 1.1767306327819824 	 0.5723259449005127 	 0.6022295951843262 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:09:56.295939 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204816 	 1000 	 1.120225429534912 	 1.1771881580352783 	 0.5725193023681641 	 0.602830171585083 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:10:01.632284 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 101606416 	 1000 	 2.2189724445343018 	 2.3456497192382812 	 1.1357970237731934 	 1.1952145099639893 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:10:12.821039 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606416 	 1000 	 2.221527338027954 	 2.335635185241699 	 1.1344382762908936 	 1.1905508041381836 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:53.091900 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
W0730 13:31:54.702451  2426 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262247006 	 1000 	 0.041687965393066406 	 0.05832815170288086 	 3.0279159545898438e-05 	 0.00024199485778808594 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:57.566139 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696685406 	 1000 	 0.041285037994384766 	 0.04123544692993164 	 2.4318695068359375e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:57.770446 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131125927 	 1000 	 0.04076957702636719 	 0.052803993225097656 	 3.3855438232421875e-05 	 6.67572021484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:57.959481 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131123806 	 1000 	 0.04114723205566406 	 0.04196047782897949 	 3.3855438232421875e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:58.124690 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564327 	 1000 	 0.05570840835571289 	 0.053702354431152344 	 0.000164031982421875 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:58.333677 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564832 	 1000 	 0.0700843334197998 	 0.05374956130981445 	 3.910064697265625e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:58.561777 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25404048 	 1000 	 0.06084871292114258 	 0.0537717342376709 	 1.6689300537109375e-05 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:58.775551 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 5131125927 	 1000 	 0.03534555435180664 	 0.03949093818664551 	 1.239776611328125e-05 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:58.928533 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131125927 	 1000 	 0.03654742240905762 	 0.03920412063598633 	 1.430511474609375e-05 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:59.096993 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 5131126432 	 1000 	 0.036064863204956055 	 0.039133310317993164 	 1.8835067749023438e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:59.403235 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131126432 	 1000 	 0.03774666786193848 	 0.039594173431396484 	 2.2172927856445312e-05 	 4.76837158203125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:59.559465 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50805648 	 1000 	 0.035334110260009766 	 0.03966331481933594 	 1.430511474609375e-05 	 3.790855407714844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:59.718562 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50805648 	 1000 	 0.039105892181396484 	 0.03953433036804199 	 2.1696090698242188e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:31:59.875285 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131124816 	 1000 	 0.040756940841674805 	 0.04086136817932129 	 1.7404556274414062e-05 	 3.2901763916015625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:00.035043 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131126432 	 1000 	 0.04047870635986328 	 0.04123711585998535 	 1.2874603271484375e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:00.194344 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696686416 	 1000 	 0.04090237617492676 	 0.042282819747924805 	 1.430511474609375e-05 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:00.362350 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262248016 	 1000 	 0.040717124938964844 	 0.04092144966125488 	 1.9073486328125e-05 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:00.522176 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401648 	 1000 	 1.1175832748413086 	 1.1741394996643066 	 0.5704331398010254 	 0.600013256072998 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:05.781435 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401648 	 1000 	 1.1191089153289795 	 1.1737642288208008 	 0.5703141689300537 	 0.5996096134185791 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:11.036172 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50803248 	 1000 	 1.1174430847167969 	 1.174464225769043 	 0.5704975128173828 	 0.5996401309967041 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:16.176300 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803248 	 1000 	 1.117046594619751 	 1.1737263202667236 	 0.5703587532043457 	 0.5996370315551758 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:21.407440 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 76204848 	 1000 	 1.1176860332489014 	 1.1738402843475342 	 0.5707089900970459 	 0.599679708480835 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:26.653117 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204848 	 1000 	 1.1161227226257324 	 1.1737468242645264 	 0.5700387954711914 	 0.5996646881103516 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:32.015647 test begin: paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080324848 	 1000 	 0.04125618934631348 	 0.04089975357055664 	 1.52587890625e-05 	 4.00543212890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:32.183224 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50805648 	 1000 	 0.04071688652038574 	 0.04113602638244629 	 1.2159347534179688e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:32.349925 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2590965648 	 1000 	 0.04770851135253906 	 0.04182004928588867 	 4.267692565917969e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:32.520288 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 101606448 	 1000 	 2.220115900039673 	 2.3625409603118896 	 1.1378958225250244 	 1.190741777420044 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:43.803448 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606448 	 1000 	 2.211097478866577 	 2.3303425312042236 	 1.1292345523834229 	 1.1905534267425537 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:54.292396 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080322448 	 1000 	 0.04115176200866699 	 0.04080533981323242 	 3.314018249511719e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:54.471585 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5105724048 	 1000 	 0.04076433181762695 	 0.04092049598693848 	 2.1219253540039062e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:54.631874 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10160644848 	 1000 	 0.041090965270996094 	 0.04048657417297363 	 2.765655517578125e-05 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:54.792623 test begin: paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.05871915817260742 	 0.08541226387023926 	 0.02997446060180664 	 0.04348635673522949 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:55.225340 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164015264 	 1000 	 0.058737993240356445 	 0.08538556098937988 	 0.029998064041137695 	 0.04349684715270996 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:55.634906 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.058759450912475586 	 0.08679533004760742 	 0.02999711036682129 	 0.043502092361450195 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:56.063828 test begin: paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.021550893783569336 	 0.03040003776550293 	 6.246566772460938e-05 	 5.054473876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:56.259422 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10162198944 	 1000 	 0.021505117416381836 	 0.03046107292175293 	 2.5272369384765625e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:56.450620 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.021445751190185547 	 0.030297279357910156 	 2.9087066650390625e-05 	 4.673004150390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:56.641477 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.021349668502807617 	 0.030553102493286133 	 0.00020194053649902344 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:56.832106 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.021590709686279297 	 0.03216814994812012 	 1.4781951904296875e-05 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:56.988911 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.05876898765563965 	 0.08744215965270996 	 0.030002355575561523 	 0.04351663589477539 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:58.939925 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10165402496 	 1000 	 0.021381139755249023 	 0.03316664695739746 	 3.5762786865234375e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:59.438350 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.02139425277709961 	 0.03024888038635254 	 0.00013208389282226562 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:59.637070 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10164173504 	 1000 	 0.021363019943237305 	 0.03256487846374512 	 0.0001990795135498047 	 6.461143493652344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:32:59.836448 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.02135467529296875 	 1.154207468032837 	 0.00014901161193847656 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:02.189261 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.02454972267150879 	 0.03687906265258789 	 2.3365020751953125e-05 	 6.937980651855469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:02.446281 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.030453205108642578 	 0.04052138328552246 	 2.7418136596679688e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:02.674198 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.030740737915039062 	 0.03946685791015625 	 2.4557113647460938e-05 	 7.295608520507812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:02.917659 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.031004667282104492 	 0.050275325775146484 	 2.1219253540039062e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:03.159225 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10176284196 	 1000 	 0.05874037742614746 	 0.08543586730957031 	 0.03000640869140625 	 0.04352211952209473 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:03.583737 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.0588076114654541 	 0.08812236785888672 	 0.030004501342773438 	 0.04350638389587402 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.034203 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10168679808 	 1000 	 0.022782325744628906 	 0.03155040740966797 	 1.7642974853515625e-05 	 4.4345855712890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.186908 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.021378517150878906 	 0.030954837799072266 	 1.5497207641601562e-05 	 4.363059997558594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.339535 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.02156662940979004 	 0.03123188018798828 	 1.5020370483398438e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.492501 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.021366596221923828 	 0.031280517578125 	 1.5020370483398438e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.644371 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.022060394287109375 	 0.030986547470092773 	 2.0503997802734375e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.797275 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.030627012252807617 	 0.033000946044921875 	 3.62396240234375e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:04.978045 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.021240711212158203 	 0.031217098236083984 	 1.621246337890625e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:05.129366 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164992832 	 1000 	 0.022255420684814453 	 0.0308840274810791 	 1.7642974853515625e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:05.285818 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.021595001220703125 	 0.03193187713623047 	 1.5497207641601562e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:05.440707 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164647178 	 1000 	 0.021416425704956055 	 0.031006574630737305 	 1.52587890625e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:05.591473 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10165300080 	 1000 	 0.05877280235290527 	 0.08796334266662598 	 0.03002166748046875 	 0.04349541664123535 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:06.008656 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.058800697326660156 	 0.08548831939697266 	 0.030025720596313477 	 0.04354071617126465 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:06.418895 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164173504 	 1000 	 0.05875515937805176 	 0.08541703224182129 	 0.02997875213623047 	 0.04348039627075195 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:06.828405 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.05878114700317383 	 0.08542585372924805 	 0.030013322830200195 	 0.04348301887512207 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:07.238292 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.05872845649719238 	 0.08542013168334961 	 0.030004501342773438 	 0.043500661849975586 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:07.650733 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.05871701240539551 	 0.08543038368225098 	 0.029996395111083984 	 0.04351043701171875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:08.067854 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.05867791175842285 	 0.08543586730957031 	 0.02994990348815918 	 0.043508052825927734 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:08.478905 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.05874204635620117 	 0.08542513847351074 	 0.029982805252075195 	 0.0435028076171875 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:08.896323 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.021445035934448242 	 0.03686666488647461 	 7.128715515136719e-05 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:09.095307 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10166375448 	 1000 	 0.021519899368286133 	 0.030785322189331055 	 0.0001270771026611328 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:09.288434 test begin: paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.02171039581298828 	 0.031614065170288086 	 1.621246337890625e-05 	 4.1961669921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:09.440659 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.021427392959594727 	 0.030997276306152344 	 1.5497207641601562e-05 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:09.590514 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10161861696 	 1000 	 0.024265289306640625 	 0.03227829933166504 	 1.9311904907226562e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:09.766730 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803440 	 1000 	 1.697624921798706 	 1.7663004398345947 	 0.8671543598175049 	 0.16347265243530273 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:20.565387 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803440 	 1000 	 2.633124589920044 	 2.597654342651367 	 1.3447415828704834 	 0.18959546089172363 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:37.277235 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803440 	 1000 	 1.7247254848480225 	 1.7661921977996826 	 0.8788919448852539 	 0.1634840965270996 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:47.462795 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 1.6985182762145996 	 1.7645397186279297 	 0.8665573596954346 	 0.16332745552062988 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:33:58.244310 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402080 	 1000 	 2.6433627605438232 	 2.590858221054077 	 1.3454718589782715 	 0.18906712532043457 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:15.453434 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 1.7182989120483398 	 1.7681920528411865 	 0.8768370151519775 	 0.16363072395324707 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:25.614372 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76205040 	 1000 	 1.694265365600586 	 1.7665395736694336 	 0.8652799129486084 	 0.16349005699157715 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:37.292565 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76205040 	 1000 	 2.6352555751800537 	 2.5969460010528564 	 1.3458788394927979 	 0.18953824043273926 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:52.268278 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5080356720 	 1000 	 0.02893853187561035 	 0.03862786293029785 	 2.3603439331054688e-05 	 6.556510925292969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:52.401966 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5080356720 	 1000 	 0.029299259185791016 	 0.032884836196899414 	 2.5510787963867188e-05 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:52.526379 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2540196720 	 1000 	 0.02887725830078125 	 0.03372979164123535 	 2.1696090698242188e-05 	 5.0067901611328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:34:52.652456 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101606640 	 1000 	 3.387582302093506 	 3.543945550918579 	 1.7303857803344727 	 0.163834810256958 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:14.807639 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101606640 	 1000 	 5.259375095367432 	 5.190730333328247 	 2.6868247985839844 	 0.1881122589111328 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:46.537922 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.028927087783813477 	 0.033118247985839844 	 1.811981201171875e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:46.675434 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131141380 	 1000 	 0.029582738876342773 	 0.03287792205810547 	 3.3855438232421875e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:46.813313 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.0289919376373291 	 0.03312182426452637 	 2.09808349609375e-05 	 5.6743621826171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:46.950963 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.02912282943725586 	 0.03323221206665039 	 1.811981201171875e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.084657 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565607050 	 1000 	 0.02901148796081543 	 0.03311920166015625 	 1.430511474609375e-05 	 5.3882598876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.226658 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.02873539924621582 	 0.03334808349609375 	 1.9311904907226562e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.358579 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696702980 	 1000 	 0.035967111587524414 	 0.033185482025146484 	 4.076957702636719e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.511349 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696702980 	 1000 	 0.02888011932373047 	 0.03505730628967285 	 1.7642974853515625e-05 	 6.127357482910156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.649906 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.029078006744384766 	 0.03303647041320801 	 2.3603439331054688e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.780118 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131137744 	 1000 	 0.028772354125976562 	 0.03518986701965332 	 1.6689300537109375e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:47.920905 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.028859615325927734 	 0.03331398963928223 	 2.4557113647460938e-05 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.053720 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.02881646156311035 	 0.03399944305419922 	 1.3828277587890625e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.188850 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565605232 	 1000 	 0.028978347778320312 	 0.033265113830566406 	 1.6689300537109375e-05 	 4.363059997558594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.320982 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.028616905212402344 	 0.03389382362365723 	 1.7881393432617188e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.460041 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696699344 	 1000 	 0.028792142868041992 	 0.033003807067871094 	 1.2636184692382812e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.589281 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696699344 	 1000 	 0.028783082962036133 	 0.03316760063171387 	 1.2159347534179688e-05 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.721835 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.02891373634338379 	 0.03296041488647461 	 1.0967254638671875e-05 	 4.172325134277344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.852207 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131135320 	 1000 	 0.028876781463623047 	 0.0331876277923584 	 2.0742416381835938e-05 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:48.985863 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.028758764266967773 	 0.03302454948425293 	 1.33514404296875e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.115114 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.028819561004638672 	 0.03320622444152832 	 1.52587890625e-05 	 3.5762786865234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.245234 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565604020 	 1000 	 0.03269815444946289 	 0.048720598220825195 	 2.6702880859375e-05 	 0.00011515617370605469 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.399400 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.028959035873413086 	 0.03338003158569336 	 1.3828277587890625e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.538817 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696696920 	 1000 	 0.02881455421447754 	 0.035207271575927734 	 1.2159347534179688e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.671919 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696696920 	 1000 	 0.030449867248535156 	 0.03336334228515625 	 1.621246337890625e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.807388 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565610080 	 1000 	 0.028823375701904297 	 0.03361344337463379 	 1.3589859008789062e-05 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:49.939112 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.0285799503326416 	 0.033262014389038086 	 1.2159347534179688e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.067927 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.028712034225463867 	 0.033498287200927734 	 1.6927719116210938e-05 	 5.984306335449219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.198153 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.028659820556640625 	 0.03306865692138672 	 1.4543533325195312e-05 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.327857 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131165620 	 1000 	 0.029377460479736328 	 0.032911062240600586 	 1.7404556274414062e-05 	 4.6253204345703125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.464390 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131165620 	 1000 	 0.028800249099731445 	 0.033321380615234375 	 1.1920928955078125e-05 	 4.2438507080078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.598469 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131166832 	 1000 	 0.028880596160888672 	 0.03283119201660156 	 1.3589859008789062e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.741921 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131166832 	 1000 	 0.029137372970581055 	 0.03502535820007324 	 1.0728836059570312e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:50.877102 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131168650 	 1000 	 0.04813218116760254 	 0.03295707702636719 	 3.409385681152344e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.029490 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131168650 	 1000 	 0.028895854949951172 	 0.03379178047180176 	 1.0967254638671875e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.167552 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131171680 	 1000 	 0.028755664825439453 	 0.03354167938232422 	 1.2874603271484375e-05 	 5.221366882324219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.297468 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131171680 	 1000 	 0.030704975128173828 	 0.03313899040222168 	 1.71661376953125e-05 	 4.887580871582031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.430935 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50839920 	 1000 	 0.028728485107421875 	 0.03323793411254883 	 1.1444091796875e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.559919 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50839920 	 1000 	 0.029361486434936523 	 0.0329747200012207 	 1.0728836059570312e-05 	 3.600120544433594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.691500 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25438320 	 1000 	 0.028594970703125 	 0.03273749351501465 	 1.1920928955078125e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.819844 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262258520 	 1000 	 0.028934001922607422 	 0.033023834228515625 	 1.5020370483398438e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:51.952805 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262258520 	 1000 	 0.029025554656982422 	 0.03296256065368652 	 1.1205673217773438e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:52.084114 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262260944 	 1000 	 0.02919745445251465 	 0.03322792053222656 	 1.5735626220703125e-05 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:52.215954 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262260944 	 1000 	 0.028853893280029297 	 0.03332972526550293 	 1.4066696166992188e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:52.347966 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262264580 	 1000 	 0.0329742431640625 	 0.033174753189086914 	 3.743171691894531e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:52.494126 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262264580 	 1000 	 0.028917551040649414 	 0.032964468002319336 	 1.4543533325195312e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:35:52.625247 test begin: paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101607120 	 1000 	 3.386150598526001 	 3.5633575916290283 	 1.729144811630249 	 0.16487646102905273 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:36:15.625508 test begin: paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101607120 	 1000 	 5.259662866592407 	 5.182569980621338 	 2.686918020248413 	 0.18801045417785645 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:36:46.459407 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 1.6950364112854004 	 1.7673702239990234 	 0.8657839298248291 	 0.16348862648010254 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:36:56.579120 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402320 	 1000 	 2.6333789825439453 	 2.5980875492095947 	 1.3450829982757568 	 0.18960356712341309 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:37:12.848514 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 1.7210869789123535 	 1.7691709995269775 	 0.8790347576141357 	 0.16342926025390625 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:37:25.729814 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76205520 	 1000 	 1.6972105503082275 	 1.7649152278900146 	 0.8668804168701172 	 0.1632823944091797 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:37:38.003677 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76205520 	 1000 	 2.6345651149749756 	 2.6024439334869385 	 1.3451769351959229 	 0.18978619575500488 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:37:52.932417 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 1.6955177783966064 	 1.7661917209625244 	 0.8655343055725098 	 0.1634378433227539 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:38:03.108930 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803920 	 1000 	 2.634434700012207 	 2.59673810005188 	 1.3456621170043945 	 0.18951654434204102 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:38:18.056156 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 1.7183306217193604 	 1.9921650886535645 	 0.8776853084564209 	 0.1638355255126953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:38:30.691432 test begin: paddle.nn.functional.mish(Tensor([12, 10585, 20, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 10585, 20, 20],"float32"), ) 	 50808000 	 1000 	 0.304797887802124 	 0.30022597312927246 	 0.29598188400268555 	 0.2779364585876465 	 0.4537234306335449 	 0.4543616771697998 	 0.4019746780395508 	 0.3453338146209717 	 
2025-07-30 13:38:33.920635 test begin: paddle.nn.functional.mish(Tensor([12, 128, 40, 827],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 128, 40, 827],"float32"), ) 	 50810880 	 1000 	 0.30541229248046875 	 0.7508015632629395 	 0.2962222099304199 	 0.28466248512268066 	 0.45386528968811035 	 0.45440101623535156 	 0.40114617347717285 	 0.3888278007507324 	 
2025-07-30 13:38:39.873340 test begin: paddle.nn.functional.mish(Tensor([12, 128, 827, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 128, 827, 40],"float32"), ) 	 50810880 	 1000 	 0.30588841438293457 	 0.30013370513916016 	 0.29621386528015137 	 0.28482913970947266 	 0.4536478519439697 	 0.4542992115020752 	 0.4024674892425537 	 0.38318562507629395 	 
2025-07-30 13:38:43.043710 test begin: paddle.nn.functional.mish(Tensor([12, 256, 40, 414],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 256, 40, 414],"float32"), ) 	 50872320 	 1000 	 0.3067307472229004 	 0.3004794120788574 	 0.29266953468322754 	 0.28490686416625977 	 0.4537835121154785 	 0.45495009422302246 	 0.40074682235717773 	 0.3911316394805908 	 
2025-07-30 13:38:46.255659 test begin: paddle.nn.functional.mish(Tensor([12, 256, 414, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 256, 414, 40],"float32"), ) 	 50872320 	 1000 	 0.30623865127563477 	 0.3004894256591797 	 0.2964761257171631 	 0.2850925922393799 	 0.4539773464202881 	 0.45500874519348145 	 0.4026761054992676 	 0.39078354835510254 	 
2025-07-30 13:38:49.436494 test begin: paddle.nn.functional.mish(Tensor([12, 2647, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 2647, 40, 40],"float32"), ) 	 50822400 	 1000 	 0.3054618835449219 	 0.3001682758331299 	 0.29683947563171387 	 0.2779970169067383 	 0.4536442756652832 	 0.45453405380249023 	 0.4026923179626465 	 0.3882274627685547 	 
2025-07-30 13:38:52.595174 test begin: paddle.nn.functional.mish(Tensor([12, 512, 20, 414],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 512, 20, 414],"float32"), ) 	 50872320 	 1000 	 0.3053455352783203 	 0.3005824089050293 	 0.2965738773345947 	 0.2779867649078369 	 0.45386576652526855 	 0.4550025463104248 	 0.40149736404418945 	 0.3835415840148926 	 
2025-07-30 13:38:55.903672 test begin: paddle.nn.functional.mish(Tensor([12, 512, 414, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 512, 414, 20],"float32"), ) 	 50872320 	 1000 	 0.3051891326904297 	 0.3004720211029053 	 0.2965092658996582 	 0.2849714756011963 	 0.45395588874816895 	 0.4549214839935303 	 0.4026832580566406 	 0.39078354835510254 	 
2025-07-30 13:38:59.058703 test begin: paddle.nn.functional.mish(Tensor([125, 256, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([125, 256, 40, 40],"float32"), ) 	 51200000 	 1000 	 0.30766844749450684 	 0.3023955821990967 	 0.29805731773376465 	 0.28693246841430664 	 0.45682477951049805 	 0.4576902389526367 	 0.39211249351501465 	 0.3939976692199707 	 
2025-07-30 13:39:02.558110 test begin: paddle.nn.functional.mish(Tensor([249, 128, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([249, 128, 40, 40],"float32"), ) 	 50995200 	 1000 	 0.30594325065612793 	 0.3037898540496826 	 0.2971522808074951 	 0.28535914421081543 	 0.45512938499450684 	 0.45591115951538086 	 0.4038052558898926 	 0.3910834789276123 	 
2025-07-30 13:39:05.715670 test begin: paddle.nn.functional.mish(Tensor([249, 512, 20, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([249, 512, 20, 20],"float32"), ) 	 50995200 	 1000 	 0.3058505058288574 	 0.3011007308959961 	 0.29727983474731445 	 0.28563356399536133 	 0.45517468452453613 	 0.45601487159729004 	 0.403794527053833 	 0.3894352912902832 	 
2025-07-30 13:39:08.913395 test begin: paddle.nn.functional.mse_loss(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), "mean", ) 	 101608320 	 1000 	 0.8936676979064941 	 0.5980224609375 	 0.22803401947021484 	 0.203369140625 	 1.0590193271636963 	 1.159921646118164 	 0.3609297275543213 	 0.296403169631958 	 
2025-07-30 13:39:14.468794 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), "mean", ) 	 101671488 	 1000 	 0.8940067291259766 	 0.5982139110565186 	 0.2281513214111328 	 0.20347261428833008 	 1.0596420764923096 	 1.1603379249572754 	 0.3611030578613281 	 0.2964446544647217 	 
2025-07-30 13:39:19.802751 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", )
/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Using a target size (torch.Size([3548, 12, 170, 8])) that is different to the input size (torch.Size([3548, 12, 170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", ) 	 65141280 	 1000 	 0.8644568920135498 	 0.574631929397583 	 0.22063231468200684 	 0.19542169570922852 	 1.5460264682769775 	 1.6168675422668457 	 0.39510393142700195 	 0.3307657241821289 	 
2025-07-30 13:39:25.497163 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), "mean", )
/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Using a target size (torch.Size([3548, 12, 170, 1])) that is different to the input size (torch.Size([3548, 12, 170, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), "mean", ) 	 65141280 	 1000 	 0.8652915954589844 	 0.5763676166534424 	 0.22086381912231445 	 0.19556879997253418 	 1.1362524032592773 	 1.6171777248382568 	 0.38726210594177246 	 0.33084535598754883 	 
2025-07-30 13:39:31.188948 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", ) 	 115806720 	 1000 	 1.021979808807373 	 0.7261860370635986 	 0.2593064308166504 	 0.24106502532958984 	 1.2057793140411377 	 1.3196356296539307 	 0.41097211837768555 	 0.3368661403656006 	 
2025-07-30 13:39:39.824700 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), "mean", ) 	 102537200 	 1000 	 0.9016039371490479 	 0.6033811569213867 	 0.23009204864501953 	 0.2052140235900879 	 1.068230390548706 	 1.1702840328216553 	 0.36408424377441406 	 0.2989675998687744 	 
2025-07-30 13:39:45.322076 test begin: paddle.nn.functional.mse_loss(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), "none", ) 	 101646336 	 1000 	 0.7459290027618408 	 0.4471144676208496 	 0.3810703754425049 	 0.4220120906829834 	 0.9247941970825195 	 1.4458379745483398 	 0.4724695682525635 	 0.3692965507507324 	 
2025-07-30 13:39:51.751890 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), "none", ) 	 101670912 	 1000 	 0.7462491989135742 	 0.4471702575683594 	 0.3812534809112549 	 0.4206349849700928 	 0.9247627258300781 	 1.4461116790771484 	 0.4724140167236328 	 0.36946916580200195 	 
2025-07-30 13:39:58.081142 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), "none", ) 	 101744640 	 1000 	 0.7465598583221436 	 0.4474296569824219 	 0.3813807964324951 	 0.4215383529663086 	 0.925457239151001 	 1.4473249912261963 	 0.4728245735168457 	 0.3697521686553955 	 
2025-07-30 13:40:04.071788 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), "none", ) 	 103809024 	 1000 	 0.7617597579956055 	 0.45642614364624023 	 0.38916826248168945 	 0.43187618255615234 	 0.9445047378540039 	 1.475771188735962 	 0.48255348205566406 	 0.3770613670349121 	 
2025-07-30 13:40:10.235844 test begin: paddle.nn.functional.mse_loss(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), "none", ) 	 103809024 	 1000 	 0.7616226673126221 	 0.45883870124816895 	 0.3890655040740967 	 0.42942118644714355 	 0.9426605701446533 	 1.4760017395019531 	 0.4816017150878906 	 0.3770425319671631 	 
2025-07-30 13:40:16.396205 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), "none", ) 	 104857600 	 1000 	 0.7716741561889648 	 0.46085667610168457 	 0.39306640625 	 0.43710851669311523 	 0.9515044689178467 	 1.4908673763275146 	 0.4861328601837158 	 0.38082027435302734 	 
2025-07-30 13:40:22.632386 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), "none", ) 	 101646336 	 1000 	 0.7458598613739014 	 0.4469108581542969 	 0.38108325004577637 	 0.41516757011413574 	 0.9243433475494385 	 1.4457271099090576 	 0.47225332260131836 	 0.3693556785583496 	 
2025-07-30 13:40:28.869349 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), "none", ) 	 101646336 	 1000 	 0.7457213401794434 	 0.44702625274658203 	 0.3809976577758789 	 0.41691017150878906 	 0.9241664409637451 	 1.4464499950408936 	 0.47222471237182617 	 0.3696134090423584 	 
2025-07-30 13:40:37.907720 test begin: paddle.nn.functional.mse_loss(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), "none", ) 	 101744640 	 1000 	 1.9184000492095947 	 0.48158740997314453 	 0.3814539909362793 	 0.41788268089294434 	 0.9249935150146484 	 1.4473507404327393 	 0.4724740982055664 	 0.3697073459625244 	 
2025-07-30 13:40:49.433544 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=None, ) 	 50803210 	 1000 	 3.380829095840454 	 3.3238189220428467 	 0.31407952308654785 	 0.28255486488342285 	 4.626243829727173 	 4.30057954788208 	 0.36472082138061523 	 0.33867716789245605 	 
2025-07-30 13:41:07.556565 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=Tensor([5, 5080321],"float64"), )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=Tensor([5, 5080321],"float64"), ) 	 76204815 	 1000 	 3.8258039951324463 	 3.76572585105896 	 0.3246147632598877 	 0.29561734199523926 	 5.3718650341033936 	 5.062497138977051 	 0.3921492099761963 	 0.3451251983642578 	 
2025-07-30 13:41:28.517794 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), weight=Tensor([5, 5080321],"float64"), reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), weight=Tensor([5, 5080321],"float64"), reduction="mean", name=None, ) 	 76204815 	 1000 	 3.823395252227783 	 3.7757370471954346 	 0.324676513671875 	 0.295670747756958 	 5.372867107391357 	 5.0627055168151855 	 0.3921794891357422 	 0.34513211250305176 	 
2025-07-30 13:41:50.592426 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=None, ) 	 50803210 	 1000 	 3.39841365814209 	 3.485257625579834 	 0.3148825168609619 	 0.29626989364624023 	 4.712346076965332 	 4.455999135971069 	 0.3714277744293213 	 0.3508472442626953 	 
2025-07-30 13:42:09.746676 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=Tensor([5080321, 5],"float64"), )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=Tensor([5080321, 5],"float64"), ) 	 76204815 	 1000 	 3.8378183841705322 	 3.9425482749938965 	 0.3262662887573242 	 0.3084716796875 	 5.458500862121582 	 5.211041212081909 	 0.39847660064697266 	 0.35523200035095215 	 
2025-07-30 13:42:29.946125 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), weight=Tensor([5080321, 5],"float64"), reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), weight=Tensor([5080321, 5],"float64"), reduction="mean", name=None, ) 	 76204815 	 1000 	 3.8378660678863525 	 3.929215669631958 	 0.32627320289611816 	 0.30846714973449707 	 5.458587646484375 	 5.211025238037109 	 0.3984191417694092 	 0.3552083969116211 	 
2025-07-30 13:42:51.771446 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
W0730 13:42:52.447214  7264 dygraph_functions.cc:93089] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 38102403 	 1000 	 3.867513418197632 	 16.22588849067688 	 0.0001983642578125 	 5.5169079303741455 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:43:16.885726 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 38102403 	 1000 	 3.785217523574829 	 16.163483142852783 	 0.0001323223114013672 	 16.12378716468811 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:43:42.218665 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 38102403 	 1000 	 3.8727922439575195 	 16.22443914413452 	 0.0001976490020751953 	 5.516451120376587 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:44:07.316598 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 76204803 	 1000 	 7.505844831466675 	 32.433563232421875 	 0.0004112720489501953 	 11.027962923049927 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:44:57.036531 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 76204803 	 1000 	 7.361191272735596 	 32.293954610824585 	 0.0002803802490234375 	 32.27440118789673 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:45:48.320481 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 76204803 	 1000 	 7.504227876663208 	 32.44480109214783 	 0.0004169940948486328 	 11.033404350280762 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:46:39.715036 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 25401610 	 1000 	 1.283015489578247 	 6.023916959762573 	 2.8133392333984375e-05 	 3.077866554260254 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:46:49.937682 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 25401610 	 1000 	 1.259032964706421 	 6.01729154586792 	 3.62396240234375e-05 	 5.998995780944824 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:47:00.129951 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 25401610 	 1000 	 1.2798371315002441 	 6.020381212234497 	 3.123283386230469e-05 	 3.0758330821990967 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:47:10.351645 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, ) 	 25443143 	 1000 	 0.027259111404418945 	 0.03745865821838379 	 2.0265579223632812e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:47:11.088294 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, ) 	 25443143 	 1000 	 0.028022289276123047 	 0.0246126651763916 	 1.71661376953125e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 13:47:11.807627 test begin: paddle.nn.functional.normalize(Tensor([2009, 25288],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2009, 25288],"float32"), ) 	 50803592 	 1000 	 0.4738779067993164 	 0.4692869186401367 	 0.09692597389221191 	 0.1597907543182373 	 2.6801679134368896 	 3.2003262042999268 	 0.548541784286499 	 0.23361635208129883 	 
2025-07-30 13:47:21.491610 test begin: paddle.nn.functional.normalize(Tensor([2081, 24413],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2081, 24413],"float32"), ) 	 50803453 	 1000 	 0.9411389827728271 	 0.47017812728881836 	 0.09731626510620117 	 0.16011786460876465 	 2.679373264312744 	 3.2018446922302246 	 0.5484857559204102 	 0.2337348461151123 	 
2025-07-30 13:47:32.715431 test begin: paddle.nn.functional.normalize(Tensor([2331, 21795],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2331, 21795],"float32"), ) 	 50804145 	 1000 	 0.4692709445953369 	 0.477614164352417 	 0.09589648246765137 	 0.16009259223937988 	 2.688274621963501 	 3.20233416557312 	 0.5503389835357666 	 0.2337644100189209 	 
2025-07-30 13:47:43.083651 test begin: paddle.nn.functional.normalize(Tensor([99226, 512],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([99226, 512],"float32"), ) 	 50803712 	 1000 	 0.4877452850341797 	 0.47572898864746094 	 0.09974980354309082 	 0.15908026695251465 	 2.7079598903656006 	 3.2114832401275635 	 0.5544047355651855 	 0.23442435264587402 	 
2025-07-30 13:47:51.683940 test begin: paddle.nn.functional.npair_loss(Tensor([18, 2822401],"float32"), positive=Tensor([18, 2822401],"float32"), labels=Tensor([18],"float32"), l2_reg=0.002, )
[Prof] paddle.nn.functional.npair_loss 	 paddle.nn.functional.npair_loss(Tensor([18, 2822401],"float32"), positive=Tensor([18, 2822401],"float32"), labels=Tensor([18],"float32"), l2_reg=0.002, ) 	 101606454 	 1000 	 1.4829583168029785 	 1.4154934883117676 	 0.06323099136352539 	 0.07207989692687988 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 13:47:59.547770 test begin: paddle.nn.functional.pad(Tensor([7573, 11, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7573, 11, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 106627840 	 1000 	 1.2354075908660889 	 0.4712953567504883 	 1.223829746246338 	 0.15956997871398926 	 0.986161470413208 	 0.8022563457489014 	 0.9324517250061035 	 0.27306199073791504 	 
2025-07-30 13:48:06.455144 test begin: paddle.nn.functional.pad(Tensor([7573, 8, 1678],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7573, 8, 1678],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 101659952 	 1000 	 1.1784875392913818 	 0.4474296569824219 	 1.1669011116027832 	 0.1523439884185791 	 0.9402015209197998 	 0.7654950618743896 	 0.8861467838287354 	 0.2605273723602295 	 
2025-07-30 13:48:13.508116 test begin: paddle.nn.functional.pad(Tensor([7710, 11, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7710, 11, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 108556800 	 1000 	 1.2568764686584473 	 0.4768192768096924 	 1.2451386451721191 	 0.16241693496704102 	 1.0042805671691895 	 0.8164052963256836 	 0.9507248401641846 	 0.27779674530029297 	 
2025-07-30 13:48:21.254219 test begin: paddle.nn.functional.pad(Tensor([7710, 8, 1648],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7710, 8, 1648],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 101648640 	 1000 	 1.1796438694000244 	 0.4556107521057129 	 1.1669721603393555 	 0.15236949920654297 	 0.9403729438781738 	 0.765099287033081 	 0.8833284378051758 	 0.26039600372314453 	 
2025-07-30 13:48:31.457587 test begin: paddle.nn.functional.pad(Tensor([8162, 10, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([8162, 10, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 104473600 	 1000 	 1.2109038829803467 	 0.9044427871704102 	 1.199312448501587 	 0.15651726722717285 	 0.9662811756134033 	 0.7867741584777832 	 0.9123528003692627 	 0.2677881717681885 	 
2025-07-30 13:48:41.658878 test begin: paddle.nn.functional.pad(Tensor([8162, 8, 1557],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([8162, 8, 1557],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 101665872 	 1000 	 1.1784443855285645 	 0.44790077209472656 	 1.1669127941131592 	 0.15245413780212402 	 0.9408314228057861 	 0.7654273509979248 	 0.8867452144622803 	 0.26052284240722656 	 
2025-07-30 13:48:48.392209 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1791975498199463 	 0.44788193702697754 	 1.1656215190887451 	 0.22698450088500977 	 0.9398233890533447 	 0.762007474899292 	 0.8862552642822266 	 0.389329195022583 	 
2025-07-30 13:48:55.044513 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1783180236816406 	 0.4443964958190918 	 1.165743112564087 	 0.22696566581726074 	 0.9397449493408203 	 0.7619967460632324 	 0.8863141536712646 	 0.3893299102783203 	 
2025-07-30 13:49:01.568124 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1792209148406982 	 0.44447994232177734 	 1.166736125946045 	 0.22697710990905762 	 0.9397823810577393 	 0.7621250152587891 	 0.8860940933227539 	 0.38936424255371094 	 
2025-07-30 13:49:08.167086 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, False, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, False, None, ) 	 101606600 	 1000 	 1.1408679485321045 	 1.0619919300079346 	 0.1939527988433838 	 0.2711985111236572 	 1.8938663005828857 	 2.774306535720825 	 0.9677095413208008 	 0.2835562229156494 	 
2025-07-30 13:49:16.695391 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, True, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, True, None, ) 	 101606600 	 1000 	 1.1403248310089111 	 1.0619897842407227 	 0.19385290145874023 	 0.2711029052734375 	 1.8947629928588867 	 2.7744243144989014 	 0.9682140350341797 	 0.2835667133331299 	 
2025-07-30 13:49:25.302265 test begin: paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, False, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, False, None, ) 	 101606600 	 1000 	 1.524254560470581 	 1.6437687873840332 	 0.3117194175720215 	 0.5600564479827881 	 1.9798462390899658 	 2.785673141479492 	 1.011678695678711 	 0.28476572036743164 	 
2025-07-30 13:49:37.722426 test begin: paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, True, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, True, None, ) 	 101606600 	 1000 	 1.536487102508545 	 1.643874168395996 	 0.31282520294189453 	 0.5601282119750977 	 1.9800453186035156 	 2.785599946975708 	 1.01170015335083 	 0.28472185134887695 	 
2025-07-30 13:49:48.117776 test begin: paddle.nn.functional.pixel_shuffle(Tensor([13, 256, 128, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([13, 256, 128, 128],"float32"), 2, "NCHW", None, ) 	 54525952 	 1000 	 0.4094970226287842 	 0.35150694847106934 	 0.3959786891937256 	 0.3334834575653076 	 0.3946664333343506 	 0.34293293952941895 	 0.34195470809936523 	 0.26728129386901855 	 
2025-07-30 13:49:51.572596 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 128, 388],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 128, 388],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.3757004737854004 	 0.33452701568603516 	 0.36598658561706543 	 0.3153038024902344 	 0.40209007263183594 	 0.325054407119751 	 0.35172319412231445 	 0.2500741481781006 	 
2025-07-30 13:49:54.754811 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 388, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 388, 128],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.383652925491333 	 0.33399486541748047 	 0.37403345108032227 	 0.31586456298828125 	 0.4003162384033203 	 0.3219444751739502 	 0.35040807723999023 	 0.24680280685424805 	 
2025-07-30 13:49:57.840578 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 776, 128, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 776, 128, 128],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.3797893524169922 	 0.3282172679901123 	 0.36830735206604004 	 0.30980730056762695 	 0.3692896366119385 	 0.320082426071167 	 0.3191525936126709 	 0.24579572677612305 	 
2025-07-30 13:50:00.948051 test begin: paddle.nn.functional.pixel_shuffle(Tensor([49, 256, 64, 64],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([49, 256, 64, 64],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.38852834701538086 	 0.32990121841430664 	 0.3788321018218994 	 0.3108823299407959 	 0.36322498321533203 	 0.32747936248779297 	 0.3132455348968506 	 0.2511754035949707 	 
2025-07-30 13:50:03.991476 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 128, 25],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 128, 25],"float32"), 2, "NCHW", None, ) 	 52428800 	 1000 	 0.38791370391845703 	 0.3396756649017334 	 0.3781707286834717 	 0.32161784172058105 	 0.3891928195953369 	 0.3412470817565918 	 0.33829712867736816 	 0.26467442512512207 	 
2025-07-30 13:50:07.114328 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 25, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 25, 128],"float32"), 2, "NCHW", None, ) 	 52428800 	 1000 	 0.39620256423950195 	 0.3386116027832031 	 0.3860602378845215 	 0.32060694694519043 	 0.3793177604675293 	 0.32213830947875977 	 0.3262767791748047 	 0.24788117408752441 	 
2025-07-30 13:50:10.257963 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 49, 64],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 49, 64],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.38779330253601074 	 0.33660340309143066 	 0.3780345916748047 	 0.3184983730316162 	 0.3651242256164551 	 0.31861162185668945 	 0.31476402282714844 	 0.24401450157165527 	 
2025-07-30 13:50:13.288465 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 64, 49],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 64, 49],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.38071203231811523 	 0.3325765132904053 	 0.37071776390075684 	 0.3146507740020752 	 0.37502217292785645 	 0.3339102268218994 	 0.29259729385375977 	 0.2578294277191162 	 
2025-07-30 13:50:16.453971 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", ) 	 25401744 	 1000 	 0.31940579414367676 	 0.3019094467163086 	 0.30678439140319824 	 0.28382229804992676 	 0.3160054683685303 	 0.30209922790527344 	 0.2664334774017334 	 0.2280411720275879 	 
2025-07-30 13:50:18.743382 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", None, ) 	 25401744 	 1000 	 0.317457914352417 	 0.30199146270751953 	 0.3069455623626709 	 0.2831239700317383 	 0.31595444679260254 	 0.3021278381347656 	 0.2644462585449219 	 0.2273104190826416 	 
2025-07-30 13:50:21.032182 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 176401, 12, 12],"float32"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 176401, 12, 12],"float32"), 3, "NCHW", ) 	 50803488 	 1000 	 0.3689548969268799 	 0.32683801651000977 	 0.35582542419433594 	 0.30855774879455566 	 0.3615248203277588 	 0.3223285675048828 	 0.31148624420166016 	 0.24814128875732422 	 
2025-07-30 13:50:24.078159 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", ) 	 25401888 	 1000 	 0.3175160884857178 	 0.30202579498291016 	 0.30705928802490234 	 0.28319287300109863 	 0.3159663677215576 	 0.3021888732910156 	 0.2659733295440674 	 0.2259683609008789 	 
2025-07-30 13:50:26.356205 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", None, ) 	 25401888 	 1000 	 0.31753039360046387 	 0.30228734016418457 	 0.30695295333862305 	 0.2837204933166504 	 0.3160433769226074 	 0.30216264724731445 	 0.25759434700012207 	 0.22740745544433594 	 
2025-07-30 13:50:28.647141 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([352801, 1, 12, 12],"float32"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([352801, 1, 12, 12],"float32"), 3, "NCHW", ) 	 50803344 	 1000 	 0.36574459075927734 	 0.32691168785095215 	 0.3552074432373047 	 0.3081235885620117 	 0.36165618896484375 	 0.3223395347595215 	 0.3107790946960449 	 0.24601364135742188 	 
2025-07-30 13:50:31.722551 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"bfloat16"), )
W0730 13:50:34.735443 10323 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"bfloat16"), ) 	 203212812 	 1000 	 3.149857521057129 	 2.6011838912963867 	 0.5357017517089844 	 0.5291497707366943 	 5.693805694580078 	 4.8102099895477295 	 0.9694197177886963 	 0.7022581100463867 	 
2025-07-30 13:50:53.093563 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"float16"), ) 	 203212812 	 1000 	 3.1490564346313477 	 2.5889334678649902 	 0.5356564521789551 	 0.5284249782562256 	 5.695014476776123 	 4.807175874710083 	 0.9693753719329834 	 0.7018172740936279 	 
2025-07-30 13:51:12.999930 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"bfloat16"), ) 	 203212816 	 1000 	 3.1498332023620605 	 2.5921130180358887 	 0.5356080532073975 	 0.5290184020996094 	 5.693122863769531 	 4.810380697250366 	 0.9692034721374512 	 0.7023007869720459 	 
2025-07-30 13:51:32.717079 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"float16"), ) 	 203212816 	 1000 	 3.154172420501709 	 2.588688373565674 	 0.5356428623199463 	 0.5283713340759277 	 5.695038557052612 	 4.807133913040161 	 0.9695930480957031 	 0.7017965316772461 	 
2025-07-30 13:51:55.357300 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 1.6681568622589111 	 1.0696163177490234 	 0.24353313446044922 	 0.21837997436523438 	 2.270622968673706 	 2.170233964920044 	 0.33149170875549316 	 0.27731776237487793 	 
2025-07-30 13:52:03.480972 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"bfloat16"), ) 	 101606424 	 1000 	 1.5864033699035645 	 1.3125975131988525 	 0.269855260848999 	 0.2679622173309326 	 2.8595306873321533 	 2.4211320877075195 	 0.48681139945983887 	 0.35350465774536133 	 
2025-07-30 13:52:13.350490 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float16"), ) 	 101606424 	 1000 	 1.5859460830688477 	 1.3118081092834473 	 0.269789457321167 	 0.2677571773529053 	 2.860722303390503 	 2.4184441566467285 	 0.4869241714477539 	 0.35306239128112793 	 
2025-07-30 13:52:23.315595 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), ) 	 101606424 	 1000 	 3.3070287704467773 	 2.101407289505005 	 0.4829130172729492 	 0.42899608612060547 	 4.511102914810181 	 4.299314975738525 	 0.6585266590118408 	 0.549407958984375 	 
2025-07-30 13:52:40.246848 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"bfloat16"), ) 	 203212824 	 1000 	 3.1490180492401123 	 2.593881845474243 	 0.5356230735778809 	 0.5294692516326904 	 5.693406105041504 	 4.809948921203613 	 0.969186544418335 	 0.7021732330322266 	 
2025-07-30 13:53:00.939960 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"float16"), ) 	 203212824 	 1000 	 3.1491410732269287 	 2.588737964630127 	 0.5355987548828125 	 0.5284321308135986 	 5.693918228149414 	 4.806937217712402 	 0.9692304134368896 	 0.7017874717712402 	 
2025-07-30 13:53:20.941607 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 1.668208122253418 	 1.0686068534851074 	 0.24358034133911133 	 0.21818804740905762 	 2.2707502841949463 	 2.1697957515716553 	 0.3314974308013916 	 0.2772653102874756 	 
2025-07-30 13:53:29.085363 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"bfloat16"), ) 	 101606416 	 1000 	 1.5865752696990967 	 1.3275103569030762 	 0.2698361873626709 	 0.2679603099822998 	 2.8595049381256104 	 2.421375036239624 	 0.4867861270904541 	 0.35348010063171387 	 
2025-07-30 13:53:42.012551 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float16"), ) 	 101606416 	 1000 	 1.5983622074127197 	 1.3107678890228271 	 0.2698194980621338 	 0.26759958267211914 	 2.861023187637329 	 2.418926477432251 	 0.48697710037231445 	 0.35314440727233887 	 
2025-07-30 13:53:52.026075 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), ) 	 101606416 	 1000 	 3.307110548019409 	 2.103137969970703 	 0.4828054904937744 	 0.42907071113586426 	 4.511138916015625 	 4.2988972663879395 	 0.6587827205657959 	 0.5494155883789062 	 
2025-07-30 13:54:09.339908 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 1.6681232452392578 	 1.0684263706207275 	 0.2435314655303955 	 0.21809077262878418 	 2.270655632019043 	 2.169989824295044 	 0.33150482177734375 	 0.27736902236938477 	 
2025-07-30 13:54:17.516830 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"bfloat16"), ) 	 101606412 	 1000 	 1.5862219333648682 	 1.3131301403045654 	 0.2697794437408447 	 0.268230676651001 	 2.85915470123291 	 2.421341896057129 	 0.4866938591003418 	 0.35344409942626953 	 
2025-07-30 13:54:27.374520 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float16"), ) 	 101606412 	 1000 	 1.5859403610229492 	 1.3108055591583252 	 0.269763708114624 	 0.26758384704589844 	 2.8607308864593506 	 2.4186246395111084 	 0.4870123863220215 	 0.3530740737915039 	 
2025-07-30 13:54:37.823175 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), ) 	 101606412 	 1000 	 3.3088557720184326 	 2.102508306503296 	 0.4829423427581787 	 0.42926907539367676 	 4.511070251464844 	 4.298648834228516 	 0.6585369110107422 	 0.5494232177734375 	 
2025-07-30 13:54:54.569492 test begin: paddle.nn.functional.prelu(Tensor([104, 128, 56, 69],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 128, 56, 69],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51437696 	 1000 	 0.30528736114501953 	 0.31262660026550293 	 0.28821468353271484 	 0.2967655658721924 	 1.0988895893096924 	 0.7958519458770752 	 0.3737752437591553 	 0.27064037322998047 	 
2025-07-30 13:54:58.743682 test begin: paddle.nn.functional.prelu(Tensor([104, 128, 69, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 128, 69, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51437696 	 1000 	 0.3043677806854248 	 0.3126258850097656 	 0.291851282119751 	 0.2969810962677002 	 1.098985195159912 	 0.7962870597839355 	 0.3738420009613037 	 0.27088403701782227 	 
2025-07-30 13:55:03.029960 test begin: paddle.nn.functional.prelu(Tensor([104, 156, 56, 56],"float32"), Tensor([156],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 156, 56, 56],"float32"), Tensor([156],"float32"), data_format="NCHW", ) 	 50878620 	 1000 	 0.301311731338501 	 0.31960368156433105 	 0.2888810634613037 	 0.28569531440734863 	 1.0817739963531494 	 0.7926678657531738 	 0.3679983615875244 	 0.26962971687316895 	 
2025-07-30 13:55:10.606177 test begin: paddle.nn.functional.prelu(Tensor([127, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([127, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 50978944 	 1000 	 0.30197715759277344 	 0.30965113639831543 	 0.2895646095275879 	 0.293743371963501 	 1.0868749618530273 	 0.7878866195678711 	 0.3696115016937256 	 0.2680225372314453 	 
2025-07-30 13:55:14.910614 test begin: paddle.nn.functional.prelu(Tensor([128, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51380352 	 1000 	 0.30394768714904785 	 0.31505537033081055 	 0.29146361351013184 	 0.2965562343597412 	 1.0956709384918213 	 0.7928950786590576 	 0.37268996238708496 	 0.26974916458129883 	 
2025-07-30 13:55:19.128389 test begin: paddle.nn.functional.prelu(Tensor([128, 256, 28, 56],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 256, 28, 56],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 51380480 	 1000 	 0.30437588691711426 	 0.312061071395874 	 0.29154038429260254 	 0.2967188358306885 	 1.0952396392822266 	 0.7939999103546143 	 0.3725244998931885 	 0.27014684677124023 	 
2025-07-30 13:55:23.314062 test begin: paddle.nn.functional.prelu(Tensor([128, 256, 56, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 256, 56, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 51380480 	 1000 	 0.30402708053588867 	 0.3119938373565674 	 0.29172301292419434 	 0.296414852142334 	 1.095344066619873 	 0.7935223579406738 	 0.3725440502166748 	 0.2699437141418457 	 
2025-07-30 13:55:27.455960 test begin: paddle.nn.functional.prelu(Tensor([128, 507, 28, 28],"float32"), Tensor([507],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 507, 28, 28],"float32"), Tensor([507],"float32"), data_format="NCHW", ) 	 50878971 	 1000 	 0.30132365226745605 	 0.3091747760772705 	 0.28862619400024414 	 0.29308128356933594 	 1.073779582977295 	 0.7797629833221436 	 0.36525464057922363 	 0.3982999324798584 	 
2025-07-30 13:55:31.563118 test begin: paddle.nn.functional.prelu(Tensor([254, 256, 28, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([254, 256, 28, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 50979072 	 1000 	 0.3019709587097168 	 0.30972886085510254 	 0.2895338535308838 	 0.29405856132507324 	 1.0874640941619873 	 0.7889459133148193 	 0.3699338436126709 	 0.2683568000793457 	 
2025-07-30 13:55:37.327333 test begin: paddle.nn.functional.relu(Tensor([10, 128, 480, 83],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 128, 480, 83],"float32"), None, ) 	 50995200 	 1000 	 0.7588577270507812 	 0.30431199073791504 	 0.28830885887145996 	 0.28270506858825684 	 0.45198750495910645 	 0.4483919143676758 	 0.40082526206970215 	 0.3791511058807373 	 
2025-07-30 13:55:41.693139 test begin: paddle.nn.functional.relu(Tensor([10, 128, 83, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 128, 83, 480],"float32"), None, ) 	 50995200 	 1000 	 0.2968940734863281 	 0.2989692687988281 	 0.2884068489074707 	 0.2749772071838379 	 0.45200347900390625 	 0.4483659267425537 	 0.3897836208343506 	 0.3732583522796631 	 
2025-07-30 13:55:44.961054 test begin: paddle.nn.functional.relu(Tensor([10, 23, 480, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 23, 480, 480],"float32"), None, ) 	 52992000 	 1000 	 0.30858683586120605 	 0.31064534187316895 	 0.29833364486694336 	 0.2941274642944336 	 0.4698359966278076 	 0.4656977653503418 	 0.4171943664550781 	 0.36437463760375977 	 
2025-07-30 13:55:48.436025 test begin: paddle.nn.functional.relu(Tensor([2, 128, 480, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([2, 128, 480, 480],"float32"), None, ) 	 58982400 	 1000 	 0.34283447265625 	 0.3482859134674072 	 0.3343796730041504 	 0.3292567729949951 	 0.521996259689331 	 0.517913818359375 	 0.4702916145324707 	 0.4399230480194092 	 
2025-07-30 13:55:52.068841 test begin: paddle.nn.functional.relu(Tensor([2, 256, 352, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([2, 256, 352, 352],"float32"), ) 	 63438848 	 1000 	 0.36855149269104004 	 0.3724658489227295 	 0.36004209518432617 	 0.3546571731567383 	 0.5609657764434814 	 0.5565426349639893 	 0.5095767974853516 	 0.4778304100036621 	 
2025-07-30 13:55:55.946297 test begin: paddle.nn.functional.relu(Tensor([64, 64, 112, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([64, 64, 112, 112],"float32"), None, ) 	 51380224 	 1000 	 0.2990913391113281 	 0.30112290382385254 	 0.2904684543609619 	 0.2855966091156006 	 0.45540595054626465 	 0.4517703056335449 	 0.4041595458984375 	 0.3746192455291748 	 
2025-07-30 13:55:59.087229 test begin: paddle.nn.functional.relu(Tensor([640, 64, 112, 12],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 64, 112, 12],"float32"), None, ) 	 55050240 	 1000 	 0.3202395439147949 	 0.32553815841674805 	 0.31176018714904785 	 0.3067188262939453 	 0.48743581771850586 	 0.48354530334472656 	 0.4321565628051758 	 0.4140031337738037 	 
2025-07-30 13:56:02.525671 test begin: paddle.nn.functional.relu(Tensor([640, 64, 12, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 64, 12, 112],"float32"), None, ) 	 55050240 	 1000 	 0.3202080726623535 	 0.32230472564697266 	 0.31174302101135254 	 0.30690884590148926 	 0.48743200302124023 	 0.483536958694458 	 0.4360337257385254 	 0.4152994155883789 	 
2025-07-30 13:56:05.928745 test begin: paddle.nn.functional.relu(Tensor([640, 7, 112, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 7, 112, 112],"float32"), None, ) 	 56197120 	 1000 	 0.32705259323120117 	 0.3289968967437744 	 0.3186352252960205 	 0.30579090118408203 	 0.4976491928100586 	 0.4936368465423584 	 0.43642139434814453 	 0.4181232452392578 	 
2025-07-30 13:56:09.472537 test begin: paddle.nn.functional.relu(Tensor([8, 256, 352, 71],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 256, 352, 71],"float32"), ) 	 51183616 	 1000 	 0.2981400489807129 	 0.5620675086975098 	 0.2886393070220947 	 0.27715229988098145 	 0.45373082160949707 	 0.4500429630279541 	 0.39264726638793945 	 0.3733968734741211 	 
2025-07-30 13:56:15.843961 test begin: paddle.nn.functional.relu(Tensor([8, 256, 71, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 256, 71, 352],"float32"), ) 	 51183616 	 1000 	 0.29902148246765137 	 0.29996347427368164 	 0.28963518142700195 	 0.28447556495666504 	 0.45360732078552246 	 0.44999003410339355 	 0.40265965461730957 	 0.3814840316772461 	 
2025-07-30 13:56:18.998831 test begin: paddle.nn.functional.relu(Tensor([8, 52, 352, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 52, 352, 352],"float32"), ) 	 51544064 	 1000 	 0.30002808570861816 	 0.3021852970123291 	 0.29155683517456055 	 0.2859835624694824 	 0.4566657543182373 	 0.4530961513519287 	 0.4053761959075928 	 0.38403797149658203 	 
2025-07-30 13:56:22.219674 test begin: paddle.nn.functional.relu6(Tensor([128, 144, 112, 25],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 144, 112, 25],"float32"), ) 	 51609600 	 1000 	 0.3003559112548828 	 0.30251264572143555 	 0.2918081283569336 	 0.28374791145324707 	 0.4573795795440674 	 0.4538235664367676 	 0.4014115333557129 	 0.36211395263671875 	 
2025-07-30 13:56:25.393723 test begin: paddle.nn.functional.relu6(Tensor([128, 144, 25, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 144, 25, 112],"float32"), ) 	 51609600 	 1000 	 0.30039429664611816 	 0.3025851249694824 	 0.291733980178833 	 0.2839019298553467 	 0.45724940299987793 	 0.45363855361938477 	 0.4058542251586914 	 0.38282203674316406 	 
2025-07-30 13:56:28.616165 test begin: paddle.nn.functional.relu6(Tensor([128, 192, 112, 19],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 192, 112, 19],"float32"), ) 	 52297728 	 1000 	 0.30428075790405273 	 0.30646681785583496 	 0.2956888675689697 	 0.2882208824157715 	 0.4634206295013428 	 0.4595608711242676 	 0.4123966693878174 	 0.3924980163574219 	 
2025-07-30 13:56:31.879054 test begin: paddle.nn.functional.relu6(Tensor([128, 192, 19, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 192, 19, 112],"float32"), ) 	 52297728 	 1000 	 0.30431246757507324 	 0.32007646560668945 	 0.29573750495910645 	 0.28821563720703125 	 0.46338534355163574 	 0.45960307121276855 	 0.4126615524291992 	 0.3919227123260498 	 
2025-07-30 13:56:35.132866 test begin: paddle.nn.functional.relu6(Tensor([128, 32, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 32, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.7455723285675049 	 0.30498313903808594 	 0.290147066116333 	 0.2829461097717285 	 0.4554166793823242 	 0.4517550468444824 	 0.403972864151001 	 0.38312411308288574 	 
2025-07-30 13:56:40.705365 test begin: paddle.nn.functional.relu6(Tensor([22, 192, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([22, 192, 112, 112],"float32"), ) 	 52985856 	 1000 	 0.3084127902984619 	 0.3106038570404053 	 0.29981112480163574 	 0.29195451736450195 	 0.4694995880126953 	 0.46559906005859375 	 0.41359424591064453 	 0.3975260257720947 	 
2025-07-30 13:56:44.092287 test begin: paddle.nn.functional.relu6(Tensor([256, 16, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 16, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.29993605613708496 	 0.30290675163269043 	 0.29035496711730957 	 0.2828068733215332 	 0.45538878440856934 	 0.45174455642700195 	 0.40418362617492676 	 0.38446640968322754 	 
2025-07-30 13:56:47.275373 test begin: paddle.nn.functional.relu6(Tensor([256, 96, 112, 19],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 96, 112, 19],"float32"), ) 	 52297728 	 1000 	 0.3042912483215332 	 0.30651283264160156 	 0.295698881149292 	 0.2882363796234131 	 0.4634068012237549 	 0.45961761474609375 	 0.4126124382019043 	 0.3928050994873047 	 
2025-07-30 13:56:50.508075 test begin: paddle.nn.functional.relu6(Tensor([256, 96, 19, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 96, 19, 112],"float32"), ) 	 52297728 	 1000 	 0.3149869441986084 	 0.31366920471191406 	 0.2955930233001709 	 0.28748559951782227 	 0.46344470977783203 	 0.4595305919647217 	 0.41229772567749023 	 0.3923485279083252 	 
2025-07-30 13:56:53.737301 test begin: paddle.nn.functional.relu6(Tensor([29, 144, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([29, 144, 112, 112],"float32"), ) 	 52383744 	 1000 	 0.3058021068572998 	 0.3069736957550049 	 0.295914888381958 	 0.2885570526123047 	 0.464191198348999 	 0.46024346351623535 	 0.4127492904663086 	 0.3931872844696045 	 
2025-07-30 13:56:56.955799 test begin: paddle.nn.functional.relu6(Tensor([43, 96, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([43, 96, 112, 112],"float32"), ) 	 51781632 	 1000 	 0.30142664909362793 	 0.30353260040283203 	 0.2926459312438965 	 0.2850508689880371 	 0.4588015079498291 	 0.4551846981048584 	 0.40777587890625 	 0.38552236557006836 	 
2025-07-30 13:57:00.153473 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 4233601],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2, 3, 4233601],"float64"), 0.05, 0.25, training=False, ) 	 25401606 	 1000 	 0.4807577133178711 	 0.2987790107727051 	 0.470813512802124 	 0.27713513374328613 	 0.5844504833221436 	 0.44320082664489746 	 0.5341253280639648 	 0.36865711212158203 	 
2025-07-30 13:57:03.056338 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3175201, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2, 3175201, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401608 	 1000 	 0.48062562942504883 	 0.29895877838134766 	 0.4707791805267334 	 0.2672543525695801 	 0.5841958522796631 	 0.44315528869628906 	 0.534102201461792 	 0.3761744499206543 	 
2025-07-30 13:57:05.972946 test begin: paddle.nn.functional.rrelu(Tensor([1, 2116801, 3, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2116801, 3, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401612 	 1000 	 0.48062896728515625 	 0.2989327907562256 	 0.47078967094421387 	 0.27678704261779785 	 0.5842211246490479 	 0.44316554069519043 	 0.5320096015930176 	 0.37593889236450195 	 
2025-07-30 13:57:08.970000 test begin: paddle.nn.functional.rrelu(Tensor([1058401, 2, 3, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1058401, 2, 3, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401624 	 1000 	 0.480762243270874 	 0.3021574020385742 	 0.4636876583099365 	 0.2681565284729004 	 0.5843014717102051 	 0.4432857036590576 	 0.532886266708374 	 0.367063045501709 	 
2025-07-30 13:57:11.943294 test begin: paddle.nn.functional.rrelu(Tensor([2, 1270081, 4, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 1270081, 4, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803240 	 1000 	 0.48750734329223633 	 0.3022472858428955 	 0.4771614074707031 	 0.2763028144836426 	 0.6032452583312988 	 0.44666504859924316 	 0.552947998046875 	 0.35878944396972656 	 
2025-07-30 13:57:15.285554 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 1693441, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 1693441, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803230 	 1000 	 0.4904611110687256 	 0.30569934844970703 	 0.47717952728271484 	 0.27614474296569824 	 0.6032376289367676 	 0.44672441482543945 	 0.5530369281768799 	 0.35909485816955566 	 
2025-07-30 13:57:20.989135 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 1058401],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 4, 1058401],"float64"), 0.1, 0.3, training=False, ) 	 25401624 	 1000 	 0.4806556701660156 	 0.30004167556762695 	 0.4702925682067871 	 0.2766721248626709 	 0.5842421054840088 	 0.4431638717651367 	 0.5306105613708496 	 0.3545806407928467 	 
2025-07-30 13:57:23.790166 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 2116801],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 4, 2116801],"float32"), 0.1, 0.3, training=False, ) 	 50803224 	 1000 	 0.48751378059387207 	 0.298018217086792 	 0.4771537780761719 	 0.27623510360717773 	 0.6032116413116455 	 0.44664478302001953 	 0.550182580947876 	 0.3603060245513916 	 
2025-07-30 13:57:27.226512 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 846721, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 846721, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401630 	 1000 	 0.4806973934173584 	 0.2989621162414551 	 0.47041940689086914 	 0.277026891708374 	 0.584200382232666 	 0.44315338134765625 	 0.5334291458129883 	 0.3697819709777832 	 
2025-07-30 13:57:30.038942 test begin: paddle.nn.functional.rrelu(Tensor([2, 635041, 4, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 635041, 4, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401640 	 1000 	 0.48041868209838867 	 0.2987949848175049 	 0.4601261615753174 	 0.2681117057800293 	 0.5842196941375732 	 0.4431760311126709 	 0.5247597694396973 	 0.3686227798461914 	 
2025-07-30 13:57:32.957845 test begin: paddle.nn.functional.rrelu(Tensor([423361, 3, 4, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([423361, 3, 4, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401660 	 1000 	 0.4803347587585449 	 0.3005821704864502 	 0.4630095958709717 	 0.2681593894958496 	 0.5842113494873047 	 0.44313621520996094 	 0.524705171585083 	 0.36898255348205566 	 
2025-07-30 13:57:37.124682 test begin: paddle.nn.functional.rrelu(Tensor([846721, 3, 4, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([846721, 3, 4, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803260 	 1000 	 0.501244068145752 	 0.2982051372528076 	 0.47704648971557617 	 0.2761523723602295 	 0.6034421920776367 	 0.44669222831726074 	 0.5523734092712402 	 0.35936522483825684 	 
2025-07-30 13:57:42.232664 test begin: paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.2997722625732422 	 1.826622724533081 	 0.29122018814086914 	 0.31110286712646484 	 0.44747138023376465 	 2.123739004135132 	 0.38843202590942383 	 0.27149486541748047 	 
2025-07-30 13:57:48.123735 test begin: paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.2997622489929199 	 1.8257205486297607 	 0.29125380516052246 	 0.31107401847839355 	 0.4477851390838623 	 2.1238176822662354 	 0.3980600833892822 	 0.27151966094970703 	 
2025-07-30 13:57:53.932194 test begin: paddle.nn.functional.selu(Tensor([2822401, 3, 3],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([2822401, 3, 3],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.30022311210632324 	 1.8255302906036377 	 0.29129528999328613 	 0.311049222946167 	 0.4480891227722168 	 2.123791456222534 	 0.3980388641357422 	 0.27146053314208984 	 
2025-07-30 13:57:59.677058 test begin: paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.2997598648071289 	 1.8257238864898682 	 0.2911398410797119 	 0.3111379146575928 	 0.44800496101379395 	 2.123837947845459 	 0.39892005920410156 	 0.2715418338775635 	 
2025-07-30 13:58:05.412240 test begin: paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.29975390434265137 	 1.8257050514221191 	 0.2912561893463135 	 0.31113457679748535 	 0.4474208354949951 	 2.123718500137329 	 0.39756178855895996 	 0.27155375480651855 	 
2025-07-30 13:58:11.137760 test begin: paddle.nn.functional.selu(Tensor([3, 2822401, 3],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 2822401, 3],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.29981255531311035 	 1.8271312713623047 	 0.2911245822906494 	 0.311126708984375 	 0.44797849655151367 	 2.1237339973449707 	 0.37544679641723633 	 0.2715489864349365 	 
2025-07-30 13:58:16.889974 test begin: paddle.nn.functional.selu(Tensor([3, 3, 2822401],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 3, 2822401],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.299854040145874 	 1.8257036209106445 	 0.29126572608947754 	 0.31110239028930664 	 0.44815707206726074 	 2.1237964630126953 	 0.39760494232177734 	 0.27150845527648926 	 
2025-07-30 13:58:23.444894 test begin: paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.30208253860473633 	 1.8293733596801758 	 0.291095495223999 	 0.3111417293548584 	 0.4480922222137451 	 2.1236722469329834 	 0.39885377883911133 	 0.2715277671813965 	 
2025-07-30 13:58:29.966342 test begin: paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.2997581958770752 	 1.8256990909576416 	 0.2907097339630127 	 0.31110167503356934 	 0.44783759117126465 	 2.1237857341766357 	 0.3979947566986084 	 0.2715291976928711 	 
2025-07-30 13:58:37.275702 test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, ) 	 25401675 	 1000 	 0.9118561744689941 	 1.831667184829712 	 0.28455638885498047 	 0.3113386631011963 	 0.44818615913391113 	 2.1246652603149414 	 0.38811707496643066 	 0.271679162979126 	 
2025-07-30 13:58:44.220818 test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, None, ) 	 25401675 	 1000 	 0.3004341125488281 	 1.8278899192810059 	 0.28470563888549805 	 0.3112175464630127 	 0.44800448417663574 	 2.1238274574279785 	 0.38858675956726074 	 0.27156519889831543 	 
2025-07-30 13:58:50.037488 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 705601],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 705601],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7788937091827393 	 1.4812748432159424 	 0.7592997550964355 	 0.5050294399261475 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:58:52.834098 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 705601, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 705601, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7788586616516113 	 1.4819462299346924 	 0.7593381404876709 	 0.5050272941589355 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:58:55.631468 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 705601, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 705601, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7788650989532471 	 1.4865796566009521 	 0.7591197490692139 	 0.5050299167633057 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:58:58.419336 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 470401, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 470401, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401654 	 1000 	 0.7788877487182617 	 1.48136568069458 	 0.7585618495941162 	 0.5051238536834717 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:59:01.223713 test begin: paddle.nn.functional.sequence_mask(Tensor([470401, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([470401, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401654 	 1000 	 0.7788615226745605 	 1.4812705516815186 	 0.7593226432800293 	 0.5050225257873535 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:59:04.039507 test begin: paddle.nn.functional.sequence_mask(Tensor([50803201],"int32"), maxlen=4, dtype="float32", )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([50803201],"int32"), maxlen=4, dtype="float32", ) 	 50803201 	 1000 	 1.2109038829803467 	 2.4233129024505615 	 1.1970746517181396 	 0.8263270854949951 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:59:08.765174 test begin: paddle.nn.functional.sigmoid(Tensor([10, 32, 400, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([10, 32, 400, 400],"float32"), ) 	 51200000 	 1000 	 0.29729795455932617 	 0.30061960220336914 	 0.2886807918548584 	 0.2888927459716797 	 0.4536921977996826 	 0.4500899314880371 	 0.40240979194641113 	 0.38263988494873047 	 
2025-07-30 13:59:11.928343 test begin: paddle.nn.functional.sigmoid(Tensor([364, 304, 460],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([364, 304, 460],"float32"), ) 	 50901760 	 1000 	 0.2956368923187256 	 0.302706241607666 	 0.2800142765045166 	 0.27689170837402344 	 0.45116138458251953 	 0.4475288391113281 	 0.38996386528015137 	 0.37099123001098633 	 
2025-07-30 13:59:15.087905 test begin: paddle.nn.functional.sigmoid(Tensor([364, 416, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([364, 416, 336],"float32"), ) 	 50878464 	 1000 	 0.2954373359680176 	 0.29868483543395996 	 0.2798275947570801 	 0.28174448013305664 	 0.4509561061859131 	 0.44733333587646484 	 0.3864903450012207 	 0.3735179901123047 	 
2025-07-30 13:59:18.193006 test begin: paddle.nn.functional.sigmoid(Tensor([372, 304, 450],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([372, 304, 450],"float32"), ) 	 50889600 	 1000 	 0.296356201171875 	 0.2988607883453369 	 0.2799952030181885 	 0.28186464309692383 	 0.4510226249694824 	 0.4474208354949951 	 0.3890814781188965 	 0.37129878997802734 	 
2025-07-30 13:59:21.306060 test begin: paddle.nn.functional.sigmoid(Tensor([372, 407, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([372, 407, 336],"float32"), ) 	 50871744 	 1000 	 0.2982645034790039 	 0.2988095283508301 	 0.2792849540710449 	 0.28179287910461426 	 0.450969934463501 	 0.44727301597595215 	 0.38611364364624023 	 0.3714582920074463 	 
2025-07-30 13:59:24.678907 test begin: paddle.nn.functional.sigmoid(Tensor([498, 304, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([498, 304, 336],"float32"), ) 	 50867712 	 1000 	 0.29541826248168945 	 0.30769991874694824 	 0.2869606018066406 	 0.2878103256225586 	 0.4509923458099365 	 0.4472079277038574 	 0.39987969398498535 	 0.37161850929260254 	 
2025-07-30 13:59:31.742814 test begin: paddle.nn.functional.sigmoid(Tensor([8, 32, 400, 497],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 32, 400, 497],"float32"), ) 	 50892800 	 1000 	 0.29552388191223145 	 0.30159449577331543 	 0.28707456588745117 	 0.28794431686401367 	 0.4511110782623291 	 0.44750165939331055 	 0.39955759048461914 	 0.3775944709777832 	 
2025-07-30 13:59:34.940152 test begin: paddle.nn.functional.sigmoid(Tensor([8, 32, 497, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 32, 497, 400],"float32"), ) 	 50892800 	 1000 	 0.7862443923950195 	 0.5467076301574707 	 0.286851167678833 	 0.2880523204803467 	 0.45108771324157715 	 0.44745850563049316 	 0.3999049663543701 	 0.37955307960510254 	 
2025-07-30 13:59:40.535964 test begin: paddle.nn.functional.sigmoid(Tensor([8, 40, 400, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 40, 400, 400],"float32"), ) 	 51200000 	 1000 	 0.2973594665527344 	 0.3005964756011963 	 0.28883934020996094 	 0.29023265838623047 	 0.453782320022583 	 0.4501328468322754 	 0.40218663215637207 	 0.35448718070983887 	 
2025-07-30 13:59:43.673852 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803248 	 1000 	 6.906790018081665 	 5.646689414978027 	 0.00067901611328125 	 0.3032193183898926 	 9.2526273727417 	 9.165118932723999 	 0.4114367961883545 	 0.3746929168701172 	 combined
2025-07-30 14:00:15.698740 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803249 	 1000 	 7.20051646232605 	 5.944921970367432 	 0.0009849071502685547 	 0.3031735420227051 	 10.007251024246216 	 10.963937997817993 	 0.39351606369018555 	 0.35033607482910156 	 combined
2025-07-30 14:00:51.549448 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803249 	 1000 	 7.207948207855225 	 5.945866346359253 	 0.0009784698486328125 	 0.3031635284423828 	 10.007734775543213 	 10.961476564407349 	 0.3934640884399414 	 0.35033559799194336 	 combined
2025-07-30 14:01:27.440182 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803320 	 1000 	 6.900827407836914 	 5.664139986038208 	 0.0006966590881347656 	 0.3033020496368408 	 9.251922369003296 	 9.165805339813232 	 0.4114351272583008 	 0.3747591972351074 	 combined
2025-07-30 14:02:02.989816 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803321 	 1000 	 7.202669143676758 	 5.93937611579895 	 0.0009796619415283203 	 0.30315136909484863 	 10.008636951446533 	 10.961572408676147 	 0.393465518951416 	 0.35035109519958496 	 combined
2025-07-30 14:02:38.274650 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803321 	 1000 	 7.204891204833984 	 5.940873861312866 	 0.0009796619415283203 	 0.30304646492004395 	 10.009167194366455 	 10.962223768234253 	 0.39346790313720703 	 0.3503572940826416 	 combined
2025-07-30 14:03:15.007817 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803360 	 1000 	 6.9013543128967285 	 5.638636589050293 	 0.0006701946258544922 	 0.3033008575439453 	 9.248286962509155 	 9.165466070175171 	 0.41126561164855957 	 0.3747673034667969 	 combined
2025-07-30 14:03:46.988710 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803361 	 1000 	 7.195755481719971 	 5.940781593322754 	 0.0009765625 	 0.30307984352111816 	 10.010223150253296 	 10.961523294448853 	 0.3935091495513916 	 0.35036277770996094 	 combined
2025-07-30 14:04:23.163643 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803361 	 1000 	 7.196625709533691 	 5.949728012084961 	 0.0009729862213134766 	 0.30309391021728516 	 10.009413719177246 	 10.961674451828003 	 0.39355993270874023 	 0.3503289222717285 	 combined
2025-07-30 14:04:58.383013 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803440 	 1000 	 6.8953773975372314 	 5.6384546756744385 	 0.0006887912750244141 	 0.30324554443359375 	 9.250065326690674 	 9.16511607170105 	 0.4112679958343506 	 0.3747825622558594 	 combined
2025-07-30 14:05:31.019505 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803441 	 1000 	 7.197090148925781 	 5.939515590667725 	 0.0009801387786865234 	 0.30309128761291504 	 10.001575231552124 	 10.961613178253174 	 0.3931457996368408 	 0.35032176971435547 	 combined
2025-07-30 14:06:06.949699 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803441 	 1000 	 7.198049306869507 	 5.939137935638428 	 0.0009746551513671875 	 0.30306553840637207 	 10.000467538833618 	 10.96246075630188 	 0.3931577205657959 	 0.35033583641052246 	 combined
2025-07-30 14:06:43.372122 test begin: paddle.nn.functional.silu(Tensor([128, 128, 128, 25],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 128, 128, 25],"float32"), None, ) 	 52428800 	 1000 	 0.30705976486206055 	 0.31158995628356934 	 0.29600095748901367 	 0.2925286293029785 	 0.46454906463623047 	 0.46442174911499023 	 0.40074801445007324 	 0.3903818130493164 	 
2025-07-30 14:06:46.795289 test begin: paddle.nn.functional.silu(Tensor([128, 128, 25, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 128, 25, 128],"float32"), None, ) 	 52428800 	 1000 	 0.3045828342437744 	 0.30776023864746094 	 0.2961249351501465 	 0.29196834564208984 	 0.4646461009979248 	 0.4646494388580322 	 0.41176891326904297 	 0.37481236457824707 	 
2025-07-30 14:06:50.130484 test begin: paddle.nn.functional.silu(Tensor([128, 25, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 25, 128, 128],"float32"), None, ) 	 52428800 	 1000 	 0.30567312240600586 	 0.30758166313171387 	 0.2957339286804199 	 0.292435884475708 	 0.4645678997039795 	 0.4645214080810547 	 0.4130368232727051 	 0.39733099937438965 	 
2025-07-30 14:06:53.397752 test begin: paddle.nn.functional.silu(Tensor([128, 256, 25, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 256, 25, 64],"float32"), None, ) 	 52428800 	 1000 	 0.3046879768371582 	 0.3076162338256836 	 0.2885417938232422 	 0.2923743724822998 	 0.46454668045043945 	 0.46453046798706055 	 0.41315126419067383 	 0.3915104866027832 	 
2025-07-30 14:06:56.873452 test begin: paddle.nn.functional.silu(Tensor([128, 256, 64, 25],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 256, 64, 25],"float32"), None, ) 	 52428800 	 1000 	 0.30463647842407227 	 0.30764031410217285 	 0.296093225479126 	 0.29253482818603516 	 0.4645261764526367 	 0.4645724296569824 	 0.412996768951416 	 0.39697694778442383 	 
2025-07-30 14:07:00.180818 test begin: paddle.nn.functional.silu(Tensor([128, 64, 128, 49],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 64, 128, 49],"float32"), None, ) 	 51380224 	 1000 	 0.29848814010620117 	 0.30155515670776367 	 0.28990912437438965 	 0.2867417335510254 	 0.455491304397583 	 0.45528435707092285 	 0.4037587642669678 	 0.3677835464477539 	 
2025-07-30 14:07:03.348900 test begin: paddle.nn.functional.silu(Tensor([128, 64, 49, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 64, 49, 128],"float32"), None, ) 	 51380224 	 1000 	 0.29854822158813477 	 0.30161571502685547 	 0.2894108295440674 	 0.2866086959838867 	 0.45548200607299805 	 0.4552779197692871 	 0.4039595127105713 	 0.3862776756286621 	 
2025-07-30 14:07:06.562750 test begin: paddle.nn.functional.silu(Tensor([128, 97, 64, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 97, 64, 64],"float32"), None, ) 	 50855936 	 1000 	 0.29555225372314453 	 0.299654483795166 	 0.2869529724121094 	 0.283313512802124 	 0.45088624954223633 	 0.4506499767303467 	 0.39931273460388184 	 0.38336801528930664 	 
2025-07-30 14:07:09.703041 test begin: paddle.nn.functional.silu(Tensor([25, 128, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([25, 128, 128, 128],"float32"), None, ) 	 52428800 	 1000 	 0.3045339584350586 	 0.308274507522583 	 0.295992374420166 	 0.2888603210449219 	 0.4645376205444336 	 0.4644947052001953 	 0.413226842880249 	 0.39763665199279785 	 
2025-07-30 14:07:14.079925 test begin: paddle.nn.functional.silu(Tensor([49, 256, 64, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([49, 256, 64, 64],"float32"), None, ) 	 51380224 	 1000 	 0.7554397583007812 	 0.30153775215148926 	 0.28997015953063965 	 0.28653430938720703 	 0.4555377960205078 	 0.4552006721496582 	 0.40375614166259766 	 0.38741350173950195 	 
2025-07-30 14:07:18.046276 test begin: paddle.nn.functional.silu(Tensor([49, 64, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([49, 64, 128, 128],"float32"), None, ) 	 51380224 	 1000 	 0.2986025810241699 	 0.30158305168151855 	 0.2877840995788574 	 0.2796213626861572 	 0.4554893970489502 	 0.4553077220916748 	 0.39424729347229004 	 0.38428473472595215 	 
2025-07-30 14:07:21.430531 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"float32"), reduction="none", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"float32"), reduction="none", ) 	 101606500 	 1000 	 0.8113338947296143 	 0.4469296932220459 	 0.4144167900085449 	 0.4134652614593506 	 1.626603603363037 	 1.4465157985687256 	 0.4156515598297119 	 0.3695693016052246 	 
2025-07-30 14:07:28.418472 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1017, 50000],"float32"), Tensor([1017, 50000],"float32"), reduction="mean", delta=1.0, name=None, )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1017, 50000],"float32"), Tensor([1017, 50000],"float32"), reduction="mean", delta=1.0, name=None, ) 	 101700000 	 1000 	 0.9650921821594238 	 0.5989651679992676 	 0.24622654914855957 	 0.2037513256072998 	 1.763045072555542 	 1.1614036560058594 	 0.3604438304901123 	 0.2965967655181885 	 
2025-07-30 14:07:34.582901 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1914, 26543],"float32"), Tensor([1914, 26543],"float32"), reduction="none", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1914, 26543],"float32"), Tensor([1914, 26543],"float32"), reduction="none", ) 	 101606604 	 1000 	 0.8126177787780762 	 0.4469599723815918 	 0.41396665573120117 	 0.4217979907989502 	 1.6233949661254883 	 1.4464731216430664 	 0.4146575927734375 	 0.3695182800292969 	 
2025-07-30 14:07:42.647075 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([33960, 187, 8],"float32"), Tensor([33960, 187, 8],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([33960, 187, 8],"float32"), Tensor([33960, 187, 8],"float32"), reduction="sum", ) 	 101608320 	 1000 	 0.9653732776641846 	 0.5978572368621826 	 0.24631214141845703 	 0.20339298248291016 	 1.7616453170776367 	 1.1602375507354736 	 0.3601248264312744 	 0.2964060306549072 	 
2025-07-30 14:07:48.832572 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([64, 187, 4245],"float32"), Tensor([64, 187, 4245],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([64, 187, 4245],"float32"), Tensor([64, 187, 4245],"float32"), reduction="sum", ) 	 101608320 	 1000 	 0.965346097946167 	 0.597855806350708 	 0.2463541030883789 	 0.20341730117797852 	 1.7614188194274902 	 1.1606249809265137 	 0.3600952625274658 	 0.2964150905609131 	 
2025-07-30 14:07:54.952392 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([64, 99226, 8],"float32"), Tensor([64, 99226, 8],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([64, 99226, 8],"float32"), Tensor([64, 99226, 8],"float32"), reduction="sum", ) 	 101607424 	 1000 	 0.9654653072357178 	 0.5980193614959717 	 0.24635601043701172 	 0.20348668098449707 	 1.7585952281951904 	 1.1602609157562256 	 0.3595240116119385 	 0.2964165210723877 	 
2025-07-30 14:08:01.232209 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([7, 7257601],"float32"), Tensor([7, 7257601],"float32"), reduction="mean", delta=1.0, name=None, )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([7, 7257601],"float32"), Tensor([7, 7257601],"float32"), reduction="mean", delta=1.0, name=None, ) 	 101606414 	 1000 	 0.9647645950317383 	 0.5978548526763916 	 0.2461528778076172 	 0.20342540740966797 	 1.7617301940917969 	 1.160536766052246 	 0.36011815071105957 	 0.2965667247772217 	 
2025-07-30 14:08:07.363717 test begin: paddle.nn.functional.softmax(Tensor([10, 2304, 2304],"float32"), axis=-1, )
W0730 14:08:08.212533 17134 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([10, 2304, 2304],"float32"), axis=-1, ) 	 53084160 	 1000 	 0.3153824806213379 	 0.5292177200317383 	 0.30507516860961914 	 0.5137436389923096 	 0.4893794059753418 	 0.9308757781982422 	 0.43143296241760254 	 0.47565484046936035 	 
2025-07-30 14:08:11.487013 test begin: paddle.nn.functional.softmax(Tensor([3840, 1, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 1, 144, 144],"float32"), -1, name=None, ) 	 79626240 	 1000 	 0.462430477142334 	 0.5024676322937012 	 0.4536154270172119 	 0.4867985248565674 	 0.7009496688842773 	 1.3925831317901611 	 0.6505753993988037 	 0.7115399837493896 	 
2025-07-30 14:08:19.073969 test begin: paddle.nn.functional.softmax(Tensor([3840, 4, 144, 23],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 4, 144, 23],"float32"), -1, name=None, ) 	 50872320 	 1000 	 0.8224360942840576 	 0.5029346942901611 	 0.353851318359375 	 0.48688721656799316 	 0.45062732696533203 	 0.8943486213684082 	 0.40076303482055664 	 0.45694851875305176 	 
2025-07-30 14:08:24.386697 test begin: paddle.nn.functional.softmax(Tensor([3840, 4, 23, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 4, 23, 144],"float32"), -1, name=None, ) 	 50872320 	 1000 	 0.2968180179595947 	 0.3233928680419922 	 0.2878916263580322 	 0.3072381019592285 	 0.4497668743133545 	 0.8924243450164795 	 0.39827847480773926 	 0.4559633731842041 	 
2025-07-30 14:08:27.989696 test begin: paddle.nn.functional.softmax(Tensor([4096, 1, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 1, 144, 144],"float32"), -1, name=None, ) 	 84934656 	 1000 	 0.49320006370544434 	 0.5404367446899414 	 0.48389434814453125 	 0.5175745487213135 	 0.747241735458374 	 1.4846775531768799 	 0.6914193630218506 	 0.7586538791656494 	 
2025-07-30 14:08:34.044188 test begin: paddle.nn.functional.softmax(Tensor([4096, 4, 144, 22],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 4, 144, 22],"float32"), -1, name=None, ) 	 51904512 	 1000 	 0.4629170894622803 	 0.54010009765625 	 0.45107030868530273 	 0.5195262432098389 	 0.4634287357330322 	 0.9145879745483398 	 0.41371798515319824 	 0.4672248363494873 	 
2025-07-30 14:08:40.492745 test begin: paddle.nn.functional.softmax(Tensor([4096, 4, 22, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 4, 22, 144],"float32"), -1, name=None, ) 	 51904512 	 1000 	 0.3038749694824219 	 0.33074283599853516 	 0.29379963874816895 	 0.31487441062927246 	 0.4587726593017578 	 0.9105079174041748 	 0.4082951545715332 	 0.46511220932006836 	 
2025-07-30 14:08:44.137919 test begin: paddle.nn.functional.softmax(Tensor([60, 2304, 368],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([60, 2304, 368],"float32"), axis=-1, ) 	 50872320 	 1000 	 0.3007199764251709 	 0.3027024269104004 	 0.29218506813049316 	 0.28723669052124023 	 0.45024633407592773 	 0.8927767276763916 	 0.4004981517791748 	 0.45618629455566406 	 
2025-07-30 14:08:47.749655 test begin: paddle.nn.functional.softmax(Tensor([60, 368, 2304],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([60, 368, 2304],"float32"), axis=-1, ) 	 50872320 	 1000 	 0.3024330139160156 	 0.5104928016662598 	 0.2920980453491211 	 0.4920237064361572 	 0.4694175720214844 	 0.8923275470733643 	 0.41597533226013184 	 0.4558675289154053 	 
2025-07-30 14:08:51.670570 test begin: paddle.nn.functional.softmax(Tensor([613, 4, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([613, 4, 144, 144],"float32"), -1, name=None, ) 	 50844672 	 1000 	 0.2967090606689453 	 0.3271827697753906 	 0.2882063388824463 	 0.3080916404724121 	 0.44945526123046875 	 0.8920228481292725 	 0.3998258113861084 	 0.4557960033416748 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:08:58.362801 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=3, ) 	 51617280 	 1000 	 0.3442864418029785 	 1.2749545574188232 	 0.32671380043029785 	 0.26011228561401367 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:01.383653 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 1, 64],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 1, 64],"int64"), axis=2, ) 	 52394496 	 1000 	 1.2698214054107666 	 2.242304801940918 	 0.6487603187561035 	 0.3812251091003418 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:06.317728 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=-1, ) 	 51600640 	 1000 	 0.343874454498291 	 1.2745587825775146 	 0.32630395889282227 	 0.2600381374359131 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:09.371151 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=3, ) 	 51600640 	 1000 	 0.34378528594970703 	 1.2745327949523926 	 0.3261265754699707 	 0.26004528999328613 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:12.440960 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, ) 	 50806784 	 1000 	 25.757400274276733 	 1.507988691329956 	 13.162292718887329 	 0.2557048797607422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:41.075746 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=-1, ) 	 51598560 	 1000 	 0.3460659980773926 	 1.2743151187896729 	 0.32625699043273926 	 0.25998401641845703 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:44.088785 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=3, ) 	 51598560 	 1000 	 0.34379029273986816 	 1.2746829986572266 	 0.32616519927978516 	 0.2600226402282715 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:47.084777 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 1, 49613],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 1, 49613],"int64"), axis=2, ) 	 52391328 	 1000 	 1.5372905731201172 	 2.2219491004943848 	 0.7854688167572021 	 0.37668490409851074 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:52.304982 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, ) 	 50804736 	 1000 	 0.6398372650146484 	 1.0760045051574707 	 0.6223890781402588 	 0.21948862075805664 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:55.310914 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, ) 	 50804736 	 1000 	 0.6398053169250488 	 1.0758378505706787 	 0.6222634315490723 	 0.21944475173950195 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:09:58.323013 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 793801],"float32"), Tensor([2, 16, 1, 793801],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 793801],"float32"), Tensor([2, 16, 1, 793801],"int64"), axis=2, ) 	 838253856 	 1000 	 23.962019443511963 	 44.67211675643921 	 12.244219779968262 	 5.207099676132202 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:11:34.078785 test begin: paddle.nn.functional.softplus(Tensor([113401, 7, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([113401, 7, 64],"float32"), ) 	 50803648 	 1000 	 0.3007938861846924 	 0.3080739974975586 	 0.2918260097503662 	 0.2886786460876465 	 0.4506840705871582 	 0.4505913257598877 	 0.39953112602233887 	 0.3823544979095459 	 
2025-07-30 14:11:39.077340 test begin: paddle.nn.functional.softplus(Tensor([13, 10, 390794],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 10, 390794],"float32"), ) 	 50803220 	 1000 	 0.30092930793762207 	 0.30684542655944824 	 0.2920651435852051 	 0.28870105743408203 	 0.4508209228515625 	 0.45053720474243164 	 0.3993685245513916 	 0.3838372230529785 	 
2025-07-30 14:11:42.211538 test begin: paddle.nn.functional.softplus(Tensor([13, 1007, 3881],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 1007, 3881],"float32"), ) 	 50806171 	 1000 	 0.30087780952453613 	 0.29988956451416016 	 0.2920570373535156 	 0.2891542911529541 	 0.4507477283477783 	 0.45065951347351074 	 0.39931583404541016 	 0.38358211517333984 	 
2025-07-30 14:11:45.435872 test begin: paddle.nn.functional.softplus(Tensor([13, 61062, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 61062, 64],"float32"), ) 	 50803584 	 1000 	 0.2993762493133545 	 0.30416178703308105 	 0.29050111770629883 	 0.28913092613220215 	 0.4504096508026123 	 0.4505636692047119 	 0.3990969657897949 	 0.38345789909362793 	 
2025-07-30 14:11:48.564978 test begin: paddle.nn.functional.softplus(Tensor([14, 56701, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([14, 56701, 64],"float32"), ) 	 50804096 	 1000 	 0.29950666427612305 	 0.3025994300842285 	 0.2906479835510254 	 0.2889823913574219 	 0.4504129886627197 	 0.45063042640686035 	 0.3993237018585205 	 0.38323259353637695 	 
2025-07-30 14:11:51.726269 test begin: paddle.nn.functional.softplus(Tensor([14, 7, 518401],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([14, 7, 518401],"float32"), ) 	 50803298 	 1000 	 0.2995178699493408 	 0.29984331130981445 	 0.29055213928222656 	 0.28909850120544434 	 0.4503970146179199 	 0.45059943199157715 	 0.39911341667175293 	 0.38367176055908203 	 
2025-07-30 14:11:54.877162 test begin: paddle.nn.functional.softplus(Tensor([789, 1007, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([789, 1007, 64],"float32"), ) 	 50849472 	 1000 	 0.3013429641723633 	 0.3001422882080078 	 0.29238343238830566 	 0.28934502601623535 	 0.4511089324951172 	 0.4509274959564209 	 0.39967775344848633 	 0.38396716117858887 	 
2025-07-30 14:11:58.007362 test begin: paddle.nn.functional.softplus(Tensor([79381, 10, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([79381, 10, 64],"float32"), ) 	 50803840 	 1000 	 0.299358606338501 	 0.299898624420166 	 0.29047250747680664 	 0.28847265243530273 	 0.45041418075561523 	 0.45063185691833496 	 0.3959217071533203 	 0.38380980491638184 	 
2025-07-30 14:12:01.182567 test begin: paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 0, None, ) 	 25401609 	 1000 	 0.298276424407959 	 0.3010063171386719 	 0.28975558280944824 	 0.28719377517700195 	 0.44787001609802246 	 0.44598841667175293 	 0.3942725658416748 	 0.3779325485229492 	 
2025-07-30 14:12:03.728351 test begin: paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 5, None, ) 	 25401609 	 1000 	 0.29826998710632324 	 0.2986941337585449 	 0.2896993160247803 	 0.2874336242675781 	 0.4481205940246582 	 0.4458906650543213 	 0.39644432067871094 	 0.37627553939819336 	 
2025-07-30 14:12:06.278991 test begin: paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 0, None, ) 	 25401609 	 1000 	 0.2982323169708252 	 0.29894256591796875 	 0.2895326614379883 	 0.2874927520751953 	 0.4480750560760498 	 0.4459216594696045 	 0.3971383571624756 	 0.3792724609375 	 
2025-07-30 14:12:08.900361 test begin: paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 5, None, ) 	 25401609 	 1000 	 0.29828524589538574 	 0.29878687858581543 	 0.2896301746368408 	 0.2873561382293701 	 0.44820380210876465 	 0.44593238830566406 	 0.39720821380615234 	 0.37792444229125977 	 
2025-07-30 14:12:11.451676 test begin: paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 0, None, ) 	 25401609 	 1000 	 0.2982625961303711 	 0.2989692687988281 	 0.2887704372406006 	 0.28757476806640625 	 0.44824695587158203 	 0.44589972496032715 	 0.3972814083099365 	 0.3794684410095215 	 
2025-07-30 14:12:14.017754 test begin: paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 5, None, ) 	 25401609 	 1000 	 0.29826974868774414 	 0.29878973960876465 	 0.2896549701690674 	 0.28728818893432617 	 0.4481222629547119 	 0.4459104537963867 	 0.39705610275268555 	 0.3726520538330078 	 
2025-07-30 14:12:16.556992 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 207, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 207, 8, 32, 2],"float32"), threshold=0.01, ) 	 50872320 	 1000 	 0.295989990234375 	 0.298785924911499 	 0.2869086265563965 	 0.28656530380249023 	 0.45092153549194336 	 0.44733452796936035 	 0.39894819259643555 	 0.37779903411865234 	 
2025-07-30 14:12:19.684418 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 207, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 207, 32, 2],"float32"), threshold=0.01, ) 	 50872320 	 1000 	 0.29599499702453613 	 0.29877519607543945 	 0.2869272232055664 	 0.28682684898376465 	 0.4509425163269043 	 0.44724369049072266 	 0.3990156650543213 	 0.37601280212402344 	 
2025-07-30 14:12:22.813089 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 32, 52],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 32, 52],"float32"), threshold=0.01, ) 	 51118080 	 1000 	 0.2973916530609131 	 0.30017662048339844 	 0.28838253021240234 	 0.28823184967041016 	 0.4532637596130371 	 0.44939517974853516 	 0.40156102180480957 	 0.3802661895751953 	 
2025-07-30 14:12:26.010695 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 827, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 827, 2],"float32"), threshold=0.01, ) 	 50810880 	 1000 	 0.2956514358520508 	 0.29850339889526367 	 0.28651952743530273 	 0.28646063804626465 	 0.4507167339324951 	 0.4467904567718506 	 0.377269983291626 	 0.3776395320892334 	 
2025-07-30 14:12:29.159016 test begin: paddle.nn.functional.softshrink(Tensor([32, 388, 8, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 388, 8, 8, 32, 2],"float32"), threshold=0.01, ) 	 50855936 	 1000 	 0.29593825340270996 	 0.29866695404052734 	 0.2794320583343506 	 0.2800924777984619 	 0.45079541206359863 	 0.4471132755279541 	 0.38953638076782227 	 0.3704385757446289 	 
2025-07-30 14:12:32.301306 test begin: paddle.nn.functional.softshrink(Tensor([827, 15, 8, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([827, 15, 8, 8, 32, 2],"float32"), threshold=0.01, ) 	 50810880 	 1000 	 0.2956826686859131 	 0.29842591285705566 	 0.27908754348754883 	 0.2797985076904297 	 0.4504969120025635 	 0.4468090534210205 	 0.38882994651794434 	 0.3709862232208252 	 
2025-07-30 14:12:37.172657 test begin: paddle.nn.functional.softsign(Tensor([12404, 4096],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([12404, 4096],"float32"), ) 	 50806784 	 1000 	 0.2951633930206299 	 1.057013988494873 	 0.28597474098205566 	 0.35547924041748047 	 0.45038342475891113 	 3.2791965007781982 	 0.3984682559967041 	 0.4188978672027588 	 
2025-07-30 14:12:46.205104 test begin: paddle.nn.functional.softsign(Tensor([2822401, 3, 3],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([2822401, 3, 3],"float64"), None, ) 	 25401609 	 1000 	 0.2993476390838623 	 1.043020248413086 	 0.28386449813842773 	 0.35527634620666504 	 0.44765615463256836 	 3.270841121673584 	 0.3860282897949219 	 0.4176173210144043 	 
2025-07-30 14:12:52.368032 test begin: paddle.nn.functional.softsign(Tensor([3, 2822401, 3],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([3, 2822401, 3],"float64"), None, ) 	 25401609 	 1000 	 0.2993052005767822 	 1.0546441078186035 	 0.29114365577697754 	 0.35531091690063477 	 0.4477255344390869 	 3.269399642944336 	 0.39664649963378906 	 0.4176182746887207 	 
2025-07-30 14:12:58.515420 test begin: paddle.nn.functional.softsign(Tensor([3, 3, 2822401],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([3, 3, 2822401],"float64"), None, ) 	 25401609 	 1000 	 0.29932522773742676 	 1.0428192615509033 	 0.29117822647094727 	 0.3553292751312256 	 0.447307825088501 	 3.2693862915039062 	 0.3963909149169922 	 0.41756510734558105 	 
2025-07-30 14:13:04.658769 test begin: paddle.nn.functional.softsign(Tensor([300, 169345],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([300, 169345],"float32"), ) 	 50803500 	 1000 	 0.2952878475189209 	 1.0431444644927979 	 0.28674912452697754 	 0.35535573959350586 	 0.4502544403076172 	 3.27872633934021 	 0.3992156982421875 	 0.41875791549682617 	 
2025-07-30 14:13:11.436642 test begin: paddle.nn.functional.softsign(Tensor([32, 1587601],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 0.2951171398162842 	 1.0461840629577637 	 0.2864871025085449 	 0.35538482666015625 	 0.4503054618835449 	 3.278771162033081 	 0.3991553783416748 	 0.4187815189361572 	 
2025-07-30 14:13:18.177196 test begin: paddle.nn.functional.softsign(Tensor([396901, 128],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.295046329498291 	 1.0430760383605957 	 0.2865869998931885 	 0.35530686378479004 	 0.45006895065307617 	 3.278696060180664 	 0.39894962310791016 	 0.4187467098236084 	 
2025-07-30 14:13:24.904482 test begin: paddle.nn.functional.square_error_cost(Tensor([10161, 100, 100],"float16"), Tensor([10161, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([10161, 100, 100],"float16"), Tensor([10161, 100, 100],"float32"), ) 	 203220000 	 1000 	 1.9617252349853516 	 1.4042625427246094 	 0.6685428619384766 	 0.7165656089782715 	 2.281087875366211 	 3.1373953819274902 	 0.77693772315979 	 0.5343236923217773 	 combined
2025-07-30 14:13:40.137225 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), ) 	 25401624 	 1000 	 0.5986452102661133 	 0.598839282989502 	 0.30593299865722656 	 0.30590176582336426 	 4.131552457809448 	 1.5167758464813232 	 1.0566158294677734 	 0.22142887115478516 	 combined
2025-07-30 14:13:48.857155 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 4233601],"float64"), label=Tensor([3, 2, 1, 4233601],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 4233601],"float64"), label=Tensor([3, 2, 1, 4233601],"float64"), ) 	 50803212 	 1000 	 0.7425098419189453 	 0.7434284687042236 	 0.3794219493865967 	 0.3786449432373047 	 0.924813985824585 	 1.3522381782531738 	 0.4724855422973633 	 0.27658820152282715 	 combined
2025-07-30 14:13:54.251735 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 1, 2],"float64"), ) 	 25401624 	 1000 	 0.5964457988739014 	 0.5987606048583984 	 0.3047628402709961 	 0.3058907985687256 	 3.8288636207580566 	 1.516599178314209 	 1.3051464557647705 	 0.22142529487609863 	 combined
2025-07-30 14:14:01.932353 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), ) 	 50803224 	 1000 	 0.7425057888031006 	 0.7413079738616943 	 0.37937211990356445 	 0.3786962032318115 	 0.924860954284668 	 1.352264642715454 	 0.47263097763061523 	 0.27650904655456543 	 combined
2025-07-30 14:14:07.309768 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 4233601, 1, 2],"float64"), label=Tensor([3, 4233601, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 4233601, 1, 2],"float64"), label=Tensor([3, 4233601, 1, 2],"float64"), ) 	 50803212 	 1000 	 0.7424449920654297 	 0.7413303852081299 	 0.37935733795166016 	 0.3787522315979004 	 0.9248650074005127 	 1.3521597385406494 	 0.472550630569458 	 0.2765312194824219 	 combined
2025-07-30 14:14:12.820227 test begin: paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float16"), Tensor([5081, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float16"), Tensor([5081, 100, 100],"float32"), ) 	 101620000 	 1000 	 0.9854223728179932 	 0.706507682800293 	 0.3357882499694824 	 0.36095142364501953 	 1.14784836769104 	 1.580174207687378 	 0.3909151554107666 	 0.2691049575805664 	 combined
2025-07-30 14:14:20.071509 test begin: paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float32"), Tensor([5081, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float32"), Tensor([5081, 100, 100],"float32"), ) 	 101620000 	 1000 	 0.7451369762420654 	 0.7430353164672852 	 0.3807845115661621 	 0.37961673736572266 	 0.921276330947876 	 1.3530175685882568 	 0.4706909656524658 	 0.27668118476867676 	 combined
2025-07-30 14:14:26.343933 test begin: paddle.nn.functional.square_error_cost(Tensor([6350401, 2, 1, 2],"float64"), label=Tensor([6350401, 2, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([6350401, 2, 1, 2],"float64"), label=Tensor([6350401, 2, 1, 2],"float64"), ) 	 50803208 	 1000 	 0.7424476146697998 	 0.74131178855896 	 0.37937188148498535 	 0.37867093086242676 	 0.9247262477874756 	 1.3521740436553955 	 0.4725072383880615 	 0.27656006813049316 	 combined
2025-07-30 14:14:31.627493 test begin: paddle.nn.functional.square_error_cost(Tensor([8, 100, 63505],"float32"), Tensor([8, 100, 63505],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([8, 100, 63505],"float32"), Tensor([8, 100, 63505],"float32"), ) 	 101608000 	 1000 	 0.7450971603393555 	 0.7547440528869629 	 0.38071322441101074 	 0.37964963912963867 	 0.921079158782959 	 1.353358507156372 	 0.4706275463104248 	 0.27677226066589355 	 combined
2025-07-30 14:14:40.741353 test begin: paddle.nn.functional.square_error_cost(Tensor([8, 63505, 100],"float32"), Tensor([8, 63505, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([8, 63505, 100],"float32"), Tensor([8, 63505, 100],"float32"), ) 	 101608000 	 1000 	 0.7450346946716309 	 0.743030309677124 	 0.38072705268859863 	 0.3795921802520752 	 0.9211850166320801 	 1.3531818389892578 	 0.47066402435302734 	 0.2767293453216553 	 combined
2025-07-30 14:14:46.900530 test begin: paddle.nn.functional.tanh(Tensor([1016065, 50],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([1016065, 50],"float32"), None, ) 	 50803250 	 1000 	 0.2954390048980713 	 0.2981905937194824 	 0.28717684745788574 	 0.2877199649810791 	 0.45003437995910645 	 0.44653749465942383 	 0.39879775047302246 	 0.3799102306365967 	 
2025-07-30 14:14:50.078145 test begin: paddle.nn.functional.tanh(Tensor([147015, 346],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([147015, 346],"float32"), None, ) 	 50867190 	 1000 	 0.29613733291625977 	 0.5300414562225342 	 0.2878596782684326 	 0.2873847484588623 	 0.4508321285247803 	 0.44725894927978516 	 0.3983123302459717 	 0.35834169387817383 	 
2025-07-30 14:14:54.673405 test begin: paddle.nn.functional.tanh(Tensor([282600, 180],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([282600, 180],"float32"), None, ) 	 50868000 	 1000 	 0.29570770263671875 	 0.3046743869781494 	 0.28736114501953125 	 0.28192687034606934 	 0.45061564445495605 	 0.4472620487213135 	 0.38670802116394043 	 0.3456859588623047 	 
2025-07-30 14:14:57.806216 test begin: paddle.nn.functional.tanh(Tensor([564481, 90],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([564481, 90],"float32"), None, ) 	 50803290 	 1000 	 0.2953908443450928 	 0.29827189445495605 	 0.286632776260376 	 0.28095364570617676 	 0.4501192569732666 	 0.446697473526001 	 0.386685848236084 	 0.3569035530090332 	 
2025-07-30 14:15:01.135959 test begin: paddle.nn.functional.tanh(Tensor([93401, 544],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([93401, 544],"float32"), None, ) 	 50810144 	 1000 	 0.2954983711242676 	 0.29808664321899414 	 0.28670382499694824 	 0.2871263027191162 	 0.45011234283447266 	 0.4465198516845703 	 0.3984529972076416 	 0.358323335647583 	 
2025-07-30 14:15:04.210112 test begin: paddle.nn.functional.tanhshrink(Tensor([2822401, 3, 3],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([2822401, 3, 3],"float64"), None, ) 	 25401609 	 1000 	 0.2992868423461914 	 0.7454116344451904 	 0.29060912132263184 	 0.37972187995910645 	 0.4477651119232178 	 1.184800386428833 	 0.3967761993408203 	 0.4036896228790283 	 
2025-07-30 14:15:07.881975 test begin: paddle.nn.functional.tanhshrink(Tensor([3, 2822401, 3],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([3, 2822401, 3],"float64"), None, ) 	 25401609 	 1000 	 0.2992696762084961 	 0.7429814338684082 	 0.2910940647125244 	 0.37955737113952637 	 0.44795942306518555 	 1.184718370437622 	 0.3972775936126709 	 0.40364909172058105 	 
2025-07-30 14:15:11.653820 test begin: paddle.nn.functional.tanhshrink(Tensor([3, 3, 2822401],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([3, 3, 2822401],"float64"), None, ) 	 25401609 	 1000 	 0.2992873191833496 	 0.7430331707000732 	 0.2909719944000244 	 0.3795897960662842 	 0.44767165184020996 	 1.1847670078277588 	 0.39672398567199707 	 0.40365028381347656 	 
2025-07-30 14:15:15.372499 test begin: paddle.nn.functional.tanhshrink(Tensor([50803201],"float32"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([50803201],"float32"), None, ) 	 50803201 	 1000 	 0.29546284675598145 	 0.7433595657348633 	 0.2870516777038574 	 0.3798494338989258 	 0.4503509998321533 	 1.188997745513916 	 0.3990764617919922 	 0.40511035919189453 	 
2025-07-30 14:15:19.672579 test begin: paddle.nn.functional.tanhshrink(x=Tensor([2822401, 3, 3],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([2822401, 3, 3],"float64"), ) 	 25401609 	 1000 	 0.29927706718444824 	 0.7431867122650146 	 0.2907099723815918 	 0.3796696662902832 	 0.44784092903137207 	 1.1847562789916992 	 0.3971683979034424 	 0.403705358505249 	 
2025-07-30 14:15:23.393127 test begin: paddle.nn.functional.tanhshrink(x=Tensor([3, 2822401, 3],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([3, 2822401, 3],"float64"), ) 	 25401609 	 1000 	 0.29926395416259766 	 0.7429611682891846 	 0.29063940048217773 	 0.3795135021209717 	 0.4474153518676758 	 1.1846630573272705 	 0.3962059020996094 	 0.4035975933074951 	 
2025-07-30 14:15:27.113752 test begin: paddle.nn.functional.tanhshrink(x=Tensor([3, 3, 2822401],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([3, 3, 2822401],"float64"), ) 	 25401609 	 1000 	 0.299283504486084 	 0.7430155277252197 	 0.2907247543334961 	 0.37957334518432617 	 0.4479222297668457 	 1.1846871376037598 	 0.39682841300964355 	 0.40370941162109375 	 
2025-07-30 14:15:30.832429 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 28225, 3, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 28225, 3, 3],"float64"), 1.0, 0.0, None, ) 	 25402500 	 1000 	 0.29790210723876953 	 0.2983267307281494 	 0.2890965938568115 	 0.2796604633331299 	 0.4481215476989746 	 0.4459869861602783 	 0.39757561683654785 	 0.37775731086730957 	 
2025-07-30 14:15:33.374640 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 21169, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 21169, 3],"float64"), 1.0, 0.0, None, ) 	 25402800 	 1000 	 0.29782891273498535 	 0.30068206787109375 	 0.28904223442077637 	 0.27948760986328125 	 0.4480288028717041 	 0.4459114074707031 	 0.397413969039917 	 0.3795461654663086 	 
2025-07-30 14:15:37.059008 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 21169],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 21169],"float64"), 1.0, 0.0, None, ) 	 25402800 	 1000 	 0.2978246212005615 	 0.31334733963012695 	 0.28172755241394043 	 0.2787787914276123 	 0.44797778129577637 	 0.4460773468017578 	 0.38756275177001953 	 0.37874484062194824 	 
2025-07-30 14:15:40.100291 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 42337],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 42337],"float32"), 1.0, 0.0, None, ) 	 50804400 	 1000 	 0.2956984043121338 	 0.2980935573577881 	 0.2867887020111084 	 0.2791142463684082 	 0.45026397705078125 	 0.4466726779937744 	 0.3993535041809082 	 0.3800663948059082 	 
2025-07-30 14:15:43.228331 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 42337, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 42337, 3],"float32"), 1.0, 0.0, None, ) 	 50804400 	 1000 	 0.2956962585449219 	 0.29807424545288086 	 0.28671860694885254 	 0.27936506271362305 	 0.4502286911010742 	 0.44669127464294434 	 0.3957645893096924 	 0.37966346740722656 	 
2025-07-30 14:15:46.352960 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 56449, 3, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 56449, 3, 3],"float32"), 1.0, 0.0, None, ) 	 50804100 	 1000 	 0.2957041263580322 	 0.29801487922668457 	 0.28662109375 	 0.27919912338256836 	 0.45034098625183105 	 0.44663143157958984 	 0.39936304092407227 	 0.3802947998046875 	 
2025-07-30 14:15:49.471623 test begin: paddle.nn.functional.thresholded_relu(Tensor([1411201, 4, 3, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([1411201, 4, 3, 3],"float32"), 1.0, 0.0, None, ) 	 50803236 	 1000 	 0.2957026958465576 	 0.29802775382995605 	 0.28662109375 	 0.27934885025024414 	 0.4501814842224121 	 0.4466438293457031 	 0.3990304470062256 	 0.37964749336242676 	 
2025-07-30 14:15:52.595114 test begin: paddle.nn.functional.thresholded_relu(Tensor([705601, 4, 3, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([705601, 4, 3, 3],"float64"), 1.0, 0.0, None, ) 	 25401636 	 1000 	 0.2977895736694336 	 0.29832887649536133 	 0.2891054153442383 	 0.2794342041015625 	 0.44796228408813477 	 0.44590020179748535 	 0.3976161479949951 	 0.37879061698913574 	 
2025-07-30 14:15:55.126543 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 42337],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 42337],"float32"), ) 	 50804400 	 1000 	 0.2957494258880615 	 0.7529523372650146 	 0.28597426414489746 	 0.2759716510772705 	 0.45026588439941406 	 0.4468207359313965 	 0.39896607398986816 	 0.3521575927734375 	 
2025-07-30 14:16:01.683965 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 42337, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 42337, 3],"float32"), ) 	 50804400 	 1000 	 0.2956218719482422 	 0.29848384857177734 	 0.28620123863220215 	 0.2793455123901367 	 0.4501643180847168 	 0.4466385841369629 	 0.39893078804016113 	 0.37876033782958984 	 
2025-07-30 14:16:04.851647 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 56449, 3, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 56449, 3, 3],"float32"), ) 	 50804100 	 1000 	 0.29575681686401367 	 0.2990074157714844 	 0.2863607406616211 	 0.27904510498046875 	 0.4502131938934326 	 0.44666457176208496 	 0.3992342948913574 	 0.37995147705078125 	 
2025-07-30 14:16:08.007924 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([1411201, 4, 3, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([1411201, 4, 3, 3],"float32"), ) 	 50803236 	 1000 	 0.2957155704498291 	 0.2979702949523926 	 0.2863495349884033 	 0.27910709381103516 	 0.45021700859069824 	 0.4466841220855713 	 0.39810895919799805 	 0.3796381950378418 	 
2025-07-30 14:16:11.158687 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 	 76204815 	 1000 	 2.323622226715088 	 1.8214621543884277 	 2.765655517578125e-05 	 0.1548171043395996 	 4.068292856216431 	 2.8681299686431885 	 0.46376967430114746 	 0.18352174758911133 	 
2025-07-30 14:16:23.944727 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 	 76204815 	 1000 	 2.3035457134246826 	 1.8186452388763428 	 1.8596649169921875e-05 	 0.16866827011108398 	 4.065485715866089 	 2.86449933052063 	 0.5202906131744385 	 0.1954493522644043 	 
2025-07-30 14:16:37.426863 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 	 76204815 	 1000 	 2.335995674133301 	 1.8220863342285156 	 2.574920654296875e-05 	 0.15496611595153809 	 4.06852912902832 	 2.864452838897705 	 0.4637019634246826 	 0.19547748565673828 	 
2025-07-30 14:16:50.523685 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 	 76204815 	 1000 	 2.8009181022644043 	 2.233607530593872 	 0.000156402587890625 	 0.20727968215942383 	 4.416625261306763 	 3.255033493041992 	 0.5032451152801514 	 0.20827770233154297 	 
2025-07-30 14:17:04.992532 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 	 76204815 	 1000 	 2.750222682952881 	 2.2012813091278076 	 0.0001430511474609375 	 0.2489485740661621 	 4.38346791267395 	 3.2234909534454346 	 0.5609714984893799 	 0.21992874145507812 	 
2025-07-30 14:17:19.285742 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 	 76204815 	 1000 	 2.794625997543335 	 2.2337565422058105 	 0.00016641616821289062 	 0.20723676681518555 	 4.416325569152832 	 3.200148582458496 	 0.5032010078430176 	 0.21834564208984375 	 
2025-07-30 14:17:33.634481 test begin: paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50831360 	 1000 	 1.7486121654510498 	 2.6414220333099365 	 0.1783146858215332 	 0.24530887603759766 	 3.736738443374634 	 7.170039415359497 	 0.34737324714660645 	 7.096898317337036 	 
2025-07-30 14:17:59.295309 test begin: paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50831360 	 1000 	 1.748964548110962 	 2.6414504051208496 	 0.17831921577453613 	 0.24531102180480957 	 3.7367944717407227 	 7.16908073425293 	 0.34737300872802734 	 7.102905035018921 	 
2025-07-30 14:18:24.307330 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50805120 	 1000 	 1.8158149719238281 	 2.663789987564087 	 0.18533992767333984 	 0.22564291954040527 	 3.7780861854553223 	 7.213280916213989 	 0.35128068923950195 	 7.1395182609558105 	 
2025-07-30 14:18:49.805803 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50805120 	 1000 	 1.8157966136932373 	 2.6491475105285645 	 0.18537688255310059 	 0.22561144828796387 	 3.7779808044433594 	 7.215375900268555 	 0.35121965408325195 	 7.141053676605225 	 
2025-07-30 14:19:17.350022 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50805120 	 1000 	 2.1440422534942627 	 2.9875082969665527 	 0.21877551078796387 	 0.2542421817779541 	 3.7112441062927246 	 7.086579322814941 	 0.345017671585083 	 7.012781620025635 	 
2025-07-30 14:19:43.952269 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50805120 	 1000 	 2.142411708831787 	 2.9850568771362305 	 0.2187798023223877 	 0.2542262077331543 	 3.7111387252807617 	 7.086091756820679 	 0.3450031280517578 	 7.019990921020508 	 
2025-07-30 14:20:09.779157 test begin: paddle.nn.functional.unfold(Tensor([338, 3, 224, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([338, 3, 224, 224],"float32"), 16, 16, ) 	 50878464 	 1000 	 24.223877906799316 	 24.05680012702942 	 0.07322812080383301 	 0.0727071762084961 	 3.2775027751922607 	 2.187903642654419 	 0.009857654571533203 	 2.1052234172821045 	 
2025-07-30 14:21:07.179272 test begin: paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50810880 	 1000 	 36.89474439620972 	 30.704258680343628 	 0.008985519409179688 	 0.007501840591430664 	 80.5069408416748 	 7.16328239440918 	 0.019847631454467773 	 7.0947277545928955 	 
2025-07-30 14:23:51.135865 test begin: paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50810880 	 1000 	 36.4257447719574 	 30.70783829689026 	 0.008990287780761719 	 0.0074977874755859375 	 80.5066921710968 	 7.163247585296631 	 0.01982736587524414 	 7.09596061706543 	 
2025-07-30 14:26:34.576430 test begin: paddle.nn.functional.unfold(Tensor([64, 16, 224, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 16, 224, 224],"float32"), 16, 16, ) 	 51380224 	 1000 	 15.365207195281982 	 7.886512041091919 	 0.24538135528564453 	 0.1259160041809082 	 1.8638451099395752 	 2.1269371509552 	 0.02920222282409668 	 2.0537967681884766 	 
2025-07-30 14:27:04.141391 test begin: paddle.nn.functional.unfold(Tensor([64, 3, 1182, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 3, 1182, 224],"float32"), 16, 16, ) 	 50835456 	 1000 	 15.334173679351807 	 7.856036186218262 	 0.24483656883239746 	 0.12548589706420898 	 1.8508820533752441 	 2.4049623012542725 	 0.029000282287597656 	 1.2288765907287598 	 
2025-07-30 14:27:33.328476 test begin: paddle.nn.functional.unfold(Tensor([64, 3, 224, 1182],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 3, 224, 1182],"float32"), 16, 16, ) 	 50835456 	 1000 	 15.757951974868774 	 7.9586756229400635 	 0.2516040802001953 	 0.12704253196716309 	 1.854379415512085 	 2.408428907394409 	 0.029067039489746094 	 1.2305347919464111 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:28:05.029794 test begin: paddle.nn.functional.zeropad2d(Tensor([338, 3, 224, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([338, 3, 224, 224],"float32"), list[2,2,2,2,], ) 	 50878464 	 1000 	 0.6286582946777344 	 0.47038984298706055 	 0.5965347290039062 	 0.23904800415039062 	 0.7541036605834961 	 0.3115553855895996 	 0.3854389190673828 	 0.2348017692565918 	 combined
2025-07-30 14:28:08.893847 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"float64"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"float64"), list[2,2,2,2,], ) 	 25489408 	 1000 	 0.32390475273132324 	 0.4590432643890381 	 0.2916879653930664 	 0.2343757152557373 	 0.46593713760375977 	 0.3036510944366455 	 0.23798322677612305 	 0.22644305229187012 	 combined
2025-07-30 14:28:11.558593 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"int64"), Tensor([4],"int32"), )
W0730 14:28:12.658879 25407 backward.cc:462] While running Node (Pad3dGradNode) raises an EnforceNotMet exception
[Error] (NotFound) The kernel with key (GPU, Undefined(AnyLayout), int64) of kernel `pad3d_grad` is not registered and fail to fallback to CPU one. Selected wrong DataType `int64`. Paddle support following DataTypes: float64, complex128, float16, float32, complex64, bfloat16.
  [Hint: Expected kernel_iter != iter->second.end(), but received kernel_iter == iter->second.end().] (at ../paddle/phi/core/kernel_factory.cc:380)

[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"int64"), Tensor([4],"int32"), ) 	 25489412 	 1000 	 0.374347448348999 	 0.5102169513702393 	 0.00032806396484375 	 0.00043392181396484375 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:28:13.286145 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 254, 224, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 254, 224, 224],"float32"), list[2,2,2,2,], ) 	 50978816 	 1000 	 0.6302361488342285 	 0.46898794174194336 	 0.5981466770172119 	 0.23952436447143555 	 0.7512438297271729 	 0.31212902069091797 	 0.3838648796081543 	 0.23499488830566406 	 combined
2025-07-30 14:28:17.152126 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 18901, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 18901, 224],"float32"), list[2,2,2,2,], ) 	 50805888 	 1000 	 0.6179549694061279 	 0.46493029594421387 	 0.5857808589935303 	 0.23745036125183105 	 0.7466335296630859 	 0.3108527660369873 	 0.38163280487060547 	 0.23428797721862793 	 combined
2025-07-30 14:28:21.005588 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 18901],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 18901],"float32"), list[2,2,2,2,], ) 	 50805888 	 1000 	 0.6161012649536133 	 0.4444706439971924 	 0.5839011669158936 	 0.22697186470031738 	 0.746941328048706 	 0.3083667755126953 	 0.38163185119628906 	 0.23111581802368164 	 combined
2025-07-30 14:28:24.793806 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 9451],"float64"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 9451],"float64"), list[2,2,2,2,], ) 	 25404288 	 1000 	 0.3193545341491699 	 0.44014978408813477 	 0.28452205657958984 	 0.22480559349060059 	 0.45745038986206055 	 0.29988598823547363 	 0.2337331771850586 	 0.20781636238098145 	 combined
2025-07-30 14:28:27.432187 test begin: paddle.nonzero(Tensor([510, 128, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 128, 28, 28],"float32"), ) 	 51179520 	 1000 	 7.404338598251343 	 2.3252437114715576 	 0.0054931640625 	 0.002129077911376953 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:39.326061 test begin: paddle.nonzero(Tensor([510, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 80, 28, 45],"float32"), ) 	 51408000 	 1000 	 7.4649248123168945 	 2.3350887298583984 	 0.005476713180541992 	 0.002228975296020508 	 None 	 None 	 None 	 None 	 
2025-07-30 14:28:50.060544 test begin: paddle.nonzero(Tensor([510, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 80, 45, 28],"float32"), ) 	 51408000 	 1000 	 7.493584394454956 	 2.337944746017456 	 0.0055370330810546875 	 0.0021224021911621094 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:00.783872 test begin: paddle.nonzero(Tensor([511, 127, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 127, 28, 28],"float32"), ) 	 50879248 	 1000 	 7.392826318740845 	 2.3304221630096436 	 0.005419254302978516 	 0.0021257400512695312 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:11.481017 test begin: paddle.nonzero(Tensor([511, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 80, 28, 45],"float32"), ) 	 51508800 	 1000 	 7.479384899139404 	 2.3432211875915527 	 0.005450725555419922 	 0.002142190933227539 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:22.178226 test begin: paddle.nonzero(Tensor([511, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 80, 45, 28],"float32"), ) 	 51508800 	 1000 	 7.47990345954895 	 2.345649242401123 	 0.005469322204589844 	 0.0021462440490722656 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:33.015378 test begin: paddle.nonzero(Tensor([512, 127, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 127, 28, 28],"float32"), ) 	 50978816 	 1000 	 7.3535754680633545 	 2.3151988983154297 	 0.005394697189331055 	 0.0021228790283203125 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:43.721607 test begin: paddle.nonzero(Tensor([512, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 80, 28, 45],"float32"), ) 	 51609600 	 1000 	 7.4763569831848145 	 2.3494203090667725 	 0.00544285774230957 	 0.002142190933227539 	 None 	 None 	 None 	 None 	 
2025-07-30 14:29:54.450319 test begin: paddle.nonzero(Tensor([512, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 80, 45, 28],"float32"), ) 	 51609600 	 1000 	 7.444228410720825 	 2.345003843307495 	 0.005480766296386719 	 0.0021390914916992188 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:05.318257 test begin: paddle.nonzero(Tensor([811, 80, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([811, 80, 28, 28],"float32"), ) 	 50865920 	 1000 	 7.348864316940308 	 2.313927173614502 	 0.005402803421020508 	 0.0021009445190429688 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:15.833330 test begin: paddle.not_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), ) 	 38103936 	 1000 	 0.5506985187530518 	 0.5148043632507324 	 0.5408060550689697 	 0.5027987957000732 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:17.524349 test begin: paddle.not_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), ) 	 38102688 	 1000 	 0.5604918003082275 	 0.5147559642791748 	 0.5508592128753662 	 0.5029175281524658 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:19.211485 test begin: paddle.not_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), ) 	 31753280 	 1000 	 0.2130112648010254 	 0.21928143501281738 	 0.19823741912841797 	 0.20799970626831055 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:20.167220 test begin: paddle.not_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), ) 	 25403456 	 1000 	 0.5627920627593994 	 0.47147297859191895 	 0.5530476570129395 	 0.4594535827636719 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:21.622884 test begin: paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), ) 	 25405120 	 1000 	 1.0410034656524658 	 0.9477858543395996 	 1.0312600135803223 	 0.9358377456665039 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:24.044612 test begin: paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), ) 	 228616128 	 1000 	 1.7968509197235107 	 1.5707499980926514 	 1.7796437740325928 	 1.552626371383667 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:32.330129 test begin: paddle.not_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), ) 	 76205064 	 1000 	 1.116736888885498 	 1.0882799625396729 	 1.1069438457489014 	 1.0764491558074951 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:37.228716 test begin: paddle.not_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), ) 	 76205376 	 1000 	 1.1274328231811523 	 1.0316267013549805 	 1.117781162261963 	 1.0109248161315918 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:40.890917 test begin: paddle.not_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), ) 	 76205184 	 1000 	 1.0966784954071045 	 1.0234930515289307 	 1.0866119861602783 	 1.0116851329803467 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:44.257265 test begin: paddle.not_equal(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 0.31055140495300293 	 0.3131735324859619 	 0.3014955520629883 	 0.30292248725891113 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:45.684895 test begin: paddle.not_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), ) 	 38102784 	 1000 	 0.5508108139038086 	 0.5148024559020996 	 0.5410394668579102 	 0.5027632713317871 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:47.359443 test begin: paddle.numel(Tensor([508032010],"float32"), )
[Prof] paddle.numel 	 paddle.numel(Tensor([508032010],"float32"), ) 	 508032010 	 1000 	 0.008657693862915039 	 0.027734756469726562 	 1.9788742065429688e-05 	 4.673004150390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:55.487585 test begin: paddle.ones_like(Tensor([144, 392, 901],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([144, 392, 901],"float32"), ) 	 50859648 	 1000 	 0.13397645950317383 	 0.13423991203308105 	 0.12379741668701172 	 0.12269210815429688 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:56.564397 test begin: paddle.ones_like(Tensor([144, 901, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([144, 901, 392],"float32"), ) 	 50859648 	 1000 	 0.1339731216430664 	 0.13422584533691406 	 0.12380027770996094 	 0.12266826629638672 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:57.651594 test begin: paddle.ones_like(Tensor([160, 392, 811],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([160, 392, 811],"float32"), ) 	 50865920 	 1000 	 0.134049654006958 	 0.13424944877624512 	 0.12388443946838379 	 0.12246870994567871 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:58.736477 test begin: paddle.ones_like(Tensor([160, 811, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([160, 811, 392],"float32"), ) 	 50865920 	 1000 	 0.13401556015014648 	 0.13425588607788086 	 0.12389850616455078 	 0.1225886344909668 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:59.842688 test begin: paddle.ones_like(Tensor([176, 392, 737],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([176, 392, 737],"float32"), ) 	 50847104 	 1000 	 0.13388919830322266 	 0.1343216896057129 	 0.12377762794494629 	 0.12294673919677734 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:00.917019 test begin: paddle.ones_like(Tensor([176, 737, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([176, 737, 392],"float32"), ) 	 50847104 	 1000 	 0.133894681930542 	 0.13583946228027344 	 0.12368464469909668 	 0.122955322265625 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:02.024846 test begin: paddle.ones_like(Tensor([331, 392, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([331, 392, 392],"float32"), ) 	 50862784 	 1000 	 0.13396215438842773 	 0.1343822479248047 	 0.12382388114929199 	 0.12267589569091797 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:03.104336 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([2],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([2],"float32"), ) 	 50803203 	 1000 	 5.271452188491821 	 1.624399185180664 	 0.1099557876586914 	 0.49641990661621094 	 3.713759183883667 	 2.615128755569458 	 1.2630927562713623 	 0.5338656902313232 	 
2025-07-30 14:31:20.121101 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([32],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([32],"float32"), ) 	 50803233 	 1000 	 5.386142253875732 	 5.544272422790527 	 0.11229658126831055 	 1.4162960052490234 	 None 	 None 	 None 	 None 	 
2025-07-30 14:32:21.831722 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([4],"float32"), )
W0730 14:32:22.805197 26958 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([4],"float32"), ) 	 50803205 	 1000 	 5.281538963317871 	 0.9541606903076172 	 0.11013627052307129 	 0.9293677806854248 	 4.341918468475342 	 5.0621256828308105 	 1.4770867824554443 	 1.0331737995147705 	 
2025-07-30 14:32:47.743083 test begin: paddle.pdist(Tensor([10, 5080321],"float32"), 0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([10, 5080321],"float32"), 0, ) 	 50803210 	 1000 	 5.930140972137451 	 9.015817403793335 	 4.8160552978515625e-05 	 9.004452228546143 	 5.631487131118774 	 0.13423800468444824 	 0.005478620529174805 	 0.050489187240600586 	 
2025-07-30 14:33:09.482010 test begin: paddle.pdist(Tensor([10, 5080321],"float32"), 1.0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([10, 5080321],"float32"), 1.0, ) 	 50803210 	 1000 	 5.937642574310303 	 8.370944499969482 	 5.0067901611328125e-05 	 8.359636068344116 	 22.804768085479736 	 13.578441143035889 	 0.02267742156982422 	 6.940465450286865 	 
2025-07-30 14:34:02.528992 test begin: paddle.pdist(Tensor([50, 508033],"float64"), 2.0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([50, 508033],"float64"), 2.0, ) 	 25401650 	 1000 	 22.963248014450073 	 2.1458637714385986 	 4.553794860839844e-05 	 2.1346609592437744 	 87.90899753570557 	 39.32105016708374 	 0.0877847671508789 	 4.4491448402404785 	 
2025-07-30 14:36:38.023260 test begin: paddle.polar(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), ) 	 101606528 	 1000 	 2.083984375 	 2.1714391708374023 	 0.4248511791229248 	 0.42411112785339355 	 4.615885972976685 	 5.03564977645874 	 0.6739027500152588 	 0.46765732765197754 	 combined
2025-07-30 14:36:57.291593 test begin: paddle.polar(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), ) 	 101613568 	 1000 	 2.0830345153808594 	 2.073902130126953 	 0.4249913692474365 	 0.42404699325561523 	 4.614155054092407 	 5.0362184047698975 	 0.6736855506896973 	 0.4677255153656006 	 combined
2025-07-30 14:37:14.168532 test begin: paddle.polar(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 51380224 	 1000 	 1.793591022491455 	 1.8028841018676758 	 0.36673617362976074 	 0.36869168281555176 	 3.498764753341675 	 4.650345802307129 	 0.3968236446380615 	 0.3654205799102783 	 combined
2025-07-30 14:37:27.935705 test begin: paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), ) 	 51380224 	 1000 	 1.2097971439361572 	 1.2135062217712402 	 0.24763870239257812 	 0.24843239784240723 	 2.6076488494873047 	 2.894496202468872 	 0.29531383514404297 	 0.2274458408355713 	 combined
2025-07-30 14:37:38.499225 test begin: paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 101711872 	 1000 	 2.095594882965088 	 2.0756871700286865 	 0.42525529861450195 	 0.4244542121887207 	 4.618883848190308 	 5.041010618209839 	 0.6741950511932373 	 0.46798229217529297 	 combined
2025-07-30 14:37:57.349688 test begin: paddle.polygamma(Tensor([10, 20, 254017],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([10, 20, 254017],"float32"), 1, ) 	 50803400 	 1000 	 5.79292106628418 	 0.6267647743225098 	 5.55781626701355 	 0.6154391765594482 	 9.067747592926025 	 10.252779006958008 	 9.014995813369751 	 5.238726854324341 	 
2025-07-30 14:38:26.662045 test begin: paddle.polygamma(Tensor([10, 5080321, 1],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([10, 5080321, 1],"float32"), 1, ) 	 50803210 	 1000 	 5.5757715702056885 	 0.6418008804321289 	 5.566391944885254 	 0.6157629489898682 	 9.068847417831421 	 10.259718418121338 	 9.016255855560303 	 5.242094039916992 	 
2025-07-30 14:38:53.967329 test begin: paddle.polygamma(Tensor([2, 12700801],"float64"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 12700801],"float64"), 1, ) 	 25401602 	 1000 	 9.251650094985962 	 0.6403565406799316 	 9.241975784301758 	 0.6296548843383789 	 11.424007892608643 	 21.49644184112549 	 11.370784044265747 	 10.983973979949951 	 
2025-07-30 14:39:38.595067 test begin: paddle.polygamma(Tensor([2, 2, 6350401],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 2, 6350401],"float64"), 2, ) 	 25401604 	 1000 	 12.358757257461548 	 21.051406860351562 	 11.346324920654297 	 21.03448462486267 	 9.117355346679688 	 9.241430044174194 	 9.0557541847229 	 4.720409870147705 	 
2025-07-30 14:40:33.079520 test begin: paddle.polygamma(Tensor([2, 2116801, 6],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 2116801, 6],"float64"), 2, ) 	 25401612 	 1000 	 11.364744901657104 	 21.045863151550293 	 11.355522632598877 	 21.03518843650818 	 9.115788221359253 	 9.235868692398071 	 9.061098575592041 	 4.7207958698272705 	 
2025-07-30 14:41:25.777879 test begin: paddle.polygamma(Tensor([2116801, 2, 6],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2116801, 2, 6],"float64"), 2, ) 	 25401612 	 1000 	 11.362473964691162 	 21.082600593566895 	 11.353138446807861 	 21.06567931175232 	 9.125718593597412 	 9.241584777832031 	 9.07306456565857 	 4.72388219833374 	 
2025-07-30 14:42:18.793722 test begin: paddle.polygamma(Tensor([2540161, 20, 1],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2540161, 20, 1],"float32"), 1, ) 	 50803220 	 1000 	 5.575841903686523 	 1.0754501819610596 	 5.566461563110352 	 0.609123945236206 	 9.075950860977173 	 10.249327898025513 	 9.02314043045044 	 5.238363742828369 	 
2025-07-30 14:42:49.347404 test begin: paddle.polygamma(Tensor([4233601, 6],"float64"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([4233601, 6],"float64"), 1, ) 	 25401606 	 1000 	 9.24694299697876 	 0.6396331787109375 	 9.237609624862671 	 0.6289691925048828 	 11.418411016464233 	 21.478281497955322 	 11.361223936080933 	 10.974425077438354 	 
2025-07-30 14:43:34.224303 test begin: paddle.positive(Tensor([100, 5080321],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.0026404857635498047 	 0.00021648406982421875 	 8.106231689453125e-06 	 1.5020370483398438e-05 	 0.029602527618408203 	 0.046653032302856445 	 2.1696090698242188e-05 	 5.8650970458984375e-05 	 combined
2025-07-30 14:43:52.621697 test begin: paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), ) 	 1016064600 	 1000 	 0.0018732547760009766 	 0.00020122528076171875 	 1.0967254638671875e-05 	 1.52587890625e-05 	 0.030099868774414062 	 0.04723930358886719 	 3.314018249511719e-05 	 3.6716461181640625e-05 	 combined
2025-07-30 14:44:30.669334 test begin: paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), ) 	 508032400 	 1000 	 0.0018537044525146484 	 0.00021028518676757812 	 8.344650268554688e-06 	 1.5735626220703125e-05 	 0.029322385787963867 	 0.05246376991271973 	 2.193450927734375e-05 	 6.031990051269531e-05 	 combined
2025-07-30 14:44:49.901615 test begin: paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), ) 	 1016064400 	 1000 	 0.0018248558044433594 	 0.000209808349609375 	 1.2636184692382812e-05 	 1.6450881958007812e-05 	 0.029299259185791016 	 0.04750943183898926 	 1.9550323486328125e-05 	 4.172325134277344e-05 	 combined
2025-07-30 14:45:27.909589 test begin: paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), ) 	 508032300 	 1000 	 0.0018868446350097656 	 0.00020122528076171875 	 7.867813110351562e-06 	 1.5020370483398438e-05 	 0.029436111450195312 	 0.048462629318237305 	 1.7642974853515625e-05 	 5.841255187988281e-05 	 combined
2025-07-30 14:45:44.362887 test begin: paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), ) 	 1016064300 	 1000 	 0.001874685287475586 	 0.00020313262939453125 	 1.0013580322265625e-05 	 1.5735626220703125e-05 	 0.03008866310119629 	 0.04885578155517578 	 3.337860107421875e-05 	 4.38690185546875e-05 	 combined
2025-07-30 14:46:22.085210 test begin: paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), ) 	 508032240 	 1000 	 0.0018415451049804688 	 0.00019812583923339844 	 8.821487426757812e-06 	 1.4781951904296875e-05 	 0.029673337936401367 	 0.04828810691833496 	 2.5272369384765625e-05 	 6.890296936035156e-05 	 combined
2025-07-30 14:46:40.198404 test begin: paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), ) 	 1016064240 	 1000 	 0.001844167709350586 	 0.00020074844360351562 	 1.2159347534179688e-05 	 1.5497207641601562e-05 	 0.029397010803222656 	 0.04802274703979492 	 1.7642974853515625e-05 	 5.602836608886719e-05 	 combined
2025-07-30 14:47:18.342720 test begin: paddle.positive(Tensor([496130, 1024],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([496130, 1024],"float32"), ) 	 508037120 	 1000 	 0.0018534660339355469 	 0.00019788742065429688 	 7.152557373046875e-06 	 1.4543533325195312e-05 	 0.02947235107421875 	 0.05277562141418457 	 2.4318695068359375e-05 	 4.601478576660156e-05 	 combined
2025-07-30 14:47:34.956360 test begin: paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), ) 	 508032600 	 1000 	 0.001829385757446289 	 0.00020837783813476562 	 1.049041748046875e-05 	 1.5735626220703125e-05 	 0.03016352653503418 	 0.05245256423950195 	 2.574920654296875e-05 	 4.649162292480469e-05 	 combined
2025-07-30 14:47:51.569456 test begin: paddle.pow(Tensor([1024, 1024, 25],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 1024, 25],"float64"), 2, ) 	 26214400 	 1000 	 0.590350866317749 	 0.3093583583831787 	 0.5809073448181152 	 0.2952721118927002 	 0.6227099895477295 	 1.0845327377319336 	 0.5674927234649658 	 0.3694736957550049 	 
2025-07-30 14:47:55.391018 test begin: paddle.pow(Tensor([1024, 1024, 49],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 1024, 49],"float32"), 2, ) 	 51380224 	 1000 	 0.3724372386932373 	 0.3041069507598877 	 0.36290597915649414 	 0.2885928153991699 	 0.45760178565979004 	 1.0640182495117188 	 0.4017159938812256 	 0.3625214099884033 	 
2025-07-30 14:47:59.295516 test begin: paddle.pow(Tensor([1024, 3101, 8],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 3101, 8],"float64"), 2, ) 	 25403392 	 1000 	 0.572005033493042 	 0.3021974563598633 	 0.5627584457397461 	 0.28427553176879883 	 0.6035394668579102 	 1.051227331161499 	 0.5500800609588623 	 0.3581392765045166 	 
2025-07-30 14:48:04.698463 test begin: paddle.pow(Tensor([1024, 6202, 8],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 6202, 8],"float32"), 2, ) 	 50806784 	 1000 	 0.368457555770874 	 0.29792165756225586 	 0.3515613079071045 	 0.27858972549438477 	 0.4525778293609619 	 1.0529184341430664 	 0.3819406032562256 	 0.35866522789001465 	 
2025-07-30 14:48:08.615607 test begin: paddle.pow(Tensor([22, 81, 94, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([22, 81, 94, 311],"float32"), 2.0, ) 	 52094988 	 1000 	 0.37802577018737793 	 0.30523085594177246 	 0.36144399642944336 	 0.29173851013183594 	 0.46350646018981934 	 1.0817327499389648 	 0.39820218086242676 	 0.27657437324523926 	 
2025-07-30 14:48:12.664978 test begin: paddle.pow(Tensor([3101, 1024, 8],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([3101, 1024, 8],"float64"), 2, ) 	 25403392 	 1000 	 0.5719418525695801 	 0.3007335662841797 	 0.5626592636108398 	 0.28549838066101074 	 0.603539228439331 	 1.0512635707855225 	 0.5494377613067627 	 0.3581686019897461 	 
2025-07-30 14:48:16.273524 test begin: paddle.pow(Tensor([4, 435, 94, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 435, 94, 311],"float32"), 2.0, ) 	 50867160 	 1000 	 0.36879444122314453 	 0.3032186031341553 	 0.35918688774108887 	 0.2850954532623291 	 0.45275139808654785 	 1.0566644668579102 	 0.39725542068481445 	 0.2702054977416992 	 
2025-07-30 14:48:20.160334 test begin: paddle.pow(Tensor([4, 81, 505, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 81, 505, 311],"float32"), 2.0, ) 	 50885820 	 1000 	 0.36936140060424805 	 0.29834580421447754 	 0.3521609306335449 	 0.2782876491546631 	 0.45308995246887207 	 1.0567996501922607 	 0.38636064529418945 	 0.2702000141143799 	 
2025-07-30 14:48:24.084174 test begin: paddle.pow(Tensor([4, 81, 94, 1669],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 81, 94, 1669],"float32"), 2.0, ) 	 50831064 	 1000 	 0.3687264919281006 	 0.29812073707580566 	 0.35913872718811035 	 0.28412652015686035 	 0.4526660442352295 	 1.0563409328460693 	 0.39815449714660645 	 0.2700338363647461 	 
2025-07-30 14:48:28.020684 test begin: paddle.pow(Tensor([6202, 1024, 8],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([6202, 1024, 8],"float32"), 2, ) 	 50806784 	 1000 	 0.3684072494506836 	 0.29784131050109863 	 0.3589460849761963 	 0.2854151725769043 	 0.45249485969543457 	 1.0525999069213867 	 0.3978118896484375 	 0.35863757133483887 	 
2025-07-30 14:48:31.950018 test begin: paddle.prod(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
Warning: The core code of paddle.prod is too complex.
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.31481480598449707 	 0.03554964065551758 	 0.0002148151397705078 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10]) and output[0] has a shape of torch.Size([1, 10, 1, 1]).
2025-07-30 14:48:33.729195 test begin: paddle.prod(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.32535886764526367 	 0.058675527572631836 	 0.00021982192993164062 	 8.916854858398438e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9]) and output[0] has a shape of torch.Size([1, 1, 9, 1]).
2025-07-30 14:48:38.951304 test begin: paddle.prod(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402412 	 1000 	 4.882403135299683 	 0.023823976516723633 	 0.004828691482543945 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10, 9]) and output[0] has a shape of torch.Size([10, 1, 1, 9]).
2025-07-30 14:48:45.274502 test begin: paddle.prod(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.24734115600585938 	 0.0628213882446289 	 0.0001418590545654297 	 7.009506225585938e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([31361]) and output[0] has a shape of torch.Size([1, 31361, 1, 1]).
2025-07-30 14:48:46.961831 test begin: paddle.prod(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.20386123657226562 	 0.036663055419921875 	 0.0001590251922607422 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10, 5]) and output[0] has a shape of torch.Size([10, 5, 1, 1]).
2025-07-30 14:48:48.580967 test begin: paddle.prod(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.19869613647460938 	 0.023740530014038086 	 0.00016355514526367188 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10, 5]) and output[0] has a shape of torch.Size([10, 5, 1, 1]).
2025-07-30 14:48:50.201603 test begin: paddle.prod(Tensor([16, 3175201],"float32"), -1, )
[Prof] paddle.prod 	 paddle.prod(Tensor([16, 3175201],"float32"), -1, ) 	 50803216 	 1000 	 0.1780555248260498 	 0.1525893211364746 	 0.09097099304199219 	 0.07794404029846191 	 0.7915945053100586 	 1.5810308456420898 	 0.7349491119384766 	 0.000637054443359375 	 
2025-07-30 14:48:53.775323 test begin: paddle.prod(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.3136599063873291 	 0.03513193130493164 	 0.0002148151397705078 	 3.2901763916015625e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10]) and output[0] has a shape of torch.Size([1, 10, 1, 1]).
2025-07-30 14:48:55.534300 test begin: paddle.prod(Tensor([49613, 1024],"float32"), -1, )
[Prof] paddle.prod 	 paddle.prod(Tensor([49613, 1024],"float32"), -1, ) 	 50803712 	 1000 	 0.14635133743286133 	 0.14737582206726074 	 0.12935900688171387 	 0.1336832046508789 	 0.7915961742401123 	 1.5951013565063477 	 0.7357923984527588 	 0.0006420612335205078 	 
2025-07-30 14:48:59.030211 test begin: paddle.prod(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402007 	 1000 	 0.5041277408599854 	 0.02386617660522461 	 0.0004699230194091797 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([5, 9]) and output[0] has a shape of torch.Size([1, 5, 1, 9]).
2025-07-30 14:49:00.945837 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 25402750 	 1000 	 38.92234206199646 	 52.3326575756073 	 0.038329362869262695 	 17.841020345687866 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:51:31.924899 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([2032129, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([2032129, 5, 5],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13048863410949707 	 0.026777982711791992 	 1.33514404296875e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:51:32.184609 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 2032129, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 2032129, 5],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.12931394577026367 	 0.026516437530517578 	 1.7642974853515625e-05 	 4.172325134277344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:51:32.439860 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 2032129],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 2032129],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.12913155555725098 	 0.02647995948791504 	 1.0967254638671875e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:51:32.689550 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 2032129, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 2032129, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 49.76826524734497 	 45.78104376792908 	 0.04889321327209473 	 15.61237096786499 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:55:06.166819 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([2032129, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([2032129, 5, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13097405433654785 	 0.026546001434326172 	 2.193450927734375e-05 	 4.863739013671875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:55:06.418864 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 2032129, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 2032129, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.1361558437347412 	 0.027090072631835938 	 2.2411346435546875e-05 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:55:06.673937 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 2032129],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 2032129],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.12919306755065918 	 0.028061866760253906 	 2.9802322387695312e-05 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:55:06.925437 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 24.440977811813354 	 25.290202617645264 	 0.02258443832397461 	 8.625122547149658 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:56:56.059219 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([1016065, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([1016065, 5, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.13762617111206055 	 0.02699732780456543 	 2.002716064453125e-05 	 4.363059997558594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:56:56.322317 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 1016065, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 1016065, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.14685726165771484 	 0.026849746704101562 	 2.0742416381835938e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:56:56.587582 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 1016065],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 1016065],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.12952971458435059 	 0.02664494514465332 	 2.0742416381835938e-05 	 3.266334533691406e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:56:56.837275 test begin: paddle.put_along_axis(Tensor([10, 10, 254017],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 254017],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.38504981994628906 	 0.6308066844940186 	 0.0003108978271484375 	 0.1286306381225586 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:56:59.110756 test begin: paddle.put_along_axis(Tensor([10, 10, 508033],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 508033],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3742539882659912 	 0.6304752826690674 	 0.00030231475830078125 	 0.12859487533569336 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:57:02.237768 test begin: paddle.put_along_axis(Tensor([10, 10, 508033],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 508033],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37244367599487305 	 0.6307754516601562 	 0.000308990478515625 	 0.12868475914001465 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:57:04.853416 test begin: paddle.put_along_axis(Tensor([10, 254017, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 254017, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.39031243324279785 	 0.6300365924835205 	 0.00030541419982910156 	 0.12852740287780762 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:57:07.238463 test begin: paddle.put_along_axis(Tensor([10, 508033, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 508033, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3736608028411865 	 0.6299803256988525 	 0.00030303001403808594 	 0.12847208976745605 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:57:10.531204 test begin: paddle.put_along_axis(Tensor([10, 508033, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 508033, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37151312828063965 	 0.6300013065338135 	 0.00029730796813964844 	 0.1284804344177246 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:57:13.386987 test begin: paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([254017, 5, 5],"int64"), Tensor([254017, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([254017, 5, 5],"int64"), Tensor([254017, 5, 5],"int64"), 1, "mul", True, False, ) 	 38102550 	 1000 	 0.8306293487548828 	 1.0292017459869385 	 0.0006237030029296875 	 0.21032238006591797 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:57:30.162945 test begin: paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.379044771194458 	 0.6306207180023193 	 0.000308990478515625 	 0.12865161895751953 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:57:32.379020 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([254017, 5, 5],"int64"), Tensor([508033, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([254017, 5, 5],"int64"), Tensor([508033, 5, 5],"float32"), 1, "mul", True, False, ) 	 69854550 	 1000 	 0.7752971649169922 	 0.9550838470458984 	 0.0005724430084228516 	 0.19518589973449707 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:57:49.323887 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37429094314575195 	 0.6305968761444092 	 0.0003044605255126953 	 0.128678560256958 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:57:52.407204 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3718836307525635 	 0.6381704807281494 	 0.0003037452697753906 	 0.1286165714263916 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:57:56.725623 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([508033, 5, 5],"int32"), Tensor([508033, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([508033, 5, 5],"int32"), Tensor([508033, 5, 5],"int32"), 1, "mul", True, False, ) 	 76204950 	 1000 	 1.0496749877929688 	 1.2603652477264404 	 0.0008351802825927734 	 0.25771450996398926 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:58:26.541584 test begin: paddle.rad2deg(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29559993743896484 	 0.2978549003601074 	 0.2799947261810303 	 0.2835726737976074 	 0.2956080436706543 	 0.2978229522705078 	 0.24355316162109375 	 0.22901201248168945 	 
2025-07-30 14:58:29.380364 test begin: paddle.rad2deg(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2958638668060303 	 0.29784631729125977 	 0.2801520824432373 	 0.28363990783691406 	 0.2958977222442627 	 0.29780149459838867 	 0.24410271644592285 	 0.22790837287902832 	 
2025-07-30 14:58:32.207605 test begin: paddle.rad2deg(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29575419425964355 	 0.32599592208862305 	 0.28014564514160156 	 0.28368115425109863 	 0.29575586318969727 	 0.29779863357543945 	 0.24291682243347168 	 0.22800207138061523 	 
2025-07-30 14:58:35.089220 test begin: paddle.rad2deg(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.29801011085510254 	 0.3042104244232178 	 0.28210926055908203 	 0.28188347816467285 	 0.29810547828674316 	 0.29840874671936035 	 0.2447803020477295 	 0.2301008701324463 	 
2025-07-30 14:58:40.242524 test begin: paddle.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.29784369468688965 	 0.29856300354003906 	 0.2822537422180176 	 0.2843930721282959 	 0.2981226444244385 	 0.2984633445739746 	 0.24613618850708008 	 0.21870017051696777 	 
2025-07-30 14:58:42.474303 test begin: paddle.rad2deg(x=Tensor([4, 1587601, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 1587601, 4],"float64"), ) 	 25401616 	 1000 	 0.2980184555053711 	 0.3045680522918701 	 0.2821812629699707 	 0.28444814682006836 	 0.2981281280517578 	 0.29841017723083496 	 0.24653983116149902 	 0.20746850967407227 	 
2025-07-30 14:58:44.742817 test begin: paddle.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.297839879989624 	 0.29846811294555664 	 0.2821931838989258 	 0.2843663692474365 	 0.2981259822845459 	 0.29840540885925293 	 0.24670863151550293 	 0.2296159267425537 	 
2025-07-30 14:58:46.985812 test begin: paddle.rad2deg(x=Tensor([4, 4, 1587601],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 1587601],"float64"), ) 	 25401616 	 1000 	 0.29803013801574707 	 0.2984282970428467 	 0.28213071823120117 	 0.2844851016998291 	 0.2980971336364746 	 0.29845094680786133 	 0.24498605728149414 	 0.22440481185913086 	 
2025-07-30 14:58:49.288986 test begin: paddle.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.2978823184967041 	 0.29853248596191406 	 0.27591586112976074 	 0.28432655334472656 	 0.29811787605285645 	 0.298295259475708 	 0.24667096138000488 	 0.22728943824768066 	 
2025-07-30 14:58:51.553852 test begin: paddle.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.2978248596191406 	 0.2984137535095215 	 0.2822301387786865 	 0.2839014530181885 	 0.2981293201446533 	 0.298309326171875 	 0.24684619903564453 	 0.22972726821899414 	 
2025-07-30 13:31:57.613327 test begin: paddle.Tensor.__abs__(Tensor([10, 5080321],"float32"), )
W0730 13:31:58.558789  2564 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2961702346801758 	 0.2992556095123291 	 0.2870752811431885 	 0.2848520278930664 	 0.45066356658935547 	 0.7428994178771973 	 0.3894221782684326 	 0.37952494621276855 	 
2025-07-30 13:32:01.598231 test begin: paddle.Tensor.__abs__(Tensor([49613, 1024],"float32"), )
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([49613, 1024],"float32"), ) 	 50803712 	 1000 	 0.2969019412994385 	 0.29959797859191895 	 0.2874879837036133 	 0.28534388542175293 	 0.45047545433044434 	 0.7427878379821777 	 0.3941030502319336 	 0.37951135635375977 	 
2025-07-30 13:32:05.047067 test begin: paddle.Tensor.__abs__(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.29614925384521484 	 0.2977938652038574 	 0.28725767135620117 	 0.2854287624359131 	 0.450361967086792 	 0.7427570819854736 	 0.39379191398620605 	 0.37950778007507324 	 
2025-07-30 13:32:08.464511 test begin: paddle.Tensor.__add__(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 1, 388, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 1, 388, 4096],"float32"), ) 	 52445184 	 1000 	 0.33688807487487793 	 0.3240945339202881 	 0.32644152641296387 	 0.3046088218688965 	 0.47670817375183105 	 0.1538853645324707 	 0.24349308013916016 	 0.07723855972290039 	 
2025-07-30 13:32:11.689868 test begin: paddle.Tensor.__add__(Tensor([1, 32, 4096, 388],"float32"), Tensor([1, 1, 4096, 388],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 4096, 388],"float32"), Tensor([1, 1, 4096, 388],"float32"), ) 	 52445184 	 1000 	 0.33602333068847656 	 0.32511019706726074 	 0.32573604583740234 	 0.30496859550476074 	 0.4765448570251465 	 0.15369653701782227 	 0.243422269821167 	 0.08080315589904785 	 
2025-07-30 13:32:14.800613 test begin: paddle.Tensor.__add__(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), ) 	 553648128 	 1000 	 4.694238662719727 	 4.625605344772339 	 4.682992458343506 	 4.6120030879974365 	 4.966116428375244 	 1.5601446628570557 	 1.690148115158081 	 1.470198392868042 	 
2025-07-30 13:32:53.453479 test begin: paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), ) 	 83886080 	 1000 	 0.5932881832122803 	 0.583564043045044 	 0.5828878879547119 	 0.5645596981048584 	 0.6635956764221191 	 0.2440643310546875 	 0.33906030654907227 	 0.16689848899841309 	 
2025-07-30 13:32:59.400175 test begin: paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 4096],"float32"), ) 	 134217728 	 1000 	 0.5935983657836914 	 0.5936546325683594 	 0.5844640731811523 	 0.5765845775604248 	 0.636620044708252 	 0.05397796630859375 	 0.5763351917266846 	 5.1975250244140625e-05 	 
2025-07-30 13:33:04.609015 test begin: paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float16"), Tensor([2, 256, 336, 336],"float32"), )
W0730 13:33:06.503379  3567 dygraph_functions.cc:87088] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float16"), Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.7836527824401855 	 0.467897891998291 	 0.4004364013671875 	 0.45424675941467285 	 0.8028323650360107 	 0.26029038429260254 	 0.41020917892456055 	 0.1904284954071045 	 
2025-07-30 13:33:09.862909 test begin: paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float32"), Tensor([2, 256, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float32"), Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.5118834972381592 	 0.507699728012085 	 0.5027077198028564 	 0.4959373474121094 	 0.5488364696502686 	 0.05692553520202637 	 0.4884059429168701 	 4.863739013671875e-05 	 
2025-07-30 13:33:14.309419 test begin: paddle.Tensor.__add__(Tensor([4, 256, 336, 336],"float16"), Tensor([4, 256, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([4, 256, 336, 336],"float16"), Tensor([4, 256, 336, 336],"float32"), ) 	 231211008 	 1000 	 1.5623795986175537 	 0.9265861511230469 	 0.7983715534210205 	 0.9150481224060059 	 1.6008331775665283 	 0.5155429840087891 	 0.8179595470428467 	 0.44663095474243164 	 
2025-07-30 13:33:24.847190 test begin: paddle.Tensor.__add__(Tensor([8, 113, 336, 336],"float16"), Tensor([8, 113, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 113, 336, 336],"float16"), Tensor([8, 113, 336, 336],"float32"), ) 	 204115968 	 1000 	 1.37996244430542 	 0.8187685012817383 	 0.7051396369934082 	 0.8071334362030029 	 1.4155585765838623 	 0.45560240745544434 	 0.7232627868652344 	 0.38587021827697754 	 
2025-07-30 13:33:34.111181 test begin: paddle.Tensor.__add__(Tensor([8, 256, 336, 74],"float32"), Tensor([8, 256, 336, 74],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 256, 336, 74],"float32"), Tensor([8, 256, 336, 74],"float32"), ) 	 101842944 	 1000 	 0.45137715339660645 	 1.3577497005462646 	 0.44208455085754395 	 0.4291524887084961 	 0.48399877548217773 	 0.06772327423095703 	 0.4231386184692383 	 8.106231689453125e-05 	 
2025-07-30 13:33:40.008597 test begin: paddle.Tensor.__add__(Tensor([8, 256, 74, 336],"float32"), Tensor([8, 256, 74, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 256, 74, 336],"float32"), Tensor([8, 256, 74, 336],"float32"), ) 	 101842944 	 1000 	 0.4513819217681885 	 0.447725772857666 	 0.4422414302825928 	 0.4356708526611328 	 0.4839437007904053 	 0.05644845962524414 	 0.42360830307006836 	 6.0558319091796875e-05 	 
2025-07-30 13:33:43.996259 test begin: paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float16"), Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float16"), Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.6988632678985596 	 0.41618895530700684 	 0.3570849895477295 	 0.4041318893432617 	 0.7164909839630127 	 0.23234105110168457 	 0.36608290672302246 	 0.15334081649780273 	 
2025-07-30 13:33:48.689735 test begin: paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float32"), Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float32"), Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.45647597312927246 	 0.4525923728942871 	 0.4473397731781006 	 0.4405517578125 	 0.48912525177001953 	 0.05389690399169922 	 0.42850756645202637 	 5.412101745605469e-05 	 
2025-07-30 13:33:52.688345 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.16121578216552734 	 0.22842168807983398 	 0.15198230743408203 	 0.2140817642211914 	 None 	 None 	 None 	 None 	 
2025-07-30 13:33:53.922529 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.16118645668029785 	 0.22889280319213867 	 0.15142035484313965 	 0.21429944038391113 	 None 	 None 	 None 	 None 	 
2025-07-30 13:33:55.116813 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 24807],"bool"), Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 24807],"bool"), Tensor([1, 1, 2048, 24807],"bool"), ) 	 101609472 	 1000 	 0.11777663230895996 	 0.11550402641296387 	 0.1061716079711914 	 0.10359907150268555 	 None 	 None 	 None 	 None 	 
2025-07-30 13:33:56.739016 test begin: paddle.Tensor.__and__(Tensor([1, 1, 24807, 2048],"bool"), Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 24807, 2048],"bool"), Tensor([1, 1, 24807, 2048],"bool"), ) 	 101609472 	 1000 	 0.11776256561279297 	 0.11547636985778809 	 0.10943770408630371 	 0.10352396965026855 	 None 	 None 	 None 	 None 	 
2025-07-30 13:33:58.382257 test begin: paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.180556058883667 	 0.22672629356384277 	 0.17125964164733887 	 0.21414613723754883 	 None 	 None 	 None 	 None 	 
2025-07-30 13:33:59.590455 test begin: paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), ) 	 109051904 	 1000 	 0.12564897537231445 	 0.12343502044677734 	 0.11729049682617188 	 0.11191749572753906 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:01.316042 test begin: paddle.Tensor.__and__(Tensor([13, 1, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), ) 	 65913185 	 1000 	 0.18473052978515625 	 0.47357940673828125 	 0.1753389835357666 	 0.2257370948791504 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:04.554122 test begin: paddle.Tensor.__and__(Tensor([13, 1, 1007, 3881],"bool"), Tensor([13, 1, 1007, 3881],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 1007, 3881],"bool"), Tensor([13, 1, 1007, 3881],"bool"), ) 	 101612342 	 1000 	 0.11803293228149414 	 0.11937284469604492 	 0.10976672172546387 	 0.10218453407287598 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:07.408476 test begin: paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.18059015274047852 	 0.2267467975616455 	 0.17055583000183105 	 0.21165132522583008 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:08.653172 test begin: paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), ) 	 109051904 	 1000 	 0.12565851211547852 	 0.12340211868286133 	 0.11738944053649902 	 0.11171507835388184 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:10.380194 test begin: paddle.Tensor.__and__(Tensor([13, 1, 3881, 1007],"bool"), Tensor([13, 1, 3881, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 3881, 1007],"bool"), Tensor([13, 1, 3881, 1007],"bool"), ) 	 101612342 	 1000 	 0.11804056167602539 	 0.11796188354492188 	 0.10979270935058594 	 0.10401368141174316 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:12.022222 test begin: paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 1, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 1, 1007, 1007],"bool"), ) 	 65913185 	 1000 	 0.19786906242370605 	 0.23884153366088867 	 0.18845438957214355 	 0.225907564163208 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:13.348715 test begin: paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), ) 	 105461096 	 1000 	 0.12279939651489258 	 0.12173128128051758 	 0.11452412605285645 	 0.10862183570861816 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:15.059693 test begin: paddle.Tensor.__and__(Tensor([194, 1, 512, 512],"bool"), Tensor([194, 1, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([194, 1, 512, 512],"bool"), Tensor([194, 1, 512, 512],"bool"), ) 	 101711872 	 1000 	 0.11778378486633301 	 0.11557340621948242 	 0.10952877998352051 	 0.10360908508300781 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:16.675315 test begin: paddle.Tensor.__and__(Tensor([51, 1, 1007, 1007],"bool"), Tensor([51, 1, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([51, 1, 1007, 1007],"bool"), Tensor([51, 1, 1007, 1007],"bool"), ) 	 103432998 	 1000 	 0.11946558952331543 	 0.11791110038757324 	 0.11126303672790527 	 0.10631871223449707 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:18.325378 test begin: paddle.Tensor.__and__(Tensor([8, 1, 12404, 512],"bool"), Tensor([8, 1, 12404, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 12404, 512],"bool"), Tensor([8, 1, 12404, 512],"bool"), ) 	 101613568 	 1000 	 0.11771798133850098 	 0.11549496650695801 	 0.10948300361633301 	 0.10361576080322266 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:19.986678 test begin: paddle.Tensor.__and__(Tensor([8, 1, 512, 12404],"bool"), Tensor([8, 1, 512, 12404],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 512, 12404],"bool"), Tensor([8, 1, 512, 12404],"bool"), ) 	 101613568 	 1000 	 0.11770820617675781 	 0.11547064781188965 	 0.10950207710266113 	 0.10362839698791504 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:21.633398 test begin: paddle.Tensor.__and__(Tensor([8, 1, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), ) 	 54525952 	 1000 	 0.18358182907104492 	 0.23563385009765625 	 0.17434310913085938 	 0.2230675220489502 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:22.785387 test begin: paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 1, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 1, 512, 512],"bool"), ) 	 54525952 	 1000 	 0.19352245330810547 	 0.23571014404296875 	 0.18387603759765625 	 0.22265172004699707 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:23.978906 test begin: paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), ) 	 104857600 	 1000 	 0.12098908424377441 	 0.1190176010131836 	 0.11248350143432617 	 0.10729098320007324 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:25.677277 test begin: paddle.Tensor.__div__(Tensor([8, 16, 396901],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([8, 16, 396901],"float32"), 2, ) 	 50803328 	 1000 	 0.29564571380615234 	 0.29806017875671387 	 0.2868800163269043 	 0.2839484214782715 	 0.2957649230957031 	 0.2978029251098633 	 0.2421884536743164 	 0.23573827743530273 	 
2025-07-30 13:34:28.511314 test begin: paddle.Tensor.__div__(Tensor([8, 198451, 32],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([8, 198451, 32],"float32"), 2, ) 	 50803456 	 1000 	 0.29581117630004883 	 0.2978854179382324 	 0.2872493267059326 	 0.28386950492858887 	 0.2959587574005127 	 0.2977926731109619 	 0.2411644458770752 	 0.23552179336547852 	 
2025-07-30 13:34:31.347620 test begin: paddle.Tensor.__div__(Tensor([99226, 16, 32],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([99226, 16, 32],"float32"), 2, ) 	 50803712 	 1000 	 0.2957744598388672 	 0.29784727096557617 	 0.28702330589294434 	 0.28388547897338867 	 0.29588890075683594 	 0.29765892028808594 	 0.24102067947387695 	 0.23311328887939453 	 
2025-07-30 13:34:34.172009 test begin: paddle.Tensor.__eq__(Tensor([138, 369303],"float32"), Tensor([138, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([138, 369303],"float32"), Tensor([138, 1],"float32"), ) 	 50963952 	 1000 	 0.19208312034606934 	 0.4473240375518799 	 0.18228864669799805 	 0.22935175895690918 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:39.180546 test begin: paddle.Tensor.__eq__(Tensor([146, 349866],"float32"), Tensor([146, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([146, 349866],"float32"), Tensor([146, 1],"float32"), ) 	 51080582 	 1000 	 0.19235539436340332 	 0.24523067474365234 	 0.18270277976989746 	 0.230302095413208 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:40.455381 test begin: paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1036801],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1036801],"float32"), ) 	 101606498 	 1000 	 0.3268897533416748 	 0.32805442810058594 	 0.3179783821105957 	 0.3161194324493408 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:42.766875 test begin: paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1],"float32"), ) 	 50803298 	 1000 	 0.1916661262512207 	 0.24144482612609863 	 0.18195891380310059 	 0.22921109199523926 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:44.010889 test begin: paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 1],"float32"), ) 	 50803256 	 1000 	 0.19176340103149414 	 0.241499662399292 	 0.1820676326751709 	 0.22925186157226562 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:45.253973 test begin: paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 958551],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 958551],"float32"), ) 	 101606406 	 1000 	 0.32683849334716797 	 0.327808141708374 	 0.31788134574890137 	 0.31633758544921875 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:47.534540 test begin: paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 1],"float32"), ) 	 50803280 	 1000 	 0.19170355796813965 	 0.24143671989440918 	 0.18197178840637207 	 0.22906804084777832 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:48.772308 test begin: paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 923695],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 923695],"float32"), ) 	 101606450 	 1000 	 0.326829195022583 	 0.32785630226135254 	 0.31781554222106934 	 0.316408634185791 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:51.026545 test begin: paddle.Tensor.__floordiv__(Tensor([10, 10160641],"float32"), Tensor([10, 10160641],"float16"), )
W0730 13:34:54.410286  4013 dygraph_functions.cc:89596] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 10160641],"float32"), Tensor([10, 10160641],"float16"), ) 	 203212820 	 1000 	 1.371906042098999 	 1.191737413406372 	 0.7011077404022217 	 1.1746563911437988 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:57.181816 test begin: paddle.Tensor.__floordiv__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4475429058074951 	 0.44780588150024414 	 0.4388604164123535 	 0.43076539039611816 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:58.883203 test begin: paddle.Tensor.__floordiv__(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float16"), ) 	 101606420 	 1000 	 0.6897139549255371 	 0.600548267364502 	 0.35253095626831055 	 0.582482099533081 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:02.186173 test begin: paddle.Tensor.__floordiv__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.44801878929138184 	 0.44803810119628906 	 0.43933558464050293 	 0.4312715530395508 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:03.994202 test begin: paddle.Tensor.__floordiv__(Tensor([4, 6350401],"int64"), 4, )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([4, 6350401],"int64"), 4, ) 	 25401604 	 1000 	 0.30454134941101074 	 0.3026001453399658 	 0.15558362007141113 	 0.28496789932250977 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:05.015522 test begin: paddle.Tensor.__floordiv__(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float16"), ) 	 101607424 	 1000 	 0.6905546188354492 	 0.6016623973846436 	 0.35291433334350586 	 0.5829582214355469 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:09.912852 test begin: paddle.Tensor.__floordiv__(Tensor([84673, 300],"int64"), 4, )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([84673, 300],"int64"), 4, ) 	 25401900 	 1000 	 0.30470776557922363 	 0.5286521911621094 	 0.15569663047790527 	 0.28412294387817383 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:13.558934 test begin: paddle.Tensor.__floordiv__(Tensor([99226, 1024],"float32"), Tensor([99226, 1024],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([99226, 1024],"float32"), Tensor([99226, 1024],"float16"), ) 	 203214848 	 1000 	 1.374403953552246 	 1.1915662288665771 	 0.7023639678955078 	 1.1747641563415527 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:19.682976 test begin: paddle.Tensor.__ge__(Tensor([50803201],"int32"), 0, )
[Prof] paddle.Tensor.__ge__ 	 paddle.Tensor.__ge__(Tensor([50803201],"int32"), 0, ) 	 50803201 	 1000 	 0.46886515617370605 	 0.18626046180725098 	 0.2395644187927246 	 0.17200016975402832 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:20.938986 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), )
W0730 13:35:48.435664  4512 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 2715238400, memory's size is 1939456000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):2715238400 > memory_size():1939456000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), ) 	 969728000 	 1000 	 0.005280017852783203 	 0.009792327880859375 	 1.33514404296875e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:57.492818 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), )
W0730 13:36:31.294163  4747 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3557386560, memory's size is 2540990464.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3557386560 > memory_size():2540990464.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), ) 	 1270495200 	 1000 	 0.005069255828857422 	 0.005673646926879883 	 1.0967254638671875e-05 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:42.327887 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), )
W0730 13:37:08.912793  4891 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3158835200, memory's size is 1974272000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3158835200 > memory_size():1974272000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), ) 	 987136000 	 1000 	 0.005019664764404297 	 0.005498409271240234 	 1.0967254638671875e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:18.554752 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), )
W0730 13:37:53.862470  5394 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064532480, memory's size is 2540332800.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064532480 > memory_size():2540332800.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), ) 	 1270166400 	 1000 	 0.005117177963256836 	 0.005491971969604492 	 1.33514404296875e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:38:06.244088 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), )
W0730 13:38:28.520078  5547 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), ) 	 1045504000 	 1000 	 0.005196332931518555 	 0.005540370941162109 	 8.58306884765625e-06 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:38:34.825690 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), )
W0730 13:39:01.408898  5627 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), ) 	 1270124000 	 1000 	 0.005225181579589844 	 0.005584239959716797 	 1.0728836059570312e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:39:09.117630 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), )
W0730 13:39:43.358899  6160 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064460800, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064460800 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), ) 	 1270144000 	 1000 	 0.005145072937011719 	 0.005617380142211914 	 1.049041748046875e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:39:55.732995 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), )
W0730 13:40:27.839946  6296 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3556403200, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3556403200 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), ) 	 1270144000 	 1000 	 0.005208492279052734 	 0.005456209182739258 	 1.239776611328125e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:40:41.050097 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), )
W0730 13:41:11.150243  6436 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), ) 	 1270144000 	 1000 	 0.009876728057861328 	 0.009654998779296875 	 1.5020370483398438e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:19.833483 test begin: paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 0, ) 	 50803600 	 1000 	 0.4702765941619873 	 0.1861426830291748 	 0.2403092384338379 	 0.16922998428344727 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:21.345983 test begin: paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 1e-09, ) 	 50803600 	 1000 	 0.47020649909973145 	 0.18599939346313477 	 0.24026274681091309 	 0.17157340049743652 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:22.865856 test begin: paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 0, ) 	 50840832 	 1000 	 0.4711341857910156 	 0.1861109733581543 	 0.24076509475708008 	 0.17197132110595703 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:24.346840 test begin: paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 1e-09, ) 	 50840832 	 1000 	 0.4711110591888428 	 0.18619275093078613 	 0.24073195457458496 	 0.1712646484375 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:25.814259 test begin: paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 0, ) 	 52684800 	 1000 	 0.48726820945739746 	 0.1925952434539795 	 0.24900031089782715 	 0.17746663093566895 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:27.370820 test begin: paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 1e-09, ) 	 52684800 	 1000 	 0.4872019290924072 	 0.19259166717529297 	 0.24892711639404297 	 0.17810869216918945 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:28.910697 test begin: paddle.Tensor.__gt__(Tensor([324000, 157],"float32"), 0.0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([324000, 157],"float32"), 0.0, ) 	 50868000 	 1000 	 0.4711008071899414 	 0.18622350692749023 	 0.2407083511352539 	 0.17180180549621582 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:30.383298 test begin: paddle.Tensor.__gt__(Tensor([635041, 80],"float32"), 0.0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([635041, 80],"float32"), 0.0, ) 	 50803280 	 1000 	 0.4706687927246094 	 0.18604063987731934 	 0.24053168296813965 	 0.16463375091552734 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:31.878765 test begin: paddle.Tensor.__le__(Tensor([243360, 209],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([243360, 209],"float32"), 0.0, ) 	 50862240 	 1000 	 0.4711620807647705 	 0.18623805046081543 	 0.24075865745544434 	 0.1717233657836914 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:33.387416 test begin: paddle.Tensor.__le__(Tensor([282240, 181],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([282240, 181],"float32"), 0.0, ) 	 51085440 	 1000 	 0.4734175205230713 	 0.19475078582763672 	 0.24202275276184082 	 0.1726076602935791 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:34.872864 test begin: paddle.Tensor.__le__(Tensor([324000, 157],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([324000, 157],"float32"), 0.0, ) 	 50868000 	 1000 	 0.47098803520202637 	 0.1934671401977539 	 0.24067282676696777 	 0.17177319526672363 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:38.490881 test begin: paddle.Tensor.__le__(Tensor([635041, 80],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([635041, 80],"float32"), 0.0, ) 	 50803280 	 1000 	 0.4710073471069336 	 0.20294857025146484 	 0.24083852767944336 	 0.17148780822753906 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:40.978701 test begin: paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), ) 	 508352000 	 1000 	 0.004736423492431641 	 0.005004405975341797 	 8.344650268554688e-06 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:50.534018 test begin: paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), ) 	 508352000 	 1000 	 0.00467681884765625 	 0.004956960678100586 	 8.58306884765625e-06 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:58.682834 test begin: paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), ) 	 509000000 	 1000 	 0.006268978118896484 	 0.006141185760498047 	 7.3909759521484375e-06 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:09.918201 test begin: paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), ) 	 518190230 	 1000 	 0.006216526031494141 	 0.006073713302612305 	 8.106231689453125e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:19.799286 test begin: paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), ) 	 508953600 	 1000 	 0.006384372711181641 	 0.0061795711517333984 	 9.059906005859375e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:29.305718 test begin: paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), ) 	 508088500 	 1000 	 0.0056688785552978516 	 0.004865407943725586 	 4.220008850097656e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:40.155584 test begin: paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), ) 	 508088500 	 1000 	 0.004640817642211914 	 0.004765748977661133 	 6.4373016357421875e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:48.481737 test begin: paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), ) 	 508033000 	 1000 	 0.00469517707824707 	 0.004793405532836914 	 5.7220458984375e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:56.989697 test begin: paddle.Tensor.__lshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.44974470138549805 	 0.9495611190795898 	 0.44056081771850586 	 0.42997217178344727 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:00.466631 test begin: paddle.Tensor.__lshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.45000505447387695 	 0.4466371536254883 	 0.4411005973815918 	 0.43425703048706055 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:02.549645 test begin: paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4481682777404785 	 0.45008420944213867 	 0.4390244483947754 	 0.4378204345703125 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:05.445563 test begin: paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.44774651527404785 	 0.45024609565734863 	 0.4385967254638672 	 0.4371671676635742 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:08.338052 test begin: paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.44770145416259766 	 0.4501163959503174 	 0.43857359886169434 	 0.4378170967102051 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:11.236728 test begin: paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.4476640224456787 	 0.45009589195251465 	 0.43868374824523926 	 0.4379861354827881 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:14.102977 test begin: paddle.Tensor.__lt__(Tensor([1034, 3, 64, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([1034, 3, 64, 128],"float64"), 1, ) 	 25411584 	 1000 	 0.4542109966278076 	 0.16838788986206055 	 0.23207688331604004 	 0.15378570556640625 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:15.255888 test begin: paddle.Tensor.__lt__(Tensor([256, 13, 64, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 13, 64, 128],"float64"), 1, ) 	 27262976 	 1000 	 0.48584866523742676 	 0.1800682544708252 	 0.24825239181518555 	 0.16570568084716797 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:16.486486 test begin: paddle.Tensor.__lt__(Tensor([256, 3, 259, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 3, 259, 128],"float64"), 1, ) 	 25460736 	 1000 	 0.45487022399902344 	 0.16870832443237305 	 0.23241448402404785 	 0.15417814254760742 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:17.638372 test begin: paddle.Tensor.__lt__(Tensor([256, 3, 64, 517],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 3, 64, 517],"float64"), 1, ) 	 25411584 	 1000 	 0.454146146774292 	 0.16843080520629883 	 0.2320561408996582 	 0.15387892723083496 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:18.783589 test begin: paddle.Tensor.__lt__(Tensor([4, 157920, 81],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([4, 157920, 81],"float32"), 0.1111111111111111, ) 	 51166080 	 1000 	 0.47415852546691895 	 0.19285225868225098 	 0.24230599403381348 	 0.1727590560913086 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:20.280221 test begin: paddle.Tensor.__lt__(Tensor([4, 1814401, 7],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([4, 1814401, 7],"float32"), 0.1111111111111111, ) 	 50803228 	 1000 	 0.4706583023071289 	 0.18602633476257324 	 0.2404944896697998 	 0.17144322395324707 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:21.781956 test begin: paddle.Tensor.__lt__(Tensor([46, 157920, 7],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([46, 157920, 7],"float32"), 0.1111111111111111, ) 	 50850240 	 1000 	 0.47075939178466797 	 0.18634915351867676 	 0.24055862426757812 	 0.17154884338378906 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:23.302338 test begin: paddle.Tensor.__lt__(Tensor([50803201],"float32"), 0.7, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([50803201],"float32"), 0.7, ) 	 50803201 	 1000 	 0.4707369804382324 	 0.18602967262268066 	 0.24054455757141113 	 0.1704578399658203 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:24.791464 test begin: paddle.Tensor.__matmul__(Tensor([10, 2304, 2304],"float32"), Tensor([10, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([10, 2304, 2304],"float32"), Tensor([10, 2304, 64],"float32"), ) 	 54558720 	 1000 	 0.9306793212890625 	 0.9306149482727051 	 0.9176197052001953 	 0.9036312103271484 	 1.3776335716247559 	 1.3774261474609375 	 0.7038681507110596 	 0.7037482261657715 	 
2025-07-30 13:43:30.563260 test begin: paddle.Tensor.__matmul__(Tensor([111, 3, 392, 392],"float32"), Tensor([111, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([111, 3, 392, 392],"float32"), Tensor([111, 3, 392, 32],"float32"), ) 	 55347264 	 1000 	 1.0341274738311768 	 1.0388810634613037 	 1.0219600200653076 	 1.0087807178497314 	 1.4510829448699951 	 1.4506165981292725 	 0.741424560546875 	 0.7411489486694336 	 
2025-07-30 13:43:37.633157 test begin: paddle.Tensor.__matmul__(Tensor([1351, 3, 392, 392],"float32"), Tensor([1351, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([1351, 3, 392, 392],"float32"), Tensor([1351, 3, 392, 32],"float32"), ) 	 673641024 	 1000 	 11.902875900268555 	 11.902692079544067 	 11.8906831741333 	 11.879087924957275 	 16.857816219329834 	 16.85487937927246 	 8.61413049697876 	 8.612644910812378 	 
2025-07-30 13:44:49.288094 test begin: paddle.Tensor.__matmul__(Tensor([176, 2, 392, 392],"float32"), Tensor([176, 2, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 2, 392, 392],"float32"), Tensor([176, 2, 392, 32],"float32"), ) 	 58505216 	 1000 	 1.1113882064819336 	 1.1116001605987549 	 1.0990338325500488 	 1.0876667499542236 	 1.5516078472137451 	 1.5516586303710938 	 0.792804479598999 	 0.7926981449127197 	 
2025-07-30 13:44:55.686794 test begin: paddle.Tensor.__matmul__(Tensor([176, 24, 392, 392],"float32"), Tensor([176, 24, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 24, 392, 392],"float32"), Tensor([176, 24, 392, 32],"float32"), ) 	 702062592 	 1000 	 12.381505966186523 	 12.38237714767456 	 12.368184804916382 	 12.354318618774414 	 17.541483163833618 	 17.539416551589966 	 8.963415384292603 	 8.962372779846191 	 
2025-07-30 13:46:10.356719 test begin: paddle.Tensor.__matmul__(Tensor([176, 3, 246, 392],"float32"), Tensor([176, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 3, 246, 392],"float32"), Tensor([176, 3, 392, 32],"float32"), ) 	 57539328 	 1000 	 0.8003253936767578 	 0.8061511516571045 	 0.7861402034759521 	 0.7753462791442871 	 1.3495113849639893 	 1.3496367931365967 	 0.6894891262054443 	 0.6895036697387695 	 
2025-07-30 13:46:17.752201 test begin: paddle.Tensor.__matmul__(Tensor([176, 3, 392, 392],"float32"), Tensor([176, 3, 392, 246],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 3, 392, 392],"float32"), Tensor([176, 3, 392, 246],"float32"), ) 	 132050688 	 1000 	 3.1649422645568848 	 3.1647331714630127 	 3.152505397796631 	 3.1365182399749756 	 7.16483998298645 	 7.164493799209595 	 3.6611697673797607 	 3.660881519317627 	 
2025-07-30 13:46:41.562777 test begin: paddle.Tensor.__matmul__(Tensor([345, 2304, 2304],"float32"), Tensor([345, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([345, 2304, 2304],"float32"), Tensor([345, 2304, 64],"float32"), ) 	 1882275840 	 1000 	 26.8980450630188 	 26.627598762512207 	 26.87745761871338 	 26.594080686569214 	 41.73630881309509 	 41.73079824447632 	 21.326980352401733 	 21.32441997528076 	 
2025-07-30 13:49:34.476316 test begin: paddle.Tensor.__matmul__(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 64],"float32"), ) 	 54591488 	 1000 	 0.8290736675262451 	 1.3377196788787842 	 0.8166260719299316 	 0.804901123046875 	 1.26190185546875 	 1.262434720993042 	 0.6447658538818359 	 0.6449344158172607 	 
2025-07-30 13:49:42.344740 test begin: paddle.Tensor.__matmul__(Tensor([60, 2304, 2304],"float32"), Tensor([60, 2304, 368],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([60, 2304, 2304],"float32"), Tensor([60, 2304, 368],"float32"), ) 	 369377280 	 1000 	 13.796544790267944 	 13.790764093399048 	 13.776324272155762 	 13.757389545440674 	 27.241748571395874 	 27.241617441177368 	 13.920078039169312 	 13.919129610061646 	 
2025-07-30 13:51:12.374193 test begin: paddle.Tensor.__matmul__(Tensor([60, 368, 2304],"float32"), Tensor([60, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([60, 368, 2304],"float32"), Tensor([60, 2304, 64],"float32"), ) 	 59719680 	 1000 	 0.9291355609893799 	 0.9290750026702881 	 0.9168093204498291 	 0.9057717323303223 	 1.1978943347930908 	 1.1982002258300781 	 0.6120281219482422 	 0.6122152805328369 	 
2025-07-30 13:51:17.656378 test begin: paddle.Tensor.__matmul__(Tensor([776, 1024, 1024],"float32"), Tensor([776, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([776, 1024, 1024],"float32"), Tensor([776, 1024, 64],"float32"), ) 	 864550912 	 1000 	 11.871599674224854 	 11.871028423309326 	 11.859153509140015 	 11.847716331481934 	 18.5362229347229 	 18.52643609046936 	 9.471929550170898 	 9.466830492019653 	 
2025-07-30 13:52:33.988481 test begin: paddle.Tensor.__matmul__(Tensor([96, 1024, 1024],"float32"), Tensor([96, 1024, 517],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([96, 1024, 1024],"float32"), Tensor([96, 1024, 517],"float32"), ) 	 151486464 	 1000 	 7.376098155975342 	 7.379996299743652 	 7.3637449741363525 	 7.342779874801636 	 13.353398323059082 	 13.3576979637146 	 6.822864294052124 	 6.825649738311768 	 
2025-07-30 13:53:20.390457 test begin: paddle.Tensor.__matmul__(Tensor([96, 517, 1024],"float32"), Tensor([96, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([96, 517, 1024],"float32"), Tensor([96, 1024, 64],"float32"), ) 	 57114624 	 1000 	 1.0322153568267822 	 1.032364845275879 	 1.0197854042053223 	 1.0088326930999756 	 1.371903896331787 	 1.3721144199371338 	 0.7009804248809814 	 0.7010538578033447 	 
2025-07-30 13:53:26.162703 test begin: paddle.Tensor.__mod__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.44743847846984863 	 0.44776129722595215 	 0.43848657608032227 	 0.43619298934936523 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:29.053417 test begin: paddle.Tensor.__mod__(Tensor([13, 2, 976985],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([13, 2, 976985],"int64"), 16, ) 	 25401610 	 1000 	 0.5828042030334473 	 0.29921627044677734 	 0.2978324890136719 	 0.2853434085845947 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:31.045869 test begin: paddle.Tensor.__mod__(Tensor([13, 30531, 64],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([13, 30531, 64],"int64"), 16, ) 	 25401792 	 1000 	 0.5824484825134277 	 0.29912257194519043 	 0.29762887954711914 	 0.2855043411254883 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:33.051101 test begin: paddle.Tensor.__mod__(Tensor([198451, 2, 64],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([198451, 2, 64],"int64"), 16, ) 	 25401728 	 1000 	 0.5828018188476562 	 0.2991476058959961 	 0.2978336811065674 	 0.28526759147644043 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:35.091945 test begin: paddle.Tensor.__mod__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4479975700378418 	 0.45506906509399414 	 0.43912816047668457 	 0.4358978271484375 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:39.585431 test begin: paddle.Tensor.__mod__(Tensor([26, 976985],"int64"), 64, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([26, 976985],"int64"), 64, ) 	 25401610 	 1000 	 0.5830614566802979 	 0.29911303520202637 	 0.29787254333496094 	 0.2853114604949951 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:41.572339 test begin: paddle.Tensor.__mod__(Tensor([396901, 64],"int64"), 64, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([396901, 64],"int64"), 64, ) 	 25401664 	 1000 	 0.582528829574585 	 0.2991468906402588 	 0.2976396083831787 	 0.28528594970703125 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:53:43.581351 test begin: paddle.Tensor.__mul__(Tensor([1, 1, 32768, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([1, 1, 32768, 32768],"float16"), 10000.0, ) 	 1073741824 	 1000 	 3.1046087741851807 	 3.0920445919036865 	 3.0961079597473145 	 3.077413320541382 	 3.104820966720581 	 3.9662537574768066 	 3.0515482425689697 	 3.8989551067352295 	 
2025-07-30 13:54:37.870609 test begin: paddle.Tensor.__mul__(Tensor([108544, 469],"float32"), Tensor([108544, 469],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([108544, 469],"float32"), Tensor([108544, 469],"float32"), ) 	 101814272 	 1000 	 0.45085906982421875 	 0.4555842876434326 	 0.43938732147216797 	 0.4360947608947754 	 1.1066303253173828 	 0.8947982788085938 	 1.0368382930755615 	 0.4571568965911865 	 
2025-07-30 13:54:43.273587 test begin: paddle.Tensor.__mul__(Tensor([111616, 456],"float32"), Tensor([111616, 456],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([111616, 456],"float32"), Tensor([111616, 456],"float32"), ) 	 101793792 	 1000 	 0.4507608413696289 	 0.4475557804107666 	 0.44166111946105957 	 0.43621253967285156 	 1.1059176921844482 	 0.8946466445922852 	 1.0346379280090332 	 0.4570915699005127 	 
2025-07-30 13:54:48.698089 test begin: paddle.Tensor.__mul__(Tensor([14176, 3584],"float32"), Tensor([14176, 3584],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([14176, 3584],"float32"), Tensor([14176, 3584],"float32"), ) 	 101613568 	 1000 	 0.45000553131103516 	 0.4466850757598877 	 0.44084954261779785 	 0.4356980323791504 	 1.105515718460083 	 0.8930675983428955 	 1.042729377746582 	 0.45629072189331055 	 
2025-07-30 13:54:54.082050 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 1551, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 1551, 32768],"float16"), 10000.0, ) 	 101646336 	 1000 	 0.298306941986084 	 0.29636192321777344 	 0.289905309677124 	 0.28228116035461426 	 0.298311710357666 	 0.2962367534637451 	 0.24486970901489258 	 0.22895479202270508 	 
2025-07-30 13:54:59.050260 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 32768, 1551],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 32768, 1551],"float16"), 10000.0, ) 	 101646336 	 1000 	 0.2983243465423584 	 0.29640626907348633 	 0.28983139991760254 	 0.2749214172363281 	 0.2983376979827881 	 0.29622435569763184 	 0.24334025382995605 	 0.1995680332183838 	 
2025-07-30 13:55:04.115596 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 32768, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 32768, 32768],"float16"), 10000.0, ) 	 2147483648 	 1000 	 6.205647230148315 	 6.189157485961914 	 6.196668863296509 	 3.1596219539642334 	 6.206430912017822 	 6.1824631690979 	 6.144804954528809 	 3.1591989994049072 	 
2025-07-30 13:56:52.570679 test begin: paddle.Tensor.__ne__(Tensor([144, 392, 901],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([144, 392, 901],"float32"), 0, ) 	 50859648 	 1000 	 0.4711897373199463 	 0.19923615455627441 	 0.24074268341064453 	 0.1721503734588623 	 None 	 None 	 None 	 None 	 
2025-07-30 13:56:54.094066 test begin: paddle.Tensor.__ne__(Tensor([144, 901, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([144, 901, 392],"float32"), 0, ) 	 50859648 	 1000 	 0.47118258476257324 	 0.1862480640411377 	 0.24074983596801758 	 0.17216730117797852 	 None 	 None 	 None 	 None 	 
2025-07-30 13:56:55.616419 test begin: paddle.Tensor.__ne__(Tensor([160, 392, 811],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([160, 392, 811],"float32"), 0, ) 	 50865920 	 1000 	 0.47150564193725586 	 0.1876964569091797 	 0.24093127250671387 	 0.1721196174621582 	 None 	 None 	 None 	 None 	 
2025-07-30 13:56:57.139714 test begin: paddle.Tensor.__ne__(Tensor([160, 811, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([160, 811, 392],"float32"), 0, ) 	 50865920 	 1000 	 0.4717533588409424 	 0.186262845993042 	 0.24114108085632324 	 0.17214083671569824 	 None 	 None 	 None 	 None 	 
2025-07-30 13:56:58.626362 test begin: paddle.Tensor.__ne__(Tensor([176, 392, 737],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([176, 392, 737],"float32"), 0, ) 	 50847104 	 1000 	 0.471437931060791 	 0.19028568267822266 	 0.24089646339416504 	 0.17141938209533691 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:00.095427 test begin: paddle.Tensor.__ne__(Tensor([176, 737, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([176, 737, 392],"float32"), 0, ) 	 50847104 	 1000 	 0.47141361236572266 	 0.18620800971984863 	 0.24084734916687012 	 0.17223095893859863 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:01.573911 test begin: paddle.Tensor.__ne__(Tensor([331, 392, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([331, 392, 392],"float32"), 0, ) 	 50862784 	 1000 	 0.4714789390563965 	 0.18621349334716797 	 0.2409355640411377 	 0.17212939262390137 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:03.056592 test begin: paddle.Tensor.__neg__(Tensor([128, 396901],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2955005168914795 	 0.29776740074157715 	 0.28699302673339844 	 0.2877182960510254 	 0.2956993579864502 	 0.29776549339294434 	 0.23751449584960938 	 0.23368501663208008 	 
2025-07-30 13:57:05.883790 test begin: paddle.Tensor.__neg__(Tensor([128, 793801],"float16"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([128, 793801],"float16"), ) 	 101606528 	 1000 	 0.2985384464263916 	 0.29629039764404297 	 0.28781652450561523 	 0.283855676651001 	 0.2985384464263916 	 0.29610657691955566 	 0.24149489402770996 	 0.23066329956054688 	 
2025-07-30 13:57:11.276236 test begin: paddle.Tensor.__neg__(Tensor([22, 81, 94, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([22, 81, 94, 311],"float32"), ) 	 52094988 	 1000 	 0.3031785488128662 	 0.30524420738220215 	 0.29442715644836426 	 0.2950325012207031 	 0.3030979633331299 	 0.3051583766937256 	 0.24976110458374023 	 0.23558640480041504 	 
2025-07-30 13:57:14.166055 test begin: paddle.Tensor.__neg__(Tensor([264, 192612],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([264, 192612],"float32"), ) 	 50849568 	 1000 	 0.2960531711578369 	 1.0869243144989014 	 0.2875187397003174 	 0.2878580093383789 	 0.29615330696105957 	 0.2980360984802246 	 0.2433946132659912 	 0.23331141471862793 	 
2025-07-30 13:57:20.956316 test begin: paddle.Tensor.__neg__(Tensor([4, 435, 94, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 435, 94, 311],"float32"), ) 	 50867160 	 1000 	 0.2960026264190674 	 0.2982163429260254 	 0.2872772216796875 	 0.28788328170776367 	 0.29627346992492676 	 0.2980995178222656 	 0.24295473098754883 	 0.23197650909423828 	 
2025-07-30 13:57:23.785475 test begin: paddle.Tensor.__neg__(Tensor([4, 81, 505, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 81, 505, 311],"float32"), ) 	 50885820 	 1000 	 0.2961082458496094 	 0.29833102226257324 	 0.2873570919036865 	 0.28794074058532715 	 0.29627394676208496 	 0.29830265045166016 	 0.2427070140838623 	 0.22909140586853027 	 
2025-07-30 13:57:26.655789 test begin: paddle.Tensor.__neg__(Tensor([4, 81, 94, 1669],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 81, 94, 1669],"float32"), ) 	 50831064 	 1000 	 0.2960355281829834 	 0.3019979000091553 	 0.28745150566101074 	 0.28666257858276367 	 0.29606103897094727 	 0.29790472984313965 	 0.24279141426086426 	 0.2295215129852295 	 
2025-07-30 13:57:29.534989 test begin: paddle.Tensor.__neg__(Tensor([528, 192612],"float16"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([528, 192612],"float16"), ) 	 101699136 	 1000 	 0.2989175319671631 	 0.2985117435455322 	 0.2902498245239258 	 0.28616786003112793 	 0.2989351749420166 	 0.2963731288909912 	 0.24540138244628906 	 0.23162221908569336 	 
2025-07-30 13:57:34.510947 test begin: paddle.Tensor.__or__(Tensor([1, 210, 241921],"bool"), Tensor([1, 210, 241921],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 210, 241921],"bool"), Tensor([1, 210, 241921],"bool"), ) 	 101606820 	 1000 	 0.11770796775817871 	 0.11999392509460449 	 0.10946869850158691 	 0.09797787666320801 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:39.249680 test begin: paddle.Tensor.__or__(Tensor([1, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), ) 	 79380000 	 1000 	 0.161848783493042 	 0.27829670906066895 	 0.15267014503479004 	 0.26555418968200684 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:40.798367 test begin: paddle.Tensor.__or__(Tensor([1, 218, 233043],"bool"), Tensor([1, 218, 233043],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 218, 233043],"bool"), Tensor([1, 218, 233043],"bool"), ) 	 101606748 	 1000 	 0.11772036552429199 	 0.11648917198181152 	 0.10812520980834961 	 0.10452985763549805 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:42.440414 test begin: paddle.Tensor.__or__(Tensor([1, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), ) 	 77001960 	 1000 	 0.15721368789672852 	 0.2696104049682617 	 0.1475069522857666 	 0.25664377212524414 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:44.069087 test begin: paddle.Tensor.__or__(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"bool"), ) 	 101607200 	 1000 	 0.11698079109191895 	 0.11997222900390625 	 0.10874533653259277 	 0.10527658462524414 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:45.737781 test begin: paddle.Tensor.__or__(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), ) 	 79027200 	 1000 	 0.134918212890625 	 0.2351703643798828 	 0.1251523494720459 	 0.21893811225891113 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:47.216427 test begin: paddle.Tensor.__or__(Tensor([1, 673, 75600],"bool"), Tensor([1, 673, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 673, 75600],"bool"), Tensor([1, 673, 75600],"bool"), ) 	 101757600 	 1000 	 0.11733269691467285 	 0.11536264419555664 	 0.10905981063842773 	 0.10354113578796387 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:48.861821 test begin: paddle.Tensor.__or__(Tensor([1, 720, 70644],"bool"), Tensor([1, 720, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 720, 70644],"bool"), Tensor([1, 720, 70644],"bool"), ) 	 101727360 	 1000 	 0.11783552169799805 	 0.11786937713623047 	 0.09847593307495117 	 0.10425877571105957 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:50.536674 test begin: paddle.Tensor.__or__(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"bool"), ) 	 101681664 	 1000 	 0.11782503128051758 	 0.1203761100769043 	 0.10941743850708008 	 0.10290074348449707 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:52.185836 test begin: paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"bool"), ) 	 79027200 	 1000 	 0.17525839805603027 	 0.23194479942321777 	 0.16591501235961914 	 0.21920442581176758 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:53.675402 test begin: paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), ) 	 105369600 	 1000 	 0.12111854553222656 	 0.11903786659240723 	 0.11285662651062012 	 0.10723328590393066 	 None 	 None 	 None 	 None 	 
2025-07-30 13:57:55.375501 test begin: paddle.rank(input=Tensor([1270080101, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([1270080101, 2],"float64"), ) 	 2540160202 	 1000 	 0.042063236236572266 	 0.028079748153686523 	 1.9550323486328125e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:48.575952 test begin: paddle.rank(input=Tensor([201, 12700801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([201, 12700801],"float64"), ) 	 2552861001 	 1000 	 0.04048442840576172 	 0.028322935104370117 	 2.2649765014648438e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:59:53.750399 test begin: paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), ) 	 2548628404 	 1000 	 0.042557477951049805 	 0.02872323989868164 	 3.075599670410156e-05 	 5.173683166503906e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:00:47.242345 test begin: paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), ) 	 2548628404 	 1000 	 0.042342185974121094 	 0.03123760223388672 	 2.3126602172851562e-05 	 5.340576171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:02:05.803265 test begin: paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), ) 	 2548628404 	 1000 	 0.044492244720458984 	 0.03073263168334961 	 3.4809112548828125e-05 	 8.082389831542969e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:03:09.671455 test begin: paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), ) 	 2540160808 	 1000 	 0.04194188117980957 	 0.028172969818115234 	 2.3603439331054688e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:04:11.350365 test begin: paddle.reciprocal(Tensor([125, 1, 640, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([125, 1, 640, 640],"float32"), ) 	 51200000 	 1000 	 0.29762983322143555 	 0.3027770519256592 	 0.28201913833618164 	 0.2835545539855957 	 0.45304179191589355 	 1.0479609966278076 	 0.3891909122467041 	 0.35697364807128906 	 
2025-07-30 14:04:15.213717 test begin: paddle.reciprocal(Tensor([16, 1, 4962, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 1, 4962, 640],"float32"), ) 	 50810880 	 1000 	 0.29547667503356934 	 0.2982826232910156 	 0.2799830436706543 	 0.2870798110961914 	 0.44974231719970703 	 1.0400290489196777 	 0.39086198806762695 	 0.3542592525482178 	 
2025-07-30 14:04:19.141109 test begin: paddle.reciprocal(Tensor([16, 1, 640, 4962],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 1, 640, 4962],"float32"), ) 	 50810880 	 1000 	 0.295551061630249 	 0.29812073707580566 	 0.2871856689453125 	 0.28764915466308594 	 0.44955897331237793 	 1.0401620864868164 	 0.3941621780395508 	 0.3543660640716553 	 
2025-07-30 14:04:22.879322 test begin: paddle.reciprocal(Tensor([16, 8, 640, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 8, 640, 640],"float32"), ) 	 52428800 	 1000 	 0.30449700355529785 	 0.30739855766296387 	 0.2961916923522949 	 0.2968885898590088 	 0.4638864994049072 	 1.0728023052215576 	 0.4079463481903076 	 0.36551356315612793 	 
2025-07-30 14:04:26.757530 test begin: paddle.reciprocal(Tensor([4, 1, 13231, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 1, 13231, 960],"float32"), ) 	 50807040 	 1000 	 0.2955646514892578 	 0.3003110885620117 	 0.28696560859680176 	 0.2877016067504883 	 0.44956254959106445 	 1.0399532318115234 	 0.393993616104126 	 0.3542768955230713 	 
2025-07-30 14:04:30.489406 test begin: paddle.reciprocal(Tensor([4, 1, 960, 13231],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 1, 960, 13231],"float32"), ) 	 50807040 	 1000 	 0.29558491706848145 	 0.2993316650390625 	 0.2870938777923584 	 0.2806525230407715 	 0.44980311393737793 	 1.0401556491851807 	 0.37606382369995117 	 0.3543727397918701 	 
2025-07-30 14:04:34.362332 test begin: paddle.reciprocal(Tensor([4, 14, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 14, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.2998778820037842 	 0.5430002212524414 	 0.2914881706237793 	 0.2918679714202881 	 0.4566535949707031 	 1.0563054084777832 	 0.400606632232666 	 0.3598482608795166 	 
2025-07-30 14:04:40.457101 test begin: paddle.reciprocal(Tensor([56, 1, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([56, 1, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.2998464107513428 	 0.30277013778686523 	 0.2914462089538574 	 0.29161882400512695 	 0.4567251205444336 	 1.0563156604766846 	 0.40083765983581543 	 0.3598301410675049 	 
2025-07-30 14:04:44.221683 test begin: paddle.reciprocal(Tensor([8, 1, 6616, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 1, 6616, 960],"float32"), ) 	 50810880 	 1000 	 0.29548048973083496 	 0.29817962646484375 	 0.27997875213623047 	 0.2813911437988281 	 0.4498586654663086 	 1.0399761199951172 	 0.38480663299560547 	 0.3542935848236084 	 
2025-07-30 14:04:48.161714 test begin: paddle.reciprocal(Tensor([8, 1, 960, 6616],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 1, 960, 6616],"float32"), ) 	 50810880 	 1000 	 0.29541945457458496 	 0.3066556453704834 	 0.27957582473754883 	 0.28763413429260254 	 0.44961094856262207 	 1.0400760173797607 	 0.3855416774749756 	 0.3543050289154053 	 
2025-07-30 14:04:52.045682 test begin: paddle.reciprocal(Tensor([8, 7, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 7, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.2997889518737793 	 0.30426526069641113 	 0.2914278507232666 	 0.29197001457214355 	 0.45673155784606934 	 1.0561816692352295 	 0.40075182914733887 	 0.35976195335388184 	 
2025-07-30 14:04:55.877000 test begin: paddle.reduce_as(Tensor([30, 1270081, 40],"float32"), Tensor([1270081, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 1270081, 40],"float32"), Tensor([1270081, 40],"float32"), ) 	 1574900440 	 1000 	 5.168812990188599 	 5.345339059829712 	 5.157407760620117 	 1.3656904697418213 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:05:50.819714 test begin: paddle.reduce_as(Tensor([30, 200, 254017],"float32"), Tensor([200, 254017],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 200, 254017],"float32"), Tensor([200, 254017],"float32"), ) 	 1574905400 	 1000 	 5.16948390007019 	 5.350884675979614 	 5.1507041454315186 	 1.365659475326538 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:06:46.759062 test begin: paddle.reduce_as(Tensor([30, 200, 8468],"float32"), Tensor([200, 8468],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 200, 8468],"float32"), Tensor([200, 8468],"float32"), ) 	 52501600 	 1000 	 0.1784992218017578 	 0.15605521202087402 	 0.1676654815673828 	 0.12126779556274414 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:06:48.149205 test begin: paddle.reduce_as(Tensor([30, 42337, 40],"float32"), Tensor([42337, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 42337, 40],"float32"), Tensor([42337, 40],"float32"), ) 	 52497880 	 1000 	 0.1792917251586914 	 0.1567366123199463 	 0.1685333251953125 	 0.1208646297454834 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:06:49.547650 test begin: paddle.reduce_as(Tensor([6351, 200, 40],"float32"), Tensor([200, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([6351, 200, 40],"float32"), Tensor([200, 40],"float32"), ) 	 50816000 	 1000 	 0.2598416805267334 	 0.15592122077941895 	 0.13273382186889648 	 0.0796959400177002 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:06:50.967076 test begin: paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"float32"), Tensor([1, 2, 1270081, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"float32"), Tensor([1, 2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 0.4501216411590576 	 0.4498622417449951 	 0.44082045555114746 	 0.43734025955200195 	 None 	 None 	 None 	 None 	 
2025-07-30 14:06:53.539113 test begin: paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"int32"), Tensor([1, 2, 1270081, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"int32"), Tensor([1, 2, 1270081, 4, 5],"int32"), ) 	 101606480 	 1000 	 0.4502549171447754 	 0.4492645263671875 	 0.43343067169189453 	 0.4318556785583496 	 None 	 None 	 None 	 None 	 
2025-07-30 14:06:55.721058 test begin: paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"float32"), Tensor([1, 2, 3, 1693441, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"float32"), Tensor([1, 2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 0.45023512840270996 	 0.44893455505371094 	 0.44057130813598633 	 0.4371452331542969 	 None 	 None 	 None 	 None 	 
2025-07-30 14:06:58.316902 test begin: paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"int32"), Tensor([1, 2, 3, 1693441, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"int32"), Tensor([1, 2, 3, 1693441, 5],"int32"), ) 	 101606460 	 1000 	 0.4502534866333008 	 0.44926905632019043 	 0.4330630302429199 	 0.43172693252563477 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:00.609150 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 1058401],"float64"), Tensor([1, 2, 3, 4, 1058401],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 1058401],"float64"), Tensor([1, 2, 3, 4, 1058401],"float64"), ) 	 50803248 	 1000 	 0.4471926689147949 	 0.4563915729522705 	 0.4382622241973877 	 0.44512319564819336 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:02.565856 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"float32"), Tensor([1, 2, 3, 4, 2116801],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"float32"), Tensor([1, 2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 0.4501023292541504 	 0.44881319999694824 	 0.4409158229827881 	 0.4374358654022217 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:05.100178 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"int32"), Tensor([1, 2, 3, 4, 2116801],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"int32"), Tensor([1, 2, 3, 4, 2116801],"int32"), ) 	 101606448 	 1000 	 0.45010828971862793 	 0.44930481910705566 	 0.4333007335662842 	 0.43172764778137207 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:07.250684 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), ) 	 50803440 	 1000 	 0.29763364791870117 	 0.3315315246582031 	 0.2873823642730713 	 0.3192901611328125 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:08.705253 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), ) 	 25401840 	 1000 	 0.43801283836364746 	 0.3715362548828125 	 0.42813611030578613 	 0.3593940734863281 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:10.046329 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), ) 	 50803440 	 1000 	 0.30088138580322266 	 0.34550929069519043 	 0.2905876636505127 	 0.3307807445526123 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:11.282360 test begin: paddle.remainder(Tensor([1, 2, 3, 846721, 5],"float64"), Tensor([1, 2, 3, 846721, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 846721, 5],"float64"), Tensor([1, 2, 3, 846721, 5],"float64"), ) 	 50803260 	 1000 	 0.4472391605377197 	 0.4625120162963867 	 0.43637585639953613 	 0.444568395614624 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:14.557532 test begin: paddle.remainder(Tensor([1, 2, 635041, 4, 5],"float64"), Tensor([1, 2, 635041, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 635041, 4, 5],"float64"), Tensor([1, 2, 635041, 4, 5],"float64"), ) 	 50803280 	 1000 	 0.4471440315246582 	 0.467266321182251 	 0.43813419342041016 	 0.44418954849243164 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:17.278768 test begin: paddle.remainder(Tensor([1, 423361, 3, 4, 5],"float64"), Tensor([1, 423361, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 423361, 3, 4, 5],"float64"), Tensor([1, 423361, 3, 4, 5],"float64"), ) 	 50803320 	 1000 	 0.4471468925476074 	 0.4563119411468506 	 0.4382460117340088 	 0.4451332092285156 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:19.254183 test begin: paddle.remainder(Tensor([1, 846721, 3, 4, 5],"float32"), Tensor([1, 846721, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 846721, 3, 4, 5],"float32"), Tensor([1, 846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 0.45017147064208984 	 0.4489593505859375 	 0.44092273712158203 	 0.43761777877807617 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:21.991367 test begin: paddle.remainder(Tensor([1, 846721, 3, 4, 5],"int32"), Tensor([1, 846721, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 846721, 3, 4, 5],"int32"), Tensor([1, 846721, 3, 4, 5],"int32"), ) 	 101606520 	 1000 	 0.45017385482788086 	 0.4491918087005615 	 0.4409806728363037 	 0.43181681632995605 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:24.062708 test begin: paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([1, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([1, 2, 3, 4, 5],"float64"), ) 	 25401840 	 1000 	 0.4191765785217285 	 0.3798694610595703 	 0.40936732292175293 	 0.3673982620239258 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:25.397463 test begin: paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), ) 	 50803440 	 1000 	 0.44717884063720703 	 0.456249475479126 	 0.43381428718566895 	 0.44507455825805664 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:27.342402 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([1, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([1, 2, 3, 4, 5],"float32"), ) 	 50803440 	 1000 	 0.2969038486480713 	 0.33188891410827637 	 0.2865939140319824 	 0.319774866104126 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:28.783262 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), ) 	 101606640 	 1000 	 0.4500856399536133 	 0.4517514705657959 	 0.44086337089538574 	 0.4365732669830322 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:31.327357 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([1, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([1, 2, 3, 4, 5],"int32"), ) 	 50803440 	 1000 	 0.2982943058013916 	 0.3381950855255127 	 0.28812670707702637 	 0.32619357109069824 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:32.545131 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), ) 	 101606640 	 1000 	 0.45023202896118164 	 0.4546010494232178 	 0.44091057777404785 	 0.4378330707550049 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:34.632991 test begin: paddle.renorm(Tensor([10, 20, 254017],"float32"), 1.0, -1, 2.05, )
[Prof] paddle.renorm 	 paddle.renorm(Tensor([10, 20, 254017],"float32"), 1.0, -1, 2.05, ) 	 50803400 	 1000 	 2.8543460369110107 	 0.48148345947265625 	 0.7283616065979004 	 0.16391563415527344 	 5.564979076385498 	 2.919220447540283 	 1.4219818115234375 	 0.22920489311218262 	 
2025-07-30 14:07:48.269664 test begin: paddle.repeat_interleave(Tensor([1, 1500, 33869],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([1, 1500, 33869],"float32"), 5, axis=0, ) 	 50803500 	 1000 	 1.8582239151000977 	 1.5097661018371582 	 0.9495491981506348 	 1.4867634773254395 	 2.420966148376465 	 0.874351978302002 	 0.8253598213195801 	 0.7761020660400391 	 
2025-07-30 14:08:00.989937 test begin: paddle.repeat_interleave(Tensor([1, 39691, 1280],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([1, 39691, 1280],"float32"), 5, axis=0, ) 	 50804480 	 1000 	 1.8641705513000488 	 1.4950647354125977 	 0.9526016712188721 	 1.469452142715454 	 2.3991923332214355 	 0.8628065586090088 	 0.8179571628570557 	 0.7287378311157227 	 
2025-07-30 14:08:12.552185 test begin: paddle.repeat_interleave(Tensor([14, 1, 384, 9451],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 1, 384, 9451],"float32"), repeats=3, axis=1, ) 	 50808576 	 1000 	 1.105520248413086 	 0.8546385765075684 	 0.5649211406707764 	 0.8257346153259277 	 1.227379560470581 	 0.5868241786956787 	 0.4183955192565918 	 0.44803500175476074 	 
2025-07-30 14:08:21.547196 test begin: paddle.repeat_interleave(Tensor([14, 1, 9451, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 1, 9451, 384],"float32"), repeats=3, axis=1, ) 	 50808576 	 1000 	 1.1055049896240234 	 0.8495161533355713 	 0.5648858547210693 	 0.8262033462524414 	 1.2267656326293945 	 0.5867769718170166 	 0.4181380271911621 	 0.4910295009613037 	 
2025-07-30 14:08:29.321161 test begin: paddle.repeat_interleave(Tensor([14, 25, 384, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 25, 384, 384],"float32"), repeats=3, axis=1, ) 	 51609600 	 1000 	 1.0458266735076904 	 0.7340395450592041 	 0.5344042778015137 	 0.7103307247161865 	 1.2126483917236328 	 0.6030769348144531 	 0.4133615493774414 	 0.5088062286376953 	 
2025-07-30 14:08:37.635988 test begin: paddle.repeat_interleave(Tensor([27, 1500, 1280],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([27, 1500, 1280],"float32"), 5, axis=0, ) 	 51840000 	 1000 	 1.6904873847961426 	 1.1160914897918701 	 0.8638210296630859 	 1.0897691249847412 	 1.8616676330566406 	 0.8813095092773438 	 0.6346378326416016 	 0.7314965724945068 	 
2025-07-30 14:08:48.333048 test begin: paddle.repeat_interleave(Tensor([345, 1, 384, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([345, 1, 384, 384],"float32"), repeats=3, axis=1, ) 	 50872320 	 1000 	 1.0306220054626465 	 0.7275481224060059 	 0.5266735553741455 	 0.699167013168335 	 1.1938414573669434 	 0.5941658020019531 	 0.4069523811340332 	 0.50042724609375 	 
2025-07-30 14:08:55.603687 test begin: paddle.repeat_interleave(Tensor([5, 1, 13231, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 1, 13231, 768],"float32"), repeats=3, axis=1, ) 	 50807040 	 1000 	 1.1223080158233643 	 0.9047620296478271 	 0.5735013484954834 	 0.88138747215271 	 1.4959235191345215 	 0.5868980884552002 	 0.5099503993988037 	 0.4910106658935547 	 
2025-07-30 14:09:03.841808 test begin: paddle.repeat_interleave(Tensor([5, 1, 768, 13231],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 1, 768, 13231],"float32"), repeats=3, axis=1, ) 	 50807040 	 1000 	 1.1223864555358887 	 0.9048688411712646 	 0.573540210723877 	 0.881493330001831 	 1.496603012084961 	 0.5869569778442383 	 0.5101797580718994 	 0.49230051040649414 	 
2025-07-30 14:09:12.168589 test begin: paddle.repeat_interleave(Tensor([5, 18, 768, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 18, 768, 768],"float32"), repeats=3, axis=1, ) 	 53084160 	 1000 	 1.0542662143707275 	 0.7062301635742188 	 0.538689136505127 	 0.6737155914306641 	 1.2515015602111816 	 0.6253881454467773 	 0.4266231060028076 	 0.5026900768280029 	 
2025-07-30 14:09:19.225390 test begin: paddle.repeat_interleave(Tensor([87, 1, 768, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([87, 1, 768, 768],"float32"), repeats=3, axis=1, ) 	 51314688 	 1000 	 1.0190198421478271 	 0.9205741882324219 	 0.5207064151763916 	 0.6587817668914795 	 1.2105960845947266 	 0.6046757698059082 	 0.4126400947570801 	 0.5104007720947266 	 
2025-07-30 14:09:27.692396 test begin: paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], )
[Prof] paddle.reshape 	 paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], ) 	 1016135680 	 1000 	 0.0054819583892822266 	 0.0065097808837890625 	 2.4080276489257812e-05 	 8.153915405273438e-05 	 0.0494532585144043 	 4.496798515319824 	 6.508827209472656e-05 	 2.2978081703186035 	 
2025-07-30 14:10:11.514125 test begin: paddle.reverse(Tensor([12, 132301, 16],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 132301, 16],"float64"), axis=list[0,], ) 	 25401792 	 1000 	 0.505695104598999 	 0.30431365966796875 	 0.49698781967163086 	 0.2906215190887451 	 0.5067520141601562 	 0.3041250705718994 	 0.4544374942779541 	 0.20904254913330078 	 
2025-07-30 14:10:14.241306 test begin: paddle.reverse(Tensor([12, 264601, 8],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 264601, 8],"float64"), axis=0, ) 	 25401696 	 1000 	 0.5080950260162354 	 0.3041653633117676 	 0.4993014335632324 	 0.2892768383026123 	 0.5067226886749268 	 0.30412936210632324 	 0.4543123245239258 	 0.23360991477966309 	 
2025-07-30 14:10:16.923765 test begin: paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=0, ) 	 25401648 	 1000 	 0.5078074932098389 	 0.30533838272094727 	 0.49906110763549805 	 0.2891082763671875 	 0.5077450275421143 	 0.3040902614593506 	 0.4495387077331543 	 0.23642325401306152 	 
2025-07-30 14:10:19.609538 test begin: paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=list[0,], ) 	 25401648 	 1000 	 0.5078039169311523 	 0.30419301986694336 	 0.4992096424102783 	 0.2894585132598877 	 0.5077676773071289 	 0.304079532623291 	 0.4546384811401367 	 0.23675298690795898 	 
2025-07-30 14:10:22.313668 test begin: paddle.reverse(Tensor([396901, 4, 16],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([396901, 4, 16],"float64"), axis=list[0,], ) 	 25401664 	 1000 	 0.5029010772705078 	 0.30298733711242676 	 0.49422359466552734 	 0.28930211067199707 	 0.5027499198913574 	 0.3028111457824707 	 0.4501066207885742 	 0.2346811294555664 	 
2025-07-30 14:10:24.977090 test begin: paddle.reverse(Tensor([4, 12, 529201],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([4, 12, 529201],"float64"), axis=1, ) 	 25401648 	 1000 	 0.5076584815979004 	 0.31520915031433105 	 0.4989602565765381 	 0.2920873165130615 	 0.5077550411224365 	 0.30589938163757324 	 0.4543726444244385 	 0.23473095893859863 	 
2025-07-30 14:10:30.898267 test begin: paddle.reverse(Tensor([4, 198451, 32],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([4, 198451, 32],"float64"), axis=1, ) 	 25401728 	 1000 	 0.5030403137207031 	 0.3037431240081787 	 0.4943544864654541 	 0.289670467376709 	 0.5031177997589111 	 0.3033745288848877 	 0.450472354888916 	 0.23522448539733887 	 
2025-07-30 14:10:33.567864 test begin: paddle.reverse(Tensor([66151, 12, 32],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([66151, 12, 32],"float64"), axis=1, ) 	 25401984 	 1000 	 0.5019731521606445 	 0.7597830295562744 	 0.49334096908569336 	 0.2897639274597168 	 0.5033986568450928 	 0.3036010265350342 	 0.45052218437194824 	 0.23572516441345215 	 
2025-07-30 14:10:39.632410 test begin: paddle.reverse(Tensor([793801, 4, 8],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([793801, 4, 8],"float64"), axis=0, ) 	 25401632 	 1000 	 0.5019407272338867 	 0.3031318187713623 	 0.49332356452941895 	 0.28953027725219727 	 0.503216028213501 	 0.3030264377593994 	 0.4508171081542969 	 0.23315954208374023 	 
2025-07-30 14:10:42.328842 test begin: paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5456540584564209 	 0.7869293689727783 	 0.5343098640441895 	 0.4020957946777344 	 0.5454998016357422 	 0.7850029468536377 	 0.4867241382598877 	 0.4010319709777832 	 
2025-07-30 14:10:46.677833 test begin: paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.545954704284668 	 0.7960433959960938 	 0.5347030162811279 	 0.4009237289428711 	 0.5456373691558838 	 0.7872872352600098 	 0.490772008895874 	 0.402205228805542 	 
2025-07-30 14:10:51.066670 test begin: paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5456242561340332 	 0.7960786819458008 	 0.5343132019042969 	 0.4035024642944336 	 0.545729398727417 	 0.7877006530761719 	 0.4891676902770996 	 0.402454137802124 	 
2025-07-30 14:10:55.433361 test begin: paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5459187030792236 	 0.7875080108642578 	 0.5345945358276367 	 0.40240025520324707 	 0.5455517768859863 	 0.7900228500366211 	 0.49048519134521484 	 0.4036216735839844 	 
2025-07-30 14:10:59.779859 test begin: paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50978816 	 1000 	 0.5459740161895752 	 0.7892968654632568 	 0.526820182800293 	 0.4033069610595703 	 0.546058177947998 	 0.7870261669158936 	 0.48254871368408203 	 0.40211009979248047 	 
2025-07-30 14:11:04.145545 test begin: paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50978816 	 1000 	 0.5460653305053711 	 0.7905881404876709 	 0.5271289348602295 	 0.40212559700012207 	 0.5460343360900879 	 0.7894983291625977 	 0.48216915130615234 	 0.40338993072509766 	 
2025-07-30 14:11:10.557230 test begin: paddle.roll(Tensor([44, 96, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([44, 96, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51904512 	 1000 	 0.5559122562408447 	 0.7981164455413818 	 0.5367844104766846 	 0.4078240394592285 	 0.5560622215270996 	 0.7953104972839355 	 0.4920780658721924 	 0.40633106231689453 	 
2025-07-30 14:11:14.991128 test begin: paddle.roll(Tensor([64, 65, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 65, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51118080 	 1000 	 0.5477499961853027 	 0.7860977649688721 	 0.5287823677062988 	 0.4016735553741455 	 0.5477504730224609 	 0.7837743759155273 	 0.48195624351501465 	 0.40044236183166504 	 
2025-07-30 14:11:19.326147 test begin: paddle.roll(Tensor([64, 96, 65, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 96, 65, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51118080 	 1000 	 0.547818660736084 	 0.7871038913726807 	 0.5287551879882812 	 0.40218448638916016 	 0.5477085113525391 	 0.7845840454101562 	 0.4837937355041504 	 0.4008615016937256 	 
2025-07-30 14:11:23.643442 test begin: paddle.roll(Tensor([64, 96, 96, 87],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 96, 96, 87],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51314688 	 1000 	 0.5496466159820557 	 0.7926874160766602 	 0.5305080413818359 	 0.4050869941711426 	 0.5497665405273438 	 0.7893040180206299 	 0.48477816581726074 	 0.4032595157623291 	 
2025-07-30 14:11:28.041488 test begin: paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 51179520 	 1000 	 0.5482633113861084 	 0.7898714542388916 	 0.5369729995727539 	 0.4036283493041992 	 0.5481874942779541 	 0.7877695560455322 	 0.4931774139404297 	 0.4024958610534668 	 
2025-07-30 14:11:34.033041 test begin: paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 51179520 	 1000 	 0.5481207370758057 	 0.792461633682251 	 0.5368201732635498 	 0.4026682376861572 	 0.5484514236450195 	 0.7904269695281982 	 0.48973536491394043 	 0.4038844108581543 	 
2025-07-30 14:11:39.099181 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5143387317657471 	 0.31061601638793945 	 0.47806334495544434 	 0.2802133560180664 	 0.8252856731414795 	 0.30397534370422363 	 0.42167162895202637 	 0.22526764869689941 	 
2025-07-30 14:11:42.169524 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8197908401489258 	 0.30356931686401367 	 0.41883420944213867 	 0.27941417694091797 	 0.5144596099853516 	 0.3034217357635498 	 0.44365954399108887 	 0.22824311256408691 	 
2025-07-30 14:11:45.181023 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8157401084899902 	 0.3035430908203125 	 0.4167745113372803 	 0.2792484760284424 	 0.5144233703613281 	 0.3031916618347168 	 0.44369077682495117 	 0.22518348693847656 	 
2025-07-30 14:11:48.211455 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5176365375518799 	 0.30454373359680176 	 0.4820067882537842 	 0.28801441192626953 	 0.8279879093170166 	 0.30291104316711426 	 0.4231555461883545 	 0.2056887149810791 	 
2025-07-30 14:11:51.433064 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.9512786865234375 	 0.3229084014892578 	 0.4860870838165283 	 0.2874925136566162 	 0.519078254699707 	 0.3044772148132324 	 0.45859622955322266 	 0.2336130142211914 	 
2025-07-30 14:11:54.596987 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.815558910369873 	 0.3045969009399414 	 0.41675376892089844 	 0.2859177589416504 	 0.5144903659820557 	 0.30318379402160645 	 0.4522416591644287 	 0.23102951049804688 	 
2025-07-30 14:11:57.591940 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.5191607475280762 	 0.30441951751708984 	 0.49520421028137207 	 0.28881287574768066 	 0.8283076286315918 	 0.3039984703063965 	 0.4231870174407959 	 0.23149657249450684 	 
2025-07-30 14:12:00.644698 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.831878662109375 	 0.3044602870941162 	 0.42505693435668945 	 0.2878146171569824 	 0.5144171714782715 	 0.30347299575805664 	 0.4512622356414795 	 0.2330009937286377 	 
2025-07-30 14:12:03.646485 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8194653987884521 	 0.30507874488830566 	 0.4187314510345459 	 0.2875485420227051 	 0.5184674263000488 	 0.3059852123260498 	 0.4572868347167969 	 0.22830510139465332 	 
2025-07-30 14:12:06.646703 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.5191633701324463 	 0.30707740783691406 	 0.49514222145080566 	 0.2886991500854492 	 0.8282754421234131 	 0.30401110649108887 	 0.42321252822875977 	 0.23183846473693848 	 
2025-07-30 14:12:09.692070 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8289058208465576 	 0.30441784858703613 	 0.42353296279907227 	 0.28754091262817383 	 0.5186915397644043 	 0.30642080307006836 	 0.4585587978363037 	 0.23523616790771484 	 
2025-07-30 14:12:12.691494 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8102447986602783 	 0.30640244483947754 	 0.41399598121643066 	 0.2896571159362793 	 0.5143759250640869 	 0.3031609058380127 	 0.4541468620300293 	 0.22072982788085938 	 
2025-07-30 14:12:15.671748 test begin: paddle.round(Tensor([128, 396901],"float32"), )
[Prof] paddle.round 	 paddle.round(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.29561948776245117 	 0.29779577255249023 	 0.28721022605895996 	 0.28745579719543457 	 0.1339271068572998 	 0.1340317726135254 	 0.0817720890045166 	 0.06907963752746582 	 
2025-07-30 14:12:18.168007 test begin: paddle.round(Tensor([16, 1587601],"float64"), )
[Prof] paddle.round 	 paddle.round(Tensor([16, 1587601],"float64"), ) 	 25401616 	 1000 	 0.3043084144592285 	 0.2989468574523926 	 0.2959585189819336 	 0.28856396675109863 	 0.13375449180603027 	 0.13455581665039062 	 0.08202219009399414 	 0.06889605522155762 	 
2025-07-30 14:12:20.075073 test begin: paddle.round(Tensor([396901, 128],"float32"), )
[Prof] paddle.round 	 paddle.round(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29568982124328613 	 0.2978084087371826 	 0.28739142417907715 	 0.2873818874359131 	 0.13398528099060059 	 0.1339859962463379 	 0.08140349388122559 	 0.040776729583740234 	 
2025-07-30 14:12:22.604195 test begin: paddle.round(Tensor([99226, 256],"float64"), )
[Prof] paddle.round 	 paddle.round(Tensor([99226, 256],"float64"), ) 	 25401856 	 1000 	 0.3048412799835205 	 0.3010876178741455 	 0.296612024307251 	 0.2879505157470703 	 0.13384628295898438 	 0.1344747543334961 	 0.06382584571838379 	 0.03575730323791504 	 
2025-07-30 14:12:24.510154 test begin: paddle.round(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.29552364349365234 	 0.29792356491088867 	 0.2793729305267334 	 0.287494421005249 	 0.13400030136108398 	 0.13401126861572266 	 0.08153772354125977 	 0.06736302375793457 	 
2025-07-30 14:12:27.124415 test begin: paddle.round(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.2955033779144287 	 0.2978053092956543 	 0.28676915168762207 	 0.2874484062194824 	 0.13400053977966309 	 0.1340014934539795 	 0.08148550987243652 	 0.06804728507995605 	 
2025-07-30 14:12:29.651610 test begin: paddle.round(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.2954533100128174 	 0.29784226417541504 	 0.286754846572876 	 0.28746557235717773 	 0.13395071029663086 	 0.1340012550354004 	 0.08174943923950195 	 0.06866025924682617 	 
2025-07-30 14:12:32.153591 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9382443428039551 	 0.9285688400268555 	 0.1598215103149414 	 0.9060337543487549 	 0.9434390068054199 	 0.08003950119018555 	 0.16066741943359375 	 0.00013709068298339844 	 
2025-07-30 14:12:39.750819 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.30771517753601074 	 0.7917134761810303 	 0.15722203254699707 	 0.1600933074951172 	 0.31406331062316895 	 0.059774160385131836 	 0.16041922569274902 	 4.792213439941406e-05 	 
2025-07-30 14:12:43.078447 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.32073545455932617 	 0.3364531993865967 	 0.08209729194641113 	 0.30963969230651855 	 0.3168501853942871 	 0.078521728515625 	 0.08105325698852539 	 4.935264587402344e-05 	 
2025-07-30 14:12:46.688716 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.32204556465148926 	 0.3211684226989746 	 0.08211874961853027 	 0.3068392276763916 	 0.322293758392334 	 0.07978296279907227 	 0.08215832710266113 	 0.00012159347534179688 	 
2025-07-30 14:12:48.788974 test begin: paddle.row_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9481217861175537 	 0.9264261722564697 	 0.16128969192504883 	 0.8900177478790283 	 0.954338550567627 	 0.0831294059753418 	 0.1625511646270752 	 3.886222839355469e-05 	 
2025-07-30 14:12:55.381190 test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.3195459842681885 	 0.32279348373413086 	 0.08178162574768066 	 0.3085043430328369 	 0.31638503074645996 	 0.10198402404785156 	 0.08093976974487305 	 0.00014328956604003906 	 
2025-07-30 14:12:57.544314 test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.3211860656738281 	 0.31958723068237305 	 0.08189511299133301 	 0.3056447505950928 	 0.32315993309020996 	 0.07628464698791504 	 0.08236837387084961 	 7.414817810058594e-05 	 
2025-07-30 14:12:59.662063 test begin: paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9496550559997559 	 0.9196884632110596 	 0.16175413131713867 	 0.905019998550415 	 0.9518589973449707 	 0.07841157913208008 	 0.16208600997924805 	 4.2438507080078125e-05 	 
2025-07-30 14:13:05.737977 test begin: paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3149983882904053 	 0.3135075569152832 	 0.1609659194946289 	 0.16008520126342773 	 0.315976619720459 	 0.05838465690612793 	 0.16141581535339355 	 3.1948089599609375e-05 	 
2025-07-30 14:13:07.818639 test begin: paddle.row_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9420287609100342 	 0.9217610359191895 	 0.16047120094299316 	 0.907322883605957 	 0.9307961463928223 	 0.07601094245910645 	 0.15850114822387695 	 3.886222839355469e-05 	 
2025-07-30 14:13:13.844801 test begin: paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9443295001983643 	 0.9302217960357666 	 0.1608576774597168 	 0.91542649269104 	 0.9470489025115967 	 0.07955694198608398 	 0.16130685806274414 	 6.699562072753906e-05 	 
2025-07-30 14:13:19.928344 test begin: paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.30771350860595703 	 0.31346845626831055 	 0.1572260856628418 	 0.16008329391479492 	 0.3141000270843506 	 0.059697628021240234 	 0.16043329238891602 	 5.054473876953125e-05 	 
2025-07-30 14:13:21.967433 test begin: paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.3128199577331543 	 0.30925679206848145 	 0.07974052429199219 	 0.295215368270874 	 0.320467472076416 	 0.07797050476074219 	 0.08167409896850586 	 4.3392181396484375e-05 	 
2025-07-30 14:13:24.039412 test begin: paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.9380929470062256 	 0.9172728061676025 	 0.1598353385925293 	 0.9025952816009521 	 0.9305834770202637 	 0.09925174713134766 	 0.1585092544555664 	 7.963180541992188e-05 	 
2025-07-30 14:13:30.608963 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.32001423835754395 	 0.3120903968811035 	 0.0815885066986084 	 0.29767441749572754 	 0.3204052448272705 	 0.0769507884979248 	 0.08163928985595703 	 7.2479248046875e-05 	 
2025-07-30 14:13:32.692333 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9493706226348877 	 1.164693832397461 	 0.16164517402648926 	 0.9082005023956299 	 0.9433002471923828 	 0.08587312698364258 	 0.16065335273742676 	 0.00010323524475097656 	 
2025-07-30 14:13:41.413588 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.31502389907836914 	 0.31351566314697266 	 0.16095542907714844 	 0.16010403633117676 	 0.31598353385925293 	 0.06622052192687988 	 0.16139864921569824 	 5.054473876953125e-05 	 
2025-07-30 14:13:43.535901 test begin: paddle.rsqrt(Tensor([10000, 1694, 3],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 1694, 3],"float32"), ) 	 50820000 	 1000 	 0.2958717346191406 	 0.29799890518188477 	 0.27817845344543457 	 0.28118324279785156 	 0.44953107833862305 	 1.0402984619140625 	 0.3854231834411621 	 0.3543686866760254 	 
2025-07-30 14:13:48.816415 test begin: paddle.rsqrt(Tensor([10000, 2, 1271],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 2, 1271],"float64"), ) 	 25420000 	 1000 	 0.29795241355895996 	 0.31043171882629395 	 0.28272104263305664 	 0.2883718013763428 	 0.4483015537261963 	 1.0411875247955322 	 0.38440728187561035 	 0.35473108291625977 	 
2025-07-30 14:13:52.788689 test begin: paddle.rsqrt(Tensor([10000, 2, 2541],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 2, 2541],"float32"), ) 	 50820000 	 1000 	 0.2958807945251465 	 0.29790282249450684 	 0.28058600425720215 	 0.28108859062194824 	 0.44952917098999023 	 1.0402209758758545 	 0.3851325511932373 	 0.35435962677001953 	 
2025-07-30 14:13:56.602099 test begin: paddle.rsqrt(Tensor([10000, 847, 3],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 847, 3],"float64"), ) 	 25410000 	 1000 	 0.297818660736084 	 0.29954075813293457 	 0.2899158000946045 	 0.28893327713012695 	 0.44807958602905273 	 1.0405914783477783 	 0.3929567337036133 	 0.3544960021972656 	 
2025-07-30 14:13:59.748498 test begin: paddle.rsqrt(Tensor([13, 1007, 3881],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([13, 1007, 3881],"float32"), ) 	 50806171 	 1000 	 0.29570913314819336 	 0.2978854179382324 	 0.2802305221557617 	 0.28105807304382324 	 0.44939327239990234 	 1.0399696826934814 	 0.38486337661743164 	 0.3542916774749756 	 
2025-07-30 14:14:03.780617 test begin: paddle.rsqrt(Tensor([13, 3907939, 1],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([13, 3907939, 1],"float32"), ) 	 50803207 	 1000 	 0.2955186367034912 	 0.29779624938964844 	 0.2873039245605469 	 0.2870979309082031 	 0.44970226287841797 	 1.039886474609375 	 0.39420604705810547 	 0.354266881942749 	 
2025-07-30 14:14:07.582532 test begin: paddle.rsqrt(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.2985684871673584 	 0.2994101047515869 	 0.2906672954559326 	 0.28884315490722656 	 0.44811558723449707 	 1.0402510166168213 	 0.39336323738098145 	 0.3543832302093506 	 
2025-07-30 14:14:10.740140 test begin: paddle.rsqrt(Tensor([50451, 1007, 1],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([50451, 1007, 1],"float32"), ) 	 50804157 	 1000 	 0.29563307762145996 	 0.29781198501586914 	 0.28742456436157227 	 0.2872617244720459 	 0.4494624137878418 	 1.0398623943328857 	 0.3940904140472412 	 0.35428524017333984 	 
2025-07-30 14:14:14.555192 test begin: paddle.rsqrt(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2955660820007324 	 0.29877233505249023 	 0.28739452362060547 	 0.2872176170349121 	 0.44960665702819824 	 1.0399503707885742 	 0.3941807746887207 	 0.35425496101379395 	 
2025-07-30 14:14:18.337033 test begin: paddle.scale(Tensor([2, 256, 256, 388],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 256, 256, 388],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29593420028686523 	 0.5958576202392578 	 0.28665852546691895 	 0.3044581413269043 	 0.2958245277404785 	 0.298020601272583 	 0.24260210990905762 	 0.2241837978363037 	 combined
2025-07-30 14:14:21.458229 test begin: paddle.scale(Tensor([2, 256, 388, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 256, 388, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2960243225097656 	 0.5959486961364746 	 0.27907657623291016 	 0.30446672439575195 	 0.2958056926727295 	 0.2980232238769531 	 0.2325439453125 	 0.21573448181152344 	 combined
2025-07-30 14:14:24.960427 test begin: paddle.scale(Tensor([2, 388, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 388, 256, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2959885597229004 	 0.595895528793335 	 0.2866818904876709 	 0.3044466972351074 	 0.2958261966705322 	 0.29805541038513184 	 0.24271178245544434 	 0.223862886428833 	 combined
2025-07-30 14:14:28.072767 test begin: paddle.scale(Tensor([4, 194, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 194, 256, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2960178852081299 	 0.5958495140075684 	 0.28669309616088867 	 0.30447888374328613 	 0.29573559761047363 	 0.29802441596984863 	 0.24239659309387207 	 0.22292065620422363 	 combined
2025-07-30 14:14:31.271241 test begin: paddle.scale(Tensor([4, 256, 194, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 194, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2959706783294678 	 0.5958743095397949 	 0.2867872714996338 	 0.30446600914001465 	 0.2957773208618164 	 0.29805612564086914 	 0.24222326278686523 	 0.22353148460388184 	 combined
2025-07-30 14:14:34.422492 test begin: paddle.scale(Tensor([4, 256, 256, 194],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 194],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2959740161895752 	 0.6078729629516602 	 0.2832348346710205 	 0.30458617210388184 	 0.29578733444213867 	 0.29808831214904785 	 0.24265074729919434 	 0.2243022918701172 	 combined
2025-07-30 14:14:39.585192 test begin: paddle.scale(Tensor([4, 256, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 256],"float32"), scale=1.1111111111111112, ) 	 67108864 	 1000 	 0.38924551010131836 	 0.7893600463867188 	 0.3795793056488037 	 0.40004944801330566 	 0.389279842376709 	 0.39160609245300293 	 0.3357260227203369 	 0.3137474060058594 	 combined
2025-07-30 14:14:43.709087 test begin: paddle.scale(Tensor([4, 256, 256, 388],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 388],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.2988908290863037 	 0.5925822257995605 	 0.289722204208374 	 0.30277514457702637 	 0.2987964153289795 	 0.2964625358581543 	 0.244370698928833 	 0.17778730392456055 	 combined
2025-07-30 14:14:49.049269 test begin: paddle.scale(Tensor([4, 256, 388, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 388, 256],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.2989518642425537 	 0.5964198112487793 	 0.2882571220397949 	 0.30275678634643555 	 0.29875636100769043 	 0.29638218879699707 	 0.24530768394470215 	 0.2183091640472412 	 combined
2025-07-30 14:14:56.618345 test begin: paddle.scale(Tensor([4, 388, 256, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 388, 256, 256],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.2989041805267334 	 0.594416618347168 	 0.28958892822265625 	 0.3027036190032959 	 0.298724889755249 	 0.29637861251831055 	 0.2454087734222412 	 0.22095966339111328 	 combined
2025-07-30 14:15:01.908635 test begin: paddle.scale(Tensor([7, 256, 256, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([7, 256, 256, 256],"float16"), scale=1.1111111111111112, ) 	 117440512 	 1000 	 0.3440999984741211 	 0.6835062503814697 	 0.3271627426147461 	 0.3488352298736572 	 0.34420108795166016 	 0.3414173126220703 	 0.28197526931762695 	 0.2609679698944092 	 combined
2025-07-30 14:15:08.054579 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([197],"int32"), Tensor([197, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([197],"int32"), Tensor([197, 194],"float32"), overwrite=True, ) 	 50894351 	 1000 	 0.3199195861816406 	 10.025318145751953 	 0.16347455978393555 	 0.00023245811462402344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:15:20.455014 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([205],"int32"), Tensor([205, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([205],"int32"), Tensor([205, 194],"float32"), overwrite=True, ) 	 50895911 	 1000 	 0.31975507736206055 	 6.9089515209198 	 0.1633927822113037 	 0.0002186298370361328 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:15:29.743899 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([219],"int32"), Tensor([219, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([219],"int32"), Tensor([219, 194],"float32"), overwrite=True, ) 	 50898641 	 1000 	 0.3199739456176758 	 7.389652252197266 	 0.16348505020141602 	 0.0002288818359375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:15:39.498590 test begin: paddle.scatter(Tensor([262144, 2314],"float32"), Tensor([219],"int32"), Tensor([219, 2314],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2314],"float32"), Tensor([219],"int32"), Tensor([219, 2314],"float32"), overwrite=True, ) 	 607108201 	 1000 	 3.7027699947357178 	 7.437010288238525 	 1.2589726448059082 	 0.0002224445343017578 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:16:14.170032 test begin: paddle.scatter(Tensor([262144, 2476],"float32"), Tensor([205],"int32"), Tensor([205, 2476],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2476],"float32"), Tensor([205],"int32"), Tensor([205, 2476],"float32"), overwrite=True, ) 	 649576329 	 1000 	 3.9631810188293457 	 7.004513502120972 	 1.3475275039672852 	 0.00022459030151367188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:16:56.253446 test begin: paddle.scatter(Tensor([262144, 2569],"float32"), Tensor([197],"int32"), Tensor([197, 2569],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2569],"float32"), Tensor([197],"int32"), Tensor([197, 2569],"float32"), overwrite=True, ) 	 673954226 	 1000 	 4.106930255889893 	 6.707624197006226 	 1.3964741230010986 	 0.00023365020751953125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:17:39.449661 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([197],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([197],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285445 	 1000 	 0.11259961128234863 	 6.818757772445679 	 0.057511329650878906 	 0.00022673606872558594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:17:47.113964 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([205],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([205],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285453 	 1000 	 0.11270809173583984 	 7.003663539886475 	 0.057575225830078125 	 0.00022268295288085938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:17:54.952282 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([219],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([219],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285467 	 1000 	 0.11265230178833008 	 9.086692810058594 	 0.05756020545959473 	 0.0002536773681640625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:18:04.860986 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([197],"int32"), Tensor([197, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([197],"int32"), Tensor([197, 64],"float32"), overwrite=True, ) 	 50816069 	 1000 	 0.3143904209136963 	 6.921987295150757 	 0.10691618919372559 	 0.0006988048553466797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:18:14.354323 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([205],"int32"), Tensor([205, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([205],"int32"), Tensor([205, 64],"float32"), overwrite=True, ) 	 50816589 	 1000 	 0.3143310546875 	 6.937945604324341 	 0.10688114166259766 	 0.0004787445068359375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:18:23.648812 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([219],"int32"), Tensor([219, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([219],"int32"), Tensor([219, 64],"float32"), overwrite=True, ) 	 50817499 	 1000 	 0.314558744430542 	 7.441941022872925 	 0.10699701309204102 	 0.00022268295288085938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:18:33.443031 test begin: paddle.scatter_nd(Tensor([1280, 2],"int64"), Tensor([1280, 9, 10],"float32"), list[3,5,9,10,], )
[Prof] paddle.scatter_nd 	 paddle.scatter_nd(Tensor([1280, 2],"int64"), Tensor([1280, 9, 10],"float32"), list[3,5,9,10,], ) 	 117760 	 1000 	 0.03602480888366699 	 152.22138714790344 	 1.239776611328125e-05 	 0.00020003318786621094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:21:06.024065 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), ) 	 105808018 	 1000 	 0.4070110321044922 	 69.58191967010498 	 0.20795392990112305 	 0.0002155303955078125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:22:20.315409 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), ) 	 105879718 	 1000 	 0.40535736083984375 	 71.30850720405579 	 0.20711684226989746 	 0.0002129077911376953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:23:37.548428 test begin: paddle.scatter_nd_add(Tensor([1, 8192, 12404],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 12404],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 8192, 12404],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 12404],"bfloat16"), ) 	 108895890 	 1000 	 0.5414257049560547 	 74.20263981819153 	 0.27667236328125 	 0.0002193450927734375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:24:56.983377 test begin: paddle.scatter_nd_add(Tensor([1, 8192, 17069],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 17069],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 8192, 17069],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 17069],"bfloat16"), ) 	 149986493 	 1000 	 0.9084439277648926 	 84.96563363075256 	 0.46421003341674805 	 0.0002124309539794922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:26:28.948735 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), ) 	 121634962 	 1000 	 0.4521324634552002 	 70.23164796829224 	 0.23102283477783203 	 0.0002148151397705078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:27:44.441402 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 7168],"bfloat16"), ) 	 121649302 	 1000 	 0.4523751735687256 	 70.29634761810303 	 0.23112821578979492 	 0.00021958351135253906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:29:00.591756 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), ) 	 121706662 	 1000 	 0.4531588554382324 	 79.2014594078064 	 0.23156166076660156 	 0.00021910667419433594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:30:25.931051 test begin: paddle.searchsorted(Tensor([1024],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"float32"), Tensor([50803201],"float32"), ) 	 50804225 	 1000 	 1.3610506057739258 	 1.0249295234680176 	 1.3536484241485596 	 1.014054536819458 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:29.163474 test begin: paddle.searchsorted(Tensor([1024],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"float64"), Tensor([25401601],"float64"), ) 	 25402625 	 1000 	 0.6605851650238037 	 0.5116798877716064 	 0.6528947353363037 	 0.5008349418640137 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:30.874189 test begin: paddle.searchsorted(Tensor([1024],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"int32"), Tensor([50803201],"int32"), ) 	 50804225 	 1000 	 1.350109338760376 	 1.0383691787719727 	 1.342545747756958 	 1.027268648147583 	 None 	 None 	 None 	 None 	 
2025-07-30 14:30:33.860009 test begin: paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), ) 	 2540160613 	 1000 	 0.010013341903686523 	 0.010668754577636719 	 0.0024192333221435547 	 3.0994415283203125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:25.649196 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 1.3967008590698242 	 1.0790462493896484 	 1.389284610748291 	 1.0682413578033447 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:29.178850 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), ) 	 25452802 	 1000 	 0.010243415832519531 	 0.010452508926391602 	 0.0023508071899414062 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:29.713550 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 2.9670746326446533 	 2.3169353008270264 	 2.9596309661865234 	 2.3059751987457275 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:37.485340 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), ) 	 50854402 	 1000 	 0.014225959777832031 	 0.02073192596435547 	 1.4543533325195312e-05 	 3.0040740966796875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:39.681538 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 2.9625844955444336 	 2.322474241256714 	 2.954984188079834 	 2.30417537689209 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:46.182667 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), ) 	 50854402 	 1000 	 0.01421356201171875 	 0.016849517822265625 	 2.0503997802734375e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:31:46.784816 test begin: paddle.select_scatter(Tensor([12700801, 3, 4],"float32"), Tensor([12700801, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([12700801, 3, 4],"float32"), Tensor([12700801, 4],"float32"), 1, 1, ) 	 203212816 	 1000 	 0.7249114513397217 	 1.654578447341919 	 0.7043166160583496 	 0.5642611980438232 	 3.2411863803863525 	 1.7970983982086182 	 0.4137418270111084 	 0.4587991237640381 	 
2025-07-30 14:32:00.108895 test begin: paddle.select_scatter(Tensor([1693441, 3, 4, 5],"float64"), Tensor([1693441, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([1693441, 3, 4, 5],"float64"), Tensor([1693441, 3, 5],"float64"), 2, 1, ) 	 127008075 	 1000 	 0.751014232635498 	 1.9865381717681885 	 0.7308080196380615 	 0.6759567260742188 	 3.477736473083496 	 2.1345551013946533 	 0.4438176155090332 	 0.545093297958374 	 
2025-07-30 14:32:13.248769 test begin: paddle.select_scatter(Tensor([2, 211681, 4, 5, 6],"int32"), Tensor([2, 211681, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 211681, 4, 5, 6],"int32"), Tensor([2, 211681, 5, 6],"int32"), 2, 1, ) 	 63504300 	 1000 	 0.17926740646362305 	 0.4922523498535156 	 0.15891242027282715 	 0.16750645637512207 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:16.235223 test begin: paddle.select_scatter(Tensor([2, 2540161, 4, 5],"float64"), Tensor([2, 2540161, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 2540161, 4, 5],"float64"), Tensor([2, 2540161, 5],"float64"), 2, 1, ) 	 127008050 	 1000 	 0.7519583702087402 	 1.9887139797210693 	 0.7319133281707764 	 0.6759252548217773 	 3.477138042449951 	 2.1344072818756104 	 0.44385766983032227 	 0.5449082851409912 	 
2025-07-30 14:32:29.471279 test begin: paddle.select_scatter(Tensor([2, 3, 25401601],"float32"), Tensor([2, 25401601],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 25401601],"float32"), Tensor([2, 25401601],"float32"), 1, 1, ) 	 203212808 	 1000 	 0.36681532859802246 	 1.25032639503479 	 0.34693169593811035 	 0.4181675910949707 	 2.6764819622039795 	 1.364485263824463 	 0.3415558338165283 	 0.34822821617126465 	 
2025-07-30 14:32:43.047781 test begin: paddle.select_scatter(Tensor([2, 3, 4, 1411201, 6],"int32"), Tensor([2, 3, 1411201, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 1411201, 6],"int32"), Tensor([2, 3, 1411201, 6],"int32"), 2, 1, ) 	 254016180 	 1000 	 0.5413849353790283 	 1.534794807434082 	 0.5209903717041016 	 0.5220258235931396 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:53.972228 test begin: paddle.select_scatter(Tensor([2, 3, 4, 352801, 6],"int32"), Tensor([2, 3, 352801, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 352801, 6],"int32"), Tensor([2, 3, 352801, 6],"int32"), 2, 1, ) 	 63504180 	 1000 	 0.1387009620666504 	 0.3928711414337158 	 0.11423063278198242 	 0.13358736038208008 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:32:56.697970 test begin: paddle.select_scatter(Tensor([2, 3, 4, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), 2, 1, ) 	 127008030 	 1000 	 0.30555105209350586 	 1.5320026874542236 	 0.28528356552124023 	 0.5209906101226807 	 2.75400972366333 	 1.6661038398742676 	 0.3512606620788574 	 0.425079345703125 	 
2025-07-30 14:33:07.729998 test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 1693441],"int32"), Tensor([2, 3, 5, 1693441],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 5, 1693441],"int32"), Tensor([2, 3, 5, 1693441],"int32"), 2, 1, ) 	 254016150 	 1000 	 0.539971113204956 	 1.5348563194274902 	 0.5194520950317383 	 0.5220410823822021 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:18.512373 test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 423361],"int32"), Tensor([2, 3, 5, 423361],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 5, 423361],"int32"), Tensor([2, 3, 5, 423361],"int32"), 2, 1, ) 	 63504150 	 1000 	 0.13872742652893066 	 0.39288854598999023 	 0.11856842041015625 	 0.13359999656677246 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:21.287390 test begin: paddle.select_scatter(Tensor([2, 3, 8467201],"float32"), Tensor([2, 8467201],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 8467201],"float32"), Tensor([2, 8467201],"float32"), 1, 1, ) 	 67737608 	 1000 	 0.12517499923706055 	 0.4269704818725586 	 0.1053016185760498 	 0.14213132858276367 	 0.9054477214813232 	 0.4661436080932617 	 0.1154940128326416 	 0.11887168884277344 	 
2025-07-30 14:33:27.060849 test begin: paddle.select_scatter(Tensor([2, 635041, 4, 5],"float64"), Tensor([2, 635041, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 635041, 4, 5],"float64"), Tensor([2, 635041, 5],"float64"), 2, 1, ) 	 31752050 	 1000 	 0.18609213829040527 	 0.49862241744995117 	 0.1544017791748047 	 0.16965532302856445 	 0.9031083583831787 	 0.5490524768829346 	 0.11524081230163574 	 0.14013671875 	 
2025-07-30 14:33:30.421459 test begin: paddle.select_scatter(Tensor([2, 846721, 4, 5, 6],"int32"), Tensor([2, 846721, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 846721, 4, 5, 6],"int32"), Tensor([2, 846721, 5, 6],"int32"), 2, 1, ) 	 254016300 	 1000 	 0.7047343254089355 	 1.9998514652252197 	 0.6754112243652344 	 0.6724050045013428 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:33:43.433065 test begin: paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, ) 	 508035600 	 1000 	 0.028876781463623047 	 3.0788486003875732 	 1.430511474609375e-05 	 1.0431199073791504 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:34:01.543213 test begin: paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, ) 	 317520300 	 1000 	 0.7565677165985107 	 3.808476209640503 	 0.7275223731994629 	 1.295436143875122 	 6.885641098022461 	 4.494225263595581 	 0.8781375885009766 	 1.4109117984771729 	 
2025-07-30 14:34:31.255263 test begin: paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, ) 	 254016600 	 1000 	 0.030659914016723633 	 3.0678582191467285 	 2.4318695068359375e-05 	 1.0428972244262695 	 3.109851598739624 	 3.070038318634033 	 0.39493536949157715 	 0.7828412055969238 	 
2025-07-30 14:34:51.242141 test begin: paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, ) 	 50803280 	 1000 	 0.029104948043823242 	 0.3165323734283447 	 1.811981201171875e-05 	 0.10757708549499512 	 0.33028626441955566 	 0.31833434104919434 	 0.041936635971069336 	 0.0811316967010498 	 
2025-07-30 14:34:54.009903 test begin: paddle.select_scatter(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 4],"float32"), 1, 1, ) 	 67737616 	 1000 	 0.2443561553955078 	 0.5600357055664062 	 0.21558094024658203 	 0.19057345390319824 	 1.1076457500457764 	 0.6177372932434082 	 0.14142322540283203 	 0.15773606300354004 	 
2025-07-30 14:34:58.523154 test begin: paddle.select_scatter(Tensor([423361, 3, 4, 5],"float64"), Tensor([423361, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([423361, 3, 4, 5],"float64"), Tensor([423361, 3, 5],"float64"), 2, 1, ) 	 31752075 	 1000 	 0.1866767406463623 	 0.4986588954925537 	 0.15763306617736816 	 0.16965484619140625 	 0.902972936630249 	 0.549015998840332 	 0.11522221565246582 	 0.1401658058166504 	 
2025-07-30 14:35:01.860125 test begin: paddle.sgn(Tensor([12, 1058401, 2],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 1058401, 2],"float64"), ) 	 25401624 	 1000 	 0.30861401557922363 	 0.29909801483154297 	 0.28360748291015625 	 0.28238487243652344 	 0.2975730895996094 	 0.06387948989868164 	 0.23575806617736816 	 5.817413330078125e-05 	 
2025-07-30 14:35:03.937980 test begin: paddle.sgn(Tensor([12, 20, 105841],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 20, 105841],"float64"), ) 	 25401840 	 1000 	 0.30892372131347656 	 0.29900264739990234 	 0.28385090827941895 	 0.2823190689086914 	 0.29793739318847656 	 0.06488442420959473 	 0.23642992973327637 	 5.364418029785156e-05 	 
2025-07-30 14:35:05.971277 test begin: paddle.sgn(Tensor([12, 20, 211681],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 20, 211681],"float32"), ) 	 50803440 	 1000 	 0.345048189163208 	 0.29776906967163086 	 0.3210916519165039 	 0.28045153617858887 	 0.2956807613372803 	 0.06411576271057129 	 0.21340441703796387 	 4.76837158203125e-05 	 
2025-07-30 14:35:08.705021 test begin: paddle.sgn(Tensor([12, 2116801, 2],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 2116801, 2],"float32"), ) 	 50803224 	 1000 	 0.3446512222290039 	 0.2997167110443115 	 0.32888078689575195 	 0.28718137741088867 	 0.29561400413513184 	 0.05744171142578125 	 0.23912572860717773 	 6.008148193359375e-05 	 
2025-07-30 14:35:11.364680 test begin: paddle.sgn(Tensor([1270081, 20, 2],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([1270081, 20, 2],"float32"), ) 	 50803240 	 1000 	 0.3445303440093994 	 0.29777002334594727 	 0.32881760597229004 	 0.287229061126709 	 0.29555630683898926 	 0.05768084526062012 	 0.24028563499450684 	 3.361701965332031e-05 	 
2025-07-30 14:35:14.034540 test begin: paddle.sgn(Tensor([635041, 20, 2],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([635041, 20, 2],"float64"), ) 	 25401640 	 1000 	 0.3089115619659424 	 0.29900550842285156 	 0.29256486892700195 	 0.28870153427124023 	 0.2979722023010254 	 0.056865692138671875 	 0.24518060684204102 	 2.765655517578125e-05 	 
2025-07-30 14:35:16.100563 test begin: paddle.shape(Tensor([10, 1600, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([10, 1600, 376, 280],"float32"), ) 	 1684480000 	 1000 	 0.004262685775756836 	 0.030696630477905273 	 1.0728836059570312e-05 	 4.267692565917969e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:35:50.799751 test begin: paddle.shape(Tensor([130, 128, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([130, 128, 256, 256],"float16"), ) 	 1090519040 	 1000 	 0.004221439361572266 	 0.030519485473632812 	 1.5735626220703125e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:36:11.414315 test begin: paddle.shape(Tensor([40, 121, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 121, 376, 280],"float32"), ) 	 509555200 	 1000 	 0.0043866634368896484 	 0.03074812889099121 	 1.4781951904296875e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:36:19.709471 test begin: paddle.shape(Tensor([40, 128, 256, 388],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 388],"float32"), ) 	 508559360 	 1000 	 0.004288911819458008 	 0.030619144439697266 	 1.1444091796875e-05 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:36:28.074185 test begin: paddle.shape(Tensor([40, 128, 256, 776],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 776],"float16"), ) 	 1017118720 	 1000 	 0.004328727722167969 	 0.03044271469116211 	 1.4543533325195312e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:36:48.897386 test begin: paddle.shape(Tensor([40, 128, 388, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 388, 256],"float32"), ) 	 508559360 	 1000 	 0.004318714141845703 	 0.03079509735107422 	 1.239776611328125e-05 	 3.790855407714844e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:36:56.987620 test begin: paddle.shape(Tensor([40, 128, 776, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 776, 256],"float16"), ) 	 1017118720 	 1000 	 0.00433659553527832 	 0.03175497055053711 	 1.2874603271484375e-05 	 4.9591064453125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:37:16.135183 test begin: paddle.shape(Tensor([40, 1600, 29, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 29, 280],"float32"), ) 	 519680000 	 1000 	 0.006436824798583984 	 0.03184652328491211 	 3.719329833984375e-05 	 6.389617919921875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:37:24.424430 test begin: paddle.shape(Tensor([40, 1600, 376, 22],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 376, 22],"float32"), ) 	 529408000 	 1000 	 0.004346132278442383 	 0.03063678741455078 	 1.52587890625e-05 	 4.1961669921875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:37:33.014659 test begin: paddle.shape(Tensor([40, 194, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 194, 256, 256],"float32"), ) 	 508559360 	 1000 	 0.004322528839111328 	 0.03261446952819824 	 1.52587890625e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:37:41.347201 test begin: paddle.shape(Tensor([40, 388, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 388, 256, 256],"float16"), ) 	 1017118720 	 1000 	 0.0044329166412353516 	 0.031051158905029297 	 4.00543212890625e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:00.999835 test begin: paddle.shape(Tensor([70, 128, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([70, 128, 256, 256],"float32"), ) 	 587202560 	 1000 	 0.004370689392089844 	 0.03150153160095215 	 1.4066696166992188e-05 	 5.364418029785156e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:10.582536 test begin: paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ) 	 25401602 	 1000 	 0.30915403366088867 	 2.0364058017730713 	 0.30092453956604004 	 0.0006668567657470703 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:13.603337 test begin: paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, ) 	 25401602 	 1000 	 0.30911755561828613 	 2.041135787963867 	 0.3008251190185547 	 0.0006551742553710938 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:16.630155 test begin: paddle.shard_index(input=Tensor([25401601, 1],"int64"), index_num=13, nshards=3, shard_id=0, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([25401601, 1],"int64"), index_num=13, nshards=3, shard_id=0, ) 	 25401601 	 1000 	 0.3096013069152832 	 2.2340574264526367 	 0.30146121978759766 	 0.0007569789886474609 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:19.681239 test begin: paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ) 	 25401604 	 1000 	 0.3091421127319336 	 2.036520004272461 	 0.3010280132293701 	 0.0006623268127441406 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:22.713291 test begin: paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, ) 	 25401604 	 1000 	 0.3091247081756592 	 2.042965888977051 	 0.3006265163421631 	 0.0006535053253173828 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:38:25.733965 test begin: paddle.sign(Tensor([12404, 32, 128],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([12404, 32, 128],"float32"), ) 	 50806784 	 1000 	 0.3447706699371338 	 0.30373263359069824 	 0.3370034694671631 	 0.2871205806732178 	 0.29555511474609375 	 0.0663137435913086 	 0.24236702919006348 	 5.9604644775390625e-05 	 
2025-07-30 14:38:28.465991 test begin: paddle.sign(Tensor([32, 12404, 128],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([32, 12404, 128],"float32"), ) 	 50806784 	 1000 	 0.3448519706726074 	 0.2977919578552246 	 0.3371000289916992 	 0.28649377822875977 	 0.29558849334716797 	 0.05879616737365723 	 0.2425529956817627 	 5.555152893066406e-05 	 
2025-07-30 14:38:31.160149 test begin: paddle.sign(Tensor([32, 32, 49613],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([32, 32, 49613],"float32"), ) 	 50803712 	 1000 	 0.3450319766998291 	 0.29777050018310547 	 0.3371853828430176 	 0.2870631217956543 	 0.29566001892089844 	 0.05662870407104492 	 0.24228739738464355 	 2.9325485229492188e-05 	 
2025-07-30 14:38:33.840611 test begin: paddle.sign(Tensor([64, 1, 28, 28351],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1, 28, 28351],"float32"), ) 	 50804992 	 1000 	 0.3450942039489746 	 0.3129756450653076 	 0.3372504711151123 	 0.2870962619781494 	 0.29569196701049805 	 0.05742168426513672 	 0.24283385276794434 	 5.7220458984375e-05 	 
2025-07-30 14:38:40.433156 test begin: paddle.sign(Tensor([64, 1, 28351, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1, 28351, 28],"float32"), ) 	 50804992 	 1000 	 0.34498095512390137 	 0.3033428192138672 	 0.33719348907470703 	 0.2868766784667969 	 0.2957291603088379 	 0.07464027404785156 	 0.24216604232788086 	 4.124641418457031e-05 	 
2025-07-30 14:38:43.170913 test begin: paddle.sign(Tensor([64, 1013, 28, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1013, 28, 28],"float32"), ) 	 50828288 	 1000 	 0.34476399421691895 	 0.297990083694458 	 0.3299698829650879 	 0.28028202056884766 	 0.29576778411865234 	 0.06392502784729004 	 0.22996282577514648 	 4.6253204345703125e-05 	 
2025-07-30 14:38:45.861705 test begin: paddle.sign(Tensor([64801, 1, 28, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64801, 1, 28, 28],"float32"), ) 	 50803984 	 1000 	 0.34431982040405273 	 0.2977635860443115 	 0.33653759956359863 	 0.2851402759552002 	 0.29561448097229004 	 0.05720067024230957 	 0.24263978004455566 	 4.696846008300781e-05 	 
2025-07-30 14:38:48.527055 test begin: paddle.sign(Tensor([66151, 1, 384],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([66151, 1, 384],"int64"), ) 	 25401984 	 1000 	 0.30795788764953613 	 0.3000333309173584 	 0.3000946044921875 	 0.2883479595184326 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:38:50.266649 test begin: paddle.sign(Tensor([7, 1, 3628801],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([7, 1, 3628801],"int64"), ) 	 25401607 	 1000 	 0.3076303005218506 	 0.2990224361419678 	 0.299802303314209 	 0.287433385848999 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:38:52.028111 test begin: paddle.sign(Tensor([7, 9451, 384],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([7, 9451, 384],"int64"), ) 	 25404288 	 1000 	 0.3080117702484131 	 0.29915666580200195 	 0.3002128601074219 	 0.2886669635772705 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:38:53.768081 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([16, 3175201],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", ) 	 50803816 	 1000 	 19.39922046661377 	 4.761122226715088 	 2.4822094440460205 	 0.975555419921875 	 43.31946778297424 	 33.87761354446411 	 2.945972204208374 	 1.7282168865203857 	 
2025-07-30 14:40:41.420541 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([16, 3175201],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", ) 	 50804416 	 1000 	 19.76519465446472 	 4.980713844299316 	 2.52913236618042 	 1.0206272602081299 	 43.117531299591064 	 32.357118129730225 	 2.9326910972595215 	 1.6509242057800293 	 
2025-07-30 14:42:28.748733 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([1993, 25500],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", ) 	 50822100 	 1000 	 17.690210342407227 	 4.788547992706299 	 2.2639083862304688 	 0.9805600643157959 	 42.47517275810242 	 31.10704803466797 	 2.8886773586273193 	 1.5869200229644775 	 
2025-07-30 14:44:12.312651 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([1993, 25500],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", ) 	 50822700 	 1000 	 18.138174533843994 	 5.062593460083008 	 2.3209171295166016 	 1.0367159843444824 	 42.80032753944397 	 31.487853050231934 	 2.9110922813415527 	 1.6064996719360352 	 
2025-07-30 14:45:55.663578 test begin: paddle.signbit(Tensor([11, 17, 271],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 17, 271],"int32"), ) 	 50677 	 1000 	 2.1822307109832764 	 0.00995779037475586 	 2.47955322265625e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:45:57.900824 test begin: paddle.signbit(Tensor([11, 17, 543],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 17, 543],"int16"), ) 	 101541 	 1000 	 4.298291444778442 	 0.009947538375854492 	 4.601478576660156e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:02.249974 test begin: paddle.signbit(Tensor([11, 461, 10],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 461, 10],"int32"), ) 	 50710 	 1000 	 2.205080270767212 	 0.01656031608581543 	 3.7670135498046875e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:04.509305 test begin: paddle.signbit(Tensor([11, 923, 10],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 923, 10],"int16"), ) 	 101530 	 1000 	 4.147982835769653 	 0.010009050369262695 	 3.6716461181640625e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:08.705266 test begin: paddle.signbit(Tensor([12, 20, 211],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([12, 20, 211],"float32"), ) 	 50640 	 1000 	 2.1912498474121094 	 0.009904861450195312 	 3.552436828613281e-05 	 2.765655517578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:10.940790 test begin: paddle.signbit(Tensor([12, 2116, 2],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([12, 2116, 2],"float32"), ) 	 50784 	 1000 	 2.173992156982422 	 0.009877443313598633 	 3.0994415283203125e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:13.158179 test begin: paddle.signbit(Tensor([1270, 20, 2],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([1270, 20, 2],"float32"), ) 	 50800 	 1000 	 2.1851658821105957 	 0.009788274765014648 	 4.2438507080078125e-05 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:15.387666 test begin: paddle.signbit(Tensor([298, 17, 10],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([298, 17, 10],"int32"), ) 	 50660 	 1000 	 2.2712862491607666 	 0.009983062744140625 	 1.8596649169921875e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:17.705588 test begin: paddle.signbit(Tensor([597, 17, 10],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([597, 17, 10],"int16"), ) 	 101490 	 1000 	 4.224224328994751 	 0.009915351867675781 	 4.982948303222656e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:46:21.976839 test begin: paddle.sin(Tensor([128512, 396],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([128512, 396],"float32"), ) 	 50890752 	 1000 	 0.29611635208129883 	 0.29863572120666504 	 0.2872188091278076 	 0.2878389358520508 	 0.4506492614746094 	 0.7441234588623047 	 0.39528846740722656 	 0.38018321990966797 	 
2025-07-30 14:46:25.463339 test begin: paddle.sin(Tensor([254017, 200],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([254017, 200],"float32"), ) 	 50803400 	 1000 	 0.2954733371734619 	 0.2980644702911377 	 0.2864549160003662 	 0.28750014305114746 	 0.4496762752532959 	 0.7429685592651367 	 0.39432263374328613 	 0.37961435317993164 	 
2025-07-30 14:46:28.932737 test begin: paddle.sin(Tensor([50000, 1017],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([50000, 1017],"float32"), ) 	 50850000 	 1000 	 0.29583215713500977 	 0.2983551025390625 	 0.286771297454834 	 0.2877533435821533 	 0.45008111000061035 	 0.743649959564209 	 0.3947141170501709 	 0.37993812561035156 	 
2025-07-30 14:46:32.395419 test begin: paddle.sin(Tensor([508033, 100],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([508033, 100],"float32"), ) 	 50803300 	 1000 	 0.2954826354980469 	 0.2981083393096924 	 0.2865152359008789 	 0.2864208221435547 	 0.44974279403686523 	 0.7429904937744141 	 0.3942997455596924 	 0.37959742546081543 	 
2025-07-30 14:46:37.456020 test begin: paddle.sin(Tensor([68608, 741],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([68608, 741],"float32"), ) 	 50838528 	 1000 	 0.29573512077331543 	 0.3112931251525879 	 0.28678059577941895 	 0.2875490188598633 	 0.4501986503601074 	 0.7435157299041748 	 0.3951759338378906 	 0.3797779083251953 	 
2025-07-30 14:46:41.183367 test begin: paddle.sinc(Tensor([16, 1587601],"float64"), )
[Prof] paddle.sinc 	 paddle.sinc(Tensor([16, 1587601],"float64"), ) 	 25401616 	 1000 	 2.951925039291382 	 0.3011336326599121 	 0.25153613090515137 	 0.2905406951904297 	 2.5966968536376953 	 3.7658214569091797 	 0.44205188751220703 	 0.32057762145996094 	 
2025-07-30 14:46:51.937352 test begin: paddle.sinc(Tensor([396901, 64],"float64"), )
[Prof] paddle.sinc 	 paddle.sinc(Tensor([396901, 64],"float64"), ) 	 25401664 	 1000 	 2.950496196746826 	 0.7525925636291504 	 0.25136780738830566 	 0.2911651134490967 	 2.5965700149536133 	 3.7658579349517822 	 0.4420919418334961 	 0.3206357955932617 	 
2025-07-30 14:47:03.961873 test begin: paddle.sinh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29546213150024414 	 0.2981600761413574 	 0.28694772720336914 	 0.2877063751220703 	 0.44957947731018066 	 0.7431907653808594 	 0.3948178291320801 	 0.37973952293395996 	 
2025-07-30 14:47:07.423841 test begin: paddle.sinh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2954092025756836 	 0.2980949878692627 	 0.2868199348449707 	 0.287585973739624 	 0.44954729080200195 	 0.7431378364562988 	 0.3928256034851074 	 0.3796727657318115 	 
2025-07-30 14:47:10.881835 test begin: paddle.sinh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2954115867614746 	 0.29808902740478516 	 0.282930850982666 	 0.28762125968933105 	 0.4495425224304199 	 0.7432162761688232 	 0.3951094150543213 	 0.3797159194946289 	 
2025-07-30 14:47:14.360144 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0730 14:47:32.006055 32531 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016099200 	 1000 	 0.007941246032714844 	 0.013422250747680664 	 1.0251998901367188e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:47:34.826133 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0730 14:47:50.362076 32627 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016099200 	 1000 	 0.007734775543212891 	 0.013427972793579102 	 1.8596649169921875e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:47:52.966369 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0730 14:48:08.541800 32681 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016099200 	 1000 	 0.007627964019775391 	 0.013614892959594727 	 1.811981201171875e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:48:11.096426 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0730 14:48:26.369894 32730 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016076800 	 1000 	 0.00754094123840332 	 0.013523101806640625 	 1.2159347534179688e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:48:28.941299 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0730 14:48:44.187045 32792 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016076800 	 1000 	 0.007508039474487305 	 0.013554811477661133 	 1.1205673217773438e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:48:46.735640 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0730 14:49:04.746503 32851 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016076800 	 1000 	 0.007552146911621094 	 0.013563156127929688 	 1.1444091796875e-05 	 2.7894973754882812e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 14:49:10.991718 test begin: paddle.slice_scatter(Tensor([8, 1058401, 3, 9],"float32"), Tensor([8, 1058401, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 1058401, 3, 9],"float32"), Tensor([8, 1058401, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 279417864 	 1000 	 1.4698491096496582 	 2.847134828567505 	 1.4543633460998535 	 0.9693233966827393 	 4.04016375541687 	 3.790550947189331 	 0.687943696975708 	 0.7748515605926514 	 combined
2025-07-30 14:49:31.782781 test begin: paddle.slice_scatter(Tensor([8, 117601, 3, 9],"float64"), Tensor([8, 117601, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 117601, 3, 9],"float64"), Tensor([8, 117601, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 31046664 	 1000 	 0.23403263092041016 	 0.5571751594543457 	 0.21786785125732422 	 0.18755245208740234 	 0.8350391387939453 	 0.7764039039611816 	 0.14211010932922363 	 0.15855121612548828 	 combined
2025-07-30 14:49:37.443870 test begin: paddle.slice_scatter(Tensor([8, 235201, 3, 9],"float32"), Tensor([8, 235201, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 235201, 3, 9],"float32"), Tensor([8, 235201, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 62093064 	 1000 	 0.32823657989501953 	 0.645512580871582 	 0.3125934600830078 	 0.2184464931488037 	 0.9262754917144775 	 0.8677356243133545 	 0.1576826572418213 	 0.17734646797180176 	 combined
2025-07-30 14:49:42.026754 test begin: paddle.slice_scatter(Tensor([8, 529201, 3, 9],"float64"), Tensor([8, 529201, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 529201, 3, 9],"float64"), Tensor([8, 529201, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 139709064 	 1000 	 1.0579698085784912 	 2.456125259399414 	 1.042715311050415 	 0.8360304832458496 	 3.639119863510132 	 3.3947973251342773 	 0.6196048259735107 	 0.693702220916748 	 combined
2025-07-30 14:49:57.982066 test begin: paddle.slice_scatter(Tensor([8, 6, 117601, 9],"float32"), Tensor([8, 6, 117601, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 117601, 9],"float32"), Tensor([8, 6, 117601, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 62093328 	 1000 	 0.3283426761627197 	 0.6416730880737305 	 0.30603742599487305 	 0.21842360496520996 	 0.9331552982330322 	 0.8676497936248779 	 0.1588611602783203 	 0.17731428146362305 	 combined
2025-07-30 14:50:02.639487 test begin: paddle.slice_scatter(Tensor([8, 6, 211681, 5],"float32"), Tensor([8, 2, 211681, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 211681, 5],"float32"), Tensor([8, 2, 211681, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 67737920 	 1000 	 0.18334579467773438 	 0.41869020462036133 	 0.1682116985321045 	 0.14239096641540527 	 0.7749807834625244 	 0.5733041763305664 	 0.13196372985839844 	 0.11705493927001953 	 combined
2025-07-30 14:50:06.538105 test begin: paddle.slice_scatter(Tensor([8, 6, 264601, 9],"float64"), Tensor([8, 6, 264601, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 264601, 9],"float64"), Tensor([8, 6, 264601, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 139709328 	 1000 	 1.057943344116211 	 2.4823524951934814 	 1.0426344871520996 	 0.8362069129943848 	 3.6310293674468994 	 3.3948965072631836 	 0.6179025173187256 	 0.6937441825866699 	 combined
2025-07-30 14:50:23.535663 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 1058401],"float32"), Tensor([8, 2, 3, 1058401],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 1058401],"float32"), Tensor([8, 2, 3, 1058401],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 203212992 	 1000 	 0.5410194396972656 	 1.2311902046203613 	 0.5254771709442139 	 0.41878628730773926 	 2.28802752494812 	 1.6745030879974365 	 0.389606237411499 	 0.34197473526000977 	 combined
2025-07-30 14:50:34.977985 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 2, 3, 352801],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 2, 3, 352801],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 67737792 	 1000 	 0.18333172798156738 	 0.43234729766845703 	 0.16821503639221191 	 0.1424713134765625 	 0.7751834392547607 	 0.573145866394043 	 0.13201594352722168 	 0.11702084541320801 	 combined
2025-07-30 14:50:40.459046 test begin: paddle.slice_scatter(Tensor([8, 6, 529201, 9],"float32"), Tensor([8, 6, 529201, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 529201, 9],"float32"), Tensor([8, 6, 529201, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 279418128 	 1000 	 1.4704458713531494 	 2.8523058891296387 	 1.4550645351409912 	 0.9692370891571045 	 4.081035852432251 	 3.7905218601226807 	 0.694753885269165 	 0.7747938632965088 	 combined
2025-07-30 14:51:00.999181 test begin: paddle.slice_scatter(Tensor([8, 6, 58801, 9],"float64"), Tensor([8, 6, 58801, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 58801, 9],"float64"), Tensor([8, 6, 58801, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 31046928 	 1000 	 0.2339797019958496 	 0.5510318279266357 	 0.2186572551727295 	 0.18755340576171875 	 0.8316953182220459 	 0.7763910293579102 	 0.14163756370544434 	 0.15864801406860352 	 combined
2025-07-30 14:51:04.604733 test begin: paddle.slice_scatter(Tensor([8, 6, 635041, 5],"float32"), Tensor([8, 2, 635041, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 635041, 5],"float32"), Tensor([8, 2, 635041, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 203213120 	 1000 	 0.5412333011627197 	 1.2332043647766113 	 0.5195255279541016 	 0.4188063144683838 	 2.2861146926879883 	 1.674356460571289 	 0.38936853408813477 	 0.3419656753540039 	 combined
2025-07-30 14:51:16.184995 test begin: paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508035600 	 1000 	 0.0152587890625 	 4.228599309921265 	 1.0013580322265625e-05 	 1.0431194305419922 	 3.102904796600342 	 3.074514150619507 	 0.5274736881256104 	 0.6271755695343018 	 combined
2025-07-30 14:51:44.819129 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 254020320 	 1000 	 0.023658275604248047 	 3.0688531398773193 	 1.5020370483398438e-05 	 1.0431876182556152 	 3.096007823944092 	 3.0754756927490234 	 0.5262999534606934 	 0.6273119449615479 	 combined
2025-07-30 14:52:04.557476 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508036320 	 1000 	 0.015245437622070312 	 3.0737884044647217 	 1.0251998901367188e-05 	 1.043241024017334 	 3.085145950317383 	 3.0752196311950684 	 0.5244450569152832 	 0.6272697448730469 	 combined
2025-07-30 14:52:31.248949 test begin: paddle.sqrt(Tensor([128, 396901],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.29465794563293457 	 0.2988302707672119 	 0.28627538681030273 	 0.2884087562561035 	 0.45041513442993164 	 0.7466163635253906 	 0.3893473148345947 	 0.38149476051330566 	 
2025-07-30 14:52:34.753523 test begin: paddle.sqrt(Tensor([18, 15, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([18, 15, 3, 256, 256],"float32"), ) 	 53084160 	 1000 	 0.3072686195373535 	 0.31352853775024414 	 0.29892849922180176 	 0.30092954635620117 	 0.47042155265808105 	 0.7796931266784668 	 0.41432833671569824 	 0.3982126712799072 	 
2025-07-30 14:52:39.701108 test begin: paddle.sqrt(Tensor([259, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([259, 3, 256, 256],"float32"), ) 	 50921472 	 1000 	 0.2953226566314697 	 0.30245065689086914 	 0.27968835830688477 	 0.2822437286376953 	 0.45139265060424805 	 0.7483787536621094 	 0.38622140884399414 	 0.38236236572265625 	 
2025-07-30 14:52:43.205427 test begin: paddle.sqrt(Tensor([4, 15, 13, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 13, 256, 256],"float32"), ) 	 51118080 	 1000 	 0.29622459411621094 	 0.3007023334503174 	 0.28070902824401855 	 0.28352999687194824 	 0.4529726505279541 	 0.7512643337249756 	 0.3876466751098633 	 0.38376283645629883 	 
2025-07-30 14:52:46.711518 test begin: paddle.sqrt(Tensor([4, 15, 3, 1103, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 3, 1103, 256],"float32"), ) 	 50826240 	 1000 	 0.2947397232055664 	 0.2989685535430908 	 0.2792391777038574 	 0.2816276550292969 	 0.45052361488342285 	 0.7470059394836426 	 0.3860585689544678 	 0.3816492557525635 	 
2025-07-30 14:52:50.217009 test begin: paddle.sqrt(Tensor([4, 15, 3, 256, 1103],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 3, 256, 1103],"float32"), ) 	 50826240 	 1000 	 0.2947514057159424 	 0.2989487648010254 	 0.279155969619751 	 0.28192996978759766 	 0.45051097869873047 	 0.7469265460968018 	 0.3827781677246094 	 0.3815803527832031 	 
2025-07-30 14:52:53.694331 test begin: paddle.sqrt(Tensor([4, 65, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 65, 3, 256, 256],"float32"), ) 	 51118080 	 1000 	 0.29627132415771484 	 0.3009803295135498 	 0.2801210880279541 	 0.2832372188568115 	 0.4530372619628906 	 0.7513482570648193 	 0.38741302490234375 	 0.38379931449890137 	 
2025-07-30 14:52:57.295986 test begin: paddle.sqrt(Tensor([544, 93431],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([544, 93431],"float32"), ) 	 50826464 	 1000 	 0.2947256565093994 	 0.2989931106567383 	 0.27913355827331543 	 0.2820725440979004 	 0.4504873752593994 	 0.7470669746398926 	 0.38486409187316895 	 0.38172149658203125 	 
2025-07-30 14:53:00.793484 test begin: paddle.sqrt(Tensor([64, 13, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 13, 256, 256],"float32"), ) 	 54525952 	 1000 	 0.31577610969543457 	 0.3202240467071533 	 0.2946043014526367 	 0.3013424873352051 	 0.4830787181854248 	 0.800400972366333 	 0.4159669876098633 	 0.40887451171875 	 
2025-07-30 14:53:04.541682 test begin: paddle.sqrt(Tensor([64, 3, 1034, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 3, 1034, 256],"float32"), ) 	 50823168 	 1000 	 0.2946643829345703 	 0.3026132583618164 	 0.2790224552154541 	 0.28753042221069336 	 0.450502872467041 	 0.7471621036529541 	 0.38568568229675293 	 0.3818633556365967 	 
2025-07-30 14:53:08.037700 test begin: paddle.sqrt(Tensor([64, 3, 256, 1034],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 3, 256, 1034],"float32"), ) 	 50823168 	 1000 	 0.2946817874908447 	 0.2989325523376465 	 0.2863929271697998 	 0.2884073257446289 	 0.4504718780517578 	 0.7469789981842041 	 0.3949408531188965 	 0.38164472579956055 	 
2025-07-30 14:53:11.533728 test begin: paddle.square(Tensor([104, 488493],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([104, 488493],"float32"), ) 	 50803272 	 1000 	 0.29584288597106934 	 0.30207109451293945 	 0.28751277923583984 	 0.2860996723175049 	 0.44948577880859375 	 1.0553343296051025 	 0.39398932456970215 	 0.26979756355285645 	 
2025-07-30 14:53:15.297843 test begin: paddle.square(Tensor([128, 396901],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2958822250366211 	 0.2978663444519043 	 0.2876749038696289 	 0.2864034175872803 	 0.4494805335998535 	 1.0553796291351318 	 0.3942270278930664 	 0.26981115341186523 	 
2025-07-30 14:53:19.086069 test begin: paddle.square(Tensor([24904, 12, 170, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([24904, 12, 170, 1],"float32"), ) 	 50804160 	 1000 	 0.2957625389099121 	 0.2978837490081787 	 0.28753137588500977 	 0.28613948822021484 	 0.4494898319244385 	 1.055328130722046 	 0.39412808418273926 	 0.2698478698730469 	 
2025-07-30 14:53:22.820046 test begin: paddle.square(Tensor([3548, 12, 1194, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 12, 1194, 1],"float32"), ) 	 50835744 	 1000 	 0.2958083152770996 	 0.2980523109436035 	 0.28757810592651367 	 0.286395788192749 	 0.4498469829559326 	 1.056018352508545 	 0.3752925395965576 	 0.2700316905975342 	 
2025-07-30 14:53:26.606054 test begin: paddle.square(Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 12, 170, 8],"float32"), ) 	 57903360 	 1000 	 0.33654236793518066 	 0.3403627872467041 	 0.32825231552124023 	 0.32668638229370117 	 0.5118529796600342 	 1.2004244327545166 	 0.45696091651916504 	 0.30687808990478516 	 
2025-07-30 14:53:32.643915 test begin: paddle.square(Tensor([3548, 85, 170, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 85, 170, 1],"float32"), ) 	 51268600 	 1000 	 0.2984170913696289 	 0.3033473491668701 	 0.2829906940460205 	 0.28235745429992676 	 0.4536299705505371 	 1.0649502277374268 	 0.3896055221557617 	 0.27222251892089844 	 
2025-07-30 14:53:39.412196 test begin: paddle.square(Tensor([544, 93431],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([544, 93431],"float32"), ) 	 50826464 	 1000 	 0.29587221145629883 	 0.2979912757873535 	 0.2803218364715576 	 0.2798924446105957 	 0.44974422454833984 	 1.055741786956787 	 0.3857395648956299 	 0.26990818977355957 	 
2025-07-30 14:53:43.161689 test begin: paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.009397268295288086 	 0.0067098140716552734 	 2.09808349609375e-05 	 6.890296936035156e-05 	 0.04385066032409668 	 0.05712103843688965 	 3.8623809814453125e-05 	 4.9591064453125e-05 	 
2025-07-30 14:54:00.177338 test begin: paddle.squeeze(Tensor([1053440, 483],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([1053440, 483],"float32"), ) 	 508811520 	 1000 	 0.007855415344238281 	 0.006964921951293945 	 1.430511474609375e-05 	 2.384185791015625e-05 	 0.06248068809509277 	 0.05844235420227051 	 3.409385681152344e-05 	 3.8623809814453125e-05 	 
2025-07-30 14:54:16.923655 test begin: paddle.squeeze(Tensor([3969010, 128],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([3969010, 128],"float32"), ) 	 508033280 	 1000 	 0.0037031173706054688 	 0.003974199295043945 	 1.33514404296875e-05 	 3.6716461181640625e-05 	 0.0461273193359375 	 0.05197000503540039 	 4.172325134277344e-05 	 4.076957702636719e-05 	 
2025-07-30 14:54:38.015099 test begin: paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, ) 	 526400000 	 1000 	 0.004395723342895508 	 0.0039403438568115234 	 6.9141387939453125e-06 	 1.9311904907226562e-05 	 0.04399371147155762 	 0.05350828170776367 	 2.193450927734375e-05 	 3.910064697265625e-05 	 
2025-07-30 14:54:55.265071 test begin: paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, ) 	 522188800 	 1000 	 0.009031057357788086 	 0.007005453109741211 	 1.239776611328125e-05 	 2.2649765014648438e-05 	 0.05078840255737305 	 0.05935263633728027 	 3.8623809814453125e-05 	 5.125999450683594e-05 	 
2025-07-30 14:55:12.490204 test begin: paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, ) 	 508033000 	 1000 	 0.008904695510864258 	 0.006885051727294922 	 1.3589859008789062e-05 	 2.002716064453125e-05 	 0.050652265548706055 	 0.059166908264160156 	 3.600120544433594e-05 	 3.8623809814453125e-05 	 
2025-07-30 14:55:29.429305 test begin: paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.004462242126464844 	 0.004900693893432617 	 8.821487426757812e-06 	 2.002716064453125e-05 	 0.04379916191101074 	 0.057006120681762695 	 2.193450927734375e-05 	 3.528594970703125e-05 	 
2025-07-30 14:55:48.215112 test begin: paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.0045354366302490234 	 0.0048940181732177734 	 7.867813110351562e-06 	 2.0265579223632812e-05 	 0.046134233474731445 	 0.059438467025756836 	 3.0517578125e-05 	 6.818771362304688e-05 	 
2025-07-30 14:56:05.092145 test begin: paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], ) 	 819200000 	 1000 	 0.004507780075073242 	 0.005066871643066406 	 1.2874603271484375e-05 	 3.361701965332031e-05 	 0.0435028076171875 	 0.05718374252319336 	 3.8623809814453125e-05 	 5.125999450683594e-05 	 
2025-07-30 14:56:31.430574 test begin: paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], ) 	 508800000 	 1000 	 0.004426240921020508 	 0.004956245422363281 	 6.9141387939453125e-06 	 2.0503997802734375e-05 	 0.04381823539733887 	 0.058901071548461914 	 2.7894973754882812e-05 	 5.245208740234375e-05 	 
2025-07-30 14:56:48.239854 test begin: paddle.stack(list[Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),], axis=-2, ) 	 259269120 	 1000 	 1.8440871238708496 	 7.127629041671753 	 1.832690715789795 	 7.11060643196106 	 2.043623924255371 	 0.09412455558776855 	 1.9660520553588867 	 5.173683166503906e-05 	 
2025-07-30 14:57:07.886226 test begin: paddle.stack(list[Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),], axis=-2, ) 	 270103680 	 1000 	 1.9417386054992676 	 7.429484844207764 	 1.9305164813995361 	 7.411938667297363 	 2.125603437423706 	 0.10096263885498047 	 2.047883987426758 	 6.151199340820312e-05 	 
2025-07-30 14:57:28.319784 test begin: paddle.stack(list[Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),], axis=0, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),], axis=0, ) 	 609681408 	 1000 	 2.948328733444214 	 2.604748487472534 	 2.936938524246216 	 2.5629799365997314 	 4.610634803771973 	 2.701659679412842 	 4.503511190414429 	 1.3804705142974854 	 
2025-07-30 14:58:03.952154 test begin: paddle.stack(list[Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),], axis=0, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),], axis=0, ) 	 609681408 	 1000 	 2.948469638824463 	 2.591848850250244 	 2.9370269775390625 	 2.5752665996551514 	 4.610389471054077 	 2.701720714569092 	 4.504052400588989 	 1.3804209232330322 	 
2025-07-30 14:58:37.997874 test begin: paddle.stack(list[Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),], axis=-2, ) 	 282839040 	 1000 	 2.0259175300598145 	 8.160587310791016 	 2.0144755840301514 	 8.143107891082764 	 2.2364490032196045 	 0.09629416465759277 	 2.158400774002075 	 7.62939453125e-05 	 
2025-07-30 14:58:59.743435 test begin: paddle.stack(list[Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),], axis=-2, ) 	 294658560 	 1000 	 2.1214330196380615 	 8.492727041244507 	 2.110114574432373 	 8.4713294506073 	 2.3287768363952637 	 0.09484744071960449 	 2.250894784927368 	 6.437301635742188e-05 	 
2025-07-30 14:59:22.530538 test begin: paddle.stack(list[Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),], axis=-2, ) 	 254018560 	 1000 	 1.8111839294433594 	 6.98378324508667 	 1.7999157905578613 	 6.961321830749512 	 2.000624179840088 	 0.10225129127502441 	 1.9193015098571777 	 5.269050598144531e-05 	 
2025-07-30 14:59:41.942157 test begin: paddle.stack(list[Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),], axis=-2, ) 	 257826240 	 1000 	 1.8436241149902344 	 7.093427658081055 	 1.832409143447876 	 7.068460941314697 	 2.0333588123321533 	 0.13862824440002441 	 1.9131553173065186 	 6.127357482910156e-05 	 
2025-07-30 15:00:01.707160 test begin: paddle.stack(list[Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),], axis=-2, ) 	 259269120 	 1000 	 1.844547986984253 	 7.133419752120972 	 1.833214282989502 	 7.109579801559448 	 2.04321551322937 	 0.09682488441467285 	 1.9647374153137207 	 7.271766662597656e-05 	 
2025-07-30 15:00:21.442874 test begin: paddle.stanh(x=Tensor([12700801, 2],"float64"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([12700801, 2],"float64"), scale_a=6.42, scale_b=3.58, ) 	 25401602 	 1000 	 0.3057253360748291 	 0.3066561222076416 	 0.296633243560791 	 0.29642605781555176 	 0.4469490051269531 	 0.7415480613708496 	 0.39260125160217285 	 0.3788266181945801 	 
2025-07-30 15:00:24.327638 test begin: paddle.stanh(x=Tensor([2, 12700801],"float64"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 12700801],"float64"), scale_a=6.42, scale_b=3.58, ) 	 25401602 	 1000 	 0.30570220947265625 	 0.30666017532348633 	 0.29668331146240234 	 0.2962374687194824 	 0.4458158016204834 	 0.7415652275085449 	 0.3911759853363037 	 0.378828763961792 	 
2025-07-30 15:00:27.183289 test begin: paddle.stanh(x=Tensor([2, 25401601],"float32"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 25401601],"float32"), scale_a=6.42, scale_b=3.58, ) 	 50803202 	 1000 	 0.29477477073669434 	 0.29871296882629395 	 0.28569698333740234 	 0.28836965560913086 	 0.4499063491821289 	 0.7424056529998779 	 0.39502596855163574 	 0.37932586669921875 	 
2025-07-30 15:00:30.607132 test begin: paddle.stanh(x=Tensor([2, 3, 2, 2116801],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3, 2, 2116801],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.2995755672454834 	 0.30037879943847656 	 0.29050207138061523 	 0.289975643157959 	 0.44893908500671387 	 0.7416913509368896 	 0.39415931701660156 	 0.3789174556732178 	 
2025-07-30 15:00:33.460422 test begin: paddle.stanh(x=Tensor([2, 3, 2116801, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3, 2116801, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.29953765869140625 	 0.5913925170898438 	 0.2903618812561035 	 0.2898130416870117 	 0.4476935863494873 	 0.7415122985839844 	 0.3928868770599365 	 0.3787970542907715 	 
2025-07-30 15:00:39.620184 test begin: paddle.stanh(x=Tensor([2, 3175201, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3175201, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401608 	 1000 	 0.29960155487060547 	 0.30030131340026855 	 0.2904508113861084 	 0.2897500991821289 	 0.4474771022796631 	 0.7416682243347168 	 0.3928215503692627 	 0.3789048194885254 	 
2025-07-30 15:00:42.457605 test begin: paddle.stanh(x=Tensor([2116801, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2116801, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.2995920181274414 	 0.3026237487792969 	 0.290299654006958 	 0.28993749618530273 	 0.44745421409606934 	 0.7429721355438232 	 0.38499999046325684 	 0.38025474548339844 	 
2025-07-30 15:00:45.328926 test begin: paddle.stanh(x=Tensor([25401601, 2],"float32"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([25401601, 2],"float32"), scale_a=6.42, scale_b=3.58, ) 	 50803202 	 1000 	 0.2947533130645752 	 0.29871392250061035 	 0.28559088706970215 	 0.2882215976715088 	 0.44993114471435547 	 0.7423632144927979 	 0.3941793441772461 	 0.3793141841888428 	 
2025-07-30 15:00:48.840334 test begin: paddle.std(Tensor([1, 1270081, 4, 10],"float32"), list[1,3,], True, False, )
W0730 15:00:49.602576 39163 dygraph_functions.cc:88394] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.std 	 paddle.std(Tensor([1, 1270081, 4, 10],"float32"), list[1,3,], True, False, ) 	 50803240 	 1000 	 1.2635951042175293 	 0.2314009666442871 	 1.8835067749023438e-05 	 0.11820793151855469 	 1.423633337020874 	 0.8036830425262451 	 0.1822071075439453 	 0.09155845642089844 	 
2025-07-30 15:00:53.404923 test begin: paddle.std(Tensor([1, 3, 1693441, 10],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 1693441, 10],"float32"), list[1,3,], True, False, ) 	 50803230 	 1000 	 1.5325920581817627 	 0.7936601638793945 	 3.7670135498046875e-05 	 0.7756595611572266 	 1.6488592624664307 	 1.077003002166748 	 0.2407069206237793 	 0.1376194953918457 	 
2025-07-30 15:00:59.317839 test begin: paddle.std(Tensor([1, 3, 4, 2116801],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 4, 2116801],"float64"), 2, True, False, ) 	 25401612 	 1000 	 1.6446342468261719 	 0.21912002563476562 	 0.0001239776611328125 	 0.2017364501953125 	 2.023012161254883 	 1.4884366989135742 	 0.29660677909851074 	 0.19032049179077148 	 
2025-07-30 15:01:05.417258 test begin: paddle.std(Tensor([1, 3, 4, 4233601],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 4, 4233601],"float32"), list[1,3,], True, False, ) 	 50803212 	 1000 	 1.2122013568878174 	 0.2341625690460205 	 2.002716064453125e-05 	 0.11963057518005371 	 1.4036855697631836 	 0.7969105243682861 	 0.17964577674865723 	 0.09063959121704102 	 
2025-07-30 15:01:11.040295 test begin: paddle.std(Tensor([1, 3, 846721, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 846721, 10],"float64"), 2, True, False, ) 	 25401630 	 1000 	 7.974486589431763 	 0.18543195724487305 	 5.626678466796875e-05 	 0.09472179412841797 	 4.809865474700928 	 0.7798514366149902 	 0.6154718399047852 	 0.08884191513061523 	 
2025-07-30 15:01:25.383681 test begin: paddle.std(Tensor([1, 635041, 4, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 635041, 4, 10],"float64"), 2, True, False, ) 	 25401640 	 1000 	 1.761751651763916 	 0.19855403900146484 	 0.00011420249938964844 	 0.18105840682983398 	 1.9415183067321777 	 1.270904779434204 	 0.28342580795288086 	 0.16227412223815918 	 
2025-07-30 15:01:31.276674 test begin: paddle.std(Tensor([1587601, 32],"float32"), )
[Prof] paddle.std 	 paddle.std(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 1.0961556434631348 	 0.16652154922485352 	 2.0742416381835938e-05 	 0.08510279655456543 	 1.340085744857788 	 0.775651216506958 	 0.1715235710144043 	 0.08834242820739746 	 
2025-07-30 15:01:39.750425 test begin: paddle.std(Tensor([211681, 3, 4, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([211681, 3, 4, 10],"float64"), 2, True, False, ) 	 25401720 	 1000 	 1.7590267658233643 	 0.20288825035095215 	 0.00010275840759277344 	 0.1749553680419922 	 1.9373431205749512 	 1.2696521282196045 	 0.28282952308654785 	 0.1622624397277832 	 
2025-07-30 15:01:45.645322 test begin: paddle.std(Tensor([32, 1587601],"float32"), )
[Prof] paddle.std 	 paddle.std(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 1.0956974029541016 	 0.1677711009979248 	 1.9073486328125e-05 	 0.08502697944641113 	 1.3399386405944824 	 0.7765567302703857 	 0.17151117324829102 	 0.08842706680297852 	 
2025-07-30 15:01:49.934135 test begin: paddle.std(Tensor([423361, 3, 4, 10],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([423361, 3, 4, 10],"float32"), list[1,3,], True, False, ) 	 50803320 	 1000 	 1.5657823085784912 	 0.840552806854248 	 3.9577484130859375e-05 	 0.8070955276489258 	 1.6369988918304443 	 1.103142261505127 	 0.23877334594726562 	 0.14114117622375488 	 
2025-07-30 15:01:55.984864 test begin: paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 25486272 	 1000 	 0.005694866180419922 	 0.21001291275024414 	 6.67572021484375e-06 	 6.079673767089844e-05 	 0.15166234970092773 	 0.2502710819244385 	 0.07160663604736328 	 0.009282112121582031 	 combined
2025-07-30 15:01:57.181887 test begin: paddle.subtract(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), ) 	 101608320 	 1000 	 0.4498307704925537 	 0.44608330726623535 	 0.4403829574584961 	 0.4348721504211426 	 0.4722621440887451 	 0.2978091239929199 	 0.41172122955322266 	 0.22162389755249023 	 
2025-07-30 15:02:01.319308 test begin: paddle.subtract(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), ) 	 101671488 	 1000 	 0.449815034866333 	 0.44636082649230957 	 0.440509557723999 	 0.43518614768981934 	 0.4734616279602051 	 0.29791927337646484 	 0.4131596088409424 	 0.22252798080444336 	 
2025-07-30 15:02:05.454441 test begin: paddle.subtract(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), ) 	 65141280 	 1000 	 0.35719752311706543 	 0.3700439929962158 	 0.3467593193054199 	 0.3433229923248291 	 0.8870816230773926 	 0.8980526924133301 	 0.4531733989715576 	 0.4588327407836914 	 
2025-07-30 15:02:09.987209 test begin: paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), ) 	 65141280 	 1000 	 0.3569653034210205 	 0.37000036239624023 	 0.3465461730957031 	 0.35775184631347656 	 0.8152167797088623 	 0.8982350826263428 	 0.2776026725769043 	 0.4589099884033203 	 
2025-07-30 15:02:14.407610 test begin: paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), ) 	 115806720 	 1000 	 0.5118815898895264 	 0.5103003978729248 	 0.5025634765625 	 0.4961576461791992 	 0.5381934642791748 	 0.3385024070739746 	 0.4783501625061035 	 0.257735013961792 	 
2025-07-30 15:02:21.551472 test begin: paddle.subtract(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), ) 	 102537200 	 1000 	 0.4538562297821045 	 0.45008373260498047 	 0.444561243057251 	 0.4389917850494385 	 0.477344274520874 	 0.3003199100494385 	 0.41684961318969727 	 0.22664237022399902 	 
2025-07-30 15:02:25.805113 test begin: paddle.subtract(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), ) 	 101646336 	 1000 	 0.44996166229248047 	 0.44626641273498535 	 0.44057345390319824 	 0.435044527053833 	 0.4729917049407959 	 0.2978949546813965 	 0.41325879096984863 	 0.22343134880065918 	 
2025-07-30 15:02:29.931078 test begin: paddle.subtract(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), ) 	 101670912 	 1000 	 0.44997239112854004 	 0.44634580612182617 	 0.4406008720397949 	 0.43491601943969727 	 0.47301220893859863 	 0.297940731048584 	 0.4120616912841797 	 0.22380757331848145 	 
2025-07-30 15:02:34.109588 test begin: paddle.subtract(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), ) 	 101744640 	 1000 	 0.45031189918518066 	 0.4550638198852539 	 0.44085025787353516 	 0.4347875118255615 	 0.4736511707305908 	 0.29808807373046875 	 0.4123499393463135 	 0.22259950637817383 	 
2025-07-30 15:02:40.111773 test begin: paddle.subtract(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), ) 	 103809024 	 1000 	 0.4594273567199707 	 0.45566868782043457 	 0.44997262954711914 	 0.4443178176879883 	 0.48506617546081543 	 0.30416345596313477 	 0.4249131679534912 	 0.23059868812561035 	 
2025-07-30 15:02:44.360426 test begin: paddle.subtract(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), ) 	 103809024 	 1000 	 0.4594097137451172 	 0.4556162357330322 	 0.45002222061157227 	 0.4441511631011963 	 0.48518848419189453 	 0.30412817001342773 	 0.4253044128417969 	 0.2296764850616455 	 
2025-07-30 15:02:48.556599 test begin: paddle.subtract(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), ) 	 104857600 	 1000 	 0.46422433853149414 	 0.4602506160736084 	 0.4548943042755127 	 0.4489307403564453 	 0.48688769340515137 	 0.3069462776184082 	 0.4214146137237549 	 0.23287582397460938 	 
2025-07-30 15:02:52.869706 test begin: paddle.subtract(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), ) 	 101646336 	 1000 	 0.45136427879333496 	 0.4462711811065674 	 0.44205522537231445 	 0.4348158836364746 	 0.4728879928588867 	 0.29789233207702637 	 0.4131133556365967 	 0.22360777854919434 	 
2025-07-30 15:02:57.015930 test begin: paddle.subtract(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), ) 	 101646336 	 1000 	 0.45147037506103516 	 0.4463169574737549 	 0.4416999816894531 	 0.42834901809692383 	 0.47289538383483887 	 0.29782962799072266 	 0.4031224250793457 	 0.21683859825134277 	 
2025-07-30 15:03:01.568698 test begin: paddle.subtract(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), ) 	 101744640 	 1000 	 0.4502685070037842 	 0.44756031036376953 	 0.44100475311279297 	 0.434767484664917 	 0.4736762046813965 	 0.2981221675872803 	 0.4135556221008301 	 0.2233436107635498 	 
2025-07-30 15:03:05.747693 test begin: paddle.sum(Tensor([3544, 32, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([3544, 32, 896],"bfloat16"), axis=1, keepdim=False, ) 	 101613568 	 1000 	 0.17036128044128418 	 0.16005229949951172 	 0.1587986946105957 	 0.14513754844665527 	 0.268355131149292 	 0.0985875129699707 	 0.2068185806274414 	 5.745887756347656e-05 	 
2025-07-30 15:03:08.321734 test begin: paddle.sum(Tensor([6017, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6017, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 102433408 	 1000 	 0.1745004653930664 	 0.17522931098937988 	 0.16303157806396484 	 0.16055607795715332 	 0.27080368995666504 	 0.09235191345214844 	 0.20917177200317383 	 4.315376281738281e-05 	 
2025-07-30 15:03:10.870671 test begin: paddle.sum(Tensor([6017, 32, 528],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6017, 32, 528],"bfloat16"), axis=1, keepdim=False, ) 	 101663232 	 1000 	 0.18287277221679688 	 0.16240668296813965 	 0.17128539085388184 	 0.14765191078186035 	 0.2702620029449463 	 0.10115885734558105 	 0.20847439765930176 	 4.1484832763671875e-05 	 
2025-07-30 15:03:13.331406 test begin: paddle.sum(Tensor([6036, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6036, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 102756864 	 1000 	 0.17495346069335938 	 0.17581915855407715 	 0.16324877738952637 	 0.15981745719909668 	 0.27170443534851074 	 0.08543729782104492 	 0.20972394943237305 	 3.719329833984375e-05 	 
2025-07-30 15:03:15.763961 test begin: paddle.sum(Tensor([6036, 32, 527],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6036, 32, 527],"bfloat16"), axis=1, keepdim=False, ) 	 101791104 	 1000 	 0.18537688255310059 	 0.1796414852142334 	 0.17386937141418457 	 0.16463279724121094 	 0.26903581619262695 	 0.08655571937561035 	 0.20713067054748535 	 6.437301635742188e-05 	 
2025-07-30 15:03:18.171762 test begin: paddle.sum(Tensor([6078, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6078, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 103471872 	 1000 	 0.17626571655273438 	 0.1769413948059082 	 0.16406011581420898 	 0.16173624992370605 	 0.2735583782196045 	 0.09761548042297363 	 0.21176481246948242 	 4.553794860839844e-05 	 
2025-07-30 15:03:20.717599 test begin: paddle.sum(Tensor([6078, 32, 523],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6078, 32, 523],"bfloat16"), axis=1, keepdim=False, ) 	 101721408 	 1000 	 0.18131303787231445 	 0.6302344799041748 	 0.16970229148864746 	 0.16028404235839844 	 0.26889872550964355 	 0.08414626121520996 	 0.2071826457977295 	 4.220008850097656e-05 	 
2025-07-30 15:03:24.327116 test begin: paddle.t(Tensor([100, 5080321],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.0040721893310546875 	 0.003665924072265625 	 1.1920928955078125e-05 	 1.811981201171875e-05 	 0.04245352745056152 	 0.05645442008972168 	 4.315376281738281e-05 	 3.719329833984375e-05 	 
2025-07-30 15:03:40.878105 test begin: paddle.t(Tensor([200, 2540161],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.00397491455078125 	 0.003667116165161133 	 8.58306884765625e-06 	 1.8835067749023438e-05 	 0.042247772216796875 	 0.05847334861755371 	 3.62396240234375e-05 	 6.151199340820312e-05 	 
2025-07-30 15:03:57.609411 test begin: paddle.t(Tensor([25401610, 20],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.0040781497955322266 	 0.0036411285400390625 	 1.2159347534179688e-05 	 1.6927719116210938e-05 	 0.0435786247253418 	 0.056075096130371094 	 2.7894973754882812e-05 	 3.743171691894531e-05 	 
2025-07-30 15:04:14.300395 test begin: paddle.t(Tensor([496130, 512],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([496130, 512],"int64"), ) 	 254018560 	 1000 	 0.004042863845825195 	 0.00368499755859375 	 1.0728836059570312e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:04:22.471486 test begin: paddle.t(Tensor([50803210, 10],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([50803210, 10],"float32"), ) 	 508032100 	 1000 	 0.004005908966064453 	 0.0036725997924804688 	 8.821487426757812e-06 	 1.9073486328125e-05 	 0.04188275337219238 	 0.05861854553222656 	 2.288818359375e-05 	 6.985664367675781e-05 	 
2025-07-30 15:04:41.245797 test begin: paddle.t(Tensor([5120, 49613],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([5120, 49613],"int64"), ) 	 254018560 	 1000 	 0.0040934085845947266 	 0.003703594207763672 	 8.821487426757812e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:04:49.331061 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", ) 	 76204806 	 1000 	 3.1953341960906982 	 2.9138095378875732 	 0.6542854309082031 	 0.42487144470214844 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:02.060837 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803807 	 1000 	 0.08802080154418945 	 0.12098145484924316 	 2.6941299438476562e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:03.260773 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([6350401, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([6350401, 3],"int64"), mode="raise", ) 	 69854407 	 1000 	 2.4123497009277344 	 2.197309732437134 	 0.5002267360687256 	 0.3205840587615967 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:13.278937 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 3],"int64"), mode="raise", ) 	 50803209 	 1000 	 0.08623218536376953 	 0.12025332450866699 	 1.3589859008789062e-05 	 5.3882598876953125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:14.453784 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 8467201],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 8467201],"int64"), mode="raise", ) 	 67737605 	 1000 	 2.1448869705200195 	 1.9580905437469482 	 0.44022369384765625 	 0.28563809394836426 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:23.289976 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803806 	 1000 	 0.0880730152130127 	 0.12172913551330566 	 2.4318695068359375e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:24.475572 test begin: paddle.take(Tensor([3, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", ) 	 25401614 	 1000 	 1.5484237670898438 	 1.1749498844146729 	 0.3177776336669922 	 0.1669001579284668 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:42.914425 test begin: paddle.take(Tensor([3, 4],"float32"), Tensor([8467201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float32"), Tensor([8467201, 3],"int64"), mode="raise", ) 	 25401615 	 1000 	 1.5484340190887451 	 1.1470036506652832 	 0.31635522842407227 	 0.16690731048583984 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:05:57.147348 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="clip", ) 	 25401620 	 1000 	 0.6462719440460205 	 0.6092898845672607 	 0.32947397232055664 	 0.3084714412689209 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:06:14.850323 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="wrap", ) 	 25401620 	 1000 	 3.3531932830810547 	 1.2011115550994873 	 0.3115088939666748 	 0.3067805767059326 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:06:37.399446 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="clip", ) 	 25401617 	 1000 	 0.6449308395385742 	 0.6039481163024902 	 0.3295094966888428 	 0.30849432945251465 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:06:55.066112 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="wrap", ) 	 25401617 	 1000 	 3.3531808853149414 	 1.2042315006256104 	 0.3115558624267578 	 0.306865930557251 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:16.052710 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="clip", ) 	 67737608 	 1000 	 3.9911158084869385 	 4.008329391479492 	 2.040004014968872 	 2.0487186908721924 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:34.567792 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="wrap", ) 	 67737608 	 1000 	 8.468096017837524 	 5.014119863510132 	 0.7870075702667236 	 1.2792418003082275 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:58.539106 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="wrap", ) 	 25401643 	 1000 	 0.14944911003112793 	 0.07442760467529297 	 2.574920654296875e-05 	 6.079673767089844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:07:59.444153 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", ) 	 25405611 	 1000 	 0.05791735649108887 	 0.043799400329589844 	 2.8133392333984375e-05 	 4.696846008300781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:00.217054 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", ) 	 25401644 	 1000 	 0.1586623191833496 	 0.07302427291870117 	 2.5987625122070312e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:01.134288 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="clip", ) 	 76204812 	 1000 	 4.7849650382995605 	 4.806419134140015 	 2.4458167552948 	 2.455203056335449 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:23.077089 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="wrap", ) 	 76204812 	 1000 	 10.147024631500244 	 5.990678310394287 	 0.9445078372955322 	 1.533109426498413 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:51.638493 test begin: paddle.take_along_axis(Tensor([1024, 384],"float32"), Tensor([1024, 24807],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 384],"float32"), Tensor([1024, 24807],"int64"), axis=-1, ) 	 25795584 	 1000 	 0.5823771953582764 	 0.7646932601928711 	 0.19829845428466797 	 0.21953725814819336 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:08:57.981848 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 24807],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 24807],"int64"), axis=-1, ) 	 76206080 	 1000 	 1.0041329860687256 	 0.44134068489074707 	 0.34207916259765625 	 0.42343568801879883 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:09:03.860998 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 7],"int64"), axis=-1, ) 	 50810880 	 1000 	 0.30437731742858887 	 0.01720595359802246 	 0.10378026962280273 	 3.1948089599609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:09:05.470542 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 8],"int64"), axis=-1, ) 	 50811904 	 1000 	 0.30449938774108887 	 0.017171621322631836 	 0.10380077362060547 	 3.1948089599609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:09:07.073362 test begin: paddle.take_along_axis(Tensor([1051, 63, 768],"float32"), axis=1, indices=Tensor([1051, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1051, 63, 768],"float32"), axis=1, indices=Tensor([1051, 7, 768],"int64"), ) 	 56501760 	 1000 	 0.5524759292602539 	 0.30684590339660645 	 0.1882946491241455 	 0.2890141010284424 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:09:09.910822 test begin: paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 7],"int64"), axis=-1, ) 	 51729691 	 1000 	 0.3644874095916748 	 0.0574488639831543 	 0.12421846389770508 	 0.04022526741027832 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:09:11.794906 test begin: paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 8],"int64"), axis=-1, ) 	 51861992 	 1000 	 0.3715832233428955 	 0.06444239616394043 	 0.12670230865478516 	 0.044944047927856445 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:09:13.743666 test begin: paddle.take_along_axis(Tensor([3175201, 384],"float32"), Tensor([3175201, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([3175201, 384],"float32"), Tensor([3175201, 8],"int64"), axis=-1, ) 	 1244678792 	 1000 	 8.608670473098755 	 1.3760685920715332 	 2.9362406730651855 	 0.35088562965393066 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:10:02.727867 test begin: paddle.take_along_axis(Tensor([3628801, 384],"float32"), Tensor([3628801, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([3628801, 384],"float32"), Tensor([3628801, 7],"int64"), axis=-1, ) 	 1418861191 	 1000 	 9.650671243667603 	 1.4196572303771973 	 3.2911036014556885 	 0.36269450187683105 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:10:56.453329 test begin: paddle.take_along_axis(Tensor([4726, 63, 768],"float32"), axis=1, indices=Tensor([4726, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([4726, 63, 768],"float32"), axis=1, indices=Tensor([4726, 7, 768],"int64"), ) 	 254069760 	 1000 	 2.429553508758545 	 1.841332197189331 	 0.8281607627868652 	 1.3521647453308105 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:13.405982 test begin: paddle.take_along_axis(Tensor([8, 63, 100801],"float32"), axis=1, indices=Tensor([8, 7, 100801],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 100801],"float32"), axis=1, indices=Tensor([8, 7, 100801],"int64"), ) 	 56448560 	 1000 	 0.5728359222412109 	 0.3086836338043213 	 0.19485878944396973 	 0.2889134883880615 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:16.399233 test begin: paddle.take_along_axis(Tensor([8, 63, 453601],"float32"), axis=1, indices=Tensor([8, 7, 453601],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 453601],"float32"), axis=1, indices=Tensor([8, 7, 453601],"int64"), ) 	 254016560 	 1000 	 3.0378003120422363 	 1.5871901512145996 	 1.0351719856262207 	 1.5690875053405762 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:33.122820 test begin: paddle.take_along_axis(Tensor([8, 63, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), ) 	 25792512 	 1000 	 0.602867603302002 	 0.2885935306549072 	 0.2053070068359375 	 0.267564058303833 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:39.220933 test begin: paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), ) 	 76210176 	 1000 	 1.3519458770751953 	 0.9505105018615723 	 0.4607584476470947 	 0.9323508739471436 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:46.539308 test begin: paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 7, 768],"int64"), ) 	 50847744 	 1000 	 0.3075852394104004 	 0.02240133285522461 	 0.10489916801452637 	 4.9591064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:11:48.201974 test begin: paddle.tan(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.294999361038208 	 0.2981083393096924 	 0.2866988182067871 	 0.2875936031341553 	 0.45128417015075684 	 1.040027379989624 	 0.39644360542297363 	 0.3543367385864258 	 
2025-07-30 15:11:51.944339 test begin: paddle.tan(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.295015811920166 	 0.30096435546875 	 0.2794055938720703 	 0.28128862380981445 	 0.45121192932128906 	 1.0400683879852295 	 0.3870382308959961 	 0.35430479049682617 	 
2025-07-30 15:11:55.686574 test begin: paddle.tan(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29502367973327637 	 0.29817700386047363 	 0.2792980670928955 	 0.28096532821655273 	 0.452528715133667 	 1.0401465892791748 	 0.3880007266998291 	 0.3543434143066406 	 
2025-07-30 15:11:59.727720 test begin: paddle.tanh(Tensor([16, 125, 25500],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([16, 125, 25500],"float32"), ) 	 51000000 	 1000 	 0.2966654300689697 	 0.30350804328918457 	 0.2880856990814209 	 0.2893211841583252 	 0.45119404792785645 	 0.4477040767669678 	 0.3953268527984619 	 0.3805661201477051 	 
2025-07-30 15:12:02.983884 test begin: paddle.tanh(Tensor([16, 64, 49613],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([16, 64, 49613],"float32"), ) 	 50803712 	 1000 	 0.29545044898986816 	 0.2980923652648926 	 0.28685760498046875 	 0.2876574993133545 	 0.4495372772216797 	 0.44613051414489746 	 0.3937263488769531 	 0.3772587776184082 	 
2025-07-30 15:12:06.183406 test begin: paddle.tanh(Tensor([28, 32, 241, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([28, 32, 241, 241],"float32"), ) 	 52040576 	 1000 	 0.3024773597717285 	 0.30515432357788086 	 0.29378485679626465 	 0.2942984104156494 	 0.4602987766265869 	 0.4568367004394531 	 0.38976550102233887 	 0.38971734046936035 	 
2025-07-30 15:12:09.431294 test begin: paddle.tanh(Tensor([32, 64, 25500],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([32, 64, 25500],"float32"), ) 	 52224000 	 1000 	 0.3035280704498291 	 0.3160734176635742 	 0.2949068546295166 	 0.29578423500061035 	 0.46202826499938965 	 0.45964884757995605 	 0.4063451290130615 	 0.39331769943237305 	 
2025-07-30 15:12:13.693949 test begin: paddle.tanh(Tensor([64, 26, 512, 1, 60],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 512, 1, 60],"float32"), ) 	 51118080 	 1000 	 0.29702043533325195 	 0.30538487434387207 	 0.2884366512298584 	 0.2893824577331543 	 0.45230650901794434 	 0.4487590789794922 	 0.39684128761291504 	 0.3682081699371338 	 
2025-07-30 15:12:16.838831 test begin: paddle.tanh(Tensor([64, 26, 512, 2, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 512, 2, 40],"float32"), ) 	 68157440 	 1000 	 0.3959310054779053 	 0.3977656364440918 	 0.387347936630249 	 0.3871276378631592 	 0.6015231609344482 	 0.5967872142791748 	 0.5460906028747559 	 0.5275852680206299 	 
2025-07-30 15:12:21.057492 test begin: paddle.tanh(Tensor([64, 26, 764, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 764, 1, 40],"float32"), ) 	 50851840 	 1000 	 0.29555845260620117 	 0.2983410358428955 	 0.2869374752044678 	 0.28780674934387207 	 0.4500153064727783 	 0.4464986324310303 	 0.38898682594299316 	 0.37726783752441406 	 
2025-07-30 15:12:24.234933 test begin: paddle.tanh(Tensor([64, 39, 512, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 39, 512, 1, 40],"float32"), ) 	 51118080 	 1000 	 0.2970092296600342 	 0.29993414878845215 	 0.2884078025817871 	 0.2893970012664795 	 0.45223069190979004 	 0.4502067565917969 	 0.39562296867370605 	 0.3823666572570801 	 
2025-07-30 15:12:27.403489 test begin: paddle.tanh(Tensor([8, 110, 241, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 110, 241, 241],"float32"), ) 	 51111280 	 1000 	 0.29705309867858887 	 0.29993128776550293 	 0.2885780334472656 	 0.289017915725708 	 0.4521067142486572 	 0.4486863613128662 	 0.39656805992126465 	 0.3800370693206787 	 
2025-07-30 15:12:30.581400 test begin: paddle.tanh(Tensor([8, 32, 241, 824],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 32, 241, 824],"float32"), ) 	 50837504 	 1000 	 0.295501708984375 	 0.29944944381713867 	 0.28698134422302246 	 0.2867610454559326 	 0.4497964382171631 	 0.4464147090911865 	 0.39357709884643555 	 0.3798210620880127 	 
2025-07-30 15:12:33.720634 test begin: paddle.tanh(Tensor([8, 32, 824, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 32, 824, 241],"float32"), ) 	 50837504 	 1000 	 0.2954730987548828 	 0.31030821800231934 	 0.28690409660339355 	 0.2876136302947998 	 0.44991016387939453 	 0.4463977813720703 	 0.39263010025024414 	 0.3793015480041504 	 
2025-07-30 15:12:38.955236 test begin: paddle.tanh(Tensor([96, 26, 512, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([96, 26, 512, 1, 40],"float32"), ) 	 51118080 	 1000 	 0.29702305793762207 	 0.29995107650756836 	 0.288501501083374 	 0.28933095932006836 	 0.4522535800933838 	 0.4487576484680176 	 0.3969228267669678 	 0.38101935386657715 	 
2025-07-30 15:12:42.160318 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, )
W0730 15:12:49.046280 53951 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.02358078956604004 	 0.007869958877563477 	 1.0728836059570312e-05 	 3.719329833984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:12:50.269521 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0730 15:12:57.292078 54121 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.030533552169799805 	 0.009101152420043945 	 9.5367431640625e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:12:58.425477 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0730 15:13:05.412048 54289 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.04016923904418945 	 0.01282811164855957 	 1.9550323486328125e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:06.681499 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, )
W0730 15:13:13.643556 54853 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.02366924285888672 	 0.0078582763671875 	 1.7881393432617188e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:14.786587 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0730 15:13:21.783989 55020 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.030312538146972656 	 0.009004831314086914 	 1.0728836059570312e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:23.044179 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0730 15:13:29.948318 55122 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.023334503173828125 	 0.007823467254638672 	 1.0013580322265625e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:31.040578 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, )
W0730 15:13:37.993444 55294 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.023519515991210938 	 0.007719516754150391 	 1.3828277587890625e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:40.081055 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, )
W0730 15:13:47.527480 55392 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.053398847579956055 	 0.014424800872802734 	 4.267692565917969e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:49.163954 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, )
W0730 15:13:56.074491 55567 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.023515939712524414 	 0.007828474044799805 	 1.6689300537109375e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:57.181014 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, )
W0730 15:14:04.025166 55730 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, ) 	 254016640 	 1000 	 0.023858308792114258 	 0.0078125 	 1.9788742065429688e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:14:05.274130 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, )
W0730 15:14:12.273795 55832 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, ) 	 254016640 	 1000 	 0.030134916305541992 	 0.009010076522827148 	 1.1444091796875e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:14:13.369023 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, )
W0730 15:14:20.291656 56006 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, ) 	 254016640 	 1000 	 0.023702144622802734 	 0.009356021881103516 	 1.52587890625e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/base/libpaddle.so

2025-07-30 13:32:00.266934 test begin: paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([1, 210, 75600],"bool"), )
W0730 13:32:01.555097  2710 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([1, 210, 75600],"bool"), ) 	 79380000 	 1000 	 0.21051836013793945 	 0.2814524173736572 	 0.20047330856323242 	 0.2644658088684082 	 None 	 None 	 None 	 None 	 
2025-07-30 13:32:02.223134 test begin: paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), ) 	 127008000 	 1000 	 0.15386104583740234 	 0.14346075057983398 	 0.13619542121887207 	 0.13122844696044922 	 None 	 None 	 None 	 None 	 
2025-07-30 13:32:04.252106 test begin: paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([1, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([1, 218, 70644],"bool"), ) 	 77001960 	 1000 	 0.20506620407104492 	 0.269392728805542 	 0.1952521800994873 	 0.2565603256225586 	 None 	 None 	 None 	 None 	 
2025-07-30 13:32:05.790842 test begin: paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), ) 	 123203136 	 1000 	 0.14139246940612793 	 0.1403505802154541 	 0.13263392448425293 	 0.12824797630310059 	 None 	 None 	 None 	 None 	 
2025-07-30 13:32:07.772007 test begin: paddle.Tensor.__pow__(Tensor([23, 17, 256, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([23, 17, 256, 256],"float64"), 2, ) 	 25624576 	 1000 	 0.5788938999176025 	 0.30710506439208984 	 0.5700047016143799 	 0.28375935554504395 	 0.6108968257904053 	 1.060074806213379 	 0.5555436611175537 	 0.36109161376953125 	 
2025-07-30 13:32:11.763058 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 244, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 244, 256],"float64"), 2, ) 	 25485312 	 1000 	 0.5761640071868896 	 0.3082113265991211 	 0.5672643184661865 	 0.28209638595581055 	 0.6075212955474854 	 1.0543205738067627 	 0.553269624710083 	 0.359175443649292 	 
2025-07-30 13:32:15.444526 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 256, 244],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 256, 244],"float64"), 2, ) 	 25485312 	 1000 	 0.5788655281066895 	 0.2992894649505615 	 0.5672249794006348 	 0.2825191020965576 	 0.6074931621551514 	 1.0542840957641602 	 0.5532248020172119 	 0.3591434955596924 	 
2025-07-30 13:32:19.056579 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 256, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 256, 256],"float64"), 2, ) 	 26738688 	 1000 	 0.6042554378509521 	 0.31385040283203125 	 0.5950055122375488 	 0.2972126007080078 	 0.6372244358062744 	 1.1061062812805176 	 0.582188606262207 	 0.37680649757385254 	 
2025-07-30 13:32:22.896663 test begin: paddle.Tensor.__pow__(Tensor([259, 3, 256, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([259, 3, 256, 256],"float32"), 2, ) 	 50921472 	 1000 	 0.370746374130249 	 0.2985036373138428 	 0.3616912364959717 	 0.28136277198791504 	 0.45343732833862305 	 1.0547733306884766 	 0.39889955520629883 	 0.35934948921203613 	 
2025-07-30 13:32:26.778299 test begin: paddle.Tensor.__pow__(Tensor([28, 32, 241, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([28, 32, 241, 241],"float32"), 2, ) 	 52040576 	 1000 	 0.37873220443725586 	 0.30493736267089844 	 0.36960816383361816 	 0.2874417304992676 	 0.462843656539917 	 1.0805659294128418 	 0.4058384895324707 	 0.27629613876342773 	 
2025-07-30 13:32:30.842470 test begin: paddle.Tensor.__pow__(Tensor([64, 13, 256, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 13, 256, 256],"float32"), 2, ) 	 54525952 	 1000 	 0.39682817459106445 	 0.31923508644104004 	 0.3873136043548584 	 0.3027055263519287 	 0.4848670959472656 	 1.1287975311279297 	 0.43036389350891113 	 0.3845643997192383 	 
2025-07-30 13:32:34.984496 test begin: paddle.Tensor.__pow__(Tensor([64, 3, 1034, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 3, 1034, 256],"float32"), 2, ) 	 50823168 	 1000 	 0.592432975769043 	 0.32595348358154297 	 0.3572990894317627 	 0.2814464569091797 	 0.452664852142334 	 1.0525836944580078 	 0.39783620834350586 	 0.35851597785949707 	 
2025-07-30 13:32:41.981901 test begin: paddle.Tensor.__pow__(Tensor([64, 3, 256, 1034],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 3, 256, 1034],"float32"), 2, ) 	 50823168 	 1000 	 0.3782529830932617 	 0.29790234565734863 	 0.36080503463745117 	 0.28108882904052734 	 0.4525301456451416 	 1.0524561405181885 	 0.3984386920928955 	 0.35852885246276855 	 
2025-07-30 13:32:45.829777 test begin: paddle.Tensor.__pow__(Tensor([8, 110, 241, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 110, 241, 241],"float32"), 2, ) 	 51111280 	 1000 	 0.37189674377441406 	 0.2996091842651367 	 0.362842321395874 	 0.28248143196105957 	 0.45504117012023926 	 1.061647891998291 	 0.400723934173584 	 0.27144694328308105 	 
2025-07-30 13:32:49.710577 test begin: paddle.Tensor.__pow__(Tensor([8, 32, 241, 824],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 32, 241, 824],"float32"), 2, ) 	 50837504 	 1000 	 0.3696553707122803 	 0.29799461364746094 	 0.360637903213501 	 0.2810492515563965 	 0.45275235176086426 	 1.0526957511901855 	 0.3972008228302002 	 0.35860657691955566 	 
2025-07-30 13:32:53.577256 test begin: paddle.Tensor.__pow__(Tensor([8, 32, 824, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 32, 824, 241],"float32"), 2, ) 	 50837504 	 1000 	 0.3720438480377197 	 0.29799890518188477 	 0.3605012893676758 	 0.2813758850097656 	 0.4528234004974365 	 1.0527746677398682 	 0.3984816074371338 	 0.3586306571960449 	 
2025-07-30 13:32:59.401501 test begin: paddle.Tensor.__radd__(Tensor([192, 104, 32, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 104, 32, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.3152916431427002 	 0.2981228828430176 	 0.29128527641296387 	 0.28395652770996094 	 0.2998771667480469 	 0.06147313117980957 	 0.24632859230041504 	 3.743171691894531e-05 	 
2025-07-30 13:33:05.086589 test begin: paddle.Tensor.__radd__(Tensor([192, 128, 16, 259],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 128, 16, 259],"float16"), 0, ) 	 101842944 	 1000 	 0.2998230457305908 	 0.2968623638153076 	 0.2900547981262207 	 0.28249406814575195 	 0.2988746166229248 	 0.061583757400512695 	 0.24808549880981445 	 3.552436828613281e-05 	 
2025-07-30 13:33:09.813290 test begin: paddle.Tensor.__radd__(Tensor([192, 128, 26, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 128, 26, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.30016398429870605 	 0.3009495735168457 	 0.29137682914733887 	 0.28394365310668945 	 0.2998771667480469 	 0.049043893814086914 	 0.24900007247924805 	 5.6743621826171875e-05 	 
2025-07-30 13:33:14.615811 test begin: paddle.Tensor.__radd__(Tensor([192, 207, 16, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 207, 16, 160],"float16"), 0, ) 	 101744640 	 1000 	 0.2985820770263672 	 0.2969956398010254 	 0.28990674018859863 	 0.2821056842803955 	 0.2985103130340576 	 0.05216836929321289 	 0.24683499336242676 	 9.1552734375e-05 	 
2025-07-30 13:33:19.435844 test begin: paddle.Tensor.__radd__(Tensor([192, 240, 16, 138],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 240, 16, 138],"float16"), 0, ) 	 101744640 	 1000 	 0.29859185218811035 	 0.29657459259033203 	 0.2898523807525635 	 0.28204941749572754 	 0.29856038093566895 	 0.05133628845214844 	 0.2467060089111328 	 5.1975250244140625e-05 	 
2025-07-30 13:33:24.183967 test begin: paddle.Tensor.__radd__(Tensor([192, 240, 28, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 240, 28, 80],"float16"), 0, ) 	 103219200 	 1000 	 0.30475616455078125 	 0.3007807731628418 	 0.29410314559936523 	 0.2861478328704834 	 0.30269837379455566 	 0.048777103424072266 	 0.2503988742828369 	 3.62396240234375e-05 	 
2025-07-30 13:33:28.991584 test begin: paddle.Tensor.__radd__(Tensor([192, 414, 16, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 414, 16, 80],"float16"), 0, ) 	 101744640 	 1000 	 0.2985856533050537 	 0.29660964012145996 	 0.2897670269012451 	 0.2821950912475586 	 0.2985243797302246 	 0.04909968376159668 	 0.24768996238708496 	 7.009506225585938e-05 	 
2025-07-30 13:33:33.753502 test begin: paddle.Tensor.__radd__(Tensor([192, 64, 32, 259],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 64, 32, 259],"float16"), 0, ) 	 101842944 	 1000 	 0.7503862380981445 	 0.30413293838500977 	 0.28992247581481934 	 0.28232812881469727 	 0.29883718490600586 	 0.04962158203125 	 0.2430579662322998 	 7.104873657226562e-05 	 
2025-07-30 13:33:40.370325 test begin: paddle.Tensor.__radd__(Tensor([192, 64, 52, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 64, 52, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.3001439571380615 	 0.2980220317840576 	 0.29134416580200195 	 0.28382277488708496 	 0.29982757568359375 	 0.04915809631347656 	 0.2480785846710205 	 5.555152893066406e-05 	 
2025-07-30 13:33:45.106144 test begin: paddle.Tensor.__radd__(Tensor([311, 128, 16, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([311, 128, 16, 160],"float16"), 0, ) 	 101908480 	 1000 	 0.2990531921386719 	 0.297130823135376 	 0.290266752243042 	 0.27490830421447754 	 0.29900121688842773 	 0.049164772033691406 	 0.2479994297027588 	 9.059906005859375e-05 	 
2025-07-30 13:33:49.918465 test begin: paddle.Tensor.__radd__(Tensor([311, 64, 32, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([311, 64, 32, 160],"float16"), 0, ) 	 101908480 	 1000 	 0.29907679557800293 	 0.2970855236053467 	 0.2900094985961914 	 0.279477596282959 	 0.2990241050720215 	 0.04943060874938965 	 0.2449204921722412 	 4.839897155761719e-05 	 
2025-07-30 13:33:54.730633 test begin: paddle.Tensor.__radd__(Tensor([331, 240, 16, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([331, 240, 16, 80],"float16"), 0, ) 	 101683200 	 1000 	 0.2984042167663574 	 0.2964000701904297 	 0.2894570827484131 	 0.28243398666381836 	 0.29833507537841797 	 0.04939579963684082 	 0.24712443351745605 	 4.935264587402344e-05 	 
2025-07-30 13:33:59.421123 test begin: paddle.Tensor.__rlshift__(Tensor([169345, 300],"int32"), -223, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([169345, 300],"int32"), -223, ) 	 50803500 	 1000 	 0.2988569736480713 	 0.29792237281799316 	 0.15250325202941895 	 0.278303861618042 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:00.603738 test begin: paddle.Tensor.__rlshift__(Tensor([200, 254017],"int32"), -223, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 254017],"int32"), -223, ) 	 50803400 	 1000 	 0.29901885986328125 	 0.29787540435791016 	 0.15258359909057617 	 0.277864933013916 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:01.772438 test begin: paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), -212, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), -212, ) 	 101606600 	 1000 	 0.3384888172149658 	 0.302046537399292 	 0.00028395652770996094 	 0.27550721168518066 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:04.627508 test begin: paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), 63, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), 63, ) 	 101606600 	 1000 	 1.4836726188659668 	 0.2994391918182373 	 0.00030732154846191406 	 0.27519869804382324 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:07.764201 test begin: paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), -212, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), -212, ) 	 101606700 	 1000 	 0.33444833755493164 	 0.29500603675842285 	 0.00031375885009765625 	 0.27556395530700684 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:09.363800 test begin: paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), 63, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), 63, ) 	 101606700 	 1000 	 0.3346595764160156 	 0.2949497699737549 	 0.0003077983856201172 	 0.2754337787628174 	 None 	 None 	 None 	 None 	 
2025-07-30 13:34:10.983455 test begin: paddle.Tensor.__rmatmul__(Tensor([10160641, 5],"float32"), Tensor([2, 10160641],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([10160641, 5],"float32"), Tensor([2, 10160641],"float32"), ) 	 71124487 	 1000 	 1.387829303741455 	 1.3845467567443848 	 0.7089190483093262 	 0.7074525356292725 	 2.0965018272399902 	 2.095689535140991 	 0.10707807540893555 	 0.10706758499145508 	 
2025-07-30 13:34:19.281077 test begin: paddle.Tensor.__rmatmul__(Tensor([25401601, 5],"float32"), Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([25401601, 5],"float32"), Tensor([2, 25401601],"float32"), ) 	 177811207 	 1000 	 3.403140068054199 	 3.3959877490997314 	 1.7388877868652344 	 1.735290288925171 	 5.240511655807495 	 5.239755153656006 	 0.10712742805480957 	 0.10709118843078613 	 
2025-07-30 13:34:39.571294 test begin: paddle.Tensor.__rmatmul__(Tensor([3, 16934401],"float32"), Tensor([2, 3],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([3, 16934401],"float32"), Tensor([2, 3],"float32"), ) 	 50803209 	 1000 	 0.764054536819458 	 0.7653307914733887 	 0.04588460922241211 	 0.045955657958984375 	 4.102113723754883 	 4.098827600479126 	 0.21887421607971191 	 0.22090983390808105 	 
2025-07-30 13:34:50.793429 test begin: paddle.Tensor.__rmatmul__(Tensor([3, 5],"float32"), Tensor([16934401, 3],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([3, 5],"float32"), Tensor([16934401, 3],"float32"), ) 	 50803218 	 1000 	 1.7861125469207764 	 1.7874813079833984 	 0.10727167129516602 	 0.10732221603393555 	 4.186924695968628 	 4.185180187225342 	 0.22566747665405273 	 0.22336792945861816 	 
2025-07-30 13:35:05.032761 test begin: paddle.Tensor.__rmod__(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), ) 	 101606412 	 1000 	 0.45084285736083984 	 0.4598836898803711 	 0.4413583278656006 	 0.4330439567565918 	 1.1157748699188232 	 1.1968963146209717 	 1.0486822128295898 	 0.40761828422546387 	 
2025-07-30 13:35:13.266701 test begin: paddle.Tensor.__rmod__(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), ) 	 101606416 	 1000 	 0.45084476470947266 	 0.44925928115844727 	 0.4414691925048828 	 0.43358707427978516 	 1.1155447959899902 	 1.1967570781707764 	 1.0538127422332764 	 0.40761590003967285 	 
2025-07-30 13:35:18.972488 test begin: paddle.Tensor.__rmod__(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), ) 	 101606424 	 1000 	 0.4507935047149658 	 0.4507174491882324 	 0.4413142204284668 	 0.4332237243652344 	 1.1154677867889404 	 1.1967577934265137 	 1.0558481216430664 	 0.4075942039489746 	 
2025-07-30 13:35:24.696470 test begin: paddle.Tensor.__rmul__(Tensor([176, 392, 737],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([176, 392, 737],"float32"), -100.0, ) 	 50847104 	 1000 	 0.29717326164245605 	 0.29815244674682617 	 0.28800129890441895 	 0.2841312885284424 	 0.2962827682495117 	 0.2979145050048828 	 0.24515366554260254 	 0.22939825057983398 	 
2025-07-30 13:35:27.495359 test begin: paddle.Tensor.__rmul__(Tensor([176, 737, 392],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([176, 737, 392],"float32"), -100.0, ) 	 50847104 	 1000 	 0.29642701148986816 	 0.2980680465698242 	 0.2876133918762207 	 0.28398942947387695 	 0.29642558097839355 	 0.2978789806365967 	 0.24557018280029297 	 0.230177640914917 	 
2025-07-30 13:35:30.322512 test begin: paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 0.75, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 0.75, ) 	 50868000 	 1000 	 0.2973287105560303 	 0.2982814311981201 	 0.2879326343536377 	 0.2839477062225342 	 0.2965705394744873 	 0.29800963401794434 	 0.2456679344177246 	 0.23043513298034668 	 
2025-07-30 13:35:33.174624 test begin: paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 1.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 1.0, ) 	 50868000 	 1000 	 0.29748988151550293 	 0.5250952243804932 	 0.2877795696258545 	 0.28400754928588867 	 0.29662275314331055 	 0.29802918434143066 	 0.24538683891296387 	 0.23056244850158691 	 
2025-07-30 13:35:39.584271 test begin: paddle.Tensor.__rmul__(Tensor([331, 392, 392],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([331, 392, 392],"float32"), -100.0, ) 	 50862784 	 1000 	 0.29778432846069336 	 0.2982926368713379 	 0.2871096134185791 	 0.28408122062683105 	 0.29653310775756836 	 0.2980360984802246 	 0.24251317977905273 	 0.23003077507019043 	 
2025-07-30 13:35:42.439160 test begin: paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 0.75, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 0.75, ) 	 50803280 	 1000 	 0.2958946228027344 	 0.29804110527038574 	 0.28665685653686523 	 0.26871156692504883 	 0.29607486724853516 	 0.2976970672607422 	 0.23199820518493652 	 0.2056572437286377 	 
2025-07-30 13:35:45.280846 test begin: paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 1.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 1.0, ) 	 50803280 	 1000 	 0.30091333389282227 	 0.2978379726409912 	 0.2868809700012207 	 0.2838170528411865 	 0.2960495948791504 	 0.29764437675476074 	 0.24497532844543457 	 0.23083829879760742 	 
2025-07-30 13:35:48.142966 test begin: paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), 5, ) 	 50803206 	 1000 	 0.2988624572753906 	 0.298903226852417 	 0.15254592895507812 	 0.2833552360534668 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:49.318020 test begin: paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), True, ) 	 50803206 	 1000 	 0.2988131046295166 	 0.297914981842041 	 0.15252351760864258 	 0.2831544876098633 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:50.487838 test begin: paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), 5, ) 	 50803210 	 1000 	 0.2988853454589844 	 0.29778218269348145 	 0.15256881713867188 	 0.2833588123321533 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:51.654845 test begin: paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), True, ) 	 50803210 	 1000 	 0.29884958267211914 	 0.297778844833374 	 0.1525864601135254 	 0.28334617614746094 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:52.821968 test begin: paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), 5, ) 	 50803215 	 1000 	 0.2988431453704834 	 0.31539106369018555 	 0.15253353118896484 	 0.2833516597747803 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:54.017486 test begin: paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), True, ) 	 50803215 	 1000 	 0.30054283142089844 	 0.2991173267364502 	 0.1525566577911377 	 0.28332018852233887 	 None 	 None 	 None 	 None 	 
2025-07-30 13:35:55.196146 test begin: paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000, )
[Prof] paddle.Tensor.__rpow__ 	 paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000, ) 	 50803201 	 1000 	 0.5829176902770996 	 0.6307375431060791 	 0.29773688316345215 	 0.32216525077819824 	 0.7010822296142578 	 0.7429242134094238 	 0.6481959819793701 	 0.37954211235046387 	 
2025-07-30 13:35:59.576940 test begin: paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000.0, )
[Prof] paddle.Tensor.__rpow__ 	 paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000.0, ) 	 50803201 	 1000 	 0.5830731391906738 	 0.6447973251342773 	 0.2979140281677246 	 0.32936763763427734 	 0.7006802558898926 	 0.7429289817810059 	 0.6480729579925537 	 0.37955641746520996 	 
2025-07-30 13:36:03.964740 test begin: paddle.Tensor.__rrshift__(Tensor([169345, 300],"int32"), 232, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([169345, 300],"int32"), 232, ) 	 50803500 	 1000 	 0.298720121383667 	 0.29781389236450195 	 0.15247726440429688 	 0.27855420112609863 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:05.137021 test begin: paddle.Tensor.__rrshift__(Tensor([200, 254017],"int32"), 232, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 254017],"int32"), 232, ) 	 50803400 	 1000 	 0.298673152923584 	 0.29785656929016113 	 0.15247511863708496 	 0.27821946144104004 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:06.306887 test begin: paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), -255, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), -255, ) 	 101606600 	 1000 	 0.33587050437927246 	 0.29600024223327637 	 0.0003135204315185547 	 0.27660369873046875 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:07.898394 test begin: paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), 11, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), 11, ) 	 101606600 	 1000 	 0.3375053405761719 	 0.2960014343261719 	 0.00031185150146484375 	 0.27657389640808105 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:09.531368 test begin: paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), -255, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), -255, ) 	 101606700 	 1000 	 0.3366725444793701 	 0.2960550785064697 	 0.0003104209899902344 	 0.27685976028442383 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:11.126356 test begin: paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), 11, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), 11, ) 	 101606700 	 1000 	 0.33853816986083984 	 0.2960796356201172 	 0.00028896331787109375 	 0.2768900394439697 	 None 	 None 	 None 	 None 	 
2025-07-30 13:36:12.718440 test begin: paddle.Tensor.__rshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 1.3362641334533691 	 0.44745922088623047 	 0.4411900043487549 	 0.43474817276000977 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:18.116059 test begin: paddle.Tensor.__rshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.450484037399292 	 0.4467952251434326 	 0.4412267208099365 	 0.43493008613586426 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:20.158248 test begin: paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4475703239440918 	 0.4501209259033203 	 0.43822622299194336 	 0.43831872940063477 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:22.991505 test begin: paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.44830989837646484 	 3.1129138469696045 	 0.43900585174560547 	 0.3535752296447754 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:28.537726 test begin: paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.4478468894958496 	 0.4501810073852539 	 0.43343472480773926 	 0.4379918575286865 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:31.409847 test begin: paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.44892287254333496 	 3.1131680011749268 	 0.43962645530700684 	 0.3536543846130371 	 None 	 None 	 None 	 None 	 combined
2025-07-30 13:36:37.518558 test begin: paddle.Tensor.__rsub__(Tensor([2, 1, 12404, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 1, 12404, 4096],"float16"), 1, ) 	 101613568 	 1000 	 0.30055856704711914 	 0.3002316951751709 	 0.2894437313079834 	 0.2771420478820801 	 0.2982962131500244 	 0.2960822582244873 	 0.24550247192382812 	 0.22826242446899414 	 
2025-07-30 13:36:43.717732 test begin: paddle.Tensor.__rsub__(Tensor([2, 1, 4096, 12404],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 1, 4096, 12404],"float16"), 1, ) 	 101613568 	 1000 	 0.2982182502746582 	 0.30054616928100586 	 0.28932809829711914 	 0.27483415603637695 	 0.29836058616638184 	 0.29613280296325684 	 0.2478480339050293 	 0.23008036613464355 	 
2025-07-30 13:36:48.676122 test begin: paddle.Tensor.__rsub__(Tensor([2, 4, 4096, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 4, 4096, 4096],"float16"), 1, ) 	 134217728 	 1000 	 0.3929445743560791 	 0.39632534980773926 	 0.38360142707824707 	 0.3707895278930664 	 0.3923609256744385 	 0.38997602462768555 	 0.34053468704223633 	 0.3216745853424072 	 
2025-07-30 13:36:55.210203 test begin: paddle.Tensor.__rsub__(Tensor([2944, 17257],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2944, 17257],"float32"), 1, ) 	 50804608 	 1000 	 0.295849084854126 	 0.2978513240814209 	 0.28688883781433105 	 0.2790846824645996 	 0.29610180854797363 	 0.29761528968811035 	 0.24497747421264648 	 0.2324662208557129 	 
2025-07-30 13:36:58.038795 test begin: paddle.Tensor.__rsub__(Tensor([4224, 12028],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([4224, 12028],"float32"), 1, ) 	 50806272 	 1000 	 0.2961137294769287 	 0.2979104518890381 	 0.2872903347015381 	 0.2789475917816162 	 0.2961001396179199 	 0.297635555267334 	 0.24547052383422852 	 0.2330615520477295 	 
2025-07-30 13:37:00.873644 test begin: paddle.Tensor.__rsub__(Tensor([7, 1, 4096, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([7, 1, 4096, 4096],"float16"), 1, ) 	 117440512 	 1000 	 0.34380555152893066 	 0.34166526794433594 	 0.3350043296813965 	 0.32245540618896484 	 0.34377217292785645 	 0.3416318893432617 	 0.2931661605834961 	 0.2722439765930176 	 
2025-07-30 13:37:06.966166 test begin: paddle.Tensor.__rsub__(Tensor([7664, 6629],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([7664, 6629],"float32"), 1, ) 	 50804656 	 1000 	 0.29613780975341797 	 0.29796528816223145 	 0.286928653717041 	 0.2782857418060303 	 0.2960660457611084 	 0.2976367473602295 	 0.24155092239379883 	 0.21119976043701172 	 
2025-07-30 13:37:09.877297 test begin: paddle.Tensor.__rtruediv__(Tensor([15548, 3268],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([15548, 3268],"float32"), 1.0, ) 	 50810864 	 1000 	 0.58376145362854 	 0.5958912372589111 	 0.2981903553009033 	 0.30437231063842773 	 0.5858280658721924 	 1.3381919860839844 	 0.5299177169799805 	 0.34197568893432617 	 
2025-07-30 13:37:14.654208 test begin: paddle.Tensor.__rtruediv__(Tensor([16773, 3029],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([16773, 3029],"float32"), 1.0, ) 	 50805417 	 1000 	 0.5838730335235596 	 0.5958325862884521 	 0.2982628345489502 	 0.3043830394744873 	 0.5857717990875244 	 1.3381192684173584 	 0.5293407440185547 	 0.34191441535949707 	 
2025-07-30 13:37:21.037807 test begin: paddle.Tensor.__rtruediv__(Tensor([26736, 1901],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([26736, 1901],"float32"), 1.0, ) 	 50825136 	 1000 	 1.4712083339691162 	 0.5961811542510986 	 0.2983870506286621 	 0.3045783042907715 	 0.5859701633453369 	 1.3386378288269043 	 0.5290539264678955 	 0.34203147888183594 	 
2025-07-30 13:37:27.405971 test begin: paddle.Tensor.__rtruediv__(Tensor([37411, 1358],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([37411, 1358],"float32"), 1.0, ) 	 50804138 	 1000 	 0.5838093757629395 	 0.5957977771759033 	 0.2982053756713867 	 0.3043668270111084 	 0.585740327835083 	 1.337982416152954 	 0.5289919376373291 	 0.34194231033325195 	 
2025-07-30 13:37:32.138869 test begin: paddle.Tensor.__rtruediv__(Tensor([6684, 7601],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([6684, 7601],"float32"), 1.0, ) 	 50805084 	 1000 	 0.5868949890136719 	 0.5994858741760254 	 0.29821038246154785 	 0.3043982982635498 	 0.5856130123138428 	 1.338280439376831 	 0.5297524929046631 	 0.34195804595947266 	 
2025-07-30 13:37:37.980447 test begin: paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), 5, ) 	 50803206 	 1000 	 1.4599416255950928 	 0.3003826141357422 	 0.1525726318359375 	 0.28313469886779785 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:41.303538 test begin: paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), True, ) 	 50803206 	 1000 	 0.29987454414367676 	 0.30037426948547363 	 0.15258455276489258 	 0.28298211097717285 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:42.487570 test begin: paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), 5, ) 	 50803210 	 1000 	 0.29972290992736816 	 0.29778265953063965 	 0.15259313583374023 	 0.2834162712097168 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:43.653267 test begin: paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), True, ) 	 50803210 	 1000 	 0.29892563819885254 	 0.2977790832519531 	 0.15255498886108398 	 0.28316164016723633 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:44.808098 test begin: paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), 5, ) 	 50803215 	 1000 	 0.2988903522491455 	 0.2979922294616699 	 0.1525566577911377 	 0.28344106674194336 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:45.975915 test begin: paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), True, ) 	 50803215 	 1000 	 0.299030065536499 	 0.2978506088256836 	 0.1525726318359375 	 0.28339314460754395 	 None 	 None 	 None 	 None 	 
2025-07-30 13:37:47.150348 test begin: paddle.Tensor.__sub__(Tensor([1, 1, 32768, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([1, 1, 32768, 32768],"float16"), 1, ) 	 1073741824 	 1000 	 3.105729341506958 	 3.0932040214538574 	 3.095947504043579 	 3.07645583152771 	 3.1057934761047363 	 0.0577692985534668 	 3.054818868637085 	 8.320808410644531e-05 	 
2025-07-30 13:38:37.616053 test begin: paddle.Tensor.__sub__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), ) 	 52174848 	 1000 	 0.30416250228881836 	 0.3284463882446289 	 0.29339122772216797 	 0.303455114364624 	 0.5357511043548584 	 0.4555983543395996 	 0.27371716499328613 	 0.2327132225036621 	 
2025-07-30 13:38:40.979732 test begin: paddle.Tensor.__sub__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), ) 	 52174848 	 1000 	 0.3039569854736328 	 0.3160274028778076 	 0.2935612201690674 	 0.3034956455230713 	 0.535750150680542 	 0.45549988746643066 	 0.273712158203125 	 0.23270392417907715 	 
2025-07-30 13:38:44.242963 test begin: paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), ) 	 53084160 	 1000 	 0.3056623935699463 	 0.3192586898803711 	 0.29518604278564453 	 0.30672264099121094 	 0.4858283996582031 	 0.462111234664917 	 0.2481839656829834 	 0.23610234260559082 	 
2025-07-30 13:38:47.536587 test begin: paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), ) 	 103809024 	 1000 	 0.46014833450317383 	 0.45781660079956055 	 0.4506678581237793 	 0.4443626403808594 	 0.484591007232666 	 0.3040759563446045 	 0.4185619354248047 	 0.23035311698913574 	 
2025-07-30 13:38:51.765592 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 1551, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 1551, 32768],"float16"), 1, ) 	 101646336 	 1000 	 0.29828572273254395 	 0.2962992191314697 	 0.2892451286315918 	 0.2821509838104248 	 0.2982361316680908 	 0.05525565147399902 	 0.24538469314575195 	 7.43865966796875e-05 	 
2025-07-30 13:38:56.520305 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 32768, 1551],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 32768, 1551],"float16"), 1, ) 	 101646336 	 1000 	 0.29820847511291504 	 0.29631471633911133 	 0.2890129089355469 	 0.28223252296447754 	 0.2982618808746338 	 0.054772138595581055 	 0.24668407440185547 	 7.772445678710938e-05 	 
2025-07-30 13:39:01.193729 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 32768, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 32768, 32768],"float16"), 1, ) 	 2147483648 	 1000 	 6.213557958602905 	 6.313922643661499 	 6.19842004776001 	 3.2757625579833984 	 6.2063798904418945 	 0.053224802017211914 	 6.15381932258606 	 3.600120544433594e-05 	 
2025-07-30 13:40:47.598761 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 1],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 1],"float32"), ) 	 161966688 	 1000 	 0.7148158550262451 	 0.7135066986083984 	 0.7052907943725586 	 0.6964683532714844 	 0.7579498291015625 	 0.4714381694793701 	 0.7000281810760498 	 0.3978092670440674 	 
2025-07-30 13:40:54.224370 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 2],"float32"), ) 	 242950032 	 1000 	 1.1744976043701172 	 1.1975629329681396 	 1.1640198230743408 	 1.184760570526123 	 2.390751361846924 	 2.467392683029175 	 1.2215731143951416 	 1.2607448101043701 	 
2025-07-30 13:41:10.156393 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 2],"float32"), Tensor([26736, 3029, 1],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 2],"float32"), Tensor([26736, 3029, 1],"float32"), ) 	 242950032 	 1000 	 1.1737253665924072 	 1.2003822326660156 	 1.1631999015808105 	 1.182147741317749 	 2.227552890777588 	 2.46771502494812 	 0.7585666179656982 	 1.2609162330627441 	 
2025-07-30 13:41:23.834827 test begin: paddle.Tensor.__sub__(Tensor([26736, 951, 2],"float32"), Tensor([26736, 951, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 951, 2],"float32"), Tensor([26736, 951, 2],"float32"), ) 	 101703744 	 1000 	 0.45049214363098145 	 0.4470350742340088 	 0.43856024742126465 	 0.43535542488098145 	 0.47689342498779297 	 0.29790663719177246 	 0.41873884201049805 	 0.2202000617980957 	 
2025-07-30 13:41:27.976249 test begin: paddle.Tensor.__sub__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), ) 	 51581952 	 1000 	 0.3001530170440674 	 0.3121359348297119 	 0.28971195220947266 	 0.29989004135131836 	 0.47873759269714355 	 0.4499852657318115 	 0.2445828914642334 	 0.22987055778503418 	 
2025-07-30 13:41:31.189415 test begin: paddle.Tensor.__sub__(Tensor([8387, 3029, 2],"float32"), Tensor([8387, 3029, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([8387, 3029, 2],"float32"), Tensor([8387, 3029, 2],"float32"), ) 	 101616892 	 1000 	 0.4503500461578369 	 0.4530463218688965 	 0.4408400058746338 	 0.4348409175872803 	 0.4756960868835449 	 0.29766035079956055 	 0.41764307022094727 	 0.2171013355255127 	 
2025-07-30 13:41:37.874714 test begin: paddle.Tensor.__truediv__(Tensor([124, 128, 34, 96],"float32"), Tensor([124, 1, 34, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 128, 34, 96],"float32"), Tensor([124, 1, 34, 96],"float32"), ) 	 52210944 	 1000 	 0.3036165237426758 	 0.3504321575164795 	 0.2930128574371338 	 0.3126852512359619 	 0.8106100559234619 	 1.8848762512207031 	 0.4141581058502197 	 0.32087135314941406 	 
2025-07-30 13:41:43.183979 test begin: paddle.Tensor.__truediv__(Tensor([124, 128, 96, 34],"float32"), Tensor([124, 1, 96, 34],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 128, 96, 34],"float32"), Tensor([124, 1, 96, 34],"float32"), ) 	 52210944 	 1000 	 0.3035905361175537 	 0.32400035858154297 	 0.2928931713104248 	 0.3119666576385498 	 0.8106257915496826 	 1.8847579956054688 	 0.4141874313354492 	 0.3208773136138916 	 
2025-07-30 13:41:50.448256 test begin: paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 1, 96, 96],"float32"), ) 	 52568064 	 1000 	 0.3033430576324463 	 0.3305530548095703 	 0.2924942970275879 	 0.31144213676452637 	 0.7692363262176514 	 1.8849353790283203 	 0.39303112030029297 	 0.32086658477783203 	 
2025-07-30 13:41:55.790854 test begin: paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 45, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 45, 96, 96],"float32"), ) 	 102850560 	 1000 	 0.4559504985809326 	 0.4551513195037842 	 0.4463226795196533 	 0.44347429275512695 	 1.1286168098449707 	 2.1169426441192627 	 1.0672619342803955 	 0.4326972961425781 	 
2025-07-30 13:42:02.438367 test begin: paddle.Tensor.__truediv__(Tensor([128, 128, 33, 96],"float32"), Tensor([128, 1, 33, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 128, 33, 96],"float32"), Tensor([128, 1, 33, 96],"float32"), ) 	 52310016 	 1000 	 0.3040294647216797 	 0.3247687816619873 	 0.29337072372436523 	 0.31263208389282227 	 0.8106672763824463 	 1.8895232677459717 	 0.4141979217529297 	 0.32167983055114746 	 
2025-07-30 13:42:07.453923 test begin: paddle.Tensor.__truediv__(Tensor([128, 128, 96, 33],"float32"), Tensor([128, 1, 96, 33],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 128, 96, 33],"float32"), Tensor([128, 1, 96, 33],"float32"), ) 	 52310016 	 1000 	 0.3040599822998047 	 0.32468509674072266 	 0.2932093143463135 	 0.3126399517059326 	 0.8108358383178711 	 1.8895535469055176 	 0.4143383502960205 	 0.3216543197631836 	 
2025-07-30 13:42:12.778150 test begin: paddle.Tensor.__truediv__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), ) 	 52174848 	 1000 	 0.303741455078125 	 0.3240058422088623 	 0.2930746078491211 	 0.31204915046691895 	 0.8240213394165039 	 1.885988712310791 	 0.42099714279174805 	 0.32109737396240234 	 
2025-07-30 13:42:17.787329 test begin: paddle.Tensor.__truediv__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), ) 	 52174848 	 1000 	 0.3037400245666504 	 0.3239891529083252 	 0.29311180114746094 	 0.31194043159484863 	 0.8241062164306641 	 1.885965347290039 	 0.4211294651031494 	 0.3210887908935547 	 
2025-07-30 13:42:22.813383 test begin: paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), ) 	 53084160 	 1000 	 0.3063931465148926 	 0.3269672393798828 	 0.295626163482666 	 0.31497812271118164 	 0.7773275375366211 	 1.9000873565673828 	 0.3971221446990967 	 0.32347965240478516 	 
2025-07-30 13:42:27.847328 test begin: paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), ) 	 103809024 	 1000 	 0.46018505096435547 	 0.46193790435791016 	 0.4500613212585449 	 0.44783830642700195 	 1.140153169631958 	 2.136634349822998 	 1.0784556865692139 	 0.43676066398620605 	 
2025-07-30 13:42:34.660118 test begin: paddle.Tensor.__truediv__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), ) 	 51581952 	 1000 	 0.3001370429992676 	 0.332324743270874 	 0.2894256114959717 	 0.3070790767669678 	 0.7647762298583984 	 1.865708351135254 	 0.3907766342163086 	 0.31738901138305664 	 
2025-07-30 13:42:42.275911 test begin: paddle.Tensor.__truediv__(Tensor([44, 128, 96, 96],"float32"), Tensor([44, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([44, 128, 96, 96],"float32"), Tensor([44, 1, 96, 96],"float32"), ) 	 52310016 	 1000 	 0.30354762077331543 	 0.329803466796875 	 0.29279303550720215 	 0.31235671043395996 	 0.7738943099975586 	 1.8874788284301758 	 0.39540934562683105 	 0.321321964263916 	 
2025-07-30 13:42:47.327809 test begin: paddle.Tensor.__xor__(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44896578788757324 	 0.45021986961364746 	 0.4403340816497803 	 0.43827176094055176 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:50.221163 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4486076831817627 	 0.4516777992248535 	 0.4399909973144531 	 0.4379582405090332 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:53.060578 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4488027095794678 	 0.45445680618286133 	 0.440079927444458 	 0.4381117820739746 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:56.984300 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.4486217498779297 	 0.4559357166290283 	 0.43991708755493164 	 0.4378929138183594 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:00.602851 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11722922325134277 	 0.11748266220092773 	 0.1085970401763916 	 0.10534262657165527 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:02.243307 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.450197696685791 	 0.4465658664703369 	 0.44168972969055176 	 0.4347107410430908 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:04.293571 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.449038028717041 	 0.45020174980163574 	 0.4404425621032715 	 0.4382176399230957 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:07.155541 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1684403419494629 	 0.22764158248901367 	 0.15873932838439941 	 0.21410107612609863 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:08.254764 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3145272731781006 	 0.47961878776550293 	 0.3047525882720947 	 0.46639537811279297 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:10.037094 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2961268424987793 	 0.3100924491882324 	 0.2862813472747803 	 0.2946925163269043 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:11.228884 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.1180269718170166 	 0.1162862777709961 	 0.10928630828857422 	 0.10419082641601562 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:12.870039 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.4501965045928955 	 0.45369386672973633 	 0.44156599044799805 	 0.43450284004211426 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:14.926805 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.4482083320617676 	 0.4502146244049072 	 0.43970441818237305 	 0.43839573860168457 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:17.765198 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1770012378692627 	 0.22775745391845703 	 0.1672840118408203 	 0.20913982391357422 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:18.887265 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11803364753723145 	 0.11644625663757324 	 0.10938501358032227 	 0.10429811477661133 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:20.589699 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29549694061279297 	 0.30798864364624023 	 0.2857489585876465 	 0.2948737144470215 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:21.782076 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.4503333568572998 	 0.4465761184692383 	 0.4415578842163086 	 0.43476247787475586 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:23.878197 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3453519344329834 	 0.47821593284606934 	 0.3357884883880615 	 0.4650402069091797 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:25.731319 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.4486668109893799 	 0.4502558708190918 	 0.4399588108062744 	 0.43782734870910645 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:28.592787 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11801838874816895 	 0.1165006160736084 	 0.10926127433776855 	 0.10325384140014648 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:30.235190 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.450178861618042 	 0.44667744636535645 	 0.4414494037628174 	 0.4347083568572998 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:32.294848 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11804556846618652 	 0.13753986358642578 	 0.10942578315734863 	 0.10327029228210449 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:33.951145 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45049095153808594 	 0.6701817512512207 	 0.4418365955352783 	 0.4345376491546631 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:39.930718 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11806464195251465 	 0.11551165580749512 	 0.10256052017211914 	 0.09608817100524902 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:41.555475 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45052027702331543 	 0.4465818405151367 	 0.4419388771057129 	 0.43474912643432617 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:43.606963 test begin: paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11802029609680176 	 0.11552572250366211 	 0.10925531387329102 	 0.10346198081970215 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:45.216628 test begin: paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4504706859588623 	 0.4466512203216553 	 0.4417147636413574 	 0.43479418754577637 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:47.241247 test begin: paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11808323860168457 	 0.1202237606048584 	 0.1094350814819336 	 0.10422444343566895 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:48.858347 test begin: paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.45025038719177246 	 0.44660043716430664 	 0.4413137435913086 	 0.4347710609436035 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:50.901176 test begin: paddle.Tensor.__xor__(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44838762283325195 	 0.45019054412841797 	 0.43979358673095703 	 0.4383275508880615 	 None 	 None 	 None 	 None 	 
2025-07-30 13:43:53.797514 test begin: paddle.Tensor.abs(Tensor([243360, 209],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([243360, 209],"float32"), ) 	 50862240 	 1000 	 0.2961111068725586 	 0.2981243133544922 	 0.28681302070617676 	 0.2855203151702881 	 0.4508237838745117 	 0.7436466217041016 	 0.39643049240112305 	 0.379946231842041 	 
2025-07-30 13:43:57.245256 test begin: paddle.Tensor.abs(Tensor([282240, 181],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([282240, 181],"float32"), ) 	 51085440 	 1000 	 0.29718518257141113 	 0.29936814308166504 	 0.28810954093933105 	 0.2867898941040039 	 0.45230746269226074 	 0.7468979358673096 	 0.3986063003540039 	 0.38158679008483887 	 
2025-07-30 13:44:02.285306 test begin: paddle.Tensor.abs(Tensor([324000, 157],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([324000, 157],"float32"), ) 	 50868000 	 1000 	 0.29615283012390137 	 0.30036020278930664 	 0.2869749069213867 	 0.2854163646697998 	 0.45087218284606934 	 0.7438178062438965 	 0.3954486846923828 	 0.3800637722015381 	 
2025-07-30 13:44:06.383189 test begin: paddle.Tensor.abs(Tensor([635041, 80],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([635041, 80],"float32"), ) 	 50803280 	 1000 	 0.2956223487854004 	 0.2977569103240967 	 0.2865266799926758 	 0.28571033477783203 	 0.4500575065612793 	 0.7428216934204102 	 0.39644384384155273 	 0.37953901290893555 	 
2025-07-30 13:44:09.818514 test begin: paddle.Tensor.add(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.add 	 paddle.Tensor.add(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.45023417472839355 	 0.4465968608856201 	 0.44060850143432617 	 0.43520689010620117 	 0.4835042953491211 	 0.05958080291748047 	 0.425433874130249 	 6.246566772460938e-05 	 
2025-07-30 13:44:13.667213 test begin: paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), ) 	 508047360 	 1000 	 0.4642515182495117 	 0.5065984725952148 	 0.2371840476989746 	 0.2588310241699219 	 None 	 None 	 None 	 None 	 
2025-07-30 13:44:21.574254 test begin: paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), ) 	 508047360 	 1000 	 0.4642505645751953 	 0.5066525936126709 	 0.23721528053283691 	 0.258878231048584 	 None 	 None 	 None 	 None 	 
2025-07-30 13:44:29.416301 test begin: paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.4986238479614258 	 0.5458266735076904 	 0.25481438636779785 	 0.27889132499694824 	 None 	 None 	 None 	 None 	 
2025-07-30 13:44:38.931010 test begin: paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.49846696853637695 	 0.545874834060669 	 0.2547180652618408 	 0.2789306640625 	 None 	 None 	 None 	 None 	 
2025-07-30 13:44:48.012331 test begin: paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), ) 	 508800000 	 1000 	 0.46620702743530273 	 0.5083529949188232 	 0.23821496963500977 	 0.2597475051879883 	 None 	 None 	 None 	 None 	 
2025-07-30 13:44:55.893795 test begin: paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), ) 	 508032200 	 1000 	 0.46719813346862793 	 0.5072836875915527 	 0.23873424530029297 	 0.259202241897583 	 None 	 None 	 None 	 None 	 
2025-07-30 13:45:03.836612 test begin: paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), ) 	 512000000 	 1000 	 0.4679088592529297 	 0.51991868019104 	 0.23908066749572754 	 0.2656562328338623 	 None 	 None 	 None 	 None 	 
2025-07-30 13:45:11.888318 test begin: paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), ) 	 508160000 	 1000 	 0.4656367301940918 	 0.5070569515228271 	 0.2379465103149414 	 0.2590773105621338 	 None 	 None 	 None 	 None 	 
2025-07-30 13:45:19.730606 test begin: paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), ) 	 512000000 	 1000 	 0.46798157691955566 	 0.5199646949768066 	 0.23910164833068848 	 0.2657039165496826 	 None 	 None 	 None 	 None 	 
2025-07-30 13:45:27.606810 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803240 	 1000 	 0.45420312881469727 	 0.47191643714904785 	 0.44237565994262695 	 0.45783066749572754 	 1.3156394958496094 	 1.6166086196899414 	 0.33606839179992676 	 0.33025693893432617 	 
2025-07-30 13:45:32.568658 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803240 	 1000 	 0.5138070583343506 	 1.2386152744293213 	 0.5012574195861816 	 0.16943669319152832 	 1.3869152069091797 	 1.5304934978485107 	 0.3542754650115967 	 0.31267738342285156 	 
2025-07-30 13:45:40.763285 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803240 	 1000 	 0.15187621116638184 	 0.15348315238952637 	 0.07757925987243652 	 0.07838559150695801 	 1.0439729690551758 	 1.2488868236541748 	 0.21353960037231445 	 0.2125566005706787 	 
2025-07-30 13:45:44.206155 test begin: paddle.Tensor.amax(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, ) 	 50803230 	 1000 	 0.4537360668182373 	 0.4825742244720459 	 0.44199180603027344 	 0.4573659896850586 	 1.3154957294464111 	 1.6164140701293945 	 0.33609557151794434 	 0.3302161693572998 	 
2025-07-30 13:45:49.139194 test begin: paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, ) 	 50803224 	 1000 	 6.286483526229858 	 0.17190146446228027 	 3.212423801422119 	 0.08784198760986328 	 5.725569486618042 	 1.3408353328704834 	 1.1685757637023926 	 0.22826790809631348 	 
2025-07-30 13:46:03.549799 test begin: paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, ) 	 50803224 	 1000 	 0.15178227424621582 	 0.15277624130249023 	 0.07754778861999512 	 0.07802939414978027 	 1.044057846069336 	 1.2486674785614014 	 0.21354460716247559 	 0.21254944801330566 	 
2025-07-30 13:46:06.967013 test begin: paddle.Tensor.amax(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, ) 	 50803224 	 1000 	 0.16957879066467285 	 0.1546154022216797 	 0.08662796020507812 	 0.07895970344543457 	 1.0655157566070557 	 1.2744834423065186 	 0.21790671348571777 	 0.21697306632995605 	 
2025-07-30 13:46:10.440068 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, ) 	 50803230 	 1000 	 0.20920014381408691 	 0.9589123725891113 	 0.19759607315063477 	 0.2022554874420166 	 1.2628238201141357 	 1.5259954929351807 	 0.3228883743286133 	 0.3117518424987793 	 
2025-07-30 13:46:17.696025 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, ) 	 50803230 	 1000 	 0.1518998146057129 	 0.15289831161499023 	 0.07758450508117676 	 0.07808566093444824 	 1.0440289974212646 	 1.2484755516052246 	 0.2135622501373291 	 0.21253371238708496 	 
2025-07-30 13:46:21.111839 test begin: paddle.Tensor.amax(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803260 	 1000 	 0.4537367820739746 	 0.47176170349121094 	 0.44188475608825684 	 0.4576280117034912 	 1.3155221939086914 	 1.6163690090179443 	 0.3360722064971924 	 0.3302192687988281 	 
2025-07-30 13:46:25.956520 test begin: paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803260 	 1000 	 0.5137162208557129 	 0.18373775482177734 	 0.5003948211669922 	 0.16939139366149902 	 1.3868591785430908 	 1.530240774154663 	 0.3542628288269043 	 0.3126366138458252 	 
2025-07-30 13:46:30.580887 test begin: paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803260 	 1000 	 0.15183663368225098 	 0.1528477668762207 	 0.07757163047790527 	 0.07806849479675293 	 1.044058084487915 	 1.2485895156860352 	 0.21352386474609375 	 0.21257662773132324 	 
2025-07-30 13:46:34.032865 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803240 	 1000 	 0.4537684917449951 	 0.4762146472930908 	 0.4416937828063965 	 0.45738840103149414 	 1.315598726272583 	 1.6165504455566406 	 0.3360579013824463 	 0.33019542694091797 	 
2025-07-30 13:46:41.297566 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803240 	 1000 	 0.5136599540710449 	 0.18379640579223633 	 0.5006897449493408 	 0.16962933540344238 	 1.386796236038208 	 1.5302913188934326 	 0.3542346954345703 	 0.3126261234283447 	 
2025-07-30 13:46:45.959640 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803240 	 1000 	 0.15187525749206543 	 0.15297245979309082 	 0.07758116722106934 	 0.07817959785461426 	 1.0440430641174316 	 1.2484605312347412 	 0.21352934837341309 	 0.21252679824829102 	 
2025-07-30 13:46:49.372910 test begin: paddle.Tensor.amin(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, ) 	 50803230 	 1000 	 0.4537334442138672 	 0.47173476219177246 	 0.4415578842163086 	 0.45554375648498535 	 1.31553053855896 	 1.6162421703338623 	 0.33605289459228516 	 0.33012890815734863 	 
2025-07-30 13:46:54.209895 test begin: paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, ) 	 50803224 	 1000 	 6.286612272262573 	 0.17192769050598145 	 3.21242094039917 	 0.0878136157989502 	 5.725438356399536 	 1.3408231735229492 	 1.1685709953308105 	 0.2282564640045166 	 
2025-07-30 13:47:08.619662 test begin: paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, ) 	 50803224 	 1000 	 0.15183234214782715 	 0.15278887748718262 	 0.07756543159484863 	 0.07804465293884277 	 1.044039011001587 	 1.248495101928711 	 0.2135310173034668 	 0.2125077247619629 	 
2025-07-30 13:47:12.024816 test begin: paddle.Tensor.amin(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, ) 	 50803224 	 1000 	 0.16959190368652344 	 0.15453243255615234 	 0.08662867546081543 	 0.07896280288696289 	 1.065441608428955 	 1.2744576930999756 	 0.2179276943206787 	 0.2169046401977539 	 
2025-07-30 13:47:15.510724 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, ) 	 50803230 	 1000 	 0.20922017097473145 	 0.22643446922302246 	 0.1975545883178711 	 0.20357632637023926 	 1.26302170753479 	 1.5259459018707275 	 0.32262516021728516 	 0.3117377758026123 	 
2025-07-30 13:47:21.500103 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, ) 	 50803230 	 1000 	 0.151824951171875 	 0.15284276008605957 	 0.07757949829101562 	 0.07805919647216797 	 1.0440311431884766 	 1.2486648559570312 	 0.21352481842041016 	 0.21256184577941895 	 
2025-07-30 13:47:26.438043 test begin: paddle.Tensor.amin(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803260 	 1000 	 0.45369720458984375 	 0.47177886962890625 	 0.4414379596710205 	 0.45769786834716797 	 1.3154757022857666 	 1.6162755489349365 	 0.336076021194458 	 0.3301682472229004 	 
2025-07-30 13:47:31.359745 test begin: paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803260 	 1000 	 0.5136427879333496 	 0.18372511863708496 	 0.5006768703460693 	 0.16984915733337402 	 1.3868145942687988 	 1.530282974243164 	 0.35428595542907715 	 0.3126645088195801 	 
2025-07-30 13:47:37.507403 test begin: paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803260 	 1000 	 0.1518714427947998 	 0.15342187881469727 	 0.07760953903198242 	 0.07838821411132812 	 1.043987512588501 	 1.2488253116607666 	 0.21354389190673828 	 0.21257495880126953 	 
2025-07-30 13:47:41.325371 test begin: paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], ) 	 508354560 	 1000 	 0.49573445320129395 	 0.5515437126159668 	 0.2532846927642822 	 0.5373694896697998 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:49.681628 test begin: paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], ) 	 508178560 	 1000 	 0.5065882205963135 	 0.5689213275909424 	 0.25884151458740234 	 0.5545518398284912 	 None 	 None 	 None 	 None 	 
2025-07-30 13:47:57.637400 test begin: paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6372175216674805 	 0.5269465446472168 	 0.3256075382232666 	 0.5127372741699219 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:05.661686 test begin: paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5423908233642578 	 0.525226354598999 	 0.27713680267333984 	 0.511049747467041 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:13.577661 test begin: paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5424222946166992 	 0.5252323150634766 	 0.27715229988098145 	 0.510793924331665 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:21.573758 test begin: paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6371691226959229 	 0.5270137786865234 	 0.3255488872528076 	 0.5073373317718506 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:31.941711 test begin: paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], ) 	 554880000 	 1000 	 0.5383377075195312 	 0.7136955261230469 	 0.5265288352966309 	 0.6992533206939697 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:41.132853 test begin: paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], ) 	 508270080 	 1000 	 0.4952518939971924 	 0.6545064449310303 	 0.48352909088134766 	 0.6400797367095947 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:49.189991 test begin: paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6218760013580322 	 0.5348753929138184 	 0.3177616596221924 	 0.5204567909240723 	 None 	 None 	 None 	 None 	 
2025-07-30 13:48:57.172902 test begin: paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6219482421875 	 0.5348305702209473 	 0.3177988529205322 	 0.5205342769622803 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:05.262549 test begin: paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], ) 	 552960000 	 1000 	 0.5366570949554443 	 0.5988194942474365 	 0.27422356605529785 	 0.5842783451080322 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:13.854349 test begin: paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], ) 	 609408000 	 1000 	 0.604029655456543 	 0.6798977851867676 	 0.30866503715515137 	 0.6655929088592529 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:23.449970 test begin: paddle.Tensor.argmax(Tensor([13, 498, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([13, 498, 8000],"float32"), axis=2, ) 	 51792000 	 1000 	 0.2786083221435547 	 0.16979575157165527 	 0.26822733879089355 	 0.1494920253753662 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:24.746282 test begin: paddle.Tensor.argmax(Tensor([14, 457, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([14, 457, 8000],"float32"), axis=2, ) 	 51184000 	 1000 	 0.2750999927520752 	 0.1680281162261963 	 0.26468372344970703 	 0.1476435661315918 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:26.006614 test begin: paddle.Tensor.argmax(Tensor([14, 477, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([14, 477, 8000],"float32"), axis=2, ) 	 53424000 	 1000 	 0.28696537017822266 	 0.17355704307556152 	 0.2766597270965576 	 0.1598048210144043 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:27.356357 test begin: paddle.Tensor.argmax(Tensor([30, 212, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 212, 8000],"float32"), axis=2, ) 	 50880000 	 1000 	 0.2736246585845947 	 0.16740179061889648 	 0.26303744316101074 	 0.15360355377197266 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:28.628688 test begin: paddle.Tensor.argmax(Tensor([30, 457, 3706],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 457, 3706],"float32"), axis=2, ) 	 50809260 	 1000 	 0.34844446182250977 	 0.16284513473510742 	 0.33308959007263184 	 0.1491544246673584 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:29.954674 test begin: paddle.Tensor.argmax(Tensor([30, 477, 3551],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 477, 3551],"float32"), axis=2, ) 	 50814810 	 1000 	 0.35869550704956055 	 0.16741657257080078 	 0.34836459159851074 	 0.15264558792114258 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:31.293419 test begin: paddle.Tensor.argmax(Tensor([30, 498, 3401],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 498, 3401],"float32"), axis=2, ) 	 50810940 	 1000 	 0.3701174259185791 	 0.16524243354797363 	 0.3597259521484375 	 0.15140986442565918 	 None 	 None 	 None 	 None 	 
2025-07-30 13:49:34.416206 test begin: paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", ) 	 508559360 	 1000 	 0.003117084503173828 	 0.0024824142456054688 	 8.106231689453125e-06 	 1.621246337890625e-05 	 0.029276132583618164 	 0.04706573486328125 	 1.71661376953125e-05 	 3.314018249511719e-05 	 
2025-07-30 13:49:51.004257 test begin: paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", ) 	 508559360 	 1000 	 0.0031614303588867188 	 0.002401590347290039 	 6.198883056640625e-06 	 1.71661376953125e-05 	 0.029027700424194336 	 0.04701876640319824 	 2.4318695068359375e-05 	 3.743171691894531e-05 	 
2025-07-30 13:50:07.195445 test begin: paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", ) 	 671088640 	 1000 	 0.003205537796020508 	 0.0023849010467529297 	 1.52587890625e-05 	 1.8835067749023438e-05 	 0.029229164123535156 	 0.047575950622558594 	 4.553794860839844e-05 	 4.2438507080078125e-05 	 
2025-07-30 13:50:28.828378 test begin: paddle.Tensor.astype(Tensor([100352, 1013],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([100352, 1013],"bfloat16"), "float32", ) 	 101656576 	 1000 	 0.4815666675567627 	 0.5588712692260742 	 0.467801570892334 	 0.5457925796508789 	 0.4503967761993408 	 0.4538118839263916 	 0.39350438117980957 	 0.3856320381164551 	 
2025-07-30 13:50:34.147002 test begin: paddle.Tensor.astype(Tensor([1013, 100352],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1013, 100352],"bfloat16"), "float32", ) 	 101656576 	 1000 	 0.4815993309020996 	 0.5658414363861084 	 0.46782565116882324 	 0.5427281856536865 	 0.45035648345947266 	 0.4538123607635498 	 0.3936324119567871 	 0.38472723960876465 	 
2025-07-30 13:50:44.210774 test begin: paddle.Tensor.astype(Tensor([12404, 8192],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([12404, 8192],"bfloat16"), "float32", ) 	 101613568 	 1000 	 0.4817492961883545 	 0.5776538848876953 	 0.46804356575012207 	 0.5444660186767578 	 0.45093607902526855 	 0.45360612869262695 	 0.3941662311553955 	 0.3793025016784668 	 
2025-07-30 13:50:49.579886 test begin: paddle.Tensor.astype(Tensor([8192, 12404],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([8192, 12404],"bfloat16"), "float32", ) 	 101613568 	 1000 	 0.48167872428894043 	 0.5585603713989258 	 0.4680449962615967 	 0.545630693435669 	 0.45100903511047363 	 0.45366907119750977 	 0.39453721046447754 	 0.3785243034362793 	 
2025-07-30 13:50:54.787037 test begin: paddle.Tensor.atanh(Tensor([1, 16934401, 3],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2971518039703369 	 0.29927921295166016 	 0.288316011428833 	 0.2876417636871338 	 0.4502749443054199 	 1.6223704814910889 	 0.3972330093383789 	 0.33165669441223145 	 
2025-07-30 13:50:59.144346 test begin: paddle.Tensor.atanh(Tensor([1, 2, 12700801],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.44399595260620117 	 0.410672664642334 	 0.4354135990142822 	 0.396500825881958 	 0.4482393264770508 	 1.6204981803894043 	 0.39557647705078125 	 0.3313252925872803 	 
2025-07-30 13:51:03.132706 test begin: paddle.Tensor.atanh(Tensor([1, 2, 25401601],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.297100305557251 	 0.29997992515563965 	 0.28826022148132324 	 0.28768253326416016 	 0.45012426376342773 	 1.6225826740264893 	 0.39714837074279785 	 0.33168935775756836 	 
2025-07-30 13:51:11.418979 test begin: paddle.Tensor.atanh(Tensor([1, 8467201, 3],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.4439730644226074 	 0.40863919258117676 	 0.43534111976623535 	 0.3958275318145752 	 0.4489881992340088 	 1.6206953525543213 	 0.3963897228240967 	 0.33127474784851074 	 
2025-07-30 13:51:15.469608 test begin: paddle.Tensor.atanh(Tensor([2, 12700801],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.4439549446105957 	 0.40770745277404785 	 0.4353616237640381 	 0.3974142074584961 	 0.44829702377319336 	 1.6203007698059082 	 0.3929605484008789 	 0.33128905296325684 	 
2025-07-30 13:51:19.438445 test begin: paddle.Tensor.atanh(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.44399070739746094 	 0.4076542854309082 	 0.4353792667388916 	 0.3974034786224365 	 0.4480733871459961 	 1.6203584671020508 	 0.39562058448791504 	 0.33124494552612305 	 
2025-07-30 13:51:23.414005 test begin: paddle.Tensor.atanh(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.4439387321472168 	 0.40767478942871094 	 0.4351944923400879 	 0.397294282913208 	 0.44808268547058105 	 1.620436668395996 	 0.3955700397491455 	 0.3312411308288574 	 
2025-07-30 13:51:27.407916 test begin: paddle.Tensor.atanh(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.29712653160095215 	 0.2981560230255127 	 0.2881770133972168 	 0.2878086566925049 	 0.45029497146606445 	 1.6223881244659424 	 0.39765429496765137 	 0.33168697357177734 	 
2025-07-30 13:51:31.738319 test begin: paddle.Tensor.bmm(Tensor([1, 16934401, 3],"float32"), Tensor([1, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 16934401, 3],"float32"), Tensor([1, 3, 2],"float32"), ) 	 50803209 	 1000 	 1.7797694206237793 	 1.7862505912780762 	 0.10689640045166016 	 0.10691714286804199 	 4.1435158252716064 	 4.138272047042847 	 0.22326087951660156 	 0.22087574005126953 	 
2025-07-30 13:51:46.323354 test begin: paddle.Tensor.bmm(Tensor([1, 170476, 299],"float32"), Tensor([1, 299, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 170476, 299],"float32"), Tensor([1, 299, 2],"float32"), ) 	 50972922 	 1000 	 0.23935747146606445 	 0.23942208290100098 	 0.22486066818237305 	 0.2214367389678955 	 0.42539310455322266 	 0.42206597328186035 	 0.1446545124053955 	 0.14351630210876465 	 
2025-07-30 13:51:48.498393 test begin: paddle.Tensor.bmm(Tensor([1, 179876, 283],"float32"), Tensor([1, 283, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 179876, 283],"float32"), Tensor([1, 283, 2],"float32"), ) 	 50905474 	 1000 	 0.2412583827972412 	 0.2411479949951172 	 0.224043607711792 	 0.22113752365112305 	 0.41695404052734375 	 0.4173927307128906 	 0.14189887046813965 	 0.14206433296203613 	 
2025-07-30 13:51:53.077909 test begin: paddle.Tensor.bmm(Tensor([1, 191277, 266],"float32"), Tensor([1, 266, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 191277, 266],"float32"), Tensor([1, 266, 2],"float32"), ) 	 50880214 	 1000 	 0.23398971557617188 	 0.23395705223083496 	 0.21788787841796875 	 0.214430570602417 	 0.4213109016418457 	 0.4207465648651123 	 0.14342904090881348 	 0.14316201210021973 	 
2025-07-30 13:51:55.253754 test begin: paddle.Tensor.bmm(Tensor([100, 170476, 3],"float32"), Tensor([100, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([100, 170476, 3],"float32"), Tensor([100, 3, 2],"float32"), ) 	 51143400 	 1000 	 4.851692199707031 	 4.854583024978638 	 4.8393330574035645 	 4.831963062286377 	 38.53541421890259 	 38.53322792053223 	 19.691092014312744 	 19.6901273727417 	 
2025-07-30 13:53:23.716750 test begin: paddle.Tensor.bmm(Tensor([89, 191277, 3],"float32"), Tensor([89, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([89, 191277, 3],"float32"), Tensor([89, 3, 2],"float32"), ) 	 51071493 	 1000 	 4.843317270278931 	 4.843544006347656 	 4.830785274505615 	 4.827695369720459 	 42.63739895820618 	 42.63751745223999 	 21.786911487579346 	 21.787740468978882 	 
2025-07-30 13:55:00.196902 test begin: paddle.Tensor.bmm(Tensor([95, 179876, 3],"float32"), Tensor([95, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([95, 179876, 3],"float32"), Tensor([95, 3, 2],"float32"), ) 	 51265230 	 1000 	 4.864249229431152 	 4.866502046585083 	 4.851602792739868 	 4.8459320068359375 	 40.40538930892944 	 40.40745830535889 	 20.64702033996582 	 20.648045539855957 	 
2025-07-30 13:56:32.236350 test begin: paddle.Tensor.cast(Tensor([128256, 793],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([128256, 793],"float16"), Dtype(float16), ) 	 101707008 	 1000 	 0.3071317672729492 	 0.003043651580810547 	 0.15694117546081543 	 1.8835067749023438e-05 	 0.30779600143432617 	 0.04630756378173828 	 0.15721988677978516 	 3.4809112548828125e-05 	 combined
2025-07-30 13:56:39.320016 test begin: paddle.Tensor.cast(Tensor([152064, 669],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([152064, 669],"float16"), Dtype(float16), ) 	 101730816 	 1000 	 0.31455397605895996 	 0.0020101070404052734 	 0.16074490547180176 	 1.6689300537109375e-05 	 0.31427621841430664 	 0.04645228385925293 	 0.16054630279541016 	 4.696846008300781e-05 	 combined
2025-07-30 13:56:43.680830 test begin: paddle.Tensor.cast(Tensor([24807, 4096],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([24807, 4096],"float16"), Dtype(float16), ) 	 101609472 	 1000 	 0.31002044677734375 	 0.002012014389038086 	 0.29929113388061523 	 1.5497207641601562e-05 	 0.3100619316101074 	 0.04644298553466797 	 0.25455594062805176 	 4.553794860839844e-05 	 combined
2025-07-30 13:56:48.099868 test begin: paddle.Tensor.cast(Tensor([28351, 3584],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([28351, 3584],"float16"), Dtype(float16), ) 	 101609984 	 1000 	 0.314298152923584 	 0.0020394325256347656 	 0.1606156826019287 	 2.0503997802734375e-05 	 0.31392502784729004 	 0.047139644622802734 	 0.16036081314086914 	 7.224082946777344e-05 	 combined
2025-07-30 13:56:52.465899 test begin: paddle.Tensor.cast(Tensor([3584, 28351],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([3584, 28351],"float16"), Dtype(float16), ) 	 101609984 	 1000 	 0.3142666816711426 	 0.0020051002502441406 	 0.1605997085571289 	 1.52587890625e-05 	 0.31392693519592285 	 0.046655893325805664 	 0.16035771369934082 	 6.937980651855469e-05 	 combined
2025-07-30 13:56:56.909283 test begin: paddle.Tensor.cast(Tensor([669, 152064],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([669, 152064],"float16"), Dtype(float16), ) 	 101730816 	 1000 	 0.3146026134490967 	 0.002040386199951172 	 0.16077685356140137 	 1.6450881958007812e-05 	 0.3142697811126709 	 0.046465396881103516 	 0.1605367660522461 	 5.1021575927734375e-05 	 combined
2025-07-30 13:57:01.302787 test begin: paddle.Tensor.ceil(Tensor([1, 50803201],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([1, 50803201],"float32"), ) 	 50803201 	 1000 	 0.29561400413513184 	 0.2978324890136719 	 0.28687477111816406 	 0.28737759590148926 	 0.13395237922668457 	 0.13402748107910156 	 0.08397507667541504 	 0.06764364242553711 	 
2025-07-30 13:57:03.776776 test begin: paddle.Tensor.ceil(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.295687198638916 	 0.29785823822021484 	 0.286806583404541 	 0.28726840019226074 	 0.13385796546936035 	 0.13399362564086914 	 0.0841517448425293 	 0.06626129150390625 	 
2025-07-30 13:57:06.245657 test begin: paddle.Tensor.ceil(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2956364154815674 	 0.2978992462158203 	 0.286679744720459 	 0.28739023208618164 	 0.13399624824523926 	 0.1340780258178711 	 0.08430838584899902 	 0.06756925582885742 	 
2025-07-30 13:57:08.696216 test begin: paddle.Tensor.ceil(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2956063747406006 	 0.29780006408691406 	 0.28681516647338867 	 0.2872920036315918 	 0.13395357131958008 	 0.13410329818725586 	 0.08376693725585938 	 0.0680534839630127 	 
2025-07-30 13:57:11.146119 test begin: paddle.Tensor.ceil(Tensor([25401601, 2],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([25401601, 2],"float32"), ) 	 50803202 	 1000 	 0.29561781883239746 	 0.2978799343109131 	 0.2868359088897705 	 0.28726863861083984 	 0.13402175903320312 	 0.13403749465942383 	 0.0843808650970459 	 0.0674283504486084 	 
2025-07-30 13:57:13.589141 test begin: paddle.Tensor.ceil(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2956557273864746 	 0.29787731170654297 	 0.28670644760131836 	 0.2874171733856201 	 0.13398218154907227 	 0.1340770721435547 	 0.08385586738586426 	 0.06683707237243652 	 
2025-07-30 13:57:16.043757 test begin: paddle.Tensor.ceil(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29563331604003906 	 0.29787445068359375 	 0.2866952419281006 	 0.28745079040527344 	 0.1348867416381836 	 0.1342320442199707 	 0.0845026969909668 	 0.06658053398132324 	 
2025-07-30 13:57:18.973956 test begin: paddle.Tensor.chunk(Tensor([1034, 32, 64, 48],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([1034, 32, 64, 48],"float16"), 2, axis=1, ) 	 101646336 	 1000 	 0.4582180976867676 	 0.006685972213745117 	 0.4436347484588623 	 2.3603439331054688e-05 	 0.30788660049438477 	 0.45206403732299805 	 0.25266551971435547 	 0.36745357513427734 	 
2025-07-30 13:57:24.153501 test begin: paddle.Tensor.chunk(Tensor([128, 2068, 192],"float32"), 3, axis=-1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([128, 2068, 192],"float32"), 3, axis=-1, ) 	 50823168 	 1000 	 0.34262871742248535 	 0.007674455642700195 	 0.32724857330322266 	 3.4332275390625e-05 	 0.30895185470581055 	 0.3095052242279053 	 0.25057291984558105 	 0.21463370323181152 	 
2025-07-30 13:57:26.818016 test begin: paddle.Tensor.chunk(Tensor([512, 32, 130, 48],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 130, 48],"float16"), 2, axis=1, ) 	 102236160 	 1000 	 0.45557665824890137 	 0.006754875183105469 	 0.44135141372680664 	 2.0742416381835938e-05 	 0.3141977787017822 	 0.45425915718078613 	 0.2589089870452881 	 0.36885738372802734 	 
2025-07-30 13:57:31.850689 test begin: paddle.Tensor.chunk(Tensor([512, 32, 64, 49],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 64, 49],"float32"), 2, axis=1, ) 	 51380224 	 1000 	 0.35188984870910645 	 0.006702423095703125 	 0.3381218910217285 	 2.002716064453125e-05 	 0.31427621841430664 	 0.3128700256347656 	 0.25899767875671387 	 0.227402925491333 	 
2025-07-30 13:57:34.519698 test begin: paddle.Tensor.chunk(Tensor([512, 32, 64, 97],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 64, 97],"float16"), 2, axis=1, ) 	 101711872 	 1000 	 0.45409631729125977 	 0.0067539215087890625 	 0.4398982524871826 	 2.8371810913085938e-05 	 0.31239938735961914 	 0.4514589309692383 	 0.2569162845611572 	 0.3629317283630371 	 
2025-07-30 13:57:39.827196 test begin: paddle.Tensor.chunk(Tensor([512, 32, 65, 48],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 65, 48],"float32"), 2, axis=1, ) 	 51118080 	 1000 	 0.35109519958496094 	 0.006728410720825195 	 0.3372206687927246 	 2.0265579223632812e-05 	 0.3142554759979248 	 0.31140851974487305 	 0.2591061592102051 	 0.22615623474121094 	 
2025-07-30 13:57:42.516918 test begin: paddle.Tensor.chunk(Tensor([517, 32, 64, 48],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([517, 32, 64, 48],"float32"), 2, axis=1, ) 	 50823168 	 1000 	 0.3487427234649658 	 0.006758213043212891 	 0.33486461639404297 	 2.193450927734375e-05 	 0.3077423572540283 	 0.3103790283203125 	 0.24868416786193848 	 0.22482848167419434 	 
2025-07-30 13:57:45.096650 test begin: paddle.Tensor.chunk(Tensor([85, 3136, 192],"float32"), 3, axis=-1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([85, 3136, 192],"float32"), 3, axis=-1, ) 	 51179520 	 1000 	 0.3471693992614746 	 0.0076105594635009766 	 0.33207035064697266 	 2.288818359375e-05 	 0.31145143508911133 	 0.3109891414642334 	 0.25283312797546387 	 0.21831822395324707 	 
2025-07-30 13:57:47.705133 test begin: paddle.Tensor.clip(Tensor([1, 386, 65856, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 386, 65856, 2],"float32"), 0, ) 	 50840832 	 1000 	 0.29572319984436035 	 0.29805898666381836 	 0.27910327911376953 	 0.28524017333984375 	 0.45078444480895996 	 0.5959274768829346 	 0.3981599807739258 	 0.20314240455627441 	 
2025-07-30 13:57:51.042579 test begin: paddle.Tensor.clip(Tensor([1, 400, 63505, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 400, 63505, 2],"float32"), 0, ) 	 50804000 	 1000 	 0.29537200927734375 	 0.29784297943115234 	 0.2791025638580322 	 0.28509044647216797 	 0.4502854347229004 	 0.5954055786132812 	 0.3977847099304199 	 0.20284605026245117 	 
2025-07-30 13:57:54.355191 test begin: paddle.Tensor.clip(Tensor([1, 400, 65856, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 400, 65856, 2],"float32"), 0, ) 	 52684800 	 1000 	 0.30661988258361816 	 0.3087286949157715 	 0.29026269912719727 	 0.29548215866088867 	 0.46682310104370117 	 0.6161587238311768 	 0.4109971523284912 	 0.21009039878845215 	 
2025-07-30 13:57:57.783830 test begin: paddle.Tensor.clip(Tensor([2100, 12096, 3],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2100, 12096, 3],"float32"), 0, ) 	 76204800 	 1000 	 0.4411756992340088 	 0.4441695213317871 	 0.4249613285064697 	 0.4308159351348877 	 0.6728756427764893 	 0.8844437599182129 	 0.6200594902038574 	 0.30155301094055176 	 
2025-07-30 13:58:02.745933 test begin: paddle.Tensor.clip(Tensor([2100, 12097, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2100, 12097, 2],"float32"), 0, ) 	 50807400 	 1000 	 0.2953205108642578 	 0.29786109924316406 	 0.2790868282318115 	 0.2837846279144287 	 0.44994616508483887 	 0.5954411029815674 	 0.39747166633605957 	 0.202986478805542 	 
2025-07-30 13:58:06.079047 test begin: paddle.Tensor.clip(Tensor([2101, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2101, 12096, 2],"float32"), 0, ) 	 50827392 	 1000 	 0.29552698135375977 	 0.2979867458343506 	 0.2794017791748047 	 0.2850344181060791 	 0.4501454830169678 	 0.5956847667694092 	 0.39729928970336914 	 0.2030162811279297 	 
2025-07-30 13:58:09.361069 test begin: paddle.Tensor.clip(Tensor([4, 525, 12096, 3],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 525, 12096, 3],"float32"), 0, ) 	 76204800 	 1000 	 0.4412562847137451 	 0.4441695213317871 	 0.4250297546386719 	 0.43065524101257324 	 0.6725647449493408 	 0.8844451904296875 	 0.6189885139465332 	 0.30153441429138184 	 
2025-07-30 13:58:14.404403 test begin: paddle.Tensor.clip(Tensor([4, 525, 12097, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 525, 12097, 2],"float32"), 0, ) 	 50807400 	 1000 	 0.2953040599822998 	 0.29784560203552246 	 0.2786557674407959 	 0.2850198745727539 	 0.449965238571167 	 0.5954489707946777 	 0.3975484371185303 	 0.20299339294433594 	 
2025-07-30 13:58:17.753165 test begin: paddle.Tensor.clip(Tensor([4, 526, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 526, 12096, 2],"float32"), 0, ) 	 50899968 	 1000 	 0.2959446907043457 	 0.2985682487487793 	 0.2796027660369873 	 0.28511929512023926 	 0.4512653350830078 	 0.5962262153625488 	 0.39836597442626953 	 0.20324182510375977 	 
2025-07-30 13:58:21.086491 test begin: paddle.Tensor.clip(Tensor([5, 525, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([5, 525, 12096, 2],"float32"), 0, ) 	 63504000 	 1000 	 0.36807847023010254 	 1.4851720333099365 	 0.35178518295288086 	 0.35732150077819824 	 0.5610659122467041 	 0.7397091388702393 	 0.508497953414917 	 0.25217103958129883 	 
2025-07-30 13:58:27.080996 test begin: paddle.Tensor.clone(Tensor([3544, 32, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([3544, 32, 896],"bfloat16"), ) 	 101613568 	 1000 	 0.30985116958618164 	 0.31015849113464355 	 0.30100393295288086 	 0.2974128723144531 	 0.6153576374053955 	 0.4537625312805176 	 0.5578558444976807 	 0.37465667724609375 	 
2025-07-30 13:58:32.077272 test begin: paddle.Tensor.clone(Tensor([6017, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6017, 19, 896],"bfloat16"), ) 	 102433408 	 1000 	 0.31657886505126953 	 0.3235054016113281 	 0.16176676750183105 	 0.16115069389343262 	 0.6273376941680908 	 0.45719432830810547 	 0.32040977478027344 	 0.3783226013183594 	 
2025-07-30 13:58:39.646975 test begin: paddle.Tensor.clone(Tensor([6017, 32, 528],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6017, 32, 528],"bfloat16"), ) 	 101663232 	 1000 	 0.31412363052368164 	 0.31296443939208984 	 0.1605057716369629 	 0.15981626510620117 	 0.6218276023864746 	 0.45386672019958496 	 0.3176918029785156 	 0.37353968620300293 	 
2025-07-30 13:58:44.669307 test begin: paddle.Tensor.clone(Tensor([6036, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6036, 19, 896],"bfloat16"), ) 	 102756864 	 1000 	 0.31752872467041016 	 0.3228645324707031 	 0.1622622013092041 	 0.16151022911071777 	 0.6282327175140381 	 0.45870232582092285 	 0.32095789909362793 	 0.3789489269256592 	 
2025-07-30 13:58:49.689523 test begin: paddle.Tensor.clone(Tensor([6036, 32, 527],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6036, 32, 527],"bfloat16"), ) 	 101791104 	 1000 	 0.3147101402282715 	 0.3135397434234619 	 0.16081643104553223 	 0.16015052795410156 	 0.6229500770568848 	 0.45449280738830566 	 0.3182690143585205 	 0.37128233909606934 	 
2025-07-30 13:58:54.722418 test begin: paddle.Tensor.clone(Tensor([6078, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6078, 19, 896],"bfloat16"), ) 	 103471872 	 1000 	 0.3131587505340576 	 0.31868886947631836 	 0.16002345085144043 	 0.16272306442260742 	 0.6177878379821777 	 0.46186327934265137 	 0.31563830375671387 	 0.38144898414611816 	 
2025-07-30 13:58:59.702931 test begin: paddle.Tensor.clone(Tensor([6078, 32, 523],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6078, 32, 523],"bfloat16"), ) 	 101721408 	 1000 	 0.3137083053588867 	 0.31707072257995605 	 0.16030025482177734 	 0.16006016731262207 	 0.6237697601318359 	 0.4541659355163574 	 0.3186936378479004 	 0.37438106536865234 	 
2025-07-30 13:59:04.849724 test begin: paddle.Tensor.conj(Tensor([10, 2540161],"float64"), )
[Prof] paddle.Tensor.conj 	 paddle.Tensor.conj(Tensor([10, 2540161],"float64"), ) 	 25401610 	 1000 	 0.2975273132324219 	 0.0016562938690185547 	 0.28925251960754395 	 1.5020370483398438e-05 	 0.2971494197845459 	 0.046320438385009766 	 0.24790120124816895 	 4.6253204345703125e-05 	 
2025-07-30 13:59:06.571527 test begin: paddle.Tensor.conj(Tensor([1270081, 20],"float64"), )
[Prof] paddle.Tensor.conj 	 paddle.Tensor.conj(Tensor([1270081, 20],"float64"), ) 	 25401620 	 1000 	 0.29755568504333496 	 0.0017070770263671875 	 0.2894566059112549 	 1.5735626220703125e-05 	 0.29715800285339355 	 0.04631471633911133 	 0.24790453910827637 	 4.744529724121094e-05 	 
2025-07-30 13:59:08.264865 test begin: paddle.Tensor.cos(Tensor([131072, 388],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([131072, 388],"float32"), ) 	 50855936 	 1000 	 0.295729398727417 	 0.2984192371368408 	 0.28694725036621094 	 0.2881486415863037 	 0.4508695602416992 	 1.04184889793396 	 0.39686107635498047 	 0.3549520969390869 	 
2025-07-30 13:59:12.004148 test begin: paddle.Tensor.cos(Tensor([3175201, 16],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([3175201, 16],"float32"), ) 	 50803216 	 1000 	 0.29538559913635254 	 0.29817724227905273 	 0.2866525650024414 	 0.2878539562225342 	 0.45023036003112793 	 1.0408401489257812 	 0.39794921875 	 0.3546292781829834 	 
2025-07-30 13:59:15.704177 test begin: paddle.Tensor.cos(Tensor([32768, 1551],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.2954256534576416 	 0.298231840133667 	 0.28670454025268555 	 0.2879977226257324 	 0.4504268169403076 	 1.0411922931671143 	 0.3977084159851074 	 0.3547353744506836 	 
2025-07-30 13:59:19.448356 test begin: paddle.Tensor.cos(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2952427864074707 	 0.29808712005615234 	 0.28650593757629395 	 0.2877516746520996 	 0.45018959045410156 	 1.0407557487487793 	 0.39775514602661133 	 0.3545691967010498 	 
2025-07-30 13:59:23.148553 test begin: paddle.Tensor.cumprod(Tensor([25401601],"float64"), -1, )
[Prof] paddle.Tensor.cumprod 	 paddle.Tensor.cumprod(Tensor([25401601],"float64"), -1, ) 	 25401601 	 1000 	 0.32518696784973145 	 0.3339266777038574 	 0.1661531925201416 	 0.16709113121032715 	 2.7954037189483643 	 2.0576624870300293 	 0.0003170967102050781 	 0.0012822151184082031 	 
2025-07-30 13:59:31.764346 test begin: paddle.Tensor.cumprod(Tensor([50803201],"float32"), -1, )
[Prof] paddle.Tensor.cumprod 	 paddle.Tensor.cumprod(Tensor([50803201],"float32"), -1, ) 	 50803201 	 1000 	 0.325397253036499 	 0.33475422859191895 	 0.16624665260314941 	 0.16840291023254395 	 3.127258062362671 	 2.1202666759490967 	 0.00030541419982910156 	 0.0013103485107421875 	 
2025-07-30 13:59:41.828370 test begin: paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 1, ) 	 50803344 	 1000 	 1.2521884441375732 	 0.3560676574707031 	 0.4266653060913086 	 0.3451802730560303 	 6.4020233154296875 	 0.9767241477966309 	 1.308870553970337 	 0.33269596099853516 	 
2025-07-30 13:59:52.522548 test begin: paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 2, ) 	 50803344 	 1000 	 0.887164831161499 	 1.0163531303405762 	 0.8775424957275391 	 1.0058133602142334 	 1.6876184940338135 	 1.641256332397461 	 0.5749385356903076 	 0.5593357086181641 	 
2025-07-30 13:59:59.414985 test begin: paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 1, ) 	 50803400 	 1000 	 1.426232099533081 	 125.03043580055237 	 0.485889196395874 	 125.0195746421814 	 2.1609857082366943 	 123.0313127040863 	 0.44147515296936035 	 41.95313286781311 	 
2025-07-30 14:04:13.009104 test begin: paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 2, ) 	 50803400 	 1000 	 0.4049036502838135 	 2.8233566284179688 	 0.3953542709350586 	 2.8123700618743896 	 4.159580707550049 	 3.445394515991211 	 1.4164798259735107 	 1.1745078563690186 	 
2025-07-30 14:04:25.556517 test begin: paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 1, ) 	 50832000 	 1000 	 1.289794921875 	 0.363971471786499 	 0.439469575881958 	 0.351574182510376 	 6.436070203781128 	 0.9937217235565186 	 1.3158812522888184 	 0.33846235275268555 	 
2025-07-30 14:04:37.586592 test begin: paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 2, ) 	 50832000 	 1000 	 0.405184268951416 	 2.8289783000946045 	 0.39563465118408203 	 2.8119382858276367 	 4.160557985305786 	 3.4474334716796875 	 1.4168572425842285 	 1.1752400398254395 	 
2025-07-30 14:04:50.051286 test begin: paddle.Tensor.cumsum(Tensor([211681, 120],"int64"), )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([211681, 120],"int64"), ) 	 25401720 	 1000 	 0.3461148738861084 	 0.3262062072753906 	 4.220008850097656e-05 	 0.1665654182434082 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:04:51.925186 test begin: paddle.Tensor.cumsum(Tensor([300, 84673],"int64"), )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([300, 84673],"int64"), ) 	 25401900 	 1000 	 0.34555959701538086 	 0.3262510299682617 	 4.3392181396484375e-05 	 0.16666078567504883 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:04:53.917750 test begin: paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), ) 	 1016565760 	 1000 	 0.0008075237274169922 	 0.0029032230377197266 	 8.106231689453125e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:05:31.974417 test begin: paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), ) 	 1016565760 	 1000 	 0.0008296966552734375 	 0.002911806106567383 	 1.5735626220703125e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:06:04.749205 test begin: paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0008029937744140625 	 0.002928495407104492 	 9.775161743164062e-06 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:06:44.296922 test begin: paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007927417755126953 	 0.002956390380859375 	 5.9604644775390625e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:07:18.652365 test begin: paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), ) 	 1016135680 	 1000 	 0.0008280277252197266 	 0.002909421920776367 	 7.152557373046875e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:07:51.814728 test begin: paddle.Tensor.diag_embed(Tensor([1, 25401601, 2],"float32"), )
[Prof] paddle.Tensor.diag_embed 	 paddle.Tensor.diag_embed(Tensor([1, 25401601, 2],"float32"), ) 	 50803202 	 1000 	 1.7673277854919434 	 1.0145695209503174 	 5.1975250244140625e-05 	 0.5179533958435059 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:55.473554 test begin: paddle.Tensor.diag_embed(Tensor([25401601, 1, 2],"float32"), )
[Prof] paddle.Tensor.diag_embed 	 paddle.Tensor.diag_embed(Tensor([25401601, 1, 2],"float32"), ) 	 50803202 	 1000 	 1.769090175628662 	 1.013765573501587 	 4.935264587402344e-05 	 0.5178577899932861 	 None 	 None 	 None 	 None 	 
2025-07-30 14:07:59.072324 test begin: paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, ) 	 25486272 	 1000 	 0.003674745559692383 	 0.004687309265136719 	 7.152557373046875e-06 	 1.811981201171875e-05 	 0.14977502822875977 	 0.14008092880249023 	 0.07636713981628418 	 0.02406454086303711 	 
2025-07-30 14:07:59.942412 test begin: paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, ) 	 25401603 	 1000 	 0.004848480224609375 	 0.0046308040618896484 	 3.218650817871094e-05 	 1.7642974853515625e-05 	 0.1486668586730957 	 0.13826417922973633 	 0.07588815689086914 	 0.0550379753112793 	 
2025-07-30 14:08:00.754340 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.9445598125457764 	 0.2615232467651367 	 0.3217768669128418 	 0.24304747581481934 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:02.480699 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.9443349838256836 	 0.2634158134460449 	 0.3216822147369385 	 0.24180006980895996 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:04.212301 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.9442789554595947 	 0.2614760398864746 	 0.321669340133667 	 0.24242019653320312 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:05.934574 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.8705008029937744 	 0.2614729404449463 	 0.2965426445007324 	 0.24303030967712402 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:07.590688 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.870490312576294 	 0.26151037216186523 	 0.2965402603149414 	 0.2422480583190918 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:09.251744 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8705000877380371 	 0.2615196704864502 	 0.29653406143188477 	 0.24228549003601074 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:10.930245 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.8704690933227539 	 0.2615389823913574 	 0.2965421676635742 	 0.2339639663696289 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:12.592446 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 1.0702731609344482 	 0.2994568347930908 	 0.3646419048309326 	 0.27968311309814453 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:14.465898 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 1.070228099822998 	 0.29943370819091797 	 0.36461329460144043 	 0.27964305877685547 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:16.352174 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 1.069859266281128 	 0.757692813873291 	 0.3645131587982178 	 0.2808501720428467 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:19.363317 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8069217205047607 	 0.49632978439331055 	 0.27492737770080566 	 0.24278020858764648 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:21.801956 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8067727088928223 	 0.26280808448791504 	 0.2748684883117676 	 0.24349737167358398 	 None 	 None 	 None 	 None 	 
2025-07-30 14:08:23.415667 test begin: paddle.Tensor.digamma(Tensor([4, 6350401],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 1.1712090969085693 	 1.1442527770996094 	 1.1628215312957764 	 1.126784086227417 	 8.57021164894104 	 1.086228609085083 	 8.518750667572021 	 0.5548851490020752 	 
2025-07-30 14:08:37.624213 test begin: paddle.Tensor.digamma(Tensor([453601, 7, 8],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([453601, 7, 8],"float64"), ) 	 25401656 	 1000 	 1.5020408630371094 	 1.1439588069915771 	 1.493776559829712 	 1.134077548980713 	 8.569303750991821 	 1.0859284400939941 	 8.517541646957397 	 0.5548403263092041 	 
2025-07-30 14:08:51.041865 test begin: paddle.Tensor.digamma(Tensor([45361, 7, 8, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([45361, 7, 8, 10],"float64"), ) 	 25402160 	 1000 	 1.17118501663208 	 1.1438989639282227 	 1.162111759185791 	 1.1339550018310547 	 8.568493604660034 	 1.0858261585235596 	 8.516709566116333 	 0.5547845363616943 	 
2025-07-30 14:09:04.100902 test begin: paddle.Tensor.digamma(Tensor([5, 635041, 8],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 635041, 8],"float64"), ) 	 25401640 	 1000 	 1.1707699298858643 	 1.146245002746582 	 1.1624305248260498 	 1.1330766677856445 	 8.568228960037231 	 1.0857832431793213 	 8.516356945037842 	 0.5547783374786377 	 
2025-07-30 14:09:17.180198 test begin: paddle.Tensor.digamma(Tensor([5, 63505, 8, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 63505, 8, 10],"float64"), ) 	 25402000 	 1000 	 1.1708893775939941 	 1.143568754196167 	 1.1622331142425537 	 1.1335859298706055 	 8.56614089012146 	 1.0857036113739014 	 8.514009475708008 	 0.5547277927398682 	 
2025-07-30 14:09:30.273505 test begin: paddle.Tensor.digamma(Tensor([5, 7, 725761],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 725761],"float64"), ) 	 25401635 	 1000 	 1.1706523895263672 	 1.1436035633087158 	 1.1624369621276855 	 1.1337203979492188 	 8.566043853759766 	 1.0855538845062256 	 8.51446008682251 	 0.554631233215332 	 
2025-07-30 14:09:43.403839 test begin: paddle.Tensor.digamma(Tensor([5, 7, 72577, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 72577, 10],"float64"), ) 	 25401950 	 1000 	 1.1706287860870361 	 1.1452052593231201 	 1.1623473167419434 	 1.1325056552886963 	 8.565792560577393 	 1.0855886936187744 	 8.514221429824829 	 0.5546681880950928 	 
2025-07-30 14:09:56.465293 test begin: paddle.Tensor.digamma(Tensor([5, 7, 8, 90721],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 8, 90721],"float64"), ) 	 25401880 	 1000 	 1.1704401969909668 	 1.1433329582214355 	 1.1620538234710693 	 1.133453130722046 	 8.566861152648926 	 1.0855085849761963 	 8.515374660491943 	 0.5546488761901855 	 
2025-07-30 14:10:09.508346 test begin: paddle.Tensor.digamma(Tensor([5080321, 5],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5080321, 5],"float64"), ) 	 25401605 	 1000 	 1.1703243255615234 	 1.1432914733886719 	 1.1619317531585693 	 1.1334021091461182 	 8.56575632095337 	 1.0854828357696533 	 8.512606859207153 	 0.5546259880065918 	 
2025-07-30 14:10:22.583635 test begin: paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), ) 	 1016821760 	 1000 	 0.0007107257843017578 	 0.0015764236450195312 	 1.2874603271484375e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:10:40.761398 test begin: paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007083415985107422 	 0.0015294551849365234 	 8.106231689453125e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:10:56.969398 test begin: paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), ) 	 1016135680 	 1000 	 0.0006928443908691406 	 0.0015683174133300781 	 7.3909759521484375e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:11:13.505012 test begin: paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), ) 	 1016135680 	 1000 	 0.000713348388671875 	 0.0016012191772460938 	 8.58306884765625e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:11:29.719000 test begin: paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), ) 	 1016821760 	 1000 	 0.0007023811340332031 	 0.0015518665313720703 	 9.298324584960938e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:11:46.099077 test begin: paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), ) 	 1016243200 	 1000 	 0.0007064342498779297 	 0.001556396484375 	 7.3909759521484375e-06 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:04.854121 test begin: paddle.Tensor.dot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
Warning: The core code of paddle.Tensor.dot is too complex.
[Prof] paddle.Tensor.dot 	 paddle.Tensor.dot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.29622888565063477 	 0.2930161952972412 	 0.28719091415405273 	 0.1497180461883545 	 0.7111873626708984 	 0.6038062572479248 	 0.3633713722229004 	 0.30849480628967285 	 
2025-07-30 14:12:08.457911 test begin: paddle.Tensor.equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), ) 	 50803456 	 1000 	 0.30904173851013184 	 0.3132202625274658 	 0.29828763008117676 	 0.3018028736114502 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:09.898553 test begin: paddle.Tensor.equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), ) 	 50803456 	 1000 	 0.3089570999145508 	 0.313185453414917 	 0.29839062690734863 	 0.3015885353088379 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:11.327886 test begin: paddle.Tensor.equal(Tensor([2, 12700801],"int64"), 3, )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([2, 12700801],"int64"), 3, ) 	 25401602 	 1000 	 0.1781294345855713 	 0.16960453987121582 	 0.09097981452941895 	 0.15360283851623535 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:12.084229 test begin: paddle.Tensor.equal(Tensor([2540161, 10],"int64"), 3, )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([2540161, 10],"int64"), 3, ) 	 25401610 	 1000 	 0.1780540943145752 	 0.16818809509277344 	 0.09093546867370605 	 0.15407514572143555 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:53.209758 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
W0730 14:12:54.302627 18860 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 0.3408396244049072 	 0.37867212295532227 	 0.1159217357635498 	 7.43865966796875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:55.398548 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), ) 	 25402402 	 1000 	 0.016449928283691406 	 0.0026967525482177734 	 9.775161743164062e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:55.831803 test begin: paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3175201],"int64"), ) 	 50803216 	 1000 	 0.34111523628234863 	 0.38209962844848633 	 0.11600470542907715 	 7.796287536621094e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:12:57.387103 test begin: paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), ) 	 2543338404 	 1000 	 0.022953510284423828 	 0.00485539436340332 	 1.5497207641601562e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:13:40.074828 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), ) 	 2543338404 	 1000 	 0.024693965911865234 	 0.004761695861816406 	 2.9087066650390625e-05 	 2.7418136596679688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:25.557010 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 25404006 	 1000 	 0.016909122467041016 	 0.002796649932861328 	 2.7894973754882812e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:26.161830 test begin: paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), ) 	 25402402 	 1000 	 0.016628503799438477 	 0.002941608428955078 	 1.2636184692382812e-05 	 4.863739013671875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:26.624711 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), ) 	 25404006 	 1000 	 0.016337871551513672 	 0.0025911331176757812 	 8.106231689453125e-06 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:27.065541 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 50803206 	 1000 	 0.3406803607940674 	 0.377521276473999 	 0.11584782600402832 	 8.153915405273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:14:28.667497 test begin: paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), ) 	 2540160327 	 1000 	 0.016448259353637695 	 0.0040683746337890625 	 1.2636184692382812e-05 	 7.128715515136719e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:15:09.310287 test begin: paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), ) 	 2540160109 	 1000 	 0.024303436279296875 	 0.0048367977142333984 	 3.62396240234375e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:15:55.123116 test begin: paddle.Tensor.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.32595324516296387 	 0.7463023662567139 	 0.3172149658203125 	 0.29187607765197754 	 0.44822001457214355 	 1.6438589096069336 	 0.3937826156616211 	 0.3360726833343506 	 
2025-07-30 14:16:03.348286 test begin: paddle.Tensor.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3261604309082031 	 0.30342769622802734 	 0.3133232593536377 	 0.2904551029205322 	 0.4480268955230713 	 1.6434507369995117 	 0.3944275379180908 	 0.3359684944152832 	 
2025-07-30 14:16:07.157895 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.3261139392852783 	 0.30263781547546387 	 0.3137078285217285 	 0.2923409938812256 	 0.447512149810791 	 1.6437733173370361 	 0.39452314376831055 	 0.33610105514526367 	 
2025-07-30 14:16:11.065190 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.3266174793243408 	 0.3037295341491699 	 0.3172130584716797 	 0.28754115104675293 	 0.44764184951782227 	 1.6435468196868896 	 0.38921499252319336 	 0.3360764980316162 	 
2025-07-30 14:16:14.877188 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.3264737129211426 	 0.30357980728149414 	 0.31761717796325684 	 0.29341912269592285 	 0.4475245475769043 	 1.6436767578125 	 0.3894929885864258 	 0.3360130786895752 	 
2025-07-30 14:16:18.769481 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.3270995616912842 	 0.30414557456970215 	 0.31826066970825195 	 0.2940034866333008 	 0.44817280769348145 	 1.6437327861785889 	 0.3930351734161377 	 0.33597373962402344 	 
2025-07-30 14:16:22.581908 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3175201],"float64"), ) 	 25401608 	 1000 	 0.3269331455230713 	 0.303957462310791 	 0.3181488513946533 	 0.29389357566833496 	 0.4476327896118164 	 1.6438477039337158 	 0.39313530921936035 	 0.33598852157592773 	 
2025-07-30 14:16:26.406019 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3265528678894043 	 0.307969331741333 	 0.31778717041015625 	 0.2939918041229248 	 0.4477858543395996 	 1.64341139793396 	 0.392519474029541 	 0.3359525203704834 	 
2025-07-30 14:16:30.214183 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2116801, 3],"float64"), ) 	 25401612 	 1000 	 0.3264179229736328 	 0.30701756477355957 	 0.31764769554138184 	 0.294842004776001 	 0.44762349128723145 	 1.6434910297393799 	 0.3945882320404053 	 0.3359999656677246 	 
2025-07-30 14:16:34.040975 test begin: paddle.Tensor.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.32648372650146484 	 0.31464481353759766 	 0.31714320182800293 	 0.2873201370239258 	 0.44775390625 	 1.6437342166900635 	 0.39495086669921875 	 0.33606505393981934 	 
2025-07-30 14:16:41.142308 test begin: paddle.Tensor.erfinv(x=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.3269815444946289 	 0.3098776340484619 	 0.3170652389526367 	 0.2937493324279785 	 0.4476161003112793 	 1.6436097621917725 	 0.39463090896606445 	 0.33601808547973633 	 
2025-07-30 14:16:44.958473 test begin: paddle.Tensor.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.3267025947570801 	 0.30925559997558594 	 0.3179774284362793 	 0.293947696685791 	 0.4476344585418701 	 1.643615961074829 	 0.3885314464569092 	 0.33597397804260254 	 
2025-07-30 14:16:48.814498 test begin: paddle.Tensor.exp(Tensor([1000000, 26],"float64"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([1000000, 26],"float64"), ) 	 26000000 	 1000 	 0.30584263801574707 	 0.3101649284362793 	 0.29691100120544434 	 0.29610753059387207 	 0.4587109088897705 	 0.45471882820129395 	 0.4031229019165039 	 0.3928563594818115 	 
2025-07-30 14:16:51.513302 test begin: paddle.Tensor.exp(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29552602767944336 	 0.2979593276977539 	 0.28674983978271484 	 0.2870521545410156 	 0.44971251487731934 	 0.4467175006866455 	 0.3939685821533203 	 0.38098931312561035 	 
2025-07-30 14:16:54.687170 test begin: paddle.Tensor.exp(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.29547810554504395 	 0.2978630065917969 	 0.28675007820129395 	 0.2872660160064697 	 0.4495840072631836 	 0.44669485092163086 	 0.39079880714416504 	 0.38624000549316406 	 
2025-07-30 14:16:57.907424 test begin: paddle.Tensor.exp(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.299468994140625 	 0.30048322677612305 	 0.2907145023345947 	 0.28960609436035156 	 0.4477882385253906 	 0.444563627243042 	 0.3803551197052002 	 0.38036060333251953 	 
2025-07-30 14:17:00.466859 test begin: paddle.Tensor.exp(Tensor([64, 793801],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([64, 793801],"float32"), ) 	 50803264 	 1000 	 0.2954673767089844 	 0.7626335620880127 	 0.2864868640899658 	 0.2870016098022461 	 0.4495880603790283 	 0.44669413566589355 	 0.39664149284362793 	 0.38213157653808594 	 
2025-07-30 14:17:06.933525 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 266, 477, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 266, 477, 401],"float32"), ) 	 50879683 	 1000 	 0.13516807556152344 	 0.004048824310302734 	 0.12349724769592285 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:08.974313 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 283, 466, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 283, 466, 386],"float32"), ) 	 50904909 	 1000 	 0.13511109352111816 	 0.004115581512451172 	 0.12378978729248047 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:10.977496 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 299, 391, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 299, 391, 436],"float32"), ) 	 50972325 	 1000 	 0.1351490020751953 	 0.00467228889465332 	 0.12391948699951172 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:12.948008 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 38841, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 38841, 436],"float32"), ) 	 50804029 	 1000 	 0.13484573364257812 	 0.008363008499145508 	 0.11498093605041504 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:14.902437 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 391, 43311],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 391, 43311],"float32"), ) 	 50803804 	 1000 	 0.1348426342010498 	 0.007708549499511719 	 0.11542844772338867 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:16.852779 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 42231, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 42231, 401],"float32"), ) 	 50803894 	 1000 	 0.13483309745788574 	 0.007727384567260742 	 0.11580467224121094 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:18.826489 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 43872, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 43872, 386],"float32"), ) 	 50803777 	 1000 	 0.134840726852417 	 0.004067420959472656 	 0.11997056007385254 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:20.817937 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 466, 36340],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 466, 36340],"float32"), ) 	 50803321 	 1000 	 0.13484811782836914 	 0.004077434539794922 	 0.12151050567626953 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:22.831800 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 477, 35502],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 477, 35502],"float32"), ) 	 50803363 	 1000 	 0.1348576545715332 	 0.004076719284057617 	 0.12318611145019531 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:24.821282 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([100, 3, 391, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([100, 3, 391, 436],"float32"), ) 	 51142801 	 1000 	 0.13573598861694336 	 0.004111528396606445 	 0.12444281578063965 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:26.779479 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([89, 3, 477, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([89, 3, 477, 401],"float32"), ) 	 51070960 	 1000 	 0.13555049896240234 	 0.004062652587890625 	 0.12421202659606934 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:28.710978 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([95, 3, 466, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([95, 3, 466, 386],"float32"), ) 	 51264661 	 1000 	 0.1359250545501709 	 0.0040400028228759766 	 0.12455463409423828 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 14:17:30.667602 test begin: paddle.Tensor.fill_(Tensor([50803201],"float32"), 0, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([50803201],"float32"), 0, ) 	 50803201 	 1000 	 0.14626407623291016 	 0.13401508331298828 	 0.1304187774658203 	 0.1255655288696289 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:32.698047 test begin: paddle.Tensor.fill_(Tensor([659782, 77],"float32"), value=-math.inf, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([659782, 77],"float32"), value=-math.inf, ) 	 50803214 	 1000 	 0.1461946964263916 	 0.13404607772827148 	 0.13062119483947754 	 0.12558794021606445 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:34.685834 test begin: paddle.Tensor.fill_(Tensor([77, 659782],"float32"), value=-math.inf, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([77, 659782],"float32"), value=-math.inf, ) 	 50803214 	 1000 	 0.14612913131713867 	 0.13405275344848633 	 0.13054990768432617 	 0.12550783157348633 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:39.353323 test begin: paddle.Tensor.fill_(x=Tensor([10, 158761, 16],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([10, 158761, 16],"float64"), value=41.2, ) 	 25401760 	 1000 	 0.14621233940124512 	 0.13447999954223633 	 0.13048839569091797 	 0.1259610652923584 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:40.790113 test begin: paddle.Tensor.fill_(x=Tensor([10, 16, 158761],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([10, 16, 158761],"float64"), value=41.2, ) 	 25401760 	 1000 	 0.1459639072418213 	 0.13443970680236816 	 0.13010191917419434 	 0.1259324550628662 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:42.261567 test begin: paddle.Tensor.fill_(x=Tensor([99226, 16, 16],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([99226, 16, 16],"float64"), value=41.2, ) 	 25401856 	 1000 	 0.14641165733337402 	 0.13459324836730957 	 0.13092780113220215 	 0.12543201446533203 	 None 	 None 	 None 	 None 	 
2025-07-30 14:17:43.659188 test begin: paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.023185253143310547 	 0.010596990585327148 	 2.1696090698242188e-05 	 2.8133392333984375e-05 	 0.032302141189575195 	 0.042595624923706055 	 2.5272369384765625e-05 	 4.744529724121094e-05 	 combined
2025-07-30 14:18:00.843540 test begin: paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.02313518524169922 	 0.010892629623413086 	 2.5272369384765625e-05 	 4.8160552978515625e-05 	 0.03242897987365723 	 0.049997568130493164 	 2.0265579223632812e-05 	 7.963180541992188e-05 	 combined
2025-07-30 14:18:17.841997 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([12700801, 4, 7],"int32"), Tensor([12700801, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([12700801, 4, 7],"int32"), Tensor([12700801, 4],"int32"), 0, 1, 2, ) 	 406425632 	 1000 	 88.88998985290527 	 4.355771064758301 	 0.004910945892333984 	 1.4833006858825684 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:21:32.891575 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([1814401, 4, 7],"int32"), Tensor([1814401, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([1814401, 4, 7],"int32"), Tensor([1814401, 4],"int32"), 0, 1, 2, ) 	 58060832 	 1000 	 4.694046258926392 	 0.6300861835479736 	 0.001524209976196289 	 0.21455168724060059 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:21:44.353278 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 3175201],"int64"), Tensor([2, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 3175201],"int64"), Tensor([2, 4],"int64"), 0, 1, 2, ) 	 25401616 	 1000 	 0.3216245174407959 	 0.31583356857299805 	 0.08198666572570801 	 0.10738778114318848 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:21:46.152879 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 6350401],"int32"), Tensor([2, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 6350401],"int32"), Tensor([2, 4],"int32"), 0, 1, 2, ) 	 50803216 	 1000 	 0.3217506408691406 	 0.3158867359161377 	 0.08210587501525879 	 0.10740113258361816 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:21:48.323583 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4233601, 3, 2],"int32"), Tensor([2, 2, 3],"int32"), offset=0, dim1=1, dim2=2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4233601, 3, 2],"int32"), Tensor([2, 2, 3],"int32"), offset=0, dim1=1, dim2=2, ) 	 50803224 	 1000 	 0.3217580318450928 	 0.3160064220428467 	 0.08211231231689453 	 0.10747313499450684 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:21:50.479235 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([6350401, 4, 7],"int64"), Tensor([6350401, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([6350401, 4, 7],"int64"), Tensor([6350401, 4],"int64"), 0, 1, 2, ) 	 203212832 	 1000 	 42.611634969711304 	 3.603083848953247 	 0.002371549606323242 	 1.2264635562896729 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:23:25.857513 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([907201, 4, 7],"int64"), Tensor([907201, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([907201, 4, 7],"int64"), Tensor([907201, 4],"int64"), 0, 1, 2, ) 	 29030432 	 1000 	 2.330075740814209 	 0.5177266597747803 	 0.0008111000061035156 	 0.17630505561828613 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:23:32.092863 test begin: paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 1684480000 	 1000 	 0.006002902984619141 	 0.004389047622680664 	 1.4543533325195312e-05 	 1.9311904907226562e-05 	 0.04458808898925781 	 0.052799224853515625 	 3.743171691894531e-05 	 3.814697265625e-05 	 
2025-07-30 14:24:27.510025 test begin: paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, ) 	 509788160 	 1000 	 0.0055694580078125 	 0.004349946975708008 	 1.33514404296875e-05 	 2.2411346435546875e-05 	 0.0414276123046875 	 0.05231022834777832 	 2.0503997802734375e-05 	 5.364418029785156e-05 	 
2025-07-30 14:24:46.509889 test begin: paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, ) 	 1019576320 	 1000 	 0.005542755126953125 	 0.004354238510131836 	 1.3589859008789062e-05 	 2.0742416381835938e-05 	 0.04188251495361328 	 0.05223965644836426 	 2.7418136596679688e-05 	 6.079673767089844e-05 	 
2025-07-30 14:25:26.096491 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.005884885787963867 	 0.00569915771484375 	 3.266334533691406e-05 	 7.009506225585938e-05 	 0.0416719913482666 	 0.05180239677429199 	 2.5987625122070312e-05 	 4.6253204345703125e-05 	 
2025-07-30 14:25:42.916297 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.005594491958618164 	 0.007975578308105469 	 1.33514404296875e-05 	 2.2411346435546875e-05 	 0.05136704444885254 	 0.05848264694213867 	 3.6716461181640625e-05 	 7.843971252441406e-05 	 
2025-07-30 14:26:25.680307 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, ) 	 513802240 	 1000 	 0.005514621734619141 	 0.004404306411743164 	 1.1682510375976562e-05 	 3.4809112548828125e-05 	 0.04285144805908203 	 0.051605939865112305 	 4.267692565917969e-05 	 4.839897155761719e-05 	 
2025-07-30 14:26:41.647227 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, ) 	 1027604480 	 1000 	 0.006007194519042969 	 0.00435638427734375 	 3.409385681152344e-05 	 2.0742416381835938e-05 	 0.042182207107543945 	 0.05527186393737793 	 3.170967102050781e-05 	 7.081031799316406e-05 	 
2025-07-30 14:27:27.231543 test begin: paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.005578041076660156 	 0.004361391067504883 	 7.3909759521484375e-06 	 2.0265579223632812e-05 	 0.041670799255371094 	 0.05157470703125 	 2.5987625122070312e-05 	 3.933906555175781e-05 	 
2025-07-30 14:27:44.217551 test begin: paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 526400000 	 1000 	 0.0058231353759765625 	 0.004706621170043945 	 7.62939453125e-06 	 4.100799560546875e-05 	 0.04141974449157715 	 0.0525050163269043 	 2.1457672119140625e-05 	 4.38690185546875e-05 	 
2025-07-30 14:28:02.233804 test begin: paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 539033600 	 1000 	 0.01087188720703125 	 0.004462718963623047 	 1.2159347534179688e-05 	 2.0742416381835938e-05 	 0.07186627388000488 	 0.0541229248046875 	 4.696846008300781e-05 	 6.890296936035156e-05 	 
2025-07-30 14:28:20.342530 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, ) 	 519680000 	 1000 	 0.0059130191802978516 	 0.004512310028076172 	 9.5367431640625e-06 	 2.1457672119140625e-05 	 0.04148530960083008 	 0.052551984786987305 	 2.2172927856445312e-05 	 6.890296936035156e-05 	 
2025-07-30 14:28:39.373211 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, ) 	 529408000 	 1000 	 0.0059163570404052734 	 0.004650592803955078 	 9.059906005859375e-06 	 2.4557113647460938e-05 	 0.04175090789794922 	 0.05185699462890625 	 2.6226043701171875e-05 	 5.412101745605469e-05 	 
2025-07-30 14:28:56.873877 test begin: paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.005505561828613281 	 0.004381656646728516 	 1.1444091796875e-05 	 2.1219253540039062e-05 	 0.05310416221618652 	 0.05337357521057129 	 4.3392181396484375e-05 	 4.3392181396484375e-05 	 
2025-07-30 14:29:37.364922 test begin: paddle.Tensor.flip(Tensor([16, 3, 224, 4726],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 3, 224, 4726],"float32"), 0, ) 	 50813952 	 1000 	 0.9648852348327637 	 0.313612699508667 	 0.9557363986968994 	 0.29704737663269043 	 0.9647841453552246 	 0.31122803688049316 	 0.914759635925293 	 0.24668025970458984 	 
2025-07-30 14:29:41.644554 test begin: paddle.Tensor.flip(Tensor([16, 3, 4726, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 3, 4726, 224],"float32"), 0, ) 	 50813952 	 1000 	 0.9649386405944824 	 0.3113846778869629 	 0.9558682441711426 	 0.2969365119934082 	 0.9648177623748779 	 0.3111858367919922 	 0.9149396419525146 	 0.23582673072814941 	 
2025-07-30 14:29:45.838562 test begin: paddle.Tensor.flip(Tensor([16, 64, 224, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 64, 224, 224],"float32"), 0, ) 	 51380224 	 1000 	 0.9751632213592529 	 0.3150970935821533 	 0.9661288261413574 	 0.3007469177246094 	 0.9750394821166992 	 0.31490135192871094 	 0.9235942363739014 	 0.24361348152160645 	 
2025-07-30 14:29:50.100066 test begin: paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-1,], ) 	 50804400 	 1000 	 0.9012148380279541 	 0.31255602836608887 	 0.891930341720581 	 0.2963533401489258 	 0.9015800952911377 	 0.312375545501709 	 0.8512213230133057 	 0.24701189994812012 	 
2025-07-30 14:29:54.243986 test begin: paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-2,], ) 	 50804400 	 1000 	 0.9012048244476318 	 0.3160696029663086 	 0.8919169902801514 	 0.30172252655029297 	 0.9017229080200195 	 0.31589603424072266 	 0.8517992496490479 	 0.2534294128417969 	 
2025-07-30 14:29:58.386753 test begin: paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-1,], ) 	 50804100 	 1000 	 0.9011030197143555 	 0.31260204315185547 	 0.8917140960693359 	 0.2982966899871826 	 0.9018614292144775 	 0.31265687942504883 	 0.8505475521087646 	 0.24387788772583008 	 
2025-07-30 14:30:02.505252 test begin: paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-2,], ) 	 50804100 	 1000 	 0.9011707305908203 	 0.31684255599975586 	 0.891869306564331 	 0.3010997772216797 	 0.902055025100708 	 0.3154768943786621 	 0.8520684242248535 	 0.25050926208496094 	 
2025-07-30 14:30:08.487023 test begin: paddle.Tensor.flip(Tensor([338, 3, 224, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([338, 3, 224, 224],"float32"), 0, ) 	 50878464 	 1000 	 0.9659888744354248 	 0.3194887638092041 	 0.9498794078826904 	 0.2899816036224365 	 0.9658691883087158 	 0.31192898750305176 	 0.9071943759918213 	 0.2403099536895752 	 
2025-07-30 14:30:12.770660 test begin: paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-1,], ) 	 50880000 	 1000 	 0.9044160842895508 	 0.31314730644226074 	 0.8880810737609863 	 0.2985074520111084 	 0.9044344425201416 	 0.31301069259643555 	 0.8535947799682617 	 0.24639153480529785 	 
2025-07-30 14:30:16.945296 test begin: paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-2,], ) 	 50880000 	 1000 	 0.9045090675354004 	 0.31658935546875 	 0.8881020545959473 	 0.2944355010986328 	 0.9045441150665283 	 0.31641268730163574 	 0.8447027206420898 	 0.2456972599029541 	 
2025-07-30 14:30:21.105934 test begin: paddle.Tensor.floor(Tensor([12700801, 4],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([12700801, 4],"float32"), ) 	 50803204 	 1000 	 0.2957286834716797 	 0.2980077266693115 	 0.27967023849487305 	 0.28123927116394043 	 0.1339411735534668 	 0.13411450386047363 	 0.07477402687072754 	 0.06624269485473633 	 
2025-07-30 14:30:23.682537 test begin: paddle.Tensor.floor(Tensor([1857, 27358],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1857, 27358],"float32"), ) 	 50803806 	 1000 	 0.29551100730895996 	 0.2978849411010742 	 0.2863287925720215 	 0.28734683990478516 	 0.13390302658081055 	 0.13414645195007324 	 0.08327174186706543 	 0.07236170768737793 	 
2025-07-30 14:30:26.277807 test begin: paddle.Tensor.floor(Tensor([1872, 27139],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1872, 27139],"float32"), ) 	 50804208 	 1000 	 0.29573702812194824 	 0.2978706359863281 	 0.2860689163208008 	 0.2868211269378662 	 0.13389921188354492 	 0.1341235637664795 	 0.08325386047363281 	 0.07340598106384277 	 
2025-07-30 14:30:28.819258 test begin: paddle.Tensor.floor(Tensor([1915, 26530],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1915, 26530],"float32"), ) 	 50804950 	 1000 	 0.29589343070983887 	 0.29958319664001465 	 0.28674864768981934 	 0.28726935386657715 	 0.13387393951416016 	 0.13412141799926758 	 0.08253216743469238 	 0.07310056686401367 	 
2025-07-30 14:30:31.361338 test begin: paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, ) 	 508032080 	 1000 	 0.009973287582397461 	 1.379791021347046 	 1.52587890625e-05 	 9.131431579589844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:30:42.570290 test begin: paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, ) 	 508032400 	 1000 	 0.009921789169311523 	 13.44087266921997 	 1.239776611328125e-05 	 0.00018548965454101562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:31:07.392311 test begin: paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, ) 	 508036000 	 1000 	 0.17005372047424316 	 140.0153751373291 	 0.160125732421875 	 0.00040268898010253906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:33:38.270717 test begin: paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), ) 	 8664 	 1000 	 0.010887861251831055 	 157.52091026306152 	 1.0967254638671875e-05 	 0.00021958351135253906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:36:16.056750 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), ) 	 462864 	 1000 	 0.010839700698852539 	 78.31426072120667 	 1.1205673217773438e-05 	 0.0002529621124267578 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:37:34.545398 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), ) 	 50920464 	 1000 	 0.010974645614624023 	 77.75518345832825 	 1.5974044799804688e-05 	 0.00022029876708984375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:38:56.008892 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), ) 	 50997264 	 1000 	 0.010916471481323242 	 77.26869821548462 	 1.1444091796875e-05 	 0.0002181529998779297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:40:14.975839 test begin: paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.019335269927978516 	 89.76644968986511 	 1.8596649169921875e-05 	 0.00022602081298828125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:41:45.873774 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.011265039443969727 	 57.80116248130798 	 1.239776611328125e-05 	 0.00021648406982421875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:42:45.037587 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.019016742706298828 	 81.71886253356934 	 1.5497207641601562e-05 	 0.00022554397583007812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:44:07.914507 test begin: paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.018695831298828125 	 67.32929992675781 	 1.2159347534179688e-05 	 0.0002741813659667969 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:45:16.362720 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.01970505714416504 	 63.51480984687805 	 2.4318695068359375e-05 	 0.0002224445343017578 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:46:21.024302 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.0187680721282959 	 61.55801725387573 	 1.3113021850585938e-05 	 0.0002231597900390625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:47:23.686099 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), ) 	 50843140 	 1000 	 0.01890707015991211 	 62.33608031272888 	 1.5735626220703125e-05 	 0.00022029876708984375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:48:27.115758 test begin: paddle.Tensor.gcd(x=Tensor([127008, 2, 4, 5],"int32"), y=Tensor([127008, 2, 4, 5],"int32"), )
W0730 14:48:39.766589 32783 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([127008, 2, 4, 5],"int32"), y=Tensor([127008, 2, 4, 5],"int32"), ) 	 10160640 	 1000 	 12.364014863967896 	 0.16151022911071777 	 3.3855438232421875e-05 	 0.14794349670410156 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:48:40.142518 test begin: paddle.Tensor.gcd(x=Tensor([2, 4, 635040],"int32"), y=Tensor([2, 4, 635040],"int32"), )
W0730 14:48:52.902777 32829 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([2, 4, 635040],"int32"), y=Tensor([2, 4, 635040],"int32"), ) 	 10160640 	 1000 	 12.5955171585083 	 0.16095423698425293 	 2.8848648071289062e-05 	 0.14793014526367188 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:48:53.093438 test begin: paddle.Tensor.gcd(x=Tensor([2, 508032, 5],"int32"), y=Tensor([2, 508032, 5],"int32"), )
W0730 14:49:05.274718 32871 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([2, 508032, 5],"int32"), y=Tensor([2, 508032, 5],"int32"), ) 	 10160640 	 1000 	 12.025020122528076 	 0.6145451068878174 	 4.315376281738281e-05 	 0.14811468124389648 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:49:07.762338 test begin: paddle.Tensor.gcd(x=Tensor([254016, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0730 14:49:29.889864 33322 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([254016, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 5080330 	 1000 	 21.952919006347656 	 0.43601083755493164 	 4.696846008300781e-05 	 0.4091928005218506 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:49:30.357680 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), ) 	 50816225 	 1000 	 0.009639978408813477 	 0.014108419418334961 	 1.7642974853515625e-05 	 4.458427429199219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:49:31.709181 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50821425 	 1000 	 0.00946044921875 	 0.01552438735961914 	 1.5020370483398438e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:49:32.735969 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), ) 	 50812325 	 1000 	 0.009509086608886719 	 0.013713836669921875 	 1.239776611328125e-05 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:49:33.730587 test begin: paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50824957 	 1000 	 3.1368203163146973 	 2.749234199523926 	 3.1268486976623535 	 2.728440284729004 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:49:46.975129 test begin: paddle.Tensor.index_select(Tensor([4004, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), ) 	 25497697 	 1000 	 8.177366733551025 	 8.598504304885864 	 8.166658639907837 	 8.584043741226196 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:50:19.036507 test begin: paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([130],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([130],"int64"), ) 	 50803638 	 1000 	 0.18908023834228516 	 0.1702563762664795 	 0.17966055870056152 	 0.15632033348083496 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:50:20.736038 test begin: paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([91],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([91],"int64"), ) 	 50803599 	 1000 	 0.1337423324584961 	 0.12156510353088379 	 0.12423205375671387 	 0.10767745971679688 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:50:22.217359 test begin: paddle.Tensor.index_select(Tensor([454, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), ) 	 25412497 	 1000 	 7.648111581802368 	 7.14622163772583 	 7.637759685516357 	 7.131680488586426 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:50:52.281842 test begin: paddle.Tensor.inner(x=Tensor([2, 1058401, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 1058401, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401744 	 1000 	 1.9699623584747314 	 1.962127685546875 	 0.2875399589538574 	 0.28637170791625977 	 3.367751359939575 	 3.2435691356658936 	 0.38254594802856445 	 0.367809534072876 	 
2025-07-30 14:51:08.411435 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), ) 	 25401744 	 1000 	 1.4602940082550049 	 1.6823585033416748 	 0.21322345733642578 	 0.2130279541015625 	 4.070436000823975 	 4.077875852584839 	 0.4618527889251709 	 0.4630289077758789 	 
2025-07-30 14:51:25.466142 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), ) 	 25401780 	 1000 	 1.8548707962036133 	 1.8603606224060059 	 0.27077198028564453 	 0.27153468132019043 	 3.400365114212036 	 3.6647448539733887 	 0.3855760097503662 	 0.4162931442260742 	 
2025-07-30 14:51:40.855133 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), ) 	 25401760 	 1000 	 1.4587054252624512 	 1.45853853225708 	 0.21288824081420898 	 0.21284174919128418 	 4.068681478500366 	 4.077112913131714 	 0.4615161418914795 	 0.46300196647644043 	 
2025-07-30 14:51:56.390525 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), ) 	 50803260 	 1000 	 0.3344120979309082 	 0.3362417221069336 	 0.1708064079284668 	 0.1717519760131836 	 0.7123603820800781 	 0.750373363494873 	 0.36397337913513184 	 0.38332271575927734 	 
2025-07-30 14:51:59.564933 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 635041, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 635041, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401760 	 1000 	 1.9815361499786377 	 1.9632701873779297 	 0.2892482280731201 	 0.286318302154541 	 3.3652830123901367 	 3.243448257446289 	 0.3822593688964844 	 0.36769604682922363 	 
2025-07-30 14:52:14.645161 test begin: paddle.Tensor.inner(x=Tensor([2116801, 3, 4],"float64"), y=Tensor([2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2116801, 3, 4],"float64"), y=Tensor([2, 5, 4],"float64"), ) 	 25401652 	 1000 	 1.8643102645874023 	 1.8521008491516113 	 0.2721536159515381 	 0.27037930488586426 	 2.243436813354492 	 2.2768776416778564 	 0.2547333240509033 	 0.2582540512084961 	 
2025-07-30 14:52:24.814998 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), ) 	 25401636 	 1000 	 1.368323802947998 	 1.3675508499145508 	 0.199753999710083 	 0.1996161937713623 	 2.652271032333374 	 2.635158061981201 	 0.3009183406829834 	 0.29912710189819336 	 
2025-07-30 14:52:33.778986 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), ) 	 25401672 	 1000 	 1.382875680923462 	 1.4216389656066895 	 0.20186662673950195 	 0.20264625549316406 	 2.368511438369751 	 2.4527711868286133 	 0.2686750888824463 	 0.27843403816223145 	 
2025-07-30 14:52:43.647873 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), ) 	 25401652 	 1000 	 1.3725016117095947 	 1.3757901191711426 	 0.2003626823425293 	 0.20085716247558594 	 2.651768922805786 	 2.63496732711792 	 0.30088329315185547 	 0.29911160469055176 	 
2025-07-30 14:52:52.607249 test begin: paddle.Tensor.inner(x=Tensor([3, 8467201],"float64"), y=Tensor([3, 2, 5, 8467201],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 8467201],"float64"), y=Tensor([3, 2, 5, 8467201],"float64"), ) 	 279417633 	 1000 	 1.78121018409729 	 1.7734503746032715 	 0.9100902080535889 	 0.9062530994415283 	 4.051947593688965 	 4.213430404663086 	 0.22992634773254395 	 0.23906421661376953 	 
2025-07-30 14:53:10.314893 test begin: paddle.Tensor.inner(x=Tensor([3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), ) 	 27941793 	 1000 	 0.1933426856994629 	 0.19174885749816895 	 0.08517289161682129 	 0.09791707992553711 	 0.41483354568481445 	 0.4246997833251953 	 0.2118537425994873 	 0.2169034481048584 	 
2025-07-30 14:53:12.128713 test begin: paddle.Tensor.inner(x=Tensor([423361, 5, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([423361, 5, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401780 	 1000 	 1.9804425239562988 	 1.9641602039337158 	 0.28911256790161133 	 0.28672051429748535 	 3.365473508834839 	 3.2427055835723877 	 0.3822054862976074 	 0.36766695976257324 	 
2025-07-30 14:53:27.374667 test begin: paddle.Tensor.inner(x=Tensor([5, 1270081, 4],"float64"), y=Tensor([2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 1270081, 4],"float64"), y=Tensor([2, 5, 4],"float64"), ) 	 25401660 	 1000 	 1.8640618324279785 	 1.8520596027374268 	 0.2721250057220459 	 0.2703697681427002 	 2.243016004562378 	 2.2768537998199463 	 0.2546961307525635 	 0.2582085132598877 	 
2025-07-30 14:53:39.406313 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 1693441],"float64"), y=Tensor([2, 5, 1693441],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 1693441],"float64"), y=Tensor([2, 5, 1693441],"float64"), ) 	 42336025 	 1000 	 0.29686784744262695 	 0.28907299041748047 	 0.15164780616760254 	 0.14769291877746582 	 0.8215289115905762 	 0.8666191101074219 	 0.20984959602355957 	 0.2213273048400879 	 
2025-07-30 14:53:42.602148 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 2540161],"float64"), y=Tensor([2, 5, 2540161],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 2540161],"float64"), y=Tensor([2, 5, 2540161],"float64"), ) 	 63504025 	 1000 	 0.42966365814208984 	 0.42467761039733887 	 0.21941876411437988 	 0.21697640419006348 	 1.2386939525604248 	 1.3226428031921387 	 0.21090221405029297 	 0.22521233558654785 	 
2025-07-30 14:53:47.367801 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([1270081, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([1270081, 5, 4],"float64"), ) 	 25401680 	 1000 	 1.5789880752563477 	 1.55802321434021 	 0.23050451278686523 	 0.2272031307220459 	 2.472766637802124 	 2.6788506507873535 	 0.2805061340332031 	 0.30410337448120117 	 
2025-07-30 14:53:58.124513 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 3175201, 4],"float64"), ) 	 25401668 	 1000 	 1.5744595527648926 	 1.5532727241516113 	 0.2298734188079834 	 0.22672605514526367 	 2.791949987411499 	 2.794975996017456 	 0.31677913665771484 	 0.31725192070007324 	 
2025-07-30 14:54:09.357415 test begin: paddle.Tensor.inner(x=Tensor([6350401, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([6350401, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401724 	 1000 	 1.9684474468231201 	 1.9642903804779053 	 0.2873544692993164 	 0.28673338890075684 	 3.3658595085144043 	 3.2433223724365234 	 0.38217711448669434 	 0.3677513599395752 	 
2025-07-30 14:54:24.575853 test begin: paddle.Tensor.inverse(Tensor([4, 39690, 4, 4],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([4, 39690, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.6689817905426025 	 1.359905481338501 	 0.00010657310485839844 	 0.0002524852752685547 	 5.393155336380005 	 1.9652514457702637 	 0.9196569919586182 	 0.28690385818481445 	 
2025-07-30 14:54:42.429756 test begin: paddle.Tensor.inverse(Tensor([70560, 6, 6],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([70560, 6, 6],"float64"), ) 	 2540160 	 1000 	 3.6930453777313232 	 0.3959195613861084 	 0.00010228157043457031 	 4.9114227294921875e-05 	 2.198234796524048 	 1.6718575954437256 	 0.5623414516448975 	 0.34110307693481445 	 
2025-07-30 14:54:50.497701 test begin: paddle.Tensor.inverse(Tensor([79380, 2, 4, 4],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([79380, 2, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.551222801208496 	 0.34409093856811523 	 0.00010728836059570312 	 9.036064147949219e-05 	 5.395562648773193 	 1.9652190208435059 	 0.9200608730316162 	 0.2868988513946533 	 
2025-07-30 14:55:05.879942 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), ) 	 2552921100 	 1000 	 0.0036814212799072266 	 0.0016477108001708984 	 7.867813110351562e-06 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:59.459405 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), ) 	 2552884920 	 1000 	 0.003553628921508789 	 0.0015952587127685547 	 1.0251998901367188e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:56:52.798104 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), ) 	 2552884920 	 1000 	 0.0035932064056396484 	 0.002332448959350586 	 1.0013580322265625e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:57:46.157910 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), ) 	 2552921100 	 1000 	 0.004728555679321289 	 0.0020933151245117188 	 1.33514404296875e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:58:39.497133 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), ) 	 2553504000 	 1000 	 0.0036313533782958984 	 0.001592874526977539 	 1.1444091796875e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:59:33.373989 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), ) 	 2553504000 	 1000 	 0.0036857128143310547 	 0.0016345977783203125 	 1.0013580322265625e-05 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:00:26.837467 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), ) 	 2540412000 	 1000 	 0.0035796165466308594 	 0.0020711421966552734 	 7.3909759521484375e-06 	 4.696846008300781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:01:21.467272 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), ) 	 2540412000 	 1000 	 0.006744861602783203 	 0.001638650894165039 	 2.8848648071289062e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:02:14.786103 test begin: paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), ) 	 2548657300 	 1000 	 0.0035943984985351562 	 0.00162506103515625 	 7.62939453125e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:03:08.320460 test begin: paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), ) 	 2548639240 	 1000 	 0.003583192825317383 	 0.0015978813171386719 	 1.1444091796875e-05 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:04:17.896619 test begin: paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), ) 	 2540404000 	 1000 	 0.0046808719635009766 	 0.0030777454376220703 	 9.298324584960938e-06 	 6.008148193359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:24.138839 test begin: paddle.Tensor.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), ) 	 50803240 	 1000 	 0.3626127243041992 	 3.0827252864837646 	 0.349653959274292 	 0.24184489250183105 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:28.755461 test begin: paddle.Tensor.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 0.36275410652160645 	 3.0828044414520264 	 0.3427011966705322 	 0.24176883697509766 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:34.587682 test begin: paddle.Tensor.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), ) 	 50803230 	 1000 	 0.36267566680908203 	 3.0816047191619873 	 0.3499124050140381 	 0.24181008338928223 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:42.977622 test begin: paddle.Tensor.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), ) 	 50803224 	 1000 	 0.36393189430236816 	 3.081366539001465 	 0.3499631881713867 	 0.241774320602417 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:47.505438 test begin: paddle.Tensor.isclose(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.42569756507873535 	 3.311755657196045 	 0.41283130645751953 	 0.25995707511901855 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:52.910199 test begin: paddle.Tensor.isnan(Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.isnan 	 paddle.Tensor.isnan(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.18121051788330078 	 0.17593836784362793 	 0.17191076278686523 	 0.1576375961303711 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:53.801899 test begin: paddle.Tensor.isnan(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.isnan 	 paddle.Tensor.isnan(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.23422503471374512 	 0.19451260566711426 	 0.22662806510925293 	 0.1749563217163086 	 None 	 None 	 None 	 None 	 
2025-07-30 15:05:55.084513 test begin: paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, ) 	 2552861001 	 1000 	 0.02031254768371582 	 0.027858257293701172 	 3.075599670410156e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:06:36.408378 test begin: paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, ) 	 2552861001 	 1000 	 0.018733739852905273 	 0.028025388717651367 	 8.821487426757812e-06 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:07:17.222430 test begin: paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, ) 	 2540160101 	 1000 	 0.01873946189880371 	 0.04119610786437988 	 1.0967254638671875e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 15:07:58.147345 test begin: paddle.Tensor.kthvalue(Tensor([2, 200, 127009],"float32"), k=200, axis=1, )
[Prof] paddle.Tensor.kthvalue 	 paddle.Tensor.kthvalue(Tensor([2, 200, 127009],"float32"), k=200, axis=1, ) 	 50803600 	 1000 	 6.68598747253418 	 11.608803987503052 	 1.7049047946929932 	 11.587952136993408 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:08:21.267102 test begin: paddle.Tensor.kthvalue(Tensor([2, 2540161, 10],"float32"), k=200, axis=1, )
[Prof] paddle.Tensor.kthvalue 	 paddle.Tensor.kthvalue(Tensor([2, 2540161, 10],"float32"), k=200, axis=1, ) 	 50803220 	 1000 	 37.50298762321472 	 33.93183612823486 	 9.563602924346924 	 33.91218304634094 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:09:40.518699 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.0, ) 	 50803360 	 1000 	 0.4508321285247803 	 0.44503259658813477 	 0.23033809661865234 	 0.4321115016937256 	 0.4804203510284424 	 0.5972158908843994 	 0.4208984375 	 0.3051271438598633 	 
2025-07-30 15:09:44.114684 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.5, ) 	 50803360 	 1000 	 0.4507124423980713 	 0.44504642486572266 	 0.23027372360229492 	 0.43186068534851074 	 0.48035359382629395 	 0.5971798896789551 	 0.4209933280944824 	 0.30515432357788086 	 
2025-07-30 15:09:47.776744 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=1.0, ) 	 50803360 	 1000 	 0.45072102546691895 	 0.4482412338256836 	 0.23027610778808594 	 0.4321153163909912 	 0.480426549911499 	 0.598555326461792 	 0.4214515686035156 	 0.30646848678588867 	 
2025-07-30 15:09:51.359215 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.0, ) 	 50803320 	 1000 	 0.4509549140930176 	 0.450669527053833 	 0.23038554191589355 	 0.4319024085998535 	 0.4811275005340576 	 0.59714674949646 	 0.4178285598754883 	 0.3051025867462158 	 
2025-07-30 15:09:55.069572 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.5, ) 	 50803320 	 1000 	 0.45104312896728516 	 0.4450373649597168 	 0.23047709465026855 	 0.43215298652648926 	 0.48125743865966797 	 0.5973317623138428 	 0.42192792892456055 	 0.30514001846313477 	 
2025-07-30 15:10:00.078689 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=1.0, ) 	 50803320 	 1000 	 0.4506220817565918 	 0.4567415714263916 	 0.23024940490722656 	 0.43320775032043457 	 0.4811880588531494 	 0.5971930027008057 	 0.42180347442626953 	 0.3051292896270752 	 
2025-07-30 15:10:04.025863 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.0, ) 	 50803296 	 1000 	 0.45100951194763184 	 0.4450531005859375 	 0.23047757148742676 	 0.43192219734191895 	 0.48124265670776367 	 0.5973794460296631 	 0.4193460941314697 	 0.30524516105651855 	 
2025-07-30 15:10:07.690504 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.5, ) 	 50803296 	 1000 	 0.45071983337402344 	 0.4450192451477051 	 0.2302389144897461 	 0.43158912658691406 	 0.48108649253845215 	 0.597177267074585 	 0.4221043586730957 	 0.3050692081451416 	 
2025-07-30 15:10:11.269211 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=1.0, ) 	 50803296 	 1000 	 0.45206403732299805 	 0.4489130973815918 	 0.23024439811706543 	 0.43193793296813965 	 0.48116588592529297 	 0.5972437858581543 	 0.4209318161010742 	 0.30507874488830566 	 
2025-07-30 15:10:14.937648 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.0, ) 	 50803320 	 1000 	 0.4510228633880615 	 0.4450247287750244 	 0.2304830551147461 	 0.4320845603942871 	 0.48113179206848145 	 0.5971934795379639 	 0.42090439796447754 	 0.30510950088500977 	 
2025-07-30 15:10:18.524307 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.5, ) 	 50803320 	 1000 	 0.45105957984924316 	 0.4492301940917969 	 0.2304675579071045 	 0.4332256317138672 	 0.48111963272094727 	 0.5972330570220947 	 0.42153406143188477 	 0.3051328659057617 	 
2025-07-30 15:10:22.150381 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=1.0, ) 	 50803320 	 1000 	 0.4509592056274414 	 0.44502806663513184 	 0.23041176795959473 	 0.43131041526794434 	 0.4810779094696045 	 0.5970370769500732 	 0.42142438888549805 	 0.3050212860107422 	 
2025-07-30 15:10:25.810687 test begin: paddle.Tensor.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.less 	 paddle.Tensor.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.3267192840576172 	 0.3277707099914551 	 0.31737399101257324 	 0.3161344528198242 	 None 	 None 	 None 	 None 	 
2025-07-30 15:10:28.110449 test begin: paddle.Tensor.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), )
[Prof] paddle.Tensor.less 	 paddle.Tensor.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), ) 	 101607424 	 1000 	 0.3269383907318115 	 0.3355581760406494 	 0.31752538681030273 	 0.317293643951416 	 None 	 None 	 None 	 None 	 
2025-07-30 15:10:30.487159 test begin: paddle.Tensor.lgamma(Tensor([100, 100, 2541],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([100, 100, 2541],"float64"), ) 	 25410000 	 1000 	 0.7129471302032471 	 0.6907186508178711 	 0.704120397567749 	 0.6739339828491211 	 1.3863306045532227 	 1.5880992412567139 	 1.3351147174835205 	 0.810713529586792 	 
2025-07-30 15:10:37.449424 test begin: paddle.Tensor.lgamma(Tensor([100, 2541, 100],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([100, 2541, 100],"float64"), ) 	 25410000 	 1000 	 0.7128782272338867 	 0.6933493614196777 	 0.7036597728729248 	 0.680145263671875 	 1.3861732482910156 	 1.5869247913360596 	 1.3347928524017334 	 0.8108811378479004 	 
2025-07-30 15:10:42.988085 test begin: paddle.Tensor.lgamma(Tensor([2541, 100, 100],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([2541, 100, 100],"float64"), ) 	 25410000 	 1000 	 0.7130265235900879 	 0.6906075477600098 	 0.7043473720550537 	 0.6806244850158691 	 1.3876516819000244 	 1.5868909358978271 	 1.3338418006896973 	 0.8108222484588623 	 
2025-07-30 15:10:48.495451 test begin: paddle.Tensor.lgamma(Tensor([453601, 7, 8],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([453601, 7, 8],"float64"), ) 	 25401656 	 1000 	 0.7127866744995117 	 0.6905052661895752 	 0.691605806350708 	 0.6806142330169678 	 1.3828251361846924 	 1.5864276885986328 	 1.3315558433532715 	 0.8105781078338623 	 
2025-07-30 15:10:53.947180 test begin: paddle.Tensor.lgamma(Tensor([45361, 7, 8, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([45361, 7, 8, 10],"float64"), ) 	 25402160 	 1000 	 0.714195728302002 	 0.6903750896453857 	 0.7055492401123047 	 0.6802337169647217 	 1.381253957748413 	 1.5878582000732422 	 1.329547643661499 	 0.8119857311248779 	 
2025-07-30 15:10:59.407076 test begin: paddle.Tensor.lgamma(Tensor([5, 635041, 8],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 635041, 8],"float64"), ) 	 25401640 	 1000 	 0.712775707244873 	 0.6904196739196777 	 0.7031452655792236 	 0.6804418563842773 	 1.3814587593078613 	 1.5864896774291992 	 1.3180382251739502 	 0.8105874061584473 	 
2025-07-30 15:11:05.362757 test begin: paddle.Tensor.lgamma(Tensor([5, 63505, 8, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 63505, 8, 10],"float64"), ) 	 25402000 	 1000 	 0.7127907276153564 	 1.8884758949279785 	 0.7041327953338623 	 0.6735754013061523 	 1.3831942081451416 	 1.5865178108215332 	 1.3318965435028076 	 0.8106427192687988 	 
2025-07-30 15:11:13.406706 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 725761],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 725761],"float64"), ) 	 25401635 	 1000 	 0.7128074169158936 	 0.6903555393218994 	 0.70058274269104 	 0.6797573566436768 	 1.3814969062805176 	 1.5863280296325684 	 1.3293125629425049 	 0.810537576675415 	 
2025-07-30 15:11:18.740929 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 72577, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 72577, 10],"float64"), ) 	 25401950 	 1000 	 0.7127401828765869 	 0.6903574466705322 	 0.7041013240814209 	 0.6801304817199707 	 1.3831088542938232 	 1.5876922607421875 	 1.3307583332061768 	 0.8118810653686523 	 
2025-07-30 15:11:24.218161 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 8, 90721],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 8, 90721],"float64"), ) 	 25401880 	 1000 	 0.7127447128295898 	 0.6917374134063721 	 0.7040557861328125 	 0.6817531585693359 	 1.383000135421753 	 1.5862412452697754 	 1.3306286334991455 	 0.8105149269104004 	 
2025-07-30 15:11:29.682527 test begin: paddle.Tensor.log(Tensor([100, 200, 1271],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([100, 200, 1271],"float64"), ) 	 25420000 	 1000 	 0.30568718910217285 	 0.3065481185913086 	 0.2969472408294678 	 0.28953051567077637 	 0.4474787712097168 	 0.44912147521972656 	 0.39301133155822754 	 0.37697649002075195 	 
2025-07-30 15:11:32.425918 test begin: paddle.Tensor.log(Tensor([100, 2541, 100],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([100, 2541, 100],"float64"), ) 	 25410000 	 1000 	 0.30538177490234375 	 0.30877041816711426 	 0.2968299388885498 	 0.29534268379211426 	 0.44761204719543457 	 0.44890689849853516 	 0.39412355422973633 	 0.3820834159851074 	 
2025-07-30 15:11:35.002840 test begin: paddle.Tensor.log(Tensor([10000, 5, 509],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([10000, 5, 509],"float64"), ) 	 25450000 	 1000 	 0.30608367919921875 	 0.3088696002960205 	 0.29729151725769043 	 0.2955050468444824 	 0.4483377933502197 	 0.4495849609375 	 0.39424633979797363 	 0.3831510543823242 	 
2025-07-30 15:11:39.226394 test begin: paddle.Tensor.log(Tensor([10000, 847, 3],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([10000, 847, 3],"float64"), ) 	 25410000 	 1000 	 0.30678224563598633 	 0.30640482902526855 	 0.29813313484191895 	 0.2954399585723877 	 0.44762659072875977 	 0.449019193649292 	 0.39470863342285156 	 0.38216662406921387 	 
2025-07-30 15:11:41.878321 test begin: paddle.Tensor.log(Tensor([1271, 200, 100],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([1271, 200, 100],"float64"), ) 	 25420000 	 1000 	 0.3057131767272949 	 0.3065361976623535 	 0.2891397476196289 	 0.28972816467285156 	 0.44763731956481934 	 0.4490642547607422 	 0.3801426887512207 	 0.37566494941711426 	 
2025-07-30 15:11:44.522079 test begin: paddle.Tensor.log(Tensor([1693441, 5, 3],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([1693441, 5, 3],"float64"), ) 	 25401615 	 1000 	 0.30533814430236816 	 0.3062715530395508 	 0.2966279983520508 	 0.2948341369628906 	 0.447542667388916 	 0.4488410949707031 	 0.39446520805358887 	 0.38205742835998535 	 
2025-07-30 15:11:47.111368 test begin: paddle.Tensor.log(Tensor([4800, 10585],"float32"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([4800, 10585],"float32"), ) 	 50808000 	 1000 	 0.2955138683319092 	 0.2975800037384033 	 0.28673458099365234 	 0.28673410415649414 	 0.4502112865447998 	 0.44960832595825195 	 0.397430419921875 	 0.3841056823730469 	 
2025-07-30 15:11:50.294417 test begin: paddle.Tensor.log(Tensor([503002, 101],"float32"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([503002, 101],"float32"), ) 	 50803202 	 1000 	 0.2956383228302002 	 0.2975497245788574 	 0.2869129180908203 	 0.2861063480377197 	 0.4500846862792969 	 0.450761079788208 	 0.39686107635498047 	 0.38557934761047363 	 
2025-07-30 15:11:53.466753 test begin: paddle.Tensor.log10(Tensor([101811, 499],"float32"), )
[Prof] paddle.Tensor.log10 	 paddle.Tensor.log10(Tensor([101811, 499],"float32"), ) 	 50803689 	 1000 	 0.29573774337768555 	 0.2975010871887207 	 0.28717780113220215 	 0.2868776321411133 	 0.45005154609680176 	 0.7458055019378662 	 0.3956913948059082 	 0.3810555934906006 	 
2025-07-30 15:11:56.902013 test begin: paddle.Tensor.log10(Tensor([80, 635041],"float32"), )
[Prof] paddle.Tensor.log10 	 paddle.Tensor.log10(Tensor([80, 635041],"float32"), ) 	 50803280 	 1000 	 0.2967665195465088 	 0.2974863052368164 	 0.28830981254577637 	 0.2869560718536377 	 0.44954538345336914 	 0.7457711696624756 	 0.39635300636291504 	 0.38101863861083984 	 
2025-07-30 15:12:00.377681 test begin: paddle.Tensor.log1p(Tensor([16934401, 3],"float32"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2956416606903076 	 0.2988593578338623 	 0.2867753505706787 	 0.2882564067840576 	 0.4513583183288574 	 0.7457292079925537 	 0.3981144428253174 	 0.3809642791748047 	 
2025-07-30 15:12:03.806147 test begin: paddle.Tensor.log1p(Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29562902450561523 	 0.29883337020874023 	 0.2867543697357178 	 0.2883272171020508 	 0.44980573654174805 	 0.7470035552978516 	 0.3713243007659912 	 0.3822648525238037 	 
2025-07-30 15:12:07.253176 test begin: paddle.Tensor.log1p(Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 3, 4233601],"float64"), ) 	 25401606 	 1000 	 0.30516839027404785 	 0.3362298011779785 	 0.29631567001342773 	 0.32558345794677734 	 0.44736337661743164 	 0.7447781562805176 	 0.39463019371032715 	 0.38049840927124023 	 
2025-07-30 15:12:10.156911 test begin: paddle.Tensor.log1p(Tensor([2, 6350401, 2],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 6350401, 2],"float64"), ) 	 25401604 	 1000 	 0.3051309585571289 	 0.345806360244751 	 0.29607605934143066 	 0.32463908195495605 	 0.4474465847015381 	 0.746229887008667 	 0.39512014389038086 	 0.3805661201477051 	 
2025-07-30 15:12:15.606264 test begin: paddle.Tensor.log1p(Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.3051903247833252 	 0.33590054512023926 	 0.29662036895751953 	 0.3249623775482178 	 0.44754672050476074 	 0.7461543083190918 	 0.3947334289550781 	 0.3818647861480713 	 
2025-07-30 15:12:18.515822 test begin: paddle.Tensor.log1p(Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([4233601, 3, 2],"float64"), ) 	 25401606 	 1000 	 0.3051469326019287 	 0.3359031677246094 	 0.29642677307128906 	 0.32529687881469727 	 0.44754838943481445 	 0.7448172569274902 	 0.38543272018432617 	 0.3805229663848877 	 
2025-07-30 15:12:21.400414 test begin: paddle.Tensor.logical_and(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_and 	 paddle.Tensor.logical_and(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11866021156311035 	 0.11630392074584961 	 0.10906672477722168 	 0.10263466835021973 	 None 	 None 	 None 	 None 	 
2025-07-30 15:12:23.078331 test begin: paddle.Tensor.logical_not(Tensor([508032010],"bool"), )
[Prof] paddle.Tensor.logical_not 	 paddle.Tensor.logical_not(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.788205623626709 	 0.7469768524169922 	 0.7795236110687256 	 0.733853816986084 	 None 	 None 	 None 	 None 	 
2025-07-30 15:12:31.579301 test begin: paddle.Tensor.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_or 	 paddle.Tensor.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11815309524536133 	 0.11595582962036133 	 0.10892677307128906 	 0.10183334350585938 	 None 	 None 	 None 	 None 	 
2025-07-30 15:12:33.307315 test begin: paddle.Tensor.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, ) 	 25401660 	 1000 	 0.3246924877166748 	 0.30502939224243164 	 0.3152444362640381 	 0.2900352478027344 	 0.44349050521850586 	 0.4487783908843994 	 0.387392520904541 	 0.38089871406555176 	 
2025-07-30 15:12:37.112459 test begin: paddle.Tensor.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, ) 	 25401640 	 1000 	 0.32467174530029297 	 0.3123619556427002 	 0.3079185485839844 	 0.2897465229034424 	 0.4435262680053711 	 0.4489426612854004 	 0.37874412536621094 	 0.3741147518157959 	 
2025-07-30 15:12:40.164927 test begin: paddle.Tensor.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, ) 	 25401630 	 1000 	 0.3246755599975586 	 0.304764986038208 	 0.3151535987854004 	 0.28681159019470215 	 0.44442272186279297 	 0.4488234519958496 	 0.3916144371032715 	 0.3797760009765625 	 
2025-07-30 15:12:42.746191 test begin: paddle.Tensor.lu(Tensor([1693, 300],"float32"), )
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:924: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  LU, pivots, infos = torch._lu_with_info(
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([1693, 300],"float32"), ) 	 507900 	 1000 	 2.8920958042144775 	 12.00865888595581 	 6.413459777832031e-05 	 0.0002124309539794922 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:12:58.487560 test begin: paddle.Tensor.lu(Tensor([216, 3, 2, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([216, 3, 2, 2],"float64"), ) 	 2592 	 1000 	 12.745160579681396 	 0.0378880500793457 	 0.00012421607971191406 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:17.339223 test begin: paddle.Tensor.lu(Tensor([3, 3, 422],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([3, 3, 422],"float64"), ) 	 3798 	 1000 	 0.15605831146240234 	 0.14899325370788574 	 0.00014591217041015625 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:18.393723 test begin: paddle.Tensor.lu(Tensor([301, 1193],"float32"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 1193],"float32"), ) 	 359093 	 1000 	 1.383970022201538 	 4.017123222351074 	 4.9591064453125e-05 	 0.00021123886108398438 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:24.937434 test begin: paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), ) 	 381066 	 1000 	 7.621222734451294 	 0.12993574142456055 	 9.179115295410156e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:37.081137 test begin: paddle.Tensor.lu(Tensor([4, 187, 2, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 187, 2, 2],"float64"), ) 	 2992 	 1000 	 14.626389503479004 	 0.03750038146972656 	 9.822845458984375e-05 	 5.173683166503906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:57.691185 test begin: paddle.Tensor.lu(Tensor([4, 3, 158, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 3, 158, 2],"float64"), ) 	 3792 	 1000 	 0.2823655605316162 	 0.10431814193725586 	 4.5299530029296875e-05 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:58.534631 test begin: paddle.Tensor.lu(Tensor([4, 3, 2, 158],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 3, 2, 158],"float64"), ) 	 3792 	 1000 	 0.39580416679382324 	 0.1410679817199707 	 3.147125244140625e-05 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:13:59.521866 test begin: paddle.Tensor.lu(Tensor([522, 3, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([522, 3, 3],"float64"), ) 	 4698 	 1000 	 11.225314617156982 	 0.061258554458618164 	 0.00011086463928222656 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:14:17.337771 test begin: paddle.Tensor.masked_fill(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 1],"bool"), 0.0, ) 	 51001907 	 1000 	 0.14302873611450195 	 0.6200251579284668 	 0.0487210750579834 	 0.2120039463043213 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:19.908667 test begin: paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1380],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1380],"bool"), 0.0, ) 	 101645280 	 1000 	 0.38124942779541016 	 0.6514079570770264 	 0.09747624397277832 	 0.22157502174377441 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:26.344285 test begin: paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, ) 	 50859468 	 1000 	 0.1421370506286621 	 0.6205143928527832 	 0.048418521881103516 	 0.2112102508544922 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:28.913556 test begin: paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1325],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1325],"bool"), 0.0, ) 	 101672550 	 1000 	 0.3823409080505371 	 0.6536276340484619 	 0.09780287742614746 	 0.22335410118103027 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:32.627282 test begin: paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, ) 	 50874642 	 1000 	 0.2494964599609375 	 0.6210682392120361 	 0.0850379467010498 	 0.21141409873962402 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:37.379358 test begin: paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, ) 	 50812650 	 1000 	 0.14200758934020996 	 0.6362340450286865 	 0.04836726188659668 	 0.2112727165222168 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:40.397315 test begin: paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 5942],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 5942],"bool"), 0.0, ) 	 101608200 	 1000 	 0.38288164138793945 	 0.6505753993988037 	 0.09790515899658203 	 0.22149419784545898 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:44.078580 test begin: paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, ) 	 52539750 	 1000 	 0.4620513916015625 	 0.6376032829284668 	 0.11824464797973633 	 0.3257591724395752 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:47.333255 test begin: paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([24, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([24, 8550, 1],"bool"), 0.0, ) 	 52736400 	 1000 	 0.14742541313171387 	 0.6366422176361084 	 0.050256967544555664 	 0.32523488998413086 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:50.154687 test begin: paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, ) 	 56604636 	 1000 	 0.49626708030700684 	 0.6883268356323242 	 0.12699341773986816 	 0.3515927791595459 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:53.774995 test begin: paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([6, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([6, 36828, 1],"bool"), 0.0, ) 	 56788776 	 1000 	 0.15917038917541504 	 0.6875479221343994 	 0.053817033767700195 	 0.3499755859375 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:14:56.644510 test begin: paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, ) 	 58970079 	 1000 	 0.5176393985748291 	 0.7191040515899658 	 0.1324779987335205 	 0.2447969913482666 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:00.407179 test begin: paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([6, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([6, 38367, 1],"bool"), 0.0, ) 	 59161914 	 1000 	 0.16460537910461426 	 0.7170979976654053 	 0.056102752685546875 	 0.24364805221557617 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:03.401039 test begin: paddle.Tensor.masked_select(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"bool"), ) 	 101606500 	 1000 	 2.6265177726745605 	 2.4556093215942383 	 0.001649618148803711 	 0.0023391246795654297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:13.528333 test begin: paddle.Tensor.masked_select(Tensor([15000, 3387],"float32"), Tensor([15000, 3387],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([15000, 3387],"float32"), Tensor([15000, 3387],"bool"), ) 	 101610000 	 1000 	 1.3882648944854736 	 2.4580299854278564 	 0.0008614063262939453 	 0.002360820770263672 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:21.166191 test begin: paddle.Tensor.masked_select(Tensor([50803201],"float32"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([50803201],"float32"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 4.812283754348755 	 1.1316745281219482 	 0.002923250198364258 	 0.0010268688201904297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:34.377473 test begin: paddle.Tensor.masked_select(Tensor([60000, 847],"float32"), Tensor([60000, 847],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([60000, 847],"float32"), Tensor([60000, 847],"bool"), ) 	 101640000 	 1000 	 1.3917970657348633 	 2.454803705215454 	 0.0008647441864013672 	 0.0023484230041503906 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:15:42.330437 test begin: paddle.Tensor.matmul(Tensor([110, 12, 197, 197],"float32"), Tensor([110, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([110, 12, 197, 197],"float32"), Tensor([110, 12, 197, 64],"float32"), ) 	 67870440 	 1000 	 1.027653455734253 	 1.027787446975708 	 1.0147027969360352 	 1.004267692565918 	 1.755735158920288 	 1.753157377243042 	 0.8971080780029297 	 0.8957655429840088 	 
2025-07-30 15:15:49.301370 test begin: paddle.Tensor.matmul(Tensor([124, 16, 100, 257],"float32"), Tensor([124, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 16, 100, 257],"float32"), Tensor([124, 16, 257, 64],"float32"), ) 	 83621632 	 1000 	 1.0259838104248047 	 1.0300214290618896 	 1.0130829811096191 	 1.0042426586151123 	 2.0558438301086426 	 2.056643009185791 	 1.0504224300384521 	 1.0508778095245361 	 
2025-07-30 15:15:57.165951 test begin: paddle.Tensor.matmul(Tensor([124, 16, 257, 257],"float32"), Tensor([124, 16, 257, 100],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 16, 257, 257],"float32"), Tensor([124, 16, 257, 100],"float32"), ) 	 182030016 	 1000 	 3.00068998336792 	 3.0037593841552734 	 2.987818956375122 	 2.9798519611358643 	 6.6900553703308105 	 6.686725616455078 	 3.4184257984161377 	 3.417926788330078 	 
2025-07-30 15:16:20.520258 test begin: paddle.Tensor.matmul(Tensor([124, 25, 257, 257],"float32"), Tensor([124, 25, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 25, 257, 257],"float32"), Tensor([124, 25, 257, 64],"float32"), ) 	 255740700 	 1000 	 4.653358697891235 	 5.442261695861816 	 4.640764951705933 	 4.624197006225586 	 8.531497955322266 	 8.445116996765137 	 4.40190863609314 	 4.314962387084961 	 
2025-07-30 15:16:55.378038 test begin: paddle.Tensor.matmul(Tensor([124, 7, 257, 257],"float32"), Tensor([124, 7, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 7, 257, 257],"float32"), Tensor([124, 7, 257, 64],"float32"), ) 	 71607396 	 1000 	 1.3444831371307373 	 1.3450028896331787 	 1.3290271759033203 	 1.3211452960968018 	 2.415957450866699 	 2.4133999347686768 	 1.235215425491333 	 1.2329962253570557 	 
2025-07-30 15:17:04.356130 test begin: paddle.Tensor.matmul(Tensor([128, 11, 197, 197],"float32"), Tensor([128, 11, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 11, 197, 197],"float32"), Tensor([128, 11, 197, 64],"float32"), ) 	 72395136 	 1000 	 1.10805344581604 	 1.111518383026123 	 1.0951869487762451 	 1.0843231678009033 	 1.8792314529418945 	 1.8806476593017578 	 0.9601807594299316 	 0.9601726531982422 	 
2025-07-30 15:17:11.810435 test begin: paddle.Tensor.matmul(Tensor([128, 12, 168, 197],"float32"), Tensor([128, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 12, 168, 197],"float32"), Tensor([128, 12, 197, 64],"float32"), ) 	 70201344 	 1000 	 1.1908819675445557 	 1.1896626949310303 	 1.176605224609375 	 1.166067361831665 	 1.852975845336914 	 1.8530404567718506 	 0.9460632801055908 	 0.9460976123809814 	 
2025-07-30 15:17:19.348872 test begin: paddle.Tensor.matmul(Tensor([128, 12, 197, 197],"float32"), Tensor([128, 12, 197, 168],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 12, 197, 197],"float32"), Tensor([128, 12, 197, 168],"float32"), ) 	 110446080 	 1000 	 2.3319413661956787 	 2.333456039428711 	 2.3166353702545166 	 2.3070409297943115 	 4.308574914932251 	 4.308629512786865 	 2.2015249729156494 	 2.2015748023986816 	 
2025-07-30 15:17:37.511076 test begin: paddle.Tensor.matmul(Tensor([128, 16, 257, 257],"float32"), Tensor([128, 16, 257, 97],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 16, 257, 257],"float32"), Tensor([128, 16, 257, 97],"float32"), ) 	 186322944 	 1000 	 3.0603041648864746 	 3.060330390930176 	 3.042778491973877 	 3.036259174346924 	 6.862872838973999 	 6.865476608276367 	 3.5081965923309326 	 3.5081639289855957 	 
2025-07-30 15:18:01.886384 test begin: paddle.Tensor.matmul(Tensor([128, 16, 97, 257],"float32"), Tensor([128, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 16, 97, 257],"float32"), Tensor([128, 16, 257, 64],"float32"), ) 	 84740096 	 1000 	 1.026641607284546 	 1.026764154434204 	 1.0137569904327393 	 1.0027072429656982 	 2.1084022521972656 	 2.108438491821289 	 1.0778882503509521 	 1.0780391693115234 	 
2025-07-30 15:18:09.796691 test begin: paddle.Tensor.matmul(Tensor([128, 25, 257, 257],"float32"), Tensor([128, 25, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 25, 257, 257],"float32"), Tensor([128, 25, 257, 64],"float32"), ) 	 263990400 	 1000 	 4.766510963439941 	 4.765910863876343 	 4.753354787826538 	 4.742042303085327 	 8.68057370185852 	 8.67600131034851 	 4.435650825500488 	 4.432653188705444 	 
2025-07-30 15:18:42.324231 test begin: paddle.Tensor.matmul(Tensor([128, 32, 197, 197],"float32"), Tensor([128, 32, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 32, 197, 197],"float32"), Tensor([128, 32, 197, 64],"float32"), ) 	 210604032 	 1000 	 3.102752923965454 	 3.1044695377349854 	 3.0900111198425293 	 3.0807371139526367 	 5.331089735031128 	 5.331818580627441 	 2.723348379135132 	 2.725147008895874 	 
2025-07-30 15:19:03.758881 test begin: paddle.Tensor.matmul(Tensor([128, 7, 257, 257],"float32"), Tensor([128, 7, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 7, 257, 257],"float32"), Tensor([128, 7, 257, 64],"float32"), ) 	 73917312 	 1000 	 1.3468539714813232 	 1.3471355438232422 	 1.3341121673583984 	 1.3234632015228271 	 2.4512827396392822 	 2.4512557983398438 	 1.2531933784484863 	 1.2531416416168213 	 
2025-07-30 15:19:12.885407 test begin: paddle.Tensor.matmul(Tensor([194, 16, 257, 257],"float32"), Tensor([194, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([194, 16, 257, 257],"float32"), Tensor([194, 16, 257, 64],"float32"), ) 	 256070688 	 1000 	 4.654927015304565 	 4.653913259506226 	 4.642124891281128 	 4.6300859451293945 	 8.451412916183472 	 8.44977068901062 	 4.317825794219971 	 4.317637920379639 	 
2025-07-30 15:19:44.959020 test begin: paddle.Tensor.matmul(Tensor([336, 12, 197, 197],"float32"), Tensor([336, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([336, 12, 197, 197],"float32"), Tensor([336, 12, 197, 64],"float32"), ) 	 207313344 	 1000 	 3.0641469955444336 	 3.073118209838867 	 3.050551414489746 	 3.039713144302368 	 5.252094030380249 	 5.254293918609619 	 2.683720588684082 	 2.6833503246307373 	 
2025-07-30 13:32:01.755516 test begin: paddle.Tensor.matmul(Tensor([49, 16, 257, 257],"float32"), Tensor([49, 16, 257, 64],"float32"), )
W0730 13:32:02.904397  2746 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([49, 16, 257, 257],"float32"), Tensor([49, 16, 257, 64],"float32"), ) 	 64677648 	 1000 	 1.1858839988708496 	 1.1855838298797607 	 1.171926736831665 	 1.1604468822479248 	 2.154151439666748 	 2.1537861824035645 	 1.1006524562835693 	 1.1004436016082764 	 
2025-07-30 13:32:10.377614 test begin: paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), -2, ) 	 50803600 	 1000 	 0.26180267333984375 	 0.195281982421875 	 0.2501509189605713 	 0.17656731605529785 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:12.877921 test begin: paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), axis=-1, keepdim=True, ) 	 50803600 	 1000 	 0.17920827865600586 	 0.15967941284179688 	 0.09157204627990723 	 0.14404511451721191 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:15.160557 test begin: paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), -2, ) 	 50840832 	 1000 	 0.3089785575866699 	 0.1602926254272461 	 0.15794682502746582 	 0.14307475090026855 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:17.630035 test begin: paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), axis=-1, keepdim=True, ) 	 50840832 	 1000 	 0.16379833221435547 	 0.15745258331298828 	 0.08369851112365723 	 0.14176297187805176 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:19.852365 test begin: paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), -2, ) 	 52684800 	 1000 	 0.25832176208496094 	 0.16819477081298828 	 0.24681353569030762 	 0.15124893188476562 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:22.374936 test begin: paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), axis=-1, keepdim=True, ) 	 52684800 	 1000 	 0.16632533073425293 	 0.16221332550048828 	 0.08498883247375488 	 0.14652609825134277 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:24.738004 test begin: paddle.Tensor.max(Tensor([324000, 157],"float32"), axis=1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([324000, 157],"float32"), axis=1, keepdim=True, ) 	 50868000 	 1000 	 0.5787742137908936 	 0.41202330589294434 	 0.5662753582000732 	 0.39610791206359863 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:27.800620 test begin: paddle.Tensor.max(Tensor([635041, 80],"float32"), axis=1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([635041, 80],"float32"), axis=1, keepdim=True, ) 	 50803280 	 1000 	 0.5393962860107422 	 0.5402228832244873 	 0.527001142501831 	 0.5245890617370605 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:30.978000 test begin: paddle.Tensor.mean(Tensor([124, 128, 34, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 128, 34, 96],"float32"), 1, keepdim=True, ) 	 51806208 	 1000 	 0.20360136032104492 	 0.151627779006958 	 0.19177961349487305 	 0.13718008995056152 	 0.14310073852539062 	 0.19728350639343262 	 0.08324646949768066 	 0.12873458862304688 	 
2025-07-30 13:32:32.518774 test begin: paddle.Tensor.mean(Tensor([124, 128, 96, 34],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 128, 96, 34],"float32"), 1, keepdim=True, ) 	 51806208 	 1000 	 0.2036149501800537 	 0.15150904655456543 	 0.19186162948608398 	 0.13732004165649414 	 0.1430964469909668 	 0.19723129272460938 	 0.08211064338684082 	 0.12985539436340332 	 
2025-07-30 13:32:34.094221 test begin: paddle.Tensor.mean(Tensor([124, 45, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 45, 96, 96],"float32"), 1, keepdim=True, ) 	 51425280 	 1000 	 0.16913223266601562 	 0.15744948387145996 	 0.15418148040771484 	 0.1435229778289795 	 0.14670848846435547 	 0.21254849433898926 	 0.07055234909057617 	 0.14423847198486328 	 
2025-07-30 13:32:40.111155 test begin: paddle.Tensor.mean(Tensor([128, 128, 33, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 128, 33, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.22684097290039062 	 0.16431164741516113 	 0.19194960594177246 	 0.1379404067993164 	 0.14351105690002441 	 0.19832372665405273 	 0.07967185974121094 	 0.129472017288208 	 
2025-07-30 13:32:41.917320 test begin: paddle.Tensor.mean(Tensor([128, 128, 96, 33],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 128, 96, 33],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.2053220272064209 	 0.15264320373535156 	 0.19326233863830566 	 0.13841843605041504 	 0.1434164047241211 	 0.19832611083984375 	 0.0829916000366211 	 0.13022518157958984 	 
2025-07-30 13:32:43.454659 test begin: paddle.Tensor.mean(Tensor([128, 192, 22, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 192, 22, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.218275785446167 	 0.15047907829284668 	 0.20603680610656738 	 0.13667082786560059 	 0.14364027976989746 	 0.19699406623840332 	 0.08331918716430664 	 0.12736177444458008 	 
2025-07-30 13:32:44.988183 test begin: paddle.Tensor.mean(Tensor([128, 192, 96, 22],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 192, 96, 22],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.21828317642211914 	 0.15048885345458984 	 0.20665383338928223 	 0.13657760620117188 	 0.14363360404968262 	 0.19696760177612305 	 0.0832526683807373 	 0.12737631797790527 	 
2025-07-30 13:32:46.521385 test begin: paddle.Tensor.mean(Tensor([128, 44, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 44, 96, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.16771674156188965 	 0.15745329856872559 	 0.15606284141540527 	 0.1434156894683838 	 0.14764904975891113 	 0.21569252014160156 	 0.08801388740539551 	 0.1425762176513672 	 
2025-07-30 13:32:48.087648 test begin: paddle.Tensor.mean(Tensor([29, 192, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([29, 192, 96, 96],"float32"), 1, keepdim=True, ) 	 51314688 	 1000 	 0.16582751274108887 	 0.14812564849853516 	 0.15396833419799805 	 0.13426971435546875 	 0.14061880111694336 	 0.19257116317749023 	 0.0814664363861084 	 0.12492179870605469 	 
2025-07-30 13:32:49.563613 test begin: paddle.Tensor.mean(Tensor([44, 128, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([44, 128, 96, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.16806554794311523 	 0.15083694458007812 	 0.15596342086791992 	 0.1367652416229248 	 0.14245176315307617 	 0.20236945152282715 	 0.08136725425720215 	 0.13286900520324707 	 
2025-07-30 13:32:51.087601 test begin: paddle.Tensor.min(Tensor([1, 193, 65856, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 193, 65856, 4],"float32"), axis=-1, ) 	 50840832 	 1000 	 0.5391848087310791 	 0.8744814395904541 	 0.5272359848022461 	 0.8494312763214111 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:32:54.982692 test begin: paddle.Tensor.min(Tensor([1, 400, 31753, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 31753, 4],"float32"), axis=-1, ) 	 50804800 	 1000 	 0.5388391017913818 	 0.8787014484405518 	 0.5268476009368896 	 0.8411202430725098 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:02.186429 test begin: paddle.Tensor.min(Tensor([1, 400, 65856, 2],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 65856, 2],"float32"), axis=-1, ) 	 52684800 	 1000 	 0.5196225643157959 	 0.8217155933380127 	 0.5051391124725342 	 0.8038303852081299 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:06.446369 test begin: paddle.Tensor.min(Tensor([1, 400, 65856, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 65856, 4],"float32"), axis=-1, ) 	 105369600 	 1000 	 1.1119921207427979 	 1.7916879653930664 	 1.0990967750549316 	 1.7736189365386963 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:14.445435 test begin: paddle.Tensor.min(Tensor([15661, 4, 811],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([15661, 4, 811],"float32"), axis=1, ) 	 50804284 	 1000 	 0.21974658966064453 	 0.30113816261291504 	 0.20789241790771484 	 0.27921223640441895 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:17.213194 test begin: paddle.Tensor.min(Tensor([24565, 3, 811],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([24565, 3, 811],"float32"), axis=1, ) 	 59766645 	 1000 	 0.3052225112915039 	 0.40638208389282227 	 0.2933075428009033 	 0.38904833793640137 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:20.812647 test begin: paddle.Tensor.min(Tensor([24565, 4, 518],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([24565, 4, 518],"float32"), axis=1, ) 	 50898680 	 1000 	 0.22656822204589844 	 0.26584506034851074 	 0.2145836353302002 	 0.24822568893432617 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:23.590994 test begin: paddle.Tensor.min(Tensor([3, 525, 12096, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([3, 525, 12096, 4],"float32"), axis=-1, ) 	 76204800 	 1000 	 0.8052451610565186 	 1.2974870204925537 	 0.7927868366241455 	 1.2797553539276123 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:29.317878 test begin: paddle.Tensor.min(Tensor([4, 263, 12096, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 263, 12096, 4],"float32"), axis=-1, ) 	 50899968 	 1000 	 0.5389206409454346 	 0.8688297271728516 	 0.5266332626342773 	 0.8511111736297607 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:33.138923 test begin: paddle.Tensor.min(Tensor([4, 525, 12096, 3],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 525, 12096, 3],"float32"), axis=-1, ) 	 76204800 	 1000 	 0.5274033546447754 	 0.9194502830505371 	 0.5144124031066895 	 0.8705079555511475 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:40.498144 test begin: paddle.Tensor.min(Tensor([4, 525, 6049, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 525, 6049, 4],"float32"), axis=-1, ) 	 50811600 	 1000 	 0.5380802154541016 	 0.8673791885375977 	 0.5257301330566406 	 0.8495543003082275 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 13:33:44.362998 test begin: paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.mm 	 paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 5080321],"float32"), ) 	 50803310 	 1000 	 0.6558651924133301 	 0.6530029773712158 	 0.13365793228149414 	 0.13341355323791504 	 1.4455904960632324 	 1.4430391788482666 	 0.2110271453857422 	 0.21064305305480957 	 
2025-07-30 13:33:50.236996 test begin: paddle.Tensor.mm(Tensor([5080321, 10],"float32"), Tensor([10, 10],"float32"), )
[Prof] paddle.Tensor.mm 	 paddle.Tensor.mm(Tensor([5080321, 10],"float32"), Tensor([10, 10],"float32"), ) 	 50803310 	 1000 	 0.651813268661499 	 0.6554608345031738 	 0.13311171531677246 	 0.1330409049987793 	 1.414524793624878 	 1.4125688076019287 	 0.20647692680358887 	 0.2062091827392578 	 
2025-07-30 13:33:56.064154 test begin: paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), ) 	 25401606 	 1000 	 49.33614778518677 	 9.412165880203247 	 0.00011372566223144531 	 0.00023889541625976562 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:34:57.641252 test begin: paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), axis=2, keepdim=True, ) 	 25401606 	 1000 	 51.20007801055908 	 9.435173988342285 	 0.00012063980102539062 	 0.0002377033233642578 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:36:01.018460 test begin: paddle.Tensor.mode(Tensor([3, 2822401, 3],"float64"), axis=1, keepdim=False, )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2822401, 3],"float64"), axis=1, keepdim=False, ) 	 25401609 	 1000 	 58.899264335632324 	 10.731005907058716 	 0.00010323524475097656 	 0.0002372264862060547 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:37:15.555653 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.007725238800048828 	 0.004549741744995117 	 3.075599670410156e-05 	 2.4318695068359375e-05 	 0.04499006271362305 	 0.05313825607299805 	 3.933906555175781e-05 	 4.553794860839844e-05 	 
2025-07-30 13:37:26.986408 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.007563352584838867 	 0.005649089813232422 	 1.9073486328125e-05 	 1.9788742065429688e-05 	 0.043473005294799805 	 0.055918216705322266 	 6.842613220214844e-05 	 8.106231689453125e-05 	 
2025-07-30 13:37:41.373744 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, ) 	 254016240 	 1000 	 0.006909847259521484 	 0.004577159881591797 	 1.0013580322265625e-05 	 2.2172927856445312e-05 	 0.0442047119140625 	 0.05243992805480957 	 5.936622619628906e-05 	 6.723403930664062e-05 	 
2025-07-30 13:37:51.859179 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.006872653961181641 	 0.004614830017089844 	 1.2159347534179688e-05 	 2.2411346435546875e-05 	 0.04462480545043945 	 0.05411529541015625 	 3.933906555175781e-05 	 6.604194641113281e-05 	 
2025-07-30 13:38:02.291822 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007521152496337891 	 0.0056226253509521484 	 1.3113021850585938e-05 	 2.4318695068359375e-05 	 0.04399371147155762 	 0.053795814514160156 	 3.409385681152344e-05 	 6.604194641113281e-05 	 
2025-07-30 13:38:12.852873 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.006997108459472656 	 0.004568338394165039 	 1.2636184692382812e-05 	 2.3365020751953125e-05 	 0.04411506652832031 	 0.05418252944946289 	 3.1948089599609375e-05 	 6.127357482910156e-05 	 
2025-07-30 13:38:23.461250 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.0074999332427978516 	 0.0056226253509521484 	 8.58306884765625e-06 	 2.0265579223632812e-05 	 0.0439915657043457 	 0.05260753631591797 	 4.887580871582031e-05 	 3.790855407714844e-05 	 
2025-07-30 13:38:34.049997 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, ) 	 254016400 	 1000 	 0.006860017776489258 	 0.0044841766357421875 	 9.298324584960938e-06 	 2.3603439331054688e-05 	 0.043653011322021484 	 0.05216336250305176 	 2.3365020751953125e-05 	 5.054473876953125e-05 	 
2025-07-30 13:38:44.776951 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.006871938705444336 	 0.005820512771606445 	 1.0967254638671875e-05 	 6.699562072753906e-05 	 0.047429800033569336 	 0.05384540557861328 	 4.863739013671875e-05 	 6.699562072753906e-05 	 
2025-07-30 13:38:55.452526 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.007428884506225586 	 0.0056955814361572266 	 1.3828277587890625e-05 	 2.288818359375e-05 	 0.04422640800476074 	 0.05367708206176758 	 4.5299530029296875e-05 	 6.270408630371094e-05 	 
2025-07-30 13:39:06.065052 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, ) 	 254016600 	 1000 	 0.006867170333862305 	 0.004507780075073242 	 8.344650268554688e-06 	 2.3603439331054688e-05 	 0.0453493595123291 	 0.052163124084472656 	 4.9591064453125e-05 	 5.054473876953125e-05 	 
2025-07-30 13:39:17.878587 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.00693821907043457 	 0.0045642852783203125 	 9.5367431640625e-06 	 2.288818359375e-05 	 0.04429197311401367 	 0.06582021713256836 	 3.314018249511719e-05 	 8.368492126464844e-05 	 
2025-07-30 13:39:33.808992 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007494688034057617 	 0.005686283111572266 	 1.7881393432617188e-05 	 2.47955322265625e-05 	 0.046448469161987305 	 0.07496452331542969 	 0.00010132789611816406 	 7.05718994140625e-05 	 
2025-07-30 13:39:45.307660 test begin: paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, ) 	 254016300 	 1000 	 0.006884336471557617 	 0.005220890045166016 	 1.1920928955078125e-05 	 6.031990051269531e-05 	 0.04377889633178711 	 0.05226325988769531 	 4.696846008300781e-05 	 5.7220458984375e-05 	 
2025-07-30 13:39:55.873908 test begin: paddle.Tensor.multiply(Tensor([132301, 768],"float16"), Tensor([132301, 1],"float32"), )
W0730 13:39:57.738502  6300 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([132301, 768],"float16"), Tensor([132301, 1],"float32"), ) 	 101739469 	 1000 	 1.0666673183441162 	 0.7291731834411621 	 0.5450992584228516 	 0.7159016132354736 	 1.9069297313690186 	 2.1274545192718506 	 0.6489989757537842 	 0.5432167053222656 	 
2025-07-30 13:40:05.430654 test begin: paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 1],"float32"), ) 	 50803520 	 1000 	 0.2964966297149658 	 0.3034811019897461 	 0.2858257293701172 	 0.29117369651794434 	 0.7715840339660645 	 0.9225599765777588 	 0.2624988555908203 	 0.2354285717010498 	 
2025-07-30 13:40:09.461649 test begin: paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 317521],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 317521],"float32"), ) 	 101606720 	 1000 	 0.45031309127807617 	 0.4469482898712158 	 0.4404640197753906 	 0.435319185256958 	 1.0745453834533691 	 0.8932464122772217 	 1.0078797340393066 	 0.4563713073730469 	 
2025-07-30 13:40:14.802777 test begin: paddle.Tensor.multiply(Tensor([160, 635041],"float16"), Tensor([160, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 635041],"float16"), Tensor([160, 1],"float32"), ) 	 101606720 	 1000 	 1.0679669380187988 	 0.6949963569641113 	 0.5456845760345459 	 0.6823239326477051 	 1.921464204788208 	 2.1364588737487793 	 0.49039173126220703 	 0.436082124710083 	 
2025-07-30 13:40:24.154171 test begin: paddle.Tensor.multiply(Tensor([16538, 3072],"float32"), Tensor([16538, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([16538, 3072],"float32"), Tensor([16538, 1],"float32"), ) 	 50821274 	 1000 	 0.29548144340515137 	 0.30783534049987793 	 0.28470611572265625 	 0.295346736907959 	 0.7364552021026611 	 0.9006590843200684 	 0.3762702941894531 	 0.3066732883453369 	 
2025-07-30 13:40:28.017648 test begin: paddle.Tensor.multiply(Tensor([33076, 3072],"float16"), Tensor([33076, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([33076, 3072],"float16"), Tensor([33076, 1],"float32"), ) 	 101642548 	 1000 	 1.068030834197998 	 0.728461503982544 	 0.5457572937011719 	 0.7106764316558838 	 1.9019465446472168 	 2.1310927867889404 	 0.6473898887634277 	 0.5440762042999268 	 
2025-07-30 13:40:40.752516 test begin: paddle.Tensor.multiply(Tensor([512, 198451],"float16"), Tensor([512, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([512, 198451],"float16"), Tensor([512, 1],"float32"), ) 	 101607424 	 1000 	 1.0706307888031006 	 0.7046151161193848 	 0.5471434593200684 	 0.682309627532959 	 1.9454503059387207 	 2.155885696411133 	 0.4965174198150635 	 0.5504951477050781 	 
2025-07-30 13:40:50.486166 test begin: paddle.Tensor.nansum(Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0646498203277588 	 0.1896224021911621 	 0.2722487449645996 	 0.17261290550231934 	 0.5277979373931885 	 0.4417548179626465 	 0.26961207389831543 	 0.15038752555847168 	 
2025-07-30 13:40:53.413932 test begin: paddle.Tensor.nansum(Tensor([2822401, 3, 3],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([2822401, 3, 3],"float64"), ) 	 25401609 	 1000 	 0.9355077743530273 	 0.14979791641235352 	 0.19100093841552734 	 0.0765383243560791 	 0.46495962142944336 	 0.41323423385620117 	 0.23752403259277344 	 0.1407155990600586 	 
2025-07-30 13:40:55.932329 test begin: paddle.Tensor.nansum(Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.064666509628296 	 0.18958425521850586 	 0.2722337245941162 	 0.17375540733337402 	 0.5277972221374512 	 0.44172072410583496 	 0.26961350440979004 	 0.1503450870513916 	 
2025-07-30 13:40:58.807038 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401780 	 1000 	 5.651477098464966 	 0.17207574844360352 	 1.1578352451324463 	 0.08790135383605957 	 0.4657461643218994 	 0.4177544116973877 	 0.23795771598815918 	 0.14219355583190918 	 
2025-07-30 13:41:09.649918 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401744 	 1000 	 0.9741697311401367 	 0.19018054008483887 	 0.2490224838256836 	 0.17441534996032715 	 0.5113470554351807 	 0.44371485710144043 	 0.2612431049346924 	 0.15109682083129883 	 
2025-07-30 13:41:12.431656 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 0.9752092361450195 	 0.19066810607910156 	 0.24932408332824707 	 0.17479300498962402 	 0.51175856590271 	 0.4441697597503662 	 0.2614328861236572 	 0.15122151374816895 	 
2025-07-30 13:41:15.222262 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, ) 	 25402320 	 1000 	 0.9741754531860352 	 0.19017672538757324 	 0.2490396499633789 	 0.17452740669250488 	 0.5116221904754639 	 0.44544053077697754 	 0.26145243644714355 	 0.15164709091186523 	 
2025-07-30 13:41:18.012863 test begin: paddle.Tensor.nansum(Tensor([3, 2822401, 3],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2822401, 3],"float64"), ) 	 25401609 	 1000 	 0.9353439807891846 	 0.14993762969970703 	 0.19094133377075195 	 0.07656455039978027 	 0.46506357192993164 	 0.41326904296875 	 0.23758244514465332 	 0.14070749282836914 	 
2025-07-30 13:41:20.511576 test begin: paddle.Tensor.nansum(Tensor([3, 3, 2822401],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 3, 2822401],"float64"), ) 	 25401609 	 1000 	 0.935382604598999 	 0.14976787567138672 	 0.19095540046691895 	 0.07651758193969727 	 0.46491169929504395 	 0.41320180892944336 	 0.23746824264526367 	 0.14068603515625 	 
2025-07-30 13:41:23.013530 test begin: paddle.Tensor.nansum(Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 1.009577751159668 	 0.15259599685668945 	 0.2061007022857666 	 0.07795953750610352 	 0.5588715076446533 	 0.5898540019989014 	 0.2855358123779297 	 0.20091795921325684 	 
2025-07-30 13:41:26.181686 test begin: paddle.Tensor.nansum(Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 1.0095572471618652 	 0.15270233154296875 	 0.20610284805297852 	 0.07805514335632324 	 0.5587751865386963 	 0.5898630619049072 	 0.28545713424682617 	 0.2009115219116211 	 
2025-07-30 13:41:29.314712 test begin: paddle.Tensor.nansum(Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 1.0641109943389893 	 0.18953657150268555 	 0.27210378646850586 	 0.17380261421203613 	 0.53025221824646 	 0.44198131561279297 	 0.2709319591522217 	 0.15050172805786133 	 
2025-07-30 13:41:32.244881 test begin: paddle.Tensor.nansum(Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 1.0095279216766357 	 0.15261411666870117 	 0.2061138153076172 	 0.07798194885253906 	 0.5588347911834717 	 0.5898916721343994 	 0.28554654121398926 	 0.20091819763183594 	 
2025-07-30 13:41:37.857726 test begin: paddle.Tensor.neg(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.neg 	 paddle.Tensor.neg(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2957944869995117 	 0.3148660659790039 	 0.28603434562683105 	 0.28542137145996094 	 0.295914888381958 	 0.2978346347808838 	 0.23992395401000977 	 0.23644709587097168 	 
2025-07-30 13:41:41.559431 test begin: paddle.Tensor.nonzero(Tensor([3628801, 14],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([3628801, 14],"bool"), ) 	 50803214 	 1000 	 5.9417665004730225 	 1.4240052700042725 	 0.0040454864501953125 	 0.0013167858123779297 	 None 	 None 	 None 	 None 	 
2025-07-30 13:41:53.408604 test begin: paddle.Tensor.nonzero(Tensor([3907939, 13],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([3907939, 13],"bool"), ) 	 50803207 	 1000 	 5.944519758224487 	 1.4217307567596436 	 0.0040547847747802734 	 0.0013098716735839844 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:01.499847 test begin: paddle.Tensor.nonzero(Tensor([4233601, 12],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([4233601, 12],"bool"), ) 	 50803212 	 1000 	 5.937832593917847 	 1.4139764308929443 	 0.00406193733215332 	 0.0013117790222167969 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:09.572198 test begin: paddle.Tensor.nonzero(Tensor([52640, 966],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([52640, 966],"bool"), ) 	 50850240 	 1000 	 5.941329002380371 	 1.4125573635101318 	 0.004066944122314453 	 0.0013184547424316406 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:17.656151 test begin: paddle.Tensor.norm(Tensor([100352, 507],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.15294933319091797 	 0.15231871604919434 	 0.051978111267089844 	 0.07774519920349121 	 0.9976658821105957 	 0.9122514724731445 	 0.9360122680664062 	 0.23322176933288574 	 
2025-07-30 13:42:21.234435 test begin: paddle.Tensor.norm(Tensor([507, 100352],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.1528937816619873 	 0.1522672176361084 	 0.05197882652282715 	 0.0777430534362793 	 0.9976437091827393 	 0.9121086597442627 	 0.9396281242370605 	 0.2331550121307373 	 
2025-07-30 13:42:24.270174 test begin: paddle.Tensor.norm(Tensor([6202, 8192],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.15250253677368164 	 0.15204501152038574 	 0.051856279373168945 	 0.07766079902648926 	 0.9966378211975098 	 0.910330057144165 	 0.9371049404144287 	 0.23269200325012207 	 
2025-07-30 13:42:27.363010 test begin: paddle.Tensor.norm(Tensor([8192, 6202],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.15249061584472656 	 0.15250444412231445 	 0.05183911323547363 	 0.07789015769958496 	 0.9969692230224609 	 0.9103105068206787 	 0.93715500831604 	 0.2327120304107666 	 
2025-07-30 13:42:30.391548 test begin: paddle.Tensor.norm(Tensor([886, 57344],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.15245485305786133 	 0.15221452713012695 	 0.05183696746826172 	 0.07771587371826172 	 0.9968266487121582 	 0.9102661609649658 	 0.9377353191375732 	 0.23267340660095215 	 
2025-07-30 13:42:33.422140 test begin: paddle.Tensor.not_equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), ) 	 50803456 	 1000 	 0.30922818183898926 	 0.31668543815612793 	 0.30010294914245605 	 0.3016672134399414 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:34.879660 test begin: paddle.Tensor.not_equal(Tensor([13, 1953970],"int64"), Tensor([1],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([13, 1953970],"int64"), Tensor([1],"int64"), ) 	 25401611 	 1000 	 0.17622971534729004 	 0.20001745223999023 	 0.16612648963928223 	 0.1680920124053955 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:39.703348 test begin: paddle.Tensor.not_equal(Tensor([13, 3907939],"bool"), Tensor([1],"bool"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([13, 3907939],"bool"), Tensor([1],"bool"), ) 	 50803208 	 1000 	 0.1379239559173584 	 0.20658040046691895 	 0.12773919105529785 	 0.1860947608947754 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:40.811781 test begin: paddle.Tensor.not_equal(Tensor([1814401, 14],"int64"), Tensor([1],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([1814401, 14],"int64"), Tensor([1],"int64"), ) 	 25401615 	 1000 	 0.1762235164642334 	 0.18366169929504395 	 0.16600847244262695 	 0.16754508018493652 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:41.574013 test begin: paddle.Tensor.not_equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), ) 	 50803456 	 1000 	 0.3091442584991455 	 0.31323671340942383 	 0.2997603416442871 	 0.3014411926269531 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:43.022049 test begin: paddle.Tensor.not_equal(Tensor([3628801, 14],"bool"), Tensor([1],"bool"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([3628801, 14],"bool"), Tensor([1],"bool"), ) 	 50803215 	 1000 	 0.13791227340698242 	 0.2052750587463379 	 0.12750864028930664 	 0.18575119972229004 	 None 	 None 	 None 	 None 	 
2025-07-30 13:42:44.084041 test begin: paddle.Tensor.outer(x=Tensor([12700801, 2],"float64"), y=Tensor([2, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([12700801, 2],"float64"), y=Tensor([2, 3, 4],"float64"), ) 	 25401626 	 1000 	 3.878390312194824 	 3.8162999153137207 	 0.15852904319763184 	 0.9748280048370361 	 7.489485025405884 	 22.861461877822876 	 2.5497779846191406 	 1.1667580604553223 	 
2025-07-30 13:43:35.458047 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3175201],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3175201],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401632 	 1000 	 4.3216705322265625 	 4.506328105926514 	 0.15853190422058105 	 0.9777498245239258 	 7.489214658737183 	 22.819098711013794 	 2.5498909950256348 	 1.164876937866211 	 
2025-07-30 13:44:30.516355 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3175201],"float64"), ) 	 25401632 	 1000 	 4.0445637702941895 	 7.113240003585815 	 0.165208101272583 	 1.8165149688720703 	 7.440973281860352 	 25.5309579372406 	 2.5336430072784424 	 1.3043806552886963 	 
2025-07-30 13:45:28.214675 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2116801, 3],"float64"), ) 	 25401636 	 1000 	 4.03612756729126 	 7.079359531402588 	 0.1648387908935547 	 1.8085815906524658 	 7.448847770690918 	 25.505164623260498 	 2.5365540981292725 	 1.3030755519866943 	 
2025-07-30 13:46:25.363906 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4233601, 2, 3],"float64"), ) 	 25401630 	 1000 	 4.184515953063965 	 7.124070882797241 	 0.17083477973937988 	 1.8200044631958008 	 7.449264287948608 	 25.74891757965088 	 2.536309242248535 	 1.5097761154174805 	 
2025-07-30 13:47:25.225789 test begin: paddle.Tensor.outer(x=Tensor([4, 2116801, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2116801, 3],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401636 	 1000 	 3.8782713413238525 	 3.831540107727051 	 0.15857744216918945 	 0.9782774448394775 	 7.488352537155151 	 22.822824239730835 	 2.5495595932006836 	 1.164811611175537 	 
2025-07-30 13:48:16.257461 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4233601],"float64"), ) 	 25401614 	 1000 	 1.5348730087280273 	 2.5057854652404785 	 0.06224536895751953 	 2.4875214099884033 	 2.7556605339050293 	 8.337076187133789 	 0.9382190704345703 	 1.7030203342437744 	 
2025-07-30 13:48:37.418467 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3175201, 4],"float64"), ) 	 25401616 	 1000 	 2.2979137897491455 	 2.359292984008789 	 0.06205439567565918 	 2.3440732955932617 	 2.7509560585021973 	 8.333055019378662 	 0.9367477893829346 	 1.7022111415863037 	 
2025-07-30 13:48:58.043120 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2116801, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2116801, 3, 4],"float64"), ) 	 25401620 	 1000 	 1.5136260986328125 	 2.35203218460083 	 0.06186270713806152 	 2.3333685398101807 	 2.7528598308563232 	 8.330335855484009 	 0.9372093677520752 	 1.7017276287078857 	 
2025-07-30 13:49:17.835849 test begin: paddle.Tensor.outer(x=Tensor([4, 6350401],"float64"), y=Tensor([2, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 6350401],"float64"), y=Tensor([2, 3, 4],"float64"), ) 	 25401628 	 1000 	 3.878387689590454 	 3.8391313552856445 	 0.15851187705993652 	 0.9786510467529297 	 7.489063739776611 	 22.78414535522461 	 2.5497663021087646 	 1.1626942157745361 	 
2025-07-30 13:50:11.246248 test begin: paddle.Tensor.outer(x=Tensor([4233601, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4233601, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401630 	 1000 	 3.881577491760254 	 3.82153582572937 	 0.15852808952331543 	 0.9764373302459717 	 7.488474607467651 	 22.799603700637817 	 2.549454927444458 	 1.163728952407837 	 
2025-07-30 13:51:03.486979 test begin: paddle.Tensor.pow(Tensor([124, 128, 34, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 128, 34, 96],"float32"), 2, ) 	 51806208 	 1000 	 0.37569284439086914 	 0.3328888416290283 	 0.3633089065551758 	 0.29084277153015137 	 0.4611930847167969 	 1.073045015335083 	 0.4030497074127197 	 0.3655588626861572 	 
2025-07-30 13:51:11.415907 test begin: paddle.Tensor.pow(Tensor([124, 128, 96, 34],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 128, 96, 34],"float32"), 2, ) 	 51806208 	 1000 	 0.375657320022583 	 0.310391902923584 	 0.36620044708251953 	 0.2910013198852539 	 0.4610767364501953 	 1.073014497756958 	 0.4026458263397217 	 0.3655872344970703 	 
2025-07-30 13:51:15.358711 test begin: paddle.Tensor.pow(Tensor([124, 45, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 45, 96, 96],"float32"), 2, ) 	 51425280 	 1000 	 0.3729579448699951 	 0.3014533519744873 	 0.36347031593322754 	 0.28848910331726074 	 0.4578242301940918 	 1.0652964115142822 	 0.39866089820861816 	 0.36287808418273926 	 
2025-07-30 13:51:19.250120 test begin: paddle.Tensor.pow(Tensor([128, 128, 33, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 128, 33, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.376415491104126 	 0.3041844367980957 	 0.3665895462036133 	 0.2916429042816162 	 0.4619925022125244 	 1.0751430988311768 	 0.39965224266052246 	 0.3662843704223633 	 
2025-07-30 13:51:23.265639 test begin: paddle.Tensor.pow(Tensor([128, 128, 96, 33],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 128, 96, 33],"float32"), 2, ) 	 51904512 	 1000 	 0.37644076347351074 	 0.30417561531066895 	 0.3668994903564453 	 0.2915492057800293 	 0.46192121505737305 	 1.0750677585601807 	 0.40287351608276367 	 0.366253137588501 	 
2025-07-30 13:51:27.188192 test begin: paddle.Tensor.pow(Tensor([128, 192, 22, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 192, 22, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.37647104263305664 	 0.30421018600463867 	 0.36656785011291504 	 0.2917141914367676 	 0.46203112602233887 	 1.075031042098999 	 0.4012563228607178 	 0.3662385940551758 	 
2025-07-30 13:51:31.150947 test begin: paddle.Tensor.pow(Tensor([128, 192, 96, 22],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 192, 96, 22],"float32"), 2, ) 	 51904512 	 1000 	 0.37642478942871094 	 0.30417585372924805 	 0.36698365211486816 	 0.2916402816772461 	 0.461916446685791 	 1.075085163116455 	 0.40006232261657715 	 0.3662407398223877 	 
2025-07-30 13:51:35.091838 test begin: paddle.Tensor.pow(Tensor([128, 44, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 44, 96, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.3764801025390625 	 2.0237481594085693 	 0.36199378967285156 	 0.291426420211792 	 0.4620230197906494 	 1.0751850605010986 	 0.4029858112335205 	 0.3662877082824707 	 
2025-07-30 13:51:41.334705 test begin: paddle.Tensor.pow(Tensor([29, 192, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([29, 192, 96, 96],"float32"), 2, ) 	 51314688 	 1000 	 0.3723292350769043 	 0.3007798194885254 	 0.36284828186035156 	 0.2883141040802002 	 0.4568600654602051 	 1.0630197525024414 	 0.39410996437072754 	 0.36215662956237793 	 
2025-07-30 13:51:45.235196 test begin: paddle.Tensor.pow(Tensor([44, 128, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([44, 128, 96, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.3765528202056885 	 0.30420613288879395 	 0.3669469356536865 	 0.291736364364624 	 0.461838960647583 	 1.075106143951416 	 0.4018237590789795 	 0.3663291931152344 	 
2025-07-30 13:51:50.542753 test begin: paddle.Tensor.prod(Tensor([1, 386, 65856, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 386, 65856, 2],"float32"), -1, ) 	 50840832 	 1000 	 0.3882014751434326 	 0.4848353862762451 	 0.37145018577575684 	 0.4468662738800049 	 1.6769602298736572 	 2.055516242980957 	 1.6172187328338623 	 0.0007169246673583984 	 
2025-07-30 13:51:56.571503 test begin: paddle.Tensor.prod(Tensor([1, 400, 63505, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 400, 63505, 2],"float32"), -1, ) 	 50804000 	 1000 	 0.3890702724456787 	 0.4677417278289795 	 0.3726944923400879 	 0.45365309715270996 	 1.6766250133514404 	 2.0546252727508545 	 1.6169958114624023 	 0.0007073879241943359 	 
2025-07-30 13:52:02.429163 test begin: paddle.Tensor.prod(Tensor([1, 400, 65856, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 400, 65856, 2],"float32"), -1, ) 	 52684800 	 1000 	 0.40195727348327637 	 0.4848756790161133 	 0.38539886474609375 	 0.4705321788787842 	 1.7378368377685547 	 2.125797748565674 	 1.677769660949707 	 0.0007433891296386719 	 
2025-07-30 13:52:08.451866 test begin: paddle.Tensor.prod(Tensor([2100, 12096, 3],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2100, 12096, 3],"float32"), -1, ) 	 76204800 	 1000 	 0.41341161727905273 	 0.5124421119689941 	 0.3970611095428467 	 0.498363733291626 	 1.8902156352996826 	 2.7250585556030273 	 1.8285784721374512 	 0.0010066032409667969 	 
2025-07-30 13:52:15.667036 test begin: paddle.Tensor.prod(Tensor([2100, 12097, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2100, 12097, 2],"float32"), -1, ) 	 50807400 	 1000 	 0.3880300521850586 	 0.4677619934082031 	 0.3714621067047119 	 0.45371031761169434 	 1.2669789791107178 	 2.0599558353424072 	 1.2022218704223633 	 0.0007061958312988281 	 
2025-07-30 13:52:21.076635 test begin: paddle.Tensor.prod(Tensor([2101, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2101, 12096, 2],"float32"), -1, ) 	 50827392 	 1000 	 0.3883802890777588 	 0.4686014652252197 	 0.37213730812072754 	 0.45327162742614746 	 1.2666947841644287 	 2.058781623840332 	 1.2051379680633545 	 0.0006873607635498047 	 
2025-07-30 13:52:26.465907 test begin: paddle.Tensor.prod(Tensor([4, 525, 12096, 3],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 525, 12096, 3],"float32"), -1, ) 	 76204800 	 1000 	 0.4134955406188965 	 0.5134506225585938 	 0.39697933197021484 	 0.4978458881378174 	 2.505951404571533 	 2.7201950550079346 	 2.4443893432617188 	 0.0009706020355224609 	 
2025-07-30 13:52:34.353899 test begin: paddle.Tensor.prod(Tensor([4, 525, 12097, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 525, 12097, 2],"float32"), -1, ) 	 50807400 	 1000 	 0.3880009651184082 	 1.683645486831665 	 0.36927270889282227 	 0.4531106948852539 	 1.6767795085906982 	 2.057891845703125 	 1.6150527000427246 	 0.0007126331329345703 	 
2025-07-30 13:52:42.264661 test begin: paddle.Tensor.prod(Tensor([4, 526, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 526, 12096, 2],"float32"), -1, ) 	 50899968 	 1000 	 0.3885810375213623 	 0.4768693447113037 	 0.37212586402893066 	 0.45462489128112793 	 1.679567813873291 	 2.0610456466674805 	 1.6189570426940918 	 0.0007112026214599609 	 
2025-07-30 13:52:48.139874 test begin: paddle.Tensor.prod(Tensor([5, 525, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([5, 525, 12096, 2],"float32"), -1, ) 	 63504000 	 1000 	 0.4834475517272949 	 0.5831501483917236 	 0.46696925163269043 	 0.5693507194519043 	 2.0933477878570557 	 2.547758102416992 	 2.033576250076294 	 0.0008947849273681641 	 
2025-07-30 13:52:56.321207 test begin: paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 145800 	 1000 	 16.36245584487915 	 0.22365331649780273 	 0.4253358840942383 	 0.00010347366333007812 	 0.20450997352600098 	 0.2403731346130371 	 2.956390380859375e-05 	 7.081031799316406e-05 	 
2025-07-30 13:53:13.493878 test begin: paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 145800 	 1000 	 13.114858865737915 	 0.22556352615356445 	 0.36848998069763184 	 7.557868957519531e-05 	 0.19035911560058594 	 0.21813559532165527 	 3.600120544433594e-05 	 5.507469177246094e-05 	 
2025-07-30 13:53:27.269555 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=3, keepdim=True, ) 	 124416 	 1000 	 13.980720043182373 	 0.2326645851135254 	 0.36325693130493164 	 0.00017380714416503906 	 0.20803236961364746 	 0.24189233779907227 	 5.4836273193359375e-05 	 6.437301635742188e-05 	 
2025-07-30 13:53:41.969745 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=5, ) 	 124416 	 1000 	 0.6906654834747314 	 0.2762584686279297 	 3.528594970703125e-05 	 0.0001647472381591797 	 0.23907852172851562 	 0.2468411922454834 	 6.198883056640625e-05 	 0.0001125335693359375 	 
2025-07-30 13:53:43.440832 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253800 	 1000 	 28.344830751419067 	 0.21816444396972656 	 0.7368283271789551 	 5.841255187988281e-05 	 0.20869970321655273 	 0.24462080001831055 	 4.982948303222656e-05 	 6.103515625e-05 	 
2025-07-30 13:54:12.504914 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=5, ) 	 253800 	 1000 	 22.714994192123413 	 0.22664499282836914 	 0.6382396221160889 	 7.605552673339844e-05 	 0.1935882568359375 	 0.21226167678833008 	 4.029273986816406e-05 	 7.081031799316406e-05 	 
2025-07-30 13:54:39.845154 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253800 	 1000 	 0.5621368885040283 	 0.2425382137298584 	 0.014539241790771484 	 0.0002357959747314453 	 0.21274185180664062 	 0.24129462242126465 	 4.863739013671875e-05 	 7.43865966796875e-05 	 
2025-07-30 13:54:41.135416 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=5, ) 	 253800 	 1000 	 22.716882944107056 	 0.2100696563720703 	 0.6382772922515869 	 8.249282836914062e-05 	 0.18914294242858887 	 0.21775245666503906 	 6.532669067382812e-05 	 7.2479248046875e-05 	 
2025-07-30 13:55:04.511405 test begin: paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253440 	 1000 	 28.327171564102173 	 0.21904873847961426 	 0.7363846302032471 	 8.20159912109375e-05 	 0.2027895450592041 	 0.2402942180633545 	 5.555152893066406e-05 	 6.914138793945312e-05 	 
2025-07-30 13:55:33.545899 test begin: paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 253440 	 1000 	 22.68740677833557 	 0.20193815231323242 	 0.6374478340148926 	 7.891654968261719e-05 	 0.18429160118103027 	 0.21289825439453125 	 4.029273986816406e-05 	 6.532669067382812e-05 	 
2025-07-30 13:55:56.868924 test begin: paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253440 	 1000 	 28.328577280044556 	 0.21463680267333984 	 0.7364540100097656 	 7.843971252441406e-05 	 0.20917963981628418 	 0.2727680206298828 	 4.839897155761719e-05 	 8.0108642578125e-05 	 
2025-07-30 13:56:25.936813 test begin: paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 253440 	 1000 	 22.689051389694214 	 0.21600866317749023 	 0.637460470199585 	 8.0108642578125e-05 	 0.18697190284729004 	 0.2173171043395996 	 4.00543212890625e-05 	 7.748603820800781e-05 	 
2025-07-30 13:56:49.286215 test begin: paddle.Tensor.rad2deg(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.298184871673584 	 0.2983858585357666 	 0.2831728458404541 	 0.2844045162200928 	 0.2982959747314453 	 0.29842257499694824 	 0.2425980567932129 	 0.22856903076171875 	 
2025-07-30 13:56:51.500270 test begin: paddle.Tensor.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2980377674102783 	 0.29842662811279297 	 0.28293776512145996 	 0.2843496799468994 	 0.29825901985168457 	 0.2983064651489258 	 0.24168992042541504 	 0.22902202606201172 	 
2025-07-30 13:56:53.734343 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 1587601, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 1587601, 4],"float64"), ) 	 25401616 	 1000 	 0.298206090927124 	 0.29842257499694824 	 0.28308534622192383 	 0.28433823585510254 	 0.29829955101013184 	 0.29836106300354004 	 0.2419595718383789 	 0.2250075340270996 	 
2025-07-30 13:56:55.950388 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2980532646179199 	 0.29839420318603516 	 0.2825751304626465 	 0.28394222259521484 	 0.29824256896972656 	 0.29847192764282227 	 0.2418806552886963 	 0.20535945892333984 	 
2025-07-30 13:56:58.138087 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 1587601],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 1587601],"float64"), ) 	 25401616 	 1000 	 0.29815196990966797 	 0.29886412620544434 	 0.2831447124481201 	 0.2839517593383789 	 0.2982959747314453 	 0.2983894348144531 	 0.24247074127197266 	 0.2298734188079834 	 
2025-07-30 13:57:00.354824 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.298062801361084 	 0.30021023750305176 	 0.28295254707336426 	 0.2826402187347412 	 0.2982621192932129 	 0.2983577251434326 	 0.24283528327941895 	 0.22886276245117188 	 
2025-07-30 13:57:02.591537 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.2980334758758545 	 0.29839253425598145 	 0.2829442024230957 	 0.28414177894592285 	 0.29824090003967285 	 0.29837799072265625 	 0.2425060272216797 	 0.22957086563110352 	 
2025-07-30 13:57:04.809322 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 6350401],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 0.2981889247894287 	 0.29844093322753906 	 0.2830624580383301 	 0.284435510635376 	 0.29826784133911133 	 0.29852294921875 	 0.24255061149597168 	 0.22999191284179688 	 
2025-07-30 13:57:07.019287 test begin: paddle.Tensor.rad2deg(x=Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.2981729507446289 	 0.2983856201171875 	 0.2829301357269287 	 0.28441286087036133 	 0.29825496673583984 	 0.2982497215270996 	 0.2430567741394043 	 0.22977733612060547 	 
2025-07-30 13:57:09.233525 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), ) 	 519045120 	 1000 	 0.05036520957946777 	 0.028974294662475586 	 3.647804260253906e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:57:20.279002 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), ) 	 519045120 	 1000 	 0.045389413833618164 	 0.028894901275634766 	 2.384185791015625e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:57:28.636742 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), ) 	 519045120 	 1000 	 0.04149127006530762 	 0.028890609741210938 	 3.123283386230469e-05 	 6.389617919921875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:57:39.254531 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), ) 	 519045120 	 1000 	 0.04126334190368652 	 0.028627395629882812 	 1.9073486328125e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:57:47.682741 test begin: paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), ) 	 508055040 	 1000 	 0.04280447959899902 	 0.02904677391052246 	 3.4809112548828125e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:57:55.728434 test begin: paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), ) 	 513146880 	 1000 	 0.04379558563232422 	 0.02906632423400879 	 3.409385681152344e-05 	 5.7697296142578125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:03.941552 test begin: paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), ) 	 513146880 	 1000 	 0.042135000228881836 	 0.028875350952148438 	 2.86102294921875e-05 	 5.626678466796875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:12.257364 test begin: paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.04215097427368164 	 0.030532360076904297 	 3.170967102050781e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:20.511300 test begin: paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.04199647903442383 	 0.030003786087036133 	 3.0040740966796875e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:28.631484 test begin: paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), ) 	 508101120 	 1000 	 0.04201149940490723 	 0.029808521270751953 	 3.218650817871094e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 13:58:38.946383 test begin: paddle.Tensor.reciprocal(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2956550121307373 	 0.29824256896972656 	 0.28676605224609375 	 0.2878873348236084 	 0.4503459930419922 	 1.040747880935669 	 0.39226841926574707 	 0.35448408126831055 	 
2025-07-30 13:58:42.685194 test begin: paddle.Tensor.reciprocal(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2956395149230957 	 0.2982759475708008 	 0.28672218322753906 	 0.287977933883667 	 0.45010876655578613 	 1.040740966796875 	 0.3919668197631836 	 0.3545668125152588 	 
2025-07-30 13:58:46.419504 test begin: paddle.Tensor.reciprocal(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29555296897888184 	 0.3070223331451416 	 0.28673601150512695 	 0.28776979446411133 	 0.45015716552734375 	 1.0406947135925293 	 0.39057207107543945 	 0.3545513153076172 	 
2025-07-30 13:58:50.165583 test begin: paddle.Tensor.reciprocal(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2956423759460449 	 0.29820704460144043 	 0.2867264747619629 	 0.28779077529907227 	 0.4501502513885498 	 1.0407280921936035 	 0.39188408851623535 	 0.3545665740966797 	 
2025-07-30 13:58:53.964493 test begin: paddle.Tensor.reciprocal(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2955765724182129 	 0.2982511520385742 	 0.2866506576538086 	 0.28768277168273926 	 0.450120210647583 	 1.0407466888427734 	 0.39168787002563477 	 0.3545668125152588 	 
2025-07-30 13:58:57.710407 test begin: paddle.Tensor.reciprocal(Tensor([4233601, 12],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([4233601, 12],"float32"), ) 	 50803212 	 1000 	 0.29561758041381836 	 0.2982163429260254 	 0.28677892684936523 	 0.28778958320617676 	 0.4501383304595947 	 1.0407211780548096 	 0.3920602798461914 	 0.3545527458190918 	 
2025-07-30 13:59:01.445093 test begin: paddle.Tensor.remainder(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), ) 	 101606412 	 1000 	 0.4508545398712158 	 0.44950032234191895 	 0.4405081272125244 	 0.43814802169799805 	 None 	 None 	 None 	 None 	 
2025-07-30 13:59:04.138095 test begin: paddle.Tensor.remainder(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), ) 	 101606416 	 1000 	 0.4508688449859619 	 0.44945836067199707 	 0.44067835807800293 	 0.4380309581756592 	 None 	 None 	 None 	 None 	 
2025-07-30 13:59:06.691224 test begin: paddle.Tensor.remainder(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), ) 	 101606424 	 1000 	 0.45085978507995605 	 0.44947195053100586 	 0.4407613277435303 	 0.43820953369140625 	 None 	 None 	 None 	 None 	 
2025-07-30 13:59:09.236842 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 1, 198451, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 1, 198451, 128],"float64"), 3, axis=1, ) 	 25401728 	 1000 	 0.897104024887085 	 0.8890273571014404 	 0.45839428901672363 	 0.8660764694213867 	 1.4847931861877441 	 0.5879011154174805 	 0.5061361789703369 	 0.4918708801269531 	 
2025-07-30 13:59:15.229038 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 1, 64, 396901],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 1, 64, 396901],"float64"), 3, axis=1, ) 	 25401664 	 1000 	 0.8983426094055176 	 0.8829286098480225 	 0.4590721130371094 	 0.8599112033843994 	 1.4854004383087158 	 0.5878119468688965 	 0.5063495635986328 	 0.48837995529174805 	 
2025-07-30 13:59:21.210795 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 3101, 64, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 3101, 64, 128],"float64"), 3, axis=1, ) 	 25403392 	 1000 	 0.6956570148468018 	 0.6377880573272705 	 0.07364344596862793 	 0.614896297454834 	 0.9173345565795898 	 0.5945179462432861 	 0.09432220458984375 	 0.4989285469055176 	 
2025-07-30 13:59:28.602277 test begin: paddle.Tensor.repeat_interleave(Tensor([3101, 1, 64, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([3101, 1, 64, 128],"float64"), 3, axis=1, ) 	 25403392 	 1000 	 0.6186885833740234 	 0.6434237957000732 	 0.31615781784057617 	 0.6148598194122314 	 0.9176716804504395 	 0.5945355892181396 	 0.3126819133758545 	 0.49540185928344727 	 
2025-07-30 13:59:33.482823 test begin: paddle.Tensor.repeat_interleave(x=Tensor([158761, 2, 4, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([158761, 2, 4, 4, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 214.2328269481659 	 0.46625256538391113 	 0.00010561943054199219 	 0.443523645401001 	 241.80218482017517 	 0.5452282428741455 	 0.00011038780212402344 	 0.43178725242614746 	 
2025-07-30 14:07:14.075912 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 158761, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 158761, 4, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 212.90954303741455 	 0.46621227264404297 	 9.1552734375e-05 	 0.443403959274292 	 241.11685132980347 	 0.5452525615692139 	 8.749961853027344e-05 	 0.43823790550231934 	 
2025-07-30 14:14:51.218003 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 158761, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 158761, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 212.37353038787842 	 0.46619224548339844 	 9.965896606445312e-05 	 0.4430880546569824 	 241.2486572265625 	 0.5452117919921875 	 8.511543273925781e-05 	 0.44235897064208984 	 
2025-07-30 14:22:27.973563 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 198451],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 198451],"float64"), repeats=2, ) 	 25401728 	 1000 	 212.1002550125122 	 0.4726903438568115 	 9.179115295410156e-05 	 0.44339466094970703 	 241.53203225135803 	 0.5452163219451904 	 0.0001087188720703125 	 0.44496798515319824 	 
2025-07-30 14:30:04.709236 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 79381, 4, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 79381, 4, 4, 5],"float64"), repeats=2, ) 	 25401920 	 1000 	 211.51670789718628 	 0.4687931537628174 	 9.72747802734375e-05 	 0.44325876235961914 	 240.39320158958435 	 0.5451695919036865 	 8.559226989746094e-05 	 0.4240758419036865 	 
2025-07-30 14:37:40.889328 test begin: paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], )
[Prof] paddle.Tensor.reshape 	 paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], ) 	 1016135680 	 1000 	 0.0055239200592041016 	 0.0039408206939697266 	 1.33514404296875e-05 	 2.288818359375e-05 	 0.04932093620300293 	 4.496663808822632 	 3.5762786865234375e-05 	 2.2976021766662598 	 
2025-07-30 14:38:21.961604 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5138845443725586 	 0.30361270904541016 	 0.4854772090911865 	 0.2879829406738281 	 0.8233871459960938 	 0.3038597106933594 	 0.4207320213317871 	 0.23170876502990723 	 
2025-07-30 14:38:24.999120 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8191275596618652 	 0.3034682273864746 	 0.4187161922454834 	 0.28610873222351074 	 0.5151898860931396 	 0.30344223976135254 	 0.4524881839752197 	 0.23083758354187012 	 
2025-07-30 14:38:27.961180 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8154118061065674 	 0.30348992347717285 	 0.4167144298553467 	 0.2866809368133545 	 0.5152301788330078 	 0.30304455757141113 	 0.45261454582214355 	 0.2306356430053711 	 
2025-07-30 14:38:30.942095 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5159621238708496 	 0.3041388988494873 	 0.4912257194519043 	 0.2886941432952881 	 0.8230719566345215 	 0.3027229309082031 	 0.4205455780029297 	 0.23071074485778809 	 
2025-07-30 14:38:33.953817 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.9482166767120361 	 0.3120849132537842 	 0.4845573902130127 	 0.2870614528656006 	 0.5180239677429199 	 0.304290771484375 	 0.45439863204956055 	 0.2324230670928955 	 
2025-07-30 14:38:40.437124 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8150885105133057 	 0.3266894817352295 	 0.41655611991882324 	 0.28651952743530273 	 0.5152575969696045 	 0.30306434631347656 	 0.4525914192199707 	 0.23143267631530762 	 
2025-07-30 14:38:43.475941 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.5168015956878662 	 0.304274320602417 	 0.4916698932647705 	 0.2889280319213867 	 0.824805736541748 	 0.3039052486419678 	 0.42144775390625 	 0.229949951171875 	 
2025-07-30 14:38:46.482861 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8308463096618652 	 0.3198091983795166 	 0.42451024055480957 	 0.28725695610046387 	 0.5141878128051758 	 0.30347371101379395 	 0.45127010345458984 	 0.22760534286499023 	 
2025-07-30 14:38:49.507624 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8180088996887207 	 0.30428385734558105 	 0.41788387298583984 	 0.28754591941833496 	 0.5167458057403564 	 0.30587100982666016 	 0.4446907043457031 	 0.23434758186340332 	 
2025-07-30 14:38:52.523219 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.5162162780761719 	 0.31007933616638184 	 0.4914078712463379 	 0.2888643741607666 	 0.8243129253387451 	 0.3038761615753174 	 0.4211597442626953 	 0.23205280303955078 	 
2025-07-30 14:38:55.513926 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8264625072479248 	 0.3180818557739258 	 0.4223017692565918 	 0.28733062744140625 	 0.5168828964233398 	 0.3062160015106201 	 0.45328307151794434 	 0.23228240013122559 	 
2025-07-30 14:38:58.562232 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8102035522460938 	 0.30963802337646484 	 0.4140021800994873 	 0.289137601852417 	 0.5141403675079346 	 0.3030514717102051 	 0.450427770614624 	 0.23077774047851562 	 
2025-07-30 14:39:04.046285 test begin: paddle.Tensor.round(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2957742214202881 	 1.528977394104004 	 0.2867252826690674 	 0.2868983745574951 	 0.13403916358947754 	 0.13430047035217285 	 0.07480669021606445 	 0.06440401077270508 	 
2025-07-30 14:39:08.975080 test begin: paddle.Tensor.round(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.295654296875 	 0.2982513904571533 	 0.2866184711456299 	 0.28647327423095703 	 0.1341722011566162 	 0.134199857711792 	 0.0789940357208252 	 0.06640362739562988 	 
2025-07-30 14:39:11.463310 test begin: paddle.Tensor.round(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.295684814453125 	 0.2979252338409424 	 0.28658246994018555 	 0.28658342361450195 	 0.13413524627685547 	 0.134138822555542 	 0.07754802703857422 	 0.06822657585144043 	 
2025-07-30 14:39:13.942553 test begin: paddle.Tensor.round(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2956671714782715 	 0.30029797554016113 	 0.28646302223205566 	 0.284778356552124 	 0.1341550350189209 	 0.13414597511291504 	 0.07886719703674316 	 0.062352895736694336 	 
2025-07-30 14:39:16.442899 test begin: paddle.Tensor.round(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.295698881149292 	 0.2979159355163574 	 0.2865889072418213 	 0.28667712211608887 	 0.13415002822875977 	 0.13416290283203125 	 0.07806849479675293 	 0.06827616691589355 	 
2025-07-30 14:39:18.919267 test begin: paddle.Tensor.rsqrt(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29581713676452637 	 0.29806065559387207 	 0.28690290451049805 	 0.28748369216918945 	 0.4502265453338623 	 1.0405664443969727 	 0.3921382427215576 	 0.3544580936431885 	 
2025-07-30 14:39:22.676524 test begin: paddle.Tensor.rsqrt(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29584336280822754 	 0.29793691635131836 	 0.28691673278808594 	 0.28742313385009766 	 0.4500081539154053 	 1.0405538082122803 	 0.39162683486938477 	 0.3544917106628418 	 
2025-07-30 14:39:26.406548 test begin: paddle.Tensor.rsqrt(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29582977294921875 	 0.297929048538208 	 0.286846399307251 	 0.2874445915222168 	 0.4500141143798828 	 1.0405387878417969 	 0.39190149307250977 	 0.35448408126831055 	 
2025-07-30 14:39:30.246627 test begin: paddle.Tensor.rsqrt(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29579806327819824 	 0.2979393005371094 	 0.2868926525115967 	 0.2876598834991455 	 0.450075626373291 	 1.0404584407806396 	 0.39169883728027344 	 0.3544776439666748 	 
2025-07-30 14:39:34.083202 test begin: paddle.Tensor.rsqrt(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2957749366760254 	 0.5201225280761719 	 0.28691577911376953 	 0.28735923767089844 	 0.45003366470336914 	 1.0406074523925781 	 0.3921382427215576 	 0.35449719429016113 	 
2025-07-30 14:39:42.170321 test begin: paddle.Tensor.scale(Tensor([100352, 1013],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([100352, 1013],"bfloat16"), 0.006378560586546936, ) 	 101656576 	 1000 	 0.2983219623565674 	 0.5925307273864746 	 0.2889442443847656 	 0.3027656078338623 	 0.5881607532501221 	 0.7498903274536133 	 0.5263681411743164 	 0.3831322193145752 	 combined
2025-07-30 14:39:47.613119 test begin: paddle.Tensor.scale(Tensor([1013, 100352],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([1013, 100352],"bfloat16"), 0.006378560586546936, ) 	 101656576 	 1000 	 0.29833459854125977 	 0.5978405475616455 	 0.2877531051635742 	 0.30284857749938965 	 0.5882294178009033 	 0.749849796295166 	 0.527338981628418 	 0.3830990791320801 	 combined
2025-07-30 14:39:53.130870 test begin: paddle.Tensor.scale(Tensor([12404, 8192],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([12404, 8192],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.2982339859008789 	 0.5923881530761719 	 0.2887990474700928 	 0.30269932746887207 	 0.588446855545044 	 0.7495214939117432 	 0.5261335372924805 	 0.38297533988952637 	 combined
2025-07-30 14:39:58.543528 test begin: paddle.Tensor.scale(Tensor([1772, 57344],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([1772, 57344],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.29820871353149414 	 0.5923731327056885 	 0.28870081901550293 	 0.3027060031890869 	 0.5884110927581787 	 0.7494914531707764 	 0.5271453857421875 	 0.38292360305786133 	 combined
2025-07-30 14:40:04.054911 test begin: paddle.Tensor.scale(Tensor([8192, 12404],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([8192, 12404],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.29822683334350586 	 0.5923027992248535 	 0.28885364532470703 	 0.3026463985443115 	 0.5885200500488281 	 0.7495517730712891 	 0.5265002250671387 	 0.38294363021850586 	 combined
2025-07-30 14:40:11.500778 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, ) 	 50805216 	 1000 	 0.09096264839172363 	 0.002254009246826172 	 3.600120544433594e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:40:14.994792 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, ) 	 50805204 	 1000 	 0.040810346603393555 	 0.002307891845703125 	 3.838539123535156e-05 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:40:15.840198 test begin: paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, ) 	 50807704 	 1000 	 0.036661386489868164 	 0.0022780895233154297 	 1.6689300537109375e-05 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 14:40:16.680333 test begin: paddle.Tensor.sigmoid(Tensor([1, 1100, 46185],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 1100, 46185],"float32"), ) 	 50803500 	 1000 	 0.2948319911956787 	 0.2984182834625244 	 0.28575825691223145 	 0.288130521774292 	 0.45000791549682617 	 0.4465916156768799 	 0.3884086608886719 	 0.37876272201538086 	 
2025-07-30 14:40:19.922286 test begin: paddle.Tensor.sigmoid(Tensor([1, 12700801, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 12700801, 4],"float32"), ) 	 50803204 	 1000 	 0.29491662979125977 	 0.2983410358428955 	 0.2857847213745117 	 0.2880420684814453 	 0.4500396251678467 	 0.446613073348999 	 0.39109349250793457 	 0.3787975311279297 	 
2025-07-30 14:40:23.126774 test begin: paddle.Tensor.sigmoid(Tensor([1, 6380, 7963],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 6380, 7963],"float32"), ) 	 50803940 	 1000 	 0.2949185371398926 	 0.2983884811401367 	 0.28586602210998535 	 0.2880692481994629 	 0.4502835273742676 	 0.44658422470092773 	 0.39215803146362305 	 0.378312349319458 	 
2025-07-30 14:40:26.260965 test begin: paddle.Tensor.sigmoid(Tensor([1, 8550, 5942],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 8550, 5942],"float32"), ) 	 50804100 	 1000 	 0.29488468170166016 	 0.29839348793029785 	 0.28576111793518066 	 0.2880251407623291 	 0.4500281810760498 	 0.4466099739074707 	 0.3913571834564209 	 0.37811923027038574 	 
2025-07-30 14:40:29.345135 test begin: paddle.Tensor.sigmoid(Tensor([11547, 1100, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([11547, 1100, 4],"float32"), ) 	 50806800 	 1000 	 0.2950117588043213 	 0.2984142303466797 	 0.2853999137878418 	 0.28803014755249023 	 0.44994592666625977 	 0.44659972190856934 	 0.39139771461486816 	 0.37631869316101074 	 
2025-07-30 14:40:32.450983 test begin: paddle.Tensor.sigmoid(Tensor([1486, 8550, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1486, 8550, 4],"float32"), ) 	 50821200 	 1000 	 0.2948777675628662 	 0.29851484298706055 	 0.2856171131134033 	 0.2882192134857178 	 0.45023298263549805 	 0.44675159454345703 	 0.3881535530090332 	 0.37753915786743164 	 
2025-07-30 14:40:37.397114 test begin: paddle.Tensor.sigmoid(Tensor([1991, 6380, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1991, 6380, 4],"float32"), ) 	 50810320 	 1000 	 0.2950124740600586 	 0.3134469985961914 	 0.2858278751373291 	 0.287872314453125 	 0.45038747787475586 	 0.44667577743530273 	 0.39163756370544434 	 0.3787527084350586 	 
2025-07-30 14:40:40.909286 test begin: paddle.Tensor.sign(Tensor([1016065, 5, 5],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1016065, 5, 5],"float64"), ) 	 25401625 	 1000 	 0.30860424041748047 	 0.2984161376953125 	 0.29930830001831055 	 0.2880253791809082 	 0.2981142997741699 	 0.13463592529296875 	 0.2422776222229004 	 0.06474614143371582 	 
2025-07-30 14:40:42.973998 test begin: paddle.Tensor.sign(Tensor([1124, 45199],"float32"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1124, 45199],"float32"), ) 	 50803676 	 1000 	 0.3457765579223633 	 0.297896146774292 	 0.3374025821685791 	 0.2865312099456787 	 0.29588937759399414 	 0.1343698501586914 	 0.23969006538391113 	 0.0682058334350586 	 
2025-07-30 14:40:45.678778 test begin: paddle.Tensor.sign(Tensor([12700801, 2],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.30861783027648926 	 0.2983534336090088 	 0.30016350746154785 	 0.2879824638366699 	 0.29810309410095215 	 0.1345686912536621 	 0.2403249740600586 	 0.06816744804382324 	 
2025-07-30 14:40:47.735409 test begin: paddle.Tensor.sign(Tensor([1587601, 32],"float32"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 0.34575939178466797 	 0.30902671813964844 	 0.33728623390197754 	 0.2873992919921875 	 0.29587340354919434 	 0.13435697555541992 	 0.23943328857421875 	 0.06785082817077637 	 
2025-07-30 14:40:50.420539 test begin: paddle.Tensor.sign(Tensor([50000, 102, 5],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 102, 5],"float64"), ) 	 25500000 	 1000 	 0.30983853340148926 	 0.2995431423187256 	 0.3013434410095215 	 0.28875255584716797 	 0.29947972297668457 	 0.13509321212768555 	 0.2425832748413086 	 0.06792140007019043 	 
2025-07-30 14:40:52.485117 test begin: paddle.Tensor.sign(Tensor([50000, 5, 102],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 5, 102],"float64"), ) 	 25500000 	 1000 	 0.30986547470092773 	 0.29956483840942383 	 0.30149316787719727 	 0.288834810256958 	 0.2994353771209717 	 0.13580965995788574 	 0.2439577579498291 	 0.06835484504699707 	 
2025-07-30 14:40:54.589083 test begin: paddle.Tensor.sign(Tensor([50000, 509],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 509],"float64"), ) 	 25450000 	 1000 	 0.3093292713165283 	 0.2990384101867676 	 0.30081796646118164 	 0.2882859706878662 	 0.2987406253814697 	 0.1348278522491455 	 0.24280571937561035 	 0.06760978698730469 	 
2025-07-30 14:40:56.652803 test begin: paddle.Tensor.signbit(Tensor([12, 10584, 2],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 10584, 2],"float64"), ) 	 254016 	 1000 	 10.243267297744751 	 0.009867191314697266 	 4.553794860839844e-05 	 2.8371810913085938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:41:07.360865 test begin: paddle.Tensor.signbit(Tensor([12, 20, 1058],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 1058],"float64"), ) 	 253920 	 1000 	 10.123059034347534 	 0.009886503219604492 	 5.316734313964844e-05 	 3.0279159545898438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:41:18.175020 test begin: paddle.Tensor.signbit(Tensor([12, 20, 2116],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 2116],"float32"), ) 	 507840 	 1000 	 22.141063928604126 	 0.009767532348632812 	 4.5299530029296875e-05 	 5.888938903808594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:41:40.956249 test begin: paddle.Tensor.signbit(Tensor([12, 20, 4233],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 4233],"int16"), ) 	 1015920 	 1000 	 40.50756502151489 	 0.010182380676269531 	 4.8160552978515625e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:42:21.568249 test begin: paddle.Tensor.signbit(Tensor([12, 21168, 2],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 21168, 2],"float32"), ) 	 508032 	 1000 	 22.04559302330017 	 0.00972127914428711 	 4.673004150390625e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:42:43.688469 test begin: paddle.Tensor.signbit(Tensor([12, 42336, 2],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 42336, 2],"int16"), ) 	 1016064 	 1000 	 40.501590967178345 	 0.010638952255249023 	 4.458427429199219e-05 	 4.100799560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:43:24.291688 test begin: paddle.Tensor.signbit(Tensor([12700, 20, 2],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12700, 20, 2],"float32"), ) 	 508000 	 1000 	 22.10971212387085 	 0.00955510139465332 	 5.173683166503906e-05 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:43:46.484564 test begin: paddle.Tensor.signbit(Tensor([25401, 20, 2],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([25401, 20, 2],"int16"), ) 	 1016040 	 1000 	 40.365041732788086 	 0.01102757453918457 	 4.4345855712890625e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:44:26.952137 test begin: paddle.Tensor.signbit(Tensor([6350, 20, 2],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([6350, 20, 2],"float64"), ) 	 254000 	 1000 	 10.135013818740845 	 0.016106128692626953 	 5.030632019042969e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:44:37.875022 test begin: paddle.Tensor.sin(Tensor([131072, 388],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([131072, 388],"float32"), ) 	 50855936 	 1000 	 0.29578542709350586 	 0.3035283088684082 	 0.28612637519836426 	 0.28786730766296387 	 0.4507904052734375 	 0.7446775436401367 	 0.39232802391052246 	 0.3803873062133789 	 
2025-07-30 14:44:43.817712 test begin: paddle.Tensor.sin(Tensor([3175201, 16],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([3175201, 16],"float32"), ) 	 50803216 	 1000 	 0.2956202030181885 	 1.297982931137085 	 0.2859642505645752 	 0.2865281105041504 	 0.4504728317260742 	 0.7437036037445068 	 0.3920249938964844 	 0.3799872398376465 	 
2025-07-30 14:44:48.767791 test begin: paddle.Tensor.sin(Tensor([32768, 1551],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.29559779167175293 	 0.29831409454345703 	 0.2858917713165283 	 0.28763318061828613 	 0.45070862770080566 	 0.7440521717071533 	 0.3918750286102295 	 0.38013410568237305 	 
2025-07-30 14:44:52.224407 test begin: paddle.Tensor.sin(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29546117782592773 	 0.29820966720581055 	 0.28579235076904297 	 0.28772735595703125 	 0.4502544403076172 	 0.7436788082122803 	 0.39103078842163086 	 0.37990283966064453 	 
2025-07-30 14:44:55.669703 test begin: paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.007528066635131836 	 0.013232946395874023 	 8.344650268554688e-06 	 2.5033950805664062e-05 	 4.843218564987183 	 4.628753900527954 	 2.474635124206543 	 2.3654541969299316 	 combined
2025-07-30 14:45:15.175949 test begin: paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.007206439971923828 	 0.013153314590454102 	 1.3113021850585938e-05 	 2.9087066650390625e-05 	 1.511364459991455 	 1.3172311782836914 	 0.7722189426422119 	 0.6730291843414307 	 combined
2025-07-30 14:45:26.164442 test begin: paddle.Tensor.slice_scatter(Tensor([4233601, 6],"float64"), Tensor([4233601, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([4233601, 6],"float64"), Tensor([4233601, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 38102409 	 1000 	 0.3767282962799072 	 0.6890692710876465 	 0.36139369010925293 	 0.23437047004699707 	 1.070819616317749 	 0.7657194137573242 	 0.18231201171875 	 0.1955864429473877 	 
2025-07-30 14:45:30.430752 test begin: paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 254016320 	 1000 	 0.014780998229980469 	 3.0680606365203857 	 1.1444091796875e-05 	 1.0430183410644531 	 3.0720725059509277 	 3.069190502166748 	 0.5222225189208984 	 0.7826032638549805 	 
2025-07-30 14:45:50.681536 test begin: paddle.Tensor.slice_scatter(Tensor([8467201, 6],"float64"), Tensor([8467201, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([8467201, 6],"float64"), Tensor([8467201, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 76204809 	 1000 	 0.7470500469207764 	 1.3630073070526123 	 0.7316133975982666 	 0.4641146659851074 	 2.1100707054138184 	 1.5048437118530273 	 0.3592238426208496 	 0.384458065032959 	 
2025-07-30 14:45:59.005433 test begin: paddle.Tensor.sqrt(Tensor([276, 80, 48, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([276, 80, 48, 48],"float32"), ) 	 50872320 	 1000 	 0.29549145698547363 	 0.29930734634399414 	 0.2865753173828125 	 0.28876566886901855 	 0.4515514373779297 	 0.7482962608337402 	 0.3893461227416992 	 0.38228774070739746 	 
2025-07-30 14:46:02.611477 test begin: paddle.Tensor.sqrt(Tensor([329, 80, 44, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([329, 80, 44, 44],"float32"), ) 	 50955520 	 1000 	 0.2955818176269531 	 0.29982781410217285 	 0.2865145206451416 	 0.28929972648620605 	 0.45227742195129395 	 0.7494611740112305 	 0.39381861686706543 	 0.3829052448272705 	 
2025-07-30 14:46:06.121059 test begin: paddle.Tensor.sqrt(Tensor([397, 80, 40, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([397, 80, 40, 40],"float32"), ) 	 50816000 	 1000 	 0.2947571277618408 	 0.29906129837036133 	 0.285780668258667 	 0.28879523277282715 	 0.45104265213012695 	 0.7475066184997559 	 0.39272427558898926 	 0.381885290145874 	 
2025-07-30 14:46:09.553358 test begin: paddle.Tensor.sqrt(Tensor([64, 345, 48, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 345, 48, 48],"float32"), ) 	 50872320 	 1000 	 0.29547786712646484 	 0.3015260696411133 	 0.2866175174713135 	 0.28804826736450195 	 0.45142149925231934 	 0.7483766078948975 	 0.39251136779785156 	 0.38233375549316406 	 
2025-07-30 14:46:13.020351 test begin: paddle.Tensor.sqrt(Tensor([64, 411, 44, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 411, 44, 44],"float32"), ) 	 50924544 	 1000 	 0.29538440704345703 	 0.2996988296508789 	 0.2863805294036865 	 0.28896474838256836 	 0.4519917964935303 	 0.7490124702453613 	 0.39013242721557617 	 0.382723331451416 	 
2025-07-30 14:46:16.450373 test begin: paddle.Tensor.sqrt(Tensor([64, 497, 40, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 497, 40, 40],"float32"), ) 	 50892800 	 1000 	 0.2955160140991211 	 0.2995574474334717 	 0.2866172790527344 	 0.28901171684265137 	 0.4515860080718994 	 0.7485232353210449 	 0.39310312271118164 	 0.38242530822753906 	 
2025-07-30 14:46:19.880153 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 207, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 207, 48],"float32"), ) 	 50872320 	 1000 	 0.29543185234069824 	 0.29935145378112793 	 0.28647565841674805 	 0.288665771484375 	 0.45145320892333984 	 0.748267650604248 	 0.3931403160095215 	 0.38225436210632324 	 
2025-07-30 14:46:23.432658 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 226, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 226, 44],"float32"), ) 	 50913280 	 1000 	 0.29555320739746094 	 0.29961323738098145 	 0.28659677505493164 	 0.28898000717163086 	 0.45178723335266113 	 0.7489173412322998 	 0.3936166763305664 	 0.3826560974121094 	 
2025-07-30 14:46:26.877809 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 249, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 249, 40],"float32"), ) 	 50995200 	 1000 	 0.29594850540161133 	 0.3000917434692383 	 0.28687405586242676 	 0.28937602043151855 	 0.4525313377380371 	 0.7500903606414795 	 0.3937194347381592 	 0.38324928283691406 	 
2025-07-30 14:46:30.329942 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 40, 249],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 40, 249],"float32"), ) 	 50995200 	 1000 	 0.29598045349121094 	 0.3001079559326172 	 0.2866861820220947 	 0.28949880599975586 	 0.45248913764953613 	 0.7500503063201904 	 0.3911325931549072 	 0.3831784725189209 	 
2025-07-30 14:46:33.785615 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 44, 226],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 44, 226],"float32"), ) 	 50913280 	 1000 	 0.29558897018432617 	 0.31961512565612793 	 0.28549909591674805 	 0.28885316848754883 	 0.45183539390563965 	 0.7489569187164307 	 0.39275240898132324 	 0.3825993537902832 	 
2025-07-30 14:46:40.008349 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 48, 207],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 48, 207],"float32"), ) 	 50872320 	 1000 	 0.29546356201171875 	 0.299379825592041 	 0.2863960266113281 	 0.28878211975097656 	 0.45142459869384766 	 0.7482569217681885 	 0.3897402286529541 	 0.3823368549346924 	 
2025-07-30 14:46:43.441882 test begin: paddle.Tensor.square(Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.2958712577819824 	 0.29788851737976074 	 0.2868471145629883 	 0.28673863410949707 	 0.4503324031829834 	 1.0558717250823975 	 0.39298486709594727 	 0.2699258327484131 	 
2025-07-30 14:46:47.192905 test begin: paddle.Tensor.square(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2957804203033447 	 0.297900915145874 	 0.2852928638458252 	 0.28669309616088867 	 0.44991588592529297 	 1.055873155593872 	 0.3921387195587158 	 0.26993298530578613 	 
2025-07-30 14:46:51.040269 test begin: paddle.Tensor.square(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.29587316513061523 	 0.2978663444519043 	 0.2868037223815918 	 0.2867441177368164 	 0.4502103328704834 	 1.0557777881622314 	 0.3924591541290283 	 0.26993489265441895 	 
2025-07-30 14:46:56.984660 test begin: paddle.Tensor.square(Tensor([8, 6350401],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([8, 6350401],"float32"), ) 	 50803208 	 1000 	 0.29587841033935547 	 0.31168651580810547 	 0.2867093086242676 	 0.28658390045166016 	 0.4503176212310791 	 1.0559124946594238 	 0.39281773567199707 	 0.26999807357788086 	 
2025-07-30 14:47:01.222133 test begin: paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.004525184631347656 	 0.004068613052368164 	 1.1682510375976562e-05 	 1.8358230590820312e-05 	 0.04948568344116211 	 0.0558927059173584 	 5.340576171875e-05 	 8.368492126464844e-05 	 
2025-07-30 14:47:26.612298 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.0043795108795166016 	 0.004006147384643555 	 1.1444091796875e-05 	 2.0742416381835938e-05 	 0.04572129249572754 	 0.0554041862487793 	 7.200241088867188e-05 	 7.62939453125e-05 	 
2025-07-30 14:47:43.346273 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, ) 	 1179648000 	 1000 	 0.004535675048828125 	 0.00402522087097168 	 9.298324584960938e-06 	 2.0742416381835938e-05 	 0.045773983001708984 	 0.053420305252075195 	 3.504753112792969e-05 	 4.38690185546875e-05 	 
2025-07-30 14:48:22.133143 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004356861114501953 	 0.012768983840942383 	 9.5367431640625e-06 	 3.218650817871094e-05 	 0.045633554458618164 	 0.05359220504760742 	 3.7670135498046875e-05 	 5.984306335449219e-05 	 
2025-07-30 14:48:40.043666 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.004502773284912109 	 0.004137516021728516 	 1.0967254638671875e-05 	 1.8596649169921875e-05 	 0.045882225036621094 	 0.06256365776062012 	 4.00543212890625e-05 	 7.271766662597656e-05 	 
2025-07-30 14:48:56.851900 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, ) 	 508044800 	 1000 	 0.00475001335144043 	 0.004149198532104492 	 2.0742416381835938e-05 	 1.8358230590820312e-05 	 0.04597759246826172 	 0.05999135971069336 	 2.8133392333984375e-05 	 7.43865966796875e-05 	 
2025-07-30 14:49:13.296998 test begin: paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, ) 	 652800000 	 1000 	 0.0043985843658447266 	 0.004047393798828125 	 1.239776611328125e-05 	 1.7642974853515625e-05 	 0.0451962947845459 	 0.05515480041503906 	 3.457069396972656e-05 	 7.891654968261719e-05 	 
2025-07-30 14:49:34.778835 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, ) 	 508036000 	 1000 	 0.004640102386474609 	 0.004132986068725586 	 1.6689300537109375e-05 	 1.7881393432617188e-05 	 0.04601097106933594 	 0.06097912788391113 	 2.5987625122070312e-05 	 6.556510925292969e-05 	 
2025-07-30 14:49:51.258260 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, ) 	 526848000 	 1000 	 0.009800910949707031 	 0.004098176956176758 	 1.3589859008789062e-05 	 1.8596649169921875e-05 	 0.045995473861694336 	 0.05720090866088867 	 4.458427429199219e-05 	 7.104873657226562e-05 	 
2025-07-30 14:50:08.363306 test begin: paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, ) 	 602112000 	 1000 	 0.0044133663177490234 	 0.004053592681884766 	 1.1682510375976562e-05 	 2.09808349609375e-05 	 0.04530501365661621 	 0.05419778823852539 	 3.5762786865234375e-05 	 7.843971252441406e-05 	 
2025-07-30 14:50:27.533123 test begin: paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.004485368728637695 	 0.004183769226074219 	 1.2874603271484375e-05 	 1.7642974853515625e-05 	 0.04577279090881348 	 0.05739736557006836 	 2.7179718017578125e-05 	 5.7697296142578125e-05 	 
2025-07-30 14:50:44.457516 test begin: paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, ) 	 508784640 	 1000 	 0.0045795440673828125 	 0.004279613494873047 	 3.0040740966796875e-05 	 3.743171691894531e-05 	 0.045899391174316406 	 0.05818819999694824 	 3.719329833984375e-05 	 7.05718994140625e-05 	 
2025-07-30 14:51:01.052276 test begin: paddle.Tensor.std(Tensor([1024, 1024, 25],"float64"), )
W0730 14:51:01.543161 34070 dygraph_functions.cc:88394] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 1024, 25],"float64"), ) 	 26214400 	 1000 	 1.3534536361694336 	 0.18392086029052734 	 2.09808349609375e-05 	 0.093994140625 	 1.5309817790985107 	 0.7914283275604248 	 0.19593310356140137 	 0.09017562866210938 	 
2025-07-30 14:51:05.519940 test begin: paddle.Tensor.std(Tensor([1024, 1024, 49],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 1024, 49],"float32"), ) 	 51380224 	 1000 	 1.1097767353057861 	 0.16805768013000488 	 1.8596649169921875e-05 	 0.08582949638366699 	 1.3557658195495605 	 0.783963680267334 	 0.17334794998168945 	 0.08929586410522461 	 
2025-07-30 14:51:11.733759 test begin: paddle.Tensor.std(Tensor([1024, 3101, 8],"float64"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 3101, 8],"float64"), ) 	 25403392 	 1000 	 1.3200719356536865 	 0.1788041591644287 	 1.9788742065429688e-05 	 0.09137821197509766 	 1.4839105606079102 	 0.7692501544952393 	 0.18991565704345703 	 0.08764338493347168 	 
2025-07-30 14:51:16.049233 test begin: paddle.Tensor.std(Tensor([1024, 6202, 8],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 6202, 8],"float32"), ) 	 50806784 	 1000 	 1.1015441417694092 	 0.16633248329162598 	 2.0503997802734375e-05 	 0.08498406410217285 	 1.3398544788360596 	 0.7753932476043701 	 0.17146992683410645 	 0.08835983276367188 	 
2025-07-30 14:51:22.118864 test begin: paddle.Tensor.std(Tensor([1444, 35183],"float32"), axis=1, )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1444, 35183],"float32"), axis=1, ) 	 50804252 	 1000 	 1.1361026763916016 	 0.17646193504333496 	 3.504753112792969e-05 	 0.16042613983154297 	 1.3618366718292236 	 0.7823059558868408 	 0.17425012588500977 	 0.10009479522705078 	 
2025-07-30 14:51:26.421434 test begin: paddle.Tensor.std(Tensor([3101, 1024, 8],"float64"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([3101, 1024, 8],"float64"), ) 	 25403392 	 1000 	 1.3102648258209229 	 0.1790478229522705 	 2.0742416381835938e-05 	 0.09145331382751465 	 1.483722448348999 	 0.7677531242370605 	 0.18983960151672363 	 0.08747220039367676 	 
2025-07-30 14:51:30.690972 test begin: paddle.Tensor.std(Tensor([49613, 1024],"float32"), axis=1, )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([49613, 1024],"float32"), axis=1, ) 	 50803712 	 1000 	 1.0977210998535156 	 0.16800618171691895 	 3.2901763916015625e-05 	 0.15202116966247559 	 1.3485708236694336 	 0.7807667255401611 	 0.19686174392700195 	 0.09991145133972168 	 
2025-07-30 14:51:34.936124 test begin: paddle.Tensor.std(Tensor([6202, 1024, 8],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([6202, 1024, 8],"float32"), ) 	 50806784 	 1000 	 1.1038639545440674 	 0.16640472412109375 	 2.0265579223632812e-05 	 0.08500480651855469 	 1.3410580158233643 	 0.775423526763916 	 0.171464204788208 	 0.08836054801940918 	 
2025-07-30 14:51:40.873918 test begin: paddle.Tensor.subtract(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.subtract 	 paddle.Tensor.subtract(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.4499785900115967 	 0.45169615745544434 	 0.4397850036621094 	 0.434894323348999 	 0.4763500690460205 	 0.29784059524536133 	 0.4128873348236084 	 0.2265329360961914 	 
2025-07-30 14:51:45.104913 test begin: paddle.Tensor.sum(Tensor([106496, 478],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([106496, 478],"float32"), axis=-1, ) 	 50905088 	 1000 	 0.1500849723815918 	 0.15516257286071777 	 0.13719987869262695 	 0.1402873992919922 	 0.13835835456848145 	 0.058371543884277344 	 0.07677507400512695 	 6.866455078125e-05 	 
2025-07-30 14:51:46.480306 test begin: paddle.Tensor.sum(Tensor([108544, 469],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([108544, 469],"float32"), axis=-1, ) 	 50907136 	 1000 	 0.1501152515411377 	 0.15494084358215332 	 0.13771510124206543 	 0.14023303985595703 	 0.137955904006958 	 0.05874347686767578 	 0.07593417167663574 	 3.24249267578125e-05 	 
2025-07-30 14:51:47.856345 test begin: paddle.Tensor.sum(Tensor([111616, 456],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([111616, 456],"float32"), axis=-1, ) 	 50896896 	 1000 	 0.1503913402557373 	 0.15278339385986328 	 0.13802814483642578 	 0.13817334175109863 	 0.13843059539794922 	 0.05783510208129883 	 0.07779884338378906 	 3.123283386230469e-05 	 
2025-07-30 14:51:49.232326 test begin: paddle.Tensor.sum(Tensor([14176, 3584],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([14176, 3584],"float32"), axis=-1, ) 	 50806784 	 1000 	 0.1461927890777588 	 0.15529608726501465 	 0.13395214080810547 	 0.14075779914855957 	 0.13721442222595215 	 0.05796098709106445 	 0.07715034484863281 	 6.437301635742188e-05 	 
2025-07-30 14:51:50.573057 test begin: paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, ) 	 50931328 	 1000 	 0.7758510112762451 	 0.4725642204284668 	 0.2642958164215088 	 0.45479726791381836 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:03.203366 test begin: paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, ) 	 50803456 	 1000 	 0.3029813766479492 	 0.017267227172851562 	 0.1033010482788086 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:04.814992 test begin: paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, ) 	 101606656 	 1000 	 1.4039092063903809 	 0.7368435859680176 	 0.47839927673339844 	 0.7189457416534424 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:13.953587 test begin: paddle.Tensor.take_along_axis(Tensor([50804, 1000],"float32"), indices=Tensor([50804, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([50804, 1000],"float32"), indices=Tensor([50804, 1],"int32"), axis=-1, ) 	 50854804 	 1000 	 0.30825042724609375 	 0.017330169677734375 	 0.10507535934448242 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:15.570831 test begin: paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, ) 	 50883280 	 1000 	 0.7637939453125 	 0.4718601703643799 	 0.2601461410522461 	 0.45267677307128906 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:28.510215 test begin: paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, ) 	 50803360 	 1000 	 0.30286240577697754 	 0.017302751541137695 	 0.10323810577392578 	 4.744529724121094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:30.144430 test begin: paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, ) 	 101606560 	 1000 	 1.4062778949737549 	 0.7488555908203125 	 0.47919392585754395 	 0.7265715599060059 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 14:52:40.598124 test begin: paddle.Tensor.tanh(Tensor([1, 16934401, 3],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2954285144805908 	 0.29825663566589355 	 0.28630614280700684 	 0.28789234161376953 	 0.449676513671875 	 0.44652438163757324 	 0.3915894031524658 	 0.37859439849853516 	 
2025-07-30 14:52:43.799467 test begin: paddle.Tensor.tanh(Tensor([1, 2, 12700801],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.299297571182251 	 0.30045509338378906 	 0.2905309200286865 	 0.2903127670288086 	 0.4479804039001465 	 0.4444441795349121 	 0.39023447036743164 	 0.37704896926879883 	 
2025-07-30 14:52:46.421208 test begin: paddle.Tensor.tanh(Tensor([1, 2, 25401601],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29538488388061523 	 0.2980978488922119 	 0.28637027740478516 	 0.28774404525756836 	 0.449782133102417 	 0.44660067558288574 	 0.39166951179504395 	 0.37511777877807617 	 
2025-07-30 14:52:49.555231 test begin: paddle.Tensor.tanh(Tensor([1, 8467201, 3],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.299304723739624 	 0.3002896308898926 	 0.2905097007751465 	 0.28990745544433594 	 0.44799017906188965 	 0.4444735050201416 	 0.3900599479675293 	 0.345247745513916 	 
2025-07-30 14:52:52.112046 test begin: paddle.Tensor.tanh(Tensor([2, 12700801],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.2993159294128418 	 0.32002949714660645 	 0.29047417640686035 	 0.28980088233947754 	 0.4481644630432129 	 0.4444398880004883 	 0.36811113357543945 	 0.37517523765563965 	 
2025-07-30 14:52:54.721199 test begin: paddle.Tensor.tanh(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.2993292808532715 	 0.30033159255981445 	 0.2904646396636963 	 0.2898571491241455 	 0.44808220863342285 	 0.4445168972015381 	 0.3900444507598877 	 0.37621235847473145 	 
2025-07-30 14:52:57.275058 test begin: paddle.Tensor.tanh(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.2993466854095459 	 0.30038905143737793 	 0.2903106212615967 	 0.29013633728027344 	 0.4480907917022705 	 0.4444727897644043 	 0.39041614532470703 	 0.3761780261993408 	 
2025-07-30 14:52:59.830886 test begin: paddle.Tensor.tanh(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.29540514945983887 	 0.2981564998626709 	 0.28635573387145996 	 0.2877678871154785 	 0.4497382640838623 	 0.4465460777282715 	 0.3917996883392334 	 0.3792088031768799 	 
2025-07-30 14:53:02.982847 test begin: paddle.Tensor.tile(Tensor([198451, 1, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([198451, 1, 256],"float32"), tuple(1,1,1,), ) 	 50803456 	 1000 	 0.2963244915008545 	 0.3133378028869629 	 0.2848091125488281 	 0.15996217727661133 	 0.31485486030578613 	 0.05379056930541992 	 0.1608436107635498 	 5.745887756347656e-05 	 
2025-07-30 14:53:05.622781 test begin: paddle.Tensor.tile(Tensor([36858, 1, 1379],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([36858, 1, 1379],"float32"), tuple(1,1,1,), ) 	 50827182 	 1000 	 0.29638671875 	 0.32590484619140625 	 0.28502893447875977 	 0.16010570526123047 	 0.3167719841003418 	 0.053389787673950195 	 0.16184115409851074 	 5.245208740234375e-05 	 
2025-07-30 14:53:08.275888 test begin: paddle.Tensor.tile(Tensor([36858, 6, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([36858, 6, 256],"float32"), tuple(1,1,1,), ) 	 56613888 	 1000 	 0.3294084072113037 	 0.34519004821777344 	 0.3179969787597656 	 0.3254709243774414 	 0.34555983543395996 	 0.05452394485473633 	 0.2809934616088867 	 6.341934204101562e-05 	 
2025-07-30 14:53:11.183927 test begin: paddle.Tensor.tile(Tensor([38402, 1, 1323],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([38402, 1, 1323],"float32"), tuple(1,1,1,), ) 	 50805846 	 1000 	 0.2958984375 	 0.31303930282592773 	 0.28452444076538086 	 0.15986967086791992 	 0.3077569007873535 	 0.05287933349609375 	 0.15722274780273438 	 4.363059997558594e-05 	 
2025-07-30 14:53:13.885239 test begin: paddle.Tensor.tile(Tensor([38402, 6, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([38402, 6, 256],"float32"), tuple(1,1,1,), ) 	 58985472 	 1000 	 0.3431277275085449 	 0.359269380569458 	 0.3316230773925781 	 0.3393533229827881 	 0.3596334457397461 	 0.05563521385192871 	 0.29786229133605957 	 7.152557373046875e-05 	 
2025-07-30 14:53:16.934414 test begin: paddle.Tensor.tolist(Tensor([11, 16, 32, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 16, 32, 43],"int64"), ) 	 242176 	 1000 	 14.02794623374939 	 17.259440898895264 	 9.369850158691406e-05 	 0.00014495849609375 	 None 	 None 	 None 	 None 	 
2025-07-30 14:53:48.261476 test begin: paddle.Tensor.tolist(Tensor([11, 25, 21, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 25, 21, 43],"int64"), ) 	 248325 	 1000 	 14.280915021896362 	 17.808587789535522 	 9.393692016601562e-05 	 0.0001423358917236328 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:20.385659 test begin: paddle.Tensor.tolist(Tensor([11, 25, 32, 28],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 25, 32, 28],"int64"), ) 	 246400 	 1000 	 15.239287614822388 	 21.489701986312866 	 8.96453857421875e-05 	 0.00014448165893554688 	 None 	 None 	 None 	 None 	 
2025-07-30 14:54:57.148619 test begin: paddle.Tensor.tolist(Tensor([7, 25, 32, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([7, 25, 32, 43],"int64"), ) 	 240800 	 1000 	 14.011974334716797 	 17.424171447753906 	 9.465217590332031e-05 	 0.00013637542724609375 	 None 	 None 	 None 	 None 	 
2025-07-30 14:55:28.615756 test begin: paddle.Tensor.topk(Tensor([1, 50803201],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1, 50803201],"float32"), 5, 1, True, True, ) 	 50803201 	 1000 	 178.11505889892578 	 5.989205360412598 	 178.10449624061584 	 0.3425915241241455 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:59:04.285465 test begin: paddle.Tensor.topk(Tensor([1024, 1034, 48],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1024, 1034, 48],"float32"), 2, axis=-1, ) 	 50823168 	 1000 	 2.6640121936798096 	 11.163953065872192 	 2.6530189514160156 	 5.702786922454834 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:59:23.554778 test begin: paddle.Tensor.topk(Tensor([1024, 8, 6202],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1024, 8, 6202],"float32"), 2, axis=-1, ) 	 50806784 	 1000 	 0.3819899559020996 	 1.5429174900054932 	 0.37132859230041504 	 0.08922672271728516 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:59:30.787521 test begin: paddle.Tensor.topk(Tensor([128, 396901],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([128, 396901],"float32"), 5, 1, True, True, ) 	 50803328 	 1000 	 1.4667901992797852 	 1.4846851825714111 	 1.45640230178833 	 0.08441352844238281 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:59:40.175171 test begin: paddle.Tensor.topk(Tensor([132301, 8, 48],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([132301, 8, 48],"float32"), 2, axis=-1, ) 	 50803584 	 1000 	 2.6612253189086914 	 11.15537977218628 	 2.6505792140960693 	 5.700945138931274 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 14:59:59.426720 test begin: paddle.Tensor.topk(Tensor([50804, 1000],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([50804, 1000],"float32"), 5, 1, True, True, ) 	 50804000 	 1000 	 0.6507627964019775 	 2.408686637878418 	 0.640369176864624 	 0.13707709312438965 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:00:08.508107 test begin: paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], ) 	 1017036800 	 1000 	 0.0033974647521972656 	 0.0043828487396240234 	 9.298324584960938e-06 	 2.002716064453125e-05 	 0.0564579963684082 	 4.500990629196167 	 4.6253204345703125e-05 	 2.2988126277923584 	 
2025-07-30 15:00:47.745068 test begin: paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], ) 	 1017057280 	 1000 	 0.0034623146057128906 	 0.004456758499145508 	 1.0728836059570312e-05 	 1.9550323486328125e-05 	 0.0476069450378418 	 4.5021374225616455 	 1.9311904907226562e-05 	 2.2997686862945557 	 
2025-07-30 15:01:25.884291 test begin: paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], ) 	 1016821760 	 1000 	 0.0034296512603759766 	 0.004438638687133789 	 8.106231689453125e-06 	 1.9311904907226562e-05 	 0.0480654239654541 	 4.501733303070068 	 4.4345855712890625e-05 	 2.301079511642456 	 
2025-07-30 15:02:03.375772 test begin: paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], ) 	 1016135680 	 1000 	 0.0034487247467041016 	 0.0049591064453125 	 1.0013580322265625e-05 	 7.128715515136719e-05 	 0.04818534851074219 	 4.498365640640259 	 6.103515625e-05 	 2.29781436920166 	 
2025-07-30 15:02:43.632284 test begin: paddle.Tensor.tril(Tensor([1, 2, 25401601],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([1, 2, 25401601],"float32"), -1, ) 	 50803202 	 1000 	 0.29953455924987793 	 0.26804685592651367 	 0.2911040782928467 	 0.25545811653137207 	 0.29961681365966797 	 0.2667686939239502 	 0.24554753303527832 	 0.20065546035766602 	 
2025-07-30 15:02:46.555544 test begin: paddle.Tensor.tril(Tensor([1, 25401601, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([1, 25401601, 2],"float32"), -1, ) 	 50803202 	 1000 	 0.4204673767089844 	 0.3217649459838867 	 0.4120805263519287 	 0.31082606315612793 	 0.41907191276550293 	 0.3215329647064209 	 0.3649415969848633 	 0.25495457649230957 	 
2025-07-30 15:02:49.811159 test begin: paddle.Tensor.tril(Tensor([12700801, 2, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([12700801, 2, 2],"float32"), -1, ) 	 50803204 	 1000 	 0.421252965927124 	 0.32437777519226074 	 0.4128270149230957 	 0.313122034072876 	 0.4198727607727051 	 0.32431626319885254 	 0.3663811683654785 	 0.25785255432128906 	 
2025-07-30 15:02:52.979017 test begin: paddle.Tensor.tril(Tensor([2, 12700801, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 12700801, 2],"float32"), -1, ) 	 50803204 	 1000 	 0.42051124572753906 	 0.3217487335205078 	 0.4122040271759033 	 0.3108251094818115 	 0.4190669059753418 	 0.3217320442199707 	 0.3649580478668213 	 0.2558155059814453 	 
2025-07-30 15:02:56.147135 test begin: paddle.Tensor.tril(Tensor([2, 2, 12700801],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 2, 12700801],"float32"), -1, ) 	 50803204 	 1000 	 0.2995288372039795 	 0.26700329780578613 	 0.2911503314971924 	 0.25612568855285645 	 0.2995903491973877 	 0.26693081855773926 	 0.24594712257385254 	 0.20009636878967285 	 
2025-07-30 15:02:59.149530 test begin: paddle.Tensor.tril(Tensor([2, 25401601],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 25401601],"float32"), -1, ) 	 50803202 	 1000 	 0.2994883060455322 	 0.18296551704406738 	 0.29082608222961426 	 0.17211246490478516 	 0.30005717277526855 	 0.1828770637512207 	 0.24570441246032715 	 0.11473250389099121 	 
2025-07-30 15:03:01.775312 test begin: paddle.Tensor.tril(Tensor([25401601, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([25401601, 2],"float32"), -1, ) 	 50803202 	 1000 	 0.4208829402923584 	 0.30663323402404785 	 0.4123985767364502 	 0.29520487785339355 	 0.41934633255004883 	 0.3063991069793701 	 0.365586519241333 	 0.24136614799499512 	 
2025-07-30 15:03:04.907378 test begin: paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), ) 	 508032280 	 1000 	 0.00863957405090332 	 3.169182538986206 	 2.4080276489257812e-05 	 2.9111862182617188 	 0.05350923538208008 	 1.3131210803985596 	 3.361701965332031e-05 	 1.2448110580444336 	 
2025-07-30 15:03:29.318779 test begin: paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), ) 	 508032160 	 1000 	 0.6794695854187012 	 2.925119161605835 	 4.863739013671875e-05 	 2.913964033126831 	 0.05378365516662598 	 1.3129050731658936 	 4.172325134277344e-05 	 1.2450413703918457 	 
2025-07-30 15:03:54.588604 test begin: paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), ) 	 508032160 	 1000 	 0.008653879165649414 	 2.925187110900879 	 1.9788742065429688e-05 	 2.914079427719116 	 0.05332016944885254 	 1.3129160404205322 	 4.887580871582031e-05 	 1.2461280822753906 	 
2025-07-30 15:04:18.219650 test begin: paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), ) 	 508032280 	 1000 	 0.008591175079345703 	 2.9270412921905518 	 2.9802322387695312e-05 	 2.9129772186279297 	 0.07229995727539062 	 1.313600778579712 	 4.887580871582031e-05 	 1.2432186603546143 	 
2025-07-30 15:04:42.063000 test begin: paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), ) 	 508032080 	 1000 	 0.008471012115478516 	 2.9251339435577393 	 2.193450927734375e-05 	 2.913963556289673 	 0.05326986312866211 	 1.3113133907318115 	 3.910064697265625e-05 	 1.2441606521606445 	 
2025-07-30 15:05:05.731115 test begin: paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), ) 	 508032640 	 1000 	 0.008605480194091797 	 2.9265553951263428 	 2.384185791015625e-05 	 2.91536545753479 	 0.053269147872924805 	 1.3112266063690186 	 3.62396240234375e-05 	 1.2446067333221436 	 
2025-07-30 15:05:29.170937 test begin: paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), ) 	 508032080 	 1000 	 0.25079774856567383 	 2.9264767169952393 	 4.696846008300781e-05 	 2.915351152420044 	 0.054662227630615234 	 1.3112914562225342 	 2.4318695068359375e-05 	 1.2451939582824707 	 
2025-07-30 15:05:52.976090 test begin: paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.05310702323913574 	 0.032190561294555664 	 3.647804260253906e-05 	 2.5272369384765625e-05 	 3.521153688430786 	 2.972822666168213 	 3.4166510105133057 	 2.687084674835205 	 
2025-07-30 15:06:16.453499 test begin: paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, ) 	 508408320 	 1000 	 0.0392000675201416 	 0.033124446868896484 	 1.239776611328125e-05 	 2.5272369384765625e-05 	 3.5236074924468994 	 2.970381021499634 	 3.4137508869171143 	 2.6774001121520996 	 
2025-07-30 15:06:43.643748 test begin: paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, ) 	 510105600 	 1000 	 0.03993415832519531 	 0.03270888328552246 	 3.218650817871094e-05 	 3.600120544433594e-05 	 3.5418927669525146 	 2.980743169784546 	 3.434896230697632 	 2.688750743865967 	 
2025-07-30 15:07:06.824384 test begin: paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, ) 	 508147200 	 1000 	 0.03937983512878418 	 0.03277850151062012 	 1.811981201171875e-05 	 2.5272369384765625e-05 	 3.5201056003570557 	 2.9686458110809326 	 3.406672477722168 	 2.640798568725586 	 
2025-07-30 15:07:30.072407 test begin: paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, ) 	 513112320 	 1000 	 0.0394136905670166 	 0.0351715087890625 	 1.9311904907226562e-05 	 5.435943603515625e-05 	 3.550165891647339 	 2.997659921646118 	 3.4457643032073975 	 2.7040462493896484 	 
2025-07-30 15:07:56.646820 test begin: paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, ) 	 509276160 	 1000 	 0.041066884994506836 	 0.03307199478149414 	 2.956390380859375e-05 	 5.316734313964844e-05 	 3.5293006896972656 	 2.9745030403137207 	 3.4171597957611084 	 2.6798861026763916 	 
2025-07-30 15:08:19.805659 test begin: paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, ) 	 513676800 	 1000 	 0.04249429702758789 	 0.03380107879638672 	 3.528594970703125e-05 	 4.839897155761719e-05 	 3.5561118125915527 	 3.001926898956299 	 3.431555986404419 	 2.7074105739593506 	 
2025-07-30 15:08:49.076527 test begin: paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.03918623924255371 	 0.03281736373901367 	 1.811981201171875e-05 	 4.1961669921875e-05 	 3.524980306625366 	 2.9733097553253174 	 3.416254997253418 	 2.68442964553833 	 
2025-07-30 15:09:12.659270 test begin: paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, ) 	 541900800 	 1000 	 0.06260490417480469 	 0.0561223030090332 	 2.5272369384765625e-05 	 8.20159912109375e-05 	 3.753751754760742 	 3.153108835220337 	 3.6170616149902344 	 2.7060155868530273 	 
2025-07-30 15:09:40.936267 test begin: paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, ) 	 602112000 	 1000 	 0.062474727630615234 	 0.05398821830749512 	 2.0742416381835938e-05 	 7.557868957519531e-05 	 4.17475438117981 	 3.5080387592315674 	 4.035555124282837 	 3.063495397567749 	 
2025-07-30 15:10:12.778864 test begin: paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, ) 	 530841600 	 1000 	 0.07387280464172363 	 0.06726646423339844 	 2.09808349609375e-05 	 8.106231689453125e-05 	 3.678736448287964 	 3.088340997695923 	 3.5268447399139404 	 2.561596393585205 	 
2025-07-30 15:10:40.393833 test begin: paddle.Tensor.unique(Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.unique 	 paddle.Tensor.unique(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 6.724070072174072 	 3.2764670848846436 	 7.2479248046875e-05 	 8.893013000488281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:10:50.894781 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, )
Warning: The core code of paddle.Tensor.unsqueeze is too complex.
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, ) 	 509009920 	 1000 	 0.004200458526611328 	 0.0036334991455078125 	 1.0728836059570312e-05 	 1.9311904907226562e-05 	 0.046521902084350586 	 0.05807828903198242 	 2.765655517578125e-05 	 7.05718994140625e-05 	 
2025-07-30 15:11:10.444615 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, ) 	 509009920 	 1000 	 0.0041828155517578125 	 0.0036509037017822266 	 1.430511474609375e-05 	 1.8835067749023438e-05 	 0.0469515323638916 	 0.05964088439941406 	 3.147125244140625e-05 	 6.914138793945312e-05 	 
2025-07-30 15:11:29.303706 test begin: paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.0041501522064208984 	 0.003702402114868164 	 1.5497207641601562e-05 	 1.8596649169921875e-05 	 0.04664897918701172 	 0.0579378604888916 	 3.0994415283203125e-05 	 4.9114227294921875e-05 	 
2025-07-30 15:11:57.255993 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, ) 	 508096000 	 1000 	 0.0042188167572021484 	 0.0036427974700927734 	 1.1205673217773438e-05 	 2.0265579223632812e-05 	 0.04635906219482422 	 0.05753016471862793 	 1.811981201171875e-05 	 3.457069396972656e-05 	 
2025-07-30 15:12:15.689597 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, ) 	 508096000 	 1000 	 0.004379987716674805 	 0.0036399364471435547 	 1.3113021850585938e-05 	 2.47955322265625e-05 	 0.048249006271362305 	 0.059676170349121094 	 5.173683166503906e-05 	 6.532669067382812e-05 	 
2025-07-30 15:12:32.443140 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, ) 	 508096000 	 1000 	 0.0041675567626953125 	 0.003643035888671875 	 1.1682510375976562e-05 	 2.6226043701171875e-05 	 0.06125521659851074 	 0.05937790870666504 	 2.9325485229492188e-05 	 6.127357482910156e-05 	 
2025-07-30 15:12:48.994055 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, ) 	 508096000 	 1000 	 0.004240512847900391 	 0.004036664962768555 	 1.0967254638671875e-05 	 4.410743713378906e-05 	 0.04752755165100098 	 0.05894064903259277 	 3.8623809814453125e-05 	 6.365776062011719e-05 	 
2025-07-30 15:13:05.917056 test begin: paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.004162788391113281 	 0.003874063491821289 	 1.1205673217773438e-05 	 4.220008850097656e-05 	 0.04638051986694336 	 0.059998512268066406 	 4.0531158447265625e-05 	 4.315376281738281e-05 	 
2025-07-30 15:13:23.242399 test begin: paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004215240478515625 	 0.003652334213256836 	 1.0967254638671875e-05 	 2.0742416381835938e-05 	 0.046491384506225586 	 0.057877540588378906 	 4.363059997558594e-05 	 5.7697296142578125e-05 	 
2025-07-30 15:13:40.799429 test begin: paddle.Tensor.var(Tensor([1000, 50804],"float32"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([1000, 50804],"float32"), axis=0, ) 	 50804000 	 1000 	 1.276656150817871 	 0.17353081703186035 	 2.2411346435546875e-05 	 0.15702009201049805 	 1.4338855743408203 	 0.7667529582977295 	 0.21042799949645996 	 0.19578886032104492 	 
2025-07-30 15:13:45.350915 test begin: paddle.Tensor.var(Tensor([100000, 255],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([100000, 255],"float64"), axis=0, ) 	 25500000 	 1000 	 1.750246286392212 	 0.1947002410888672 	 2.002716064453125e-05 	 0.09945225715637207 	 1.707700252532959 	 0.7627794742584229 	 0.2491312026977539 	 0.15591859817504883 	 
2025-07-30 15:13:50.302963 test begin: paddle.Tensor.var(Tensor([1000000, 26],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([1000000, 26],"float64"), axis=0, ) 	 26000000 	 1000 	 6.18472957611084 	 0.18901848793029785 	 3.123283386230469e-05 	 0.09656047821044922 	 3.93648362159729 	 0.7868616580963135 	 0.5745632648468018 	 0.16077089309692383 	 
2025-07-30 15:14:02.100492 test begin: paddle.Tensor.var(Tensor([6350401, 4],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([6350401, 4],"float64"), axis=0, ) 	 25401604 	 1000 	 11.5263032913208 	 0.2502741813659668 	 4.553794860839844e-05 	 0.12784314155578613 	 6.60678768157959 	 0.7646994590759277 	 0.9654452800750732 	 0.15622448921203613 	 
2025-07-30 15:14:23.313141 test begin: paddle.Tensor.var(Tensor([64801, 784],"float32"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([64801, 784],"float32"), axis=0, ) 	 50803984 	 1000 	 1.4141247272491455 	 0.2594759464263916 	 1.8835067749023438e-05 	 0.1324753761291504 	 1.4983444213867188 	 0.8013241291046143 	 0.21867823600769043 	 0.1635749340057373 	 
2025-07-30 15:14:28.132007 test begin: paddle.Tensor.zero_(Tensor([100352, 507],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.14534330368041992 	 0.13422369956970215 	 0.13087058067321777 	 0.1271049976348877 	 None 	 None 	 None 	 None 	 
2025-07-30 15:14:30.120901 test begin: paddle.Tensor.zero_(Tensor([507, 100352],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.1452198028564453 	 0.1342601776123047 	 0.13106393814086914 	 0.12714862823486328 	 None 	 None 	 None 	 None 	 
2025-07-30 15:14:32.092285 test begin: paddle.Tensor.zero_(Tensor([6202, 8192],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.146712064743042 	 0.13414883613586426 	 0.13277101516723633 	 0.12714028358459473 	 None 	 None 	 None 	 None 	 
2025-07-30 15:14:34.090169 test begin: paddle.Tensor.zero_(Tensor([8192, 6202],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.14688777923583984 	 0.13405942916870117 	 0.1328113079071045 	 0.12682366371154785 	 None 	 None 	 None 	 None 	 
2025-07-30 15:14:37.375494 test begin: paddle.Tensor.zero_(Tensor([886, 57344],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.14685821533203125 	 0.13425087928771973 	 0.13289880752563477 	 0.12711191177368164 	 None 	 None 	 None 	 None 	 
2025-07-30 15:14:39.825836 test begin: paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[0,], ) 	 101606500 	 1000 	 1.0814754962921143 	 0.8429787158966064 	 0.36839866638183594 	 0.4313676357269287 	 1.5870623588562012 	 1.5939476490020752 	 0.8108789920806885 	 0.8135924339294434 	 
2025-07-30 15:14:46.725694 test begin: paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[3,0,], ) 	 101606500 	 1000 	 1.1621766090393066 	 3.5838828086853027 	 0.29764628410339355 	 0.9152431488037109 	 0.7942979335784912 	 0.7939674854278564 	 0.20538115501403809 	 0.20421528816223145 	 
2025-07-30 15:14:54.823505 test begin: paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.108266830444336 	 4.138293027877808 	 0.47365760803222656 	 0.42201972007751465 	 11.543955326080322 	 10.646969079971313 	 0.908963680267334 	 0.9050698280334473 	 
2025-07-30 15:15:48.515148 test begin: paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 1.428131103515625 	 0.7267234325408936 	 0.36514949798583984 	 0.1855907440185547 	 0.7849533557891846 	 0.7824521064758301 	 0.20045161247253418 	 0.19985365867614746 	 
2025-07-30 15:15:54.033896 test begin: paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.110248565673828 	 4.134135007858276 	 0.4752054214477539 	 0.42203402519226074 	 11.587496757507324 	 10.653328895568848 	 0.9114682674407959 	 0.9058749675750732 	 
2025-07-30 15:16:46.691411 test begin: paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 1.4248683452606201 	 0.7284202575683594 	 0.36370396614074707 	 0.1872391700744629 	 0.7855117321014404 	 0.7839899063110352 	 0.20070624351501465 	 0.20116615295410156 	 
2025-07-30 15:16:52.109000 test begin: paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[3,0,], ) 	 101606500 	 1000 	 2.096628189086914 	 2.5179717540740967 	 0.5359458923339844 	 0.6423702239990234 	 0.7983300685882568 	 0.796550989151001 	 0.20447087287902832 	 0.20393085479736328 	 
2025-07-30 15:17:00.114634 test begin: paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.110116958618164 	 4.133249521255493 	 0.47514915466308594 	 0.42198729515075684 	 11.558018207550049 	 10.65438723564148 	 0.9096941947937012 	 0.9059181213378906 	 
2025-07-30 15:17:53.889082 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 4.555006980895996 	 4.560666561126709 	 0.42328381538391113 	 0.4654839038848877 	 12.392466306686401 	 12.232723474502563 	 0.06697201728820801 	 0.0718381404876709 	 
2025-07-30 15:18:52.231613 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 0.8636107444763184 	 1.2834432125091553 	 0.22060251235961914 	 0.32704710960388184 	 0.8026654720306396 	 0.8014082908630371 	 0.2047576904296875 	 0.20462632179260254 	 
2025-07-30 15:18:57.771406 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 4.554683208465576 	 4.558132648468018 	 0.42322421073913574 	 0.4656400680541992 	 12.4065420627594 	 12.243461847305298 	 0.06704521179199219 	 0.07195448875427246 	 
2025-07-30 15:19:54.769193 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 0.8644225597381592 	 1.3083503246307373 	 0.22085332870483398 	 0.32561731338500977 	 0.8016130924224854 	 0.8017106056213379 	 0.20478534698486328 	 0.20476508140563965 	 
2025-07-30 15:20:00.315987 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[0,], ) 	 50803875 	 1000 	 4.554409027099609 	 5.020169258117676 	 0.4232521057128906 	 0.46572399139404297 	 12.407392501831055 	 12.240201473236084 	 0.0670006275177002 	 0.07194876670837402 	 
2025-07-30 15:21:00.272347 test begin: paddle.tensordot(x=Tensor([4, 105841, 3, 5, 4],"float64"), y=Tensor([105841, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 105841, 3, 5, 4],"float64"), y=Tensor([105841, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205520 	 1000 	 1.690241813659668 	 1.3646743297576904 	 0.4317340850830078 	 0.464641809463501 	 3.357783555984497 	 3.4985814094543457 	 0.24474811553955078 	 0.2612762451171875 	 
2025-07-30 15:21:13.362325 test begin: paddle.tensordot(x=Tensor([4, 2, 158761, 5, 4],"float64"), y=Tensor([2, 4, 158761, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 158761, 5, 4],"float64"), y=Tensor([2, 4, 158761, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205280 	 1000 	 1.6727845668792725 	 1.360668659210205 	 0.4270036220550537 	 0.46125221252441406 	 3.331312417984009 	 3.5504488945007324 	 0.24291539192199707 	 0.26844215393066406 	 
2025-07-30 15:21:24.980409 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 132301, 4],"float64"), y=Tensor([2, 4, 3, 132301, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 132301, 4],"float64"), y=Tensor([2, 4, 3, 132301, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38102688 	 1000 	 0.839714527130127 	 0.6927454471588135 	 0.21453142166137695 	 0.2359156608581543 	 1.6710820198059082 	 1.7754755020141602 	 0.2144308090209961 	 0.2293412685394287 	 
2025-07-30 15:21:30.744125 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 264601, 4],"float64"), y=Tensor([2, 4, 3, 264601, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 264601, 4],"float64"), y=Tensor([2, 4, 3, 264601, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205088 	 1000 	 1.675471305847168 	 1.6455132961273193 	 0.42734265327453613 	 0.4623408317565918 	 3.325192451477051 	 3.5876262187957764 	 0.2425835132598877 	 0.26134371757507324 	 
2025-07-30 15:21:44.097976 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 5, 211681],"float64"), y=Tensor([2, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 5, 211681],"float64"), y=Tensor([2, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 25402680 	 1000 	 0.530012845993042 	 0.19932246208190918 	 0.18068456649780273 	 0.10162711143493652 	 0.3540947437286377 	 0.3788635730743408 	 0.12132644653320312 	 0.12893271446228027 	 
2025-07-30 15:21:46.170103 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 5, 4],"float64"), y=Tensor([2, 4, 3, 5, 211681],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 5, 4],"float64"), y=Tensor([2, 4, 3, 5, 211681],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 25402200 	 1000 	 0.49048399925231934 	 0.4844057559967041 	 0.166886568069458 	 0.24742627143859863 	 0.3857264518737793 	 0.3718407154083252 	 0.13125896453857422 	 0.12656927108764648 	 
2025-07-30 15:21:48.446991 test begin: paddle.tensordot(x=Tensor([4, 2, 79381, 5, 4],"float64"), y=Tensor([2, 4, 79381, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 79381, 5, 4],"float64"), y=Tensor([2, 4, 79381, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38102880 	 1000 	 0.8414328098297119 	 0.6923408508300781 	 0.21497845649719238 	 0.23581409454345703 	 1.6742939949035645 	 1.713310956954956 	 0.213226318359375 	 0.2187042236328125 	 
2025-07-30 15:21:54.228328 test begin: paddle.tensordot(x=Tensor([4, 52921, 3, 5, 4],"float64"), y=Tensor([52921, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 52921, 3, 5, 4],"float64"), y=Tensor([52921, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38103120 	 1000 	 0.8527038097381592 	 0.6955263614654541 	 0.2185211181640625 	 0.23676085472106934 	 1.6818783283233643 	 1.756455659866333 	 0.21474146842956543 	 0.2293989658355713 	 
2025-07-30 15:22:00.211670 test begin: paddle.tile(Tensor([102426, 248, 1, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([102426, 248, 1, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50803296 	 1000 	 0.296144962310791 	 0.3132503032684326 	 0.2845008373260498 	 0.15998029708862305 	 0.3077239990234375 	 0.06786775588989258 	 0.15720558166503906 	 6.151199340820312e-05 	 
2025-07-30 15:22:02.830486 test begin: paddle.tile(Tensor([1511, 10, 1, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([1511, 10, 1, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 50830040 	 1000 	 2.0830442905426025 	 0.9398107528686523 	 1.1192681789398193 	 0.9169304370880127 	 1.8885204792022705 	 0.7312633991241455 	 1.8295495510101318 	 0.6475939750671387 	 
2025-07-30 15:22:13.199255 test begin: paddle.tile(Tensor([16, 1, 1, 3, 16538, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 3, 16538, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50804736 	 1000 	 6.073971748352051 	 2.746016502380371 	 3.102830171585083 	 1.402860403060913 	 3.3644776344299316 	 1.7349658012390137 	 3.3055419921875 	 0.8865160942077637 	 
2025-07-30 15:22:37.885276 test begin: paddle.tile(Tensor([16, 1, 1, 3, 64, 16538],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 3, 64, 16538],"float32"), list[1,11,1,1,1,1,], ) 	 50804736 	 1000 	 6.783936023712158 	 2.74873948097229 	 3.103360176086426 	 1.4050076007843018 	 3.3636422157287598 	 1.7363109588623047 	 3.3038828372955322 	 0.8878731727600098 	 
2025-07-30 15:23:03.923286 test begin: paddle.tile(Tensor([16, 1, 1, 776, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 776, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50855936 	 1000 	 6.08430290222168 	 2.7568013668060303 	 3.1099298000335693 	 1.4092445373535156 	 3.365124464035034 	 1.7356269359588623 	 3.3062331676483154 	 0.8868088722229004 	 
2025-07-30 15:23:27.741674 test begin: paddle.tile(Tensor([16, 1, 259, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 259, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50921472 	 1000 	 6.097730398178101 	 2.759690523147583 	 3.1164848804473877 	 1.4111406803131104 	 3.369089126586914 	 1.738140344619751 	 3.308579206466675 	 0.8881239891052246 	 
2025-07-30 15:23:53.214945 test begin: paddle.tile(Tensor([16, 10, 1, 5475, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 1, 5475, 58],"float32"), list[1,1,4,1,1,], ) 	 50808000 	 1000 	 1.9470024108886719 	 0.8700757026672363 	 0.9941236972808838 	 0.8424685001373291 	 1.890193223953247 	 0.7453193664550781 	 1.8310668468475342 	 0.6676056385040283 	 
2025-07-30 15:24:02.857131 test begin: paddle.tile(Tensor([16, 10, 1, 58, 5475],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 1, 58, 5475],"float32"), list[1,1,4,1,1,], ) 	 50808000 	 1000 	 1.9456896781921387 	 0.8658969402313232 	 0.9925785064697266 	 0.843616247177124 	 1.8870177268981934 	 0.7468030452728271 	 1.8279685974121094 	 0.6707282066345215 	 
2025-07-30 15:24:12.584447 test begin: paddle.tile(Tensor([16, 10, 95, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 95, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 51132800 	 1000 	 1.9552130699157715 	 0.8707327842712402 	 0.9991598129272461 	 0.8453977108001709 	 1.9031167030334473 	 0.738518238067627 	 1.8438115119934082 	 0.6627235412597656 	 
2025-07-30 15:24:22.198239 test begin: paddle.tile(Tensor([16, 259, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 259, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50921472 	 1000 	 6.100630283355713 	 2.756856918334961 	 3.1179308891296387 	 1.4082167148590088 	 3.3708484172821045 	 1.7424840927124023 	 3.3117575645446777 	 0.8910033702850342 	 
2025-07-30 15:24:46.290112 test begin: paddle.tile(Tensor([16, 944, 1, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 944, 1, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 50809856 	 1000 	 1.9721686840057373 	 0.9507277011871338 	 1.0084733963012695 	 0.91619873046875 	 1.8874554634094238 	 0.7310123443603516 	 1.827821969985962 	 0.6530406475067139 	 
2025-07-30 15:24:56.403730 test begin: paddle.tile(Tensor([216, 117601, 1, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 117601, 1, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50803632 	 1000 	 0.2961874008178711 	 0.3133265972137451 	 0.2844550609588623 	 0.1600179672241211 	 0.3161187171936035 	 0.05418896675109863 	 0.16147708892822266 	 3.695487976074219e-05 	 
2025-07-30 15:24:59.231721 test begin: paddle.tile(Tensor([216, 248, 1, 1, 949],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 1, 1, 949],"float32"), list[1,1,1,1,1,], ) 	 50836032 	 1000 	 0.296358585357666 	 0.3135514259338379 	 0.2845919132232666 	 0.16011643409729004 	 0.3163020610809326 	 0.05921220779418945 	 0.16158103942871094 	 7.367134094238281e-05 	 
2025-07-30 15:25:01.951949 test begin: paddle.tile(Tensor([216, 248, 1, 475, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 1, 475, 2],"float32"), list[1,1,1,1,1,], ) 	 50889600 	 1000 	 0.2964000701904297 	 0.3187906742095947 	 0.28467249870300293 	 0.1602320671081543 	 0.3095123767852783 	 0.05449652671813965 	 0.15874242782592773 	 5.0067901611328125e-05 	 
2025-07-30 15:25:04.655828 test begin: paddle.tile(Tensor([216, 248, 475, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 475, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50889600 	 1000 	 0.29639601707458496 	 0.31960415840148926 	 0.2847287654876709 	 0.16025471687316895 	 0.3082244396209717 	 0.054718732833862305 	 0.15729522705078125 	 5.125999450683594e-05 	 
2025-07-30 15:25:07.315512 test begin: paddle.tile(Tensor([4135, 1, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([4135, 1, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50810880 	 1000 	 5.007406949996948 	 2.4586918354034424 	 2.5579285621643066 	 1.2560322284698486 	 3.362466812133789 	 1.7537708282470703 	 3.3031482696533203 	 0.8974742889404297 	 
2025-07-30 15:25:30.026603 test begin: paddle.tolist(Tensor([10160, 5],"float32"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([10160, 5],"float32"), ) 	 50800 	 1000 	 9.297642946243286 	 13.905131101608276 	 9.465217590332031e-05 	 0.0001125335693359375 	 None 	 None 	 None 	 None 	 
2025-07-30 15:25:53.240653 test begin: paddle.tolist(Tensor([2, 25400],"float32"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([2, 25400],"float32"), ) 	 50800 	 1000 	 0.8871486186981201 	 1.028254747390747 	 5.173683166503906e-05 	 7.486343383789062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:25:55.176044 test begin: paddle.tolist(Tensor([8467, 3],"int64"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([8467, 3],"int64"), ) 	 25401 	 1000 	 6.456554889678955 	 10.549557447433472 	 0.00011897087097167969 	 0.00010943412780761719 	 None 	 None 	 None 	 None 	 
2025-07-30 15:26:12.189221 test begin: paddle.topk(Tensor([138, 369303],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([138, 369303],"float32"), k=1, axis=0, ) 	 50963814 	 1000 	 2.404510021209717 	 8.903773784637451 	 0.6126327514648438 	 8.556984901428223 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:26:34.370285 test begin: paddle.topk(Tensor([146, 349866],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([146, 349866],"float32"), k=1, axis=0, ) 	 51080436 	 1000 	 2.35294771194458 	 11.111961126327515 	 0.6031320095062256 	 11.097110033035278 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:26:58.378681 test begin: paddle.topk(Tensor([148, 343728],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([148, 343728],"float32"), k=1, axis=0, ) 	 50871744 	 1000 	 2.1005795001983643 	 9.286970376968384 	 0.5356020927429199 	 9.269817590713501 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:27:20.185195 test begin: paddle.topk(Tensor([49, 1036801],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([49, 1036801],"float32"), k=1, axis=0, ) 	 50803249 	 1000 	 2.2109005451202393 	 4.148365259170532 	 0.564359188079834 	 4.13165807723999 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:27:40.121549 test begin: paddle.topk(Tensor([53, 958551],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([53, 958551],"float32"), k=1, axis=0, ) 	 50803203 	 1000 	 2.2214467525482178 	 4.236722230911255 	 0.5660157203674316 	 4.2211573123931885 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:27:57.556462 test begin: paddle.topk(Tensor([55, 923695],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([55, 923695],"float32"), k=1, axis=0, ) 	 50803225 	 1000 	 2.1681642532348633 	 4.477239370346069 	 0.5535538196563721 	 4.46224045753479 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:28:15.315823 test begin: paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.2469170093536377 	 0.08102941513061523 	 9.202957153320312e-05 	 0.05893445014953613 	 0.7688720226287842 	 0.24055171012878418 	 3.600120544433594e-05 	 0.12291073799133301 	 combined
2025-07-30 15:28:17.338460 test begin: paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401604 	 1000 	 0.24427151679992676 	 0.1187593936920166 	 7.62939453125e-05 	 0.09574437141418457 	 0.7818448543548584 	 0.3343346118927002 	 3.981590270996094e-05 	 0.17077112197875977 	 combined
2025-07-30 15:28:19.483620 test begin: paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, ) 	 2540160 	 1000 	 0.06617403030395508 	 0.023550987243652344 	 3.9577484130859375e-05 	 7.653236389160156e-05 	 0.1752758026123047 	 0.09124541282653809 	 3.2901763916015625e-05 	 8.273124694824219e-05 	 combined
2025-07-30 15:28:19.892555 test begin: paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, ) 	 2540160 	 1000 	 0.06794452667236328 	 0.02034759521484375 	 3.743171691894531e-05 	 6.628036499023438e-05 	 0.13868117332458496 	 0.08776235580444336 	 2.765655517578125e-05 	 7.176399230957031e-05 	 combined
2025-07-30 15:28:20.246055 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.06580853462219238 	 0.020679950714111328 	 2.288818359375e-05 	 5.316734313964844e-05 	 0.7687501907348633 	 0.13992762565612793 	 4.38690185546875e-05 	 0.05331754684448242 	 combined
2025-07-30 15:28:21.786264 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401606 	 1000 	 0.06517171859741211 	 0.020424842834472656 	 2.0265579223632812e-05 	 3.314018249511719e-05 	 0.76204514503479 	 0.1383838653564453 	 4.553794860839844e-05 	 0.05138444900512695 	 combined
2025-07-30 15:28:23.304578 test begin: paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, ) 	 25401604 	 1000 	 0.06735968589782715 	 0.019887924194335938 	 3.3855438232421875e-05 	 4.506111145019531e-05 	 0.6023190021514893 	 0.13843059539794922 	 4.220008850097656e-05 	 0.05367755889892578 	 combined
2025-07-30 15:28:24.659473 test begin: paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], ) 	 786432000 	 1000 	 0.0034637451171875 	 0.0045299530029296875 	 1.430511474609375e-05 	 1.9073486328125e-05 	 0.04396462440490723 	 0.05765271186828613 	 3.743171691894531e-05 	 5.1975250244140625e-05 	 
2025-07-30 15:28:50.253782 test begin: paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.003367185592651367 	 0.00443577766418457 	 1.1682510375976562e-05 	 1.9073486328125e-05 	 0.04805731773376465 	 4.552944660186768 	 3.266334533691406e-05 	 2.325090169906616 	 
2025-07-30 15:29:29.114819 test begin: paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.0034089088439941406 	 0.0044748783111572266 	 7.867813110351562e-06 	 1.8596649169921875e-05 	 0.04384136199951172 	 0.059696197509765625 	 2.6702880859375e-05 	 7.891654968261719e-05 	 
2025-07-30 15:29:49.817670 test begin: paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.003398418426513672 	 0.00447392463684082 	 1.0013580322265625e-05 	 1.7881393432617188e-05 	 0.04371762275695801 	 0.05832195281982422 	 4.482269287109375e-05 	 6.389617919921875e-05 	 
2025-07-30 15:30:06.627057 test begin: paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.003588438034057617 	 0.005385637283325195 	 1.4781951904296875e-05 	 7.677078247070312e-05 	 0.04837632179260254 	 4.552536487579346 	 2.6226043701171875e-05 	 2.3248512744903564 	 
2025-07-30 15:30:45.878921 test begin: paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], ) 	 513802240 	 1000 	 0.003336668014526367 	 0.0044596195220947266 	 1.1205673217773438e-05 	 1.8596649169921875e-05 	 0.04384016990661621 	 0.05769705772399902 	 4.673004150390625e-05 	 5.412101745605469e-05 	 
2025-07-30 15:31:03.145493 test begin: paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0034062862396240234 	 0.005012989044189453 	 7.867813110351562e-06 	 5.459785461425781e-05 	 0.04819822311401367 	 4.50115704536438 	 4.553794860839844e-05 	 2.3021762371063232 	 
2025-07-30 15:31:41.785421 test begin: paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0034220218658447266 	 0.0044400691986083984 	 1.7642974853515625e-05 	 2.002716064453125e-05 	 0.05194807052612305 	 4.502474069595337 	 5.793571472167969e-05 	 2.298877477645874 	 
2025-07-30 15:32:23.446657 test begin: paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.003392934799194336 	 0.00477910041809082 	 1.2636184692382812e-05 	 4.553794860839844e-05 	 0.04789400100708008 	 4.500819444656372 	 3.314018249511719e-05 	 2.2977633476257324 	 
2025-07-30 15:33:02.764092 test begin: paddle.tril(Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.30794453620910645 	 0.2607252597808838 	 0.299468994140625 	 0.24761152267456055 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:33:05.268333 test begin: paddle.tril(Tensor([1, 1, 2048, 24807],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 2048, 24807],"float32"), ) 	 50804736 	 1000 	 0.3121676445007324 	 0.3327972888946533 	 0.3037087917327881 	 0.3220210075378418 	 0.310715913772583 	 0.3327057361602783 	 0.25638580322265625 	 0.25089216232299805 	 
2025-07-30 15:33:08.231197 test begin: paddle.tril(Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.37236547470092773 	 0.23725175857543945 	 0.36368346214294434 	 0.22540736198425293 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:33:10.680949 test begin: paddle.tril(Tensor([1, 1, 24807, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 24807, 2048],"float32"), ) 	 50804736 	 1000 	 0.4140932559967041 	 0.37626218795776367 	 0.40566396713256836 	 0.36258697509765625 	 0.4137279987335205 	 0.3756227493286133 	 0.35251688957214355 	 0.30733323097229004 	 
2025-07-30 15:33:14.045730 test begin: paddle.tril(Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 13, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.38387441635131836 	 0.25092363357543945 	 0.375347375869751 	 0.23980093002319336 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:33:16.641429 test begin: paddle.tril(Tensor([1, 13, 2048, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 13, 2048, 2048],"float32"), ) 	 54525952 	 1000 	 0.41507411003112793 	 0.3865537643432617 	 0.4067535400390625 	 0.371309757232666 	 0.41497302055358887 	 0.3803553581237793 	 0.35648679733276367 	 0.30947303771972656 	 
2025-07-30 15:33:20.181627 test begin: paddle.tril(Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([13, 1, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.38239264488220215 	 0.25096702575683594 	 0.37363481521606445 	 0.24006891250610352 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:33:22.735019 test begin: paddle.tril(Tensor([13, 1, 2048, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([13, 1, 2048, 2048],"float32"), ) 	 54525952 	 1000 	 0.4165070056915283 	 0.38126468658447266 	 0.4080810546875 	 0.370342493057251 	 0.4150841236114502 	 0.38053369522094727 	 0.35225605964660645 	 0.3105010986328125 	 
2025-07-30 15:33:26.142039 test begin: paddle.tril(Tensor([2048, 24807],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.3079655170440674 	 0.2582981586456299 	 0.29950428009033203 	 0.24718093872070312 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:33:28.594236 test begin: paddle.tril(Tensor([24807, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.3723576068878174 	 0.2360525131225586 	 0.36362671852111816 	 0.2252027988433838 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:33:31.013951 test begin: paddle.triu(Tensor([1, 1, 1024, 99226],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 1024, 99226],"float16"), diagonal=1, ) 	 101607424 	 1000 	 0.7738943099975586 	 0.5348379611968994 	 0.7652015686035156 	 0.5149028301239014 	 0.768017053604126 	 0.5268332958221436 	 0.7144131660461426 	 0.4573488235473633 	 
2025-07-30 15:33:39.099170 test begin: paddle.triu(Tensor([1, 1, 12404, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 12404, 4096],"float32"), diagonal=1, ) 	 50806784 	 1000 	 0.3273952007293701 	 0.3389148712158203 	 0.3163323402404785 	 0.3278076648712158 	 0.3248462677001953 	 0.3388240337371826 	 0.27077293395996094 	 0.2722482681274414 	 
2025-07-30 15:33:42.132260 test begin: paddle.triu(Tensor([1, 1, 2048, 49613],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 2048, 49613],"float16"), ) 	 101607424 	 1000 	 0.7707524299621582 	 0.5248692035675049 	 0.7623591423034668 	 0.5135400295257568 	 0.7677092552185059 	 0.5248513221740723 	 0.7129247188568115 	 0.4558682441711426 	 
2025-07-30 15:33:48.606552 test begin: paddle.triu(Tensor([1, 1, 4096, 12404],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 4096, 12404],"float32"), diagonal=1, ) 	 50806784 	 1000 	 0.41108226776123047 	 0.3712046146392822 	 0.39713382720947266 	 0.35990381240844727 	 0.4094235897064209 	 0.3710963726043701 	 0.35266923904418945 	 0.3046994209289551 	 
2025-07-30 15:33:51.916266 test begin: paddle.triu(Tensor([1, 1, 49613, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 49613, 2048],"float16"), ) 	 101607424 	 1000 	 0.5902392864227295 	 0.36745762825012207 	 0.5817563533782959 	 0.3543426990509033 	 0.588820219039917 	 0.36713242530822754 	 0.5293593406677246 	 0.299971342086792 	 
2025-07-30 15:33:57.832388 test begin: paddle.triu(Tensor([1, 1, 99226, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 99226, 1024],"float16"), diagonal=1, ) 	 101607424 	 1000 	 0.5849828720092773 	 0.3647162914276123 	 0.5763611793518066 	 0.34522509574890137 	 0.5850498676300049 	 0.3658018112182617 	 0.5147781372070312 	 0.29741621017456055 	 
2025-07-30 15:34:03.611733 test begin: paddle.triu(Tensor([1, 25, 2048, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 25, 2048, 2048],"float16"), ) 	 104857600 	 1000 	 0.7434625625610352 	 0.44260120391845703 	 0.7349376678466797 	 0.42565035820007324 	 0.7424755096435547 	 0.4413797855377197 	 0.6856045722961426 	 0.3541254997253418 	 
2025-07-30 15:34:10.868059 test begin: paddle.triu(Tensor([1, 4, 4096, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 4, 4096, 4096],"float32"), diagonal=1, ) 	 67108864 	 1000 	 0.4947378635406494 	 0.4711642265319824 	 0.48598361015319824 	 0.4526658058166504 	 0.4950094223022461 	 0.4692575931549072 	 0.44097447395324707 	 0.40212082862854004 	 
2025-07-30 15:34:15.075078 test begin: paddle.triu(Tensor([1, 97, 1024, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 97, 1024, 1024],"float16"), diagonal=1, ) 	 101711872 	 1000 	 0.7400116920471191 	 0.4426758289337158 	 0.7313241958618164 	 0.41603708267211914 	 0.7422642707824707 	 0.4261181354522705 	 0.6886370182037354 	 0.3443591594696045 	 
2025-07-30 15:34:21.368817 test begin: paddle.triu(Tensor([25, 1, 2048, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([25, 1, 2048, 2048],"float16"), ) 	 104857600 	 1000 	 0.7434477806091309 	 0.43715953826904297 	 0.734915018081665 	 0.42607784271240234 	 0.7425222396850586 	 0.4372735023498535 	 0.6865172386169434 	 0.3701150417327881 	 
2025-07-30 15:34:27.618190 test begin: paddle.triu(Tensor([4, 1, 4096, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([4, 1, 4096, 4096],"float32"), diagonal=1, ) 	 67108864 	 1000 	 0.4961566925048828 	 0.46808528900146484 	 0.4873976707458496 	 0.4558568000793457 	 0.4950110912322998 	 0.46793651580810547 	 0.4394540786743164 	 0.3991076946258545 	 
2025-07-30 15:34:31.892964 test begin: paddle.triu(Tensor([97, 1, 1024, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([97, 1, 1024, 1024],"float16"), diagonal=1, ) 	 101711872 	 1000 	 0.7415001392364502 	 0.42824387550354004 	 0.7328732013702393 	 0.4147310256958008 	 0.73931884765625 	 0.4262962341308594 	 0.685676097869873 	 0.3568077087402344 	 
2025-07-30 15:34:39.269810 test begin: paddle.trunc(Tensor([200, 2540161],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.009753227233886719 	 2.9349677562713623 	 1.9788742065429688e-05 	 2.917279005050659 	 0.05434870719909668 	 1.3126556873321533 	 2.3603439331054688e-05 	 1.2446632385253906 	 
2025-07-30 15:35:03.103781 test begin: paddle.trunc(Tensor([25401610, 20],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.008669137954711914 	 2.931147336959839 	 2.3365020751953125e-05 	 2.9196972846984863 	 0.05652475357055664 	 1.3110010623931885 	 2.9802322387695312e-05 	 1.2430720329284668 	 
2025-07-30 15:35:29.646258 test begin: paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.011957883834838867 	 2.921494483947754 	 3.528594970703125e-05 	 2.9035568237304688 	 0.05487394332885742 	 1.3136897087097168 	 3.933906555175781e-05 	 1.2330482006072998 	 
2025-07-30 15:35:46.095638 test begin: paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), ) 	 254028960 	 1000 	 0.011453866958618164 	 2.917840003967285 	 3.24249267578125e-05 	 2.901923179626465 	 0.06475305557250977 	 1.3120825290679932 	 5.221366882324219e-05 	 1.242004632949829 	 
2025-07-30 15:36:04.398530 test begin: paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.008736133575439453 	 3.5888683795928955 	 2.1696090698242188e-05 	 2.8989689350128174 	 0.05338788032531738 	 1.3181860446929932 	 2.4080276489257812e-05 	 1.2479147911071777 	 
2025-07-30 15:36:21.777145 test begin: paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.008864164352416992 	 2.9173097610473633 	 2.3603439331054688e-05 	 2.902658224105835 	 0.05354762077331543 	 1.311807632446289 	 4.1484832763671875e-05 	 1.238598108291626 	 
2025-07-30 15:36:40.369586 test begin: paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), ) 	 254022480 	 1000 	 0.014079093933105469 	 2.914720296859741 	 2.574920654296875e-05 	 2.9028725624084473 	 0.054872751235961914 	 1.3150434494018555 	 3.719329833984375e-05 	 1.2449584007263184 	 
2025-07-30 15:36:56.646693 test begin: paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), ) 	 254022480 	 1000 	 0.008846521377563477 	 2.917790174484253 	 2.6226043701171875e-05 	 2.905773878097534 	 0.05318427085876465 	 1.31337571144104 	 4.506111145019531e-05 	 1.2419626712799072 	 
2025-07-30 15:37:12.995751 test begin: paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.009010791778564453 	 2.9204704761505127 	 2.09808349609375e-05 	 2.9048759937286377 	 0.07285928726196289 	 1.3118188381195068 	 3.838539123535156e-05 	 1.2429969310760498 	 
2025-07-30 15:37:29.472956 test begin: paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), ) 	 254018160 	 1000 	 0.00892782211303711 	 2.9229557514190674 	 2.2172927856445312e-05 	 2.9014315605163574 	 0.05363941192626953 	 1.3153085708618164 	 4.124641418457031e-05 	 1.21817946434021 	 
2025-07-30 15:37:46.696125 test begin: paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), ) 	 254018160 	 1000 	 0.009877681732177734 	 2.9198591709136963 	 2.3365020751953125e-05 	 2.904308795928955 	 0.05320262908935547 	 1.311797857284546 	 3.552436828613281e-05 	 1.2412805557250977 	 
2025-07-30 15:38:02.950942 test begin: paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, ) 	 508032480 	 1000 	 0.02793717384338379 	 0.022663354873657227 	 1.3828277587890625e-05 	 2.6464462280273438e-05 	 3.6317529678344727 	 3.0470635890960693 	 3.5413730144500732 	 2.8294711112976074 	 
2025-07-30 15:38:27.065538 test begin: paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, ) 	 508032480 	 1000 	 0.028189659118652344 	 0.022812366485595703 	 2.002716064453125e-05 	 2.86102294921875e-05 	 3.631894588470459 	 3.0470948219299316 	 3.5427682399749756 	 2.8348543643951416 	 
2025-07-30 15:38:50.899885 test begin: paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, ) 	 508033280 	 1000 	 0.032288551330566406 	 0.023053407669067383 	 2.956390380859375e-05 	 3.218650817871094e-05 	 3.526796817779541 	 2.993837356567383 	 3.4321038722991943 	 2.7791354656219482 	 
2025-07-30 15:39:14.518235 test begin: paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, ) 	 508032150 	 1000 	 0.050054311752319336 	 0.03215599060058594 	 4.291534423828125e-05 	 4.3392181396484375e-05 	 3.6721596717834473 	 3.0711746215820312 	 3.5641350746154785 	 2.7813687324523926 	 
2025-07-30 15:39:45.412069 test begin: paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, ) 	 508032270 	 1000 	 0.03741908073425293 	 0.03293752670288086 	 2.1219253540039062e-05 	 5.6743621826171875e-05 	 3.674605369567871 	 3.0739684104919434 	 3.5668206214904785 	 2.804966688156128 	 
2025-07-30 15:40:09.222314 test begin: paddle.unbind(Tensor([40, 2116801, 6],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 2116801, 6],"float32"), ) 	 508032240 	 1000 	 0.04935789108276367 	 0.0839381217956543 	 3.170967102050781e-05 	 0.00010323524475097656 	 3.6717188358306885 	 3.0494890213012695 	 3.5506348609924316 	 2.709385871887207 	 
2025-07-30 15:40:33.043483 test begin: paddle.unbind(Tensor([40, 5, 2540161],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 5, 2540161],"float32"), ) 	 508032200 	 1000 	 0.04843497276306152 	 0.04214978218078613 	 2.3603439331054688e-05 	 5.3882598876953125e-05 	 3.6781535148620605 	 3.054771661758423 	 3.5487661361694336 	 2.702608108520508 	 
2025-07-30 15:40:59.472707 test begin: paddle.unflatten(x=Tensor([4, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 50803266 	 1000 	 0.10127377510070801 	 0.005195140838623047 	 3.337860107421875e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:41:01.378877 test begin: paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032242 	 1000 	 0.09991240501403809 	 0.005148649215698242 	 3.24249267578125e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:41:18.354351 test begin: paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032642 	 1000 	 0.10375690460205078 	 0.005106449127197266 	 2.5272369384765625e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:41:37.200635 test begin: paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032962 	 1000 	 0.09865808486938477 	 0.005037069320678711 	 2.956390380859375e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:41:54.500672 test begin: paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, ) 	 1016064050 	 1000 	 0.01619410514831543 	 0.004436492919921875 	 1.1205673217773438e-05 	 1.8596649169921875e-05 	 41.14043927192688 	 40.96075439453125 	 41.08014893531799 	 13.966949224472046 	 
2025-07-30 15:45:08.015658 test begin: paddle.unique(Tensor([25401601],"int64"), )
[Prof] paddle.unique 	 paddle.unique(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 6.715577840805054 	 3.2743465900421143 	 7.009506225585938e-05 	 8.726119995117188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:45:18.525019 test begin: paddle.unique(Tensor([25401601],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", )
[Prof] paddle.unique 	 paddle.unique(Tensor([25401601],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", ) 	 25401601 	 1000 	 10.085992336273193 	 11.158856630325317 	 8.845329284667969e-05 	 0.00021505355834960938 	 None 	 None 	 None 	 None 	 
2025-07-30 15:45:40.509606 test begin: paddle.unique_consecutive(Tensor([25401601],"float64"), )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 1.6122403144836426 	 0.3639528751373291 	 4.220008850097656e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:45:43.031900 test begin: paddle.unique_consecutive(Tensor([25401601],"float64"), return_inverse=True, return_counts=True, )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([25401601],"float64"), return_inverse=True, return_counts=True, ) 	 25401601 	 1000 	 3.2405834197998047 	 1.0106613636016846 	 7.319450378417969e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:45:47.888606 test begin: paddle.unique_consecutive(Tensor([2540],"float64"), return_inverse=True, return_counts=True, axis=-1, )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([2540],"float64"), return_inverse=True, return_counts=True, axis=-1, ) 	 2540 	 1000 	 1.4286718368530273 	 0.1758406162261963 	 4.696846008300781e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 15:45:49.661137 test begin: paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, )
Warning: The core code of paddle.unsqueeze is too complex.
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, ) 	 262144000 	 1000 	 0.004275798797607422 	 0.0037081241607666016 	 1.8358230590820312e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:45:58.093916 test begin: paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, ) 	 508160000 	 1000 	 0.008776187896728516 	 0.006386518478393555 	 1.0728836059570312e-05 	 6.556510925292969e-05 	 0.06266307830810547 	 0.0603175163269043 	 7.319450378417969e-05 	 5.459785461425781e-05 	 
2025-07-30 15:46:17.062988 test begin: paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, ) 	 254033920 	 1000 	 0.004156827926635742 	 0.0036742687225341797 	 1.2159347534179688e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:46:25.293121 test begin: paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, ) 	 254033920 	 1000 	 0.006165504455566406 	 0.003723621368408203 	 1.4781951904296875e-05 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:46:33.426074 test begin: paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, ) 	 509050880 	 1000 	 0.0068492889404296875 	 0.0036361217498779297 	 3.814697265625e-05 	 2.002716064453125e-05 	 0.04637002944946289 	 0.05798697471618652 	 3.5762786865234375e-05 	 5.173683166503906e-05 	 
2025-07-30 15:46:50.217471 test begin: paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, ) 	 508144000 	 1000 	 0.004376888275146484 	 0.0036690235137939453 	 8.344650268554688e-06 	 1.7404556274414062e-05 	 0.046514034271240234 	 0.05905032157897949 	 2.5272369384765625e-05 	 6.794929504394531e-05 	 
2025-07-30 15:47:07.037163 test begin: paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, ) 	 508559360 	 1000 	 0.004369974136352539 	 0.003658294677734375 	 1.2159347534179688e-05 	 1.811981201171875e-05 	 0.0464785099029541 	 0.057732582092285156 	 2.4318695068359375e-05 	 4.410743713378906e-05 	 
2025-07-30 15:47:23.916540 test begin: paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, ) 	 508160000 	 1000 	 0.004488945007324219 	 0.005533456802368164 	 2.6226043701171875e-05 	 5.173683166503906e-05 	 0.05055999755859375 	 0.06041741371154785 	 5.745887756347656e-05 	 6.651878356933594e-05 	 
2025-07-30 15:47:43.970256 test begin: paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-1, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-1, ) 	 50803350 	 1000 	 0.32696533203125 	 0.019524097442626953 	 0.3011140823364258 	 6.079673767089844e-05 	 0.4754652976989746 	 4.484212160110474 	 0.39618372917175293 	 4.306644678115845 	 
2025-07-30 15:47:50.995976 test begin: paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-2, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-2, ) 	 50803350 	 1000 	 0.4038398265838623 	 0.013262033462524414 	 0.3828575611114502 	 2.2172927856445312e-05 	 0.35105013847351074 	 1.262876033782959 	 0.2794151306152344 	 1.1198058128356934 	 
2025-07-30 15:47:54.527614 test begin: paddle.unstack(Tensor([5, 10, 1016065],"float32"), axis=-2, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([5, 10, 1016065],"float32"), axis=-2, ) 	 50803250 	 1000 	 0.3888561725616455 	 0.014500617980957031 	 0.36623048782348633 	 3.910064697265625e-05 	 0.33118677139282227 	 0.306201696395874 	 0.2398364543914795 	 0.16735291481018066 	 
2025-07-30 15:47:57.293993 test begin: paddle.unstack(Tensor([5, 677377, 15],"float32"), axis=-1, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([5, 677377, 15],"float32"), axis=-1, ) 	 50803275 	 1000 	 0.32698607444763184 	 0.01804494857788086 	 0.2855062484741211 	 2.193450927734375e-05 	 0.4792211055755615 	 4.4779064655303955 	 0.38588953018188477 	 4.281428098678589 	 
2025-07-30 15:48:04.126303 test begin: paddle.unstack(x=Tensor([2, 32, 793801],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([2, 32, 793801],"float32"), axis=0, ) 	 50803264 	 1000 	 0.38936662673950195 	 0.005344867706298828 	 0.37653589248657227 	 3.24249267578125e-05 	 0.3496232032775879 	 0.30942559242248535 	 0.2888185977935791 	 0.22408437728881836 	 
2025-07-30 15:48:06.880946 test begin: paddle.unstack(x=Tensor([2, 49613, 512],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([2, 49613, 512],"float32"), axis=0, ) 	 50803712 	 1000 	 0.3847212791442871 	 0.0053043365478515625 	 0.3718705177307129 	 1.7642974853515625e-05 	 0.3516819477081299 	 0.3056364059448242 	 0.29446840286254883 	 0.22072482109069824 	 
2025-07-30 15:48:09.770696 test begin: paddle.unstack(x=Tensor([3101, 32, 512],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([3101, 32, 512],"float32"), axis=0, ) 	 50806784 	 1000 	 3.7439234256744385 	 5.852741241455078 	 0.00010967254638671875 	 0.00017499923706054688 	 5.506227731704712 	 20.686758995056152 	 5.698204040527344e-05 	 0.0002465248107910156 	 
2025-07-30 15:48:48.472523 test begin: paddle.var(Tensor([264601, 192, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([264601, 192, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803392 	 1000 	 1.310359239578247 	 0.27466630935668945 	 0.11082863807678223 	 0.25812506675720215 	 1.5762701034545898 	 0.777259349822998 	 0.2683134078979492 	 0.19852209091186523 	 
2025-07-30 15:48:53.334043 test begin: paddle.var(Tensor([384, 132301, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 132301, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803584 	 1000 	 1.036689043045044 	 0.18568134307861328 	 0.07657146453857422 	 0.09485149383544922 	 13.772008895874023 	 0.7738742828369141 	 2.012371778488159 	 0.15787792205810547 	 
2025-07-30 15:49:10.070133 test begin: paddle.var(Tensor([384, 192, 1, 690],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 192, 1, 690],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50872320 	 1000 	 1.0221953392028809 	 0.18001413345336914 	 0.07450032234191895 	 0.09266328811645508 	 1.3777236938476562 	 0.7713479995727539 	 0.202056884765625 	 0.1576521396636963 	 
2025-07-30 15:49:14.401629 test begin: paddle.var(Tensor([384, 192, 690, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 192, 690, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50872320 	 1000 	 1.02042555809021 	 0.17856073379516602 	 0.0743856430053711 	 0.0912327766418457 	 13.523753643035889 	 0.7725300788879395 	 1.9773132801055908 	 0.15785717964172363 	 
2025-07-30 15:49:30.832188 test begin: paddle.var(Tensor([384, 96, 1, 1379],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 96, 1, 1379],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50835456 	 1000 	 1.020338773727417 	 0.18100595474243164 	 0.07439565658569336 	 0.09251093864440918 	 1.3772814273834229 	 0.7749407291412354 	 0.20070719718933105 	 0.15810012817382812 	 
2025-07-30 15:49:35.074024 test begin: paddle.var(Tensor([384, 96, 1379, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 96, 1379, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50835456 	 1000 	 1.0220816135406494 	 0.18094205856323242 	 0.0745534896850586 	 0.09246277809143066 	 13.777695894241333 	 0.7736592292785645 	 2.0133347511291504 	 0.15813899040222168 	 
2025-07-30 15:49:51.710932 test begin: paddle.var(Tensor([529201, 96, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([529201, 96, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803296 	 1000 	 1.2862491607666016 	 0.4555797576904297 	 0.10914897918701172 	 0.43715500831604004 	 1.5912954807281494 	 0.8221549987792969 	 0.2705566883087158 	 0.20992231369018555 	 
2025-07-30 15:49:56.752293 test begin: paddle.var(Tensor([58801, 96, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([58801, 96, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50804064 	 1000 	 0.9789433479309082 	 0.17686128616333008 	 0.08303976058959961 	 0.1606907844543457 	 1.3614096641540527 	 0.7702968120574951 	 0.2314586639404297 	 0.19630670547485352 	 
2025-07-30 15:50:00.967442 test begin: paddle.var(Tensor([96, 58801, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 58801, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50804064 	 1000 	 0.9942290782928467 	 0.21616220474243164 	 0.0723416805267334 	 0.11042284965515137 	 1.3472044467926025 	 0.7877814769744873 	 0.19759798049926758 	 0.16068530082702637 	 
2025-07-30 15:50:05.249064 test begin: paddle.var(Tensor([96, 96, 1838, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 96, 1838, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50817024 	 1000 	 0.9911372661590576 	 0.21192312240600586 	 0.07221078872680664 	 0.10828423500061035 	 1.345855712890625 	 0.7872350215911865 	 0.19632506370544434 	 0.16203022003173828 	 
2025-07-30 15:50:09.450501 test begin: paddle.var(Tensor([96, 96, 3, 1838],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 96, 3, 1838],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50817024 	 1000 	 0.9886147975921631 	 0.21196961402893066 	 0.07206392288208008 	 0.1083219051361084 	 1.3472082614898682 	 0.7870907783508301 	 0.19622397422790527 	 0.16054105758666992 	 
2025-07-30 15:50:13.648339 test begin: paddle.vecdot(Tensor([12700801, 4],"float32"), Tensor([12700801, 4],"float32"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([12700801, 4],"float32"), Tensor([12700801, 4],"float32"), axis=-1, ) 	 101606408 	 1000 	 1.1511602401733398 	 0.9349431991577148 	 0.3919086456298828 	 0.4759974479675293 	 1.5930838584899902 	 0.6833934783935547 	 0.5434815883636475 	 0.34912753105163574 	 combined
2025-07-30 15:50:19.953227 test begin: paddle.vecdot(Tensor([1270081, 4, 5],"float64"), Tensor([1270081, 4, 5],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([1270081, 4, 5],"float64"), Tensor([1270081, 4, 5],"float64"), axis=1, ) 	 50803240 	 1000 	 1.0316565036773682 	 0.6502101421356201 	 0.35103702545166016 	 0.32317399978637695 	 1.2443265914916992 	 0.672980785369873 	 0.4236304759979248 	 0.3438143730163574 	 combined
2025-07-30 15:50:24.860893 test begin: paddle.vecdot(Tensor([2, 3, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2, 3, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), axis=-1, ) 	 50803212 	 1000 	 0.985771894454956 	 0.596264123916626 	 0.2522745132446289 	 0.20288610458374023 	 1.1797571182250977 	 0.6010093688964844 	 0.40213823318481445 	 0.30696582794189453 	 combined
2025-07-30 15:50:30.533056 test begin: paddle.vecdot(Tensor([2, 3175201, 4],"float64"), Tensor([2, 3175201, 4],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2, 3175201, 4],"float64"), Tensor([2, 3175201, 4],"float64"), axis=-1, ) 	 50803216 	 1000 	 0.9974901676177979 	 0.7227089405059814 	 0.33989429473876953 	 0.36607861518859863 	 1.2431161403656006 	 0.6733975410461426 	 0.42360997200012207 	 0.34335827827453613 	 combined
2025-07-30 15:50:37.142016 test begin: paddle.vecdot(Tensor([2116801, 3, 4],"float64"), Tensor([2116801, 3, 4],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2116801, 3, 4],"float64"), Tensor([2116801, 3, 4],"float64"), axis=-1, ) 	 50803224 	 1000 	 0.9975152015686035 	 0.7165558338165283 	 0.339874267578125 	 0.3660471439361572 	 1.2444744110107422 	 0.6748788356781006 	 0.4250047206878662 	 0.3448023796081543 	 combined
2025-07-30 15:50:42.022811 test begin: paddle.vecdot(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), axis=-1, ) 	 101606406 	 1000 	 0.964515209197998 	 0.6002457141876221 	 0.24712419509887695 	 0.20376849174499512 	 1.525606393814087 	 0.6068565845489502 	 0.5218930244445801 	 0.31000351905822754 	 combined
2025-07-30 15:50:47.512087 test begin: paddle.vecdot(Tensor([3, 1693441, 5],"float64"), Tensor([3, 1693441, 5],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 1693441, 5],"float64"), Tensor([3, 1693441, 5],"float64"), axis=1, ) 	 50803230 	 1000 	 7.031573057174683 	 0.599590539932251 	 1.7997362613677979 	 0.20403814315795898 	 1.181516170501709 	 0.6014556884765625 	 0.4022090435028076 	 0.3072516918182373 	 combined
2025-07-30 15:50:58.122247 test begin: paddle.vecdot(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), axis=1, ) 	 50803224 	 1000 	 0.9341456890106201 	 0.6309301853179932 	 0.32004404067993164 	 0.3224186897277832 	 1.3397529125213623 	 0.90061354637146 	 0.45604801177978516 	 0.46091580390930176 	 combined
2025-07-30 15:51:03.123432 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.014132261276245117 	 0.003968954086303711 	 3.075599670410156e-05 	 1.71661376953125e-05 	 0.045932769775390625 	 0.07306528091430664 	 4.744529724121094e-05 	 5.412101745605469e-05 	 
2025-07-30 15:51:19.704692 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013373374938964844 	 0.004073143005371094 	 2.288818359375e-05 	 1.8835067749023438e-05 	 0.04603743553161621 	 0.05749249458312988 	 3.1948089599609375e-05 	 3.457069396972656e-05 	 
2025-07-30 15:51:43.590007 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013392925262451172 	 0.004539966583251953 	 2.002716064453125e-05 	 5.364418029785156e-05 	 0.04685235023498535 	 0.058567047119140625 	 3.2901763916015625e-05 	 6.723403930664062e-05 	 
2025-07-30 15:52:01.618467 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013965368270874023 	 0.0040929317474365234 	 2.193450927734375e-05 	 1.7881393432617188e-05 	 0.04609394073486328 	 0.05865359306335449 	 5.6743621826171875e-05 	 7.104873657226562e-05 	 
2025-07-30 15:52:18.273408 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013489723205566406 	 0.004547834396362305 	 1.8596649169921875e-05 	 5.316734313964844e-05 	 0.04581093788146973 	 0.05950140953063965 	 4.2438507080078125e-05 	 7.343292236328125e-05 	 
2025-07-30 15:52:34.875421 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013580322265625 	 0.0040018558502197266 	 1.049041748046875e-05 	 1.8358230590820312e-05 	 0.04592275619506836 	 0.05730938911437988 	 4.673004150390625e-05 	 6.365776062011719e-05 	 
2025-07-30 15:52:54.152503 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013329744338989258 	 0.0039730072021484375 	 1.4543533325195312e-05 	 1.6927719116210938e-05 	 0.04750561714172363 	 0.056322574615478516 	 2.1696090698242188e-05 	 5.507469177246094e-05 	 
2025-07-30 15:53:11.031209 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013652563095092773 	 0.004040241241455078 	 9.5367431640625e-06 	 1.7404556274414062e-05 	 0.04595375061035156 	 0.058591365814208984 	 4.9591064453125e-05 	 7.390975952148438e-05 	 
2025-07-30 15:53:27.941448 test begin: paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), )
[Prof] paddle.view_as 	 paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), ) 	 101608000 	 1000 	 0.014048576354980469 	 0.0033676624298095703 	 1.2636184692382812e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 15:53:30.558976 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], )
W0730 15:53:41.023397 32323 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.03125119209289551 	 0.014081001281738281 	 1.9550323486328125e-05 	 7.677078247070312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:53:42.774215 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], )
W0730 15:53:51.067852 32878 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.017223119735717773 	 0.0071392059326171875 	 1.1682510375976562e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:53:54.836272 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], )
W0730 15:54:01.834745 33515 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.024226903915405273 	 0.008137941360473633 	 2.09808349609375e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:54:03.050150 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], )
W0730 15:54:13.539640 34118 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.031100034713745117 	 0.009346723556518555 	 2.1457672119140625e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:54:15.193710 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], )
W0730 15:54:22.267117 34903 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.016998767852783203 	 0.007191181182861328 	 1.2636184692382812e-05 	 2.765655517578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:54:24.177862 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], )
W0730 15:54:31.312465 35516 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.024034976959228516 	 0.008142232894897461 	 1.621246337890625e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:54:32.428855 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], )
W0730 15:54:42.796929 36122 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.031744956970214844 	 0.009478569030761719 	 5.245208740234375e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:54:44.631243 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], )
W0730 15:54:51.658150 36752 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.01707744598388672 	 0.007211208343505859 	 3.075599670410156e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:54:52.646487 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], )
W0730 15:55:00.096477 37148 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.029175281524658203 	 0.008177518844604492 	 4.673004150390625e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 15:55:01.720712 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9417965412139893 	 0.9221923351287842 	 0.1604158878326416 	 0.907310962677002 	 0.9561598300933838 	 0.08550786972045898 	 0.16356110572814941 	 6.556510925292969e-05 	 
2025-07-30 15:55:07.971856 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], name=None, ) 	 76204872 	 1000 	 0.9417812824249268 	 0.923835277557373 	 0.1604173183441162 	 0.9091002941131592 	 0.9520981311798096 	 0.09571027755737305 	 0.16213750839233398 	 6.818771362304688e-05 	 
2025-07-30 15:55:14.076861 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.31514930725097656 	 0.31322789192199707 	 0.1610276699066162 	 0.1599721908569336 	 0.3175046443939209 	 0.06009531021118164 	 0.1614534854888916 	 5.793571472167969e-05 	 
2025-07-30 15:55:16.233742 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3135097026824951 	 0.32338833808898926 	 0.08024120330810547 	 0.3089287281036377 	 0.3224790096282959 	 0.08187603950500488 	 0.08252120018005371 	 7.462501525878906e-05 	 
2025-07-30 15:55:18.479021 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.3135387897491455 	 0.3230273723602295 	 0.08024954795837402 	 0.308551549911499 	 0.3237745761871338 	 0.0768585205078125 	 0.08250808715820312 	 4.6253204345703125e-05 	 
2025-07-30 15:55:20.682577 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3158113956451416 	 0.3203604221343994 	 0.08055472373962402 	 0.3060152530670166 	 0.32537198066711426 	 0.07996582984924316 	 0.08291912078857422 	 0.0001628398895263672 	 
2025-07-30 15:55:22.822147 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.3157641887664795 	 0.3203458786010742 	 0.0805199146270752 	 0.3059849739074707 	 0.3268153667449951 	 0.08492851257324219 	 0.08293318748474121 	 7.724761962890625e-05 	 
2025-07-30 15:55:24.938101 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9389069080352783 	 0.9189150333404541 	 0.15991640090942383 	 0.9039828777313232 	 0.9394211769104004 	 0.0785822868347168 	 0.15946197509765625 	 7.390975952148438e-05 	 
2025-07-30 15:55:31.063091 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], name=None, ) 	 76204980 	 1000 	 0.9390153884887695 	 0.9335250854492188 	 0.15991449356079102 	 0.9034175872802734 	 0.9365444183349609 	 0.08058452606201172 	 0.15949249267578125 	 0.00010275840759277344 	 
2025-07-30 15:55:39.291925 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3084895610809326 	 0.33387279510498047 	 0.15688371658325195 	 0.16000151634216309 	 0.3091254234313965 	 0.06161904335021973 	 0.15861177444458008 	 6.842613220214844e-05 	 
2025-07-30 15:55:41.383941 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.942925214767456 	 0.9291706085205078 	 0.16063451766967773 	 0.9142959117889404 	 0.9516499042510986 	 0.07941579818725586 	 0.16159510612487793 	 4.601478576660156e-05 	 
2025-07-30 15:55:47.521370 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], name=None, ) 	 76204890 	 1000 	 0.9458093643188477 	 0.9292171001434326 	 0.16204404830932617 	 0.9142522811889648 	 0.9488182067871094 	 0.08149957656860352 	 0.16159391403198242 	 6.127357482910156e-05 	 
2025-07-30 15:55:53.741979 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3151061534881592 	 0.3132517337799072 	 0.16098356246948242 	 0.15996623039245605 	 0.31606364250183105 	 0.06315827369689941 	 0.1614534854888916 	 6.914138793945312e-05 	 
2025-07-30 15:55:55.815514 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3132619857788086 	 0.3111758232116699 	 0.07987427711486816 	 0.2968258857727051 	 0.3198966979980469 	 0.08020377159118652 	 0.08153939247131348 	 7.677078247070312e-05 	 
2025-07-30 15:55:58.379457 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.31316137313842773 	 0.311084508895874 	 0.07985591888427734 	 0.29668617248535156 	 0.31992316246032715 	 0.07941365242004395 	 0.08155369758605957 	 7.62939453125e-05 	 
2025-07-30 15:56:02.217936 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9382631778717041 	 0.9225063323974609 	 0.15982961654663086 	 0.9074318408966064 	 0.9441335201263428 	 0.07833456993103027 	 0.1605699062347412 	 6.508827209472656e-05 	 
2025-07-30 15:56:08.267923 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, ) 	 76204920 	 1000 	 0.9427282810211182 	 0.9224283695220947 	 0.16143560409545898 	 0.9055838584899902 	 0.9429178237915039 	 0.08398866653442383 	 0.16057062149047852 	 7.43865966796875e-05 	 
2025-07-30 15:56:14.543332 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3084850311279297 	 0.313265323638916 	 0.1568765640258789 	 0.15997862815856934 	 0.30769848823547363 	 0.05868840217590332 	 0.15718817710876465 	 4.410743713378906e-05 	 
2025-07-30 15:56:16.582900 test begin: paddle.where(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"float32"), Tensor([1, 400, 127009],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"float32"), Tensor([1, 400, 127009],"float32"), ) 	 152410800 	 1000 	 0.48598146438598633 	 0.4844791889190674 	 0.464524507522583 	 0.47084617614746094 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:21.267861 test begin: paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), ) 	 105369600 	 1000 	 0.9350907802581787 	 0.5168206691741943 	 0.3187239170074463 	 0.5016968250274658 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:26.225828 test begin: paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), ) 	 105369600 	 1000 	 0.9365148544311523 	 0.516124963760376 	 0.32010602951049805 	 0.499131441116333 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:31.019772 test begin: paddle.where(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"float32"), Tensor([1, 772, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"float32"), Tensor([1, 772, 65856],"float32"), ) 	 152522496 	 1000 	 0.48874568939208984 	 0.9493627548217773 	 0.4694366455078125 	 0.4677445888519287 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:39.376330 test begin: paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), ) 	 105369600 	 1000 	 1.1176824569702148 	 0.5178103446960449 	 0.3803114891052246 	 0.5017597675323486 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:44.701747 test begin: paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), ) 	 158054400 	 1000 	 0.5031554698944092 	 0.5055577754974365 	 0.48381900787353516 	 0.4864938259124756 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:49.667674 test begin: paddle.where(Tensor([4, 125, 320, 320],"bool"), Tensor([4, 125, 320, 320],"float32"), Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 125, 320, 320],"bool"), Tensor([4, 125, 320, 320],"float32"), Tensor([4, 125, 320, 320],"float32"), ) 	 153600000 	 1000 	 0.488863468170166 	 0.48805737495422363 	 0.46083736419677734 	 0.473980188369751 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:54.468166 test begin: paddle.where(Tensor([4, 280, 376, 25, 5],"bool"), Tensor([4, 280, 376, 25, 5],"float32"), Tensor([4, 280, 376, 25, 5],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 376, 25, 5],"bool"), Tensor([4, 280, 376, 25, 5],"float32"), Tensor([4, 280, 376, 25, 5],"float32"), ) 	 157920000 	 1000 	 0.5026500225067139 	 0.5154318809509277 	 0.4828629493713379 	 0.4868001937866211 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:56:59.352241 test begin: paddle.where(Tensor([4, 280, 376, 41, 3],"bool"), Tensor([4, 280, 376, 41, 3],"float32"), Tensor([4, 280, 376, 41, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 376, 41, 3],"bool"), Tensor([4, 280, 376, 41, 3],"float32"), Tensor([4, 280, 376, 41, 3],"float32"), ) 	 155393280 	 1000 	 0.49410557746887207 	 0.49425292015075684 	 0.47414374351501465 	 0.48050451278686523 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:04.124267 test begin: paddle.where(Tensor([4, 280, 605, 25, 3],"bool"), Tensor([4, 280, 605, 25, 3],"float32"), Tensor([4, 280, 605, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 605, 25, 3],"bool"), Tensor([4, 280, 605, 25, 3],"float32"), Tensor([4, 280, 605, 25, 3],"float32"), ) 	 152460000 	 1000 	 0.4850642681121826 	 0.48702120780944824 	 0.4653892517089844 	 0.47052502632141113 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:10.803559 test begin: paddle.where(Tensor([4, 451, 376, 25, 3],"bool"), Tensor([4, 451, 376, 25, 3],"float32"), Tensor([4, 451, 376, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 451, 376, 25, 3],"bool"), Tensor([4, 451, 376, 25, 3],"float32"), Tensor([4, 451, 376, 25, 3],"float32"), ) 	 152618400 	 1000 	 0.4853222370147705 	 0.48557376861572266 	 0.464780330657959 	 0.4704396724700928 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:15.833827 test begin: paddle.where(Tensor([4, 64, 320, 621],"bool"), Tensor([4, 64, 320, 621],"float32"), Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 64, 320, 621],"bool"), Tensor([4, 64, 320, 621],"float32"), Tensor([4, 64, 320, 621],"float32"), ) 	 152616960 	 1000 	 0.48578977584838867 	 0.5016329288482666 	 0.46607279777526855 	 0.470348596572876 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:20.725260 test begin: paddle.where(Tensor([4, 64, 621, 320],"bool"), Tensor([4, 64, 621, 320],"float32"), Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 64, 621, 320],"bool"), Tensor([4, 64, 621, 320],"float32"), Tensor([4, 64, 621, 320],"float32"), ) 	 152616960 	 1000 	 0.4859170913696289 	 0.487628698348999 	 0.46629858016967773 	 0.47026801109313965 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:25.532308 test begin: paddle.where(Tensor([7, 280, 376, 25, 3],"bool"), Tensor([7, 280, 376, 25, 3],"float32"), Tensor([7, 280, 376, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([7, 280, 376, 25, 3],"bool"), Tensor([7, 280, 376, 25, 3],"float32"), Tensor([7, 280, 376, 25, 3],"float32"), ) 	 165816000 	 1000 	 0.5274639129638672 	 0.5328934192657471 	 0.5076892375946045 	 0.5119743347167969 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:30.682665 test begin: paddle.where(Tensor([8, 64, 320, 320],"bool"), Tensor([8, 64, 320, 320],"float32"), Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([8, 64, 320, 320],"bool"), Tensor([8, 64, 320, 320],"float32"), Tensor([8, 64, 320, 320],"float32"), ) 	 157286400 	 1000 	 0.5012574195861816 	 0.5057616233825684 	 0.4815943241119385 	 0.4853799343109131 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 15:57:37.589613 test begin: paddle.zeros_like(Tensor([16, 64, 320, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([16, 64, 320, 320],"float16"), ) 	 104857600 	 1000 	 0.13840818405151367 	 0.1594865322113037 	 0.127150297164917 	 0.12646245956420898 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:39.891139 test begin: paddle.zeros_like(Tensor([4, 1051, 12096],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 1051, 12096],"float32"), ) 	 50851584 	 1000 	 0.13419508934020996 	 0.13834667205810547 	 0.12308382987976074 	 0.12290143966674805 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:41.030257 test begin: paddle.zeros_like(Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 125, 320, 320],"float32"), ) 	 51200000 	 1000 	 0.13504338264465332 	 0.13609528541564941 	 0.1239931583404541 	 0.12378668785095215 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:42.157521 test begin: paddle.zeros_like(Tensor([4, 249, 320, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 249, 320, 320],"float16"), ) 	 101990400 	 1000 	 0.13446664810180664 	 0.13458657264709473 	 0.12346267700195312 	 0.12252283096313477 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:44.498008 test begin: paddle.zeros_like(Tensor([4, 525, 24193],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 525, 24193],"float32"), ) 	 50805300 	 1000 	 0.13407182693481445 	 0.1342179775238037 	 0.12310910224914551 	 0.12264084815979004 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:45.631693 test begin: paddle.zeros_like(Tensor([4, 64, 1241, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 1241, 320],"float16"), ) 	 101662720 	 1000 	 0.13399147987365723 	 0.13416481018066406 	 0.12296605110168457 	 0.12280869483947754 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:47.795245 test begin: paddle.zeros_like(Tensor([4, 64, 320, 1241],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 320, 1241],"float16"), ) 	 101662720 	 1000 	 0.1342005729675293 	 0.1519310474395752 	 0.12316036224365234 	 0.12399029731750488 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:50.029226 test begin: paddle.zeros_like(Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 320, 621],"float32"), ) 	 50872320 	 1000 	 0.1344923973083496 	 0.14362621307373047 	 0.12340617179870605 	 0.1224679946899414 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:51.190999 test begin: paddle.zeros_like(Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 621, 320],"float32"), ) 	 50872320 	 1000 	 0.13423895835876465 	 0.13443207740783691 	 0.12304019927978516 	 0.12201476097106934 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:52.261864 test begin: paddle.zeros_like(Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([8, 64, 320, 320],"float32"), ) 	 52428800 	 1000 	 0.13822484016418457 	 0.1384115219116211 	 0.12725520133972168 	 0.12685203552246094 	 None 	 None 	 None 	 None 	 
2025-07-30 15:57:53.433925 test begin: paddle.zeros_like(Tensor([9, 525, 12096],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([9, 525, 12096],"float32"), ) 	 57153600 	 1000 	 0.1504964828491211 	 0.15325212478637695 	 0.13953042030334473 	 0.13953232765197754 	 None 	 None 	 None 	 None 	 
Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/base/libpaddle.so