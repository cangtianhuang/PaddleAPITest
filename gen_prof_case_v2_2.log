2025-07-30 19:24:14.437112 test begin: paddle.abs(Tensor([13, 64, 256, 256],"float32"), )
W0730 19:24:15.597132 23402 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.abs 	 paddle.abs(Tensor([13, 64, 256, 256],"float32"), ) 	 54525952 	 1000 	 0.31760668754577637 	 0.32040882110595703 	 0.30811047554016113 	 0.3055844306945801 	 0.4830777645111084 	 0.7982008457183838 	 0.42790842056274414 	 0.40714120864868164 	 
2025-07-30 19:24:18.927591 test begin: paddle.abs(Tensor([16, 128, 128, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 128, 128, 194],"float32"), ) 	 50855936 	 1000 	 0.29651522636413574 	 0.29831457138061523 	 0.2868218421936035 	 0.2854018211364746 	 0.4506559371948242 	 0.7437591552734375 	 0.39624834060668945 	 0.3800032138824463 	 
2025-07-30 19:24:22.891251 test begin: paddle.abs(Tensor([16, 128, 194, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 128, 194, 128],"float32"), ) 	 50855936 	 1000 	 0.2981550693511963 	 0.2981376647949219 	 0.2868776321411133 	 0.2852632999420166 	 0.4507420063018799 	 0.7437832355499268 	 0.396381139755249 	 0.3800170421600342 	 
2025-07-30 19:24:26.438134 test begin: paddle.abs(Tensor([16, 194, 128, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 194, 128, 128],"float32"), ) 	 50855936 	 1000 	 0.29650139808654785 	 0.2981302738189697 	 0.28700971603393555 	 0.2851548194885254 	 0.45073843002319336 	 0.7436652183532715 	 0.3963632583618164 	 0.37998175621032715 	 
2025-07-30 19:24:29.936315 test begin: paddle.abs(Tensor([16, 256, 194, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 256, 194, 64],"float32"), ) 	 50855936 	 1000 	 0.29642581939697266 	 0.29818081855773926 	 0.28000426292419434 	 0.28531408309936523 	 0.45078301429748535 	 0.7436764240264893 	 0.39662790298461914 	 0.38001346588134766 	 
2025-07-30 19:24:33.531460 test begin: paddle.abs(Tensor([16, 256, 64, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 256, 64, 194],"float32"), ) 	 50855936 	 1000 	 0.2964034080505371 	 0.7461075782775879 	 0.28693175315856934 	 0.28335094451904297 	 0.45103931427001953 	 0.7436299324035645 	 0.39505457878112793 	 0.37990307807922363 	 
2025-07-30 19:24:39.346285 test begin: paddle.abs(Tensor([16, 49, 256, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 49, 256, 256],"float32"), ) 	 51380224 	 1000 	 0.3031015396118164 	 0.3012089729309082 	 0.28993773460388184 	 0.28821802139282227 	 0.45674848556518555 	 0.751276969909668 	 0.40087175369262695 	 0.383861780166626 	 
2025-07-30 19:24:42.865915 test begin: paddle.abs(Tensor([16, 64, 194, 256],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 64, 194, 256],"float32"), ) 	 50855936 	 1000 	 0.2964918613433838 	 0.3038902282714844 	 0.2869088649749756 	 0.28519678115844727 	 0.45086097717285156 	 0.7445664405822754 	 0.39635682106018066 	 0.38089513778686523 	 
2025-07-30 19:24:46.361479 test begin: paddle.abs(Tensor([16, 64, 256, 194],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 64, 256, 194],"float32"), ) 	 50855936 	 1000 	 0.2964496612548828 	 0.298184871673584 	 0.2868821620941162 	 0.2852821350097656 	 0.45076584815979004 	 0.743811845779419 	 0.3960731029510498 	 0.37999796867370605 	 
2025-07-30 19:24:50.000189 test begin: paddle.abs(Tensor([16, 776, 64, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([16, 776, 64, 64],"float32"), ) 	 50855936 	 1000 	 0.29645204544067383 	 0.29816770553588867 	 0.28705835342407227 	 0.2846510410308838 	 0.45070481300354004 	 0.7436685562133789 	 0.3966331481933594 	 0.37991786003112793 	 
2025-07-30 19:24:53.392795 test begin: paddle.abs(Tensor([25, 128, 128, 128],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([25, 128, 128, 128],"float32"), ) 	 52428800 	 1000 	 0.3066089153289795 	 0.3130335807800293 	 0.29593515396118164 	 0.2936861515045166 	 0.46465635299682617 	 0.7667450904846191 	 0.41025853157043457 	 0.39180660247802734 	 
2025-07-30 19:24:58.881415 test begin: paddle.abs(Tensor([49, 256, 64, 64],"float32"), )
[Prof] paddle.abs 	 paddle.abs(Tensor([49, 256, 64, 64],"float32"), ) 	 51380224 	 1000 	 1.9159607887268066 	 0.3012380599975586 	 0.2897770404815674 	 0.28779053688049316 	 0.4554758071899414 	 0.7513113021850586 	 0.39755916595458984 	 0.3838469982147217 	 
2025-07-30 19:25:04.709282 test begin: paddle.acos(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29587674140930176 	 0.29776430130004883 	 0.28673839569091797 	 0.286541223526001 	 0.4505302906036377 	 2.080313205718994 	 0.3966507911682129 	 0.35442471504211426 	 
2025-07-30 19:25:09.582017 test begin: paddle.acos(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2959024906158447 	 0.2989158630371094 	 0.28685712814331055 	 0.28626394271850586 	 0.4505741596221924 	 2.0801658630371094 	 0.3965878486633301 	 0.35439181327819824 	 
2025-07-30 19:25:14.364157 test begin: paddle.acos(Tensor([10, 5080321],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29589247703552246 	 0.29764771461486816 	 0.2869112491607666 	 0.2864866256713867 	 0.45026445388793945 	 2.0803349018096924 	 0.3966996669769287 	 0.35438060760498047 	 
2025-07-30 19:25:19.026122 test begin: paddle.acos(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29595184326171875 	 0.2978978157043457 	 0.2869853973388672 	 0.28673338890075684 	 0.4506087303161621 	 2.0803565979003906 	 0.39678525924682617 	 0.3544013500213623 	 
2025-07-30 19:25:23.906922 test begin: paddle.acos(Tensor([5080321, 10],"float32"), )
[Prof] paddle.acos 	 paddle.acos(Tensor([5080321, 10],"float32"), ) 	 50803210 	 1000 	 0.2958986759185791 	 0.2977128028869629 	 0.28698158264160156 	 0.28645968437194824 	 0.45059847831726074 	 2.080251455307007 	 0.39693164825439453 	 0.3543829917907715 	 
2025-07-30 19:25:28.589059 test begin: paddle.acos(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.29595375061035156 	 0.2978699207305908 	 0.2766153812408447 	 0.28539395332336426 	 0.45073390007019043 	 2.0803380012512207 	 0.39726734161376953 	 0.35454511642456055 	 
2025-07-30 19:25:33.595775 test begin: paddle.acos(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.2971532344818115 	 0.310044527053833 	 0.2796804904937744 	 0.27986955642700195 	 0.4505906105041504 	 2.0802831649780273 	 0.3854060173034668 	 0.35433053970336914 	 
2025-07-30 19:25:41.972018 test begin: paddle.acos(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.acos 	 paddle.acos(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.2958865165710449 	 0.2977330684661865 	 0.28669047355651855 	 0.28658246994018555 	 0.4505462646484375 	 2.0801517963409424 	 0.39678072929382324 	 0.3543202877044678 	 
2025-07-30 19:25:46.708005 test begin: paddle.acosh(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2954387664794922 	 0.2990283966064453 	 0.2862539291381836 	 0.2877318859100342 	 0.4522218704223633 	 1.3379480838775635 	 0.3986504077911377 	 0.3418309688568115 	 
2025-07-30 19:25:50.669258 test begin: paddle.acosh(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2954139709472656 	 0.29976391792297363 	 0.2861456871032715 	 0.28760361671447754 	 0.45211219787597656 	 1.3378865718841553 	 0.3991355895996094 	 0.3418424129486084 	 
2025-07-30 19:25:54.654867 test begin: paddle.acosh(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.acosh 	 paddle.acosh(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29547667503356934 	 0.2995903491973877 	 0.2862393856048584 	 0.28753066062927246 	 0.45203304290771484 	 1.337888240814209 	 0.3983621597290039 	 0.3418736457824707 	 
2025-07-30 19:25:58.602070 test begin: paddle.add(x=Tensor([2, 256, 320, 352],"float32"), y=Tensor([2, 256, 320, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 320, 352],"float32"), y=Tensor([2, 256, 320, 352],"float32"), ) 	 115343360 	 1000 	 0.5109469890594482 	 0.955162763595581 	 0.5005931854248047 	 0.4938685894012451 	 0.5481312274932861 	 0.0756223201751709 	 0.48498988151550293 	 6.151199340820312e-05 	 
2025-07-30 19:26:08.018275 test begin: paddle.add(x=Tensor([2, 256, 336, 336],"float32"), y=Tensor([2, 256, 336, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 336, 336],"float32"), y=Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.5125749111175537 	 0.5077168941497803 	 0.5024197101593018 	 0.4949331283569336 	 0.5491042137145996 	 0.07612085342407227 	 0.4907715320587158 	 5.698204040527344e-05 	 
2025-07-30 19:26:12.434357 test begin: paddle.add(x=Tensor([2, 256, 352, 352],"float32"), y=Tensor([2, 256, 352, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([2, 256, 352, 352],"float32"), y=Tensor([2, 256, 352, 352],"float32"), ) 	 126877696 	 1000 	 0.5613348484039307 	 0.5565710067749023 	 0.5512096881866455 	 0.5442047119140625 	 0.6021685600280762 	 0.07090330123901367 	 0.5390462875366211 	 3.4332275390625e-05 	 
2025-07-30 19:26:17.143010 test begin: paddle.add(x=Tensor([8, 256, 320, 78],"float32"), y=Tensor([8, 256, 320, 78],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 320, 78],"float32"), y=Tensor([8, 256, 320, 78],"float32"), ) 	 102236160 	 1000 	 0.45322155952453613 	 0.4494321346282959 	 0.4431583881378174 	 0.4373340606689453 	 0.4857368469238281 	 0.07025599479675293 	 0.4273366928100586 	 4.1484832763671875e-05 	 
2025-07-30 19:26:21.096800 test begin: paddle.add(x=Tensor([8, 256, 336, 74],"float32"), y=Tensor([8, 256, 336, 74],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 336, 74],"float32"), y=Tensor([8, 256, 336, 74],"float32"), ) 	 101842944 	 1000 	 0.4515416622161865 	 0.4476594924926758 	 0.44136881828308105 	 0.4352099895477295 	 0.4838275909423828 	 0.0701291561126709 	 0.42548227310180664 	 4.7206878662109375e-05 	 
2025-07-30 19:26:24.901631 test begin: paddle.add(x=Tensor([8, 256, 352, 71],"float32"), y=Tensor([8, 256, 352, 71],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 352, 71],"float32"), y=Tensor([8, 256, 352, 71],"float32"), ) 	 102367232 	 1000 	 0.4537031650543213 	 0.44996190071105957 	 0.4436800479888916 	 0.4310598373413086 	 0.4864382743835449 	 0.07980155944824219 	 0.418764591217041 	 6.818771362304688e-05 	 
2025-07-30 19:26:29.010047 test begin: paddle.add(x=Tensor([8, 256, 71, 352],"float32"), y=Tensor([8, 256, 71, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 71, 352],"float32"), y=Tensor([8, 256, 71, 352],"float32"), ) 	 102367232 	 1000 	 0.45366954803466797 	 0.4498438835144043 	 0.4435560703277588 	 0.4376213550567627 	 0.4864077568054199 	 0.07049727439880371 	 0.4279203414916992 	 7.772445678710938e-05 	 
2025-07-30 19:26:32.924919 test begin: paddle.add(x=Tensor([8, 256, 74, 336],"float32"), y=Tensor([8, 256, 74, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 256, 74, 336],"float32"), y=Tensor([8, 256, 74, 336],"float32"), ) 	 101842944 	 1000 	 0.4515798091888428 	 0.7298741340637207 	 0.44159889221191406 	 0.4327983856201172 	 0.4840240478515625 	 0.0722508430480957 	 0.4233086109161377 	 0.0001361370086669922 	 
2025-07-30 19:26:40.384534 test begin: paddle.add(x=Tensor([8, 52, 352, 352],"float32"), y=Tensor([8, 52, 352, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 52, 352, 352],"float32"), y=Tensor([8, 52, 352, 352],"float32"), ) 	 103088128 	 1000 	 0.46015381813049316 	 0.45404863357543945 	 0.4469895362854004 	 0.44011473655700684 	 0.4900965690612793 	 0.07006335258483887 	 0.43158888816833496 	 4.57763671875e-05 	 
2025-07-30 19:26:44.604934 test begin: paddle.add(x=Tensor([8, 57, 320, 352],"float32"), y=Tensor([8, 57, 320, 352],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 57, 320, 352],"float32"), y=Tensor([8, 57, 320, 352],"float32"), ) 	 102727680 	 1000 	 0.4554708003997803 	 0.4517331123352051 	 0.4380030632019043 	 0.4327983856201172 	 0.48844480514526367 	 0.08278179168701172 	 0.4207780361175537 	 0.0001556873321533203 	 
2025-07-30 19:26:48.687669 test begin: paddle.add(x=Tensor([8, 57, 336, 336],"float32"), y=Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.add 	 paddle.add(x=Tensor([8, 57, 336, 336],"float32"), y=Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.4564549922943115 	 0.45474672317504883 	 0.44637203216552734 	 0.4396193027496338 	 0.4892234802246094 	 0.0701899528503418 	 0.43086743354797363 	 6.914138793945312e-05 	 
2025-07-30 19:26:52.594142 test begin: paddle.add_n(list[Tensor([194, 128, 64, 64],"float16"),Tensor([194, 128, 64, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([194, 128, 64, 64],"float16"),Tensor([194, 128, 64, 64],"float16"),], ) 	 203423744 	 1000 	 0.5725264549255371 	 1.517305850982666 	 0.555072546005249 	 0.7754135131835938 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:26:58.492930 test begin: paddle.add_n(list[Tensor([388, 256, 32, 32],"float16"),Tensor([388, 256, 32, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([388, 256, 32, 32],"float16"),Tensor([388, 256, 32, 32],"float16"),], ) 	 203423744 	 1000 	 0.5720269680023193 	 1.5178024768829346 	 0.5616028308868408 	 0.7756035327911377 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:04.238719 test begin: paddle.add_n(list[Tensor([64, 128, 194, 64],"float16"),Tensor([64, 128, 194, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 194, 64],"float16"),Tensor([64, 128, 194, 64],"float16"),], ) 	 203423744 	 1000 	 0.576444149017334 	 1.5271203517913818 	 0.5648298263549805 	 0.7753069400787354 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:13.146511 test begin: paddle.add_n(list[Tensor([64, 128, 64, 194],"float16"),Tensor([64, 128, 64, 194],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 64, 194],"float16"),Tensor([64, 128, 64, 194],"float16"),], ) 	 203423744 	 1000 	 0.5719497203826904 	 1.5166544914245605 	 0.5615396499633789 	 0.7750260829925537 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:18.884157 test begin: paddle.add_n(list[Tensor([64, 128, 64, 97],"float32"),Tensor([64, 128, 64, 97],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 64, 97],"float32"),Tensor([64, 128, 64, 97],"float32"),], ) 	 101711872 	 1000 	 0.4733858108520508 	 1.0581002235412598 	 0.46291351318359375 	 0.5407071113586426 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:22.052070 test begin: paddle.add_n(list[Tensor([64, 128, 97, 64],"float32"),Tensor([64, 128, 97, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 128, 97, 64],"float32"),Tensor([64, 128, 97, 64],"float32"),], ) 	 101711872 	 1000 	 0.47378110885620117 	 1.0606729984283447 	 0.4632875919342041 	 0.5408773422241211 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:25.163551 test begin: paddle.add_n(list[Tensor([64, 1551, 32, 32],"float16"),Tensor([64, 1551, 32, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 1551, 32, 32],"float16"),Tensor([64, 1551, 32, 32],"float16"),], ) 	 203292672 	 1000 	 0.5739693641662598 	 1.517458438873291 	 0.563546895980835 	 0.775404691696167 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:31.148511 test begin: paddle.add_n(list[Tensor([64, 194, 64, 64],"float32"),Tensor([64, 194, 64, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 194, 64, 64],"float32"),Tensor([64, 194, 64, 64],"float32"),], ) 	 101711872 	 1000 	 0.4737396240234375 	 1.0582363605499268 	 0.46323299407958984 	 0.5408368110656738 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:34.317162 test begin: paddle.add_n(list[Tensor([64, 256, 194, 32],"float16"),Tensor([64, 256, 194, 32],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 256, 194, 32],"float16"),Tensor([64, 256, 194, 32],"float16"),], ) 	 203423744 	 1000 	 1.1032676696777344 	 1.5247375965118408 	 0.5614781379699707 	 0.7756779193878174 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:41.717808 test begin: paddle.add_n(list[Tensor([64, 256, 32, 194],"float16"),Tensor([64, 256, 32, 194],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 256, 32, 194],"float16"),Tensor([64, 256, 32, 194],"float16"),], ) 	 203423744 	 1000 	 0.5752596855163574 	 1.5167498588562012 	 0.5620632171630859 	 0.7750871181488037 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:47.774674 test begin: paddle.add_n(list[Tensor([64, 388, 64, 64],"float16"),Tensor([64, 388, 64, 64],"float16"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([64, 388, 64, 64],"float16"),Tensor([64, 388, 64, 64],"float16"),], ) 	 203423744 	 1000 	 0.5721943378448486 	 1.5171051025390625 	 0.55470871925354 	 0.7752132415771484 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:53.994585 test begin: paddle.add_n(list[Tensor([97, 128, 64, 64],"float32"),Tensor([97, 128, 64, 64],"float32"),], )
[Prof] paddle.add_n 	 paddle.add_n(list[Tensor([97, 128, 64, 64],"float32"),Tensor([97, 128, 64, 64],"float32"),], ) 	 101711872 	 1000 	 0.4733917713165283 	 1.058269739151001 	 0.46301817893981934 	 0.5408000946044922 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:27:57.064630 test begin: paddle.addmm(Tensor([1016065, 50],"float32"), Tensor([1016065, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([1016065, 50],"float32"), Tensor([1016065, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, ) 	 132092450 	 1000 	 1.023195505142212 	 0.9902825355529785 	 0.5208120346069336 	 0.3363981246948242 	 2.6763250827789307 	 1.873631238937378 	 0.3907322883605957 	 0.47799015045166016 	 
2025-07-30 19:28:06.863114 test begin: paddle.addmm(Tensor([30, 1693441],"float32"), Tensor([30, 80],"float32"), Tensor([80, 1693441],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 1693441],"float32"), Tensor([30, 80],"float32"), Tensor([80, 1693441],"float32"), alpha=1.0, beta=2.0, ) 	 186280910 	 1000 	 1.1703362464904785 	 1.1509132385253906 	 0.39865708351135254 	 0.29355478286743164 	 3.2167818546295166 	 2.096757173538208 	 0.41114020347595215 	 0.42830896377563477 	 
2025-07-30 19:28:19.747916 test begin: paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1016065],"float32"), Tensor([1016065, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1016065],"float32"), Tensor([1016065, 50],"float32"), alpha=1.0, beta=2.0, ) 	 81286700 	 1000 	 0.31438374519348145 	 0.31345391273498535 	 0.10717177391052246 	 0.10681843757629395 	 1.0937504768371582 	 0.6131641864776611 	 0.1865251064300537 	 0.2088451385498047 	 
2025-07-30 19:28:23.418205 test begin: paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1693441],"float32"), Tensor([1693441, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 50],"float32"), Tensor([30, 1693441],"float32"), Tensor([1693441, 50],"float32"), alpha=1.0, beta=2.0, ) 	 135476780 	 1000 	 0.5001587867736816 	 0.49431300163269043 	 0.17049360275268555 	 0.16852378845214844 	 1.827502965927124 	 1.0341496467590332 	 0.2339017391204834 	 0.2130134105682373 	 
2025-07-30 19:28:29.663719 test begin: paddle.addmm(Tensor([30, 635041],"float32"), Tensor([30, 80],"float32"), Tensor([80, 635041],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([30, 635041],"float32"), Tensor([30, 80],"float32"), Tensor([80, 635041],"float32"), alpha=1.0, beta=2.0, ) 	 69856910 	 1000 	 0.42284131050109863 	 0.41886019706726074 	 0.21584701538085938 	 0.1426241397857666 	 1.2205102443695068 	 0.7919735908508301 	 0.17817378044128418 	 0.20234036445617676 	 
2025-07-30 19:28:33.897301 test begin: paddle.addmm(Tensor([635041, 50],"float32"), Tensor([635041, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, )
[Prof] paddle.addmm 	 paddle.addmm(Tensor([635041, 50],"float32"), Tensor([635041, 80],"float32"), Tensor([80, 50],"float32"), alpha=1.0, beta=2.0, ) 	 82559330 	 1000 	 1.3107383251190186 	 0.6375038623809814 	 0.3317742347717285 	 0.21457242965698242 	 1.6902437210083008 	 1.1832993030548096 	 0.2467174530029297 	 0.30248141288757324 	 
2025-07-30 19:28:41.600328 test begin: paddle.addmm(input=Tensor([5, 5],"float64"), x=Tensor([5, 5080321],"float64"), y=Tensor([5080321, 5],"float64"), )
[Prof] paddle.addmm 	 paddle.addmm(input=Tensor([5, 5],"float64"), x=Tensor([5, 5080321],"float64"), y=Tensor([5080321, 5],"float64"), ) 	 50803235 	 1000 	 0.6195042133331299 	 0.6212673187255859 	 0.21123337745666504 	 0.21185088157653809 	 3.0035736560821533 	 2.5323541164398193 	 0.21926474571228027 	 0.25881457328796387 	 
2025-07-30 19:28:49.510292 test begin: paddle.all(Tensor([423361, 6, 10],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([423361, 6, 10],"float64"), None, False, None, ) 	 25401660 	 1000 	 0.20099186897277832 	 0.1504042148590088 	 0.06835627555847168 	 0.07677793502807617 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:50.434173 test begin: paddle.all(Tensor([5, 508033, 10],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 508033, 10],"float64"), None, False, None, ) 	 25401650 	 1000 	 0.20116925239562988 	 0.15021467208862305 	 0.06841850280761719 	 0.0767359733581543 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:51.258565 test begin: paddle.all(Tensor([5, 6, 846721],"float64"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([5, 6, 846721],"float64"), None, False, None, ) 	 25401630 	 1000 	 0.20257115364074707 	 0.1503124237060547 	 0.06888628005981445 	 0.07678437232971191 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:52.079062 test begin: paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 1016065, 10],"bool"), None, False, None, ) 	 508032500 	 1000 	 0.464766263961792 	 0.5083773136138916 	 0.2372899055480957 	 0.25977301597595215 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:00.011117 test begin: paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([50, 6, 1693441],"bool"), None, False, None, ) 	 508032300 	 1000 	 0.464306116104126 	 0.5083165168762207 	 0.23719120025634766 	 0.2597157955169678 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:09.484428 test begin: paddle.all(Tensor([508032010],"bool"), )
[Prof] paddle.all 	 paddle.all(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.46713876724243164 	 0.5083396434783936 	 0.23867249488830566 	 0.25973963737487793 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:17.294088 test begin: paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, )
[Prof] paddle.all 	 paddle.all(Tensor([8467210, 6, 10],"bool"), None, False, None, ) 	 508032600 	 1000 	 0.46567440032958984 	 0.5077712535858154 	 0.23736310005187988 	 0.2594637870788574 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:25.703010 test begin: paddle.allclose(Tensor([1124, 45199],"float32"), Tensor([1124, 45199],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([1124, 45199],"float32"), Tensor([1124, 45199],"float32"), ) 	 101607352 	 1000 	 1.0339529514312744 	 3.414080858230591 	 1.0216832160949707 	 7.796287536621094e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:31.754194 test begin: paddle.allclose(Tensor([13, 32, 122124],"float32"), Tensor([13, 32, 122124],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([13, 32, 122124],"float32"), Tensor([13, 32, 122124],"float32"), rtol=0.0001, atol=0.0001, ) 	 101607168 	 1000 	 1.0466766357421875 	 3.4131722450256348 	 1.0341589450836182 	 0.00014710426330566406 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:37.910878 test begin: paddle.allclose(Tensor([13, 61062, 64],"float32"), Tensor([13, 61062, 64],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([13, 61062, 64],"float32"), Tensor([13, 61062, 64],"float32"), rtol=0.0001, atol=0.0001, ) 	 101607168 	 1000 	 1.0463829040527344 	 3.4231455326080322 	 1.0338082313537598 	 0.00024771690368652344 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:44.134143 test begin: paddle.allclose(Tensor([1587601, 32],"float32"), Tensor([1587601, 32],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([1587601, 32],"float32"), Tensor([1587601, 32],"float32"), ) 	 101606464 	 1000 	 1.041924238204956 	 3.413064479827881 	 1.0294342041015625 	 0.0005660057067871094 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:50.202479 test begin: paddle.allclose(Tensor([24807, 32, 64],"float32"), Tensor([24807, 32, 64],"float32"), rtol=0.0001, atol=0.0001, )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([24807, 32, 64],"float32"), Tensor([24807, 32, 64],"float32"), rtol=0.0001, atol=0.0001, ) 	 101609472 	 1000 	 1.055699110031128 	 3.405604600906372 	 1.0440611839294434 	 0.0002894401550292969 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:56.387761 test begin: paddle.allclose(Tensor([30522, 1665],"float32"), Tensor([30522, 1665],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([30522, 1665],"float32"), Tensor([30522, 1665],"float32"), ) 	 101638260 	 1000 	 1.0315632820129395 	 3.416029691696167 	 1.01218843460083 	 0.0002143383026123047 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:02.502487 test begin: paddle.allclose(Tensor([6350401, 8],"float32"), Tensor([6350401, 8],"float32"), )
[Prof] paddle.allclose 	 paddle.allclose(Tensor([6350401, 8],"float32"), Tensor([6350401, 8],"float32"), ) 	 101606416 	 1000 	 1.0418059825897217 	 3.413914680480957 	 1.0295519828796387 	 0.0005016326904296875 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:08.606945 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.2276902198791504 	 0.17820143699645996 	 0.11631631851196289 	 0.09098553657531738 	 1.1105730533599854 	 1.3117291927337646 	 0.22711801528930664 	 0.2232508659362793 	 
2025-07-30 19:30:12.331423 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.241896390914917 	 0.20105409622192383 	 0.12355828285217285 	 0.10271310806274414 	 1.1245746612548828 	 1.3553509712219238 	 0.23003554344177246 	 0.23087096214294434 	 
2025-07-30 19:30:16.038334 test begin: paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 0.19772934913635254 	 0.16048169136047363 	 0.18485093116760254 	 0.14556646347045898 	 1.090804100036621 	 1.2885186672210693 	 0.27872323989868164 	 0.2631239891052246 	 
2025-07-30 19:30:19.551859 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22765517234802246 	 0.1781926155090332 	 0.11630654335021973 	 0.09104776382446289 	 1.1105401515960693 	 1.3118958473205566 	 0.22711610794067383 	 0.22339320182800293 	 
2025-07-30 19:30:23.167658 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.5705387592315674 	 0.8194670677185059 	 0.5565211772918701 	 0.43721437454223633 	 1.3121697902679443 	 1.4590389728546143 	 0.3352952003479004 	 0.29801344871520996 	 
2025-07-30 19:30:30.011969 test begin: paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.942861795425415 	 0.1658461093902588 	 3.0368142127990723 	 0.08471798896789551 	 5.896072149276733 	 1.2925035953521729 	 1.2034075260162354 	 0.2200181484222412 	 
2025-07-30 19:30:44.696150 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.43959617614746094 	 0.2880556583404541 	 0.4190359115600586 	 0.2648932933807373 	 1.177582025527954 	 1.311286449432373 	 0.3008420467376709 	 0.2678534984588623 	 
2025-07-30 19:30:48.808689 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.2580280303955078 	 0.21552252769470215 	 0.13190913200378418 	 0.11011290550231934 	 1.1385157108306885 	 1.423828363418579 	 0.2328479290008545 	 0.24247503280639648 	 
2025-07-30 19:30:52.686183 test begin: paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amax 	 paddle.amax(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.942789554595947 	 0.1658635139465332 	 3.0367379188537598 	 0.08473372459411621 	 5.895843267440796 	 1.2931687831878662 	 1.2033100128173828 	 0.2201547622680664 	 
2025-07-30 19:31:08.662303 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22772002220153809 	 0.17813444137573242 	 0.11636686325073242 	 0.09098672866821289 	 1.11063551902771 	 1.311842441558838 	 0.22708940505981445 	 0.22335290908813477 	 
2025-07-30 19:31:13.310766 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.2418985366821289 	 0.20109009742736816 	 0.12359189987182617 	 0.10270500183105469 	 1.1244792938232422 	 1.3551366329193115 	 0.2299661636352539 	 0.23061275482177734 	 
2025-07-30 19:31:17.031903 test begin: paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 10, 508033],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 0.19771718978881836 	 0.1605219841003418 	 0.18550848960876465 	 0.1456620693206787 	 1.0908596515655518 	 1.2885355949401855 	 0.2787184715270996 	 0.26320743560791016 	 
2025-07-30 19:31:20.636610 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.22768259048461914 	 0.17816829681396484 	 0.11630988121032715 	 0.09100914001464844 	 1.1105775833129883 	 1.3117611408233643 	 0.22708821296691895 	 0.2232959270477295 	 
2025-07-30 19:31:24.271506 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.570526123046875 	 0.45258164405822754 	 0.5568585395812988 	 0.4374380111694336 	 1.311500072479248 	 1.4590668678283691 	 0.3349943161010742 	 0.29798293113708496 	 
2025-07-30 19:31:28.898158 test begin: paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([10, 508033, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.942856550216675 	 0.16587090492248535 	 3.0367727279663086 	 0.08472299575805664 	 5.896061897277832 	 1.2928264141082764 	 1.2034051418304443 	 0.22009491920471191 	 
2025-07-30 19:31:43.505797 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 	 50803300 	 1000 	 0.4396073818206787 	 0.2878906726837158 	 0.4270288944244385 	 0.2729833126068115 	 1.1776766777038574 	 1.3113183975219727 	 0.3008439540863037 	 0.26784300804138184 	 
2025-07-30 19:31:47.492789 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 	 50803300 	 1000 	 0.2581207752227783 	 0.21543598175048828 	 0.13186383247375488 	 0.11005353927612305 	 1.1386067867279053 	 1.423861026763916 	 0.23284363746643066 	 0.24241065979003906 	 
2025-07-30 19:31:51.359885 test begin: paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[Prof] paddle.amin 	 paddle.amin(Tensor([508033, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 	 50803300 	 1000 	 5.942837238311768 	 0.16590666770935059 	 3.0367743968963623 	 0.08473372459411621 	 5.895964860916138 	 1.292858362197876 	 1.2033116817474365 	 0.22008776664733887 	 
2025-07-30 19:32:05.538092 test begin: paddle.any(Tensor([10, 12404, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 12404, 4096],"bool"), ) 	 508067840 	 1000 	 0.4656035900115967 	 0.5279130935668945 	 0.23733878135681152 	 0.26975154876708984 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:13.460003 test begin: paddle.any(Tensor([10, 300, 169345],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([10, 300, 169345],"bool"), ) 	 508035000 	 1000 	 0.46456241607666016 	 0.5292572975158691 	 0.23737668991088867 	 0.2704353332519531 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:21.342918 test begin: paddle.any(Tensor([11240, 45199],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([11240, 45199],"bool"), ) 	 508036760 	 1000 	 0.46338987350463867 	 0.5279417037963867 	 0.23679351806640625 	 0.2697606086730957 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:29.229668 test begin: paddle.any(Tensor([15876010, 32],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.4665863513946533 	 0.5293326377868652 	 0.23840713500976562 	 0.27050352096557617 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:38.632117 test begin: paddle.any(Tensor([420, 300, 4096],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([420, 300, 4096],"bool"), ) 	 516096000 	 1000 	 0.47332096099853516 	 0.5392420291900635 	 0.24126434326171875 	 0.2755129337310791 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:46.520446 test begin: paddle.any(Tensor([5120, 99226],"bool"), )
[Prof] paddle.any 	 paddle.any(Tensor([5120, 99226],"bool"), ) 	 508037120 	 1000 	 0.46584200859069824 	 0.5288636684417725 	 0.23804235458374023 	 0.2702140808105469 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:54.390923 test begin: paddle.argmax(Tensor([15877, 100, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([15877, 100, 32],"float32"), axis=1, ) 	 50806400 	 1000 	 0.7611551284790039 	 0.18286800384521484 	 0.7422318458557129 	 0.1622028350830078 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:56.152968 test begin: paddle.argmax(Tensor([29151, 100, 18],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 100, 18],"float32"), axis=1, ) 	 52471800 	 1000 	 0.6405942440032959 	 0.17375469207763672 	 0.6241428852081299 	 0.15975069999694824 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:57.866005 test begin: paddle.argmax(Tensor([29151, 28, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 28, 64],"float32"), axis=1, ) 	 52238592 	 1000 	 1.50307297706604 	 0.17650151252746582 	 1.4849388599395752 	 0.15531301498413086 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:00.454963 test begin: paddle.argmax(Tensor([29151, 55, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([29151, 55, 32],"float32"), axis=1, ) 	 51305760 	 1000 	 0.7544257640838623 	 0.16863155364990234 	 0.7434992790222168 	 0.1530442237854004 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:02.187163 test begin: paddle.argmax(Tensor([39691, 20, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([39691, 20, 64],"float32"), axis=1, ) 	 50804480 	 1000 	 2.0447864532470703 	 0.17618799209594727 	 2.0335121154785156 	 0.16204404830932617 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:05.169357 test begin: paddle.argmax(Tensor([7939, 100, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([7939, 100, 64],"float32"), axis=1, ) 	 50809600 	 1000 	 0.7602193355560303 	 0.18041372299194336 	 0.7491536140441895 	 0.16656994819641113 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:06.948929 test begin: paddle.argmax(Tensor([80239, 10, 64],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([80239, 10, 64],"float32"), axis=1, ) 	 51352960 	 1000 	 4.129377126693726 	 0.19602465629577637 	 4.111286163330078 	 0.1748673915863037 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:12.220527 test begin: paddle.argmax(Tensor([80239, 20, 32],"float32"), axis=1, )
[Prof] paddle.argmax 	 paddle.argmax(Tensor([80239, 20, 32],"float32"), axis=1, ) 	 51352960 	 1000 	 2.066704750061035 	 0.18323159217834473 	 2.0557641983032227 	 0.16364431381225586 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:15.289908 test begin: paddle.argmin(Tensor([104534, 3, 3, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([104534, 3, 3, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 0.4763302803039551 	 0.16082215309143066 	 0.46495866775512695 	 0.08214998245239258 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:16.413660 test begin: paddle.argmin(Tensor([203213, 5, 5, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([203213, 5, 5, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 0.4842989444732666 	 0.16274547576904297 	 0.4730086326599121 	 0.08313345909118652 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:17.539020 test begin: paddle.argmin(Tensor([3, 104534, 3, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 104534, 3, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805685997009277 	 0.20574545860290527 	 6.787174224853516 	 0.18149662017822266 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:25.162678 test begin: paddle.argmin(Tensor([3, 3, 104534, 3, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 104534, 3, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805428981781006 	 0.20350956916809082 	 6.79427170753479 	 0.1881570816040039 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:32.717040 test begin: paddle.argmin(Tensor([3, 3, 3, 104534, 3, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 104534, 3, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805561304092407 	 0.21741795539855957 	 6.794296741485596 	 0.18810033798217773 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:40.869648 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 104534, 3],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 3, 104534, 3],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805671453475952 	 0.22188377380371094 	 6.794255495071411 	 0.188277006149292 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:49.402824 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 3, 104534],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([3, 3, 3, 3, 3, 104534],"float64"), axis=0, ) 	 25401762 	 1000 	 6.805835008621216 	 0.20352745056152344 	 6.7872278690338135 	 0.18841123580932617 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:57.024691 test begin: paddle.argmin(Tensor([4, 4, 4, 4, 99226],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 4, 4, 99226],"float64"), axis=0, ) 	 25401856 	 1000 	 5.1053807735443115 	 0.19113850593566895 	 5.093939542770386 	 0.1767115592956543 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:02.889909 test begin: paddle.argmin(Tensor([4, 4, 4, 99226, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 4, 99226, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.105594635009766 	 0.19110536575317383 	 5.094305515289307 	 0.176408052444458 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:08.880663 test begin: paddle.argmin(Tensor([4, 4, 99226, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 4, 99226, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.105529069900513 	 0.19383931159973145 	 5.08705735206604 	 0.17641401290893555 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:14.743519 test begin: paddle.argmin(Tensor([4, 99226, 4, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([4, 99226, 4, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 5.105506896972656 	 0.19109845161437988 	 5.09409236907959 	 0.17650198936462402 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:20.621021 test begin: paddle.argmin(Tensor([5, 203213, 5, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 203213, 5, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 4.085226774215698 	 0.1963658332824707 	 4.066627740859985 	 0.17506861686706543 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:25.451054 test begin: paddle.argmin(Tensor([5, 5, 203213, 5],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 5, 203213, 5],"float64"), axis=0, ) 	 25401625 	 1000 	 4.0849974155426025 	 0.1964092254638672 	 4.0659027099609375 	 0.1819286346435547 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:30.397366 test begin: paddle.argmin(Tensor([5, 5, 5, 203213],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([5, 5, 5, 203213],"float64"), axis=0, ) 	 25401625 	 1000 	 4.084956645965576 	 0.19632315635681152 	 4.073732137680054 	 0.18208909034729004 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:37.146884 test begin: paddle.argmin(Tensor([99226, 4, 4, 4, 4],"float64"), axis=0, )
[Prof] paddle.argmin 	 paddle.argmin(Tensor([99226, 4, 4, 4, 4],"float64"), axis=0, ) 	 25401856 	 1000 	 0.4353749752044678 	 0.32311224937438965 	 0.4169914722442627 	 0.1651747226715088 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:40.579602 test begin: paddle.argsort(Tensor([25401601],"float64"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([25401601],"float64"), stable=True, ) 	 25401601 	 1000 	 10.65246319770813 	 7.5112385749816895 	 9.775161743164062e-05 	 0.33440470695495605 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:35:04.319968 test begin: paddle.argsort(Tensor([50803201],"float32"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([50803201],"float32"), stable=True, ) 	 50803201 	 1000 	 16.271795988082886 	 7.860908508300781 	 0.00010395050048828125 	 0.5361988544464111 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:35:39.946911 test begin: paddle.argsort(Tensor([50803201],"int32"), stable=True, )
[Prof] paddle.argsort 	 paddle.argsort(Tensor([50803201],"int32"), stable=True, ) 	 50803201 	 1000 	 16.268567323684692 	 7.215511083602905 	 0.00010585784912109375 	 0.491962194442749 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:36:13.502202 test begin: paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 207, 8, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.006811380386352539 	 0.007920503616333008 	 1.239776611328125e-05 	 2.1457672119140625e-05 	 0.04618430137634277 	 0.06762337684631348 	 2.86102294921875e-05 	 6.413459777832031e-05 	 
2025-07-30 19:36:28.351179 test begin: paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 207, 32, 2],"float32"), ) 	 508723200 	 1000 	 0.003197193145751953 	 0.00900721549987793 	 1.2159347534179688e-05 	 9.274482727050781e-05 	 0.048406124114990234 	 0.06777787208557129 	 4.3392181396484375e-05 	 6.771087646484375e-05 	 
2025-07-30 19:36:42.239831 test begin: paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 15, 8, 8, 827, 2],"float32"), ) 	 508108800 	 1000 	 0.0031752586364746094 	 0.004292964935302734 	 9.775161743164062e-06 	 2.574920654296875e-05 	 0.03910422325134277 	 0.0768136978149414 	 3.981590270996094e-05 	 7.462501525878906e-05 	 
2025-07-30 19:36:59.103366 test begin: paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([320, 388, 8, 8, 32, 2],"float32"), ) 	 508559360 	 1000 	 0.0031685829162597656 	 0.004254579544067383 	 1.0013580322265625e-05 	 2.3126602172851562e-05 	 0.039995670318603516 	 0.05859565734863281 	 4.076957702636719e-05 	 6.866455078125e-05 	 
2025-07-30 19:37:11.635637 test begin: paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), )
[Prof] paddle.as_complex 	 paddle.as_complex(Tensor([8270, 15, 8, 8, 32, 2],"float32"), ) 	 508108800 	 1000 	 0.003145933151245117 	 0.005705356597900391 	 7.152557373046875e-06 	 3.075599670410156e-05 	 0.041539907455444336 	 0.05986928939819336 	 4.100799560546875e-05 	 5.030632019042969e-05 	 
2025-07-30 19:37:25.807104 test begin: paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([15876010, 32],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.017699003219604492 	 0.004373073577880859 	 1.7404556274414062e-05 	 1.8835067749023438e-05 	 1.5120353698730469 	 1.3166003227233887 	 0.7723796367645264 	 0.6711549758911133 	 
2025-07-30 19:37:38.194668 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.01774120330810547 	 0.004441976547241211 	 1.9073486328125e-05 	 3.7670135498046875e-05 	 1.508458137512207 	 1.314424753189087 	 0.7712826728820801 	 0.6713888645172119 	 
2025-07-30 19:38:01.040690 test begin: paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([31752010, 32],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.017633676528930664 	 0.004540443420410156 	 1.2636184692382812e-05 	 2.2649765014648438e-05 	 1.5059528350830078 	 1.3154916763305664 	 0.7688522338867188 	 0.6718747615814209 	 
2025-07-30 19:38:28.219185 test begin: paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 1587601],"float32"), shape=tuple(3,), stride=tuple(1,), ) 	 508032320 	 1000 	 0.022907018661499023 	 0.00791478157043457 	 1.5735626220703125e-05 	 2.4557113647460938e-05 	 1.51230788230896 	 1.3147878646850586 	 0.7728464603424072 	 0.6717398166656494 	 
2025-07-30 19:38:40.955495 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,), stride=tuple(1,), ) 	 1016064320 	 1000 	 0.01752018928527832 	 0.004374027252197266 	 1.811981201171875e-05 	 1.9788742065429688e-05 	 1.5074028968811035 	 1.3145112991333008 	 0.7708141803741455 	 0.6713967323303223 	 
2025-07-30 19:39:06.270183 test begin: paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), )
[Prof] paddle.as_strided 	 paddle.as_strided(Tensor([320, 3175201],"float16"), shape=tuple(3,4,), stride=tuple(32,1,), ) 	 1016064320 	 1000 	 0.017644166946411133 	 0.004513263702392578 	 1.2874603271484375e-05 	 2.0742416381835938e-05 	 1.5075135231018066 	 1.3153610229492188 	 0.7701852321624756 	 0.6718778610229492 	 
2025-07-30 19:39:32.351567 test begin: paddle.asin(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29533839225769043 	 0.2975962162017822 	 0.2862708568572998 	 0.286421537399292 	 0.4503505229949951 	 1.7832164764404297 	 0.39193201065063477 	 0.36444807052612305 	 
2025-07-30 19:39:38.597308 test begin: paddle.asin(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29544496536254883 	 0.3189833164215088 	 0.2793233394622803 	 0.2790210247039795 	 0.45041513442993164 	 1.7832365036010742 	 0.38698649406433105 	 0.3644752502441406 	 
2025-07-30 19:39:43.667263 test begin: paddle.asin(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.asin 	 paddle.asin(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29547786712646484 	 0.2987794876098633 	 0.2864058017730713 	 0.2857825756072998 	 0.45032477378845215 	 1.7831766605377197 	 0.3964097499847412 	 0.36446499824523926 	 
2025-07-30 19:39:48.101985 test begin: paddle.asinh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.30091309547424316 	 0.30045318603515625 	 0.29198431968688965 	 0.2890951633453369 	 0.4501357078552246 	 1.3379254341125488 	 0.3968355655670166 	 0.3418614864349365 	 
2025-07-30 19:39:52.139152 test begin: paddle.asinh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.3010518550872803 	 0.300992488861084 	 0.29219651222229004 	 0.28882837295532227 	 0.45049524307250977 	 1.3378784656524658 	 0.3967266082763672 	 0.3418262004852295 	 
2025-07-30 19:39:56.120818 test begin: paddle.asinh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.asinh 	 paddle.asinh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.3011329174041748 	 0.3004343509674072 	 0.2923450469970703 	 0.2891411781311035 	 0.4505150318145752 	 1.337873935699463 	 0.396726131439209 	 0.34183835983276367 	 
2025-07-30 19:40:00.091077 test begin: paddle.atan(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2976212501525879 	 0.29759740829467773 	 0.288468599319458 	 0.28647565841674805 	 0.45018863677978516 	 1.0432379245758057 	 0.39693784713745117 	 0.35539913177490234 	 
2025-07-30 19:40:03.771176 test begin: paddle.atan(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2976398468017578 	 0.29758310317993164 	 0.288543701171875 	 0.28632402420043945 	 0.4504542350769043 	 1.0432753562927246 	 0.39715075492858887 	 0.3553926944732666 	 
2025-07-30 19:40:07.384795 test begin: paddle.atan(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.atan 	 paddle.atan(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29776525497436523 	 0.2975575923919678 	 0.2885549068450928 	 0.2863612174987793 	 0.450423002243042 	 1.0432937145233154 	 0.39670848846435547 	 0.3554708957672119 	 
2025-07-30 19:40:11.185771 test begin: paddle.atan2(Tensor([100],"float64"), Tensor([254017, 100],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([100],"float64"), Tensor([254017, 100],"float64"), ) 	 25401800 	 1000 	 0.8812088966369629 	 0.3136613368988037 	 0.30036401748657227 	 0.3009305000305176 	 1.6832404136657715 	 2.743337392807007 	 0.3436107635498047 	 0.2547945976257324 	 
2025-07-30 19:40:17.842568 test begin: paddle.atan2(Tensor([111, 222, 1031],"float64"), Tensor([222, 1031],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([111, 222, 1031],"float64"), Tensor([222, 1031],"float64"), ) 	 25634784 	 1000 	 0.8820321559906006 	 0.3228452205657959 	 0.30046820640563965 	 0.30361104011535645 	 1.2333004474639893 	 2.987755537033081 	 0.3146181106567383 	 0.3052701950073242 	 
2025-07-30 19:40:25.258917 test begin: paddle.atan2(Tensor([111, 688, 333],"float64"), Tensor([688, 333],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([111, 688, 333],"float64"), Tensor([688, 333],"float64"), ) 	 25659648 	 1000 	 0.883540153503418 	 0.3216118812561035 	 0.300891637802124 	 0.29175543785095215 	 1.228761911392212 	 2.9946694374084473 	 0.31357669830322266 	 0.30602574348449707 	 
2025-07-30 19:40:31.935492 test begin: paddle.atan2(Tensor([344, 222, 333],"float64"), Tensor([222, 333],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(Tensor([344, 222, 333],"float64"), Tensor([222, 333],"float64"), ) 	 25504470 	 1000 	 0.8803372383117676 	 0.31871485710144043 	 0.29989004135131836 	 0.296004056930542 	 1.3152127265930176 	 2.984903573989868 	 0.33560824394226074 	 0.3050520420074463 	 
2025-07-30 19:40:40.905148 test begin: paddle.atan2(x=Tensor([19601, 6, 6, 6, 6],"float64"), y=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([19601, 6, 6, 6, 6],"float64"), y=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 50805792 	 1000 	 0.44628334045410156 	 0.45363283157348633 	 0.4281349182128906 	 0.435230016708374 	 0.7326912879943848 	 3.408398389816284 	 0.6660952568054199 	 0.3872036933898926 	 
2025-07-30 19:40:47.508922 test begin: paddle.atan2(x=Tensor([3, 39201, 6, 6, 6],"float64"), y=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 39201, 6, 6, 6],"float64"), y=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 50804496 	 1000 	 0.44612693786621094 	 0.4537527561187744 	 0.43500328063964844 	 0.44150853157043457 	 0.7329130172729492 	 3.408318519592285 	 0.6753239631652832 	 0.38713836669921875 	 
2025-07-30 19:40:54.017607 test begin: paddle.atan2(x=Tensor([3, 6, 39201, 6, 6],"float64"), y=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 39201, 6, 6],"float64"), y=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 50804496 	 1000 	 0.4460744857788086 	 0.45372438430786133 	 0.43469905853271484 	 0.44139957427978516 	 0.7328968048095703 	 3.408236265182495 	 0.6754739284515381 	 0.38722753524780273 	 
2025-07-30 19:41:00.492301 test begin: paddle.atan2(x=Tensor([3, 6, 6, 39201, 6],"float64"), y=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 6, 39201, 6],"float64"), y=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 50804496 	 1000 	 0.4461352825164795 	 0.4536929130554199 	 0.4347546100616455 	 0.441422700881958 	 0.7329175472259521 	 3.4082283973693848 	 0.6753771305084229 	 0.38712286949157715 	 
2025-07-30 19:41:08.646542 test begin: paddle.atan2(x=Tensor([3, 6, 6, 6, 39201],"float64"), y=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.atan2 	 paddle.atan2(x=Tensor([3, 6, 6, 6, 39201],"float64"), y=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 50804496 	 1000 	 0.44609546661376953 	 0.45600056648254395 	 0.42782044410705566 	 0.4349033832550049 	 0.7328619956970215 	 3.408336639404297 	 0.6662421226501465 	 0.38721179962158203 	 
2025-07-30 19:41:15.257885 test begin: paddle.atanh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29678916931152344 	 0.2983081340789795 	 0.28060150146484375 	 0.2807779312133789 	 0.44995760917663574 	 1.62239408493042 	 0.3849177360534668 	 0.3316824436187744 	 
2025-07-30 19:41:19.502378 test begin: paddle.atanh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2968873977661133 	 0.2983076572418213 	 0.28061652183532715 	 0.28080034255981445 	 0.4504709243774414 	 1.6223158836364746 	 0.3862802982330322 	 0.33165979385375977 	 
2025-07-30 19:41:23.724452 test begin: paddle.atanh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.atanh 	 paddle.atanh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2969703674316406 	 0.2982308864593506 	 0.28084516525268555 	 0.280719518661499 	 0.4504415988922119 	 1.6224489212036133 	 0.38721513748168945 	 0.3316977024078369 	 
2025-07-30 19:42:27.774155 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
W0730 19:43:11.084949 31563 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0029413700103759766 	 0.014364480972290039 	 1.0967254638671875e-05 	 7.271766662597656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:43:21.410846 test begin: paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0027687549591064453 	 0.007551431655883789 	 1.0251998901367188e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:44:14.162769 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0015673637390136719 	 0.006250143051147461 	 6.4373016357421875e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:04.110938 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
W0730 19:46:48.000072 33061 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.0030732154846191406 	 0.009467363357543945 	 2.4080276489257812e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:58.162105 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.002863168716430664 	 0.007619142532348633 	 1.1444091796875e-05 	 5.9604644775390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:48:04.777911 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0028705596923828125 	 0.010522127151489258 	 8.58306884765625e-06 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:48:05.495523 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.002851247787475586 	 0.007414340972900391 	 9.775161743164062e-06 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:48:53.872629 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0028705596923828125 	 0.010508298873901367 	 1.1920928955078125e-05 	 3.0994415283203125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:56.848102 test begin: paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0027801990509033203 	 0.007400035858154297 	 1.430511474609375e-05 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:57.571440 test begin: paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.002804994583129883 	 0.007401466369628906 	 9.5367431640625e-06 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:45.798074 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.002825021743774414 	 0.007460594177246094 	 9.298324584960938e-06 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:51:35.312773 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0028722286224365234 	 0.007384777069091797 	 9.5367431640625e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:52:24.662829 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.0027933120727539062 	 0.0073490142822265625 	 1.2159347534179688e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:53:13.405905 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.002798318862915039 	 0.007389545440673828 	 7.3909759521484375e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:53:14.132521 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0027840137481689453 	 0.010512828826904297 	 9.059906005859375e-06 	 3.0279159545898438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:54:10.184047 test begin: paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0028350353240966797 	 0.007823944091796875 	 8.821487426757812e-06 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:54:10.886498 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0016584396362304688 	 0.008305072784423828 	 1.2159347534179688e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:54:59.716243 test begin: paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.002846956253051758 	 0.007328033447265625 	 9.059906005859375e-06 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:55:55.250753 test begin: paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0027816295623779297 	 0.0073282718658447266 	 7.62939453125e-06 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:56:49.349901 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.00164794921875 	 0.006085634231567383 	 1.33514404296875e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:38.622508 test begin: paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0028116703033447266 	 0.007715940475463867 	 1.2636184692382812e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:58:26.803127 test begin: paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.002809286117553711 	 0.008142232894897461 	 1.1205673217773438e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:58:27.441025 test begin: paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.002749919891357422 	 0.007308006286621094 	 9.5367431640625e-06 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:59:18.054474 test begin: paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0028030872344970703 	 0.00765538215637207 	 8.58306884765625e-06 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:59:18.684216 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0015988349914550781 	 0.0061533451080322266 	 1.2159347534179688e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:31.288042 test begin: paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_1d 	 paddle.atleast_1d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0028333663940429688 	 0.010427474975585938 	 1.0967254638671875e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:01:35.174478 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0038661956787109375 	 0.007414340972900391 	 1.4066696166992188e-05 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:02:23.613079 test begin: paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.0037527084350585938 	 0.007401943206787109 	 7.152557373046875e-06 	 3.6716461181640625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:03:12.316402 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003780364990234375 	 0.010458230972290039 	 9.775161743164062e-06 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:12.024734 test begin: paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0037131309509277344 	 0.007464408874511719 	 6.198883056640625e-06 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:11.970141 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.0019600391387939453 	 0.006201267242431641 	 1.1205673217773438e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:00.158780 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.0038297176361083984 	 0.008496761322021484 	 1.2636184692382812e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:07:01.080207 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.0038590431213378906 	 0.007341146469116211 	 9.5367431640625e-06 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:08:03.704394 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.00415492057800293 	 0.007220268249511719 	 1.2874603271484375e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:08:57.201182 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.003797292709350586 	 0.008805513381958008 	 9.298324584960938e-06 	 5.555152893066406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:07.425313 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.003838777542114258 	 0.0073854923248291016 	 1.0967254638671875e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:56.037289 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.003755331039428711 	 0.007370471954345703 	 6.9141387939453125e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:56.749706 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.00383758544921875 	 0.0072710514068603516 	 7.867813110351562e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:45.070653 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0037860870361328125 	 0.010391712188720703 	 1.049041748046875e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:34.285463 test begin: paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.003741741180419922 	 0.007909059524536133 	 6.9141387939453125e-06 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:35.026807 test begin: paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.00377655029296875 	 0.010597705841064453 	 9.298324584960938e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:13:24.131814 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.0037660598754882812 	 0.012711763381958008 	 6.198883056640625e-06 	 5.7220458984375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:14:13.326206 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0037577152252197266 	 0.0073909759521484375 	 7.152557373046875e-06 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:15:02.201345 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.0037631988525390625 	 0.007373809814453125 	 9.5367431640625e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:15:50.809156 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003742218017578125 	 0.0073986053466796875 	 5.9604644775390625e-06 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:15:51.511379 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.00380706787109375 	 0.007384777069091797 	 1.1205673217773438e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:16:40.976434 test begin: paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.0044062137603759766 	 0.0071887969970703125 	 2.47955322265625e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:16:41.701925 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0019555091857910156 	 0.00609135627746582 	 1.0967254638671875e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:17:30.919767 test begin: paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0038182735443115234 	 0.00728154182434082 	 9.298324584960938e-06 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:18:19.910538 test begin: paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0037682056427001953 	 0.01184701919555664 	 1.0013580322265625e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:19:08.581734 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.001964569091796875 	 0.00603032112121582 	 8.106231689453125e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:19:57.454120 test begin: paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.003797292709350586 	 0.007256984710693359 	 8.821487426757812e-06 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:45.395209 test begin: paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.003719329833984375 	 0.007241725921630859 	 6.9141387939453125e-06 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:46.034812 test begin: paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.003748655319213867 	 0.0070912837982177734 	 1.1444091796875e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:34.316052 test begin: paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.003743886947631836 	 0.007388591766357422 	 6.67572021484375e-06 	 5.507469177246094e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:34.950756 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.0020177364349365234 	 0.006092071533203125 	 1.0728836059570312e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:23.555118 test begin: paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_2d 	 paddle.atleast_2d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.003782987594604492 	 0.010343790054321289 	 1.4781951904296875e-05 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:25.998102 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.010999441146850586 	 0.018983125686645508 	 3.886222839355469e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:24:14.622429 test begin: paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2, 5],"float64"), Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.004720926284790039 	 0.00720524787902832 	 7.62939453125e-06 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:25:02.597165 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.004605531692504883 	 0.0071032047271728516 	 1.1205673217773438e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:25:50.803374 test begin: paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3, 4, 2],"float64"), Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.0046694278717041016 	 0.007239580154418945 	 1.1682510375976562e-05 	 2.6464462280273438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:26:41.477592 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548629608 	 1000 	 0.002288341522216797 	 0.010442018508911133 	 1.0728836059570312e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:27:30.167467 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.004952430725097656 	 0.013232231140136719 	 1.1205673217773438e-05 	 6.628036499023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:28:18.565666 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548653688 	 1000 	 0.004821062088012695 	 0.007281780242919922 	 1.0967254638671875e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:29:08.851747 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 1058401],"float64"), ) 	 2548653688 	 1000 	 0.004834890365600586 	 0.007234811782836914 	 1.0967254638671875e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:29:58.353096 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), ) 	 2548657300 	 1000 	 0.004921674728393555 	 0.007126808166503906 	 1.1682510375976562e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:30:47.741210 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0047643184661865234 	 0.007197141647338867 	 8.344650268554688e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:31:38.203119 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.004775524139404297 	 0.0072939395904541016 	 7.3909759521484375e-06 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:31:41.818901 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.004801034927368164 	 0.007227182388305664 	 7.3909759521484375e-06 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:32:33.636061 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.004810810089111328 	 0.01037144660949707 	 1.1205673217773438e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:33:25.990583 test begin: paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2, 5],"float64"), Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.0047454833984375 	 0.010189294815063477 	 1.1920928955078125e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:33:26.711048 test begin: paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.00473475456237793 	 0.007280826568603516 	 7.3909759521484375e-06 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:34:14.939404 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548633220 	 1000 	 0.004718303680419922 	 0.007311105728149414 	 1.049041748046875e-05 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:35:03.816510 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2116801],"float64"), ) 	 2548633220 	 1000 	 0.0047452449798583984 	 0.0071258544921875 	 1.1682510375976562e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:35:52.538928 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), ) 	 2548632618 	 1000 	 0.004685640335083008 	 0.007146120071411133 	 8.344650268554688e-06 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:36:44.163656 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004697322845458984 	 0.007104158401489258 	 7.62939453125e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:36:44.866521 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.004718780517578125 	 0.007255077362060547 	 8.106231689453125e-06 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:37:33.134169 test begin: paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 2],"float64"), Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004664421081542969 	 0.007259845733642578 	 6.9141387939453125e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:37:33.847939 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), ) 	 2548633220 	 1000 	 0.0022835731506347656 	 0.00630950927734375 	 1.2636184692382812e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:38:22.150317 test begin: paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4, 423361, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548657300 	 1000 	 0.0048253536224365234 	 0.007285118103027344 	 1.1444091796875e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:39:10.610893 test begin: paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 4233601, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 2548632618 	 1000 	 0.0047872066497802734 	 0.007231712341308594 	 1.1682510375976562e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:39:59.048505 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), ) 	 2548630210 	 1000 	 0.002288818359375 	 0.0061931610107421875 	 1.2159347534179688e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:40:47.330498 test begin: paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([301, 846721, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 2548654290 	 1000 	 0.0049991607666015625 	 0.007569551467895508 	 2.574920654296875e-05 	 6.389617919921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:37.547363 test begin: paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([3175201, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), Tensor([301, 4, 2],"float64"), ) 	 25406424 	 1000 	 0.004687309265136719 	 0.007322788238525391 	 1.0967254638671875e-05 	 3.0994415283203125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:40.178932 test begin: paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([317520101, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), Tensor([3, 4, 2],"float64"), ) 	 2540160856 	 1000 	 0.00459742546081543 	 0.0071582794189453125 	 1.049041748046875e-05 	 2.0742416381835938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:28.263333 test begin: paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([635041, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), Tensor([301, 4, 2, 5],"float64"), ) 	 25425720 	 1000 	 0.005284786224365234 	 0.007211923599243164 	 2.9325485229492188e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:28.905530 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), ) 	 2540164040 	 1000 	 0.002237558364868164 	 0.006148338317871094 	 1.1920928955078125e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:43:17.210334 test begin: paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), )
[Prof] paddle.atleast_3d 	 paddle.atleast_3d(Tensor([63504101, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), Tensor([3, 4, 2, 5],"float64"), ) 	 2540164280 	 1000 	 0.005368471145629883 	 0.007193803787231445 	 2.9087066650390625e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:05.185257 test begin: paddle.bincount(Tensor([25401601],"int64"), minlength=Tensor([1],"int32"), )
[Prof] paddle.bincount 	 paddle.bincount(Tensor([25401601],"int64"), minlength=Tensor([1],"int32"), ) 	 25401602 	 1000 	 1.0056631565093994 	 0.8317553997039795 	 0.0005121231079101562 	 0.00046896934509277344 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:07.615622 test begin: paddle.bincount(Tensor([50803201],"int32"), weights=Tensor([50803201],"float32"), )
[Prof] paddle.bincount 	 paddle.bincount(Tensor([50803201],"int32"), weights=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 1.8214504718780518 	 1.4440374374389648 	 0.0010628700256347656 	 0.0010743141174316406 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:12.319415 test begin: paddle.bincount(x=Tensor([50803201],"int32"), weights=Tensor([50803201],"int32"), )
[Prof] paddle.bincount 	 paddle.bincount(x=Tensor([50803201],"int32"), weights=Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.7966272830963135 	 1.8094508647918701 	 0.0010457038879394531 	 0.0009748935699462891 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:17.061736 test begin: paddle.bitwise_and(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44840574264526367 	 0.45005130767822266 	 0.43839240074157715 	 0.43752527236938477 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:19.906011 test begin: paddle.bitwise_and(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4483952522277832 	 0.4498717784881592 	 0.4326653480529785 	 0.43115234375 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:22.751148 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44817638397216797 	 0.449826717376709 	 0.43916940689086914 	 0.4376835823059082 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:25.646475 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.4483029842376709 	 0.45282506942749023 	 0.43938112258911133 	 0.4375185966491699 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:28.505130 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11848235130310059 	 0.135941743850708 	 0.10952258110046387 	 0.09887886047363281 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:32.463474 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.4496772289276123 	 0.448789119720459 	 0.43883800506591797 	 0.43317747116088867 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:35.438767 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.4481828212738037 	 0.6722621917724609 	 0.43921875953674316 	 0.4204845428466797 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:40.372693 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1779017448425293 	 0.2304375171661377 	 0.1678318977355957 	 0.21385478973388672 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:41.473662 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.31543469429016113 	 0.4797537326812744 	 0.3055253028869629 	 0.4662044048309326 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:43.220298 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2960801124572754 	 0.31136345863342285 	 0.28612804412841797 	 0.2948036193847656 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:44.367360 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11845946311950684 	 0.1169431209564209 	 0.10944485664367676 	 0.10415959358215332 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:46.000074 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.4497859477996826 	 0.44617748260498047 	 0.4407958984375 	 0.43409252166748047 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:47.975902 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.44810938835144043 	 0.44997286796569824 	 0.43912267684936523 	 0.43747615814208984 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:50.807308 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1844174861907959 	 0.22729873657226562 	 0.17435717582702637 	 0.21373414993286133 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:51.923117 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11843085289001465 	 0.1164555549621582 	 0.10933256149291992 	 0.10429763793945312 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:53.533145 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2956387996673584 	 0.31311607360839844 	 0.2857241630554199 	 0.2947700023651123 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:54.687917 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.44976305961608887 	 0.4461863040924072 	 0.43863749504089355 	 0.4340667724609375 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:56.689165 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.34467506408691406 	 0.47908473014831543 	 0.3347644805908203 	 0.46473002433776855 	 None 	 None 	 None 	 None 	 
2025-07-30 20:44:58.454912 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.44869208335876465 	 0.4498867988586426 	 0.43974876403808594 	 0.4378471374511719 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:01.259379 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11819767951965332 	 0.11549210548400879 	 0.10902714729309082 	 0.1034855842590332 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:02.895846 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.4497833251953125 	 0.4461982250213623 	 0.4395716190338135 	 0.43396782875061035 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:04.869061 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11818146705627441 	 0.1154940128326416 	 0.10906314849853516 	 0.10345768928527832 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:06.500291 test begin: paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44969677925109863 	 0.44872283935546875 	 0.44062232971191406 	 0.43386292457580566 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:08.493879 test begin: paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11820268630981445 	 0.1154928207397461 	 0.10914158821105957 	 0.10341882705688477 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:10.104943 test begin: paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44971704483032227 	 0.4461534023284912 	 0.44068479537963867 	 0.4337756633758545 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:12.087545 test begin: paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11818552017211914 	 0.11551022529602051 	 0.10905075073242188 	 0.10327935218811035 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:13.744344 test begin: paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44974637031555176 	 0.44616246223449707 	 0.4389305114746094 	 0.43405890464782715 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:15.711526 test begin: paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11842870712280273 	 0.11629080772399902 	 0.10932040214538574 	 0.10416436195373535 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:17.318826 test begin: paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.44977569580078125 	 0.4461963176727295 	 0.4408683776855469 	 0.43406105041503906 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:19.285877 test begin: paddle.bitwise_and(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_and 	 paddle.bitwise_and(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44823193550109863 	 0.44997262954711914 	 0.4392669200897217 	 0.43805718421936035 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:22.072404 test begin: paddle.bitwise_invert(Tensor([12700801, 4, 1],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([12700801, 4, 1],"int32"), ) 	 50803204 	 1000 	 0.2956869602203369 	 0.29864001274108887 	 0.2871232032775879 	 0.28644251823425293 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:23.257256 test begin: paddle.bitwise_invert(Tensor([2, 1270081, 4, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 1270081, 4, 5],"int32"), ) 	 50803240 	 1000 	 0.2956271171569824 	 0.29787683486938477 	 0.2870903015136719 	 0.28641486167907715 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:24.416553 test begin: paddle.bitwise_invert(Tensor([2, 3, 1693441, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 3, 1693441, 5],"int32"), ) 	 50803230 	 1000 	 0.29563307762145996 	 0.2978672981262207 	 0.2869887351989746 	 0.2858562469482422 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:25.563867 test begin: paddle.bitwise_invert(Tensor([2, 3, 4, 2116801],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([2, 3, 4, 2116801],"int32"), ) 	 50803224 	 1000 	 0.29563045501708984 	 0.29788756370544434 	 0.28707289695739746 	 0.28636670112609863 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:26.705646 test begin: paddle.bitwise_invert(Tensor([3, 16934401, 1],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([3, 16934401, 1],"int32"), ) 	 50803203 	 1000 	 0.29563164710998535 	 0.2978637218475342 	 0.2870655059814453 	 0.2863435745239258 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:27.851188 test begin: paddle.bitwise_invert(Tensor([3, 4, 4233601],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([3, 4, 4233601],"int32"), ) 	 50803212 	 1000 	 0.29560422897338867 	 0.2978553771972656 	 0.287078857421875 	 0.286374568939209 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:28.998134 test begin: paddle.bitwise_invert(Tensor([846721, 3, 4, 5],"int32"), )
[Prof] paddle.bitwise_invert 	 paddle.bitwise_invert(Tensor([846721, 3, 4, 5],"int32"), ) 	 50803260 	 1000 	 0.29563307762145996 	 0.29796862602233887 	 0.28720808029174805 	 0.28630828857421875 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:30.149441 test begin: paddle.bitwise_left_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.4498932361602783 	 0.4462854862213135 	 0.44077205657958984 	 0.43428802490234375 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:32.228879 test begin: paddle.bitwise_left_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.44985508918762207 	 0.4462003707885742 	 0.44079089164733887 	 0.43282246589660645 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:34.218900 test begin: paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.44781041145324707 	 0.45630335807800293 	 0.4385080337524414 	 0.43137407302856445 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:39.584290 test begin: paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.44767117500305176 	 0.4797542095184326 	 0.4383585453033447 	 0.4313657283782959 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:42.474458 test begin: paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.44759511947631836 	 0.4568824768066406 	 0.43152523040771484 	 0.4273219108581543 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:45.445933 test begin: paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.bitwise_left_shift 	 paddle.bitwise_left_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.4476473331451416 	 0.44965243339538574 	 0.4382765293121338 	 0.4376516342163086 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:48.296902 test begin: paddle.bitwise_not(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.2981405258178711 	 0.2963263988494873 	 0.28989529609680176 	 0.2847630977630615 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:49.859004 test begin: paddle.bitwise_not(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.2981741428375244 	 0.2999277114868164 	 0.28984546661376953 	 0.284771203994751 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:51.404915 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 101607120 	 1000 	 0.29817986488342285 	 0.29630541801452637 	 0.2897038459777832 	 0.2828099727630615 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:52.948402 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 101606940 	 1000 	 0.297440767288208 	 0.30185461044311523 	 0.2891201972961426 	 0.28463101387023926 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:54.566869 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 50803632 	 1000 	 0.29551172256469727 	 0.2979118824005127 	 0.28681468963623047 	 0.28626513481140137 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:55.706932 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 101606832 	 1000 	 0.29816508293151855 	 0.296297550201416 	 0.28975510597229004 	 0.2847893238067627 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:57.280517 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 50804280 	 1000 	 0.29573774337768555 	 0.29802489280700684 	 0.2873518466949463 	 0.28537940979003906 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:58.421075 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 101607480 	 1000 	 0.29744434356689453 	 0.29638099670410156 	 0.2892177104949951 	 0.2847762107849121 	 None 	 None 	 None 	 None 	 
2025-07-30 20:45:59.965686 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50805360 	 1000 	 0.2956833839416504 	 0.2979135513305664 	 0.287078857421875 	 0.2864861488342285 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:01.109185 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101608560 	 1000 	 0.297473669052124 	 0.2963254451751709 	 0.28908205032348633 	 0.2847144603729248 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:02.663731 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 50803740 	 1000 	 0.29578685760498047 	 0.2978498935699463 	 0.28743696212768555 	 0.28618931770324707 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:03.814349 test begin: paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2956845760345459 	 0.2979848384857178 	 0.2853891849517822 	 0.28570127487182617 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:04.984813 test begin: paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.2957139015197754 	 0.29787778854370117 	 0.2874126434326172 	 0.28613996505737305 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:06.159759 test begin: paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50803920 	 1000 	 0.295717716217041 	 0.29796671867370605 	 0.2874033451080322 	 0.2865006923675537 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:07.326894 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 508036320 	 1000 	 0.846388578414917 	 0.7470924854278564 	 0.8379523754119873 	 0.7352502346038818 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:16.077004 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 508042800 	 1000 	 0.8571836948394775 	 0.7476565837860107 	 0.8428323268890381 	 0.7358007431030273 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:24.586266 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 508053600 	 1000 	 0.8474814891815186 	 0.747072696685791 	 0.8391149044036865 	 0.7351109981536865 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:33.412636 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 508037400 	 1000 	 0.8570361137390137 	 0.7471532821655273 	 0.8487179279327393 	 0.7352132797241211 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:41.940190 test begin: paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8474743366241455 	 0.7564408779144287 	 0.8390641212463379 	 0.7346773147583008 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:51.026047 test begin: paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.847445011138916 	 0.7471449375152588 	 0.8389978408813477 	 0.7351889610290527 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:59.444645 test begin: paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([20, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508039200 	 1000 	 0.8475110530853271 	 0.7470347881317139 	 0.8389015197753906 	 0.7353205680847168 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:08.108461 test begin: paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50804280 	 1000 	 0.2957329750061035 	 0.29787135124206543 	 0.2865574359893799 	 0.28630924224853516 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:09.250815 test begin: paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([470410, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 508042800 	 1000 	 0.8571596145629883 	 0.7476770877838135 	 0.8487439155578613 	 0.7356863021850586 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:17.704836 test begin: paddle.bitwise_not(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_not 	 paddle.bitwise_not(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101607480 	 1000 	 0.297426700592041 	 0.2975797653198242 	 0.2891221046447754 	 0.2846672534942627 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:19.305130 test begin: paddle.bitwise_or(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4480772018432617 	 0.4498586654663086 	 0.43894290924072266 	 0.4376718997955322 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:22.106384 test begin: paddle.bitwise_or(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44815659523010254 	 0.4498271942138672 	 0.4371459484100342 	 0.4358243942260742 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:24.891876 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4482893943786621 	 0.44991636276245117 	 0.43935298919677734 	 0.43756604194641113 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:27.704778 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.44864654541015625 	 0.4518415927886963 	 0.43979430198669434 	 0.43761777877807617 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:30.506810 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11802864074707031 	 0.1172029972076416 	 0.10779476165771484 	 0.10479116439819336 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:32.123631 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.449660062789917 	 0.4482128620147705 	 0.44072628021240234 	 0.4337596893310547 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:34.170760 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.4484596252441406 	 0.454087495803833 	 0.43903160095214844 	 0.4373929500579834 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:39.409334 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.15549111366271973 	 0.22986292839050293 	 0.14556074142456055 	 0.21382832527160645 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:40.544342 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.31539130210876465 	 0.479708194732666 	 0.30534911155700684 	 0.4663078784942627 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:42.300810 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29609203338623047 	 0.3082430362701416 	 0.28600215911865234 	 0.294205904006958 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:43.440962 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11795210838317871 	 0.1175680160522461 	 0.1090841293334961 	 0.10358214378356934 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:45.051881 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.44983625411987305 	 0.448331356048584 	 0.44095468521118164 	 0.43388986587524414 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:47.022055 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.44841909408569336 	 0.44991278648376465 	 0.4394664764404297 	 0.43773984909057617 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:49.846606 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.17338347434997559 	 0.45154690742492676 	 0.16336584091186523 	 0.21319985389709473 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:52.665586 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11797523498535156 	 0.12729811668395996 	 0.10902833938598633 	 0.10378050804138184 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:55.022981 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29559898376464844 	 0.31352996826171875 	 0.28578710556030273 	 0.2946138381958008 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:56.184369 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.4499046802520752 	 0.4462268352508545 	 0.43409299850463867 	 0.4278895854949951 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:58.249556 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3446648120880127 	 0.4783182144165039 	 0.3277318477630615 	 0.4585449695587158 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:00.012362 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.4486963748931885 	 0.44992494583129883 	 0.43283772468566895 	 0.4312114715576172 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:02.872562 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11767244338989258 	 0.11514854431152344 	 0.10857892036437988 	 0.10287261009216309 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:04.571991 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.4498591423034668 	 0.44614195823669434 	 0.4409754276275635 	 0.43410372734069824 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:06.547183 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11766219139099121 	 0.11509490013122559 	 0.10868620872497559 	 0.10291790962219238 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:08.175353 test begin: paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4497542381286621 	 0.44618654251098633 	 0.44065165519714355 	 0.4342525005340576 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:10.148044 test begin: paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1176595687866211 	 0.11508297920227051 	 0.10777711868286133 	 0.10286569595336914 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:11.838566 test begin: paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44973039627075195 	 0.4463026523590088 	 0.4408397674560547 	 0.4340505599975586 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:13.843278 test begin: paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11765718460083008 	 0.11511421203613281 	 0.10873651504516602 	 0.10291123390197754 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:15.474585 test begin: paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4497363567352295 	 0.446120023727417 	 0.4408712387084961 	 0.43404245376586914 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:17.440860 test begin: paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11796283721923828 	 0.11777138710021973 	 0.10896921157836914 	 0.10371541976928711 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:19.048666 test begin: paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.4497859477996826 	 0.4461636543273926 	 0.4409348964691162 	 0.4342834949493408 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:21.053740 test begin: paddle.bitwise_or(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_or 	 paddle.bitwise_or(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.4487149715423584 	 0.4498937129974365 	 0.4398930072784424 	 0.43783092498779297 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:23.824389 test begin: paddle.bitwise_right_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.4498879909515381 	 0.4461658000946045 	 0.4408836364746094 	 0.4340224266052246 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:48:25.783237 test begin: paddle.bitwise_right_shift(Tensor([200, 127009],"int64"), Tensor([200, 127009],"int64"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 127009],"int64"), Tensor([200, 127009],"int64"), ) 	 50803600 	 1000 	 0.4480404853820801 	 0.44733619689941406 	 0.4393930435180664 	 0.4266681671142578 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:48:27.420023 test begin: paddle.bitwise_right_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.4497997760772705 	 0.4501609802246094 	 0.44083619117736816 	 0.4338564872741699 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:48:29.406718 test begin: paddle.bitwise_right_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4471755027770996 	 0.4497215747833252 	 0.43820953369140625 	 0.4373595714569092 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:48:32.201409 test begin: paddle.bitwise_right_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.4472811222076416 	 0.449862003326416 	 0.43827366828918457 	 0.43634891510009766 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:48:35.050654 test begin: paddle.bitwise_right_shift(Tensor([84673, 300],"int64"), Tensor([84673, 300],"int64"), )
[Prof] paddle.bitwise_right_shift 	 paddle.bitwise_right_shift(Tensor([84673, 300],"int64"), Tensor([84673, 300],"int64"), ) 	 50803800 	 1000 	 0.44861745834350586 	 0.4478328227996826 	 0.43990182876586914 	 0.41774439811706543 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:48:39.552621 test begin: paddle.bitwise_xor(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4484589099884033 	 0.44985008239746094 	 0.439561128616333 	 0.4377114772796631 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:42.316297 test begin: paddle.bitwise_xor(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4482533931732178 	 0.449798583984375 	 0.43933701515197754 	 0.43767428398132324 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:45.081935 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.44820523262023926 	 0.44988441467285156 	 0.4394199848175049 	 0.4377291202545166 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:48.367539 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.44849300384521484 	 0.4498860836029053 	 0.439558744430542 	 0.4375455379486084 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:51.195115 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11802196502685547 	 0.11743402481079102 	 0.10892081260681152 	 0.1051938533782959 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:52.811075 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.4497368335723877 	 0.45070457458496094 	 0.44089674949645996 	 0.433713436126709 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:54.800974 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.44835448265075684 	 0.45133256912231445 	 0.43953752517700195 	 0.4374735355377197 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:59.856572 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.16825366020202637 	 0.22736692428588867 	 0.1582503318786621 	 0.21362948417663574 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:00.969751 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3154256343841553 	 0.47969794273376465 	 0.2983250617980957 	 0.45969629287719727 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:02.704195 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.296069860458374 	 0.30820417404174805 	 0.2788522243499756 	 0.28826260566711426 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:03.850089 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11798548698425293 	 0.1163334846496582 	 0.10217595100402832 	 0.09766435623168945 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:05.477783 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.449784517288208 	 0.44617557525634766 	 0.440093994140625 	 0.43407630920410156 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:07.442292 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.44814610481262207 	 0.44995689392089844 	 0.43926048278808594 	 0.43778181076049805 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:10.216167 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1765897274017334 	 0.22724604606628418 	 0.1665494441986084 	 0.2136855125427246 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:11.310476 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11799263954162598 	 0.11646223068237305 	 0.10895776748657227 	 0.10430693626403809 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:12.940650 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.29567909240722656 	 0.3082275390625 	 0.2857024669647217 	 0.2946953773498535 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:14.087322 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.4497697353363037 	 0.4461228847503662 	 0.44086313247680664 	 0.43387722969055176 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:16.082937 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3446061611175537 	 0.4784824848175049 	 0.33472514152526855 	 0.46505188941955566 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:17.848700 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.44837021827697754 	 0.4497702121734619 	 0.4394373893737793 	 0.4376335144042969 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:20.668678 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11766958236694336 	 0.11546635627746582 	 0.1084754467010498 	 0.10321331024169922 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:22.283383 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.44979190826416016 	 0.44614553451538086 	 0.44091343879699707 	 0.43399477005004883 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:24.261719 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1176457405090332 	 0.11547589302062988 	 0.10861945152282715 	 0.10329174995422363 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:25.952992 test begin: paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.4496314525604248 	 0.44614291191101074 	 0.43961334228515625 	 0.43392133712768555 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:27.917995 test begin: paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11766862869262695 	 0.11549735069274902 	 0.10858774185180664 	 0.1033484935760498 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:29.530683 test begin: paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44977235794067383 	 0.44649672508239746 	 0.44084715843200684 	 0.43387889862060547 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:31.506906 test begin: paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.1176762580871582 	 0.11591911315917969 	 0.10863852500915527 	 0.10321593284606934 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:33.166519 test begin: paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.44976067543029785 	 0.44680285453796387 	 0.4408233165740967 	 0.43370985984802246 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:35.171527 test begin: paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11795568466186523 	 0.12171578407287598 	 0.10893440246582031 	 0.10400819778442383 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:39.398700 test begin: paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.44971680641174316 	 0.44802188873291016 	 0.44069743156433105 	 0.433854341506958 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:41.399247 test begin: paddle.bitwise_xor(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.bitwise_xor 	 paddle.bitwise_xor(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.44846582412719727 	 0.44983625411987305 	 0.43958187103271484 	 0.43764781951904297 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:44.230504 test begin: paddle.bmm(Tensor([112, 1043, 435],"float32"), Tensor([112, 435, 64],"float32"), )

[Prof] paddle.bmm 	 paddle.bmm(Tensor([112, 1043, 435],"float32"), Tensor([112, 435, 64],"float32"), ) 	 53933040 	 1000 	 0.8942279815673828 	 0.9025239944458008 	 0.881375789642334 	 0.8771476745605469 	 1.6097018718719482 	 1.6098392009735107 	 0.8224732875823975 	 0.8225522041320801 	 
2025-07-30 20:49:50.643683 test begin: paddle.bmm(Tensor([112, 435, 435],"float32"), Tensor([112, 435, 1043],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([112, 435, 435],"float32"), Tensor([112, 435, 1043],"float32"), ) 	 72008160 	 1000 	 3.37018084526062 	 3.37777042388916 	 3.3574118614196777 	 3.3513824939727783 	 6.950579404830933 	 6.950005292892456 	 3.551710844039917 	 3.551422595977783 	 
2025-07-30 20:50:15.110150 test begin: paddle.bmm(Tensor([14, 81, 7332],"float32"), Tensor([14, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([14, 81, 7332],"float32"), Tensor([14, 7332, 512],"float32"), ) 	 60870264 	 1000 	 1.4671907424926758 	 1.467299461364746 	 1.454404592514038 	 1.4509553909301758 	 1.4255270957946777 	 1.4254975318908691 	 0.72835373878479 	 0.7283308506011963 	 
2025-07-30 20:50:21.839350 test begin: paddle.bmm(Tensor([1825, 435, 435],"float32"), Tensor([1825, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([1825, 435, 435],"float32"), Tensor([1825, 435, 64],"float32"), ) 	 396143625 	 1000 	 6.017980337142944 	 6.0181310176849365 	 6.005242586135864 	 6.001609802246094 	 9.952194690704346 	 9.95140790939331 	 5.085528373718262 	 5.084996223449707 	 
2025-07-30 20:51:01.319674 test begin: paddle.bmm(Tensor([26, 1024, 1024],"float32"), Tensor([26, 1024, 1909],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([26, 1024, 1024],"float32"), Tensor([26, 1024, 1909],"float32"), ) 	 78088192 	 1000 	 5.942569255828857 	 5.942409038543701 	 5.9297263622283936 	 5.9262306690216064 	 12.074045181274414 	 12.07166051864624 	 6.169738054275513 	 6.168484449386597 	 
2025-07-30 20:51:39.958466 test begin: paddle.bmm(Tensor([26, 1909, 1024],"float32"), Tensor([26, 1024, 12],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([26, 1909, 1024],"float32"), Tensor([26, 1024, 12],"float32"), ) 	 51144704 	 1000 	 0.8278229236602783 	 0.8280835151672363 	 0.8151018619537354 	 0.8120162487030029 	 0.9364104270935059 	 0.9365108013153076 	 0.47843170166015625 	 0.4784727096557617 	 
2025-07-30 20:51:44.310673 test begin: paddle.bmm(Tensor([269, 435, 435],"float32"), Tensor([269, 435, 64],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([269, 435, 435],"float32"), Tensor([269, 435, 64],"float32"), ) 	 58390485 	 1000 	 0.8956165313720703 	 0.8958423137664795 	 0.8750109672546387 	 0.8722929954528809 	 1.4856665134429932 	 1.4856929779052734 	 0.7590734958648682 	 0.7590939998626709 	 
2025-07-30 20:51:50.089853 test begin: paddle.bmm(Tensor([4, 1733, 7332],"float32"), Tensor([4, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 1733, 7332],"float32"), Tensor([4, 7332, 512],"float32"), ) 	 65841360 	 1000 	 4.385453701019287 	 4.386841535568237 	 4.364908933639526 	 4.361259460449219 	 6.3328025341033936 	 6.332472324371338 	 3.2360196113586426 	 3.235732316970825 	 
2025-07-30 20:52:12.717033 test begin: paddle.bmm(Tensor([4, 81, 156801],"float32"), Tensor([4, 156801, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 156801],"float32"), Tensor([4, 156801, 512],"float32"), ) 	 371931972 	 1000 	 31.183338165283203 	 31.18122911453247 	 31.170647621154785 	 31.165269374847412 	 8.201557874679565 	 8.537463426589966 	 4.190335512161255 	 4.5250749588012695 	 
2025-07-30 20:53:38.067344 test begin: paddle.bmm(Tensor([4, 81, 24807],"float32"), Tensor([4, 24807, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 24807],"float32"), Tensor([4, 24807, 512],"float32"), ) 	 58842204 	 1000 	 4.941882848739624 	 4.941764831542969 	 4.92914605140686 	 4.925837516784668 	 1.3919086456298828 	 1.3929450511932373 	 0.7118234634399414 	 0.7111690044403076 	 
2025-07-30 20:53:51.857657 test begin: paddle.bmm(Tensor([4, 81, 7332],"float32"), Tensor([4, 7332, 1733],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([4, 81, 7332],"float32"), Tensor([4, 7332, 1733],"float32"), ) 	 53200992 	 1000 	 1.4673514366149902 	 1.4673776626586914 	 1.4545862674713135 	 1.4514999389648438 	 1.6460628509521484 	 1.6445119380950928 	 0.8416197299957275 	 0.8402416706085205 	 
2025-07-30 20:53:58.966779 test begin: paddle.bmm(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 12],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 12],"float32"), ) 	 51982336 	 1000 	 0.8292913436889648 	 0.8281550407409668 	 0.8165831565856934 	 0.8124806880950928 	 0.9918162822723389 	 0.991736888885498 	 0.5067415237426758 	 0.5066916942596436 	 
2025-07-30 20:54:03.423575 test begin: paddle.bmm(Tensor([86, 81, 7332],"float32"), Tensor([86, 7332, 512],"float32"), )
[Prof] paddle.bmm 	 paddle.bmm(Tensor([86, 81, 7332],"float32"), Tensor([86, 7332, 512],"float32"), ) 	 373917336 	 1000 	 5.8397722244262695 	 5.892064332962036 	 5.827056884765625 	 5.875993490219116 	 8.364516735076904 	 8.364491939544678 	 4.2741358280181885 	 4.274169445037842 	 
2025-07-30 20:54:40.088667 test begin: paddle.broadcast_tensors(list[Tensor([127009, 200],"float64"),Tensor([127009, 200],"float64"),], )
[Prof] paddle.broadcast_tensors 	 paddle.broadcast_tensors(list[Tensor([127009, 200],"float64"),Tensor([127009, 200],"float64"),], ) 	 50803600 	 1000 	 0.6157815456390381 	 0.01047825813293457 	 0.3153045177459717 	 3.6716461181640625e-05 	 0.6241998672485352 	 0.06287741661071777 	 0.15944266319274902 	 4.696846008300781e-05 	 
2025-07-30 20:54:43.414496 test begin: paddle.broadcast_tensors(list[Tensor([200, 127009],"float64"),Tensor([200, 127009],"float64"),], )
[Prof] paddle.broadcast_tensors 	 paddle.broadcast_tensors(list[Tensor([200, 127009],"float64"),Tensor([200, 127009],"float64"),], ) 	 50803600 	 1000 	 0.6143834590911865 	 0.010360002517700195 	 0.31383585929870605 	 2.6226043701171875e-05 	 0.6255779266357422 	 0.0876312255859375 	 0.15948033332824707 	 0.0001583099365234375 	 
2025-07-30 20:54:46.912084 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), ) 	 38102403 	 1000 	 1.3431000709533691 	 1.037203311920166 	 1.332038164138794 	 1.0260424613952637 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:50.161669 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), out_int32=True, ) 	 38102403 	 1000 	 1.3362326622009277 	 1.0328500270843506 	 1.3247663974761963 	 1.0213065147399902 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:53.274052 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([12700801],"float64"), right=True, ) 	 38102403 	 1000 	 1.3448846340179443 	 1.0411760807037354 	 1.3336436748504639 	 1.0298194885253906 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:56.481093 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), ) 	 25401606 	 1000 	 0.31807661056518555 	 0.3152751922607422 	 0.30731916427612305 	 0.3041872978210449 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:57.596376 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), out_int32=True, ) 	 25401606 	 1000 	 0.28475356101989746 	 0.2452692985534668 	 0.2735419273376465 	 0.23360133171081543 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:58.613921 test begin: paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 12700801],"float64"), Tensor([4],"float64"), right=True, ) 	 25401606 	 1000 	 0.3164341449737549 	 0.31482911109924316 	 0.3050270080566406 	 0.3033316135406494 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:59.894869 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 76204803 	 1000 	 2.775606155395508 	 2.143052101135254 	 2.7572085857391357 	 2.131739616394043 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:06.878568 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 76204803 	 1000 	 2.7711732387542725 	 2.138667345046997 	 2.7519757747650146 	 2.121121644973755 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:13.404717 test begin: paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 25401601],"float64"), Tensor([25401601],"float64"), right=True, ) 	 76204803 	 1000 	 2.7778759002685547 	 2.150585174560547 	 2.766465425491333 	 2.1391239166259766 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:19.897522 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), ) 	 2540160109 	 1000 	 0.011066675186157227 	 0.013041973114013672 	 1.7642974853515625e-05 	 5.316734313964844e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:56:07.858046 test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2540160101],"float64"), right=True, ) 	 2540160109 	 1000 	 0.011445045471191406 	 0.013127565383911133 	 1.5020370483398438e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:01.945562 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), ) 	 25402405 	 1000 	 0.010951042175292969 	 0.011156797409057617 	 1.8596649169921875e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:02.455616 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), out_int32=True, ) 	 25402405 	 1000 	 0.011354446411132812 	 0.01137089729309082 	 1.52587890625e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:02.963948 test begin: paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([201, 4],"float64"), Tensor([25401601],"float64"), right=True, ) 	 25402405 	 1000 	 0.019207477569580078 	 0.017206668853759766 	 1.6689300537109375e-05 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:03.489810 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), ) 	 25401608 	 1000 	 0.31761813163757324 	 0.3152496814727783 	 0.2992076873779297 	 0.29799461364746094 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:04.610674 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), out_int32=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), out_int32=True, ) 	 25401608 	 1000 	 0.2847604751586914 	 0.24984264373779297 	 0.2659292221069336 	 0.22810864448547363 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:05.659833 test begin: paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), right=True, )
[Prof] paddle.bucketize 	 paddle.bucketize(Tensor([6350401, 4],"float64"), Tensor([4],"float64"), right=True, ) 	 25401608 	 1000 	 0.317950963973999 	 0.3156309127807617 	 0.2991018295288086 	 0.29808688163757324 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:06.780815 test begin: paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([20],"complex128"),Tensor([50],"complex128"),Tensor([5080],"complex128"),], ) 	 5150 	 1000 	 0.5901329517364502 	 1.11818265914917 	 0.0861213207244873 	 0.28506898880004883 	 110.62550616264343 	 0.5252060890197754 	 28.215852975845337 	 0.10726761817932129 	 
2025-07-30 20:59:00.264080 test begin: paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([30],"complex128"),Tensor([30],"complex128"),Tensor([5080],"complex128"),], ) 	 5140 	 1000 	 0.532611608505249 	 1.0057861804962158 	 0.07770252227783203 	 0.25832533836364746 	 78.14118194580078 	 0.4782261848449707 	 19.94073510169983 	 0.09764528274536133 	 
2025-07-30 21:00:20.920810 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([30],"int32"),Tensor([5080],"int32"),], ) 	 5150 	 1000 	 0.3616344928741455 	 0.534069299697876 	 0.05280613899230957 	 0.13444232940673828 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:01:22.433763 test begin: paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], )
[Prof] paddle.cartesian_prod 	 paddle.cartesian_prod(list[Tensor([40],"int32"),Tensor([400],"int32"),Tensor([508],"int32"),], ) 	 948 	 1000 	 0.4710853099822998 	 0.7053115367889404 	 0.06876564025878906 	 0.17985844612121582 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:40.875466 test begin: paddle.cast(Tensor([1, 1, 32768, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([1, 1, 32768, 32768],"float16"), dtype=Dtype(float16), ) 	 1073741824 	 1000 	 3.2666256427764893 	 0.0019865036010742188 	 1.668550968170166 	 2.09808349609375e-05 	 3.26802659034729 	 0.06181740760803223 	 1.6691272258758545 	 8.678436279296875e-05 	 combined
2025-07-30 21:03:32.971537 test begin: paddle.cast(Tensor([128256, 793],"bfloat16"), Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([128256, 793],"bfloat16"), Dtype(float16), ) 	 101707008 	 1000 	 0.29821133613586426 	 0.5195395946502686 	 0.28861522674560547 	 0.49717044830322266 	 0.29850339889526367 	 0.5060312747955322 	 0.2400341033935547 	 0.44382715225219727 	 combined
2025-07-30 21:03:39.472474 test begin: paddle.cast(Tensor([2, 1, 1551, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 1551, 32768],"float16"), dtype=Dtype(float16), ) 	 101646336 	 1000 	 0.31304335594177246 	 0.001981496810913086 	 0.3022274971008301 	 1.6927719116210938e-05 	 0.31313538551330566 	 0.04410910606384277 	 0.2554750442504883 	 3.814697265625e-05 	 combined
2025-07-30 21:03:43.854922 test begin: paddle.cast(Tensor([2, 1, 32768, 1551],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 32768, 1551],"float16"), dtype=Dtype(float16), ) 	 101646336 	 1000 	 0.31307172775268555 	 0.0031659603118896484 	 0.29445862770080566 	 1.8358230590820312e-05 	 0.3131556510925293 	 0.04860568046569824 	 0.2472972869873047 	 6.699562072753906e-05 	 combined
2025-07-30 21:03:48.448903 test begin: paddle.cast(Tensor([2, 1, 32768, 32768],"float16"), dtype=Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1, 32768, 32768],"float16"), dtype=Dtype(float16), ) 	 2147483648 	 1000 	 6.515005111694336 	 0.002656221389770508 	 3.3297762870788574 	 6.127357482910156e-05 	 6.516493082046509 	 0.04540061950683594 	 3.3298466205596924 	 5.245208740234375e-05 	 combined
2025-07-30 21:05:21.674981 test begin: paddle.cast(Tensor([2, 1024, 50304],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([2, 1024, 50304],"float16"), dtype="float32", ) 	 103022592 	 1000 	 0.4857192039489746 	 0.5575439929962158 	 0.4662013053894043 	 0.5373125076293945 	 0.45581555366516113 	 0.45948171615600586 	 0.3921189308166504 	 0.38893985748291016 	 combined
2025-07-30 21:05:27.178338 test begin: paddle.cast(Tensor([33076, 3072],"bfloat16"), Dtype(float16), )
[Prof] paddle.cast 	 paddle.cast(Tensor([33076, 3072],"bfloat16"), Dtype(float16), ) 	 101609472 	 1000 	 0.29783082008361816 	 0.5132122039794922 	 0.2882513999938965 	 0.4981253147125244 	 0.2981584072113037 	 0.5055792331695557 	 0.2398223876953125 	 0.44286179542541504 	 combined
2025-07-30 21:05:32.964301 test begin: paddle.cast(Tensor([8, 1024, 12404],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([8, 1024, 12404],"float16"), dtype="float32", ) 	 101613568 	 1000 	 0.47942471504211426 	 0.5556926727294922 	 0.4678196907043457 	 0.5364358425140381 	 0.44954586029052734 	 0.4532902240753174 	 0.3953061103820801 	 0.3901641368865967 	 combined
2025-07-30 21:05:39.429916 test begin: paddle.cast(Tensor([8, 253, 50304],"float16"), dtype="float32", )
[Prof] paddle.cast 	 paddle.cast(Tensor([8, 253, 50304],"float16"), dtype="float32", ) 	 101815296 	 1000 	 0.4801368713378906 	 0.558570146560669 	 0.4685056209564209 	 0.5371389389038086 	 0.45052409172058105 	 0.45533227920532227 	 0.39621973037719727 	 0.38434648513793945 	 combined
2025-07-30 21:05:44.844607 test begin: paddle.cdist(Tensor([12700801, 4],"float32"), Tensor([1, 4],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([12700801, 4],"float32"), Tensor([1, 4],"float32"), p=1, ) 	 50803208 	 1000 	 0.6906683444976807 	 26.803727388381958 	 0.3528599739074707 	 26.780056953430176 	 8.358476877212524 	 14.202341556549072 	 2.8489320278167725 	 2.8963887691497803 	 
2025-07-30 21:06:37.258470 test begin: paddle.cdist(Tensor([6380, 7963],"float32"), Tensor([1, 7963],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([6380, 7963],"float32"), Tensor([1, 7963],"float32"), p=1, ) 	 50811903 	 1000 	 0.45021843910217285 	 0.1941840648651123 	 0.23006129264831543 	 0.1719970703125 	 2.1828601360321045 	 1.1818270683288574 	 0.7423148155212402 	 0.24187874794006348 	 
2025-07-30 21:06:43.194626 test begin: paddle.cdist(Tensor([8550, 5942],"float32"), Tensor([1, 5942],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([8550, 5942],"float32"), Tensor([1, 5942],"float32"), p=1, ) 	 50810042 	 1000 	 0.45059919357299805 	 0.1932990550994873 	 0.2302248477935791 	 0.1715078353881836 	 2.193385124206543 	 1.1647965908050537 	 0.7459039688110352 	 0.2371683120727539 	 
2025-07-30 21:06:48.037524 test begin: paddle.cdist(Tensor([900, 56449],"float32"), Tensor([1, 56449],"float32"), p=1, )
[Prof] paddle.cdist 	 paddle.cdist(Tensor([900, 56449],"float32"), Tensor([1, 56449],"float32"), p=1, ) 	 50860549 	 1000 	 0.4786567687988281 	 0.2920873165130615 	 0.1629199981689453 	 0.2700786590576172 	 2.1514153480529785 	 1.2289531230926514 	 0.7317874431610107 	 0.3136105537414551 	 
2025-07-30 21:06:52.998361 test begin: paddle.ceil(Tensor([12404, 32, 128],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([12404, 32, 128],"float32"), ) 	 50806784 	 1000 	 0.2956230640411377 	 0.2979464530944824 	 0.2796516418457031 	 0.27497100830078125 	 0.13435673713684082 	 0.13413786888122559 	 0.07341742515563965 	 0.0665428638458252 	 
2025-07-30 21:06:55.597074 test begin: paddle.ceil(Tensor([141121, 6, 3, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([141121, 6, 3, 1, 2, 5],"float64"), ) 	 25401780 	 1000 	 0.2992880344390869 	 0.29983997344970703 	 0.2903165817260742 	 0.2877969741821289 	 0.13540339469909668 	 0.13461518287658691 	 0.07960844039916992 	 0.06974315643310547 	 
2025-07-30 21:06:57.531567 test begin: paddle.ceil(Tensor([3, 141121, 3, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 141121, 3, 4, 1, 5],"float64"), ) 	 25401780 	 1000 	 0.2979588508605957 	 0.3000669479370117 	 0.2890655994415283 	 0.2870054244995117 	 0.13405752182006836 	 0.13458013534545898 	 0.08231353759765625 	 0.061385154724121094 	 
2025-07-30 21:06:59.372767 test begin: paddle.ceil(Tensor([3, 282241, 3, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 282241, 3, 1, 2, 5],"float64"), ) 	 25401690 	 1000 	 0.29800963401794434 	 0.31317996978759766 	 0.28911423683166504 	 0.28786730766296387 	 0.1353158950805664 	 0.13466358184814453 	 0.08401608467102051 	 0.04774022102355957 	 
2025-07-30 21:07:01.279644 test begin: paddle.ceil(Tensor([3, 6, 141121, 1, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 141121, 1, 2, 5],"float64"), ) 	 25401780 	 1000 	 0.29796528816223145 	 0.29894161224365234 	 0.2890338897705078 	 0.287888765335083 	 0.13405251502990723 	 0.1346116065979004 	 0.08273553848266602 	 0.060448408126831055 	 
2025-07-30 21:07:03.131649 test begin: paddle.ceil(Tensor([3, 6, 3, 1, 2, 235201],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 1, 2, 235201],"float64"), ) 	 25401708 	 1000 	 0.29796481132507324 	 0.29900550842285156 	 0.28896164894104004 	 0.2879331111907959 	 0.1340646743774414 	 0.13471198081970215 	 0.08051896095275879 	 0.06972122192382812 	 
2025-07-30 21:07:04.982052 test begin: paddle.ceil(Tensor([3, 6, 3, 1, 94081, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 1, 94081, 5],"float64"), ) 	 25401870 	 1000 	 0.2972288131713867 	 0.2989308834075928 	 0.28827810287475586 	 0.28790783882141113 	 0.1340489387512207 	 0.1345973014831543 	 0.08242559432983398 	 0.07047390937805176 	 
2025-07-30 21:07:06.818429 test begin: paddle.ceil(Tensor([3, 6, 3, 4, 1, 117601],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 4, 1, 117601],"float64"), ) 	 25401816 	 1000 	 0.2980515956878662 	 0.29896020889282227 	 0.28895092010498047 	 0.28786301612854004 	 0.13405179977416992 	 0.13460087776184082 	 0.0825967788696289 	 0.06984806060791016 	 
2025-07-30 21:07:08.664250 test begin: paddle.ceil(Tensor([3, 6, 3, 4, 23521, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 4, 23521, 5],"float64"), ) 	 25402680 	 1000 	 0.2979860305786133 	 0.300112247467041 	 0.28905749320983887 	 0.2889540195465088 	 0.13532614707946777 	 0.1346118450164795 	 0.08363890647888184 	 0.07030725479125977 	 
2025-07-30 21:07:10.570136 test begin: paddle.ceil(Tensor([3, 6, 3, 47041, 2, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 47041, 2, 5],"float64"), ) 	 25402140 	 1000 	 0.2972719669342041 	 0.29897451400756836 	 0.288210391998291 	 0.2878553867340088 	 0.1341228485107422 	 0.1345810890197754 	 0.08234715461730957 	 0.06832599639892578 	 
2025-07-30 21:07:12.479205 test begin: paddle.ceil(Tensor([3, 6, 3, 94081, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 3, 94081, 1, 5],"float64"), ) 	 25401870 	 1000 	 0.29723143577575684 	 0.30155277252197266 	 0.28824496269226074 	 0.2879507541656494 	 0.13461613655090332 	 0.13461899757385254 	 0.08290338516235352 	 0.07084178924560547 	 
2025-07-30 21:07:14.336866 test begin: paddle.ceil(Tensor([3, 6, 70561, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([3, 6, 70561, 4, 1, 5],"float64"), ) 	 25401960 	 1000 	 0.2980213165283203 	 0.2989790439605713 	 0.28906869888305664 	 0.2879307270050049 	 0.13406133651733398 	 0.13458037376403809 	 0.07820534706115723 	 0.07075309753417969 	 
2025-07-30 21:07:16.162656 test begin: paddle.ceil(Tensor([32, 12404, 128],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([32, 12404, 128],"float32"), ) 	 50806784 	 1000 	 0.29561543464660645 	 0.29803919792175293 	 0.28656578063964844 	 0.2869877815246582 	 0.13417410850524902 	 0.13412880897521973 	 0.08225631713867188 	 0.07301759719848633 	 
2025-07-30 21:07:18.598872 test begin: paddle.ceil(Tensor([32, 32, 49613],"float32"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([32, 32, 49613],"float32"), ) 	 50803712 	 1000 	 0.29685354232788086 	 0.29775381088256836 	 0.28492283821105957 	 0.2869133949279785 	 0.13425421714782715 	 0.13416337966918945 	 0.0821530818939209 	 0.07193732261657715 	 
2025-07-30 21:07:21.041449 test begin: paddle.ceil(Tensor([70561, 6, 3, 4, 1, 5],"float64"), )
[Prof] paddle.ceil 	 paddle.ceil(Tensor([70561, 6, 3, 4, 1, 5],"float64"), ) 	 25401960 	 1000 	 0.2980365753173828 	 0.2989215850830078 	 0.28915858268737793 	 0.2877390384674072 	 0.1340773105621338 	 0.13459277153015137 	 0.08158302307128906 	 0.0708775520324707 	 
2025-07-30 21:07:22.907838 test begin: paddle.chunk(Tensor([115, 216, 64, 64],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([115, 216, 64, 64],"float16"), 3, axis=1, ) 	 101744640 	 1000 	 0.43574070930480957 	 0.020450592041015625 	 0.419405460357666 	 3.123283386230469e-05 	 0.31278419494628906 	 0.5059413909912109 	 0.24242234230041504 	 0.4155082702636719 	 
2025-07-30 21:07:28.243827 test begin: paddle.chunk(Tensor([16, 128, 24807],"float32"), 2, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([16, 128, 24807],"float32"), 2, axis=1, ) 	 50804736 	 1000 	 0.3380708694458008 	 0.006355762481689453 	 0.32260560989379883 	 2.002716064453125e-05 	 0.3146648406982422 	 0.30880117416381836 	 0.2569389343261719 	 0.23142027854919434 	 
2025-07-30 21:07:30.772130 test begin: paddle.chunk(Tensor([16, 128, 25500],"float32"), 2, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([16, 128, 25500],"float32"), 2, axis=1, ) 	 52224000 	 1000 	 0.3567392826080322 	 0.0063707828521728516 	 0.3420989513397217 	 1.8835067749023438e-05 	 0.32307910919189453 	 0.31679248809814453 	 0.2637753486633301 	 0.23938822746276855 	 
2025-07-30 21:07:33.455539 test begin: paddle.chunk(Tensor([4, 216, 1838, 64],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 1838, 64],"float16"), 3, axis=1, ) 	 101634048 	 1000 	 0.4339425563812256 	 0.007371664047241211 	 0.4181499481201172 	 2.2649765014648438e-05 	 0.30992794036865234 	 0.5042324066162109 	 0.2467482089996338 	 0.41559576988220215 	 
2025-07-30 21:07:39.861923 test begin: paddle.chunk(Tensor([4, 216, 64, 1838],"float16"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 64, 1838],"float16"), 3, axis=1, ) 	 101634048 	 1000 	 0.4338865280151367 	 0.0076084136962890625 	 0.4181187152862549 	 4.076957702636719e-05 	 0.30980944633483887 	 0.5042312145233154 	 0.24915099143981934 	 0.38967227935791016 	 
2025-07-30 21:07:46.082545 test begin: paddle.chunk(Tensor([4, 216, 64, 919],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 64, 919],"float32"), 3, axis=1, ) 	 50817024 	 1000 	 0.3396909236907959 	 0.007421970367431641 	 0.3238184452056885 	 2.0503997802734375e-05 	 0.31006503105163574 	 0.3051934242248535 	 0.24978375434875488 	 0.20649242401123047 	 
2025-07-30 21:07:48.613819 test begin: paddle.chunk(Tensor([4, 216, 919, 64],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([4, 216, 919, 64],"float32"), 3, axis=1, ) 	 50817024 	 1000 	 0.33834052085876465 	 0.007382392883300781 	 0.3224496841430664 	 1.7881393432617188e-05 	 0.3100299835205078 	 0.30515480041503906 	 0.2489619255065918 	 0.20946407318115234 	 
2025-07-30 21:07:51.152462 test begin: paddle.chunk(Tensor([58, 216, 64, 64],"float32"), 3, axis=1, )
[Prof] paddle.chunk 	 paddle.chunk(Tensor([58, 216, 64, 64],"float32"), 3, axis=1, ) 	 51314688 	 1000 	 0.3482532501220703 	 0.007408618927001953 	 0.33237361907958984 	 2.0503997802734375e-05 	 0.3143324851989746 	 0.3085899353027344 	 0.25417017936706543 	 0.222639799118042 	 
2025-07-30 21:07:53.688629 test begin: paddle.clip(Tensor([1408, 36082],"float32"), min=-2, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([1408, 36082],"float32"), min=-2, max=2, ) 	 50803456 	 1000 	 0.29532432556152344 	 0.29963254928588867 	 0.277728796005249 	 0.28620195388793945 	 0.44968247413635254 	 0.736295223236084 	 0.3958268165588379 	 0.1502687931060791 	 
2025-07-30 21:07:57.235573 test begin: paddle.clip(Tensor([2, 3840, 10240],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([2, 3840, 10240],"float32"), 0, 255, ) 	 78643200 	 1000 	 0.45479846000671387 	 0.45929408073425293 	 0.43814873695373535 	 0.4460291862487793 	 0.6941831111907959 	 1.1209251880645752 	 0.6371228694915771 	 0.22919535636901855 	 
2025-07-30 21:08:02.444698 test begin: paddle.clip(Tensor([23, 17, 256, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([23, 17, 256, 256],"float64"), min=0, max=2, ) 	 25624576 	 1000 	 0.301222562789917 	 0.30121564865112305 	 0.2841482162475586 	 0.2882215976715088 	 0.45148682594299316 	 0.7269060611724854 	 0.39585351943969727 	 0.14955353736877441 	 
2025-07-30 21:08:05.271336 test begin: paddle.clip(Tensor([24, 17, 244, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 244, 256],"float64"), min=0, max=2, ) 	 25485312 	 1000 	 0.29958224296569824 	 0.2995903491973877 	 0.2826542854309082 	 0.28621959686279297 	 0.4492659568786621 	 0.7219479084014893 	 0.39567136764526367 	 0.14759469032287598 	 
2025-07-30 21:08:08.041839 test begin: paddle.clip(Tensor([24, 17, 256, 244],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 256, 244],"float64"), min=0, max=2, ) 	 25485312 	 1000 	 0.29961419105529785 	 0.29956626892089844 	 0.28238701820373535 	 0.2862880229949951 	 0.45061564445495605 	 0.7231872081756592 	 0.39575743675231934 	 0.1476423740386963 	 
2025-07-30 21:08:10.846910 test begin: paddle.clip(Tensor([24, 17, 256, 256],"float64"), min=0, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([24, 17, 256, 256],"float64"), min=0, max=2, ) 	 26738688 	 1000 	 0.31414341926574707 	 0.31415843963623047 	 0.2970449924468994 	 0.3013639450073242 	 0.4714672565460205 	 0.7557461261749268 	 0.4176137447357178 	 0.15452909469604492 	 
2025-07-30 21:08:13.761159 test begin: paddle.clip(Tensor([3, 1654, 10240],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([3, 1654, 10240],"float32"), 0, 255, ) 	 50810880 	 1000 	 0.2952723503112793 	 0.298372745513916 	 0.27849888801574707 	 0.28472304344177246 	 0.44968247413635254 	 0.733853816986084 	 0.3956129550933838 	 0.1500248908996582 	 
2025-07-30 21:08:17.142098 test begin: paddle.clip(Tensor([3, 3840, 4411],"float32"), 0, 255, )
[Prof] paddle.clip 	 paddle.clip(Tensor([3, 3840, 4411],"float32"), 0, 255, ) 	 50814720 	 1000 	 0.2954070568084717 	 0.2988259792327881 	 0.26985692977905273 	 0.27678513526916504 	 0.45226001739501953 	 0.7353384494781494 	 0.38949108123779297 	 0.1503300666809082 	 
2025-07-30 21:08:20.743999 test begin: paddle.clip(Tensor([8269, 6144],"float32"), min=-2, max=2, )
[Prof] paddle.clip 	 paddle.clip(Tensor([8269, 6144],"float32"), min=-2, max=2, ) 	 50804736 	 1000 	 0.2952268123626709 	 0.29783201217651367 	 0.27791738510131836 	 0.28488683700561523 	 0.4495265483856201 	 0.7363965511322021 	 0.39505958557128906 	 0.15122222900390625 	 
2025-07-30 21:08:24.126301 test begin: paddle.clone(Tensor([145, 12, 112, 261],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 12, 112, 261],"float32"), ) 	 50863680 	 1000 	 0.3149070739746094 	 0.31396961212158203 	 0.16092848777770996 	 0.1603384017944336 	 0.30848193168640137 	 0.0650017261505127 	 0.15757966041564941 	 5.8650970458984375e-05 	 
2025-07-30 21:08:26.691985 test begin: paddle.clone(Tensor([145, 12, 261, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 12, 261, 112],"float32"), ) 	 50863680 	 1000 	 0.31602048873901367 	 0.31403088569641113 	 0.16204023361206055 	 0.16034364700317383 	 0.30847883224487305 	 0.048911094665527344 	 0.1575789451599121 	 6.413459777832031e-05 	 
2025-07-30 21:08:29.249001 test begin: paddle.clone(Tensor([145, 28, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([145, 28, 112, 112],"float32"), ) 	 50928640 	 1000 	 0.3138401508331299 	 0.3114035129547119 	 0.3045310974121094 	 0.29830265045166016 	 0.31369924545288086 	 0.04809212684631348 	 0.2594165802001953 	 2.9087066650390625e-05 	 
2025-07-30 21:08:31.789292 test begin: paddle.clone(Tensor([22, 185, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 185, 112, 112],"float32"), ) 	 51054080 	 1000 	 0.31743860244750977 	 0.3164973258972168 	 0.16221046447753906 	 0.16088080406188965 	 0.3174173831939697 	 0.0480039119720459 	 0.16216731071472168 	 3.4809112548828125e-05 	 
2025-07-30 21:08:34.373013 test begin: paddle.clone(Tensor([22, 64, 112, 323],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 64, 112, 323],"float32"), ) 	 50935808 	 1000 	 0.31392645835876465 	 0.3167872428894043 	 0.3046269416809082 	 0.29847288131713867 	 0.3137638568878174 	 0.04897284507751465 	 0.25939393043518066 	 5.173683166503906e-05 	 
2025-07-30 21:08:39.569623 test begin: paddle.clone(Tensor([22, 64, 323, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([22, 64, 323, 112],"float32"), ) 	 50935808 	 1000 	 0.31398677825927734 	 0.31160879135131836 	 0.30462098121643066 	 0.2984952926635742 	 0.3137984275817871 	 0.04955768585205078 	 0.25794005393981934 	 7.796287536621094e-05 	 
2025-07-30 21:08:42.190345 test begin: paddle.clone(Tensor([338, 12, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([338, 12, 112, 112],"float32"), ) 	 50878464 	 1000 	 0.31348347663879395 	 0.31557226181030273 	 0.3041951656341553 	 0.2937147617340088 	 0.31342101097106934 	 0.04982495307922363 	 0.2519099712371826 	 6.198883056640625e-05 	 
2025-07-30 21:08:44.814067 test begin: paddle.clone(Tensor([43, 256, 56, 83],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 256, 56, 83],"float32"), ) 	 51165184 	 1000 	 0.31520652770996094 	 0.33087897300720215 	 0.30596065521240234 	 0.29434776306152344 	 0.31529927253723145 	 0.048380374908447266 	 0.25928425788879395 	 6.389617919921875e-05 	 
2025-07-30 21:08:48.550788 test begin: paddle.clone(Tensor([43, 256, 83, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 256, 83, 56],"float32"), ) 	 51165184 	 1000 	 0.3152158260345459 	 0.31655430793762207 	 0.30592894554138184 	 0.29338908195495605 	 0.3152651786804199 	 0.04872465133666992 	 0.2548239231109619 	 7.081031799316406e-05 	 
2025-07-30 21:08:51.367710 test begin: paddle.clone(Tensor([43, 377, 56, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([43, 377, 56, 56],"float32"), ) 	 50837696 	 1000 	 0.30817389488220215 	 0.31346869468688965 	 0.15747523307800293 	 0.1600937843322754 	 0.31525611877441406 	 0.05753135681152344 	 0.16106224060058594 	 6.437301635742188e-05 	 
2025-07-30 21:08:53.987546 test begin: paddle.clone(Tensor([64, 256, 56, 56],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([64, 256, 56, 56],"float32"), ) 	 51380224 	 1000 	 0.3166673183441162 	 0.3169257640838623 	 0.3073558807373047 	 0.30285024642944336 	 0.3166952133178711 	 0.05295252799987793 	 0.26213622093200684 	 5.745887756347656e-05 	 
2025-07-30 21:08:56.645477 test begin: paddle.clone(Tensor([64, 64, 112, 112],"float32"), )
[Prof] paddle.clone 	 paddle.clone(Tensor([64, 64, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.31670546531677246 	 0.31409788131713867 	 0.3073418140411377 	 0.2997117042541504 	 0.316652774810791 	 0.04855847358703613 	 0.2623558044433594 	 4.887580871582031e-05 	 
2025-07-30 21:08:59.273859 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9338364601135254 	 0.9266531467437744 	 0.9181759357452393 	 0.9087183475494385 	 0.9291167259216309 	 0.06854009628295898 	 0.8585832118988037 	 6.604194641113281e-05 	 
2025-07-30 21:09:05.005055 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.31777143478393555 	 0.3136253356933594 	 0.30455827713012695 	 0.1601719856262207 	 0.31064915657043457 	 0.06220841407775879 	 0.2519948482513428 	 5.364418029785156e-05 	 
2025-07-30 21:09:07.015508 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3174722194671631 	 0.322371244430542 	 0.3018217086791992 	 0.302201509475708 	 0.3123016357421875 	 0.07350993156433105 	 0.24226927757263184 	 5.841255187988281e-05 	 
2025-07-30 21:09:09.019674 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31897521018981934 	 0.32154250144958496 	 0.30336523056030273 	 0.2999610900878906 	 0.31450939178466797 	 0.07256650924682617 	 0.22740745544433594 	 7.2479248046875e-05 	 
2025-07-30 21:09:11.155583 test begin: paddle.column_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9290225505828857 	 0.9233906269073486 	 0.9133439064025879 	 0.9086713790893555 	 0.9301354885101318 	 0.06776118278503418 	 0.8600485324859619 	 6.318092346191406e-05 	 
2025-07-30 21:09:16.893779 test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 25401654 	 1000 	 0.31836962699890137 	 0.31992316246032715 	 0.302661657333374 	 0.30558300018310547 	 0.312732458114624 	 0.06789875030517578 	 0.24188661575317383 	 4.839897155761719e-05 	 
2025-07-30 21:09:18.939238 test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.3184666633605957 	 0.31952333450317383 	 0.3001587390899658 	 0.3052480220794678 	 0.3126654624938965 	 0.08272671699523926 	 0.24252057075500488 	 8.106231689453125e-05 	 
2025-07-30 21:09:20.954797 test begin: paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9298644065856934 	 0.9296462535858154 	 0.9139578342437744 	 0.9145727157592773 	 0.9312179088592529 	 0.07242012023925781 	 0.8607699871063232 	 6.318092346191406e-05 	 
2025-07-30 21:09:26.828373 test begin: paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3159351348876953 	 0.314713716506958 	 0.3028690814971924 	 0.16127943992614746 	 0.3128044605255127 	 0.05340266227722168 	 0.255596399307251 	 5.245208740234375e-05 	 
2025-07-30 21:09:28.836443 test begin: paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.31740617752075195 	 0.3136415481567383 	 0.3017871379852295 	 0.29922938346862793 	 0.3125014305114746 	 0.06859707832336426 	 0.24260544776916504 	 7.43865966796875e-05 	 
2025-07-30 21:09:30.816882 test begin: paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9356677532196045 	 0.9373660087585449 	 0.9199173450469971 	 0.9135334491729736 	 0.9448204040527344 	 0.06800627708435059 	 0.8742494583129883 	 3.838539123535156e-05 	 
2025-07-30 21:09:40.682473 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31870007514953613 	 0.3188343048095703 	 0.2948291301727295 	 0.2909419536590576 	 0.3134152889251709 	 0.07096672058105469 	 0.2341289520263672 	 6.008148193359375e-05 	 
2025-07-30 21:09:42.692054 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9359526634216309 	 0.9386730194091797 	 0.9119842052459717 	 0.923816442489624 	 0.9436581134796143 	 0.07556605339050293 	 0.8634963035583496 	 9.059906005859375e-05 	 
2025-07-30 21:09:48.491504 test begin: paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.31749844551086426 	 0.3136427402496338 	 0.29634952545166016 	 0.16016006469726562 	 0.31201887130737305 	 0.06192898750305176 	 0.24474096298217773 	 5.650520324707031e-05 	 
2025-07-30 21:09:50.554016 test begin: paddle.column_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.9760630130767822 	 1.4112837314605713 	 0.9523277282714844 	 1.3749535083770752 	 0.9607079029083252 	 0.06911683082580566 	 0.8810980319976807 	 6.461143493652344e-05 	 
2025-07-30 21:09:58.579202 test begin: paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9308416843414307 	 1.030043125152588 	 0.9151177406311035 	 1.0074379444122314 	 0.9395687580108643 	 0.07509350776672363 	 0.8594624996185303 	 5.125999450683594e-05 	 
2025-07-30 21:10:04.549063 test begin: paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.column_stack 	 paddle.column_stack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3083028793334961 	 0.3150327205657959 	 0.29522061347961426 	 0.16158556938171387 	 0.32762980461120605 	 0.055941104888916016 	 0.2709352970123291 	 6.699562072753906e-05 	 
2025-07-30 21:10:06.510418 test begin: paddle.combinations(Tensor([2540160101],"int64"), 0, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([2540160101],"int64"), 0, True, ) 	 2540160101 	 1000 	 0.012423515319824219 	 0.004048585891723633 	 1.2159347534179688e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:42.538532 test begin: paddle.combinations(Tensor([50803201],"int32"), 1, True, )
[Prof] paddle.combinations 	 paddle.combinations(Tensor([50803201],"int32"), 1, True, ) 	 50803201 	 1000 	 5.469883918762207 	 2.134528875350952 	 0.0031986236572265625 	 0.001323699951171875 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:56.587588 test begin: paddle.complex(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), ) 	 101606528 	 1000 	 0.592087984085083 	 0.5888135433197021 	 0.5827498435974121 	 0.5757598876953125 	 0.5906317234039307 	 0.07019758224487305 	 0.5300569534301758 	 8.082389831542969e-05 	 
2025-07-30 21:11:03.194294 test begin: paddle.complex(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), ) 	 101613568 	 1000 	 0.5929417610168457 	 0.5887529850006104 	 0.5835316181182861 	 0.5754265785217285 	 0.5917108058929443 	 0.07249975204467773 	 0.530775785446167 	 6.961822509765625e-05 	 
2025-07-30 21:11:07.510475 test begin: paddle.complex(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 51380224 	 1000 	 0.5046875476837158 	 0.48136305809020996 	 0.4947245121002197 	 0.46088266372680664 	 0.5143129825592041 	 0.2886233329772949 	 0.4488210678100586 	 0.2038266658782959 	 
2025-07-30 21:11:13.528430 test begin: paddle.complex(Tensor([20, 2417, 1051],"float32"), Tensor([20, 2417, 1051],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 2417, 1051],"float32"), Tensor([20, 2417, 1051],"float32"), ) 	 101610680 	 1000 	 0.59287428855896 	 0.5886962413787842 	 0.5833742618560791 	 0.5750281810760498 	 0.5910966396331787 	 0.06797599792480469 	 0.5314779281616211 	 4.2438507080078125e-05 	 
2025-07-30 21:11:17.860220 test begin: paddle.complex(Tensor([20, 2538, 1001],"float32"), Tensor([20, 2538, 1001],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 2538, 1001],"float32"), Tensor([20, 2538, 1001],"float32"), ) 	 101621520 	 1000 	 0.5930814743041992 	 0.5887935161590576 	 0.5835115909576416 	 0.5755355358123779 	 0.5908606052398682 	 0.06843018531799316 	 0.5311474800109863 	 5.793571472167969e-05 	 
2025-07-30 21:11:22.142922 test begin: paddle.complex(Tensor([20, 64, 39691],"float32"), Tensor([20, 64, 39691],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([20, 64, 39691],"float32"), Tensor([20, 64, 39691],"float32"), ) 	 101608960 	 1000 	 0.5928587913513184 	 0.5887062549591064 	 0.583096981048584 	 0.5755136013031006 	 0.5929808616638184 	 0.06864523887634277 	 0.5329999923706055 	 7.271766662597656e-05 	 
2025-07-30 21:11:26.498250 test begin: paddle.complex(Tensor([756, 64, 1051],"float32"), Tensor([756, 64, 1051],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([756, 64, 1051],"float32"), Tensor([756, 64, 1051],"float32"), ) 	 101703168 	 1000 	 0.59336256980896 	 0.5899004936218262 	 0.5838549137115479 	 0.5760130882263184 	 0.5935590267181396 	 0.07439756393432617 	 0.5084116458892822 	 0.00010538101196289062 	 
2025-07-30 21:11:30.820121 test begin: paddle.complex(Tensor([794, 64, 1001],"float32"), Tensor([794, 64, 1001],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([794, 64, 1001],"float32"), Tensor([794, 64, 1001],"float32"), ) 	 101733632 	 1000 	 0.5935027599334717 	 0.6146752834320068 	 0.5840833187103271 	 0.5751070976257324 	 0.5919969081878662 	 0.07161307334899902 	 0.5323605537414551 	 6.031990051269531e-05 	 
2025-07-30 21:11:37.570860 test begin: paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), ) 	 51380224 	 1000 	 0.4836866855621338 	 0.48383355140686035 	 0.47348928451538086 	 0.45977354049682617 	 0.511150598526001 	 0.28749775886535645 	 0.4479074478149414 	 0.20356178283691406 	 
2025-07-30 21:11:41.056010 test begin: paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.complex 	 paddle.complex(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 101711872 	 1000 	 0.5934586524963379 	 0.5906939506530762 	 0.5769290924072266 	 0.5777864456176758 	 0.5921416282653809 	 0.09431934356689453 	 0.5328083038330078 	 5.9604644775390625e-05 	 
2025-07-30 21:11:45.602862 test begin: paddle.concat(list[Tensor([101606401],"bfloat16"),], )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([101606401],"bfloat16"),], ) 	 101606401 	 1000 	 0.3157827854156494 	 0.3151111602783203 	 0.1613459587097168 	 0.16157865524291992 	 0.609182596206665 	 0.4533061981201172 	 0.3112318515777588 	 0.37656140327453613 	 
2025-07-30 21:11:50.394776 test begin: paddle.concat(list[Tensor([254, 32, 112, 112],"float16"),Tensor([254, 32, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([254, 32, 112, 112],"float16"),Tensor([254, 32, 112, 112],"float16"),], axis=1, ) 	 203915264 	 1000 	 0.614924430847168 	 0.9081604480743408 	 0.6020097732543945 	 0.8935070037841797 	 0.9437410831451416 	 0.06211137771606445 	 0.8797292709350586 	 6.341934204101562e-05 	 
2025-07-30 21:12:00.335588 test begin: paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6178562641143799 	 0.9159009456634521 	 0.5970604419708252 	 0.9017765522003174 	 0.941509485244751 	 0.06292843818664551 	 0.878507137298584 	 8.0108642578125e-05 	 
2025-07-30 21:12:10.355134 test begin: paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 32, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 16, 112, 112],"float16"),Tensor([512, 32, 112, 112],"float16"),], axis=1, ) 	 308281344 	 1000 	 0.9269137382507324 	 1.6169664859771729 	 0.9142858982086182 	 1.601522445678711 	 1.4288876056671143 	 0.06180429458618164 	 1.3662302494049072 	 5.888938903808594e-05 	 
2025-07-30 21:12:25.491892 test begin: paddle.concat(list[Tensor([512, 32, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 112, 112],"float16"),Tensor([512, 16, 112, 112],"float16"),], axis=1, ) 	 308281344 	 1000 	 0.9292969703674316 	 1.5550460815429688 	 0.9163763523101807 	 1.5316894054412842 	 1.4320619106292725 	 0.0616765022277832 	 1.3691420555114746 	 5.555152893066406e-05 	 
2025-07-30 21:12:41.638975 test begin: paddle.concat(list[Tensor([512, 32, 112, 56],"float16"),Tensor([512, 32, 112, 56],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 112, 56],"float16"),Tensor([512, 32, 112, 56],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6189806461334229 	 0.9177336692810059 	 0.6062238216400146 	 0.9012172222137451 	 0.942983865737915 	 0.061829566955566406 	 0.8775136470794678 	 4.1484832763671875e-05 	 
2025-07-30 21:12:51.881609 test begin: paddle.concat(list[Tensor([512, 32, 56, 112],"float16"),Tensor([512, 32, 56, 112],"float16"),], axis=1, )
[Prof] paddle.concat 	 paddle.concat(list[Tensor([512, 32, 56, 112],"float16"),Tensor([512, 32, 56, 112],"float16"),], axis=1, ) 	 205520896 	 1000 	 0.6189672946929932 	 0.9144375324249268 	 0.6061301231384277 	 0.9001772403717041 	 0.9428050518035889 	 0.07965779304504395 	 0.8798186779022217 	 7.843971252441406e-05 	 
2025-07-30 21:13:01.923338 test begin: paddle.conj(Tensor([2, 20, 2, 635041],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 20, 2, 635041],"float32"), ) 	 50803280 	 1000 	 0.3108386993408203 	 0.0022885799407958984 	 0.30251479148864746 	 1.8596649169921875e-05 	 0.3099544048309326 	 0.06442451477050781 	 0.25010085105895996 	 0.00011038780212402344 	 
2025-07-30 21:13:04.386385 test begin: paddle.conj(Tensor([2, 20, 423361, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 20, 423361, 3],"float32"), ) 	 50803320 	 1000 	 0.30939745903015137 	 0.0018267631530761719 	 0.3012702465057373 	 1.9550323486328125e-05 	 0.3099491596221924 	 0.0449061393737793 	 0.25879693031311035 	 4.220008850097656e-05 	 
2025-07-30 21:13:06.596168 test begin: paddle.conj(Tensor([2, 4233601, 2, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([2, 4233601, 2, 3],"float32"), ) 	 50803212 	 1000 	 0.30817246437072754 	 0.00176239013671875 	 0.29999852180480957 	 1.52587890625e-05 	 0.30947136878967285 	 0.04486846923828125 	 0.25853538513183594 	 4.482269287109375e-05 	 
2025-07-30 21:13:08.860422 test begin: paddle.conj(Tensor([423361, 20, 2, 3],"float32"), )
[Prof] paddle.conj 	 paddle.conj(Tensor([423361, 20, 2, 3],"float32"), ) 	 50803320 	 1000 	 0.3094139099121094 	 0.0017483234405517578 	 0.3011448383331299 	 1.6450881958007812e-05 	 0.30996108055114746 	 0.04637742042541504 	 0.2584989070892334 	 5.173683166503906e-05 	 
2025-07-30 21:13:11.586896 test begin: paddle.copysign(Tensor([12, 1058401, 2],"float64"), Tensor([12, 1058401, 2],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 1058401, 2],"float64"), Tensor([12, 1058401, 2],"float64"), ) 	 50803248 	 1000 	 0.4487273693084717 	 0.45467448234558105 	 0.43559718132019043 	 0.4313347339630127 	 0.7402632236480713 	 1.5185363292694092 	 0.678856611251831 	 0.3102734088897705 	 
2025-07-30 21:13:16.774832 test begin: paddle.copysign(Tensor([12, 20, 105841],"float64"), Tensor([12, 20, 105841],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 20, 105841],"float64"), Tensor([12, 20, 105841],"float64"), ) 	 50803680 	 1000 	 0.44846391677856445 	 0.46045756340026855 	 0.43544626235961914 	 0.4326457977294922 	 0.740241527557373 	 1.5183794498443604 	 0.6788501739501953 	 0.31020545959472656 	 
2025-07-30 21:13:21.397157 test begin: paddle.copysign(Tensor([12, 20, 211681],"float32"), Tensor([12, 20, 211681],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 20, 211681],"float32"), Tensor([12, 20, 211681],"float32"), ) 	 101606880 	 1000 	 0.4497060775756836 	 0.4462599754333496 	 0.4366617202758789 	 0.4288363456726074 	 1.2216212749481201 	 1.5531606674194336 	 1.1505577564239502 	 0.3175621032714844 	 
2025-07-30 21:13:27.502378 test begin: paddle.copysign(Tensor([12, 2116801, 2],"float32"), Tensor([12, 2116801, 2],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([12, 2116801, 2],"float32"), Tensor([12, 2116801, 2],"float32"), ) 	 101606448 	 1000 	 0.4510762691497803 	 0.4462132453918457 	 0.4298739433288574 	 0.42868971824645996 	 1.2178990840911865 	 1.5553257465362549 	 1.1437621116638184 	 0.318713903427124 	 
2025-07-30 21:13:33.625139 test begin: paddle.copysign(Tensor([1270081, 20, 2],"float32"), Tensor([1270081, 20, 2],"float32"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([1270081, 20, 2],"float32"), Tensor([1270081, 20, 2],"float32"), ) 	 101606480 	 1000 	 0.44979310035705566 	 0.45041537284851074 	 0.4367711544036865 	 0.42859625816345215 	 1.245023250579834 	 1.5532851219177246 	 1.181955337524414 	 0.3175690174102783 	 
2025-07-30 21:13:41.309887 test begin: paddle.copysign(Tensor([635041, 20, 2],"float64"), Tensor([635041, 20, 2],"float64"), )
[Prof] paddle.copysign 	 paddle.copysign(Tensor([635041, 20, 2],"float64"), Tensor([635041, 20, 2],"float64"), ) 	 50803280 	 1000 	 0.44823217391967773 	 0.44800281524658203 	 0.4353029727935791 	 0.43163466453552246 	 0.7402472496032715 	 1.5172340869903564 	 0.6769852638244629 	 0.3102855682373047 	 
2025-07-30 21:13:46.036036 test begin: paddle.cos(Tensor([1587601, 32],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 0.29651951789855957 	 0.29809021949768066 	 0.28745079040527344 	 0.28719019889831543 	 0.4499044418334961 	 1.0404400825500488 	 0.39183735847473145 	 0.35446906089782715 	 
2025-07-30 21:13:49.729149 test begin: paddle.cos(Tensor([198451, 256],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([198451, 256],"float32"), ) 	 50803456 	 1000 	 0.29676389694213867 	 0.29804205894470215 	 0.2878546714782715 	 0.28725123405456543 	 0.45094728469848633 	 1.0404398441314697 	 0.39656805992126465 	 0.35448646545410156 	 
2025-07-30 21:13:53.370522 test begin: paddle.cos(Tensor([32768, 1551],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.29560208320617676 	 0.2981870174407959 	 0.28665924072265625 	 0.28717827796936035 	 0.45120954513549805 	 1.0433251857757568 	 0.3953826427459717 	 0.3546280860900879 	 
2025-07-30 21:13:57.045451 test begin: paddle.cos(Tensor([396901, 128],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29554033279418945 	 0.2980470657348633 	 0.2864391803741455 	 0.28725147247314453 	 0.44980478286743164 	 1.0427448749542236 	 0.3914361000061035 	 0.35556817054748535 	 
2025-07-30 21:14:00.731446 test begin: paddle.cos(Tensor([5000, 10161],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([5000, 10161],"float32"), ) 	 50805000 	 1000 	 0.2953979969024658 	 0.30034875869750977 	 0.2863647937774658 	 0.28730154037475586 	 0.4498283863067627 	 1.041600227355957 	 0.3952980041503906 	 0.35565757751464844 	 
2025-07-30 21:14:04.365812 test begin: paddle.cos(Tensor([8192, 6202],"float32"), )
[Prof] paddle.cos 	 paddle.cos(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.2967367172241211 	 0.2980797290802002 	 0.2877371311187744 	 0.28725457191467285 	 0.44989728927612305 	 1.04044508934021 	 0.39541149139404297 	 0.35444045066833496 	 
2025-07-30 21:14:08.031632 test begin: paddle.cosh(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29473304748535156 	 0.29854893684387207 	 0.2856776714324951 	 0.28778672218322754 	 0.4496898651123047 	 0.7426888942718506 	 0.3953874111175537 	 0.37943267822265625 	 
2025-07-30 21:14:11.494696 test begin: paddle.cosh(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2947533130645752 	 0.303408145904541 	 0.2857036590576172 	 0.28894758224487305 	 0.4497029781341553 	 0.7437808513641357 	 0.3956024646759033 	 0.3806002140045166 	 
2025-07-30 21:14:17.072409 test begin: paddle.cosh(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2946591377258301 	 0.3035743236541748 	 0.28561997413635254 	 0.2880418300628662 	 0.4496188163757324 	 0.7440924644470215 	 0.39513254165649414 	 0.37947988510131836 	 
2025-07-30 21:14:21.029866 test begin: paddle.cosh(Tensor([28, 32, 241, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([28, 32, 241, 241],"float32"), ) 	 52040576 	 1000 	 0.30207085609436035 	 0.30574607849121094 	 0.28173136711120605 	 0.28827714920043945 	 0.460529088973999 	 0.7603673934936523 	 0.3978278636932373 	 0.38849782943725586 	 
2025-07-30 21:14:24.562952 test begin: paddle.cosh(Tensor([8, 110, 241, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 110, 241, 241],"float32"), ) 	 51111280 	 1000 	 0.2976548671722412 	 0.300278902053833 	 0.28142809867858887 	 0.28265833854675293 	 0.4522101879119873 	 0.7471308708190918 	 0.3895113468170166 	 0.3817424774169922 	 
2025-07-30 21:14:27.922888 test begin: paddle.cosh(Tensor([8, 32, 241, 824],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 32, 241, 824],"float32"), ) 	 50837504 	 1000 	 0.2949404716491699 	 0.29873013496398926 	 0.27864694595336914 	 0.2813572883605957 	 0.4513397216796875 	 0.7431728839874268 	 0.3883786201477051 	 0.37970590591430664 	 
2025-07-30 21:14:31.330756 test begin: paddle.cosh(Tensor([8, 32, 824, 241],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(Tensor([8, 32, 824, 241],"float32"), ) 	 50837504 	 1000 	 0.29495954513549805 	 0.29868650436401367 	 0.2787628173828125 	 0.2814977169036865 	 0.4512064456939697 	 0.7444558143615723 	 0.3884403705596924 	 0.38097596168518066 	 
2025-07-30 21:14:34.693913 test begin: paddle.cosh(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.2947556972503662 	 0.31505846977233887 	 0.2855989933013916 	 0.28135085105895996 	 0.4497945308685303 	 0.7426464557647705 	 0.3956410884857178 	 0.3794128894805908 	 
2025-07-30 21:14:40.178011 test begin: paddle.cosh(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.2946958541870117 	 0.29856395721435547 	 0.28545403480529785 	 0.2878406047821045 	 0.4497084617614746 	 0.7426886558532715 	 0.39548373222351074 	 0.3794376850128174 	 
2025-07-30 21:14:43.602149 test begin: paddle.cosh(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.cosh 	 paddle.cosh(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.29468488693237305 	 0.3034248352050781 	 0.28550148010253906 	 0.2877826690673828 	 0.44985437393188477 	 0.7463035583496094 	 0.3779888153076172 	 0.38061094284057617 	 
2025-07-30 21:14:46.972113 test begin: paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401796 	 1000 	 0.6009576320648193 	 0.5275740623474121 	 0.20473337173461914 	 0.17969775199890137 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:14:49.138663 test begin: paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 129601, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401796 	 1000 	 0.6008203029632568 	 0.5303046703338623 	 0.20470237731933594 	 0.17975616455078125 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 129601, 1]) and output[0] has a shape of torch.Size([1, 129601]).
2025-07-30 21:14:51.337851 test begin: paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401670 	 1000 	 0.6126308441162109 	 0.5453402996063232 	 0.15649867057800293 	 0.13924741744995117 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:14:53.494555 test begin: paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 14, 5, 362881],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401670 	 1000 	 0.6126623153686523 	 0.5479676723480225 	 0.15650010108947754 	 0.14036917686462402 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 5, 1]) and output[0] has a shape of torch.Size([1, 5]).
2025-07-30 21:14:55.653008 test begin: paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25401670 	 1000 	 0.6106648445129395 	 0.5540704727172852 	 0.15597963333129883 	 0.14150094985961914 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:14:57.790427 test begin: paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([1, 362881, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25401670 	 1000 	 0.6106982231140137 	 0.5553622245788574 	 0.1559889316558838 	 0.1415109634399414 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1, 5, 1]) and output[0] has a shape of torch.Size([1, 5]).
2025-07-30 21:14:59.930744 test begin: paddle.count_nonzero(Tensor([2, 1270081, 4, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 1270081, 4, 5],"float32"), axis=-1, keepdim=False, ) 	 50803240 	 1000 	 0.9716196060180664 	 1.0618767738342285 	 0.33112168312072754 	 0.3618922233581543 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:15:03.864345 test begin: paddle.count_nonzero(Tensor([2, 3, 1693441, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 3, 1693441, 5],"float32"), axis=-1, keepdim=False, ) 	 50803230 	 1000 	 0.9735918045043945 	 1.0619335174560547 	 0.33090901374816895 	 0.3618950843811035 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:15:07.765708 test begin: paddle.count_nonzero(Tensor([2, 3, 4, 2116801],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([2, 3, 4, 2116801],"float32"), axis=-1, keepdim=False, ) 	 50803224 	 1000 	 0.8732287883758545 	 0.8684308528900146 	 0.2224271297454834 	 0.2217566967010498 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:15:11.141841 test begin: paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 	 25402580 	 1000 	 0.5925676822662354 	 0.5302536487579346 	 0.20192575454711914 	 0.1814413070678711 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:15:13.322226 test begin: paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([25921, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 	 25402580 	 1000 	 0.5925717353820801 	 0.5291252136230469 	 0.2018876075744629 	 0.18024325370788574 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([25921, 1, 5, 1]) and output[0] has a shape of torch.Size([25921, 5]).
2025-07-30 21:15:15.444700 test begin: paddle.count_nonzero(Tensor([846721, 3, 4, 5],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.count_nonzero 	 paddle.count_nonzero(Tensor([846721, 3, 4, 5],"float32"), axis=-1, keepdim=False, ) 	 50803260 	 1000 	 0.9715940952301025 	 1.0633020401000977 	 0.3311610221862793 	 0.3632514476776123 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:15:19.346533 test begin: paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 14112, 3, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.030387163162231445 	 0.019153118133544922 	 3.504753112792969e-05 	 4.2438507080078125e-05 	 0.14693617820739746 	 0.16375041007995605 	 0.0791473388671875 	 0.010576009750366211 	 combined
2025-07-30 21:15:22.212247 test begin: paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 14112, 3],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.019287824630737305 	 0.019586801528930664 	 1.6689300537109375e-05 	 4.2438507080078125e-05 	 0.15402698516845703 	 0.1692190170288086 	 0.10020947456359863 	 0.01685190200805664 	 combined
2025-07-30 21:15:24.912655 test begin: paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([201, 3, 3, 14112],"float64"), shape=list[2,1,-1,2,], offsets=list[0,0,1,1,], ) 	 25528608 	 1000 	 0.027486562728881836 	 0.02798295021057129 	 2.4318695068359375e-05 	 2.384185791015625e-05 	 0.14731979370117188 	 0.17978549003601074 	 0.08509230613708496 	 0.012093067169189453 	 combined
2025-07-30 21:15:25.812761 test begin: paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([301, 84672],"float64"), shape=list[2,2,], ) 	 25486272 	 1000 	 0.019868135452270508 	 0.01306009292602539 	 1.5974044799804688e-05 	 2.47955322265625e-05 	 0.15033578872680664 	 0.15064001083374023 	 0.09662747383117676 	 0.030686616897583008 	 combined
2025-07-30 21:15:26.623275 test begin: paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], )
[Prof] paddle.crop 	 paddle.crop(x=Tensor([8467201, 3],"float64"), shape=list[2,2,], ) 	 25401603 	 1000 	 0.020224571228027344 	 0.013075828552246094 	 1.5974044799804688e-05 	 2.3603439331054688e-05 	 0.14652585983276367 	 0.14312362670898438 	 0.08722996711730957 	 0.03657388687133789 	 combined
2025-07-30 21:15:27.423778 test begin: paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=1, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=1, ) 	 50803218 	 1000 	 0.45001745223999023 	 0.45455384254455566 	 0.4385702610015869 	 0.4376816749572754 	 0.749955415725708 	 0.9002811908721924 	 0.687758207321167 	 0.4591517448425293 	 
2025-07-30 21:15:31.426974 test begin: paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=2, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([2822401, 3, 3],"float64"), y=Tensor([2822401, 3, 3],"float64"), axis=2, ) 	 50803218 	 1000 	 0.4501519203186035 	 0.45201873779296875 	 0.4391608238220215 	 0.4374856948852539 	 0.7571141719818115 	 0.9023647308349609 	 0.6657454967498779 	 0.46033596992492676 	 
2025-07-30 21:15:40.219294 test begin: paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=0, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=0, ) 	 50803218 	 1000 	 0.44845104217529297 	 0.4487001895904541 	 0.4299447536468506 	 0.4271061420440674 	 0.7414035797119141 	 0.8963901996612549 	 0.6682446002960205 	 0.4579923152923584 	 
2025-07-30 21:15:44.261943 test begin: paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=2, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 2822401, 3],"float64"), y=Tensor([3, 2822401, 3],"float64"), axis=2, ) 	 50803218 	 1000 	 0.45026350021362305 	 0.4508359432220459 	 0.4387855529785156 	 0.43641138076782227 	 0.7597026824951172 	 0.9010488986968994 	 0.6962635517120361 	 0.4602351188659668 	 
2025-07-30 21:15:48.436205 test begin: paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=0, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=0, ) 	 50803218 	 1000 	 0.44745373725891113 	 0.45485997200012207 	 0.436687707901001 	 0.43550896644592285 	 0.7426445484161377 	 0.8964629173278809 	 0.669741153717041 	 0.45800232887268066 	 
2025-07-30 21:15:52.500953 test begin: paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=1, )
[Prof] paddle.cross 	 paddle.cross(x=Tensor([3, 3, 2822401],"float64"), y=Tensor([3, 3, 2822401],"float64"), axis=1, ) 	 50803218 	 1000 	 0.4483218193054199 	 0.44766783714294434 	 0.4374504089355469 	 0.43221378326416016 	 0.7417840957641602 	 0.8968274593353271 	 0.6619212627410889 	 0.45747947692871094 	 
2025-07-30 21:15:56.525478 test begin: paddle.cummax(Tensor([100, 2080],"float32"), )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), ) 	 208000 	 1000 	 11.337390899658203 	 0.8122060298919678 	 11.306078433990479 	 0.7929015159606934 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:16:09.175316 test begin: paddle.cummax(Tensor([100, 2080],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([100, 2080],"float32"), axis=-1, ) 	 208000 	 1000 	 0.18103671073913574 	 0.05185437202453613 	 0.16024255752563477 	 0.010764360427856445 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:16:09.494419 test begin: paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([10001, 2080],"float32"), axis=-2, ) 	 20802080 	 1000 	 5.698218584060669 	 5.704492568969727 	 5.677542209625244 	 5.681381940841675 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:16:22.635332 test begin: paddle.cummax(Tensor([2080, 100],"float32"), )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), ) 	 208000 	 1000 	 11.335143327713013 	 0.8122043609619141 	 11.303845405578613 	 0.7971484661102295 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:24:17.894101 test begin: paddle.cummax(Tensor([2080, 100],"float32"), axis=-2, )
W0730 19:24:18.207734 23525 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.cummax 	 paddle.cummax(Tensor([2080, 100],"float32"), axis=-2, ) 	 208000 	 1000 	 0.4338409900665283 	 0.4101696014404297 	 0.4113152027130127 	 0.3817472457885742 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:24:19.548916 test begin: paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, )
[Prof] paddle.cummax 	 paddle.cummax(Tensor([208001, 100],"float32"), axis=-1, ) 	 20800100 	 1000 	 0.5544350147247314 	 3.506291389465332 	 0.5298445224761963 	 3.478309154510498 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:24:25.591798 test begin: paddle.cummin(Tensor([100, 508033],"float32"), axis=-1, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([100, 508033],"float32"), axis=-1, ) 	 50803300 	 1000 	 58.81859040260315 	 2.5427794456481934 	 58.77507257461548 	 2.52726411819458 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:26:33.133642 test begin: paddle.cummin(Tensor([100, 508033],"float32"), axis=-2, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([100, 508033],"float32"), axis=-2, ) 	 50803300 	 1000 	 0.7915334701538086 	 0.7935359477996826 	 0.7784206867218018 	 0.7751040458679199 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:26:44.048120 test begin: paddle.cummin(Tensor([508033, 100],"float32"), axis=-1, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([508033, 100],"float32"), axis=-1, ) 	 50803300 	 1000 	 1.330759048461914 	 8.545710563659668 	 1.3177087306976318 	 8.530146360397339 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:26:58.293126 test begin: paddle.cummin(Tensor([508033, 100],"float32"), axis=-2, )
[Prof] paddle.cummin 	 paddle.cummin(Tensor([508033, 100],"float32"), axis=-2, ) 	 50803300 	 1000 	 250.28081727027893 	 249.95261645317078 	 250.26740217208862 	 249.93659830093384 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:35:24.904609 test begin: paddle.cumprod(Tensor([2, 127009, 10, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 127009, 10, 10],"float64"), 1, ) 	 25401800 	 1000 	 65.89588832855225 	 64.02448964118958 	 65.88703989982605 	 64.01292705535889 	 257.0904302597046 	 65.78275942802429 	 0.06546640396118164 	 0.06452012062072754 	 
2025-07-30 19:42:59.612135 test begin: paddle.cumprod(Tensor([2, 3, 10, 423361],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 10, 423361],"float64"), 1, ) 	 25401660 	 1000 	 0.3023555278778076 	 0.30291128158569336 	 0.2937180995941162 	 0.2915642261505127 	 2.8474032878875732 	 2.041195869445801 	 0.000331878662109375 	 0.0012826919555664062 	 
2025-07-30 19:43:06.186268 test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=0, ) 	 50803272 	 1000 	 0.3307535648345947 	 0.31177735328674316 	 0.3205862045288086 	 0.30054807662963867 	 3.421522378921509 	 2.115370273590088 	 0.000476837158203125 	 0.0013277530670166016 	 
2025-07-30 19:43:14.359004 test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 4, 705601],"float32"), dim=1, ) 	 50803272 	 1000 	 0.3222470283508301 	 0.3175358772277832 	 0.31327104568481445 	 0.3062887191772461 	 3.2645556926727295 	 2.1295390129089355 	 0.0004296302795410156 	 0.0013353824615478516 	 
2025-07-30 19:43:22.038273 test begin: paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=0, ) 	 50803290 	 1000 	 0.3298916816711426 	 0.31182050704956055 	 0.3205685615539551 	 0.30053043365478516 	 3.41164231300354 	 2.113831043243408 	 0.0004787445068359375 	 0.0013184547424316406 	 
2025-07-30 19:43:30.092185 test begin: paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 3, 564481, 5],"float32"), dim=1, ) 	 50803290 	 1000 	 0.32233190536499023 	 2.5375683307647705 	 0.3132503032684326 	 0.30655479431152344 	 3.265392780303955 	 2.133612632751465 	 0.0004253387451171875 	 0.0013287067413330078 	 
2025-07-30 19:43:42.637110 test begin: paddle.cumprod(Tensor([2, 3, 423361, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 10],"float64"), 1, ) 	 25401660 	 1000 	 0.3023097515106201 	 0.31263017654418945 	 0.2937736511230469 	 0.2851853370666504 	 2.851457357406616 	 2.039327383041382 	 0.0003437995910644531 	 0.0012862682342529297 	 
2025-07-30 19:43:50.305143 test begin: paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=0, ) 	 50803320 	 1000 	 0.32958221435546875 	 0.31174325942993164 	 0.31361818313598633 	 0.29401159286499023 	 3.414543390274048 	 2.1154894828796387 	 0.0004630088806152344 	 0.0013124942779541016 	 
2025-07-30 19:43:58.222142 test begin: paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 3, 423361, 4, 5],"float32"), dim=1, ) 	 50803320 	 1000 	 0.3217439651489258 	 0.3176848888397217 	 0.31285762786865234 	 0.306441068649292 	 3.2775726318359375 	 2.130506992340088 	 0.0003972053527832031 	 0.0013151168823242188 	 
2025-07-30 19:44:06.165527 test begin: paddle.cumprod(Tensor([2, 423361, 3, 4, 5],"float32"), dim=0, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([2, 423361, 3, 4, 5],"float32"), dim=0, ) 	 50803320 	 1000 	 0.3314635753631592 	 0.31171488761901855 	 0.3209564685821533 	 0.2966172695159912 	 3.41267466545105 	 2.123624801635742 	 0.0004799365997314453 	 0.0013036727905273438 	 
2025-07-30 19:44:14.066314 test begin: paddle.cumprod(Tensor([282241, 3, 3, 4, 5],"float32"), dim=1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([282241, 3, 3, 4, 5],"float32"), dim=1, ) 	 50803380 	 1000 	 0.32785844802856445 	 0.32260990142822266 	 0.31873035430908203 	 0.31127119064331055 	 3.2551538944244385 	 2.1400506496429443 	 0.0004248619079589844 	 0.0013213157653808594 	 
2025-07-30 19:44:21.847249 test begin: paddle.cumprod(Tensor([84673, 3, 10, 10],"float64"), 1, )
[Prof] paddle.cumprod 	 paddle.cumprod(Tensor([84673, 3, 10, 10],"float64"), 1, ) 	 25401900 	 1000 	 0.3042867183685303 	 0.30713772773742676 	 0.2952613830566406 	 0.29265761375427246 	 2.8418397903442383 	 2.0412018299102783 	 0.00035572052001953125 	 0.0012919902801513672 	 
2025-07-30 19:44:28.490761 test begin: paddle.cumsum(Tensor([50803201],"float32"), axis=0, )
[Prof] paddle.cumsum 	 paddle.cumsum(Tensor([50803201],"float32"), axis=0, ) 	 50803201 	 1000 	 0.3500485420227051 	 0.329132080078125 	 0.0001475811004638672 	 0.16806554794311523 	 0.39908885955810547 	 0.9454770088195801 	 3.337860107421875e-05 	 0.24165916442871094 	 
2025-07-30 19:44:32.186674 test begin: paddle.deg2rad(Tensor([25401601],"int64"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 0.3792836666107178 	 0.23556041717529297 	 0.19371652603149414 	 0.21063685417175293 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:44:34.009983 test begin: paddle.deg2rad(Tensor([50803201],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2961866855621338 	 0.3259847164154053 	 0.27181196212768555 	 0.2832784652709961 	 0.29635119438171387 	 0.29779839515686035 	 0.2355496883392334 	 0.20647501945495605 	 
2025-07-30 19:44:40.185551 test begin: paddle.deg2rad(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2980039119720459 	 0.29804491996765137 	 0.2809326648712158 	 0.28333187103271484 	 0.2962372303009033 	 0.29778146743774414 	 0.2423539161682129 	 0.23408985137939453 	 
2025-07-30 19:44:42.955617 test begin: paddle.deg2rad(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2960028648376465 	 0.2980923652648926 	 0.28058362007141113 	 0.2769737243652344 	 0.2962675094604492 	 0.2978017330169678 	 0.24431657791137695 	 0.2342984676361084 	 
2025-07-30 19:44:45.790589 test begin: paddle.deg2rad(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.deg2rad 	 paddle.deg2rad(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29608607292175293 	 0.3075132369995117 	 0.28070068359375 	 0.2833595275878906 	 0.2962968349456787 	 0.29776978492736816 	 0.24451613426208496 	 0.23265743255615234 	 
2025-07-30 19:44:48.571752 test begin: paddle.diag(Tensor([20000, 25402],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), ) 	 508040000 	 1000 	 0.015562057495117188 	 0.025419950485229492 	 1.71661376953125e-05 	 5.888938903808594e-05 	 1.51863694190979 	 1.3271148204803467 	 0.7757375240325928 	 0.6781802177429199 	 
2025-07-30 19:44:59.514131 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.01596808433532715 	 0.025655031204223633 	 1.811981201171875e-05 	 6.699562072753906e-05 	 1.5185437202453613 	 1.326667308807373 	 0.775719404220581 	 0.6778676509857178 	 
2025-07-30 19:45:10.687257 test begin: paddle.diag(Tensor([20000, 25402],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([20000, 25402],"float32"), offset=1, ) 	 508040000 	 1000 	 0.015974044799804688 	 0.02562570571899414 	 1.6927719116210938e-05 	 0.00013709068298339844 	 1.5192208290100098 	 1.3269212245941162 	 0.7754969596862793 	 0.6779706478118896 	 
2025-07-30 19:45:22.334227 test begin: paddle.diag(Tensor([254020, 2000],"float32"), )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), ) 	 508040000 	 1000 	 0.009677410125732422 	 0.01949334144592285 	 1.8835067749023438e-05 	 6.937980651855469e-05 	 1.5021073818206787 	 1.3187365531921387 	 0.7672703266143799 	 0.673760175704956 	 
2025-07-30 19:45:33.287678 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=-1, ) 	 508040000 	 1000 	 0.0090179443359375 	 0.019490957260131836 	 1.0967254638671875e-05 	 7.486343383789062e-05 	 1.5020217895507812 	 1.3189730644226074 	 0.7672739028930664 	 0.6739282608032227 	 
2025-07-30 19:45:44.323817 test begin: paddle.diag(Tensor([254020, 2000],"float32"), offset=1, )
[Prof] paddle.diag 	 paddle.diag(Tensor([254020, 2000],"float32"), offset=1, ) 	 508040000 	 1000 	 0.008974313735961914 	 0.017461538314819336 	 1.2636184692382812e-05 	 4.458427429199219e-05 	 1.502446174621582 	 1.3188707828521729 	 0.7671804428100586 	 0.6738612651824951 	 
2025-07-30 19:45:55.319328 test begin: paddle.diag_embed(Tensor([1058401, 3, 8],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([1058401, 3, 8],"float64"), ) 	 25401624 	 1000 	 6.921938180923462 	 2.609997510910034 	 0.00010776519775390625 	 1.3333179950714111 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:06.878570 test begin: paddle.diag_embed(Tensor([1411201, 3, 6],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([1411201, 3, 6],"float64"), ) 	 25401618 	 1000 	 2.4800949096679688 	 2.1949925422668457 	 7.62939453125e-05 	 1.121016502380371 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:12.099052 test begin: paddle.diag_embed(Tensor([2, 1058401, 12],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 1058401, 12],"float64"), ) 	 25401624 	 1000 	 4.251163482666016 	 3.831923007965088 	 9.846687316894531e-05 	 0.9794106483459473 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:20.918227 test begin: paddle.diag_embed(Tensor([2, 1587601, 8],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 1587601, 8],"float64"), ) 	 25401616 	 1000 	 2.879329204559326 	 2.610389471054077 	 6.699562072753906e-05 	 1.3336219787597656 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:26.967550 test begin: paddle.diag_embed(Tensor([2, 2116801, 6],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([2, 2116801, 6],"float64"), ) 	 25401612 	 1000 	 2.519763946533203 	 2.194098711013794 	 5.2928924560546875e-05 	 1.1210181713104248 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:32.228991 test begin: paddle.diag_embed(Tensor([705601, 3, 12],"float64"), )
[Prof] paddle.diag_embed 	 paddle.diag_embed(Tensor([705601, 3, 12],"float64"), ) 	 25401636 	 1000 	 10.279119729995728 	 3.8318467140197754 	 9.465217590332031e-05 	 0.9795281887054443 	 None 	 None 	 None 	 None 	 
2025-07-30 19:46:46.943182 test begin: paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([117601, 6, 6, 6],"float64"), ) 	 25401816 	 1000 	 0.003706693649291992 	 0.004411935806274414 	 1.1920928955078125e-05 	 2.002716064453125e-05 	 0.1506335735321045 	 0.13871002197265625 	 0.07683157920837402 	 0.04829072952270508 	 
2025-07-30 19:46:47.846845 test begin: paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([176401, 6, 6, 2, 2],"float64"), ) 	 25401744 	 1000 	 0.003564596176147461 	 0.004556894302368164 	 1.2874603271484375e-05 	 1.9073486328125e-05 	 0.15123963356018066 	 0.13878464698791504 	 0.07721447944641113 	 0.04733896255493164 	 
2025-07-30 19:46:48.663025 test begin: paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1176, 6, 6],"float64"), ) 	 25443936 	 1000 	 0.0036630630493164062 	 0.004446744918823242 	 7.3909759521484375e-06 	 1.8358230590820312e-05 	 0.15169358253479004 	 0.1409461498260498 	 0.0774993896484375 	 0.04865622520446777 	 
2025-07-30 19:46:49.498626 test begin: paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 1764, 6, 2, 2],"float64"), ) 	 25443936 	 1000 	 0.003653287887573242 	 0.004559516906738281 	 3.147125244140625e-05 	 2.2649765014648438e-05 	 0.1522986888885498 	 0.13963675498962402 	 0.07772612571716309 	 0.04773139953613281 	 
2025-07-30 19:46:50.321844 test begin: paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1176, 6],"float64"), ) 	 25443936 	 1000 	 0.0037622451782226562 	 0.00447535514831543 	 2.4080276489257812e-05 	 1.8835067749023438e-05 	 0.1502220630645752 	 0.13974595069885254 	 0.07667016983032227 	 0.048441410064697266 	 
2025-07-30 19:46:51.151598 test begin: paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 1764, 2, 2],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.003818511962890625 	 0.004703998565673828 	 8.106231689453125e-06 	 2.002716064453125e-05 	 0.15381264686584473 	 0.14255094528198242 	 0.07846927642822266 	 0.048871755599975586 	 
2025-07-30 19:46:51.994857 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 1176],"float64"), ) 	 25443936 	 1000 	 0.0036444664001464844 	 0.004584074020385742 	 9.059906005859375e-06 	 1.9073486328125e-05 	 0.15025091171264648 	 0.13972902297973633 	 0.07671403884887695 	 0.046729087829589844 	 
2025-07-30 19:46:52.815873 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), ) 	 25443936 	 1000 	 0.007947444915771484 	 0.007712602615356445 	 3.0517578125e-05 	 2.0742416381835938e-05 	 0.15040349960327148 	 0.13973259925842285 	 0.07677078247070312 	 0.028848886489868164 	 
2025-07-30 19:46:53.681121 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 2, 588],"float64"), axis1=-1, axis2=2, ) 	 25443936 	 1000 	 0.0038535594940185547 	 0.004664421081542969 	 7.62939453125e-06 	 2.1219253540039062e-05 	 0.16624164581298828 	 0.15459346771240234 	 0.08485126495361328 	 0.06264495849609375 	 
2025-07-30 19:46:54.542506 test begin: paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), )
[Prof] paddle.diagonal 	 paddle.diagonal(x=Tensor([601, 6, 6, 588, 2],"float64"), ) 	 25443936 	 1000 	 0.003592252731323242 	 0.004624843597412109 	 6.9141387939453125e-06 	 1.8596649169921875e-05 	 0.15035605430603027 	 0.13966131210327148 	 0.0767216682434082 	 0.04697561264038086 	 
2025-07-30 19:46:55.364960 test begin: paddle.diagonal_scatter(Tensor([10, 10160641],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 10160641],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 	 101606420 	 1000 	 0.3219640254974365 	 0.32301974296569824 	 0.08208656311035156 	 0.10751128196716309 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:46:58.348252 test begin: paddle.diagonal_scatter(Tensor([10, 5080321],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10, 5080321],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.3213012218475342 	 0.3165097236633301 	 0.08192229270935059 	 0.10752129554748535 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:47:00.471888 test begin: paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([100, 5080321],"bool"), Tensor([100],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032200 	 1000 	 0.7782201766967773 	 0.7741405963897705 	 0.1984245777130127 	 0.26314854621887207 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:47:21.435812 test begin: paddle.diagonal_scatter(Tensor([10160641, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([10160641, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 	 101606420 	 1000 	 0.32128405570983887 	 0.3164699077606201 	 0.08191180229187012 	 0.10749602317810059 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:47:24.354060 test begin: paddle.diagonal_scatter(Tensor([5080321, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([5080321, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 	 50803220 	 1000 	 0.32132959365844727 	 0.31647467613220215 	 0.0819251537322998 	 0.10752654075622559 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:47:26.451295 test begin: paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.diagonal_scatter 	 paddle.diagonal_scatter(Tensor([50803210, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 	 508032110 	 1000 	 0.7779145240783691 	 0.7739341259002686 	 0.19837093353271484 	 0.26308226585388184 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:47:43.574947 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.9448249340057373 	 0.2616584300994873 	 0.32184505462646484 	 0.2423872947692871 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:45.344119 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.9445333480834961 	 0.2645556926727295 	 0.32176756858825684 	 0.2418820858001709 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:47.092021 test begin: paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.9446027278900146 	 0.2616736888885498 	 0.3218097686767578 	 0.23398923873901367 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:48.845217 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.8710181713104248 	 0.26163291931152344 	 0.2967092990875244 	 0.2421870231628418 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:50.518951 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8710136413574219 	 0.26248931884765625 	 0.2967402935028076 	 0.2419743537902832 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:52.184511 test begin: paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.871084451675415 	 0.26178836822509766 	 0.29676079750061035 	 0.233872652053833 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:53.869667 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.8708682060241699 	 0.2616581916809082 	 0.296705961227417 	 0.2425687313079834 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:55.575195 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 1.0708122253417969 	 0.2997474670410156 	 0.36481809616088867 	 0.2797689437866211 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:57.469664 test begin: paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 1.0708520412445068 	 0.2997548580169678 	 0.36482858657836914 	 0.2803037166595459 	 None 	 None 	 None 	 None 	 
2025-07-30 19:47:59.367896 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 1.0707345008850098 	 0.29970884323120117 	 0.36477112770080566 	 0.28038835525512695 	 None 	 None 	 None 	 None 	 
2025-07-30 19:48:01.269135 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8070840835571289 	 0.2630617618560791 	 0.27495837211608887 	 0.23540973663330078 	 None 	 None 	 None 	 None 	 
2025-07-30 19:48:02.990259 test begin: paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, )
[Prof] paddle.diff 	 paddle.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, ) 	 25401664 	 1000 	 0.807098388671875 	 0.26288437843322754 	 0.2749755382537842 	 0.24332261085510254 	 None 	 None 	 None 	 None 	 
2025-07-30 19:48:04.603959 test begin: paddle.digamma(Tensor([16538, 3, 32, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([16538, 3, 32, 32],"float32"), ) 	 50804736 	 1000 	 0.9611372947692871 	 1.063765525817871 	 0.9526371955871582 	 1.052771806716919 	 4.496647596359253 	 1.0724306106567383 	 4.444562911987305 	 0.5479180812835693 	 
2025-07-30 19:48:13.902843 test begin: paddle.digamma(Tensor([8, 3, 32, 33076],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 32, 33076],"float64"), ) 	 25402368 	 1000 	 1.1689445972442627 	 1.1411025524139404 	 1.1606671810150146 	 1.1306161880493164 	 8.551295757293701 	 1.0844690799713135 	 8.498721837997437 	 0.5541284084320068 	 
2025-07-30 19:48:27.000163 test begin: paddle.digamma(Tensor([8, 3, 32, 66151],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 32, 66151],"float32"), ) 	 50803968 	 1000 	 0.9609866142272949 	 1.214174509048462 	 0.952561616897583 	 1.1622655391693115 	 4.487699508666992 	 1.0725948810577393 	 4.435071706771851 	 0.5479385852813721 	 
2025-07-30 19:48:37.201010 test begin: paddle.digamma(Tensor([8, 3, 33076, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 33076, 32],"float64"), ) 	 25402368 	 1000 	 1.1901378631591797 	 1.1416120529174805 	 1.181647777557373 	 1.1310980319976807 	 8.550857305526733 	 1.0847711563110352 	 8.498313426971436 	 0.5542182922363281 	 
2025-07-30 19:48:50.322443 test begin: paddle.digamma(Tensor([8, 3, 66151, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3, 66151, 32],"float32"), ) 	 50803968 	 1000 	 0.9605717658996582 	 1.0629942417144775 	 0.9518449306488037 	 1.0524742603302002 	 4.489641427993774 	 1.072481393814087 	 4.436981439590454 	 0.5479423999786377 	 
2025-07-30 19:48:59.589051 test begin: paddle.digamma(Tensor([8, 3101, 32, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 3101, 32, 32],"float64"), ) 	 25403392 	 1000 	 1.1688060760498047 	 1.1414554119110107 	 1.1602201461791992 	 1.1309444904327393 	 8.550721645355225 	 1.0846068859100342 	 8.496366739273071 	 0.5541396141052246 	 
2025-07-30 19:49:13.324118 test begin: paddle.digamma(Tensor([8, 6202, 32, 32],"float32"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8, 6202, 32, 32],"float32"), ) 	 50806784 	 1000 	 0.9606342315673828 	 1.0626256465911865 	 0.9521632194519043 	 1.05194091796875 	 4.487030982971191 	 1.0723857879638672 	 4.434104919433594 	 0.5478870868682861 	 
2025-07-30 19:49:22.589638 test begin: paddle.digamma(Tensor([8269, 3, 32, 32],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(Tensor([8269, 3, 32, 32],"float64"), ) 	 25402368 	 1000 	 1.1685905456542969 	 1.1415631771087646 	 1.160005807876587 	 1.1311097145080566 	 8.55084228515625 	 1.084503173828125 	 8.498404026031494 	 0.5541353225708008 	 
2025-07-30 19:49:37.183474 test begin: paddle.digamma(x=Tensor([19601, 6, 6, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([19601, 6, 6, 6, 6],"float64"), ) 	 25402896 	 1000 	 1.1689271926879883 	 1.1424672603607178 	 1.160588264465332 	 1.1307556629180908 	 8.545300483703613 	 1.0845818519592285 	 8.492549419403076 	 0.5541403293609619 	 
2025-07-30 19:49:50.306735 test begin: paddle.digamma(x=Tensor([3, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 39201, 6, 6, 6],"float64"), ) 	 25402248 	 1000 	 1.1688568592071533 	 1.1417570114135742 	 1.160139799118042 	 1.131270408630371 	 8.549830913543701 	 1.084627628326416 	 8.497364521026611 	 0.554154634475708 	 
2025-07-30 19:50:03.350811 test begin: paddle.digamma(x=Tensor([3, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 39201, 6, 6],"float64"), ) 	 25402248 	 1000 	 1.168724536895752 	 1.1528067588806152 	 1.160020351409912 	 1.1307222843170166 	 8.54947543144226 	 1.0846495628356934 	 8.496826171875 	 0.5541486740112305 	 
2025-07-30 19:50:16.454287 test begin: paddle.digamma(x=Tensor([3, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 6, 39201, 6],"float64"), ) 	 25402248 	 1000 	 1.1682555675506592 	 1.141402244567871 	 1.1595125198364258 	 1.1308367252349854 	 8.549599885940552 	 1.0846726894378662 	 8.497169017791748 	 0.5541572570800781 	 
2025-07-30 19:50:29.532304 test begin: paddle.digamma(x=Tensor([3, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.digamma 	 paddle.digamma(x=Tensor([3, 6, 6, 6, 39201],"float64"), ) 	 25402248 	 1000 	 1.168761968612671 	 1.1464247703552246 	 1.1529946327209473 	 1.1306235790252686 	 8.54910159111023 	 1.0847914218902588 	 8.486800909042358 	 0.5542471408843994 	 
2025-07-30 19:50:42.951274 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([2540161, 10],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([10],"float64"), y=Tensor([2540161, 10],"float64"), ) 	 25401620 	 1000 	 0.4544558525085449 	 0.4553401470184326 	 0.11586737632751465 	 0.15495610237121582 	 6.736791372299194 	 2.8749024868011475 	 1.3789849281311035 	 0.22583794593811035 	 
2025-07-30 19:50:54.578085 test begin: paddle.dist(x=Tensor([113401, 1, 1, 4, 4],"float64"), y=Tensor([113401, 8, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([113401, 1, 1, 4, 4],"float64"), y=Tensor([113401, 8, 7, 1, 4],"float64"), ) 	 27216240 	 1000 	 1.3772249221801758 	 1.404905080795288 	 0.3511953353881836 	 0.4782421588897705 	 8.512342691421509 	 11.310192108154297 	 1.7388505935668945 	 0.8890635967254639 	 
2025-07-30 19:51:19.022230 test begin: paddle.dist(x=Tensor([1587601, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([1587601, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 	 25401644 	 1000 	 2.2152113914489746 	 2.2969915866851807 	 0.5648412704467773 	 0.7819478511810303 	 15.2055983543396 	 19.245157718658447 	 2.5871360301971436 	 1.4047715663909912 	 
2025-07-30 19:52:01.178433 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 453601, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 453601, 7, 1, 4],"float64"), ) 	 25401688 	 1000 	 1.3619813919067383 	 1.3947513103485107 	 0.34733128547668457 	 0.47478151321411133 	 9.918287992477417 	 11.316070079803467 	 1.688408374786377 	 0.8259410858154297 	 
2025-07-30 19:52:25.768937 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 396901, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 396901, 1, 4],"float64"), ) 	 25401696 	 1000 	 1.361565113067627 	 1.394073724746704 	 0.3471486568450928 	 0.474637508392334 	 9.941396951675415 	 11.313860654830933 	 1.6923182010650635 	 0.825869083404541 	 
2025-07-30 19:52:51.965173 test begin: paddle.dist(x=Tensor([2, 1, 3175201, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 3175201, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 	 25401636 	 1000 	 3.043708324432373 	 3.0654420852661133 	 0.7760906219482422 	 1.043104648590088 	 16.17961573600769 	 20.83155655860901 	 2.7530200481414795 	 1.5206823348999023 	 
2025-07-30 19:53:35.764676 test begin: paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([6350401, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([6350401, 1, 4],"float64"), ) 	 25401636 	 1000 	 2.7083160877227783 	 2.7536909580230713 	 0.6906321048736572 	 0.9374513626098633 	 17.593716859817505 	 22.355592727661133 	 2.9946703910827637 	 1.631880283355713 	 
2025-07-30 19:54:23.344132 test begin: paddle.dist(x=Tensor([2, 1, 793801, 4, 4],"float64"), y=Tensor([2, 8, 793801, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 1, 793801, 4, 4],"float64"), y=Tensor([2, 8, 793801, 1, 4],"float64"), ) 	 76204896 	 1000 	 3.754328966140747 	 3.7490153312683105 	 0.9573798179626465 	 1.2757179737091064 	 18.122952461242676 	 24.644748210906982 	 3.7016851902008057 	 1.9370946884155273 	 
2025-07-30 19:55:15.997682 test begin: paddle.dist(x=Tensor([2, 793801, 1, 4, 4],"float64"), y=Tensor([2, 793801, 7, 1, 4],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([2, 793801, 1, 4, 4],"float64"), y=Tensor([2, 793801, 7, 1, 4],"float64"), ) 	 69854488 	 1000 	 2.5266387462615967 	 2.5557498931884766 	 0.6443116664886475 	 0.869929313659668 	 15.25321912765503 	 20.08120346069336 	 3.1156485080718994 	 1.578594446182251 	 
2025-07-30 19:56:00.718861 test begin: paddle.dist(x=Tensor([25401601],"float64"), y=Tensor([4, 25401601],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([25401601],"float64"), y=Tensor([4, 25401601],"float64"), ) 	 127008005 	 1000 	 2.3461239337921143 	 2.3548598289489746 	 0.5982301235198975 	 0.8012158870697021 	 8.473066568374634 	 12.599358320236206 	 2.162510395050049 	 1.072828769683838 	 
2025-07-30 19:56:29.320245 test begin: paddle.dist(x=Tensor([6350401],"float64"), y=Tensor([4, 6350401],"float64"), )
[Prof] paddle.dist 	 paddle.dist(x=Tensor([6350401],"float64"), y=Tensor([4, 6350401],"float64"), ) 	 31752005 	 1000 	 0.6023836135864258 	 0.599522590637207 	 0.15360093116760254 	 0.20397186279296875 	 2.143954277038574 	 3.1910178661346436 	 0.5472400188446045 	 0.27172136306762695 	 
2025-07-30 19:56:38.190585 test begin: paddle.divide(Tensor([128, 396901],"float32"), Tensor([1, 396901],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([128, 396901],"float32"), Tensor([1, 396901],"float32"), ) 	 51200229 	 1000 	 0.2997853755950928 	 0.32370495796203613 	 0.28151774406433105 	 0.29239463806152344 	 0.8019649982452393 	 1.837944746017456 	 0.4097156524658203 	 0.3128674030303955 	 
2025-07-30 19:56:43.170980 test begin: paddle.divide(Tensor([51059, 995],"float32"), Tensor([1, 995],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([51059, 995],"float32"), Tensor([1, 995],"float32"), ) 	 50804700 	 1000 	 0.29755163192749023 	 0.3147902488708496 	 0.27938175201416016 	 0.2973606586456299 	 0.9044990539550781 	 1.863086223602295 	 0.3078114986419678 	 0.2719461917877197 	 
2025-07-30 19:56:48.179681 test begin: paddle.divide(Tensor([51059, 995],"float32"), Tensor([51059, 995],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([51059, 995],"float32"), Tensor([51059, 995],"float32"), ) 	 101607410 	 1000 	 0.45026636123657227 	 0.449892520904541 	 0.4365854263305664 	 0.43813657760620117 	 1.1295230388641357 	 2.0920848846435547 	 1.0623118877410889 	 0.42765259742736816 	 
2025-07-30 19:56:54.819543 test begin: paddle.divide(Tensor([512, 99226],"float32"), Tensor([1, 99226],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([512, 99226],"float32"), Tensor([1, 99226],"float32"), ) 	 50902938 	 1000 	 0.29551148414611816 	 0.3104226589202881 	 0.284771203994751 	 0.29792189598083496 	 0.8425695896148682 	 1.832862138748169 	 0.2866630554199219 	 0.31203508377075195 	 
2025-07-30 19:57:02.096316 test begin: paddle.divide(Tensor([544, 93431],"float32"), Tensor([1, 93431],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([544, 93431],"float32"), Tensor([1, 93431],"float32"), ) 	 50919895 	 1000 	 0.29579639434814453 	 0.3138580322265625 	 0.285231351852417 	 0.298018217086792 	 0.8940944671630859 	 1.8386962413787842 	 0.30438733100891113 	 0.31304264068603516 	 
2025-07-30 19:57:08.128099 test begin: paddle.divide(Tensor([544, 93431],"float32"), Tensor([544, 93431],"float32"), )
[Prof] paddle.divide 	 paddle.divide(Tensor([544, 93431],"float32"), Tensor([544, 93431],"float32"), ) 	 101652928 	 1000 	 0.45039868354797363 	 0.4500610828399658 	 0.4404439926147461 	 0.4382803440093994 	 1.1299867630004883 	 2.093008041381836 	 1.0673935413360596 	 0.42783093452453613 	 
2025-07-30 19:57:14.741688 test begin: paddle.divide(x=Tensor([16934401, 3],"float32"), y=Tensor([3],"float32"), )
[Prof] paddle.divide 	 paddle.divide(x=Tensor([16934401, 3],"float32"), y=Tensor([3],"float32"), ) 	 50803206 	 1000 	 0.2968168258666992 	 0.3097541332244873 	 0.27805066108703613 	 0.29077649116516113 	 5.6579766273498535 	 1.8547732830047607 	 1.9287889003753662 	 0.27077722549438477 	 
2025-07-30 19:57:24.846790 test begin: paddle.divide(x=Tensor([187679, 271],"float32"), y=Tensor([271],"float32"), )
[Prof] paddle.divide 	 paddle.divide(x=Tensor([187679, 271],"float32"), y=Tensor([271],"float32"), ) 	 50861280 	 1000 	 0.29734277725219727 	 0.31012892723083496 	 0.2787649631500244 	 0.29123425483703613 	 1.0057659149169922 	 1.8381693363189697 	 0.34235358238220215 	 0.26836252212524414 	 
2025-07-30 19:57:29.926457 test begin: paddle.dot(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
Warning: The core code of paddle.dot is too complex.
[Prof] paddle.dot 	 paddle.dot(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 6.283560276031494 	 0.2935934066772461 	 6.266956090927124 	 0.14998579025268555 	 0.6261892318725586 	 0.6004650592803955 	 0.3199501037597656 	 0.3067648410797119 	 
2025-07-30 19:57:41.134952 test begin: paddle.dot(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), )
[Prof] paddle.dot 	 paddle.dot(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.2969474792480469 	 0.2929244041442871 	 0.2871990203857422 	 0.14963793754577637 	 0.7102165222167969 	 0.6039965152740479 	 0.3628673553466797 	 0.30855870246887207 	 
2025-07-30 19:57:44.673927 test begin: paddle.dot(x=Tensor([5080320],"int32"), y=Tensor([5080320],"int32"), )
[Prof] paddle.dot 	 paddle.dot(x=Tensor([5080320],"int32"), y=Tensor([5080320],"int32"), ) 	 10160640 	 1000 	 213.0424087047577 	 0.038480520248413086 	 213.03282022476196 	 0.018951892852783203 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:01:18.176917 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], )
W0730 20:01:29.054466 38898 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.032195329666137695 	 0.009442567825317383 	 1.6450881958007812e-05 	 2.4080276489257812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:01:31.264482 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], )
W0730 20:01:39.619264 38937 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.029035091400146484 	 0.01593804359436035 	 5.888938903808594e-05 	 8.869171142578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:01:41.735517 test begin: paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], )
W0730 20:01:48.623953 38968 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([14112010, 3, 6],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.024215221405029297 	 0.008253097534179688 	 1.2874603271484375e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:01:49.866419 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], )
W0730 20:01:59.961977 38995 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.0525820255279541 	 0.00944066047668457 	 1.4781951904296875e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:02:03.433091 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], )
W0730 20:02:10.454957 39035 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.017571687698364258 	 0.007130861282348633 	 1.430511474609375e-05 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:02:11.692547 test begin: paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], )
W0730 20:02:19.254556 39054 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 1058401, 6],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.04021096229553223 	 0.013486385345458984 	 1.2159347534179688e-05 	 2.4318695068359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:02:20.979748 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], )
W0730 20:02:33.113772 39083 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.031285762786865234 	 0.00940847396850586 	 1.2874603271484375e-05 	 2.574920654296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:02:35.240001 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], )
W0730 20:02:42.191188 39127 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.017265796661376953 	 0.006979465484619141 	 1.430511474609375e-05 	 2.2172927856445312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:02:43.324571 test begin: paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], )
W0730 20:02:50.206542 39156 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.dsplit 	 paddle.dsplit(Tensor([40, 3, 2116801],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.02429032325744629 	 0.00836324691772461 	 2.1219253540039062e-05 	 3.170967102050781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:02:51.332329 test begin: paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9427380561828613 	 0.9397318363189697 	 0.9144012928009033 	 0.9248573780059814 	 0.9529550075531006 	 0.07588911056518555 	 0.8739628791809082 	 5.841255187988281e-05 	 
2025-07-30 20:02:57.952154 test begin: paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3200061321258545 	 0.325314998626709 	 0.3047144412994385 	 0.15996098518371582 	 0.3195614814758301 	 0.059670209884643555 	 0.26287341117858887 	 9.799003601074219e-05 	 
2025-07-30 20:03:00.029660 test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401900 	 1000 	 0.3216538429260254 	 0.32299041748046875 	 0.3018312454223633 	 0.30861854553222656 	 0.322662353515625 	 0.08280229568481445 	 0.2522158622741699 	 6.389617919921875e-05 	 
2025-07-30 20:03:02.144632 test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401900 	 1000 	 0.3217508792877197 	 0.32915425300598145 	 0.3018310070037842 	 0.3147013187408447 	 0.3222386837005615 	 0.07669544219970703 	 0.2523772716522217 	 4.1484832763671875e-05 	 
2025-07-30 20:03:04.297160 test begin: paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9726448059082031 	 0.9397821426391602 	 0.9530198574066162 	 0.918647050857544 	 0.9653503894805908 	 0.0777733325958252 	 0.8952522277832031 	 6.341934204101562e-05 	 
2025-07-30 20:03:10.424762 test begin: paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401660 	 1000 	 0.3218562602996826 	 0.3168623447418213 	 0.30121517181396484 	 0.3025064468383789 	 0.32137489318847656 	 0.07959604263305664 	 0.25141310691833496 	 4.601478576660156e-05 	 
2025-07-30 20:03:12.513072 test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401660 	 1000 	 0.3218834400177002 	 0.3259291648864746 	 0.3019866943359375 	 0.3117392063140869 	 0.32186102867126465 	 0.07598352432250977 	 0.25205302238464355 	 3.695487976074219e-05 	 
2025-07-30 20:03:14.653305 test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 25401660 	 1000 	 0.3217897415161133 	 0.32038235664367676 	 0.29375696182250977 	 0.2990295886993408 	 0.3223593235015869 	 0.10856819152832031 	 0.24251556396484375 	 0.00011014938354492188 	 
2025-07-30 20:03:16.728820 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401900 	 1000 	 0.32184815406799316 	 0.31961941719055176 	 0.3019990921020508 	 0.3052237033843994 	 0.3218996524810791 	 0.07616305351257324 	 0.25158166885375977 	 3.075599670410156e-05 	 
2025-07-30 20:03:18.814628 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9690537452697754 	 0.9467728137969971 	 0.9490475654602051 	 0.932044267654419 	 0.9683341979980469 	 0.07676887512207031 	 0.8990943431854248 	 4.863739013671875e-05 	 
2025-07-30 20:03:25.000600 test begin: paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.32178258895874023 	 0.313342809677124 	 0.30634355545043945 	 0.15998363494873047 	 0.3217616081237793 	 0.05813717842102051 	 0.26496148109436035 	 3.647804260253906e-05 	 
2025-07-30 20:03:27.060371 test begin: paddle.dstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 1.5525329113006592 	 2.866858720779419 	 1.5327599048614502 	 2.3787808418273926 	 2.6026406288146973 	 0.0790719985961914 	 2.5324907302856445 	 5.2928924560546875e-05 	 
2025-07-30 20:03:39.606246 test begin: paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9621241092681885 	 2.5251924991607666 	 0.9421558380126953 	 2.498832941055298 	 1.0668666362762451 	 0.08391284942626953 	 0.995699405670166 	 4.673004150390625e-05 	 
2025-07-30 20:03:47.716754 test begin: paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3899085521697998 	 0.3134181499481201 	 0.37467336654663086 	 0.16002202033996582 	 0.39548802375793457 	 0.061524391174316406 	 0.3386361598968506 	 5.817413330078125e-05 	 
2025-07-30 20:03:49.916689 test begin: paddle.dstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 1.5524733066558838 	 2.4021239280700684 	 1.5326385498046875 	 2.3861913681030273 	 2.6018731594085693 	 0.07678484916687012 	 2.5320942401885986 	 7.653236389160156e-05 	 
2025-07-30 20:03:59.799539 test begin: paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9628047943115234 	 2.52312970161438 	 0.9428117275238037 	 2.5060205459594727 	 1.0719316005706787 	 0.07733750343322754 	 1.0031557083129883 	 4.100799560546875e-05 	 
2025-07-30 20:04:07.692796 test begin: paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.dstack 	 paddle.dstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3896059989929199 	 0.31339073181152344 	 0.3742833137512207 	 0.15999674797058105 	 0.3957247734069824 	 0.05876421928405762 	 0.33630990982055664 	 4.410743713378906e-05 	 
2025-07-30 20:04:09.892286 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([200, 8, 498, 498],"float32"), Tensor([200, 8, 498, 64],"float32"), )
Warning: The core code of paddle.einsum is too complex.
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([200, 8, 498, 498],"float32"), Tensor([200, 8, 498, 64],"float32"), ) 	 447801600 	 1000 	 6.074416399002075 	 7.229615688323975 	 6.015709400177002 	 6.0139124393463135 	 12.326142311096191 	 9.485430240631104 	 2.520277500152588 	 4.846545934677124 	 
2025-07-30 20:04:55.184196 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([209, 8, 477, 477],"float32"), Tensor([209, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([209, 8, 477, 477],"float32"), Tensor([209, 8, 477, 64],"float32"), ) 	 431471304 	 1000 	 5.985414743423462 	 5.985283851623535 	 5.927412509918213 	 5.931747198104858 	 12.298821449279785 	 9.554739952087402 	 2.51523494720459 	 4.8821961879730225 	 
2025-07-30 20:05:37.322243 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([218, 8, 457, 457],"float32"), Tensor([218, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([218, 8, 457, 457],"float32"), Tensor([218, 8, 457, 64],"float32"), ) 	 415241168 	 1000 	 6.179850339889526 	 6.063214540481567 	 6.121967077255249 	 6.009282350540161 	 12.402501106262207 	 9.803304195404053 	 2.5363430976867676 	 5.009328365325928 	 
2025-07-30 20:06:20.706273 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([26, 8, 498, 498],"float32"), Tensor([26, 8, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([26, 8, 498, 498],"float32"), Tensor([26, 8, 498, 64],"float32"), ) 	 58214208 	 1000 	 0.8209228515625 	 0.821014404296875 	 0.7628257274627686 	 0.7680308818817139 	 1.6524689197540283 	 1.2761034965515137 	 0.33790063858032227 	 0.6519784927368164 	 
2025-07-30 20:06:26.366788 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([28, 8, 477, 477],"float32"), Tensor([28, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([28, 8, 477, 477],"float32"), Tensor([28, 8, 477, 64],"float32"), ) 	 57804768 	 1000 	 0.8776626586914062 	 0.8805539608001709 	 0.8196377754211426 	 0.8232007026672363 	 1.7452809810638428 	 1.3676230907440186 	 0.35691118240356445 	 0.6987159252166748 	 
2025-07-30 20:06:32.326075 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 54, 498, 498],"float32"), Tensor([30, 54, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 54, 498, 498],"float32"), Tensor([30, 54, 498, 64],"float32"), ) 	 453399120 	 1000 	 6.084366083145142 	 6.078505754470825 	 6.018559455871582 	 6.005768060684204 	 12.408066272735596 	 9.535726070404053 	 2.5375428199768066 	 4.8726747035980225 	 
2025-07-30 20:07:17.678464 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 56, 477, 477],"float32"), Tensor([30, 56, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 56, 477, 477],"float32"), Tensor([30, 56, 477, 64],"float32"), ) 	 433535760 	 1000 	 6.077147006988525 	 6.076432228088379 	 6.008864879608154 	 6.006130695343018 	 12.422269105911255 	 9.66449499130249 	 2.5402636528015137 	 4.938397169113159 	 
2025-07-30 20:08:02.598772 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 58, 457, 457],"float32"), Tensor([30, 58, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 58, 457, 457],"float32"), Tensor([30, 58, 457, 64],"float32"), ) 	 414288780 	 1000 	 6.062360048294067 	 6.062513113021851 	 6.003726243972778 	 6.008666753768921 	 12.388515949249268 	 9.794878959655762 	 2.5335099697113037 	 5.005126714706421 	 
2025-07-30 20:08:44.693180 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 7, 498, 498],"float32"), Tensor([30, 7, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 7, 498, 498],"float32"), Tensor([30, 7, 498, 64],"float32"), ) 	 58773960 	 1000 	 0.8208761215209961 	 0.8283979892730713 	 0.7496261596679688 	 0.7490339279174805 	 1.6669697761535645 	 1.2812669277191162 	 0.3409116268157959 	 0.654533863067627 	 
2025-07-30 20:08:50.468691 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 426, 498],"float32"), Tensor([30, 8, 498, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 426, 498],"float32"), Tensor([30, 8, 498, 64],"float32"), ) 	 58564800 	 1000 	 0.9212689399719238 	 0.9216525554656982 	 0.8626585006713867 	 0.8665573596954346 	 1.6920928955078125 	 1.3193669319152832 	 0.34597349166870117 	 0.6740548610687256 	 
2025-07-30 20:08:56.444226 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 444, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 444, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), ) 	 58155840 	 1000 	 0.8788900375366211 	 0.8839099407196045 	 0.8110911846160889 	 0.8052544593811035 	 1.721508264541626 	 1.3478894233703613 	 0.3519625663757324 	 0.6886124610900879 	 
2025-07-30 20:09:02.472140 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 457, 457],"float32"), Tensor([30, 8, 457, 464],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 457, 457],"float32"), Tensor([30, 8, 457, 464],"float32"), ) 	 101015280 	 1000 	 3.3726208209991455 	 3.3651249408721924 	 3.3122146129608154 	 3.3077635765075684 	 7.618727445602417 	 6.74382472038269 	 1.5578222274780273 	 3.4459218978881836 	 
2025-07-30 20:09:26.290092 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 464, 457],"float32"), Tensor([30, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 464, 457],"float32"), Tensor([30, 8, 457, 64],"float32"), ) 	 57911040 	 1000 	 0.8504045009613037 	 0.8556649684906006 	 0.7823381423950195 	 0.7826783657073975 	 1.7449123859405518 	 1.3755595684051514 	 0.35682010650634766 	 0.7027852535247803 	 
2025-07-30 20:09:32.237199 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 444],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 444],"float32"), ) 	 105436080 	 1000 	 3.481569528579712 	 3.4815428256988525 	 3.413290500640869 	 3.4267430305480957 	 7.655925035476685 	 6.745004415512085 	 1.5655474662780762 	 3.4465694427490234 	 
2025-07-30 20:09:56.379241 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 477, 477],"float32"), Tensor([30, 8, 477, 64],"float32"), ) 	 61933680 	 1000 	 0.8795599937438965 	 0.8794827461242676 	 0.8204782009124756 	 0.8251659870147705 	 1.8054134845733643 	 1.4029183387756348 	 0.36916375160217285 	 0.7167191505432129 	 
2025-07-30 20:10:02.608325 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 498, 498],"float32"), Tensor([30, 8, 498, 426],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 8, 498, 498],"float32"), Tensor([30, 8, 498, 426],"float32"), ) 	 110436480 	 1000 	 3.65226411819458 	 3.6599557399749756 	 3.5939881801605225 	 3.5779600143432617 	 7.739996671676636 	 6.800563812255859 	 1.5828967094421387 	 3.4748270511627197 	 
2025-07-30 20:10:27.216943 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 9, 457, 457],"float32"), Tensor([30, 9, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([30, 9, 457, 457],"float32"), Tensor([30, 9, 457, 64],"float32"), ) 	 64286190 	 1000 	 0.9438683986663818 	 0.943838357925415 	 0.883493185043335 	 0.8898446559906006 	 1.943962574005127 	 1.5335073471069336 	 0.3975403308868408 	 0.7834672927856445 	 
2025-07-30 20:10:33.849275 test begin: paddle.einsum("b h i j, b h j d -> b h i d", Tensor([31, 8, 457, 457],"float32"), Tensor([31, 8, 457, 64],"float32"), )
[Prof] paddle.einsum 	 paddle.einsum("b h i j, b h j d -> b h i d", Tensor([31, 8, 457, 457],"float32"), Tensor([31, 8, 457, 64],"float32"), ) 	 59048056 	 1000 	 0.9416468143463135 	 0.9574708938598633 	 0.8828105926513672 	 0.8881781101226807 	 1.862048625946045 	 1.4847071170806885 	 0.3807806968688965 	 0.7584555149078369 	 
2025-07-30 20:10:41.893724 test begin: paddle.empty_like(Tensor([1016064010],"uint8"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([1016064010],"uint8"), ) 	 1016064010 	 1000 	 0.0118560791015625 	 0.005887031555175781 	 1.2636184692382812e-05 	 3.6716461181640625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:51.338468 test begin: paddle.empty_like(Tensor([40960, 12404],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"bool"), ) 	 508067840 	 1000 	 0.01124715805053711 	 0.005722761154174805 	 1.0013580322265625e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:58.271214 test begin: paddle.empty_like(Tensor([40960, 12404],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([40960, 12404],"float32"), ) 	 508067840 	 1000 	 0.4664137363433838 	 1.1477370262145996 	 3.0994415283203125e-05 	 7.963180541992188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:09.461920 test begin: paddle.empty_like(Tensor([7938010, 64],"bool"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"bool"), ) 	 508032640 	 1000 	 0.01128530502319336 	 1.4886724948883057 	 8.344650268554688e-06 	 7.557868957519531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:18.476066 test begin: paddle.empty_like(Tensor([7938010, 64],"float32"), )
[Prof] paddle.empty_like 	 paddle.empty_like(Tensor([7938010, 64],"float32"), ) 	 508032640 	 1000 	 0.012595176696777344 	 0.006127357482910156 	 1.4066696166992188e-05 	 3.6716461181640625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:28.470619 test begin: paddle.equal(Tensor([4148, 6124],"int64"), Tensor([4148, 6124],"int64"), )
[Prof] paddle.equal 	 paddle.equal(Tensor([4148, 6124],"int64"), Tensor([4148, 6124],"int64"), ) 	 50804704 	 1000 	 0.3110995292663574 	 0.31330084800720215 	 0.29993677139282227 	 0.3018226623535156 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:29.981570 test begin: paddle.equal(Tensor([416, 61062],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([416, 61062],"int64"), 0, ) 	 25401792 	 1000 	 0.17805027961730957 	 0.16832423210144043 	 0.09094834327697754 	 0.1544945240020752 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:30.736017 test begin: paddle.equal(Tensor([512, 49613],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([512, 49613],"int64"), 0, ) 	 25401856 	 1000 	 0.17808794975280762 	 0.16829895973205566 	 0.09096670150756836 	 0.1542530059814453 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:31.496019 test begin: paddle.equal(Tensor([846721, 30],"int64"), 0, )
[Prof] paddle.equal 	 paddle.equal(Tensor([846721, 30],"int64"), 0, ) 	 25401630 	 1000 	 0.1772911548614502 	 0.16842412948608398 	 0.09057450294494629 	 0.15348315238952637 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:32.255641 test begin: paddle.equal(Tensor([846721, 30],"int64"), Tensor([846721, 30],"int64"), )
[Prof] paddle.equal 	 paddle.equal(Tensor([846721, 30],"int64"), Tensor([846721, 30],"int64"), ) 	 50803260 	 1000 	 0.31020069122314453 	 0.31324100494384766 	 0.2990593910217285 	 0.3017129898071289 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:33.701586 test begin: paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 2540161],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 10, 2540161],"bool"), Tensor([1, 2, 10, 2540161],"bool"), ) 	 101606440 	 1000 	 0.1698746681213379 	 0.20587587356567383 	 0.05779862403869629 	 8.487701416015625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:38.894085 test begin: paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 2, 1587601, 16],"bool"), Tensor([1, 2, 1587601, 16],"bool"), ) 	 101606464 	 1000 	 0.16986393928527832 	 0.20768499374389648 	 0.057805776596069336 	 7.05718994140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:40.698429 test begin: paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1, 317521, 10, 16],"bool"), Tensor([1, 317521, 10, 16],"bool"), ) 	 101606720 	 1000 	 0.16985797882080078 	 0.20714759826660156 	 0.057801008224487305 	 6.246566772460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:42.537046 test begin: paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([101, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.018494129180908203 	 0.002560138702392578 	 1.1444091796875e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:43.254120 test begin: paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([12801],"float32"), Tensor([50803201],"float32"), ) 	 50816002 	 1000 	 0.018390655517578125 	 0.002525806427001953 	 1.3828277587890625e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:44.124681 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([101, 2, 10, 16],"bool"), ) 	 50835840 	 1000 	 0.017489910125732422 	 0.002512216567993164 	 9.298324584960938e-06 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:44.844596 test begin: paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([158761, 2, 10, 16],"bool"), Tensor([158761, 2, 10, 16],"bool"), ) 	 101607040 	 1000 	 0.17000794410705566 	 0.20850157737731934 	 0.0578608512878418 	 7.152557373046875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:46.936270 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([16, 3175201],"float32"), ) 	 101606432 	 1000 	 0.3802042007446289 	 0.41652917861938477 	 0.12932324409484863 	 7.224082946777344e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:49.358952 test begin: paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([16, 3175201],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.017572879791259766 	 0.002537250518798828 	 1.1444091796875e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:50.187692 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([16, 3175201],"float32"), ) 	 50828832 	 1000 	 0.01726365089416504 	 0.0025637149810791016 	 1.0251998901367188e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:51.053807 test begin: paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([1601, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 50828832 	 1000 	 0.017452239990234375 	 0.0025115013122558594 	 9.5367431640625e-06 	 1.4781951904296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:51.890843 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([1601, 16],"float32"), ) 	 50828832 	 1000 	 0.017451763153076172 	 0.002530813217163086 	 1.0967254638671875e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:52.721109 test begin: paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([3175201, 16],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([3175201, 16],"float32"), Tensor([3175201, 16],"float32"), ) 	 101606432 	 1000 	 0.3802039623260498 	 0.41860246658325195 	 0.12929797172546387 	 0.0001857280731201172 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:55.137446 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([12801],"float32"), ) 	 50816002 	 1000 	 0.01739501953125 	 0.0024881362915039062 	 1.0013580322265625e-05 	 1.5497207641601562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:55.972045 test begin: paddle.equal_all(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.equal_all 	 paddle.equal_all(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.3801891803741455 	 0.4176623821258545 	 0.12929487228393555 	 8.511543273925781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:58.408915 test begin: paddle.erf(Tensor([11, 2309237],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([11, 2309237],"float64"), ) 	 25401607 	 1000 	 0.3379528522491455 	 0.3038160800933838 	 0.32898497581481934 	 0.2925269603729248 	 0.44820451736450195 	 1.6382293701171875 	 0.39469122886657715 	 0.33489108085632324 	 
2025-07-30 20:12:02.246977 test begin: paddle.erf(Tensor([1494212, 17],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([1494212, 17],"float64"), ) 	 25401604 	 1000 	 0.33796000480651855 	 0.30382490158081055 	 0.3219485282897949 	 0.28605127334594727 	 0.4481825828552246 	 1.6382520198822021 	 0.3854024410247803 	 0.3349273204803467 	 
2025-07-30 20:12:06.114724 test begin: paddle.erf(Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.33765625953674316 	 0.3045790195465088 	 0.32158589363098145 	 0.2860260009765625 	 0.44785022735595703 	 1.6380059719085693 	 0.3854234218597412 	 0.33491015434265137 	 
2025-07-30 20:12:09.908409 test begin: paddle.erf(Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.33774328231811523 	 0.30385851860046387 	 0.32181406021118164 	 0.292388916015625 	 0.44794797897338867 	 1.6382253170013428 	 0.3947632312774658 	 0.33483290672302246 	 
2025-07-30 20:12:13.772472 test begin: paddle.erf(Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.337939977645874 	 0.3100566864013672 	 0.3219470977783203 	 0.28586697578430176 	 0.44793009757995605 	 1.638091802597046 	 0.3855290412902832 	 0.33490705490112305 	 
2025-07-30 20:12:17.569290 test begin: paddle.erf(Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.33789539337158203 	 0.30374646186828613 	 0.3220674991607666 	 0.28582191467285156 	 0.44817447662353516 	 1.6380717754364014 	 0.3858025074005127 	 0.334942102432251 	 
2025-07-30 20:12:21.354133 test begin: paddle.erf(Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.337299108505249 	 0.7629330158233643 	 0.32134461402893066 	 0.28585100173950195 	 0.44757580757141113 	 1.6381752490997314 	 0.3852856159210205 	 0.3348536491394043 	 
2025-07-30 20:12:27.756423 test begin: paddle.erf(Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.33765172958374023 	 0.3037528991699219 	 0.3216729164123535 	 0.285813570022583 	 0.44784116744995117 	 1.63859224319458 	 0.3849618434906006 	 0.33498644828796387 	 
2025-07-30 20:12:31.615826 test begin: paddle.erf(Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3376164436340332 	 0.3038182258605957 	 0.3215770721435547 	 0.2858560085296631 	 0.4478769302368164 	 1.6382362842559814 	 0.38547372817993164 	 0.3348991870880127 	 
2025-07-30 20:12:37.167911 test begin: paddle.erf(Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.33778929710388184 	 0.3086535930633545 	 0.32178425788879395 	 0.2858915328979492 	 0.4478566646575928 	 1.6382966041564941 	 0.38588428497314453 	 0.33493995666503906 	 
2025-07-30 20:12:41.269879 test begin: paddle.erf(Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.erf 	 paddle.erf(Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.3379528522491455 	 0.30379176139831543 	 0.3290536403656006 	 0.2924835681915283 	 0.4481997489929199 	 1.6379621028900146 	 0.39478397369384766 	 0.334881067276001 	 
2025-07-30 20:12:45.058660 test begin: paddle.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.3319728374481201 	 0.3110356330871582 	 0.31565237045288086 	 0.2919809818267822 	 0.44736528396606445 	 1.642733097076416 	 0.3853938579559326 	 0.3358018398284912 	 
2025-07-30 20:12:48.922441 test begin: paddle.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.3344991207122803 	 0.3089916706085205 	 0.32518577575683594 	 0.29816174507141113 	 0.447340726852417 	 1.642505168914795 	 0.39435529708862305 	 0.33589768409729004 	 
2025-07-30 20:12:52.724764 test begin: paddle.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.33430004119873047 	 0.30895280838012695 	 0.3249683380126953 	 0.2922184467315674 	 0.4475705623626709 	 1.642406940460205 	 0.3817100524902344 	 0.3358595371246338 	 
2025-07-30 20:12:56.617183 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.33414506912231445 	 0.30899691581726074 	 0.3247244358062744 	 0.29824233055114746 	 0.44795894622802734 	 1.6423850059509277 	 0.3946561813354492 	 0.33576059341430664 	 
2025-07-30 20:13:00.438137 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.334367036819458 	 0.3091104030609131 	 0.3249368667602539 	 0.29235410690307617 	 0.4470784664154053 	 1.6423614025115967 	 0.39400172233581543 	 0.33579397201538086 	 
2025-07-30 20:13:04.211562 test begin: paddle.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.33470988273620605 	 0.30904269218444824 	 0.31835389137268066 	 0.2922854423522949 	 0.4473865032196045 	 1.6423633098602295 	 0.38428831100463867 	 0.3356356620788574 	 
2025-07-30 20:13:08.141853 test begin: paddle.erfinv(x=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 3175201],"float64"), ) 	 25401608 	 1000 	 0.33428478240966797 	 0.3122367858886719 	 0.3250758647918701 	 0.2993309497833252 	 0.4479849338531494 	 1.6422781944274902 	 0.39464807510375977 	 0.3356966972351074 	 
2025-07-30 20:13:11.949177 test begin: paddle.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.33470988273620605 	 0.3103475570678711 	 0.325397253036499 	 0.29936671257019043 	 0.44749999046325684 	 1.6424486637115479 	 0.3942375183105469 	 0.3357088565826416 	 
2025-07-30 20:13:15.743528 test begin: paddle.erfinv(x=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 2116801, 3],"float64"), ) 	 25401612 	 1000 	 0.3347899913787842 	 0.311084508895874 	 0.32537317276000977 	 0.3004579544067383 	 0.44784975051879883 	 1.642787218093872 	 0.39473843574523926 	 0.3359098434448242 	 
2025-07-30 20:13:19.544196 test begin: paddle.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.3346998691558838 	 0.31154322624206543 	 0.3252854347229004 	 0.30080151557922363 	 0.4473092555999756 	 1.6429939270019531 	 0.3939547538757324 	 0.33589887619018555 	 
2025-07-30 20:13:23.328950 test begin: paddle.erfinv(x=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.3347053527832031 	 0.3114786148071289 	 0.3254988193511963 	 0.3008296489715576 	 0.44791626930236816 	 1.6422927379608154 	 0.39461421966552734 	 0.33571910858154297 	 
2025-07-30 20:13:27.118442 test begin: paddle.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.erfinv 	 paddle.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.33486390113830566 	 0.7770469188690186 	 0.32544398307800293 	 0.2966747283935547 	 0.4479200839996338 	 1.642310619354248 	 0.3948996067047119 	 0.33574438095092773 	 
2025-07-30 20:13:33.348534 test begin: paddle.exp(Tensor([125, 1, 640, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([125, 1, 640, 640],"float32"), ) 	 51200000 	 1000 	 0.2979915142059326 	 0.5304219722747803 	 0.28218793869018555 	 0.28275561332702637 	 0.45360898971557617 	 0.4501962661743164 	 0.3903517723083496 	 0.37262988090515137 	 
2025-07-30 20:13:39.513700 test begin: paddle.exp(Tensor([13, 243, 1007, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 243, 1007, 16],"float32"), ) 	 50897808 	 1000 	 0.2961876392364502 	 0.2987332344055176 	 0.28032422065734863 	 0.28077006340026855 	 0.45104146003723145 	 0.447521448135376 	 0.3861422538757324 	 0.37169551849365234 	 
2025-07-30 20:13:42.992724 test begin: paddle.exp(Tensor([13, 64, 1007, 61],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 64, 1007, 61],"float32"), ) 	 51107264 	 1000 	 0.29728007316589355 	 0.29970264434814453 	 0.28835248947143555 	 0.2882704734802246 	 0.45270562171936035 	 0.4493072032928467 	 0.3988204002380371 	 0.38051652908325195 	 
2025-07-30 20:13:46.128165 test begin: paddle.exp(Tensor([13, 64, 3817, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([13, 64, 3817, 16],"float32"), ) 	 50811904 	 1000 	 0.2958393096923828 	 0.2980043888092041 	 0.28696441650390625 	 0.28658390045166016 	 0.4501059055328369 	 0.4467785358428955 	 0.396028995513916 	 0.3791637420654297 	 
2025-07-30 20:13:49.237853 test begin: paddle.exp(Tensor([16, 1, 4962, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 1, 4962, 640],"float32"), ) 	 50810880 	 1000 	 0.29561829566955566 	 0.297879695892334 	 0.28685593605041504 	 0.2866036891937256 	 0.4500296115875244 	 0.4467802047729492 	 0.39583611488342285 	 0.3784902095794678 	 
2025-07-30 20:13:52.355079 test begin: paddle.exp(Tensor([16, 1, 640, 4962],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 1, 640, 4962],"float32"), ) 	 50810880 	 1000 	 0.2955811023712158 	 0.29796862602233887 	 0.27986764907836914 	 0.2805361747741699 	 0.45014262199401855 	 0.44680261611938477 	 0.38459181785583496 	 0.3772084712982178 	 
2025-07-30 20:13:55.615476 test begin: paddle.exp(Tensor([16, 8, 640, 640],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([16, 8, 640, 640],"float32"), ) 	 52428800 	 1000 	 0.30494189262390137 	 0.3071739673614502 	 0.29598188400268555 	 0.29594993591308594 	 0.4642617702484131 	 0.460726261138916 	 0.41045594215393066 	 0.390866756439209 	 
2025-07-30 20:13:58.839010 test begin: paddle.exp(Tensor([50, 64, 1007, 16],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([50, 64, 1007, 16],"float32"), ) 	 51558400 	 1000 	 0.29998111724853516 	 0.30225586891174316 	 0.2910783290863037 	 0.29075074195861816 	 0.45659446716308594 	 0.4532957077026367 	 0.40212297439575195 	 0.38468027114868164 	 
2025-07-30 20:14:01.990269 test begin: paddle.exp(Tensor([56, 1, 960, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([56, 1, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3002598285675049 	 0.3025188446044922 	 0.2844846248626709 	 0.28484654426574707 	 0.45706987380981445 	 0.4537656307220459 	 0.3924851417541504 	 0.37679362297058105 	 
2025-07-30 20:14:05.250697 test begin: paddle.exp(Tensor([8, 1, 6616, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 1, 6616, 960],"float32"), ) 	 50810880 	 1000 	 0.2955968379974365 	 0.2979404926300049 	 0.28663110733032227 	 0.28675007820129395 	 0.4500577449798584 	 0.44688892364501953 	 0.39563655853271484 	 0.3781306743621826 	 
2025-07-30 20:14:08.358614 test begin: paddle.exp(Tensor([8, 1, 960, 6616],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 1, 960, 6616],"float32"), ) 	 50810880 	 1000 	 0.2957422733306885 	 0.2980377674102783 	 0.2868931293487549 	 0.28678178787231445 	 0.4501481056213379 	 0.44689345359802246 	 0.3959848880767822 	 0.37853336334228516 	 
2025-07-30 20:14:11.462992 test begin: paddle.exp(Tensor([8, 7, 960, 960],"float32"), )
[Prof] paddle.exp 	 paddle.exp(Tensor([8, 7, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.3005218505859375 	 0.30513548851013184 	 0.291595458984375 	 0.2909259796142578 	 0.45703840255737305 	 0.45374536514282227 	 0.4028487205505371 	 0.38497376441955566 	 
2025-07-30 20:14:14.671644 test begin: paddle.expand_as(Tensor([1621, 80, 1, 1],"float32"), Tensor([1621, 80, 28, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([1621, 80, 1, 1],"float32"), Tensor([1621, 80, 28, 28],"float16"), ) 	 101798800 	 1000 	 0.270305871963501 	 0.003755807876586914 	 0.2587721347808838 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:14:18.714240 test begin: paddle.expand_as(Tensor([511, 127, 1, 1],"float32"), Tensor([511, 127, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 127, 1, 1],"float32"), Tensor([511, 127, 28, 28],"float32"), ) 	 50944145 	 1000 	 0.1374192237854004 	 0.0038378238677978516 	 0.12602972984313965 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:14:20.617484 test begin: paddle.expand_as(Tensor([511, 80, 1, 1243],"float32"), Tensor([511, 80, 28, 1243],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1243],"float32"), Tensor([511, 80, 28, 1243],"float32"), ) 	 1473601360 	 1000 	 4.05724024772644 	 0.0038099288940429688 	 4.0454864501953125 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:15:28.438524 test begin: paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 28, 45],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 28, 45],"float32"), ) 	 51549680 	 1000 	 0.14017510414123535 	 0.0037584304809570312 	 0.12825417518615723 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:15:30.535174 test begin: paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 45, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1, 1],"float32"), Tensor([511, 80, 45, 28],"float32"), ) 	 51549680 	 1000 	 0.13890671730041504 	 0.003760814666748047 	 0.12738370895385742 	 1.7881393432617188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:15:32.493539 test begin: paddle.expand_as(Tensor([511, 80, 1243, 1],"float32"), Tensor([511, 80, 1243, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([511, 80, 1243, 1],"float32"), Tensor([511, 80, 1243, 28],"float32"), ) 	 1473601360 	 1000 	 4.317623138427734 	 0.0037817955017089844 	 4.305727481842041 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:16:31.711421 test begin: paddle.expand_as(Tensor([512, 127, 1, 1],"float32"), Tensor([512, 127, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 127, 1, 1],"float32"), Tensor([512, 127, 28, 28],"float32"), ) 	 51043840 	 1000 	 0.1390395164489746 	 0.003762483596801758 	 0.12758255004882812 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:16:33.851633 test begin: paddle.expand_as(Tensor([512, 254, 1, 1],"float32"), Tensor([512, 254, 28, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 254, 1, 1],"float32"), Tensor([512, 254, 28, 28],"float16"), ) 	 102087680 	 1000 	 0.27110815048217773 	 0.007082700729370117 	 0.25963902473449707 	 3.337860107421875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:16:39.656554 test begin: paddle.expand_as(Tensor([512, 80, 1, 1241],"float32"), Tensor([512, 80, 28, 1241],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1241],"float32"), Tensor([512, 80, 28, 1241],"float32"), ) 	 1474109440 	 1000 	 4.058029651641846 	 0.006626605987548828 	 4.038617849349976 	 7.62939453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:17:42.186217 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 45],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 45],"float32"), ) 	 51650560 	 1000 	 0.14030027389526367 	 0.0037937164306640625 	 0.12887167930603027 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:17:44.284335 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 89],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 28, 89],"float16"), ) 	 102113280 	 1000 	 0.2704787254333496 	 0.0037665367126464844 	 0.25897884368896484 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:17:48.470143 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 45, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 45, 28],"float32"), ) 	 51650560 	 1000 	 0.1390538215637207 	 0.0037627220153808594 	 0.12766432762145996 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:17:50.442592 test begin: paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 89, 28],"float16"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1, 1],"float32"), Tensor([512, 80, 89, 28],"float16"), ) 	 102113280 	 1000 	 0.27121829986572266 	 0.003769397735595703 	 0.25977325439453125 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:17:54.505744 test begin: paddle.expand_as(Tensor([512, 80, 1241, 1],"float32"), Tensor([512, 80, 1241, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([512, 80, 1241, 1],"float32"), Tensor([512, 80, 1241, 28],"float32"), ) 	 1474109440 	 1000 	 4.318159580230713 	 0.0037293434143066406 	 4.306396007537842 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:19:01.462632 test begin: paddle.expand_as(Tensor([811, 80, 1, 1],"float32"), Tensor([811, 80, 28, 28],"float32"), )
[Prof] paddle.expand_as 	 paddle.expand_as(Tensor([811, 80, 1, 1],"float32"), Tensor([811, 80, 28, 28],"float32"), ) 	 50930800 	 1000 	 0.13876986503601074 	 0.0037088394165039062 	 0.12717127799987793 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:19:03.535018 test begin: paddle.expm1(Tensor([198451, 16, 32],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([198451, 16, 32],"float16"), ) 	 101606912 	 1000 	 0.33481264114379883 	 0.30417799949645996 	 0.3259754180908203 	 0.29311323165893555 	 0.44840097427368164 	 0.7457051277160645 	 0.3945963382720947 	 0.38101649284362793 	 
2025-07-30 20:19:09.182156 test begin: paddle.expm1(Tensor([8, 16, 793801],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([8, 16, 793801],"float16"), ) 	 101606528 	 1000 	 0.3352823257446289 	 0.3056674003601074 	 0.3263278007507324 	 0.29310107231140137 	 0.4483470916748047 	 0.7456583976745605 	 0.3943631649017334 	 0.3809504508972168 	 
2025-07-30 20:19:14.815572 test begin: paddle.expm1(Tensor([8, 396901, 32],"float16"), )
[Prof] paddle.expm1 	 paddle.expm1(Tensor([8, 396901, 32],"float16"), ) 	 101606656 	 1000 	 0.33484840393066406 	 0.30414342880249023 	 0.3259544372558594 	 0.2930126190185547 	 0.4481945037841797 	 0.7457497119903564 	 0.39282679557800293 	 0.38106870651245117 	 
2025-07-30 20:19:20.429903 test begin: paddle.fft.fftn(Tensor([226801, 7, 32],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([226801, 7, 32],"float32"), ) 	 50803424 	 1000 	 11.140221118927002 	 15.96791934967041 	 5.9604644775390625e-05 	 1.8137948513031006 	 19.58119821548462 	 15.481156349182129 	 1.5392911434173584 	 1.9769229888916016 	 
2025-07-30 20:20:24.709330 test begin: paddle.fft.fftn(Tensor([39, 40708, 32],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([39, 40708, 32],"float32"), ) 	 50803584 	 1000 	 9.360980749130249 	 10.526970148086548 	 4.601478576660156e-05 	 1.0767357349395752 	 11.963990926742554 	 10.191397190093994 	 1.0180158615112305 	 1.1582214832305908 	 
2025-07-30 20:21:10.534613 test begin: paddle.fft.fftn(Tensor([39, 7, 186093],"float32"), )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([39, 7, 186093],"float32"), ) 	 50803389 	 1000 	 6.948177337646484 	 6.040706157684326 	 6.246566772460938e-05 	 0.7714033126831055 	 7.5458173751831055 	 5.588201522827148 	 0.7706859111785889 	 0.8165526390075684 	 
2025-07-30 20:21:39.825726 test begin: paddle.fft.fftn(Tensor([7, 32, 481, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([7, 32, 481, 481],"float32"), axes=list[2,3,], ) 	 51824864 	 1000 	 5.9855897426605225 	 4.417255640029907 	 5.936622619628906e-05 	 0.9052648544311523 	 5.516723871231079 	 3.983769178390503 	 0.8054702281951904 	 1.0172934532165527 	 
2025-07-30 20:22:01.779421 test begin: paddle.fft.fftn(Tensor([8, 28, 481, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 28, 481, 481],"float32"), axes=list[2,3,], ) 	 51824864 	 1000 	 5.976552248001099 	 4.42059850692749 	 3.218650817871094e-05 	 0.9046182632446289 	 5.516693353652954 	 3.9861037731170654 	 0.8054201602935791 	 1.0211496353149414 	 
2025-07-30 20:22:23.683368 test begin: paddle.fft.fftn(Tensor([8, 32, 413, 481],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 32, 413, 481],"float32"), axes=list[2,3,], ) 	 50855168 	 1000 	 5.959010601043701 	 4.280789852142334 	 5.1975250244140625e-05 	 0.8773844242095947 	 5.597578287124634 	 3.8501298427581787 	 0.8172998428344727 	 0.9838027954101562 	 
2025-07-30 20:22:45.739640 test begin: paddle.fft.fftn(Tensor([8, 32, 481, 413],"float32"), axes=list[2,3,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(Tensor([8, 32, 481, 413],"float32"), axes=list[2,3,], ) 	 50855168 	 1000 	 5.948618412017822 	 4.264281988143921 	 3.600120544433594e-05 	 0.8733212947845459 	 5.614362478256226 	 3.8329787254333496 	 0.8193635940551758 	 0.9813137054443359 	 
2025-07-30 20:23:07.383312 test begin: paddle.fft.fftn(x=Tensor([50, 133, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 133, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50832600 	 1000 	 6.0161662101745605 	 2.9735238552093506 	 5.555152893066406e-05 	 0.6079766750335693 	 4.37673544883728 	 2.4998838901519775 	 0.6390013694763184 	 0.6391913890838623 	 
2025-07-30 20:23:26.714256 test begin: paddle.fft.fftn(x=Tensor([50, 8, 39, 14, 233],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 39, 14, 233],"float32"), axes=list[-3,-2,-1,], ) 	 50887200 	 1000 	 6.818088054656982 	 3.6889700889587402 	 3.5762786865234375e-05 	 0.7541892528533936 	 6.395822286605835 	 3.231822967529297 	 0.869232177734375 	 0.8260703086853027 	 
2025-07-30 20:23:50.147482 test begin: paddle.fft.fftn(x=Tensor([50, 8, 39, 233, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 39, 233, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50887200 	 1000 	 7.204574823379517 	 4.124319076538086 	 6.127357482910156e-05 	 0.8439054489135742 	 6.521198511123657 	 3.6419076919555664 	 0.9520576000213623 	 0.9310133457183838 	 
2025-07-30 20:24:13.711395 test begin: paddle.fft.fftn(x=Tensor([50, 8, 649, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([50, 8, 649, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50881600 	 1000 	 6.356895208358765 	 3.552910327911377 	 4.506111145019531e-05 	 0.7258973121643066 	 4.957362651824951 	 3.0694973468780518 	 0.7237424850463867 	 0.7839179039001465 	 
2025-07-30 20:24:33.589993 test begin: paddle.fft.fftn(x=Tensor([831, 8, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], )
[Prof] paddle.fft.fftn 	 paddle.fft.fftn(x=Tensor([831, 8, 39, 14, 14],"float32"), axes=list[-3,-2,-1,], ) 	 50817312 	 1000 	 6.01541805267334 	 2.9723849296569824 	 5.602836608886719e-05 	 0.6075944900512695 	 4.375006437301636 	 2.490298271179199 	 0.6387076377868652 	 0.6362051963806152 	 
2025-07-30 20:24:51.408640 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 6, 264601],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 4, 6, 264601],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401696 	 1000 	 3.0009512901306152 	 1.393017053604126 	 2.574920654296875e-05 	 0.3554389476776123 	 2.8615915775299072 	 1.9013442993164062 	 0.365703821182251 	 0.3887476921081543 	 
2025-07-30 20:25:01.555460 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 793801, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 4, 793801, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401632 	 1000 	 2.8418920040130615 	 1.3911786079406738 	 2.1219253540039062e-05 	 0.3553731441497803 	 2.5978455543518066 	 1.9007387161254883 	 0.33182239532470703 	 0.3888087272644043 	 
2025-07-30 20:25:11.184095 test begin: paddle.fft.ifftn(x=Tensor([4, 529201, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([4, 529201, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401648 	 1000 	 0.25103330612182617 	 0.49323558807373047 	 1.8358230590820312e-05 	 0.1258230209350586 	 0.1691882610321045 	 0.7276463508605957 	 0.021599769592285156 	 0.09307026863098145 	 
2025-07-30 20:25:13.365174 test begin: paddle.fft.ifftn(x=Tensor([529201, 4, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Prof] paddle.fft.ifftn 	 paddle.fft.ifftn(x=Tensor([529201, 4, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), ) 	 25401648 	 1000 	 0.23970675468444824 	 0.4932694435119629 	 1.5020370483398438e-05 	 0.1258544921875 	 0.16881442070007324 	 0.2803487777709961 	 0.021527767181396484 	 0.05639338493347168 	 
2025-07-30 20:25:15.086742 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), ) 	 25401618 	 1000 	 1.8631510734558105 	 0.7593963146209717 	 0.3808474540710449 	 0.38788414001464844 	 3.4385056495666504 	 2.6258137226104736 	 0.5856373310089111 	 0.5366988182067871 	 
2025-07-30 20:25:24.829290 test begin: paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 1411201, 3, 3],"float64"), n=2, ) 	 25401618 	 1000 	 1.9735181331634521 	 0.763923168182373 	 0.336287260055542 	 0.39024972915649414 	 2.8830902576446533 	 1.8305227756500244 	 0.36812591552734375 	 0.3741295337677002 	 
2025-07-30 20:25:34.767966 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), ) 	 25401624 	 1000 	 1.8634603023529053 	 0.7770965099334717 	 0.3809521198272705 	 0.3880155086517334 	 3.4387454986572266 	 2.6264994144439697 	 0.5855822563171387 	 0.5369434356689453 	 
2025-07-30 20:25:46.919072 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, ) 	 25401624 	 1000 	 1.9734888076782227 	 0.763808012008667 	 0.33628273010253906 	 0.39013195037841797 	 2.8831849098205566 	 1.8304052352905273 	 0.3681309223175049 	 0.3739478588104248 	 
2025-07-30 20:25:55.457060 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 1058401, 3],"float64"), n=2, axis=1, ) 	 25401624 	 1000 	 1.7393381595611572 	 0.6927788257598877 	 0.2963988780975342 	 0.23606109619140625 	 2.477067232131958 	 1.7013702392578125 	 0.3160741329193115 	 0.28964781761169434 	 
2025-07-30 20:26:02.986618 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 6.977402925491333 	 6.1068902015686035 	 0.5094337463378906 	 0.5674662590026855 	 13.041615962982178 	 11.806406736373901 	 1.0255372524261475 	 1.0052800178527832 	 
2025-07-30 20:26:41.985802 test begin: paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([2, 4, 3, 1058401],"float64"), n=2, axis=1, ) 	 25401624 	 1000 	 1.8574771881103516 	 0.7000117301940918 	 0.31677985191345215 	 0.23600459098815918 	 2.4616847038269043 	 1.7014966011047363 	 0.3145449161529541 	 0.28980231285095215 	 
2025-07-30 20:26:50.420084 test begin: paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 14112, 3, 3],"float64"), n=2, axis=1, ) 	 25528608 	 1000 	 0.07395672798156738 	 0.05065011978149414 	 2.86102294921875e-05 	 5.5789947509765625e-05 	 0.1744680404663086 	 0.2059485912322998 	 0.02232217788696289 	 0.00011777877807617188 	 
2025-07-30 20:26:51.437096 test begin: paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([201, 4, 3, 10584],"float64"), n=2, ) 	 25528608 	 1000 	 0.07405614852905273 	 0.03943300247192383 	 1.3828277587890625e-05 	 4.1961669921875e-05 	 0.1742079257965088 	 0.15926265716552734 	 0.022264957427978516 	 0.00011968612670898438 	 
2025-07-30 20:26:52.421888 test begin: paddle.fft.ihfft(x=Tensor([705601, 4, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft 	 paddle.fft.ihfft(x=Tensor([705601, 4, 3, 3],"float64"), ) 	 25401636 	 1000 	 1.8623082637786865 	 0.7593772411346436 	 0.38071465492248535 	 0.3879666328430176 	 3.437786102294922 	 2.6260125637054443 	 0.5851325988769531 	 0.5358381271362305 	 
2025-07-30 20:27:02.168956 test begin: paddle.fft.ihfft2(x=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([1270081, 4, 5],"float64"), ) 	 25401620 	 1000 	 2.0952389240264893 	 2.1304781436920166 	 0.3569512367248535 	 0.3628993034362793 	 3.996738910675049 	 3.516660213470459 	 0.583507776260376 	 0.4495105743408203 	 
2025-07-30 20:27:14.943448 test begin: paddle.fft.ihfft2(x=Tensor([2822401, 3, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([2822401, 3, 3],"float64"), s=tuple(1,2,), ) 	 25401609 	 1000 	 0.7740247249603271 	 0.6312837600708008 	 0.13182306289672852 	 0.1612405776977539 	 1.1474320888519287 	 1.1613438129425049 	 0.14659571647644043 	 0.14830803871154785 	 
2025-07-30 20:27:19.358429 test begin: paddle.fft.ihfft2(x=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([3, 1693441, 5],"float64"), ) 	 25401615 	 1000 	 8.844837188720703 	 7.386446952819824 	 0.6956193447113037 	 0.6864938735961914 	 15.542419195175171 	 8.784012079238892 	 1.1344120502471924 	 0.689518928527832 	 
2025-07-30 20:28:01.205497 test begin: paddle.fft.ihfft2(x=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([3, 4, 2116801],"float64"), ) 	 25401612 	 1000 	 9.109708547592163 	 7.31592059135437 	 0.6201088428497314 	 0.49797630310058594 	 13.641670942306519 	 13.136375188827515 	 0.9959981441497803 	 0.895085334777832 	 
2025-07-30 20:28:45.493588 test begin: paddle.fft.ihfft2(x=Tensor([4, 2116801, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 2116801, 3],"float64"), s=tuple(1,2,), ) 	 25401612 	 1000 	 0.09718728065490723 	 0.06281375885009766 	 1.5974044799804688e-05 	 4.744529724121094e-05 	 0.16757440567016602 	 0.19905400276184082 	 0.021392345428466797 	 0.0001125335693359375 	 
2025-07-30 20:28:46.587661 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 3, 705601],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 3, 705601],"float64"), ) 	 25401636 	 1000 	 7.284888982772827 	 7.306501865386963 	 0.49596452713012695 	 0.49737071990966797 	 13.62149977684021 	 12.744515180587769 	 0.9943056106567383 	 0.8684389591217041 	 
2025-07-30 20:29:28.595549 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 705601, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 3, 705601, 3],"float64"), ) 	 25401636 	 1000 	 9.466193914413452 	 8.99451994895935 	 0.7445907592773438 	 0.7079980373382568 	 15.112580299377441 	 10.492543935775757 	 1.1030831336975098 	 0.7147092819213867 	 
2025-07-30 20:30:16.099360 test begin: paddle.fft.ihfft2(x=Tensor([4, 705601, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([4, 705601, 3, 3],"float64"), ) 	 25401636 	 1000 	 2.269217014312744 	 2.3791627883911133 	 0.38652968406677246 	 0.40534090995788574 	 4.045547008514404 	 3.85803484916687 	 0.5906586647033691 	 0.493058443069458 	 
2025-07-30 20:30:29.718137 test begin: paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([401, 21168, 3],"float64"), s=tuple(1,2,), ) 	 25465104 	 1000 	 0.0996091365814209 	 0.06302356719970703 	 2.574920654296875e-05 	 5.555152893066406e-05 	 0.1694808006286621 	 0.203446626663208 	 0.021625995635986328 	 0.00011396408081054688 	 
2025-07-30 20:30:30.789760 test begin: paddle.fft.ihfft2(x=Tensor([940801, 3, 3, 3],"float64"), )
[Prof] paddle.fft.ihfft2 	 paddle.fft.ihfft2(x=Tensor([940801, 3, 3, 3],"float64"), ) 	 25401627 	 1000 	 2.2703068256378174 	 2.3913087844848633 	 0.38672900199890137 	 0.4054715633392334 	 4.045724868774414 	 3.855482816696167 	 0.5904898643493652 	 0.4926280975341797 	 
2025-07-30 20:30:46.748971 test begin: paddle.fft.ihfftn(Tensor([1270081, 4, 5],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([1270081, 4, 5],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401620 	 1000 	 2.095245361328125 	 2.1326003074645996 	 0.3569223880767822 	 0.36284923553466797 	 3.9962093830108643 	 3.515951156616211 	 0.5832669734954834 	 0.44921326637268066 	 
2025-07-30 20:30:59.577936 test begin: paddle.fft.ihfftn(Tensor([3, 1693441, 5],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([3, 1693441, 5],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401615 	 1000 	 8.848488807678223 	 7.378640651702881 	 0.6955451965332031 	 0.6858956813812256 	 15.542968511581421 	 8.77505874633789 	 1.1345806121826172 	 0.6889479160308838 	 
2025-07-30 20:31:41.869197 test begin: paddle.fft.ihfftn(Tensor([3, 4, 2116801],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([3, 4, 2116801],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401612 	 1000 	 9.109081268310547 	 7.317285060882568 	 0.6199920177459717 	 0.49814915657043457 	 13.643420934677124 	 13.137202978134155 	 0.996009349822998 	 0.8951363563537598 	 
2025-07-30 20:32:26.209855 test begin: paddle.fft.ihfftn(Tensor([4, 3, 3, 705601],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 3, 3, 705601],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 7.28603196144104 	 7.30626916885376 	 0.4960594177246094 	 0.4974207878112793 	 13.620019912719727 	 12.744580507278442 	 0.9943797588348389 	 0.8684322834014893 	 
2025-07-30 20:33:08.306706 test begin: paddle.fft.ihfftn(Tensor([4, 3, 705601, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 3, 705601, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 9.466245889663696 	 8.994384765625 	 0.7444953918457031 	 0.7080678939819336 	 15.112804174423218 	 10.492545127868652 	 1.1032600402832031 	 0.71470046043396 	 
2025-07-30 20:33:53.533694 test begin: paddle.fft.ihfftn(Tensor([4, 705601, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([4, 705601, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401636 	 1000 	 2.269204616546631 	 2.379075050354004 	 0.38666820526123047 	 0.40530824661254883 	 4.045636177062988 	 3.856907606124878 	 0.5905358791351318 	 0.49285054206848145 	 
2025-07-30 20:34:07.166926 test begin: paddle.fft.ihfftn(Tensor([940801, 3, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(Tensor([940801, 3, 3, 3],"float64"), None, tuple(-2,-1,), "backward", None, ) 	 25401627 	 1000 	 2.270087480545044 	 2.380329132080078 	 0.38677453994750977 	 0.405346155166626 	 4.045926094055176 	 3.8546974658966064 	 0.5907375812530518 	 0.49278879165649414 	 
2025-07-30 20:34:20.786626 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 1058401, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 3, 1058401, 2],"float64"), ) 	 25401624 	 1000 	 15.225941896438599 	 14.115952014923096 	 0.9147813320159912 	 1.0303940773010254 	 18.418210744857788 	 14.266440391540527 	 1.046468734741211 	 1.0414471626281738 	 
2025-07-30 20:35:24.297978 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 5, 423361],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 3, 5, 423361],"float64"), ) 	 25401660 	 1000 	 7.300374269485474 	 6.408917665481567 	 0.4386439323425293 	 0.4671602249145508 	 15.377270460128784 	 10.89124321937561 	 0.9829387664794922 	 0.7949552536010742 	 
2025-07-30 20:36:06.645172 test begin: paddle.fft.ihfftn(x=Tensor([4, 635041, 5, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([4, 635041, 5, 2],"float64"), ) 	 25401640 	 1000 	 16.846577644348145 	 15.652685165405273 	 1.0119924545288086 	 1.1426615715026855 	 19.995271682739258 	 15.79187297821045 	 1.1360445022583008 	 1.1528069972991943 	 
2025-07-30 20:37:16.393568 test begin: paddle.fft.ihfftn(x=Tensor([846721, 3, 5, 2],"float64"), )
[Prof] paddle.fft.ihfftn 	 paddle.fft.ihfftn(x=Tensor([846721, 3, 5, 2],"float64"), ) 	 25401630 	 1000 	 19.01684808731079 	 15.566094398498535 	 1.215569019317627 	 1.3242805004119873 	 17.16589903831482 	 15.697623014450073 	 0.9759905338287354 	 1.335493803024292 	 
2025-07-30 20:38:26.124800 test begin: paddle.fft.rfft(Tensor([20, 1210, 2101],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 1210, 2101],"float32"), ) 	 50844200 	 1000 	 2.601313591003418 	 2.0060598850250244 	 0.5312933921813965 	 0.6835765838623047 	 4.896900177001953 	 3.3689839839935303 	 0.9999759197235107 	 1.1484169960021973 	 
2025-07-30 20:38:40.852115 test begin: paddle.fft.rfft(Tensor([20, 1270, 2001],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 1270, 2001],"float32"), ) 	 50825400 	 1000 	 1.9772424697875977 	 1.3277490139007568 	 0.4039754867553711 	 0.45236706733703613 	 3.679246425628662 	 2.0154662132263184 	 0.7515578269958496 	 0.6870169639587402 	 
2025-07-30 20:38:51.202902 test begin: paddle.fft.rfft(Tensor([20, 64, 39691],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([20, 64, 39691],"float32"), ) 	 50804480 	 1000 	 4.7311766147613525 	 4.113602876663208 	 0.4831535816192627 	 0.5256175994873047 	 9.089263677597046 	 7.509681463241577 	 0.9282526969909668 	 0.9603595733642578 	 
2025-07-30 20:39:18.126659 test begin: paddle.fft.rfft(Tensor([378, 64, 2101],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([378, 64, 2101],"float32"), ) 	 50827392 	 1000 	 2.6010420322418213 	 2.0049242973327637 	 0.5312395095825195 	 0.6833100318908691 	 4.877038478851318 	 3.3678834438323975 	 0.9958758354187012 	 1.1481115818023682 	 
2025-07-30 20:39:32.444425 test begin: paddle.fft.rfft(Tensor([397, 64, 2001],"float32"), )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([397, 64, 2001],"float32"), ) 	 50841408 	 1000 	 1.9800467491149902 	 1.331857442855835 	 0.40453124046325684 	 0.45270371437072754 	 3.6576194763183594 	 2.016119956970215 	 0.7459449768066406 	 0.687145471572876 	 
2025-07-30 20:39:44.348598 test begin: paddle.fft.rfft(Tensor([4, 32, 32, 12404],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 32, 32, 12404],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 4.891095876693726 	 4.321060657501221 	 0.49947166442871094 	 0.5518743991851807 	 10.121755599975586 	 8.735575914382935 	 0.9406969547271729 	 0.9930450916290283 	 
2025-07-30 20:40:14.000197 test begin: paddle.fft.rfft(Tensor([4, 32, 6202, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 32, 6202, 64],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 1.2776093482971191 	 0.6260678768157959 	 0.32634496688842773 	 0.31982946395874023 	 3.5095014572143555 	 1.8379719257354736 	 0.59765625 	 0.46976518630981445 	 
2025-07-30 20:40:22.699585 test begin: paddle.fft.rfft(Tensor([4, 6202, 32, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([4, 6202, 32, 64],"float32"), axis=-1, norm="forward", ) 	 50806784 	 1000 	 1.2777340412139893 	 0.6261718273162842 	 0.32641077041625977 	 0.3198666572570801 	 3.509530782699585 	 1.8380396366119385 	 0.5976839065551758 	 0.4698481559753418 	 
2025-07-30 20:40:31.302528 test begin: paddle.fft.rfft(Tensor([776, 32, 32, 64],"float32"), axis=-1, norm="forward", )
[Prof] paddle.fft.rfft 	 paddle.fft.rfft(Tensor([776, 32, 32, 64],"float32"), axis=-1, norm="forward", ) 	 50855936 	 1000 	 1.2794287204742432 	 0.6285135746002197 	 0.32681775093078613 	 0.3200826644897461 	 3.5126125812530518 	 1.839568853378296 	 0.59814453125 	 0.47040700912475586 	 
2025-07-30 20:40:40.374153 test begin: paddle.fft.rfft2(Tensor([26, 32, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([26, 32, 250, 250],"float32"), ) 	 52000000 	 1000 	 1.4789879322052002 	 0.8231136798858643 	 0.3777627944946289 	 0.4216148853302002 	 3.5957260131835938 	 1.9189033508300781 	 0.6123087406158447 	 0.49054694175720215 	 
2025-07-30 20:40:49.588267 test begin: paddle.fft.rfft2(Tensor([32, 26, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 26, 250, 250],"float32"), ) 	 52000000 	 1000 	 1.4782073497772217 	 0.8226721286773682 	 0.37755608558654785 	 0.42167210578918457 	 3.5956835746765137 	 1.9188144207000732 	 0.6123740673065186 	 0.49056005477905273 	 
2025-07-30 20:40:58.835569 test begin: paddle.fft.rfft2(Tensor([32, 32, 199, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 32, 199, 250],"float32"), ) 	 50944000 	 1000 	 2.6933484077453613 	 1.5022799968719482 	 0.6886844635009766 	 0.7595279216766357 	 6.094407320022583 	 3.248626232147217 	 1.1549642086029053 	 0.8309946060180664 	 
2025-07-30 20:41:16.924626 test begin: paddle.fft.rfft2(Tensor([32, 32, 250, 199],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([32, 32, 250, 199],"float32"), ) 	 50944000 	 1000 	 2.736125946044922 	 1.6368420124053955 	 0.46579957008361816 	 0.4178812503814697 	 5.233366966247559 	 2.6969377994537354 	 0.8906974792480469 	 0.6898074150085449 	 
2025-07-30 20:41:30.622560 test begin: paddle.fft.rfft2(Tensor([8, 102, 250, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 102, 250, 250],"float32"), ) 	 51000000 	 1000 	 1.4485652446746826 	 0.8143603801727295 	 0.3699319362640381 	 0.4158322811126709 	 3.527925729751587 	 1.8861439228057861 	 0.6007716655731201 	 0.4821796417236328 	 
2025-07-30 20:41:42.119525 test begin: paddle.fft.rfft2(Tensor([8, 32, 250, 794],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 32, 250, 794],"float32"), ) 	 50816000 	 1000 	 2.1050946712493896 	 1.4639759063720703 	 0.43003177642822266 	 0.49829792976379395 	 4.3848793506622314 	 2.730625867843628 	 0.7464501857757568 	 0.6985082626342773 	 
2025-07-30 20:41:54.264403 test begin: paddle.fft.rfft2(Tensor([8, 32, 794, 250],"float32"), )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(Tensor([8, 32, 794, 250],"float32"), ) 	 50816000 	 1000 	 2.3197853565216064 	 1.6250860691070557 	 0.5930256843566895 	 0.8303208351135254 	 5.242687225341797 	 3.5075578689575195 	 0.8923563957214355 	 0.8972597122192383 	 
2025-07-30 20:42:08.383548 test begin: paddle.fft.rfft2(x=Tensor([32, 15, 15, 7057],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 15, 15, 7057],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50810400 	 1000 	 1.6004576683044434 	 1.5863275527954102 	 0.3271336555480957 	 0.4051949977874756 	 3.9260830879211426 	 3.0461819171905518 	 0.6684486865997314 	 0.6230180263519287 	 
2025-07-30 20:42:20.120110 test begin: paddle.fft.rfft2(x=Tensor([32, 15, 414, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 15, 414, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50872320 	 1000 	 2.3208444118499756 	 1.8442275524139404 	 0.33879947662353516 	 0.3768131732940674 	 4.266670227050781 	 3.1259853839874268 	 0.6228418350219727 	 0.5325779914855957 	 
2025-07-30 20:42:33.345330 test begin: paddle.fft.rfft2(x=Tensor([32, 414, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([32, 414, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50872320 	 1000 	 1.6709723472595215 	 1.6706538200378418 	 0.3414802551269531 	 0.42670488357543945 	 4.2998433113098145 	 3.4317476749420166 	 0.6272776126861572 	 0.584491491317749 	 
2025-07-30 20:42:47.116438 test begin: paddle.fft.rfft2(x=Tensor([883, 15, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", )
[Prof] paddle.fft.rfft2 	 paddle.fft.rfft2(x=Tensor([883, 15, 15, 256],"float32"), axes=tuple(1,2,), norm="ortho", ) 	 50860800 	 1000 	 1.5668156147003174 	 1.5648751258850098 	 0.3202824592590332 	 0.3994872570037842 	 3.8941292762756348 	 3.022042989730835 	 0.6625525951385498 	 0.6181490421295166 	 
2025-07-30 20:42:58.637426 test begin: paddle.fft.rfftn(Tensor([26, 32, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([26, 32, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 52000000 	 1000 	 1.4782114028930664 	 0.8275167942047119 	 0.377521276473999 	 0.4223823547363281 	 3.595569133758545 	 1.9189867973327637 	 0.6122500896453857 	 0.490506649017334 	 
2025-07-30 20:43:07.846211 test begin: paddle.fft.rfftn(Tensor([32, 15, 15, 7057],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 15, 15, 7057],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50810400 	 1000 	 1.600325584411621 	 1.5866315364837646 	 0.3270730972290039 	 0.40523672103881836 	 3.926928997039795 	 3.045754909515381 	 0.668609619140625 	 0.6230051517486572 	 
2025-07-30 20:43:19.448951 test begin: paddle.fft.rfftn(Tensor([32, 15, 414, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 15, 414, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50872320 	 1000 	 2.3203039169311523 	 1.8481547832489014 	 0.3388247489929199 	 0.37691187858581543 	 4.266917943954468 	 3.1261050701141357 	 0.6230459213256836 	 0.5326991081237793 	 
2025-07-30 20:43:34.088573 test begin: paddle.fft.rfftn(Tensor([32, 26, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 26, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 52000000 	 1000 	 1.4781053066253662 	 0.828387975692749 	 0.37755393981933594 	 0.4248819351196289 	 3.5983481407165527 	 1.9188117980957031 	 0.6123590469360352 	 0.4905517101287842 	 
2025-07-30 20:43:43.855383 test begin: paddle.fft.rfftn(Tensor([32, 32, 199, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 32, 199, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50944000 	 1000 	 2.691605806350708 	 1.4924237728118896 	 0.6882185935974121 	 0.7638413906097412 	 5.948998928070068 	 3.249812602996826 	 1.0122640132904053 	 0.8312616348266602 	 
2025-07-30 20:43:58.651273 test begin: paddle.fft.rfftn(Tensor([32, 32, 250, 199],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 32, 250, 199],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50944000 	 1000 	 2.7355387210845947 	 1.6379337310791016 	 0.4656362533569336 	 0.4179074764251709 	 5.230272531509399 	 2.696748733520508 	 0.8900933265686035 	 0.6897077560424805 	 
2025-07-30 20:44:12.450270 test begin: paddle.fft.rfftn(Tensor([32, 414, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([32, 414, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50872320 	 1000 	 1.6708831787109375 	 1.6702189445495605 	 0.3415250778198242 	 0.4266345500946045 	 4.297423839569092 	 3.4309067726135254 	 0.6274819374084473 	 0.5844264030456543 	 
2025-07-30 20:44:24.968403 test begin: paddle.fft.rfftn(Tensor([8, 102, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 102, 250, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 51000000 	 1000 	 1.4482040405273438 	 0.8256380558013916 	 0.3698263168334961 	 0.4131937026977539 	 3.527529001235962 	 1.886509895324707 	 0.6007611751556396 	 0.48217153549194336 	 
2025-07-30 20:44:38.233995 test begin: paddle.fft.rfftn(Tensor([8, 32, 250, 794],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 32, 250, 794],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50816000 	 1000 	 2.1048121452331543 	 1.4640426635742188 	 0.42998647689819336 	 0.4983336925506592 	 4.385072231292725 	 2.730860471725464 	 0.746467113494873 	 0.6985588073730469 	 
2025-07-30 20:44:50.329436 test begin: paddle.fft.rfftn(Tensor([8, 32, 794, 250],"float32"), None, tuple(-2,-1,), "backward", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([8, 32, 794, 250],"float32"), None, tuple(-2,-1,), "backward", None, ) 	 50816000 	 1000 	 2.320383310317993 	 1.6251718997955322 	 0.593092679977417 	 0.8303611278533936 	 5.242861032485962 	 3.507539987564087 	 0.8922789096832275 	 0.8971905708312988 	 
2025-07-30 20:45:04.514554 test begin: paddle.fft.rfftn(Tensor([883, 15, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, )
[Prof] paddle.fft.rfftn 	 paddle.fft.rfftn(Tensor([883, 15, 15, 256],"float32"), None, tuple(1,2,), "ortho", None, ) 	 50860800 	 1000 	 1.5668528079986572 	 1.5645744800567627 	 0.3202354907989502 	 0.3999471664428711 	 3.8922195434570312 	 3.0223615169525146 	 0.6626522541046143 	 0.61818528175354 	 
2025-07-30 20:45:15.986104 test begin: paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40510, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 508157440 	 1000 	 0.00593113899230957 	 0.004233360290527344 	 1.2874603271484375e-05 	 2.1696090698242188e-05 	 0.042603492736816406 	 0.056817054748535156 	 4.744529724121094e-05 	 6.29425048828125e-05 	 
2025-07-30 20:45:32.279536 test begin: paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 254, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 509788160 	 1000 	 0.005922794342041016 	 0.004258632659912109 	 1.2636184692382812e-05 	 2.0265579223632812e-05 	 0.04263591766357422 	 0.05626678466796875 	 4.3392181396484375e-05 	 4.673004150390625e-05 	 
2025-07-30 20:45:52.103140 test begin: paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([40960, 256, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 	 513802240 	 1000 	 0.0058290958404541016 	 0.004232883453369141 	 1.1682510375976562e-05 	 1.8835067749023438e-05 	 0.0425114631652832 	 0.05608010292053223 	 5.269050598144531e-05 	 5.364418029785156e-05 	 
2025-07-30 20:46:08.582594 test begin: paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 10, 256],"float32"), start_axis=2, ) 	 532480000 	 1000 	 0.005839824676513672 	 0.005380153656005859 	 1.33514404296875e-05 	 2.6226043701171875e-05 	 0.04244637489318848 	 0.05759406089782715 	 3.743171691894531e-05 	 6.365776062011719e-05 	 
2025-07-30 20:46:26.118748 test begin: paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 50, 7, 349],"float32"), start_axis=2, ) 	 508144000 	 1000 	 0.005560874938964844 	 0.004156827926635742 	 1.4543533325195312e-05 	 1.8835067749023438e-05 	 0.04229426383972168 	 0.056552886962890625 	 4.00543212890625e-05 	 4.00543212890625e-05 	 
2025-07-30 20:46:42.407460 test begin: paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([4160, 69, 7, 256],"float32"), start_axis=2, ) 	 514375680 	 1000 	 0.005662202835083008 	 0.0040781497955322266 	 1.2159347534179688e-05 	 1.8596649169921875e-05 	 0.04316234588623047 	 0.05656743049621582 	 2.5033950805664062e-05 	 3.552436828613281e-05 	 
2025-07-30 20:46:59.183051 test begin: paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 7, 284],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.005623340606689453 	 0.004174470901489258 	 1.0967254638671875e-05 	 1.8835067749023438e-05 	 0.0424656867980957 	 0.05647587776184082 	 3.9577484130859375e-05 	 4.7206878662109375e-05 	 
2025-07-30 20:47:15.734460 test begin: paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 50, 8, 256],"float32"), start_axis=2, ) 	 524288000 	 1000 	 0.005698680877685547 	 0.0041158199310302734 	 1.4781951904296875e-05 	 1.7881393432617188e-05 	 0.04256916046142578 	 0.05666017532348633 	 4.315376281738281e-05 	 5.7697296142578125e-05 	 
2025-07-30 20:47:32.836984 test begin: paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5120, 56, 7, 256],"float32"), start_axis=2, ) 	 513802240 	 1000 	 0.00555109977722168 	 0.004366874694824219 	 7.62939453125e-06 	 3.981590270996094e-05 	 0.04218173027038574 	 0.05942058563232422 	 3.266334533691406e-05 	 7.510185241699219e-05 	 
2025-07-30 20:47:49.568703 test begin: paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, )
[Prof] paddle.flatten 	 paddle.flatten(Tensor([5680, 50, 7, 256],"float32"), start_axis=2, ) 	 508928000 	 1000 	 0.010579347610473633 	 0.0041599273681640625 	 1.2636184692382812e-05 	 1.7881393432617188e-05 	 0.04494833946228027 	 0.05693411827087402 	 4.291534423828125e-05 	 5.054473876953125e-05 	 
2025-07-30 20:48:06.175139 test begin: paddle.flip(Tensor([127, 8, 224, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([127, 8, 224, 224],"float32"), axis=list[3,], ) 	 50978816 	 1000 	 0.964879035949707 	 0.31319570541381836 	 0.9555859565734863 	 0.29849934577941895 	 0.9647016525268555 	 0.31316113471984863 	 0.913461446762085 	 0.24022841453552246 	 
2025-07-30 20:48:10.450087 test begin: paddle.flip(Tensor([1351, 3, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([1351, 3, 112, 112],"float32"), axis=-1, ) 	 50840832 	 1000 	 0.9648199081420898 	 0.3125016689300537 	 0.9485127925872803 	 0.29819774627685547 	 0.9652087688446045 	 0.3122572898864746 	 0.9053184986114502 	 0.23898100852966309 	 
2025-07-30 20:48:14.680970 test begin: paddle.flip(Tensor([3, 338, 224, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 338, 224, 224],"float32"), axis=list[3,], ) 	 50878464 	 1000 	 0.9630823135375977 	 0.3126199245452881 	 0.9536349773406982 	 0.29788732528686523 	 0.9626200199127197 	 0.31254029273986816 	 0.9113967418670654 	 0.23980140686035156 	 
2025-07-30 20:48:18.948536 test begin: paddle.flip(Tensor([3, 8, 224, 9451],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 8, 224, 9451],"float32"), axis=list[3,], ) 	 50808576 	 1000 	 0.9618587493896484 	 0.3125770092010498 	 0.9524953365325928 	 0.2983360290527344 	 0.9614183902740479 	 0.31235527992248535 	 0.9103646278381348 	 0.21933865547180176 	 
2025-07-30 20:48:23.155518 test begin: paddle.flip(Tensor([3, 8, 9451, 224],"float32"), axis=list[3,], )
[Prof] paddle.flip 	 paddle.flip(Tensor([3, 8, 9451, 224],"float32"), axis=list[3,], ) 	 50808576 	 1000 	 0.961219072341919 	 0.312152624130249 	 0.9517931938171387 	 0.2978193759918213 	 0.9613420963287354 	 0.31195497512817383 	 0.9053709506988525 	 0.24348163604736328 	 
2025-07-30 20:48:27.365802 test begin: paddle.flip(Tensor([52, 3, 112, 2908],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 3, 112, 2908],"float32"), axis=-1, ) 	 50808576 	 1000 	 0.9622056484222412 	 0.31383442878723145 	 0.9519357681274414 	 0.2979736328125 	 0.9616587162017822 	 0.3123338222503662 	 0.9085407257080078 	 0.2434847354888916 	 
2025-07-30 20:48:31.576203 test begin: paddle.flip(Tensor([52, 3, 2908, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 3, 2908, 112],"float32"), axis=-1, ) 	 50808576 	 1000 	 0.964301586151123 	 0.31501197814941406 	 0.9549534320831299 	 0.29798197746276855 	 0.964214563369751 	 0.31200480461120605 	 0.9101982116699219 	 0.24344301223754883 	 
2025-07-30 20:48:37.360560 test begin: paddle.flip(Tensor([52, 78, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([52, 78, 112, 112],"float32"), axis=-1, ) 	 50878464 	 1000 	 0.9660677909851074 	 0.3144974708557129 	 0.9566860198974609 	 0.29807257652282715 	 0.9657130241394043 	 0.3129148483276367 	 0.9081215858459473 	 0.2426300048828125 	 
2025-07-30 20:48:41.644854 test begin: paddle.flip(Tensor([64, 3, 112, 2363],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 3, 112, 2363],"float32"), axis=-1, ) 	 50813952 	 1000 	 0.9619696140289307 	 0.3125486373901367 	 0.9527809619903564 	 0.29814672470092773 	 0.961740255355835 	 0.3123929500579834 	 0.9101047515869141 	 0.2429189682006836 	 
2025-07-30 20:48:45.954526 test begin: paddle.flip(Tensor([64, 3, 2363, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 3, 2363, 112],"float32"), axis=-1, ) 	 50813952 	 1000 	 0.9646308422088623 	 0.31229305267333984 	 0.9553470611572266 	 0.29807567596435547 	 0.9644331932067871 	 0.3120296001434326 	 0.9134111404418945 	 0.2420363426208496 	 
2025-07-30 20:48:50.194428 test begin: paddle.flip(Tensor([64, 64, 112, 112],"float32"), axis=-1, )
[Prof] paddle.flip 	 paddle.flip(Tensor([64, 64, 112, 112],"float32"), axis=-1, ) 	 51380224 	 1000 	 0.9755690097808838 	 0.3185887336730957 	 0.9663276672363281 	 0.30131006240844727 	 0.9752328395843506 	 0.31584668159484863 	 0.9233496189117432 	 0.24579644203186035 	 
2025-07-30 20:48:54.493957 test begin: paddle.floor(Tensor([100000, 170, 3],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([100000, 170, 3],"float32"), ) 	 51000000 	 1000 	 0.29698824882507324 	 0.30739307403564453 	 0.28769516944885254 	 0.2875709533691406 	 0.13455867767333984 	 0.13479852676391602 	 0.08271002769470215 	 0.06651806831359863 	 
2025-07-30 20:48:59.620934 test begin: paddle.floor(Tensor([100000, 2, 255],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([100000, 2, 255],"float32"), ) 	 51000000 	 1000 	 0.29702210426330566 	 0.29910945892333984 	 0.2809772491455078 	 0.2814173698425293 	 0.13462352752685547 	 0.1347520351409912 	 0.07404541969299316 	 0.06060171127319336 	 
2025-07-30 20:49:02.219024 test begin: paddle.floor(Tensor([322, 157920],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([322, 157920],"float32"), ) 	 50850240 	 1000 	 0.29593539237976074 	 0.2982180118560791 	 0.2867109775543213 	 0.28727126121520996 	 0.13421106338500977 	 0.13433170318603516 	 0.08161425590515137 	 0.06688261032104492 	 
2025-07-30 20:49:04.769215 test begin: paddle.floor(Tensor([4, 12700801],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([4, 12700801],"float32"), ) 	 50803204 	 1000 	 0.29592394828796387 	 0.29795289039611816 	 0.28681111335754395 	 0.286884069442749 	 0.1341381072998047 	 0.13428759574890137 	 0.08170199394226074 	 0.0665903091430664 	 
2025-07-30 20:49:07.317004 test begin: paddle.floor(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.floor 	 paddle.floor(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.29595088958740234 	 0.29790353775024414 	 0.28679347038269043 	 0.286510705947876 	 0.1341838836669922 	 0.13436341285705566 	 0.08240795135498047 	 0.060643911361694336 	 
2025-07-30 20:49:09.815960 test begin: paddle.floor(x=Tensor([100, 352, 38, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 352, 38, 38],"float32"), ) 	 50828800 	 1000 	 0.2959566116333008 	 0.2993438243865967 	 0.2866225242614746 	 0.2869586944580078 	 0.13417577743530273 	 0.13433408737182617 	 0.08234167098999023 	 0.06396365165710449 	 
2025-07-30 20:49:12.388699 test begin: paddle.floor(x=Tensor([100, 4, 3343, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 4, 3343, 38],"float32"), ) 	 50813600 	 1000 	 0.29573512077331543 	 0.31497740745544434 	 0.2861940860748291 	 0.28055405616760254 	 0.13411235809326172 	 0.1343860626220703 	 0.06831550598144531 	 0.05902981758117676 	 
2025-07-30 20:49:14.940923 test begin: paddle.floor(x=Tensor([100, 4, 38, 3343],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([100, 4, 38, 3343],"float32"), ) 	 50813600 	 1000 	 0.295743465423584 	 0.2980160713195801 	 0.28644514083862305 	 0.286801815032959 	 0.13416171073913574 	 0.13426661491394043 	 0.08227992057800293 	 0.06560373306274414 	 
2025-07-30 20:49:17.453695 test begin: paddle.floor(x=Tensor([8796, 4, 38, 38],"float32"), )
[Prof] paddle.floor 	 paddle.floor(x=Tensor([8796, 4, 38, 38],"float32"), ) 	 50805696 	 1000 	 0.295651912689209 	 0.2979240417480469 	 0.2862734794616699 	 0.2865896224975586 	 0.13416433334350586 	 0.1343529224395752 	 0.08168482780456543 	 0.06538009643554688 	 
2025-07-30 20:49:19.978370 test begin: paddle.floor_divide(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.42673492431640625 	 0.49243879318237305 	 0.4164590835571289 	 0.47867465019226074 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:21.789362 test begin: paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.4252183437347412 	 0.4951140880584717 	 0.4152548313140869 	 0.47813987731933594 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:23.540478 test begin: paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.45210838317871094 	 0.45537257194519043 	 0.4428575038909912 	 0.4426288604736328 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:26.090138 test begin: paddle.floor_divide(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4478433132171631 	 0.44791269302368164 	 0.4388902187347412 	 0.43504834175109863 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:27.809021 test begin: paddle.floor_divide(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.4520711898803711 	 0.45662927627563477 	 0.4427642822265625 	 0.44217419624328613 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:30.365095 test begin: paddle.floor_divide(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.44767284393310547 	 0.44799184799194336 	 0.4386250972747803 	 0.4338951110839844 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:32.147568 test begin: paddle.floor_divide(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.floor_divide 	 paddle.floor_divide(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.452146053314209 	 0.4553506374359131 	 0.44280457496643066 	 0.4424171447753906 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:34.742782 test begin: paddle.fmax(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 558835211 	 1000 	 4.444021224975586 	 4.406079053878784 	 4.433163166046143 	 4.393263816833496 	 45.20996046066284 	 27.185792446136475 	 45.150622844696045 	 1.9845211505889893 	 
2025-07-30 20:51:16.459748 test begin: paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.45015740394592285 	 0.45093345642089844 	 0.4404895305633545 	 0.43516087532043457 	 0.7360801696777344 	 2.643043279647827 	 0.6769180297851562 	 0.2078535556793213 	 
2025-07-30 20:51:23.236200 test begin: paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), ) 	 55883531 	 1000 	 0.4514479637145996 	 0.44783663749694824 	 0.44047069549560547 	 0.43366551399230957 	 4.520740032196045 	 2.745835781097412 	 4.461245775222778 	 0.2004098892211914 	 
2025-07-30 20:51:33.213600 test begin: paddle.fmax(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), ) 	 101616000 	 1000 	 0.4501948356628418 	 1.420229434967041 	 0.44060444831848145 	 0.4354264736175537 	 0.7360055446624756 	 2.6403443813323975 	 0.6731705665588379 	 0.20757603645324707 	 
2025-07-30 20:51:42.844383 test begin: paddle.fmax(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), ) 	 101608800 	 1000 	 0.450209379196167 	 0.4468843936920166 	 0.44047975540161133 	 0.4354407787322998 	 0.735856294631958 	 2.6452934741973877 	 0.6766209602355957 	 0.20800352096557617 	 
2025-07-30 20:51:49.615198 test begin: paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), ) 	 50803230 	 1000 	 0.2967536449432373 	 0.3034207820892334 	 0.28598618507385254 	 0.29115724563598633 	 8.32830023765564 	 2.4724252223968506 	 8.268990278244019 	 0.16829466819763184 	 
2025-07-30 20:52:02.730144 test begin: paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), ) 	 101606430 	 1000 	 0.4502291679382324 	 0.4468553066253662 	 0.4405558109283447 	 0.435375452041626 	 0.7359578609466553 	 2.6430373191833496 	 0.6768085956573486 	 0.20785260200500488 	 
2025-07-30 20:52:09.438363 test begin: paddle.fmax(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), )
[Prof] paddle.fmax 	 paddle.fmax(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), ) 	 101616000 	 1000 	 0.4502224922180176 	 0.44977807998657227 	 0.4405066967010498 	 0.43500781059265137 	 0.7359199523925781 	 2.640371084213257 	 0.6770789623260498 	 0.20762348175048828 	 
2025-07-30 20:52:17.002716 test begin: paddle.fmin(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 558835211 	 1000 	 4.445301055908203 	 4.410722255706787 	 4.4327192306518555 	 4.390820026397705 	 45.18221855163574 	 27.195571899414062 	 45.09714102745056 	 1.986177921295166 	 
2025-07-30 20:53:57.141487 test begin: paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.4502379894256592 	 0.4468989372253418 	 0.4403421878814697 	 0.4353976249694824 	 0.7359945774078369 	 2.642991542816162 	 0.6763272285461426 	 0.20782876014709473 	 
2025-07-30 20:54:03.999770 test begin: paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([10, 5080321],"float32"), Tensor([5080321],"float32"), ) 	 55883531 	 1000 	 0.45148324966430664 	 0.4459648132324219 	 0.44060373306274414 	 0.4337031841278076 	 4.520227909088135 	 2.7477352619171143 	 4.460361957550049 	 0.2004384994506836 	 
2025-07-30 20:54:13.954777 test begin: paddle.fmin(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([30, 200, 8468],"float32"), Tensor([30, 200, 8468],"float32"), ) 	 101616000 	 1000 	 0.45021939277648926 	 0.4468870162963867 	 0.4329829216003418 	 0.4289824962615967 	 0.7359075546264648 	 2.6415176391601562 	 0.6675107479095459 	 0.20759940147399902 	 
2025-07-30 20:54:20.708526 test begin: paddle.fmin(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([30, 42337, 40],"float32"), Tensor([30, 42337, 40],"float32"), ) 	 101608800 	 1000 	 0.4502432346343994 	 0.4468541145324707 	 0.4403705596923828 	 0.4353210926055908 	 0.7358698844909668 	 2.645193099975586 	 0.6762833595275879 	 0.20801305770874023 	 
2025-07-30 20:54:29.863904 test begin: paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([15],"float32"), ) 	 50803230 	 1000 	 0.29676389694213867 	 0.31294918060302734 	 0.28539085388183594 	 0.2909812927246094 	 8.33021879196167 	 2.4790549278259277 	 8.2704439163208 	 0.16864013671875 	 
2025-07-30 20:54:43.258713 test begin: paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([3386881, 15],"float32"), Tensor([3386881, 15],"float32"), ) 	 101606430 	 1000 	 0.45023393630981445 	 0.4468848705291748 	 0.4403340816497803 	 0.43535447120666504 	 0.7372941970825195 	 2.643066883087158 	 0.678328275680542 	 0.20781683921813965 	 
2025-07-30 20:54:49.988611 test begin: paddle.fmin(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), )
[Prof] paddle.fmin 	 paddle.fmin(Tensor([6351, 200, 40],"float32"), Tensor([6351, 200, 40],"float32"), ) 	 101616000 	 1000 	 0.4502253532409668 	 0.44692111015319824 	 0.4403953552246094 	 0.43537187576293945 	 0.7359035015106201 	 2.64168643951416 	 0.6766777038574219 	 0.20758867263793945 	 
2025-07-30 20:54:56.740313 test begin: paddle.frac(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.8062934875488281 	 0.2980494499206543 	 0.7833142280578613 	 0.2854340076446533 	 1.1836133003234863 	 0.052297353744506836 	 0.6053950786590576 	 4.267692565917969e-05 	 
2025-07-30 20:55:00.811161 test begin: paddle.frac(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.8040103912353516 	 0.29795384407043457 	 0.7812075614929199 	 0.2870903015136719 	 1.1843562126159668 	 0.05308175086975098 	 0.6058139801025391 	 4.9114227294921875e-05 	 
2025-07-30 20:55:04.810604 test begin: paddle.frac(Tensor([16934401, 3],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.8040299415588379 	 0.29792261123657227 	 0.7811336517333984 	 0.28696513175964355 	 1.182976484298706 	 0.05136728286743164 	 0.6044623851776123 	 3.504753112792969e-05 	 
2025-07-30 20:55:08.977403 test begin: paddle.frac(Tensor([2, 12700801],"float64"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.7477400302886963 	 0.2982311248779297 	 0.7240538597106934 	 0.2872486114501953 	 1.064725637435913 	 0.05842709541320801 	 0.5440161228179932 	 3.838539123535156e-05 	 
2025-07-30 20:55:12.204708 test begin: paddle.frac(Tensor([2, 25401601],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.805466890335083 	 0.2979562282562256 	 0.7826669216156006 	 0.2870523929595947 	 1.1830122470855713 	 0.05471444129943848 	 0.60443115234375 	 6.389617919921875e-05 	 
2025-07-30 20:55:16.205760 test begin: paddle.frac(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.805469274520874 	 0.2979738712310791 	 0.7825210094451904 	 0.2870347499847412 	 1.1830101013183594 	 0.05443906784057617 	 0.6044681072235107 	 5.793571472167969e-05 	 
2025-07-30 20:55:20.202361 test begin: paddle.frac(Tensor([8467201, 3],"float64"), )
[Prof] paddle.frac 	 paddle.frac(Tensor([8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.7476961612701416 	 0.30109667778015137 	 0.7238869667053223 	 0.2870602607727051 	 1.0659997463226318 	 0.05235004425048828 	 0.5440077781677246 	 5.412101745605469e-05 	 
2025-07-30 20:55:23.489781 test begin: paddle.full_like(Tensor([1, 300, 169345],"float32"), 1, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([1, 300, 169345],"float32"), 1, ) 	 50803500 	 1000 	 0.1340651512145996 	 0.13443732261657715 	 0.12308526039123535 	 0.12186813354492188 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:24.587896 test begin: paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 2048, 24807],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 1.2314271926879883 	 0.6678845882415771 	 0.6464595794677734 	 0.6462111473083496 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:35.880563 test begin: paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 1, 24807, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 508047360 	 1000 	 0.6580891609191895 	 0.6577961444854736 	 0.6467592716217041 	 0.6445953845977783 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:44.161540 test begin: paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([10, 13, 2048, 2048],"bool"), -65504.0, dtype=Dtype(float16), ) 	 545259520 	 1000 	 0.7055232524871826 	 0.705702543258667 	 0.6942250728607178 	 0.6924240589141846 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:53.178084 test begin: paddle.full_like(Tensor([199, 256000],"float32"), 0.0, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([199, 256000],"float32"), 0.0, ) 	 50944000 	 1000 	 0.13447332382202148 	 0.14961004257202148 	 0.12379217147827148 	 0.12301301956176758 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:54.329008 test begin: paddle.full_like(Tensor([42, 300, 4096],"float32"), 1, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([42, 300, 4096],"float32"), 1, ) 	 51609600 	 1000 	 0.13613057136535645 	 0.13660764694213867 	 0.11761283874511719 	 0.11700224876403809 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:55.506811 test begin: paddle.full_like(Tensor([6, 8467201],"float32"), 0.0, )
[Prof] paddle.full_like 	 paddle.full_like(Tensor([6, 8467201],"float32"), 0.0, ) 	 50803206 	 1000 	 0.13407254219055176 	 0.13443946838378906 	 0.12337994575500488 	 0.1216576099395752 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:56.606605 test begin: paddle.gammainc(Tensor([1270081, 40],"float32"), y=Tensor([1270081, 40],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([1270081, 40],"float32"), y=Tensor([1270081, 40],"float32"), ) 	 101606480 	 1000 	 4.210922718048096 	 2.262296438217163 	 0.003032684326171875 	 2.250685930252075 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 20:56:07.080294 test begin: paddle.gammainc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 4.208786725997925 	 2.2626261711120605 	 0.003041982650756836 	 2.2506210803985596 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 20:56:17.507159 test begin: paddle.gammainc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 4.207027435302734 	 2.2655820846557617 	 0.0030434131622314453 	 2.248569965362549 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 20:56:27.958812 test begin: paddle.gammainc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 4.210538387298584 	 3.0805575847625732 	 0.003032207489013672 	 2.2402753829956055 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 20:56:42.185042 test begin: paddle.gammainc(Tensor([3, 16934401],"float32"), y=Tensor([3, 16934401],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([3, 16934401],"float32"), y=Tensor([3, 16934401],"float32"), ) 	 101606406 	 1000 	 4.204094886779785 	 2.2622742652893066 	 0.003036975860595703 	 2.2503821849823 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 20:56:52.626874 test begin: paddle.gammainc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.gammainc 	 paddle.gammainc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 4.211833477020264 	 2.2623701095581055 	 0.0030350685119628906 	 2.2502408027648926 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igamma: input' is not implemented.
2025-07-30 20:57:03.098224 test begin: paddle.gammaincc(Tensor([1270081, 40],"float32"), Tensor([1270081, 40],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([1270081, 40],"float32"), Tensor([1270081, 40],"float32"), ) 	 101606480 	 1000 	 3.9178824424743652 	 7.093999147415161 	 0.0027647018432617188 	 7.082054853439331 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 20:57:17.830319 test begin: paddle.gammaincc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 3.932279586791992 	 7.094937801361084 	 0.002760171890258789 	 7.076868772506714 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 20:57:32.733246 test begin: paddle.gammaincc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 3.917017698287964 	 7.0983500480651855 	 0.002763032913208008 	 7.072526454925537 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 20:57:49.261464 test begin: paddle.gammaincc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 3.9244632720947266 	 7.095000267028809 	 0.002765178680419922 	 7.083104372024536 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 20:58:04.215128 test begin: paddle.gammaincc(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), ) 	 101606406 	 1000 	 3.912818431854248 	 7.095687389373779 	 0.0027725696563720703 	 7.083879232406616 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 20:58:18.874587 test begin: paddle.gammaincc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.gammaincc 	 paddle.gammaincc(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 3.914341449737549 	 7.094284534454346 	 0.002773284912109375 	 7.082467079162598 	 None 	 None 	 None 	 None 	 
[Error] the derivative for 'igammac: input' is not implemented.
2025-07-30 20:58:33.949071 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08857965469360352 	 16.1277174949646 	 0.07823991775512695 	 0.000255584716796875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:54.922276 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.08946847915649414 	 22.136378049850464 	 0.0720677375793457 	 0.00025081634521484375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:59:20.602279 test begin: paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 2, 7],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09343171119689941 	 16.87999725341797 	 0.08334589004516602 	 0.0001533031463623047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:59:39.572362 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([482, 1],"int64"), ) 	 58720738 	 1000 	 0.08817934989929199 	 15.829837322235107 	 0.07819294929504395 	 0.00022554397583007812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:59:57.081338 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([496, 1],"int64"), ) 	 58720752 	 1000 	 0.0892019271850586 	 16.620928049087524 	 0.07174277305603027 	 0.00021767616271972656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:17.621452 test begin: paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 2048, 7, 2],"float32"), Tensor([512, 1],"int64"), ) 	 58720768 	 1000 	 0.09322524070739746 	 16.928393602371216 	 0.0830380916595459 	 0.00019598007202148438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:37.386337 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([482, 1],"int64"), ) 	 50878946 	 1000 	 0.11727094650268555 	 16.212279796600342 	 0.10425400733947754 	 0.0002231597900390625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:55.790614 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([496, 1],"int64"), ) 	 50878960 	 1000 	 0.12058687210083008 	 16.294504404067993 	 0.1104269027709961 	 0.0002224445343017578 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:01:14.185094 test begin: paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([2048, 507, 7, 7],"float32"), Tensor([512, 1],"int64"), ) 	 50878976 	 1000 	 0.12403368949890137 	 16.93981432914734 	 0.11393618583679199 	 0.0002110004425048828 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:01:32.660355 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([482, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([482, 1],"int64"), ) 	 50878946 	 1000 	 0.2811720371246338 	 15.872034788131714 	 0.2712521553039551 	 0.0002446174621582031 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:01:53.172252 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([496, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([496, 1],"int64"), ) 	 50878960 	 1000 	 0.28967857360839844 	 16.125808715820312 	 0.2797393798828125 	 0.00023651123046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:02:12.124758 test begin: paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([512, 1],"int64"), )
[Prof] paddle.gather 	 paddle.gather(Tensor([507, 2048, 7, 7],"float32"), Tensor([512, 1],"int64"), ) 	 50878976 	 1000 	 0.29736757278442383 	 16.776950359344482 	 0.2874715328216553 	 0.00023865699768066406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:02:31.781037 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([20, 50, 2],"int64"), ) 	 52918864 	 1000 	 0.013359546661376953 	 92.11033463478088 	 1.9073486328125e-05 	 0.00022172927856445312 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:04:05.044404 test begin: paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([1001, 413, 128],"float32"), index=Tensor([5, 50, 2],"int64"), ) 	 52917364 	 1000 	 0.011487960815429688 	 20.134676694869995 	 1.4066696166992188e-05 	 0.00020956993103027344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:04:26.988390 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102473328 	 1000 	 0.011011838912963867 	 83.70475029945374 	 1.4543533325195312e-05 	 0.0002536773681640625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:05:52.765227 test begin: paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 1417, 716],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102473404 	 1000 	 0.011096477508544922 	 77.70288801193237 	 1.4066696166992188e-05 	 0.00021123886108398438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:12.550478 test begin: paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 819, 1240],"bfloat16"), Tensor([778, 2],"int64"), ) 	 102573116 	 1000 	 0.011608362197875977 	 62.45184254646301 	 0.0004687309265136719 	 0.0002117156982421875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:08:17.080449 test begin: paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), )
[Prof] paddle.gather_nd 	 paddle.gather_nd(Tensor([101, 8192, 124],"bfloat16"), Tensor([816, 2],"int64"), ) 	 102598240 	 1000 	 0.010966300964355469 	 73.14367175102234 	 1.3589859008789062e-05 	 0.00010609626770019531 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:09:32.285458 test begin: paddle.gcd(Tensor([10, 50803],"int32"), Tensor([10, 50803],"int32"), )
W0730 21:09:38.461411 84826 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(Tensor([10, 50803],"int32"), Tensor([10, 50803],"int32"), ) 	 1016060 	 1000 	 6.152049541473389 	 0.026282310485839844 	 4.76837158203125e-05 	 0.015500068664550781 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:09:40.584900 test begin: paddle.gcd(Tensor([25401, 20],"int32"), Tensor([25401, 20],"int32"), )
W0730 21:09:47.153203 84928 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(Tensor([25401, 20],"int32"), Tensor([25401, 20],"int32"), ) 	 1016040 	 1000 	 6.547078371047974 	 0.026600360870361328 	 5.269050598144531e-05 	 0.015622615814208984 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:09:47.189832 test begin: paddle.gcd(x=Tensor([12700, 2, 4, 5],"int32"), y=Tensor([12700, 2, 4, 5],"int32"), )
W0730 21:09:53.870925 85172 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([12700, 2, 4, 5],"int32"), y=Tensor([12700, 2, 4, 5],"int32"), ) 	 1016000 	 1000 	 6.660055875778198 	 0.026116371154785156 	 5.14984130859375e-05 	 0.014999151229858398 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:09:53.920886 test begin: paddle.gcd(x=Tensor([25401, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0730 21:10:00.632151 85342 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([25401, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 508030 	 1000 	 6.687872409820557 	 0.05636715888977051 	 4.482269287109375e-05 	 0.04444074630737305 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:00.696010 test begin: paddle.gcd(x=Tensor([6, 1, 16934, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0730 21:10:08.903600 85571 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 1, 16934, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 508030 	 1000 	 8.183653593063354 	 0.05726766586303711 	 5.2928924560546875e-05 	 0.03896903991699219 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:08.972877 test begin: paddle.gcd(x=Tensor([6, 1, 4, 21168],"int32"), y=Tensor([2, 1, 21168],"int32"), )
W0730 21:10:15.987839 85829 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 1, 4, 21168],"int32"), y=Tensor([2, 1, 21168],"int32"), ) 	 550368 	 1000 	 6.991833686828613 	 0.05590534210205078 	 4.291534423828125e-05 	 0.04412102699279785 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:16.048887 test begin: paddle.gcd(x=Tensor([6, 2, 4, 10584],"int32"), y=Tensor([6, 2, 4, 10584],"int32"), )
W0730 21:10:22.603753 86140 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 2, 4, 10584],"int32"), y=Tensor([6, 2, 4, 10584],"int32"), ) 	 1016064 	 1000 	 6.531897068023682 	 0.026189088821411133 	 4.792213439941406e-05 	 0.015187501907348633 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:22.635886 test begin: paddle.gcd(x=Tensor([6, 2, 8467, 5],"int32"), y=Tensor([6, 2, 8467, 5],"int32"), )
W0730 21:10:29.586066 86313 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 2, 8467, 5],"int32"), y=Tensor([6, 2, 8467, 5],"int32"), ) 	 1016040 	 1000 	 6.929436922073364 	 0.02631092071533203 	 4.220008850097656e-05 	 0.015378952026367188 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:29.618164 test begin: paddle.gcd(x=Tensor([6, 4233, 4, 5],"int32"), y=Tensor([6, 4233, 4, 5],"int32"), )
W0730 21:10:36.223431 86624 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.gcd 	 paddle.gcd(x=Tensor([6, 4233, 4, 5],"int32"), y=Tensor([6, 4233, 4, 5],"int32"), ) 	 1015920 	 1000 	 6.583592891693115 	 0.026048660278320312 	 4.863739013671875e-05 	 0.015270233154296875 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:10:37.405197 test begin: paddle.geometric.segment_max(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.7313134670257568 	 10.057915449142456 	 0.0007069110870361328 	 0.00021505355834960938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:10:50.166678 test begin: paddle.geometric.segment_max(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), ) 	 101606480 	 1000 	 1.5711431503295898 	 10.447619915008545 	 0.0015397071838378906 	 0.0002162456512451172 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:11:05.368354 test begin: paddle.geometric.segment_max(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_max 	 paddle.geometric.segment_max(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.605534553527832 	 10.295684099197388 	 0.0005805492401123047 	 0.00035572052001953125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:11:18.224802 test begin: paddle.geometric.segment_mean(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), ) 	 26671701 	 1000 	 0.5177960395812988 	 1.040348768234253 	 0.00048160552978515625 	 0.00018310546875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:11:23.650065 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 8.875507593154907 	 11.600427389144897 	 0.008847713470458984 	 0.00156402587890625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:12:27.451534 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 6.699371337890625 	 13.873304843902588 	 0.0061261653900146484 	 0.002365589141845703 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:13:55.573411 test begin: paddle.geometric.segment_mean(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 7.2513532638549805 	 10.410056114196777 	 0.0072040557861328125 	 0.001361846923828125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:14:53.419024 test begin: paddle.geometric.segment_mean(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), ) 	 53343381 	 1000 	 0.6411941051483154 	 1.429579496383667 	 0.0005710124969482422 	 0.00022172927856445312 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:15:02.025068 test begin: paddle.geometric.segment_mean(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.46871447563171387 	 1.0040178298950195 	 0.0004363059997558594 	 0.0001728534698486328 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:18:24.061463 test begin: paddle.geometric.segment_mean(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.5255100727081299 	 1.341933250427246 	 0.0004894733428955078 	 0.0002868175506591797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:21:59.212082 test begin: paddle.geometric.segment_mean(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), )
[Prof] paddle.geometric.segment_mean 	 paddle.geometric.segment_mean(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), ) 	 106686741 	 1000 	 1.6138701438903809 	 1.6293532848358154 	 0.0015842914581298828 	 0.00010704994201660156 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:22:07.140307 test begin: paddle.geometric.segment_min(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([1270081, 20],"float64"), Tensor([1270081],"int64"), ) 	 26671701 	 1000 	 0.6522905826568604 	 1.154733419418335 	 0.0006227493286132812 	 0.00022530555725097656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:22:10.775295 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float16"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 10.87530517578125 	 39.010621070861816 	 0.010798931121826172 	 0.0002257823944091797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:23:18.193337 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float32"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 9.345818281173706 	 15.346675157546997 	 0.009275674819946289 	 0.0016808509826660156 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:24:07.539293 test begin: paddle.geometric.segment_min(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([25401601, 20],"float64"), Tensor([25401601],"int64"), ) 	 533433621 	 1000 	 11.909733772277832 	 20.667877435684204 	 0.01181340217590332 	 0.0038433074951171875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:25:14.611205 test begin: paddle.geometric.segment_min(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([2540161, 20],"float32"), Tensor([2540161],"int64"), ) 	 53343381 	 1000 	 1.0075502395629883 	 1.6291100978851318 	 0.0009648799896240234 	 0.00025177001953125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:25:21.282838 test begin: paddle.geometric.segment_min(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 1270081],"float32"), Tensor([40],"int64"), ) 	 50803280 	 1000 	 0.7052605152130127 	 0.708549976348877 	 0.0006818771362304688 	 0.00020432472229003906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:25:24.429317 test begin: paddle.geometric.segment_min(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 2540161],"float16"), Tensor([40],"int64"), ) 	 101606480 	 1000 	 1.7135508060455322 	 2.161149263381958 	 0.00167083740234375 	 0.0003235340118408203 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:25:32.201669 test begin: paddle.geometric.segment_min(Tensor([40, 635041],"float64"), Tensor([40],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([40, 635041],"float64"), Tensor([40],"int64"), ) 	 25401680 	 1000 	 0.4735145568847656 	 0.6709985733032227 	 0.00044798851013183594 	 0.00013136863708496094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:25:34.958045 test begin: paddle.geometric.segment_min(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), )
[Prof] paddle.geometric.segment_min 	 paddle.geometric.segment_min(Tensor([5080321, 20],"float16"), Tensor([5080321],"int64"), ) 	 106686741 	 1000 	 2.3021509647369385 	 4.875108480453491 	 0.0022482872009277344 	 0.0005967617034912109 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:25:47.413509 test begin: paddle.geometric.segment_sum(Tensor([25401601, 15],"float16"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([25401601, 15],"float16"), Tensor([25401601],"int64"), ) 	 406425616 	 1000 	 5.841901063919067 	 4.617080450057983 	 0.0058002471923828125 	 2.35620379447937 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:12.015558 test begin: paddle.geometric.segment_sum(Tensor([25401601, 15],"float32"), Tensor([25401601],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([25401601, 15],"float32"), Tensor([25401601],"int64"), ) 	 406425616 	 1000 	 4.14253306388855 	 3.353606700897217 	 0.0040895938873291016 	 1.7084836959838867 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:33.991924 test begin: paddle.geometric.segment_sum(Tensor([2540161, 20],"float32"), Tensor([2540161],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([2540161, 20],"float32"), Tensor([2540161],"int32"), ) 	 53343381 	 1000 	 0.5972785949707031 	 0.46201467514038086 	 0.000568389892578125 	 0.23440289497375488 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:39.523580 test begin: paddle.geometric.segment_sum(Tensor([30, 1693441],"float32"), Tensor([30],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([30, 1693441],"float32"), Tensor([30],"int64"), ) 	 50803260 	 1000 	 0.48469090461730957 	 0.30782175064086914 	 0.0004546642303466797 	 0.1571798324584961 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:41.930195 test begin: paddle.geometric.segment_sum(Tensor([30, 3386881],"float16"), Tensor([30],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([30, 3386881],"float16"), Tensor([30],"int64"), ) 	 101606460 	 1000 	 1.4232237339019775 	 1.1322195529937744 	 0.001390695571899414 	 0.5784580707550049 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:48.769204 test begin: paddle.geometric.segment_sum(Tensor([3386881, 15],"float32"), Tensor([3386881],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([3386881, 15],"float32"), Tensor([3386881],"int64"), ) 	 54190096 	 1000 	 0.5655307769775391 	 0.45070910453796387 	 0.0005426406860351562 	 0.22888731956481934 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:51.670533 test begin: paddle.geometric.segment_sum(Tensor([40, 1270081],"float32"), Tensor([40],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([40, 1270081],"float32"), Tensor([40],"int32"), ) 	 50803280 	 1000 	 0.4944467544555664 	 0.36079883575439453 	 0.0004668235778808594 	 0.18209457397460938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:26:54.455606 test begin: paddle.geometric.segment_sum(Tensor([50803201, 20],"float32"), Tensor([50803201],"int32"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([50803201, 20],"float32"), Tensor([50803201],"int32"), ) 	 1066867221 	 1000 	 12.77571702003479 	 10.230621576309204 	 0.012735366821289062 	 2.619258165359497 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:03.040770 test begin: paddle.geometric.segment_sum(Tensor([6773761, 15],"float16"), Tensor([6773761],"int64"), )
[Prof] paddle.geometric.segment_sum 	 paddle.geometric.segment_sum(Tensor([6773761, 15],"float16"), Tensor([6773761],"int64"), ) 	 108380176 	 1000 	 1.8280274868011475 	 1.4469716548919678 	 0.0017828941345214844 	 0.7327220439910889 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:11.318968 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, ) 	 25401640 	 1000 	 1.0271937847137451 	 3.718270778656006 	 0.3500857353210449 	 0.00046133995056152344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:18.464002 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, ) 	 25401640 	 1000 	 1.081181526184082 	 4.35481858253479 	 0.22054624557495117 	 0.00023674964904785156 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:25.831152 test begin: paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([10, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, ) 	 25401640 	 1000 	 1.0218620300292969 	 3.716806411743164 	 0.34870457649230957 	 0.0004687309265136719 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:33.362476 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "max", None, None, ) 	 25401650 	 1000 	 0.4496653079986572 	 2.268540382385254 	 0.15325403213500977 	 0.0004658699035644531 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:41.614481 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mean", None, None, ) 	 25401650 	 1000 	 0.35983896255493164 	 2.6310741901397705 	 0.07360053062438965 	 0.00017118453979492188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:45.843482 test begin: paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, )
[Prof] paddle.geometric.send_u_recv 	 paddle.geometric.send_u_recv(Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "min", None, None, ) 	 25401650 	 1000 	 0.449418306350708 	 2.320575714111328 	 0.1530916690826416 	 0.00045752525329589844 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:49.880766 test begin: paddle.geometric.send_ue_recv(Tensor([10, 1693441],"float64"), Tensor([15, 1693441],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 1693441],"float64"), Tensor([15, 1693441],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 42336055 	 1000 	 0.8517627716064453 	 2.6959846019744873 	 0.1736156940460205 	 0.00021648406982421875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:28:55.795089 test begin: paddle.geometric.send_ue_recv(Tensor([10, 2540161],"float64"), Tensor([15, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 2540161],"float64"), Tensor([15, 2540161],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 63504055 	 1000 	 1.2827107906341553 	 3.4783637523651123 	 0.26166319847106934 	 0.0002148151397705078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:29:04.461221 test begin: paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 33022175 	 1000 	 62.2417426109314 	 3.7002618312835693 	 8.749961853027344e-05 	 0.0004940032958984375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:31:22.828351 test begin: paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 508033, 5],"float64"), Tensor([15, 508033, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 33022175 	 1000 	 61.75922679901123 	 2.647662878036499 	 0.00011157989501953125 	 0.00010323524475097656 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:34:30.718744 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 25401830 	 1000 	 60.75269794464111 	 3.4353129863739014 	 9.584426879882812e-05 	 0.0005083084106445312 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:38:37.504453 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([10, 8, 317521],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 25401830 	 1000 	 65.06215071678162 	 2.4489874839782715 	 9.083747863769531e-05 	 0.00020074844360351562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:43:46.024786 test begin: paddle.geometric.send_ue_recv(Tensor([1270081, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([1270081, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, ) 	 25401950 	 1000 	 0.3596498966217041 	 2.309394598007202 	 0.0735464096069336 	 8.0108642578125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:43:49.935389 test begin: paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "max", None, None, ) 	 25401790 	 1000 	 0.5446085929870605 	 1.7834701538085938 	 4.1484832763671875e-05 	 0.00045990943908691406 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:43:53.674354 test begin: paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
[Prof] paddle.geometric.send_ue_recv 	 paddle.geometric.send_ue_recv(Tensor([635041, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, ) 	 25401790 	 1000 	 0.26175808906555176 	 1.5465731620788574 	 4.410743713378906e-05 	 0.00024771690368652344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:44:00.465928 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", ) 	 50805302 	 1000 	 7.948753833770752 	 6.068088054656982 	 9.059906005859375e-05 	 3.1024041175842285 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:44:53.496614 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 20],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "mul", ) 	 50805302 	 1000 	 7.966278076171875 	 6.0760931968688965 	 8.535385131835938e-05 	 3.100860834121704 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:45:47.500697 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401830 	 1000 	 4.564913988113403 	 0.050446510314941406 	 9.202957153320312e-05 	 0.030177593231201172 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:45:54.504216 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([100, 254017],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 25401830 	 1000 	 3.3972835540771484 	 0.05137467384338379 	 0.00010991096496582031 	 0.028828144073486328 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:46:03.267535 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401750 	 1000 	 0.09659314155578613 	 0.011853456497192383 	 2.4080276489257812e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:46:04.109913 test begin: paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 25401750 	 1000 	 0.09519720077514648 	 0.011648416519165039 	 3.0517578125e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:46:05.060988 test begin: paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([100, 1],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([100, 1],"float64"), Tensor([25401601],"int64"), Tensor([25401601],"int64"), "add", ) 	 50805302 	 1000 	 8.603283882141113 	 6.0664262771606445 	 7.104873657226562e-05 	 3.1009299755096436 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:46:59.444297 test begin: paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25403631 	 1000 	 0.09627342224121094 	 0.011535406112670898 	 3.552436828613281e-05 	 3.1948089599609375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:47:07.904044 test begin: paddle.geometric.send_uv(Tensor([100, 254017],"float64"), Tensor([100, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([100, 254017],"float64"), Tensor([100, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 25401830 	 1000 	 9.381448030471802 	 0.05041003227233887 	 9.107589721679688e-05 	 0.03839278221130371 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:47:19.650617 test begin: paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 26671731 	 1000 	 0.0963449478149414 	 0.011581897735595703 	 3.0279159545898438e-05 	 3.147125244140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:47:20.915386 test begin: paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 1],"float64"), Tensor([1270081, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", ) 	 26671731 	 1000 	 0.0974891185760498 	 0.011719226837158203 	 3.337860107421875e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:47:22.292763 test begin: paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([1270081, 20],"float64"), Tensor([1270081, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 26674703 	 1000 	 0.09694385528564453 	 0.011615991592407227 	 2.6464462280273438e-05 	 2.956390380859375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:47:23.481288 test begin: paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 1],"float64"), Tensor([25401601, 20],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "mul", ) 	 533436623 	 1000 	 0.09703254699707031 	 0.011676549911499023 	 2.7894973754882812e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:47:45.626956 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([1501],"int64"), Tensor([1501],"int64"), "add", ) 	 533436623 	 1000 	 0.11728239059448242 	 0.011568784713745117 	 3.647804260253906e-05 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:48:09.262101 test begin: paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", )
[Prof] paddle.geometric.send_uv 	 paddle.geometric.send_uv(Tensor([25401601, 20],"float64"), Tensor([25401601, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", ) 	 533433651 	 1000 	 0.09892868995666504 	 0.011363506317138672 	 2.7894973754882812e-05 	 4.76837158203125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:48:31.843201 test begin: paddle.greater_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), ) 	 38103936 	 1000 	 0.5612893104553223 	 0.5012426376342773 	 0.5512790679931641 	 0.4888300895690918 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:33.656553 test begin: paddle.greater_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), ) 	 38102688 	 1000 	 0.5548045635223389 	 0.5139060020446777 	 0.5450117588043213 	 0.48980116844177246 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:35.405999 test begin: paddle.greater_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), ) 	 31753280 	 1000 	 0.21455788612365723 	 0.2218925952911377 	 0.20480084419250488 	 0.20680570602416992 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:39.700061 test begin: paddle.greater_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), ) 	 25403456 	 1000 	 0.5632889270782471 	 0.44932007789611816 	 0.5534501075744629 	 0.4328150749206543 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:41.494082 test begin: paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), ) 	 25405120 	 1000 	 1.0573952198028564 	 0.9080891609191895 	 1.0477383136749268 	 0.8960154056549072 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:43.882432 test begin: paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), ) 	 228616128 	 1000 	 1.8176045417785645 	 1.571903944015503 	 1.807011604309082 	 1.5595982074737549 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:50.991198 test begin: paddle.greater_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), ) 	 76205064 	 1000 	 1.1129932403564453 	 0.9978258609771729 	 1.1032850742340088 	 0.9792094230651855 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:54.574023 test begin: paddle.greater_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), ) 	 76205376 	 1000 	 1.1175978183746338 	 0.9963510036468506 	 1.1004068851470947 	 0.9775402545928955 	 None 	 None 	 None 	 None 	 
2025-07-30 21:48:58.010160 test begin: paddle.greater_equal(Tensor([16935, 10, 15, 20],"float32"), Tensor([16935, 10, 15, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([16935, 10, 15, 20],"float32"), Tensor([16935, 10, 15, 20],"float32"), ) 	 101610000 	 1000 	 0.3284013271331787 	 0.3279688358306885 	 0.3190348148345947 	 0.3161323070526123 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:00.345156 test begin: paddle.greater_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), ) 	 76205184 	 1000 	 1.1161000728607178 	 0.9975478649139404 	 1.1062824726104736 	 0.985344409942627 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:03.743231 test begin: paddle.greater_equal(Tensor([49613, 1024, 1, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([49613, 1024, 1, 1],"float32"), Tensor([1],"float32"), ) 	 50803713 	 1000 	 0.18776941299438477 	 0.23091530799865723 	 0.17773675918579102 	 0.21849465370178223 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:04.981629 test begin: paddle.greater_equal(Tensor([5, 10, 15, 67738],"float32"), Tensor([5, 10, 15, 67738],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 10, 15, 67738],"float32"), Tensor([5, 10, 15, 67738],"float32"), ) 	 101607000 	 1000 	 0.32722926139831543 	 0.3279743194580078 	 0.3109300136566162 	 0.3101973533630371 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:07.357258 test begin: paddle.greater_equal(Tensor([5, 10, 50804, 20],"float32"), Tensor([5, 10, 50804, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 10, 50804, 20],"float32"), Tensor([5, 10, 50804, 20],"float32"), ) 	 101608000 	 1000 	 0.3272528648376465 	 0.3278937339782715 	 0.31803417205810547 	 0.3159360885620117 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:09.838063 test begin: paddle.greater_equal(Tensor([5, 33869, 15, 20],"float32"), Tensor([5, 33869, 15, 20],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([5, 33869, 15, 20],"float32"), Tensor([5, 33869, 15, 20],"float32"), ) 	 101607000 	 1000 	 0.3272433280944824 	 0.32912254333496094 	 0.3180370330810547 	 0.31618309020996094 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:12.169226 test begin: paddle.greater_equal(Tensor([8, 1024, 1, 6202],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 1024, 1, 6202],"float32"), Tensor([1],"float32"), ) 	 50806785 	 1000 	 0.18824481964111328 	 0.24755144119262695 	 0.17076969146728516 	 0.21322894096374512 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:13.483726 test begin: paddle.greater_equal(Tensor([8, 1024, 6202, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 1024, 6202, 1],"float32"), Tensor([1],"float32"), ) 	 50806785 	 1000 	 0.18821406364440918 	 0.24825119972229004 	 0.17817139625549316 	 0.21835041046142578 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:14.757448 test begin: paddle.greater_equal(Tensor([8, 6350401, 1, 1],"float32"), Tensor([1],"float32"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([8, 6350401, 1, 1],"float32"), Tensor([1],"float32"), ) 	 50803209 	 1000 	 0.18778204917907715 	 0.2309119701385498 	 0.17763733863830566 	 0.2181556224822998 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:15.997645 test begin: paddle.greater_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), )
[Prof] paddle.greater_equal 	 paddle.greater_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), ) 	 38102784 	 1000 	 0.5625338554382324 	 0.5026488304138184 	 0.5526509284973145 	 0.48885250091552734 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:17.700024 test begin: paddle.greater_than(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19118833541870117 	 0.24862360954284668 	 0.18095898628234863 	 0.2364339828491211 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:18.981373 test begin: paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.188493013381958 	 0.2506594657897949 	 0.17847967147827148 	 0.23700857162475586 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:22.251694 test begin: paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.32692909240722656 	 0.33624720573425293 	 0.31743693351745605 	 0.31409525871276855 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:25.198157 test begin: paddle.greater_than(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.32689952850341797 	 0.3279285430908203 	 0.31731700897216797 	 0.3164703845977783 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:27.532952 test begin: paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), )
W0730 21:49:30.966449 68773 dygraph_functions.cc:90428] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), ) 	 203212812 	 1000 	 1.1293056011199951 	 0.7184321880340576 	 0.5770606994628906 	 0.7067334651947021 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:32.987279 test begin: paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float64"), ) 	 203212812 	 1000 	 2.0564255714416504 	 0.9916996955871582 	 1.0624282360076904 	 0.9658713340759277 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:40.978707 test begin: paddle.greater_than(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3269033432006836 	 0.3279078006744385 	 0.3174610137939453 	 0.31638550758361816 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:43.352334 test begin: paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), ) 	 203212816 	 1000 	 1.1294662952423096 	 0.718574047088623 	 0.5771956443786621 	 0.7065892219543457 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:48.750066 test begin: paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float64"), ) 	 203212816 	 1000 	 2.0339136123657227 	 0.9823637008666992 	 1.0386073589324951 	 0.970496416091919 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:55.923859 test begin: paddle.greater_than(Tensor([4, 3, 2116801],"float16"), Tensor([4, 3, 2116801],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 2116801],"float16"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 0.5182805061340332 	 0.2508575916290283 	 0.2648277282714844 	 0.23900580406188965 	 None 	 None 	 None 	 None 	 
2025-07-30 21:49:57.681778 test begin: paddle.greater_than(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 0.570749044418335 	 0.36845993995666504 	 0.292248010635376 	 0.3524165153503418 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:00.480261 test begin: paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), ) 	 203212824 	 1000 	 1.131913185119629 	 0.7308492660522461 	 0.5796816349029541 	 0.7061870098114014 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:05.856439 test begin: paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float64"), ) 	 203212824 	 1000 	 2.0337228775024414 	 0.9779727458953857 	 1.0384271144866943 	 0.966205358505249 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:12.916407 test begin: paddle.greater_than(Tensor([4, 3175201, 2],"float16"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 3175201, 2],"float16"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 0.5183422565460205 	 0.2602827548980713 	 0.26485109329223633 	 0.24034738540649414 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:14.912406 test begin: paddle.greater_than(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 0.5695157051086426 	 0.3629298210144043 	 0.29105067253112793 	 0.3513026237487793 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:17.610169 test begin: paddle.greater_than(Tensor([4233601, 3, 2],"float16"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([4233601, 3, 2],"float16"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 0.5182688236236572 	 0.2549278736114502 	 0.2648179531097412 	 0.2404322624206543 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:19.548978 test begin: paddle.greater_than(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.greater_than 	 paddle.greater_than(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 0.5694634914398193 	 0.36617159843444824 	 0.2909817695617676 	 0.35122251510620117 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:22.337927 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([1],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([1],"float32"), ) 	 50804737 	 1000 	 0.29651570320129395 	 0.30358147621154785 	 0.28569531440734863 	 0.290813684463501 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 21:50:59.182294 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([2048],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([2048],"float32"), ) 	 50806784 	 1000 	 0.2970602512359619 	 0.3064546585083008 	 0.28647351264953613 	 0.29386281967163086 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 21:51:02.741806 test begin: paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([24807, 2048],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([24807, 2048],"float32"), Tensor([24807, 2048],"float32"), ) 	 101609472 	 1000 	 0.45294976234436035 	 0.4533851146697998 	 0.43622326850891113 	 0.4335517883300781 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 21:51:10.030503 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([169345],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([169345],"float32"), ) 	 50972845 	 1000 	 0.2958250045776367 	 0.3093738555908203 	 0.28497838973999023 	 0.2946741580963135 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 21:51:12.938104 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([1],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([1],"float32"), ) 	 50803501 	 1000 	 0.29668641090393066 	 0.3034398555755615 	 0.28589320182800293 	 0.28372931480407715 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 21:51:49.802112 test begin: paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), )
[Prof] paddle.heaviside 	 paddle.heaviside(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), ) 	 101607000 	 1000 	 0.44974517822265625 	 0.4463198184967041 	 0.4398977756500244 	 0.4341118335723877 	 None 	 None 	 None 	 None 	 
[Error] derivative for aten::heaviside is not implemented
2025-07-30 21:51:53.768187 test begin: paddle.histogram(input=Tensor([4, 6350401],"int64"), )
[Prof] paddle.histogram 	 paddle.histogram(input=Tensor([4, 6350401],"int64"), ) 	 25401604 	 1000 	 6.481791734695435 	 0.7657644748687744 	 0.0003972053527832031 	 0.0004134178161621094 	 None 	 None 	 None 	 None 	 
2025-07-30 21:52:01.522537 test begin: paddle.histogram(input=Tensor([6350401, 4],"int64"), )
[Prof] paddle.histogram 	 paddle.histogram(input=Tensor([6350401, 4],"int64"), ) 	 25401604 	 1000 	 6.478167533874512 	 0.7700297832489014 	 0.00040030479431152344 	 0.0007131099700927734 	 None 	 None 	 None 	 None 	 
2025-07-30 21:52:09.391658 test begin: paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([2540161, 20],"float32"), bins=10, min=0, max=1, ) 	 50803220 	 1000 	 0.10368180274963379 	 0.016534805297851562 	 2.6226043701171875e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:52:10.384073 test begin: paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([5, 10160641],"float32"), bins=10, min=1, max=1, ) 	 50803205 	 1000 	 0.10112309455871582 	 0.016429424285888672 	 2.47955322265625e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:52:11.326264 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=0, max=1, ) 	 508032050 	 1000 	 0.09993481636047363 	 0.01653599739074707 	 2.1457672119140625e-05 	 4.38690185546875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:52:20.068006 test begin: paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, )
[Prof] paddle.histogram_bin_edges 	 paddle.histogram_bin_edges(Tensor([50, 10160641],"float32"), bins=10, min=1, max=1, ) 	 508032050 	 1000 	 0.10080289840698242 	 0.01665329933166504 	 2.193450927734375e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:52:28.370099 test begin: paddle.histogramdd(Tensor([1270, 2, 2],"float64"), bins=5, weights=Tensor([1270, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, )
/usr/local/lib/python3.10/dist-packages/paddle/tensor/linalg.py:5741: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  edge = paddle.to_tensor(edge)
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([1270, 2, 2],"float64"), bins=5, weights=Tensor([1270, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, ) 	 7620 	 1000 	 1.9331145286560059 	 0.0640263557434082 	 1.430511474609375e-05 	 0.00010371208190917969 	 None 	 None 	 None 	 None 	 
2025-07-30 21:52:30.396107 test begin: paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=False, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=False, ) 	 317520 	 1000 	 3.9356017112731934 	 1.1537184715270996 	 2.002716064453125e-05 	 0.0001952648162841797 	 None 	 None 	 None 	 None 	 
2025-07-30 21:52:35.506181 test begin: paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 15876, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 15876],"float64"), ranges=None, density=True, ) 	 317520 	 1000 	 3.9707746505737305 	 1.1062312126159668 	 1.4066696166992188e-05 	 9.894371032714844e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:52:40.611160 test begin: paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=False, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=False, ) 	 1270080 	 1000 	 20.924230337142944 	 5.415035009384155 	 4.982948303222656e-05 	 0.0002942085266113281 	 None 	 None 	 None 	 None 	 
2025-07-30 21:53:07.039321 test begin: paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([4, 63504, 4],"float64"), bins=list[1,2,3,4,], weights=Tensor([4, 63504],"float64"), ranges=None, density=True, ) 	 1270080 	 1000 	 20.99086594581604 	 4.2779459953308105 	 3.147125244140625e-05 	 0.00011038780212402344 	 None 	 None 	 None 	 None 	 
2025-07-30 21:53:32.389176 test begin: paddle.histogramdd(Tensor([63504, 2, 2],"float64"), bins=5, weights=Tensor([63504, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, )
[Prof] paddle.histogramdd 	 paddle.histogramdd(Tensor([63504, 2, 2],"float64"), bins=5, weights=Tensor([63504, 2],"float64"), ranges=list[1.0,10.0,1.0,100.0,], density=True, ) 	 381024 	 1000 	 3.2906455993652344 	 0.1498708724975586 	 0.00018095970153808594 	 9.012222290039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:53:35.845868 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], )
W0730 21:53:47.511468 107352 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.03704547882080078 	 0.009351730346679688 	 3.910064697265625e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:53:50.691754 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], )
W0730 21:53:57.639169 108393 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.01778388023376465 	 0.006955385208129883 	 1.5974044799804688e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:53:58.861931 test begin: paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], )
W0730 21:54:06.074779 108944 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([14112010, 6, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.02510213851928711 	 0.008219003677368164 	 1.7881393432617188e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:54:07.189415 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], )
W0730 21:54:17.614521 109717 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.03240680694580078 	 0.009318351745605469 	 2.1696090698242188e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:54:19.668142 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], )
W0730 21:54:26.687132 110850 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.01771235466003418 	 0.007034778594970703 	 2.0742416381835938e-05 	 1.9550323486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:54:27.836060 test begin: paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], )
W0730 21:54:34.813393 111481 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 2116801, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.02502584457397461 	 0.008278608322143555 	 2.2649765014648438e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:54:39.658867 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], )
W0730 21:54:49.047878 112369 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.03208661079406738 	 0.009403467178344727 	 1.5497207641601562e-05 	 2.193450927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:54:50.714012 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], )
W0730 21:54:57.832078 113219 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.017889738082885742 	 0.01166534423828125 	 1.1205673217773438e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:54:59.544171 test begin: paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], )
W0730 21:55:06.722981 113716 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.hsplit 	 paddle.hsplit(Tensor([40, 6, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.024662256240844727 	 0.008205413818359375 	 1.4781951904296875e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:55:07.819866 test begin: paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9325246810913086 	 0.9244511127471924 	 0.9138634204864502 	 0.9095542430877686 	 0.9295883178710938 	 0.09103012084960938 	 0.8597559928894043 	 6.771087646484375e-05 	 
2025-07-30 21:55:14.022538 test begin: paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3152954578399658 	 0.31487274169921875 	 0.30003905296325684 	 0.16138648986816406 	 0.31115269660949707 	 0.058774471282958984 	 0.25332212448120117 	 5.698204040527344e-05 	 
2025-07-30 21:55:16.081296 test begin: paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31574583053588867 	 0.3220705986022949 	 0.2892899513244629 	 0.30057740211486816 	 0.3126406669616699 	 0.09522128105163574 	 0.23145413398742676 	 7.557868957519531e-05 	 
2025-07-30 21:55:18.222207 test begin: paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.31600046157836914 	 0.3214850425720215 	 0.2973599433898926 	 0.3071296215057373 	 0.31424474716186523 	 0.08382582664489746 	 0.24245691299438477 	 9.918212890625e-05 	 
2025-07-30 21:55:20.309544 test begin: paddle.hstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9261054992675781 	 0.9361317157745361 	 0.89949631690979 	 0.908027172088623 	 0.9339292049407959 	 0.07752203941345215 	 0.8517117500305176 	 7.414817810058594e-05 	 
2025-07-30 21:55:26.949702 test begin: paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 25401654 	 1000 	 0.31634044647216797 	 0.3233320713043213 	 0.297776460647583 	 0.3043487071990967 	 0.3141319751739502 	 0.08402347564697266 	 0.24162721633911133 	 5.8650970458984375e-05 	 
2025-07-30 21:55:29.210199 test begin: paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.3164846897125244 	 0.3195662498474121 	 0.29813385009765625 	 0.3054182529449463 	 0.3125646114349365 	 0.07761168479919434 	 0.24086928367614746 	 7.2479248046875e-05 	 
2025-07-30 21:55:31.303328 test begin: paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9281620979309082 	 0.9340825080871582 	 0.909775972366333 	 0.9105896949768066 	 0.9317200183868408 	 0.07919931411743164 	 0.8460690975189209 	 8.034706115722656e-05 	 
2025-07-30 21:55:41.057227 test begin: paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.3140602111816406 	 0.31360960006713867 	 0.29885005950927734 	 0.16012811660766602 	 0.31106019020080566 	 0.058773040771484375 	 0.2536499500274658 	 3.838539123535156e-05 	 
2025-07-30 21:55:43.115063 test begin: paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401654 	 1000 	 0.3157639503479004 	 0.3168051242828369 	 0.2894418239593506 	 0.2930629253387451 	 0.3124673366546631 	 0.0807335376739502 	 0.23212075233459473 	 5.245208740234375e-05 	 
2025-07-30 21:55:45.275991 test begin: paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9320337772369385 	 0.9334521293640137 	 0.9138174057006836 	 0.918278694152832 	 0.9465444087982178 	 0.08352494239807129 	 0.8749995231628418 	 6.580352783203125e-05 	 
2025-07-30 21:55:51.323446 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401870 	 1000 	 0.3157529830932617 	 0.3191814422607422 	 0.29738354682922363 	 0.2978816032409668 	 0.31249094009399414 	 0.11773109436035156 	 0.24155235290527344 	 0.00011134147644042969 	 
2025-07-30 21:55:53.410061 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9355320930480957 	 0.9465856552124023 	 0.90909743309021 	 0.9258155822753906 	 0.9423332214355469 	 0.10500907897949219 	 0.8605108261108398 	 0.00010943412780761719 	 
2025-07-30 21:56:01.756512 test begin: paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.315263032913208 	 0.3136723041534424 	 0.3000650405883789 	 0.16018891334533691 	 0.3128376007080078 	 0.07631325721740723 	 0.25510191917419434 	 6.842613220214844e-05 	 
2025-07-30 21:56:03.870355 test begin: paddle.hstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.979090690612793 	 1.4010295867919922 	 0.9609427452087402 	 1.3798224925994873 	 0.9596498012542725 	 0.07808780670166016 	 0.8884832859039307 	 4.553794860839844e-05 	 
2025-07-30 21:56:11.009796 test begin: paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9272878170013428 	 1.0321547985076904 	 0.9094524383544922 	 1.0168540477752686 	 0.9418394565582275 	 0.10978341102600098 	 0.8709766864776611 	 0.00010180473327636719 	 
2025-07-30 21:56:17.286985 test begin: paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.hstack 	 paddle.hstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3084571361541748 	 0.31566429138183594 	 0.29349398612976074 	 0.16015362739562988 	 0.3286139965057373 	 0.07648444175720215 	 0.2709989547729492 	 0.00010585784912109375 	 
2025-07-30 21:56:19.457868 test begin: paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 1],"float32"), ) 	 50803220 	 1000 	 0.9637112617492676 	 0.32450222969055176 	 0.24563241004943848 	 0.3100712299346924 	 1.112962007522583 	 1.836364984512329 	 0.22742509841918945 	 0.31417393684387207 	 
2025-07-30 21:56:25.536775 test begin: paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 1.4804327487945557 	 0.44793081283569336 	 0.3778975009918213 	 0.43612170219421387 	 1.6631553173065186 	 1.7940402030944824 	 0.33960533142089844 	 0.4598820209503174 	 
2025-07-30 21:56:33.626798 test begin: paddle.hypot(Tensor([2540161, 20],"float32"), Tensor([2540161, 20],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([2540161, 20],"float32"), Tensor([2540161, 20],"float32"), ) 	 101606440 	 1000 	 1.4803693294525146 	 0.6765859127044678 	 0.3778982162475586 	 0.4336225986480713 	 1.6604349613189697 	 1.794201135635376 	 0.33961033821105957 	 0.4588456153869629 	 
2025-07-30 21:56:42.895003 test begin: paddle.hypot(Tensor([50803201],"float32"), Tensor([1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([50803201],"float32"), Tensor([1],"float32"), ) 	 50803202 	 1000 	 0.961200475692749 	 0.3147926330566406 	 0.24568915367126465 	 0.2944936752319336 	 1.0611193180084229 	 1.807253360748291 	 0.21770215034484863 	 0.3066587448120117 	 
2025-07-30 21:56:48.711364 test begin: paddle.hypot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 1.4813706874847412 	 0.4593479633331299 	 0.3790464401245117 	 0.43590831756591797 	 1.6602232456207275 	 1.7945165634155273 	 0.3395202159881592 	 0.4601709842681885 	 
2025-07-30 21:56:56.819017 test begin: paddle.hypot(Tensor([5080321, 10],"float32"), Tensor([5080321, 1],"float32"), )
[Prof] paddle.hypot 	 paddle.hypot(Tensor([5080321, 10],"float32"), Tensor([5080321, 1],"float32"), ) 	 55883531 	 1000 	 1.0140106678009033 	 0.35086965560913086 	 0.259082555770874 	 0.3091881275177002 	 1.2995903491973877 	 2.0965492725372314 	 0.3314211368560791 	 0.42797255516052246 	 
2025-07-30 21:57:06.129417 test begin: paddle.i0(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.4688453674316406 	 0.4109532833099365 	 0.4522058963775635 	 0.39636826515197754 	 0.44727563858032227 	 0.854569673538208 	 0.38445043563842773 	 0.43667125701904297 	 
2025-07-30 21:57:10.252799 test begin: paddle.i0(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.4670989513397217 	 0.4084908962249756 	 0.4577600955963135 	 0.39823436737060547 	 0.44591856002807617 	 0.8557844161987305 	 0.3916776180267334 	 0.4365537166595459 	 
2025-07-30 21:57:14.132050 test begin: paddle.i0(Tensor([25401601],"float64"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.49568700790405273 	 0.46585702896118164 	 0.48671770095825195 	 0.45537638664245605 	 0.5143179893493652 	 0.9157974720001221 	 0.4606027603149414 	 0.4678955078125 	 
2025-07-30 21:57:17.575414 test begin: paddle.i0(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.46552538871765137 	 0.4127840995788574 	 0.45323824882507324 	 0.39831066131591797 	 0.4460134506225586 	 0.8556594848632812 	 0.39081859588623047 	 0.4378030300140381 	 
2025-07-30 21:57:21.405053 test begin: paddle.i0(Tensor([50803201],"float32"), )
[Prof] paddle.i0 	 paddle.i0(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.46830034255981445 	 0.41294312477111816 	 0.45909595489501953 	 0.39809131622314453 	 0.4461078643798828 	 0.8557415008544922 	 0.3917577266693115 	 0.4378962516784668 	 
2025-07-30 21:57:25.308524 test begin: paddle.i0e(Tensor([25401601],"float64"), )
[Prof] paddle.i0e 	 paddle.i0e(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.39392900466918945 	 0.36794424057006836 	 0.384904146194458 	 0.35468029975891113 	 0.5898137092590332 	 2.0035018920898438 	 0.5360517501831055 	 0.40932774543762207 	 
2025-07-30 21:57:29.745957 test begin: paddle.i0e(Tensor([50803201],"float32"), )
[Prof] paddle.i0e 	 paddle.i0e(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.42831921577453613 	 0.3674499988555908 	 0.4190359115600586 	 0.3572237491607666 	 0.5881659984588623 	 1.93233323097229 	 0.5322699546813965 	 0.3958933353424072 	 
2025-07-30 21:57:34.736880 test begin: paddle.i1(Tensor([25401601],"float64"), )
[Prof] paddle.i1 	 paddle.i1(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.49961233139038086 	 0.4930450916290283 	 0.4909353256225586 	 0.46140432357788086 	 0.6038124561309814 	 3.210838556289673 	 0.5495681762695312 	 0.2976388931274414 	 

2025-07-30 19:24:20.637098 test begin: paddle.i1(Tensor([50803201],"float32"), )
W0730 19:24:21.596858 23681 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.i1 	 paddle.i1(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.33649563789367676 	 0.41385316848754883 	 0.3274097442626953 	 0.40193676948547363 	 0.5891978740692139 	 3.3414411544799805 	 0.5343296527862549 	 0.3104109764099121 	 
2025-07-30 19:24:27.747929 test begin: paddle.i1e(Tensor([25401601],"float64"), )
[Prof] paddle.i1e 	 paddle.i1e(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.395890474319458 	 0.3741335868835449 	 0.3850739002227783 	 0.36383676528930664 	 0.5896651744842529 	 3.8477532863616943 	 0.5357389450073242 	 0.30289316177368164 	 
2025-07-30 19:24:34.056169 test begin: paddle.i1e(Tensor([50803201],"float32"), )
[Prof] paddle.i1e 	 paddle.i1e(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.31437230110168457 	 0.3234410285949707 	 0.3057386875152588 	 0.2869753837585449 	 0.5873522758483887 	 4.047314167022705 	 0.5338037014007568 	 0.3182663917541504 	 
2025-07-30 19:24:43.401943 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([7576, 13412],"bfloat16"), Tensor([7576, 13412],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
/usr/local/lib/python3.10/dist-packages/paddle/incubate/nn/functional/fused_dropout_add.py:100: UserWarning: Currently, fused_dropout_add maybe has precision problem, so it falls back to dropout + add. 
  warnings.warn(
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([7576, 13412],"bfloat16"), Tensor([7576, 13412],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203218624 	 1000 	 0.4493570327758789 	 0.4503777027130127 	 0.43798398971557617 	 0.4279305934906006 	 0.9633443355560303 	 0.45371317863464355 	 0.8977446556091309 	 0.37548828125 	 combined
2025-07-30 19:24:50.786881 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([7712, 13176],"bfloat16"), Tensor([7712, 13176],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([7712, 13176],"bfloat16"), Tensor([7712, 13176],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203226624 	 1000 	 0.449937105178833 	 0.45824646949768066 	 0.4371147155761719 	 0.4276447296142578 	 0.9631857872009277 	 0.4537384510040283 	 0.8967838287353516 	 0.37590789794921875 	 combined
2025-07-30 19:25:02.087285 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([79381, 1280],"bfloat16"), Tensor([79381, 1280],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([79381, 1280],"bfloat16"), Tensor([79381, 1280],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203215360 	 1000 	 0.44933056831359863 	 0.45046305656433105 	 0.43011927604675293 	 0.4172236919403076 	 0.9633710384368896 	 0.45375990867614746 	 0.8873562812805176 	 0.34657931327819824 	 combined
2025-07-30 19:25:09.189582 test begin: paddle.incubate.nn.functional.fused_dropout_add(Tensor([8168, 12440],"bfloat16"), Tensor([8168, 12440],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, )
[Prof] paddle.incubate.nn.functional.fused_dropout_add 	 paddle.incubate.nn.functional.fused_dropout_add(Tensor([8168, 12440],"bfloat16"), Tensor([8168, 12440],"bfloat16"), p=0.0, training=True, mode="upscale_in_train", name=None, ) 	 203219840 	 1000 	 0.4489600658416748 	 0.4504435062408447 	 0.43750643730163574 	 0.4280390739440918 	 0.9632837772369385 	 0.45361828804016113 	 0.8963465690612793 	 0.3703789710998535 	 combined
2025-07-30 19:25:16.698478 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 14176, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0730 19:25:33.090901 24851 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 14176, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 193376768 	 1000 	 10.647461414337158 	 10.72502613067627 	 10.620151042938232 	 10.686765432357788 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:26:08.063241 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 12404],"bfloat16"), Tensor([12404, 8192],"bfloat16"), None, False, None, )
W0730 19:26:16.152588 25120 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 12404],"bfloat16"), Tensor([12404, 8192],"bfloat16"), None, False, None, ) 	 152420352 	 1000 	 5.192773818969727 	 5.2939980030059814 	 2.658259868621826 	 2.7099504470825195 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:26:32.365617 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 16384],"bfloat16"), Tensor([16384, 6202],"bfloat16"), None, False, None, )
W0730 19:26:41.031463 25210 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 16384],"bfloat16"), Tensor([16384, 6202],"bfloat16"), None, False, None, ) 	 168722432 	 1000 	 5.773562908172607 	 5.785380125045776 	 2.9494564533233643 	 2.956061363220215 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:26:59.169751 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 24807],"bfloat16"), Tensor([24807, 8192],"bfloat16"), None, False, None, )
W0730 19:27:23.047755 25310 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 24807],"bfloat16"), Tensor([24807, 8192],"bfloat16"), None, False, None, ) 	 304828416 	 1000 	 18.793028116226196 	 21.17336130142212 	 9.606534719467163 	 10.8089280128479 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:28:32.048440 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 8192],"bfloat16"), Tensor([8192, 12404],"bfloat16"), None, transpose_weight=False, )
W0730 19:28:40.441067 26094 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 4096, 8192],"bfloat16"), Tensor([8192, 12404],"bfloat16"), None, transpose_weight=False, ) 	 135168000 	 1000 	 5.561621189117432 	 5.600602626800537 	 5.545129060745239 	 5.570605993270874 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:28:58.244646 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 6202, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, )
W0730 19:29:09.411321 26176 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 6202, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, ) 	 235831296 	 1000 	 6.8669562339782715 	 6.884832382202148 	 6.851484537124634 	 6.851248264312744 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:29:30.848764 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 12404],"bfloat16"), Tensor([12404, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0730 19:29:52.346063 26673 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 12404],"bfloat16"), Tensor([12404, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 260397568 	 1000 	 16.055824041366577 	 16.31493091583252 	 16.03939914703369 	 16.281351566314697 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:30:41.359043 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 7168],"bfloat16"), Tensor([7168, 14176],"bfloat16"), Tensor([14176],"bfloat16"), )
W0730 19:30:52.434466 26890 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([1, 8192, 7168],"bfloat16"), Tensor([7168, 14176],"bfloat16"), Tensor([14176],"bfloat16"), ) 	 160348000 	 1000 	 6.9922776222229 	 6.997086048126221 	 6.973302602767944 	 6.962958097457886 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:31:14.193399 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([2, 4096, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, )
W0730 19:31:28.338732 27387 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([2, 4096, 16384],"bfloat16"), Tensor([16384, 8192],"bfloat16"), None, False, None, ) 	 268435456 	 1000 	 8.776388883590698 	 8.773200750350952 	 8.753245830535889 	 8.732692241668701 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:31:57.271808 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([2, 8192, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), )
W0730 19:32:15.888860 27526 backward.cc:462] While running Node (FusedGemmEpilogueGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([2, 8192, 7168],"bfloat16"), Tensor([7168, 12800],"bfloat16"), Tensor([12800],"bfloat16"), ) 	 209203712 	 1000 	 12.319812774658203 	 12.307136535644531 	 12.299024105072021 	 12.270486831665039 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:32:54.305842 test begin: paddle.incubate.nn.functional.fused_linear(Tensor([4, 4096, 8192],"bfloat16"), Tensor([8192, 100352],"bfloat16"), None, transpose_weight=False, )
W0730 19:35:24.108626 27689 backward.cc:462] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.fused_linear 	 paddle.incubate.nn.functional.fused_linear(Tensor([4, 4096, 8192],"bfloat16"), Tensor([8192, 100352],"bfloat16"), None, transpose_weight=False, ) 	 956301312 	 1000 	 111.01500916481018 	 112.14124345779419 	 110.96045970916748 	 112.07296252250671 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:41:14.616120 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([40, 50],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([40, 50],"float32"), None, False, True, ) 	 50805250 	 1000 	 0.47244787216186523 	 0.4724299907684326 	 0.45949459075927734 	 0.44500303268432617 	 0.904660701751709 	 0.9026491641998291 	 0.30845117568969727 	 0.3083188533782959 	 
2025-07-30 19:41:18.960413 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([50, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1016065, 50],"float32"), Tensor([50, 40],"float32"), None, False, False, ) 	 50805250 	 1000 	 0.4664018154144287 	 0.4664490222930908 	 0.45127391815185547 	 0.446108341217041 	 0.9098200798034668 	 0.9083292484283447 	 0.309999942779541 	 0.3100316524505615 	 
2025-07-30 19:41:23.175372 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1270081, 30],"float32"), Tensor([40, 1270081],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1270081, 30],"float32"), Tensor([40, 1270081],"float32"), None, True, True, ) 	 88905670 	 1000 	 0.3962259292602539 	 0.39459800720214844 	 0.20242524147033691 	 0.20157599449157715 	 0.6947760581970215 	 0.699352502822876 	 0.1777944564819336 	 0.17877984046936035 	 
2025-07-30 19:41:26.781082 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1693441, 30],"float32"), Tensor([40, 1693441],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([1693441, 30],"float32"), Tensor([40, 1693441],"float32"), None, True, True, ) 	 118540870 	 1000 	 0.520195484161377 	 0.5175626277923584 	 0.2657902240753174 	 0.26444578170776367 	 0.9203507900238037 	 0.9193379878997803 	 0.23698806762695312 	 0.23641538619995117 	 
2025-07-30 19:41:34.050998 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([1270081, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([1270081, 40],"float32"), None, False, False, ) 	 88905670 	 1000 	 0.41846609115600586 	 0.41467928886413574 	 0.21378731727600098 	 0.21189093589782715 	 0.725252628326416 	 0.7289984226226807 	 0.18527674674987793 	 0.18617010116577148 	 
2025-07-30 19:41:41.430073 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([40, 1270081],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1270081],"float32"), Tensor([40, 1270081],"float32"), None, False, True, ) 	 88905670 	 1000 	 0.40462303161621094 	 0.4030497074127197 	 0.20671701431274414 	 0.20592284202575684 	 0.6805331707000732 	 0.6875438690185547 	 0.17386603355407715 	 0.17560887336730957 	 
2025-07-30 19:41:45.104231 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([1693441, 40],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([1693441, 40],"float32"), None, False, False, ) 	 118540870 	 1000 	 0.5424425601959229 	 0.53737473487854 	 0.2771182060241699 	 0.27457594871520996 	 0.9574432373046875 	 0.9551365375518799 	 0.24460911750793457 	 0.24426579475402832 	 
2025-07-30 19:41:50.014538 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([40, 1693441],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 1693441],"float32"), Tensor([40, 1693441],"float32"), None, False, True, ) 	 118540870 	 1000 	 0.5309700965881348 	 0.5287208557128906 	 0.271284818649292 	 0.2701597213745117 	 0.9050583839416504 	 0.9082996845245361 	 0.23248052597045898 	 0.2329714298248291 	 
2025-07-30 19:41:54.838500 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([1016065, 50],"float32"), None, False, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([1016065, 50],"float32"), None, False, True, ) 	 50804750 	 1000 	 0.30239105224609375 	 0.3039724826812744 	 0.27692699432373047 	 0.2744870185852051 	 0.62788987159729 	 0.6309607028961182 	 0.21372056007385254 	 0.21465682983398438 	 
2025-07-30 19:41:58.119982 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([50, 1016065],"float32"), None, False, False, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([30, 50],"float32"), Tensor([50, 1016065],"float32"), None, False, False, ) 	 50804750 	 1000 	 0.3038036823272705 	 0.29332399368286133 	 0.2753450870513916 	 0.26085495948791504 	 0.6484882831573486 	 0.6508326530456543 	 0.22075319290161133 	 0.22140955924987793 	 
2025-07-30 19:42:01.337837 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 1016065],"float32"), Tensor([40, 50],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 1016065],"float32"), Tensor([40, 50],"float32"), None, True, True, ) 	 50805250 	 1000 	 0.4602060317993164 	 0.4612846374511719 	 0.4391965866088867 	 0.4080030918121338 	 0.8887302875518799 	 0.8843472003936768 	 0.3026726245880127 	 0.3009607791900635 	 
2025-07-30 19:42:05.508445 test begin: paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 30],"float32"), Tensor([1016065, 50],"float32"), None, True, True, )
[Prof] paddle.incubate.nn.functional.fused_matmul_bias 	 paddle.incubate.nn.functional.fused_matmul_bias(Tensor([50, 30],"float32"), Tensor([1016065, 50],"float32"), None, True, True, ) 	 50804750 	 1000 	 0.30155420303344727 	 0.3041098117828369 	 0.2800469398498535 	 0.2559540271759033 	 0.6550583839416504 	 0.6545255184173584 	 0.22296714782714844 	 0.22270441055297852 	 
2025-07-30 19:42:08.770503 test begin: paddle.incubate.nn.functional.swiglu(Tensor([14176, 7168],"bfloat16"), )
W0730 19:42:11.414460 31424 backward.cc:462] While running Node (SwigluGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (bfloat16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():16 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.incubate.nn.functional.swiglu 	 paddle.incubate.nn.functional.swiglu(Tensor([14176, 7168],"bfloat16"), ) 	 101613568 	 1000 	 0.22992157936096191 	 0.5227131843566895 	 0.21340298652648926 	 0.26703715324401855 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:42:13.708571 test begin: paddle.incubate.segment_max(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_max" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_max" instead.
    Reason: paddle.incubate.segment_max will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_max" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_max" instead.
    Reason: paddle.incubate.segment_max will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_max 	 paddle.incubate.segment_max(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 1.1122550964355469 	 1.2419588565826416 	 0.0010867118835449219 	 0.0003345012664794922 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:42:18.498910 test begin: paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_mean" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_mean" instead.
    Reason: paddle.incubate.segment_mean will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_mean 	 paddle.incubate.segment_mean(Tensor([301, 16934],"float32"), Tensor([301],"int32"), ) 	 5097435 	 1000 	 0.08281421661376953 	 0.273221492767334 	 5.507469177246094e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:42:25.383521 test begin: paddle.incubate.segment_min(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_min" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_min" instead.
    Reason: paddle.incubate.segment_min will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_min" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_min" instead.
    Reason: paddle.incubate.segment_min will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_min 	 paddle.incubate.segment_min(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 1.0282435417175293 	 1.070342779159546 	 0.001001596450805664 	 0.0002257823944091797 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:42:29.770987 test begin: paddle.incubate.segment_sum(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:130: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_sum" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_sum" instead.
    Reason: paddle.incubate.segment_sum will be removed in future [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/paddle_torch_gpu_performance.py:148: VisibleDeprecationWarning: [93m
Warning:
API "paddle.incubate.tensor.math.segment_sum" is deprecated since 2.4.0, and will be removed in future versions. Please use "paddle.geometric.segment_sum" instead.
    Reason: paddle.incubate.segment_sum will be removed in future [0m
  self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[Prof] paddle.incubate.segment_sum 	 paddle.incubate.segment_sum(Tensor([3, 16934401],"float32"), Tensor([3],"int32"), ) 	 50803206 	 1000 	 0.526557445526123 	 0.5105946063995361 	 0.0004940032958984375 	 0.2608306407928467 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:42:32.544659 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([1013, 1, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([1013, 1, 224, 224],"float32"), ) 	 50828288 	 1000 	 0.2636294364929199 	 0.6206772327423096 	 0.25467610359191895 	 0.15598130226135254 	 0.3264892101287842 	 0.8938002586364746 	 0.2752702236175537 	 0.45664191246032715 	 combined
2025-07-30 19:42:39.536856 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([145, 7, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([145, 7, 224, 224],"float32"), ) 	 50928640 	 1000 	 0.2734506130218506 	 0.6300704479217529 	 0.25323939323425293 	 0.1563248634338379 	 0.3312218189239502 	 0.8957147598266602 	 0.2700471878051758 	 0.4576222896575928 	 combined
2025-07-30 19:42:45.636629 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([3, 338, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([3, 338, 224, 224],"float32"), ) 	 50878464 	 1000 	 0.26216745376586914 	 0.6163673400878906 	 0.24688291549682617 	 0.15606188774108887 	 0.330822229385376 	 0.8948028087615967 	 0.27050256729125977 	 0.45715975761413574 	 combined
2025-07-30 19:42:49.434608 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([4511, 11, 32, 32],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([4511, 11, 32, 32],"float32"), ) 	 50811904 	 1000 	 0.7487385272979736 	 0.6762022972106934 	 0.7393510341644287 	 0.173051118850708 	 0.44907188415527344 	 0.8941271305084229 	 0.3978452682495117 	 0.45682525634765625 	 combined
2025-07-30 19:42:53.927172 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([5, 203, 224, 224],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([5, 203, 224, 224],"float32"), ) 	 50928640 	 1000 	 0.2625124454498291 	 0.6105272769927979 	 0.24689984321594238 	 0.15620803833007812 	 0.33113932609558105 	 0.8955700397491455 	 0.27069640159606934 	 0.45755553245544434 	 combined
2025-07-30 19:42:57.656164 test begin: paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 7088, 32, 32],"float32"), )
[Prof] paddle.incubate.softmax_mask_fuse_upper_triangle 	 paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 7088, 32, 32],"float32"), ) 	 50806784 	 1000 	 0.7474863529205322 	 0.6762497425079346 	 0.7321741580963135 	 0.1730513572692871 	 0.44901394844055176 	 0.8940443992614746 	 0.38509082794189453 	 0.45680904388427734 	 combined
2025-07-30 19:43:02.078233 test begin: paddle.index_add(Tensor([100, 100, 25402],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 25402],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 25402],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 25402],"float32"), ) 	 304824020 	 1000 	 1.9947972297668457 	 3.829404830932617 	 0.6786117553710938 	 8.940696716308594e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:43:19.367254 test begin: paddle.index_add(Tensor([100, 100, 25],"float32"), Tensor([5081],"int32"), 2, Tensor([100, 100, 5081],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 25],"float32"), Tensor([5081],"int32"), 2, Tensor([100, 100, 5081],"float32"), ) 	 51065081 	 1000 	 1.7709016799926758 	 406.2388231754303 	 0.9049053192138672 	 0.00021886825561523438 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:09.497441 test begin: paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5081],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5081],"float32"), ) 	 60972020 	 1000 	 0.4086344242095947 	 2.3374059200286865 	 0.1389784812927246 	 6.985664367675781e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:14.504381 test begin: paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 2, Tensor([100, 100, 20],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 100, 5081],"float32"), Tensor([20],"int32"), 2, Tensor([100, 100, 20],"float32"), ) 	 51010020 	 1000 	 0.3424811363220215 	 2.3637421131134033 	 0.11642098426818848 	 0.0002090930938720703 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:20.637075 test begin: paddle.index_add(Tensor([100, 101607, 5],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 101607, 5],"float32"), Tensor([20],"int32"), 1, Tensor([100, 20, 5],"float32"), ) 	 50813520 	 1000 	 0.31140804290771484 	 1.7986900806427002 	 0.10583901405334473 	 0.00017023086547851562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:24.748786 test begin: paddle.index_add(Tensor([100, 2540161],"float32"), Tensor([20],"int32"), 0, Tensor([20, 2540161],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 2540161],"float32"), Tensor([20],"int32"), 0, Tensor([20, 2540161],"float32"), ) 	 304819340 	 1000 	 1.9962193965911865 	 3.564432382583618 	 0.6791510581970215 	 0.00022482872009277344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:44.245516 test begin: paddle.index_add(Tensor([100, 508033],"float32"), Tensor([20],"int32"), 0, Tensor([20, 508033],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([100, 508033],"float32"), Tensor([20],"int32"), 0, Tensor([20, 508033],"float32"), ) 	 60963980 	 1000 	 0.40293073654174805 	 2.2936880588531494 	 0.1370832920074463 	 8.726119995117188e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:49.232049 test begin: paddle.index_add(Tensor([10160641, 5],"float32"), Tensor([20],"int32"), 0, Tensor([20, 5],"float32"), )
[Prof] paddle.index_add 	 paddle.index_add(Tensor([10160641, 5],"float32"), Tensor([20],"int32"), 0, Tensor([20, 5],"float32"), ) 	 50803325 	 1000 	 0.31810808181762695 	 2.30667781829834 	 0.10818362236022949 	 9.179115295410156e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:53.825306 test begin: paddle.index_fill(Tensor([10, 1016065, 10],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 1016065, 10],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606505 	 1000 	 0.8288812637329102 	 0.3170771598815918 	 0.0005860328674316406 	 0.10773706436157227 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:50:59.679431 test begin: paddle.index_fill(Tensor([10, 15, 169345],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 169345],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401755 	 1000 	 1.003086805343628 	 0.36963582038879395 	 0.06370854377746582 	 0.1256694793701172 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:02.942804 test begin: paddle.index_fill(Tensor([10, 15, 338689],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 338689],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803355 	 1000 	 0.9130749702453613 	 1.251016616821289 	 0.0007803440093994141 	 0.05789446830749512 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:07.899514 test begin: paddle.index_fill(Tensor([10, 15, 677377],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 15, 677377],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606555 	 1000 	 2.2671525478363037 	 0.48489999771118164 	 0.0018925666809082031 	 0.16495156288146973 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:17.386585 test begin: paddle.index_fill(Tensor([10, 254017, 10],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 254017, 10],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401705 	 1000 	 0.6589310169219971 	 0.3171370029449463 	 0.044756412506103516 	 0.10778284072875977 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:19.841844 test begin: paddle.index_fill(Tensor([10, 508033, 10],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([10, 508033, 10],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803305 	 1000 	 0.34130859375 	 0.7558383941650391 	 0.00016188621520996094 	 0.02980327606201172 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:23.394897 test begin: paddle.index_fill(Tensor([169345, 15, 10],"int64"), Tensor([5],"int32"), 1, -1, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([169345, 15, 10],"int64"), Tensor([5],"int32"), 1, -1, ) 	 25401755 	 1000 	 1.09999680519104 	 0.4661240577697754 	 0.06987643241882324 	 0.15859723091125488 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:27.987931 test begin: paddle.index_fill(Tensor([338689, 15, 10],"bool"), Tensor([5],"int32"), 1, True, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([338689, 15, 10],"bool"), Tensor([5],"int32"), 1, True, ) 	 50803355 	 1000 	 1.0882151126861572 	 0.16634583473205566 	 0.0009491443634033203 	 0.056569576263427734 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:31.801832 test begin: paddle.index_fill(Tensor([677377, 15, 10],"float16"), Tensor([5],"int64"), 1, 0.5, )
[Prof] paddle.index_fill 	 paddle.index_fill(Tensor([677377, 15, 10],"float16"), Tensor([5],"int64"), 1, 0.5, ) 	 101606555 	 1000 	 2.4487650394439697 	 0.539304256439209 	 0.0023093223571777344 	 0.17504525184631348 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:41.141059 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25628144 	 1000 	 0.3649294376373291 	 0.4506220817565918 	 0.021890878677368164 	 0.012186288833618164 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:43.831049 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, ) 	 25628144 	 1000 	 0.35755443572998047 	 0.33732008934020996 	 0.026093244552612305 	 0.08389782905578613 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:45.956984 test begin: paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 42, 99, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25628144 	 1000 	 0.3575921058654785 	 0.43883347511291504 	 0.026090383529663086 	 0.012958288192749023 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:48.192715 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25541904 	 1000 	 0.35764265060424805 	 0.45017004013061523 	 0.021448850631713867 	 0.01215219497680664 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:50.475576 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), False, ) 	 25541904 	 1000 	 0.3494706153869629 	 0.32948875427246094 	 0.025502443313598633 	 0.08360838890075684 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:52.574688 test begin: paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([110, 74, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25541904 	 1000 	 0.3495192527770996 	 0.440096378326416 	 0.02550482749938965 	 0.01301717758178711 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:54.791685 test begin: paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([1, 16],"int32"),), Tensor([16, 16, 56],"float64"), True, ) 	 25435280 	 1000 	 0.35605430603027344 	 0.4473690986633301 	 0.021364212036132812 	 0.01210784912109375 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:57.078776 test begin: paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, )
[Prof] paddle.index_put 	 paddle.index_put(Tensor([193, 42, 56, 56],"float64"), tuple(Tensor([16, 16],"int64"),Tensor([16, 16],"int64"),Tensor([1, 16],"int64"),), Tensor([16, 16, 56],"float64"), True, ) 	 25435280 	 1000 	 0.34787654876708984 	 0.43628859519958496 	 0.02538919448852539 	 0.012986898422241211 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:51:59.312394 test begin: paddle.index_sample(Tensor([1865664, 100],"float32"), Tensor([1865664, 14],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 100],"float32"), Tensor([1865664, 14],"int64"), ) 	 212685696 	 1000 	 0.7489039897918701 	 1.1392123699188232 	 0.740619421005249 	 0.3883373737335205 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:52:06.703690 test begin: paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 14],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 14],"int64"), ) 	 78357888 	 1000 	 0.523972749710083 	 0.8028178215026855 	 0.5157501697540283 	 0.2736623287200928 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:52:10.259795 test begin: paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([1865664, 28],"float32"), Tensor([1865664, 1],"int64"), ) 	 54104256 	 1000 	 0.41476917266845703 	 0.15651559829711914 	 0.40651440620422363 	 0.07858395576477051 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:52:12.214794 test begin: paddle.index_sample(Tensor([25401601, 100],"float32"), Tensor([25401601, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([25401601, 100],"float32"), Tensor([25401601, 1],"int64"), ) 	 2565561701 	 1000 	 4.539587020874023 	 2.094698905944824 	 4.5314040184021 	 1.0702524185180664 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:14.675613 test begin: paddle.index_sample(Tensor([25401601, 20],"float32"), Tensor([25401601, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([25401601, 20],"float32"), Tensor([25401601, 1],"int64"), ) 	 533433621 	 1000 	 4.3297669887542725 	 2.040055274963379 	 4.321481227874756 	 0.9175279140472412 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:38.717804 test begin: paddle.index_sample(Tensor([2540161, 20],"float32"), Tensor([2540161, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([2540161, 20],"float32"), Tensor([2540161, 1],"int64"), ) 	 53343381 	 1000 	 0.5382380485534668 	 0.2132730484008789 	 0.5299282073974609 	 0.10138583183288574 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:41.432305 test begin: paddle.index_sample(Tensor([508033, 100],"float32"), Tensor([508033, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([508033, 100],"float32"), Tensor([508033, 1],"int64"), ) 	 51311333 	 1000 	 0.11936306953430176 	 0.052756547927856445 	 0.11107635498046875 	 0.007203817367553711 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:44.297657 test begin: paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 1],"int64"), ) 	 56488256 	 1000 	 0.9572439193725586 	 0.31736230850219727 	 0.9486870765686035 	 0.16205859184265137 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:47.443437 test begin: paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 5],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 10],"float32"), Tensor([5135296, 5],"int64"), ) 	 77029440 	 1000 	 1.0648424625396729 	 0.8634707927703857 	 1.05625581741333 	 0.2933657169342041 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:52.019975 test begin: paddle.index_sample(Tensor([5135296, 20],"float32"), Tensor([5135296, 5],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([5135296, 20],"float32"), Tensor([5135296, 5],"int64"), ) 	 128382400 	 1000 	 1.1134121417999268 	 0.9927968978881836 	 1.1050071716308594 	 0.33721375465393066 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:53:57.940845 test begin: paddle.index_sample(Tensor([932832, 100],"float32"), Tensor([932832, 28],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 100],"float32"), Tensor([932832, 28],"int64"), ) 	 119402496 	 1000 	 0.5063571929931641 	 0.8792955875396729 	 0.4979093074798584 	 0.29982614517211914 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:02.578100 test begin: paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 1],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 1],"int64"), ) 	 52238592 	 1000 	 0.21262764930725098 	 0.08726072311401367 	 0.20407438278198242 	 0.04026341438293457 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:04.085004 test begin: paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 28],"int64"), )
[Prof] paddle.index_sample 	 paddle.index_sample(Tensor([932832, 55],"float32"), Tensor([932832, 28],"int64"), ) 	 77425056 	 1000 	 0.3896322250366211 	 0.7782609462738037 	 0.3810579776763916 	 0.26537370681762695 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:07.409127 test begin: paddle.index_select(Tensor([16, 11109, 286],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 11109, 286],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50834864 	 1000 	 0.20212197303771973 	 0.22127652168273926 	 0.19252252578735352 	 0.20710325241088867 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:09.358710 test begin: paddle.index_select(Tensor([16, 12096, 263],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 12096, 263],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50900048 	 1000 	 0.2131037712097168 	 0.23186683654785156 	 0.20363950729370117 	 0.21821951866149902 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:11.446398 test begin: paddle.index_select(Tensor([16, 39201, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([16, 39201, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50804576 	 1000 	 0.6326706409454346 	 0.5603420734405518 	 0.6235001087188721 	 0.5444018840789795 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:15.035267 test begin: paddle.index_select(Tensor([205, 3060, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([205, 3060, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50811380 	 1000 	 0.6328439712524414 	 0.5587279796600342 	 0.6235191822052002 	 0.5450670719146729 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:18.609198 test begin: paddle.index_select(Tensor([52, 12096, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([52, 12096, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50948432 	 1000 	 0.6349074840545654 	 0.5650362968444824 	 0.6257250308990479 	 0.5514492988586426 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:22.193736 test begin: paddle.index_select(Tensor([57, 11109, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([57, 11109, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 51290333 	 1000 	 0.6392045021057129 	 0.5652406215667725 	 0.6299445629119873 	 0.551504373550415 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:25.801133 test begin: paddle.index_select(Tensor([64, 3060, 260],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([64, 3060, 260],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50918480 	 1000 	 0.21525931358337402 	 0.2318253517150879 	 0.20606517791748047 	 0.21810030937194824 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:27.869041 test begin: paddle.index_select(Tensor([64, 9801, 81],"float32"), Tensor([80],"int64"), axis=-1, )
[Prof] paddle.index_select 	 paddle.index_select(Tensor([64, 9801, 81],"float32"), Tensor([80],"int64"), axis=-1, ) 	 50808464 	 1000 	 0.6336648464202881 	 0.5585837364196777 	 0.6243793964385986 	 0.5448482036590576 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:54:31.434947 test begin: paddle.inner(Tensor([20, 1270081],"float64"), Tensor([1270081],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([20, 1270081],"float64"), Tensor([1270081],"float64"), ) 	 26671701 	 1000 	 0.16426301002502441 	 0.16431522369384766 	 0.08382749557495117 	 0.08383870124816895 	 0.362018346786499 	 0.362729549407959 	 0.12323355674743652 	 0.12341952323913574 	 
2025-07-30 19:54:33.070358 test begin: paddle.inner(Tensor([20, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([20, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 533433621 	 1000 	 3.037963390350342 	 3.0342071056365967 	 1.5523149967193604 	 1.5503416061401367 	 6.900291442871094 	 6.85054349899292 	 0.2733273506164551 	 0.268139123916626 	 
2025-07-30 19:55:03.943621 test begin: paddle.inner(Tensor([508033, 50],"float64"), Tensor([50],"float64"), )
[Prof] paddle.inner 	 paddle.inner(Tensor([508033, 50],"float64"), Tensor([50],"float64"), ) 	 25401700 	 1000 	 0.16047191619873047 	 0.1587815284729004 	 0.09134173393249512 	 0.13181138038635254 	 0.38349342346191406 	 0.3769657611846924 	 0.13043999671936035 	 0.12816596031188965 	 
2025-07-30 19:55:05.571412 test begin: paddle.is_complex(Tensor([1003520, 507],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([1003520, 507],"float32"), ) 	 508784640 	 1000 	 0.0037107467651367188 	 0.0017457008361816406 	 5.9604644775390625e-06 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:55:13.855181 test begin: paddle.is_complex(Tensor([5070, 100352],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([5070, 100352],"float32"), ) 	 508784640 	 1000 	 0.0037126541137695312 	 0.0017161369323730469 	 9.059906005859375e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:55:21.919151 test begin: paddle.is_complex(Tensor([62020, 8192],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([62020, 8192],"float32"), ) 	 508067840 	 1000 	 0.004431962966918945 	 0.002095937728881836 	 1.1920928955078125e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:55:31.615861 test begin: paddle.is_complex(Tensor([81920, 6202],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([81920, 6202],"float32"), ) 	 508067840 	 1000 	 0.004469871520996094 	 0.0021696090698242188 	 1.4781951904296875e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:55:40.596314 test begin: paddle.is_complex(Tensor([8860, 57344],"float32"), )
[Prof] paddle.is_complex 	 paddle.is_complex(Tensor([8860, 57344],"float32"), ) 	 508067840 	 1000 	 0.0037140846252441406 	 0.0017528533935546875 	 7.62939453125e-06 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:55:48.621203 test begin: paddle.is_empty(Tensor([101606410, 5],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([101606410, 5],"float32"), ) 	 508032050 	 1000 	 0.003640413284301758 	 0.0015628337860107422 	 7.62939453125e-06 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:55:58.860384 test begin: paddle.is_empty(Tensor([169344010, 3],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([169344010, 3],"float32"), ) 	 508032030 	 1000 	 0.0036106109619140625 	 0.0015022754669189453 	 9.298324584960938e-06 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:56:07.951911 test begin: paddle.is_empty(Tensor([20, 25401601],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([20, 25401601],"float32"), ) 	 508032020 	 1000 	 0.008390426635742188 	 0.0021202564239501953 	 4.00543212890625e-05 	 2.1696090698242188e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:56:17.305728 test begin: paddle.is_empty(Tensor([30, 16934401],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(Tensor([30, 16934401],"float32"), ) 	 508032030 	 1000 	 0.0035746097564697266 	 0.001524209976196289 	 7.62939453125e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:56:25.440263 test begin: paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 32, 396901],"float32"), ) 	 508033280 	 1000 	 0.003735065460205078 	 0.0015106201171875 	 1.049041748046875e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:56:33.748266 test begin: paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([40, 396901, 32],"float32"), ) 	 508033280 	 1000 	 0.0037806034088134766 	 0.0015113353729248047 	 1.239776611328125e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:56:41.747265 test begin: paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), )
[Prof] paddle.is_empty 	 paddle.is_empty(x=Tensor([496130, 32, 32],"float32"), ) 	 508037120 	 1000 	 0.0037479400634765625 	 0.0015261173248291016 	 8.106231689453125e-06 	 1.52587890625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:56:49.984165 test begin: paddle.isclose(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), rtol=1e-05, atol=1e-08, )
[Prof] paddle.isclose 	 paddle.isclose(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), rtol=1e-05, atol=1e-08, ) 	 50803220 	 1000 	 0.36353278160095215 	 3.0828206539154053 	 0.35070085525512695 	 0.2418816089630127 	 None 	 None 	 None 	 None 	 
2025-07-30 19:56:54.523788 test begin: paddle.isclose(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), rtol=1e-05, atol=1e-08, )
[Prof] paddle.isclose 	 paddle.isclose(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), rtol=1e-05, atol=1e-08, ) 	 50803220 	 1000 	 0.36357998847961426 	 3.0828335285186768 	 0.350954532623291 	 0.24191546440124512 	 None 	 None 	 None 	 None 	 
2025-07-30 19:56:59.024123 test begin: paddle.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), ) 	 50803240 	 1000 	 0.36337971687316895 	 3.082867383956909 	 0.3510396480560303 	 0.24190735816955566 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:05.917084 test begin: paddle.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 0.3634793758392334 	 3.0830228328704834 	 0.3508949279785156 	 0.24185991287231445 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:10.406935 test begin: paddle.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), ) 	 50803230 	 1000 	 0.36351513862609863 	 3.082960844039917 	 0.3510406017303467 	 0.24199533462524414 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:14.956764 test begin: paddle.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.isclose 	 paddle.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), ) 	 50803224 	 1000 	 0.3633275032043457 	 3.082786798477173 	 0.35068321228027344 	 0.24190258979797363 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:19.496836 test begin: paddle.isfinite(Tensor([1738, 94, 311],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([1738, 94, 311],"float32"), ) 	 50808692 	 1000 	 0.23378276824951172 	 0.7887423038482666 	 0.2261979579925537 	 0.20146894454956055 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:21.335681 test begin: paddle.isfinite(Tensor([28462, 17, 5, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([28462, 17, 5, 6, 7],"float16"), ) 	 101609340 	 1000 	 0.39552783966064453 	 0.9722144603729248 	 0.3881239891052246 	 0.2483537197113037 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:24.563777 test begin: paddle.isfinite(Tensor([4, 280, 376, 25, 5],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 376, 25, 5],"float32"), ) 	 52640000 	 1000 	 0.24235773086547852 	 0.8141176700592041 	 0.2348918914794922 	 0.20789337158203125 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:26.466945 test begin: paddle.isfinite(Tensor([4, 280, 376, 41, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 376, 41, 3],"float32"), ) 	 51797760 	 1000 	 0.23906469345092773 	 0.8027844429016113 	 0.2316131591796875 	 0.20500397682189941 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:28.358638 test begin: paddle.isfinite(Tensor([4, 280, 605, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 280, 605, 25, 3],"float32"), ) 	 50820000 	 1000 	 0.2343735694885254 	 0.7887787818908691 	 0.22684741020202637 	 0.201446533203125 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:30.218017 test begin: paddle.isfinite(Tensor([4, 40839, 311],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 40839, 311],"float32"), ) 	 50803716 	 1000 	 0.2340080738067627 	 0.7868504524230957 	 0.2264726161956787 	 0.2009599208831787 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:32.054413 test begin: paddle.isfinite(Tensor([4, 451, 376, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 451, 376, 25, 3],"float32"), ) 	 50872800 	 1000 	 0.23486042022705078 	 0.7882363796234131 	 0.22731924057006836 	 0.2013227939605713 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:33.914654 test begin: paddle.isfinite(Tensor([4, 94, 135115],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([4, 94, 135115],"float32"), ) 	 50803240 	 1000 	 0.23448920249938965 	 0.7893743515014648 	 0.22703886032104492 	 0.2011089324951172 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:37.617561 test begin: paddle.isfinite(Tensor([7, 280, 376, 25, 3],"float32"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([7, 280, 376, 25, 3],"float32"), ) 	 55272000 	 1000 	 0.25519537925720215 	 0.8628270626068115 	 0.2467508316040039 	 0.2181847095489502 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:40.993706 test begin: paddle.isfinite(Tensor([8, 17, 17789, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 17789, 6, 7],"float16"), ) 	 101610768 	 1000 	 0.39536523818969727 	 0.977191686630249 	 0.381101131439209 	 0.24794840812683105 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:44.272462 test begin: paddle.isfinite(Tensor([8, 17, 5, 21346, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 5, 21346, 7],"float16"), ) 	 101606960 	 1000 	 0.3955717086791992 	 0.9711282253265381 	 0.37977004051208496 	 0.24810791015625 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:47.513823 test begin: paddle.isfinite(Tensor([8, 17, 5, 6, 24904],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 17, 5, 6, 24904],"float16"), ) 	 101608320 	 1000 	 0.3955235481262207 	 0.9721910953521729 	 0.38148999214172363 	 0.24831175804138184 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:50.832570 test begin: paddle.isfinite(Tensor([8, 60481, 5, 6, 7],"float16"), )
[Prof] paddle.isfinite 	 paddle.isfinite(Tensor([8, 60481, 5, 6, 7],"float16"), ) 	 101608080 	 1000 	 0.3911247253417969 	 0.9716446399688721 	 0.3767578601837158 	 0.2467195987701416 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:54.102472 test begin: paddle.isin(Tensor([396901, 64],"float64"), Tensor([4, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([396901, 64],"float64"), Tensor([4, 256],"float64"), False, False, ) 	 25402688 	 1000 	 2.727001428604126 	 21.330771446228027 	 0.002490520477294922 	 0.0008709430694580078 	 None 	 None 	 None 	 None 	 
2025-07-30 19:58:18.803149 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, False, ) 	 50804288 	 1000 	 4.454611301422119 	 25.278965711593628 	 0.004241228103637695 	 0.0020401477813720703 	 None 	 None 	 None 	 None 	 
2025-07-30 19:58:49.458224 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([4, 256],"float32"), False, True, ) 	 50804288 	 1000 	 4.5231239795684814 	 25.275872230529785 	 0.004271507263183594 	 0.002041339874267578 	 None 	 None 	 None 	 None 	 
2025-07-30 19:59:20.141103 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, False, ) 	 254016320 	 1000 	 87.4269745349884 	 45.223883390426636 	 0.052687883377075195 	 0.002573251724243164 	 None 	 None 	 None 	 None 	 
2025-07-30 20:01:37.606990 test begin: paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([793801, 64],"float32"), Tensor([793801, 256],"float32"), False, True, ) 	 254016320 	 1000 	 83.60409188270569 	 45.23677062988281 	 0.05250692367553711 	 0.002568960189819336 	 None 	 None 	 None 	 None 	 
2025-07-30 20:03:50.857516 test begin: paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 256],"float64"), False, False, ) 	 25402632 	 1000 	 2.7308719158172607 	 21.318487405776978 	 0.002496004104614258 	 0.0008733272552490234 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:15.547925 test begin: paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 3175201],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 3175201],"float64"), Tensor([4, 3175201],"float64"), False, False, ) 	 38102412 	 1000 	 26.695145845413208 	 27.2167546749115 	 0.017720699310302734 	 0.0009775161743164062 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:10.389992 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, False, ) 	 50804232 	 1000 	 4.444331169128418 	 25.278614282608032 	 0.004209041595458984 	 0.0020341873168945312 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:41.020645 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 256],"float32"), False, True, ) 	 50804232 	 1000 	 4.53060507774353 	 25.272438764572144 	 0.0042879581451416016 	 0.002027750015258789 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:11.723916 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, False, ) 	 76204812 	 1000 	 49.665799140930176 	 29.985718965530396 	 0.03621244430541992 	 0.0022089481353759766 	 None 	 None 	 None 	 None 	 
2025-07-30 20:07:32.731309 test begin: paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 6350401],"float32"), Tensor([4, 6350401],"float32"), False, True, ) 	 76204812 	 1000 	 48.93207931518555 	 29.99419927597046 	 0.03633737564086914 	 0.0022182464599609375 	 None 	 None 	 None 	 None 	 
2025-07-30 20:08:53.162300 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, False, ) 	 50803968 	 1000 	 19.37841296195984 	 8.300201892852783 	 5.7220458984375e-05 	 0.00028514862060546875 	 None 	 None 	 None 	 None 	 
2025-07-30 20:09:21.759833 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([198451, 256],"float32"), False, True, ) 	 50803968 	 1000 	 19.5425226688385 	 8.292259216308594 	 6.103515625e-05 	 0.00027632713317871094 	 None 	 None 	 None 	 None 	 
2025-07-30 20:09:50.699223 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, False, ) 	 50803716 	 1000 	 16.511815786361694 	 8.30373239517212 	 5.626678466796875e-05 	 0.0002789497375488281 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:16.470001 test begin: paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, True, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float32"), Tensor([4, 12700801],"float32"), False, True, ) 	 50803716 	 1000 	 16.523045778274536 	 8.297004222869873 	 5.555152893066406e-05 	 0.0002777576446533203 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:42.264279 test begin: paddle.isin(Tensor([8, 64],"float64"), Tensor([4, 6350401],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float64"), Tensor([4, 6350401],"float64"), False, False, ) 	 25402116 	 1000 	 10.697670221328735 	 12.006864786148071 	 5.364418029785156e-05 	 0.0002357959747314453 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:07.197683 test begin: paddle.isin(Tensor([8, 64],"float64"), Tensor([99226, 256],"float64"), False, False, )
[Prof] paddle.isin 	 paddle.isin(Tensor([8, 64],"float64"), Tensor([99226, 256],"float64"), False, False, ) 	 25402368 	 1000 	 14.386701107025146 	 12.018073081970215 	 5.7220458984375e-05 	 0.00023603439331054688 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:36.958283 test begin: paddle.isinf(Tensor([14, 226801, 16],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 226801, 16],"float32"), ) 	 50803424 	 1000 	 0.23421859741210938 	 0.49121761322021484 	 0.2266998291015625 	 0.24820780754089355 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:39.465004 test begin: paddle.isinf(Tensor([14, 36655, 99],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 36655, 99],"float32"), ) 	 50803830 	 1000 	 0.2328648567199707 	 0.4878246784210205 	 0.22538495063781738 	 0.24814105033874512 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:41.139634 test begin: paddle.isinf(Tensor([14, 64, 56701],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 64, 56701],"float32"), ) 	 50804096 	 1000 	 0.2336738109588623 	 0.485598087310791 	 0.22582769393920898 	 0.24810791015625 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:42.683210 test begin: paddle.isinf(Tensor([14, 7, 518401],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([14, 7, 518401],"float32"), ) 	 50803298 	 1000 	 0.2334756851196289 	 0.4856233596801758 	 0.2259998321533203 	 0.24815583229064941 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:44.217714 test begin: paddle.isinf(Tensor([28462, 17, 5, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([28462, 17, 5, 6, 7],"float16"), ) 	 101609340 	 1000 	 0.38988709449768066 	 0.5205774307250977 	 0.38243532180786133 	 0.26600217819213867 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:47.015124 test begin: paddle.isinf(Tensor([49613, 64, 16],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([49613, 64, 16],"float32"), ) 	 50803712 	 1000 	 0.23391175270080566 	 0.4855506420135498 	 0.22636175155639648 	 0.24808907508850098 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:48.578825 test begin: paddle.isinf(Tensor([73310, 7, 99],"float32"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([73310, 7, 99],"float32"), ) 	 50803830 	 1000 	 0.23285150527954102 	 0.48555755615234375 	 0.225264310836792 	 0.2480909824371338 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:50.113403 test begin: paddle.isinf(Tensor([8, 17, 17789, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 17789, 6, 7],"float16"), ) 	 101610768 	 1000 	 0.3894648551940918 	 0.5205326080322266 	 0.38208723068237305 	 0.26596593856811523 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:53.090490 test begin: paddle.isinf(Tensor([8, 17, 5, 21346, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 5, 21346, 7],"float16"), ) 	 101606960 	 1000 	 0.39040493965148926 	 0.5205950736999512 	 0.3829309940338135 	 0.2660067081451416 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:55.923567 test begin: paddle.isinf(Tensor([8, 17, 5, 6, 24904],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 17, 5, 6, 24904],"float16"), ) 	 101608320 	 1000 	 0.38991713523864746 	 0.52069091796875 	 0.37592315673828125 	 0.26607489585876465 	 None 	 None 	 None 	 None 	 
2025-07-30 20:11:59.191456 test begin: paddle.isinf(Tensor([8, 60481, 5, 6, 7],"float16"), )
[Prof] paddle.isinf 	 paddle.isinf(Tensor([8, 60481, 5, 6, 7],"float16"), ) 	 101608080 	 1000 	 0.3860280513763428 	 0.5205655097961426 	 0.3784952163696289 	 0.2659893035888672 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:02.036180 test begin: paddle.isnan(Tensor([10445, 4864],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([10445, 4864],"float32"), ) 	 50804480 	 1000 	 0.23419451713562012 	 0.18615102767944336 	 0.22635173797607422 	 0.17506861686706543 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:03.326283 test begin: paddle.isnan(Tensor([16, 64, 320, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([16, 64, 320, 320],"float16"), ) 	 104857600 	 1000 	 0.40553808212280273 	 0.23195266723632812 	 0.39775848388671875 	 0.2208695411682129 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:05.936368 test begin: paddle.isnan(Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 125, 320, 320],"float32"), ) 	 51200000 	 1000 	 0.23642992973327637 	 0.18775033950805664 	 0.22865891456604004 	 0.17635107040405273 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:07.183787 test begin: paddle.isnan(Tensor([4, 249, 320, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 249, 320, 320],"float16"), ) 	 101990400 	 1000 	 0.3940005302429199 	 0.22578692436218262 	 0.38625192642211914 	 0.21470928192138672 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:09.669572 test begin: paddle.isnan(Tensor([4, 64, 1241, 320],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 1241, 320],"float16"), ) 	 101662720 	 1000 	 0.39200544357299805 	 0.22590303421020508 	 0.38421201705932617 	 0.21354079246520996 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:12.184074 test begin: paddle.isnan(Tensor([4, 64, 320, 1241],"float16"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 320, 1241],"float16"), ) 	 101662720 	 1000 	 0.3920106887817383 	 0.2250535488128662 	 0.3841116428375244 	 0.21386313438415527 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:14.683471 test begin: paddle.isnan(Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 320, 621],"float32"), ) 	 50872320 	 1000 	 0.23453855514526367 	 0.18637371063232422 	 0.22682666778564453 	 0.17516469955444336 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:15.916306 test begin: paddle.isnan(Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4, 64, 621, 320],"float32"), ) 	 50872320 	 1000 	 0.2345128059387207 	 0.18639016151428223 	 0.22674942016601562 	 0.17529654502868652 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:17.147300 test begin: paddle.isnan(Tensor([4864, 10445],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([4864, 10445],"float32"), ) 	 50804480 	 1000 	 0.23419594764709473 	 0.18614554405212402 	 0.22641968727111816 	 0.17498993873596191 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:18.386755 test begin: paddle.isnan(Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.isnan 	 paddle.isnan(Tensor([8, 64, 320, 320],"float32"), ) 	 52428800 	 1000 	 0.24178838729858398 	 0.19187426567077637 	 0.2339918613433838 	 0.18099117279052734 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:19.660328 test begin: paddle.isneginf(Tensor([11, 17, 2716],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 17, 2716],"int32"), ) 	 507892 	 1000 	 20.068369150161743 	 0.010921001434326172 	 4.9114227294921875e-05 	 2.9325485229492188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:12:39.779145 test begin: paddle.isneginf(Tensor([11, 17, 5433],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 17, 5433],"int16"), ) 	 1015971 	 1000 	 44.130099296569824 	 0.012657642364501953 	 5.5789947509765625e-05 	 4.0531158447265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:13:24.000365 test begin: paddle.isneginf(Tensor([11, 4618, 10],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 4618, 10],"int32"), ) 	 507980 	 1000 	 19.95755100250244 	 0.010896921157836914 	 4.506111145019531e-05 	 2.6941299438476562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:13:43.996757 test begin: paddle.isneginf(Tensor([11, 46184],"float32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 46184],"float32"), ) 	 508024 	 1000 	 19.995039463043213 	 0.010243654251098633 	 5.316734313964844e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:14:04.033602 test begin: paddle.isneginf(Tensor([11, 9236, 10],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([11, 9236, 10],"int16"), ) 	 1015960 	 1000 	 40.16278290748596 	 0.011253118515014648 	 5.221366882324219e-05 	 4.506111145019531e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:14:44.260164 test begin: paddle.isneginf(Tensor([2988, 17, 10],"int32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([2988, 17, 10],"int32"), ) 	 507960 	 1000 	 20.064658641815186 	 0.010930061340332031 	 5.459785461425781e-05 	 3.170967102050781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:15:04.363809 test begin: paddle.isneginf(Tensor([29884, 17],"float32"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([29884, 17],"float32"), ) 	 508028 	 1000 	 20.160468816757202 	 0.010197877883911133 	 4.935264587402344e-05 	 2.8371810913085938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:15:24.565164 test begin: paddle.isneginf(Tensor([5976, 17, 10],"int16"), )
[Prof] paddle.isneginf 	 paddle.isneginf(Tensor([5976, 17, 10],"int16"), ) 	 1015920 	 1000 	 41.040083169937134 	 0.017932891845703125 	 6.628036499023438e-05 	 6.246566772460938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:16:05.681776 test begin: paddle.isposinf(Tensor([11, 17, 2716],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 17, 2716],"int32"), ) 	 507892 	 1000 	 20.257665395736694 	 0.017868518829345703 	 5.1021575927734375e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:16:26.012213 test begin: paddle.isposinf(Tensor([11, 17, 5433],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 17, 5433],"int16"), ) 	 1015971 	 1000 	 40.622050046920776 	 0.011240720748901367 	 5.841255187988281e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:17:06.701173 test begin: paddle.isposinf(Tensor([11, 4618, 10],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 4618, 10],"int32"), ) 	 507980 	 1000 	 20.077886819839478 	 0.010844945907592773 	 5.435943603515625e-05 	 2.9802322387695312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:17:26.817791 test begin: paddle.isposinf(Tensor([11, 46184],"float32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 46184],"float32"), ) 	 508024 	 1000 	 20.11835241317749 	 0.010144472122192383 	 4.744529724121094e-05 	 2.7179718017578125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:17:46.976441 test begin: paddle.isposinf(Tensor([11, 9236, 10],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([11, 9236, 10],"int16"), ) 	 1015960 	 1000 	 40.20312547683716 	 0.017897367477416992 	 5.53131103515625e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:18:27.247894 test begin: paddle.isposinf(Tensor([2988, 17, 10],"int32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([2988, 17, 10],"int32"), ) 	 507960 	 1000 	 20.25076699256897 	 0.011513948440551758 	 4.9114227294921875e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:18:47.538497 test begin: paddle.isposinf(Tensor([29884, 17],"float32"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([29884, 17],"float32"), ) 	 508028 	 1000 	 19.985941171646118 	 0.010825395584106445 	 0.00013446807861328125 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:19:07.569843 test begin: paddle.isposinf(Tensor([5976, 17, 10],"int16"), )
[Prof] paddle.isposinf 	 paddle.isposinf(Tensor([5976, 17, 10],"int16"), ) 	 1015920 	 1000 	 39.92517614364624 	 0.011359214782714844 	 5.793571472167969e-05 	 4.792213439941406e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:19:47.559802 test begin: paddle.isreal(Tensor([15876010, 32],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([15876010, 32],"bool"), ) 	 508032320 	 1000 	 0.3843386173248291 	 0.3305838108062744 	 0.36798667907714844 	 0.31859683990478516 	 None 	 None 	 None 	 None 	 
2025-07-30 20:19:55.151944 test begin: paddle.isreal(Tensor([31752010, 32],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"bfloat16"), ) 	 1016064320 	 1000 	 0.7657308578491211 	 0.6580398082733154 	 0.748821496963501 	 0.6458697319030762 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:15.657944 test begin: paddle.isreal(Tensor([31752010, 32],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([31752010, 32],"float16"), ) 	 1016064320 	 1000 	 0.7660174369812012 	 0.6829047203063965 	 0.7497155666351318 	 0.6452591419219971 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:40.199124 test begin: paddle.isreal(Tensor([640, 1587601],"bfloat16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"bfloat16"), ) 	 1016064640 	 1000 	 0.7657761573791504 	 0.658074140548706 	 0.7401783466339111 	 0.6396183967590332 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:05.248052 test begin: paddle.isreal(Tensor([640, 1587601],"float16"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 1587601],"float16"), ) 	 1016064640 	 1000 	 0.7660863399505615 	 0.6579222679138184 	 0.741093635559082 	 0.6393821239471436 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:31.911574 test begin: paddle.isreal(Tensor([640, 793801],"bool"), )
[Prof] paddle.isreal 	 paddle.isreal(Tensor([640, 793801],"bool"), ) 	 508032640 	 1000 	 0.3843514919281006 	 0.3588368892669678 	 0.35941147804260254 	 0.3186519145965576 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:40.493194 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([22336, 5, 4, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([22336, 5, 4, 3, 2],"float32"), ) 	 2680420 	 1000 	 9.747756481170654 	 1.360114336013794 	 9.655952453613281e-05 	 1.3434474468231201 	 14.939952611923218 	 5.914909362792969 	 7.700920104980469e-05 	 1.2094347476959229 	 
2025-07-30 20:22:17.712078 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 22336, 4, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 22336, 4, 3, 2],"float32"), ) 	 2680420 	 1000 	 9.73813796043396 	 1.361626148223877 	 0.00010228157043457031 	 1.344914197921753 	 14.968409061431885 	 5.917385816574097 	 5.435943603515625e-05 	 1.2094249725341797 	 
2025-07-30 20:22:54.261387 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 13868, 3, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 13868, 3, 2],"float32"), ) 	 2080300 	 1000 	 7.615779161453247 	 1.0620009899139404 	 0.00011038780212402344 	 1.0455842018127441 	 11.663604021072388 	 4.857806444168091 	 6.580352783203125e-05 	 0.9931066036224365 	 
2025-07-30 20:23:24.089106 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 15401, 2],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 15401, 2],"float32"), ) 	 3080300 	 1000 	 11.117783308029175 	 1.5715651512145996 	 9.775161743164062e-05 	 1.5550487041473389 	 16.9500572681427 	 6.515981435775757 	 8.630752563476562e-05 	 1.3321082592010498 	 
2025-07-30 20:24:05.668977 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 8934],"float32"), )
[Prof] paddle.kron 	 paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 8934],"float32"), ) 	 2680300 	 1000 	 9.67117714881897 	 1.3697199821472168 	 0.00010275840759277344 	 1.3429152965545654 	 17.302995681762695 	 4.998510360717773 	 7.128715515136719e-05 	 1.0212042331695557 	 
2025-07-30 20:24:44.738472 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, ) 	 50808000 	 1000 	 4.000844955444336 	 4.130472898483276 	 1.0200104713439941 	 4.108392953872681 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:24:54.012288 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=1, axis=1, keepdim=True, ) 	 50808000 	 1000 	 4.01812744140625 	 4.12877082824707 	 1.0254628658294678 	 4.111297369003296 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:25:03.251721 test begin: paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 200, 8468],"float32"), k=2, ) 	 50808000 	 1000 	 3.0864670276641846 	 2.4878265857696533 	 3.0766961574554443 	 2.468980312347412 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:25:09.872939 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, ) 	 50804400 	 1000 	 4.497070074081421 	 11.20556926727295 	 1.1466667652130127 	 11.18657398223877 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:25:27.283227 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=1, axis=1, keepdim=True, ) 	 50804400 	 1000 	 4.476893663406372 	 11.0991051197052 	 1.1417741775512695 	 11.078484058380127 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:25:45.631922 test begin: paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([30, 42337, 40],"float32"), k=2, ) 	 50804400 	 1000 	 5.204173564910889 	 5.141187429428101 	 5.186705589294434 	 5.098198652267456 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:25:57.458319 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, ) 	 50808000 	 1000 	 3.9737472534179688 	 4.134815454483032 	 1.013108730316162 	 4.114213466644287 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:26:06.635730 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, keepdim=True, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=1, axis=1, keepdim=True, ) 	 50808000 	 1000 	 3.9790875911712646 	 4.134556293487549 	 1.0151338577270508 	 4.114674091339111 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:26:15.836974 test begin: paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=2, )
[Prof] paddle.kthvalue 	 paddle.kthvalue(Tensor([6351, 200, 40],"float32"), k=2, ) 	 50808000 	 1000 	 5.218958139419556 	 5.137122631072998 	 5.209212064743042 	 5.117921590805054 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:26:27.537967 test begin: paddle.lcm(Tensor([1],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([1],"int64"), Tensor([25401601],"int64"), ) 	 25401602 	 1000 	 87.70241069793701 	 5.716964483261108 	 0.0022788047790527344 	 0.0009179115295410156 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:28:03.084062 test begin: paddle.lcm(Tensor([25401601],"int64"), Tensor([1],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([25401601],"int64"), Tensor([1],"int64"), ) 	 25401602 	 1000 	 73.68168926239014 	 5.65552020072937 	 0.002253293991088867 	 0.0009157657623291016 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:29:23.446446 test begin: paddle.lcm(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 101.85377860069275 	 5.884819507598877 	 0.002414703369140625 	 0.0009186267852783203 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:31:14.909385 test begin: paddle.lcm(Tensor([50803201],"int32"), Tensor([1],"int32"), )
[Prof] paddle.lcm 	 paddle.lcm(Tensor([50803201],"int32"), Tensor([1],"int32"), ) 	 50803202 	 1000 	 86.36771559715271 	 7.982844114303589 	 0.0023174285888671875 	 0.0013127326965332031 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:32:51.174609 test begin: paddle.ldexp(Tensor([25401601],"float64"), Tensor([25401601],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([25401601],"float64"), Tensor([25401601],"int32"), ) 	 50803202 	 1000 	 1.2822837829589844 	 1.1001548767089844 	 0.3280026912689209 	 0.36995410919189453 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:34:19.840695 test begin: paddle.ldexp(Tensor([25401601],"int64"), Tensor([25401601],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([25401601],"int64"), Tensor([25401601],"int32"), ) 	 50803202 	 1000 	 0.8253433704376221 	 0.6447796821594238 	 0.1687915325164795 	 0.21892857551574707 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:34:54.614283 test begin: paddle.ldexp(Tensor([50803201],"float64"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"float64"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 2.554121494293213 	 2.1538026332855225 	 0.6533348560333252 	 0.7343335151672363 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:37:51.873661 test begin: paddle.ldexp(Tensor([50803201],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"int32"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.4715919494628906 	 1.1333162784576416 	 0.3010721206665039 	 0.3864431381225586 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:39:00.141342 test begin: paddle.ldexp(Tensor([50803201],"int64"), Tensor([50803201],"int32"), )
[Prof] paddle.ldexp 	 paddle.ldexp(Tensor([50803201],"int64"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 1.6295101642608643 	 1.2791187763214111 	 0.3332557678222656 	 0.43535876274108887 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:40:11.541578 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 604801],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 604801],"float32"), 0.36, ) 	 50803285 	 1000 	 0.29865336418151855 	 0.3036670684814453 	 0.1525425910949707 	 0.2886488437652588 	 0.6295640468597412 	 0.7491259574890137 	 0.21417498588562012 	 0.19116687774658203 	 
2025-07-30 20:40:15.198869 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 604801, 28],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 604801, 28],"float32"), 0.36, ) 	 50803285 	 1000 	 0.2986176013946533 	 0.3025026321411133 	 0.15254950523376465 	 0.2887880802154541 	 0.629479169845581 	 0.7490406036376953 	 0.2141740322113037 	 0.19112873077392578 	 
2025-07-30 20:40:18.831287 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([64801, 28, 28],"float32"), 0.36, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([64801, 28, 28],"float32"), 0.36, ) 	 50803985 	 1000 	 0.2989017963409424 	 0.30254054069519043 	 0.1527233123779297 	 0.28880977630615234 	 0.6320948600769043 	 0.7491390705108643 	 0.21504616737365723 	 0.19118523597717285 	 
2025-07-30 20:40:22.516206 test begin: paddle.lerp(Tensor([1, 1814401, 28],"float32"), Tensor([3, 1814401, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 1814401, 28],"float32"), Tensor([3, 1814401, 28],"float32"), 1.0, ) 	 203212912 	 1000 	 1.3400285243988037 	 1.32594633102417 	 0.6848039627075195 	 1.3115968704223633 	 2.203334093093872 	 2.3538644313812256 	 1.1259548664093018 	 0.8017399311065674 	 
2025-07-30 20:40:37.507317 test begin: paddle.lerp(Tensor([1, 28, 1814401],"float32"), Tensor([3, 28, 1814401],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 28, 1814401],"float32"), Tensor([3, 28, 1814401],"float32"), 1.0, ) 	 203212912 	 1000 	 1.339972734451294 	 1.3259007930755615 	 0.684704065322876 	 1.3117921352386475 	 2.203305721282959 	 2.3539037704467773 	 1.1258413791656494 	 0.8016846179962158 	 
2025-07-30 20:40:50.474170 test begin: paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, ) 	 50804768 	 1000 	 0.29822683334350586 	 0.30472397804260254 	 0.1523418426513672 	 0.29076290130615234 	 0.7932069301605225 	 0.7821090221405029 	 0.2699618339538574 	 0.19957780838012695 	 
2025-07-30 20:40:54.337983 test begin: paddle.lerp(Tensor([3, 28, 604801],"float32"), Tensor([3, 28, 604801],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([3, 28, 604801],"float32"), Tensor([3, 28, 604801],"float32"), 1.2, ) 	 101606568 	 1000 	 0.45241641998291016 	 0.4469339847564697 	 0.23116755485534668 	 0.434004545211792 	 0.4727029800415039 	 0.5954992771148682 	 0.4131190776824951 	 0.3042008876800537 	 
2025-07-30 20:40:58.748161 test begin: paddle.lerp(Tensor([3, 604801, 28],"float32"), Tensor([3, 604801, 28],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([3, 604801, 28],"float32"), Tensor([3, 604801, 28],"float32"), 1.2, ) 	 101606568 	 1000 	 0.45269250869750977 	 0.44698214530944824 	 0.23142361640930176 	 0.4274330139160156 	 0.4727742671966553 	 0.5954601764678955 	 0.40386343002319336 	 0.30423927307128906 	 
2025-07-30 20:41:03.294343 test begin: paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.0, ) 	 101607968 	 1000 	 0.45255160331726074 	 0.44696688652038574 	 0.2312169075012207 	 0.42737436294555664 	 0.4722311496734619 	 0.5955841541290283 	 0.4030125141143799 	 0.30423450469970703 	 
2025-07-30 20:41:10.167706 test begin: paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.2, )
[Prof] paddle.lerp 	 paddle.lerp(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), 1.2, ) 	 101607968 	 1000 	 0.4525332450866699 	 0.44919347763061523 	 0.23120808601379395 	 0.4339282512664795 	 0.4721519947052002 	 0.595421314239502 	 0.41254281997680664 	 0.30419063568115234 	 
2025-07-30 20:41:16.929288 test begin: paddle.less(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19066882133483887 	 0.24610519409179688 	 0.1806330680847168 	 0.2316136360168457 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:18.189860 test begin: paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18843483924865723 	 0.24435806274414062 	 0.17840933799743652 	 0.23017096519470215 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:19.445847 test begin: paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3265690803527832 	 0.3278825283050537 	 0.3172173500061035 	 0.31676363945007324 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:21.750638 test begin: paddle.less(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.3265876770019531 	 0.3278472423553467 	 0.31730103492736816 	 0.3166511058807373 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:24.038777 test begin: paddle.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.3264899253845215 	 0.32785487174987793 	 0.31731557846069336 	 0.3167996406555176 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:26.344542 test begin: paddle.less(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.326556921005249 	 0.32781219482421875 	 0.3172130584716797 	 0.3166806697845459 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:28.654083 test begin: paddle.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), ) 	 101607424 	 1000 	 0.3262484073638916 	 0.32789087295532227 	 0.3170456886291504 	 0.31652355194091797 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:30.989080 test begin: paddle.less(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.less 	 paddle.less(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.32655811309814453 	 0.33037638664245605 	 0.3172318935394287 	 0.3165245056152344 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:33.287341 test begin: paddle.less_equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19064879417419434 	 0.24808025360107422 	 0.18074560165405273 	 0.23117303848266602 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:34.564791 test begin: paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18842649459838867 	 0.2615776062011719 	 0.17108631134033203 	 0.2318582534790039 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:38.839709 test begin: paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.326540470123291 	 0.3330113887786865 	 0.31414294242858887 	 0.3164384365081787 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:41.182895 test begin: paddle.less_equal(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.3265831470489502 	 0.327866792678833 	 0.3102288246154785 	 0.3105018138885498 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:43.498917 test begin: paddle.less_equal(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), )
W0730 20:41:46.916613 53663 dygraph_functions.cc:90806] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([16934401, 3, 2],"float16"), Tensor([16934401, 3, 2],"float32"), ) 	 203212812 	 1000 	 1.1283318996429443 	 0.7199034690856934 	 0.5765705108642578 	 0.701643705368042 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:48.999679 test begin: paddle.less_equal(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.32655978202819824 	 0.3278825283050537 	 0.31026768684387207 	 0.31055736541748047 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:51.298093 test begin: paddle.less_equal(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 12700801, 2],"float16"), Tensor([4, 12700801, 2],"float32"), ) 	 203212816 	 1000 	 1.1281793117523193 	 0.71980881690979 	 0.5765104293823242 	 0.7020905017852783 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:56.804522 test begin: paddle.less_equal(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 3, 4233601],"float16"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 0.5696232318878174 	 0.3637361526489258 	 0.29106926918029785 	 0.35208868980407715 	 None 	 None 	 None 	 None 	 
2025-07-30 20:41:59.561422 test begin: paddle.less_equal(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 3, 8467201],"float16"), Tensor([4, 3, 8467201],"float32"), ) 	 203212824 	 1000 	 1.128218412399292 	 0.7198953628540039 	 0.5765435695648193 	 0.7083268165588379 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:04.971851 test begin: paddle.less_equal(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([4, 6350401, 2],"float16"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 0.5696251392364502 	 0.36371684074401855 	 0.29106736183166504 	 0.3519911766052246 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:07.687605 test begin: paddle.less_equal(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.less_equal 	 paddle.less_equal(Tensor([8467201, 3, 2],"float16"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 0.569617748260498 	 0.3637726306915283 	 0.291029691696167 	 0.35213351249694824 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:10.424097 test begin: paddle.less_than(Tensor([1, 128, 198451],"int64"), Tensor([1, 128, 198451],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 198451],"int64"), Tensor([1, 128, 198451],"int64"), ) 	 50803456 	 1000 	 0.3099939823150635 	 0.31325459480285645 	 0.300886869430542 	 0.30199098587036133 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:11.877262 test begin: paddle.less_than(Tensor([1, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), ) 	 50855936 	 1000 	 0.19158482551574707 	 0.24435758590698242 	 0.1779794692993164 	 0.2323927879333496 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:13.142620 test begin: paddle.less_than(Tensor([1, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), ) 	 25460736 	 1000 	 0.20670151710510254 	 0.1839280128479004 	 0.1970353126525879 	 0.1695694923400879 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:13.963845 test begin: paddle.less_than(Tensor([1, 128, 396901],"float32"), Tensor([1, 128, 396901],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 128, 396901],"float32"), Tensor([1, 128, 396901],"float32"), ) 	 101606656 	 1000 	 0.32674646377563477 	 0.33179783821105957 	 0.31760263442993164 	 0.31272029876708984 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:16.270860 test begin: paddle.less_than(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 256],"float32"), ) 	 101606912 	 1000 	 0.32656145095825195 	 0.33840250968933105 	 0.31737184524536133 	 0.3163478374481201 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:20.435237 test begin: paddle.less_than(Tensor([1, 99226, 256],"int64"), Tensor([1, 99226, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1, 99226, 256],"int64"), Tensor([1, 99226, 256],"int64"), ) 	 50803712 	 1000 	 0.3101475238800049 	 0.31614065170288086 	 0.2939178943634033 	 0.2997772693634033 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:23.821168 test begin: paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1, 128, 256],"float32"), ) 	 50855936 	 1000 	 0.1896064281463623 	 0.24461913108825684 	 0.17224383354187012 	 0.22632312774658203 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:25.085519 test begin: paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([1551, 128, 256],"float32"), Tensor([1551, 128, 256],"float32"), ) 	 101646336 	 1000 	 0.32632875442504883 	 0.3280801773071289 	 0.3099045753479004 	 0.31081366539001465 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:27.419165 test begin: paddle.less_than(Tensor([3101, 1, 128, 128],"float32"), Tensor([3101, 1, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([3101, 1, 128, 128],"float32"), Tensor([3101, 1, 128, 128],"float32"), ) 	 101613568 	 1000 	 0.32622337341308594 	 0.32788968086242676 	 0.31003665924072266 	 0.3104407787322998 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:29.791903 test begin: paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([1, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([1, 128, 256],"int64"), ) 	 25460736 	 1000 	 0.1760861873626709 	 0.18169331550598145 	 0.16636395454406738 	 0.16977167129516602 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:30.565698 test begin: paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([776, 128, 256],"int64"), Tensor([776, 128, 256],"int64"), ) 	 50855936 	 1000 	 0.3105642795562744 	 0.3135530948638916 	 0.30138468742370605 	 0.3024015426635742 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:32.072560 test begin: paddle.less_than(Tensor([8, 1, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), ) 	 50987008 	 1000 	 0.19401836395263672 	 0.2593207359313965 	 0.18395614624023438 	 0.24721026420593262 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:33.348574 test begin: paddle.less_than(Tensor([8, 1, 128, 49613],"float32"), Tensor([8, 1, 128, 49613],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 128, 49613],"float32"), Tensor([8, 1, 128, 49613],"float32"), ) 	 101607424 	 1000 	 0.3262646198272705 	 0.33753466606140137 	 0.310147762298584 	 0.3161153793334961 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:39.516943 test begin: paddle.less_than(Tensor([8, 1, 49613, 128],"float32"), Tensor([8, 1, 49613, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 1, 49613, 128],"float32"), Tensor([8, 1, 49613, 128],"float32"), ) 	 101607424 	 1000 	 0.32624101638793945 	 0.3279750347137451 	 0.31662893295288086 	 0.31638002395629883 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:41.738943 test begin: paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 1, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 1, 128, 128],"float32"), ) 	 50987008 	 1000 	 0.19156217575073242 	 0.25957489013671875 	 0.18151640892028809 	 0.24758625030517578 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:43.048310 test begin: paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), )
[Prof] paddle.less_than 	 paddle.less_than(Tensor([8, 388, 128, 128],"float32"), Tensor([8, 388, 128, 128],"float32"), ) 	 101711872 	 1000 	 0.3265259265899658 	 0.328171968460083 	 0.3171873092651367 	 0.3169844150543213 	 None 	 None 	 None 	 None 	 
2025-07-30 20:42:45.375293 test begin: paddle.lgamma(Tensor([10, 10, 10, 25402],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 10, 10, 25402],"float64"), ) 	 25402000 	 1000 	 0.7120804786682129 	 0.6896250247955322 	 0.7036857604980469 	 0.6793928146362305 	 1.3841443061828613 	 1.5869638919830322 	 1.3333499431610107 	 0.8115496635437012 	 
2025-07-30 20:42:50.817690 test begin: paddle.lgamma(Tensor([10, 10, 127009, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 10, 127009, 2],"float64"), ) 	 25401800 	 1000 	 0.7119190692901611 	 0.6936032772064209 	 0.7033829689025879 	 0.6788711547851562 	 1.3802034854888916 	 1.5905401706695557 	 1.3297393321990967 	 0.8123373985290527 	 
2025-07-30 20:42:56.318166 test begin: paddle.lgamma(Tensor([10, 127009, 10, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([10, 127009, 10, 2],"float64"), ) 	 25401800 	 1000 	 0.7117068767547607 	 0.6896660327911377 	 0.7032403945922852 	 0.6793003082275391 	 1.3801841735839844 	 1.5912961959838867 	 1.3292884826660156 	 0.8131952285766602 	 
2025-07-30 20:43:01.738023 test begin: paddle.lgamma(Tensor([100, 254017],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([100, 254017],"float64"), ) 	 25401700 	 1000 	 0.7117183208465576 	 0.6896324157714844 	 0.7031867504119873 	 0.6793742179870605 	 1.3809959888458252 	 1.59181547164917 	 1.3112578392028809 	 0.8133141994476318 	 
2025-07-30 20:43:07.208047 test begin: paddle.lgamma(Tensor([127009, 10, 10, 2],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([127009, 10, 10, 2],"float64"), ) 	 25401800 	 1000 	 0.7119803428649902 	 0.6896436214447021 	 0.7035393714904785 	 0.6791951656341553 	 1.380671739578247 	 1.5892529487609863 	 1.3288908004760742 	 0.8130483627319336 	 
2025-07-30 20:43:12.640592 test begin: paddle.lgamma(Tensor([1948, 26080],"float32"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([1948, 26080],"float32"), ) 	 50803840 	 1000 	 0.398756742477417 	 0.3805360794067383 	 0.38277745246887207 	 0.3644742965698242 	 0.961228609085083 	 1.514714241027832 	 0.8997817039489746 	 0.773958683013916 	 
2025-07-30 20:43:17.592874 test begin: paddle.lgamma(Tensor([254017, 100],"float64"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([254017, 100],"float64"), ) 	 25401700 	 1000 	 0.7123942375183105 	 0.6896853446960449 	 0.7039704322814941 	 0.6795389652252197 	 1.3816730976104736 	 1.5911757946014404 	 1.3273723125457764 	 0.8132917881011963 	 
2025-07-30 20:43:23.026309 test begin: paddle.lgamma(Tensor([50803201, 1],"float32"), )
[Prof] paddle.lgamma 	 paddle.lgamma(Tensor([50803201, 1],"float32"), ) 	 50803201 	 1000 	 0.3999359607696533 	 0.3816676139831543 	 0.3913455009460449 	 0.37070322036743164 	 0.9660255908966064 	 1.5132346153259277 	 0.9144589900970459 	 0.7725324630737305 	 
2025-07-30 20:43:28.981572 test begin: paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-1, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-1, ) 	 25401664 	 1000 	 90.10565257072449 	 3.492403745651245 	 0.001215219497680664 	 0.05360913276672363 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [4, 396901, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 20:45:23.671571 test begin: paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-math.inf, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([4, 396901, 4, 4],"float64"), p=-math.inf, ) 	 25401664 	 1000 	 77.75908088684082 	 3.477370023727417 	 0.0011546611785888672 	 0.05336809158325195 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [4, 396901, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 20:47:05.887113 test begin: paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-1, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-1, ) 	 25401632 	 1000 	 78.34618616104126 	 3.494847297668457 	 0.001214742660522461 	 0.05359673500061035 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [793801, 2, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 20:48:48.715866 test begin: paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-math.inf, )
[Prof] paddle.linalg.cond 	 paddle.linalg.cond(x=Tensor([793801, 2, 4, 4],"float64"), p=-math.inf, ) 	 25401632 	 1000 	 78.39415740966797 	 3.477337598800659 	 0.001146554946899414 	 0.05334329605102539 	 None 	 None 	 None 	 None 	 
[Error] one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.DoubleTensor [793801, 2, 4, 4]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-07-30 20:50:31.575778 test begin: paddle.linalg.corrcoef(Tensor([4, 12700801],"float32"), )
[Prof] paddle.linalg.corrcoef 	 paddle.linalg.corrcoef(Tensor([4, 12700801],"float32"), ) 	 50803204 	 1000 	 2.895712375640869 	 2.347848892211914 	 0.1648094654083252 	 0.002033710479736328 	 4.538931846618652 	 3.446784019470215 	 0.10413002967834473 	 0.0637199878692627 	 
2025-07-30 20:50:45.808071 test begin: paddle.linalg.corrcoef(Tensor([4, 6350401],"float64"), )
[Prof] paddle.linalg.corrcoef 	 paddle.linalg.corrcoef(Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 1.9665868282318115 	 1.2701435089111328 	 0.11181139945983887 	 0.000986337661743164 	 4.955333948135376 	 3.3536319732666016 	 0.1535639762878418 	 0.07871508598327637 	 
2025-07-30 20:50:57.946257 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([50803201],"int32"), )
W0730 20:50:58.470038 56957 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([50803201],"int32"), ) 	 50803401 	 1000 	 0.5185623168945312 	 0.331148624420166 	 1.71661376953125e-05 	 6.937980651855469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:50:58.804689 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([25401601],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([25401601],"float64"), ) 	 25401811 	 1000 	 0.7600622177124023 	 0.4094390869140625 	 1.7881393432617188e-05 	 7.867813110351562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:00.433798 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([10],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([25401601],"int64"), aweights=Tensor([10],"float64"), ) 	 25401811 	 1000 	 0.7676024436950684 	 0.40206480026245117 	 1.811981201171875e-05 	 7.05718994140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:02.063156 test begin: paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([50803201],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 10],"float64"), rowvar=True, ddof=True, fweights=Tensor([50803201],"int32"), aweights=None, ) 	 50803401 	 1000 	 0.6095864772796631 	 0.31722426414489746 	 1.7881393432617188e-05 	 7.224082946777344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:03.358196 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([10],"int32"), )
W0730 20:51:06.461577 57378 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([10],"int32"), ) 	 25401630 	 1000 	 2.1703414916992188 	 1.718249797821045 	 0.0015735626220703125 	 0.0009007453918457031 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:10.860206 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([1270081],"int32"), )
W0730 20:51:13.976419 57395 backward.cc:462] While running Node (CastGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=None, aweights=Tensor([1270081],"int32"), ) 	 26671701 	 1000 	 2.1739275455474854 	 1.7083032131195068 	 0.0015799999237060547 	 0.0009255409240722656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:16.338799 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int32"), aweights=None, ) 	 25401630 	 1000 	 2.3346076011657715 	 1.7050118446350098 	 0.001611471176147461 	 0.0009028911590576172 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:25.312417 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([10],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([10],"int64"), aweights=Tensor([10],"float64"), ) 	 25401640 	 1000 	 2.425426721572876 	 1.7662346363067627 	 0.001661062240600586 	 0.0009217262268066406 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:34.420545 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int32"), aweights=None, )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int32"), aweights=None, ) 	 26671701 	 1000 	 2.275444269180298 	 1.671161413192749 	 0.0015749931335449219 	 0.0009095668792724609 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:43.136239 test begin: paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int64"), aweights=Tensor([1270081],"float64"), )
[Prof] paddle.linalg.cov 	 paddle.linalg.cov(Tensor([20, 1270081],"float64"), rowvar=True, ddof=True, fweights=Tensor([1270081],"int64"), aweights=Tensor([1270081],"float64"), ) 	 27941782 	 1000 	 2.4179396629333496 	 1.7679979801177979 	 0.001665353775024414 	 0.0009253025054931641 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:51:52.270862 test begin: paddle.linalg.det(Tensor([12737, 3, 5, 5],"float32"), )
[Prof] paddle.linalg.det 	 paddle.linalg.det(Tensor([12737, 3, 5, 5],"float32"), ) 	 955275 	 1000 	 11.307843923568726 	 0.12074661254882812 	 0.00010442733764648438 	 4.410743713378906e-05 	 2.033524513244629 	 0.2258303165435791 	 3.7670135498046875e-05 	 4.673004150390625e-05 	 
2025-07-30 20:52:06.021128 test begin: paddle.linalg.det(Tensor([3, 12737, 5, 5],"float32"), )
[Prof] paddle.linalg.det 	 paddle.linalg.det(Tensor([3, 12737, 5, 5],"float32"), ) 	 955275 	 1000 	 11.441420555114746 	 0.17919063568115234 	 0.00010418891906738281 	 9.560585021972656e-05 	 2.080819606781006 	 0.23585915565490723 	 8.249282836914062e-05 	 7.390975952148438e-05 	 
2025-07-30 20:52:20.112078 test begin: paddle.linalg.inv(x=Tensor([5, 31752, 4, 4],"float64"), )
[Prof] paddle.linalg.inv 	 paddle.linalg.inv(x=Tensor([5, 31752, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.674516916275024 	 0.3380434513092041 	 4.100799560546875e-05 	 7.033348083496094e-05 	 2.629075288772583 	 1.97407865524292 	 0.33487820625305176 	 0.28819894790649414 	 
2025-07-30 20:52:32.867353 test begin: paddle.linalg.inv(x=Tensor([52920, 3, 4, 4],"float64"), )
[Prof] paddle.linalg.inv 	 paddle.linalg.inv(x=Tensor([52920, 3, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.543232440948486 	 0.341052770614624 	 5.459785461425781e-05 	 5.936622619628906e-05 	 4.467419862747192 	 1.974104404449463 	 0.33515286445617676 	 0.28821730613708496 	 
2025-07-30 20:52:47.290151 test begin: paddle.linalg.lu(Tensor([103, 5, 5, 5],"float64"), )
/usr/local/lib/python3.10/dist-packages/torch/functional.py:2162: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([103, 5, 5, 5],"float64"), ) 	 12875 	 1000 	 12.765474081039429 	 0.0386812686920166 	 6.771087646484375e-05 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:53:04.402069 test begin: paddle.linalg.lu(Tensor([106, 5, 5, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([106, 5, 5, 5],"float32"), ) 	 13250 	 1000 	 12.951908349990845 	 0.03793907165527344 	 0.00011610984802246094 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:53:22.010844 test begin: paddle.linalg.lu(Tensor([3, 138, 5, 5],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 138, 5, 5],"float64"), ) 	 10350 	 1000 	 10.287020206451416 	 0.05072593688964844 	 9.584426879882812e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:53:36.963599 test begin: paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), ) 	 13275 	 1000 	 14.433742761611938 	 0.03802084922790527 	 0.00011014938354492188 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:53:57.596680 test begin: paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 177, 5, 5],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 13.057084798812866 	 0.03811502456665039 	 0.00010013580322265625 	 4.76837158203125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:15.008232 test begin: paddle.linalg.lu(Tensor([3, 5, 138, 5],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 138, 5],"float64"), ) 	 10350 	 1000 	 0.4793825149536133 	 0.11718869209289551 	 2.8133392333984375e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:16.090765 test begin: paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), ) 	 13275 	 1000 	 0.4564526081085205 	 0.1165318489074707 	 4.7206878662109375e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:17.140222 test begin: paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 177, 5],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 0.4537825584411621 	 0.13690900802612305 	 3.314018249511719e-05 	 4.76837158203125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:18.310568 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 138],"float64"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 138],"float64"), ) 	 10350 	 1000 	 0.5594911575317383 	 0.16409015655517578 	 4.5299530029296875e-05 	 0.00015783309936523438 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:19.607307 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), ) 	 13275 	 1000 	 0.6042952537536621 	 0.1688699722290039 	 4.863739013671875e-05 	 5.936622619628906e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:21.037689 test begin: paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), pivot=True, get_infos=True, )
[Prof] paddle.linalg.lu 	 paddle.linalg.lu(Tensor([3, 5, 5, 177],"float32"), pivot=True, get_infos=True, ) 	 13275 	 1000 	 0.5587329864501953 	 0.16922760009765625 	 4.410743713378906e-05 	 5.602836608886719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:22.239774 test begin: paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float32"), Tensor([203, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float32"), Tensor([203, 5, 5],"int32"), ) 	 2545200 	 1000 	 8.536762475967407 	 0.11806535720825195 	 9.441375732421875e-05 	 0.013999462127685547 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([203, 5, 5, 5]) and output[0] has a shape of torch.Size([20321, 5, 5, 5]).
2025-07-30 20:54:31.177699 test begin: paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float64"), Tensor([203, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([20321, 5, 5, 5],"float64"), Tensor([203, 5, 5],"int32"), ) 	 2545200 	 1000 	 9.17002534866333 	 0.1564180850982666 	 0.00012445449829101562 	 0.018793582916259766 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([203, 5, 5, 5]) and output[0] has a shape of torch.Size([20321, 5, 5, 5]).
2025-07-30 20:54:41.015328 test begin: paddle.linalg.lu_unpack(Tensor([3, 5, 5, 338689],"float64"), Tensor([3, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([3, 5, 5, 338689],"float64"), Tensor([3, 5, 5],"int32"), ) 	 25401750 	 1000 	 0.9330978393554688 	 0.361452579498291 	 4.9114227294921875e-05 	 0.046198129653930664 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:44.851232 test begin: paddle.linalg.lu_unpack(Tensor([3, 5, 5, 677377],"float32"), Tensor([3, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([3, 5, 5, 677377],"float32"), Tensor([3, 5, 5],"int32"), ) 	 50803350 	 1000 	 1.2002153396606445 	 0.4040689468383789 	 5.602836608886719e-05 	 0.05166292190551758 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:49.765842 test begin: paddle.linalg.lu_unpack(Tensor([4064, 5, 5, 5],"float32"), Tensor([406, 5, 5],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([4064, 5, 5, 5],"float32"), Tensor([406, 5, 5],"int32"), ) 	 518150 	 1000 	 15.461116790771484 	 0.06433439254760742 	 9.751319885253906e-05 	 8.249282836914062e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([406, 5, 5, 5]) and output[0] has a shape of torch.Size([4064, 5, 5, 5]).
2025-07-30 20:55:05.445666 test begin: paddle.linalg.lu_unpack(Tensor([6773, 5, 5, 3],"float32"), Tensor([277, 5, 3],"int32"), )
[Prof] paddle.linalg.lu_unpack 	 paddle.linalg.lu_unpack(Tensor([6773, 5, 5, 3],"float32"), Tensor([277, 5, 3],"int32"), ) 	 512130 	 1000 	 10.651339292526245 	 0.0676276683807373 	 0.00010466575622558594 	 7.82012939453125e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([277, 5, 5, 5]) and output[0] has a shape of torch.Size([6773, 5, 5, 5]).
2025-07-30 20:55:16.295895 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4233601],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 4233601],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401606 	 1000 	 0.2354896068572998 	 0.1758134365081787 	 0.12030339241027832 	 0.1582930088043213 	 1.2962794303894043 	 1.2551581859588623 	 0.4412071704864502 	 0.3208131790161133 	 
2025-07-30 20:55:19.970165 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 	 25401630 	 1000 	 17.365556240081787 	 17.484044313430786 	 8.702278137207031e-05 	 0.00024437904357910156 	 1.3005890846252441 	 1.700606346130371 	 0.0701603889465332 	 0.2478172779083252 	 
2025-07-30 20:55:59.493310 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3, 846721, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 	 25401630 	 1000 	 17.58124828338623 	 17.65191650390625 	 8.749961853027344e-05 	 0.0002391338348388672 	 1.3037405014038086 	 1.6989750862121582 	 0.06705307960510254 	 0.2477741241455078 	 
2025-07-30 20:56:39.539551 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3175201, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 3175201, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401608 	 1000 	 5.261672735214233 	 0.15891242027282715 	 1.7935504913330078 	 0.08116364479064941 	 1.082388162612915 	 0.9076709747314453 	 0.3687105178833008 	 0.23201608657836914 	 
2025-07-30 20:56:47.519551 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 	 25401640 	 1000 	 17.88500738143921 	 16.370453357696533 	 0.00024700164794921875 	 0.00024390220642089844 	 2.5678536891937256 	 1.7584826946258545 	 0.13861680030822754 	 0.25662922859191895 	 
2025-07-30 20:57:26.716147 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2, 635041, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 	 25401640 	 1000 	 17.63601040840149 	 16.201753616333008 	 0.00024771690368652344 	 0.0002486705780029297 	 2.5715930461883545 	 1.7583990097045898 	 0.1317145824432373 	 0.2566194534301758 	 
2025-07-30 20:58:07.195638 test begin: paddle.linalg.matrix_norm(x=Tensor([2116801, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Prof] paddle.linalg.matrix_norm 	 paddle.linalg.matrix_norm(x=Tensor([2116801, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, ) 	 25401612 	 1000 	 5.262859344482422 	 0.15892291069030762 	 1.7947311401367188 	 0.08119583129882812 	 1.0829100608825684 	 0.9075679779052734 	 0.3689439296722412 	 0.23198151588439941 	 
2025-07-30 20:58:15.191669 test begin: paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-10, ) 	 25411584 	 1000 	 7.169771671295166 	 6.274851083755493 	 0.003193378448486328 	 0.0015382766723632812 	 20.573164463043213 	 6.772736072540283 	 0.01640152931213379 	 0.4611246585845947 	 
2025-07-30 20:58:58.418742 test begin: paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([2068, 2, 3, 2, 1, 32, 32],"float64"), n=-2, ) 	 25411584 	 1000 	 4.742380380630493 	 5.03816819190979 	 0.0003299713134765625 	 0.00037741661071777344 	 6.212631702423096 	 2.615823745727539 	 0.0022096633911132812 	 0.4454312324523926 	 
2025-07-30 20:59:18.164971 test begin: paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-10, ) 	 25417728 	 1000 	 7.167909622192383 	 6.266843318939209 	 0.003195524215698242 	 0.0015552043914794922 	 20.586163997650146 	 6.774503946304321 	 0.016411781311035156 	 0.4612996578216553 	 
2025-07-30 21:00:01.257703 test begin: paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 1379, 3, 2, 1, 32, 32],"float64"), n=-2, ) 	 25417728 	 1000 	 4.739680767059326 	 5.035624742507935 	 0.0003178119659423828 	 0.00036978721618652344 	 6.186736106872559 	 2.6177940368652344 	 0.002221822738647461 	 0.44553327560424805 	 
2025-07-30 21:00:20.970791 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 2005, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 2005, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25407360 	 1000 	 17.449506759643555 	 17.07656979560852 	 0.3436884880065918 	 0.3498568534851074 	 46.48671746253967 	 42.679951667785645 	 0.3639054298400879 	 0.4272453784942627 	 
2025-07-30 21:02:26.020507 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 1719, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 1719, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.45660376548767 	 17.079835653305054 	 0.3439161777496338 	 0.3500027656555176 	 46.520055055618286 	 42.79263520240784 	 0.36417436599731445 	 0.42769694328308105 	 
2025-07-30 21:04:31.129702 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 3151, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 3151, 4, 4],"float64"), n=3, ) 	 25409664 	 1000 	 17.448038816452026 	 17.088423490524292 	 0.3435349464416504 	 0.34993886947631836 	 46.5572395324707 	 42.684865951538086 	 0.36393237113952637 	 0.4275238513946533 	 
2025-07-30 21:06:37.272597 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 287, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 287, 11, 4, 4],"float64"), n=3, ) 	 25458048 	 1000 	 17.46234369277954 	 17.13341760635376 	 0.34386181831359863 	 0.3509056568145752 	 46.58460068702698 	 42.762484550476074 	 0.3659970760345459 	 0.4280998706817627 	 
2025-07-30 21:08:42.566844 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-10, ) 	 25411584 	 1000 	 7.165237188339233 	 6.2695887088775635 	 0.0031938552856445312 	 0.0015435218811035156 	 20.584864377975464 	 6.777209281921387 	 0.016408443450927734 	 0.4611952304840088 	 
2025-07-30 21:09:24.557664 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 2068, 2, 1, 32, 32],"float64"), n=-2, ) 	 25411584 	 1000 	 4.720957279205322 	 5.066434621810913 	 0.00032973289489746094 	 0.0003597736358642578 	 6.195743799209595 	 2.6157970428466797 	 0.0022106170654296875 	 0.44542598724365234 	 
2025-07-30 21:09:45.171887 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-10, ) 	 25417728 	 1000 	 7.167731285095215 	 6.278036594390869 	 0.0031991004943847656 	 0.001550436019897461 	 20.58451795578003 	 6.776926755905151 	 0.016382694244384766 	 0.4613654613494873 	 
2025-07-30 21:10:27.199415 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 1379, 1, 32, 32],"float64"), n=-2, ) 	 25417728 	 1000 	 4.748859167098999 	 5.040483236312866 	 0.0003170967102050781 	 0.0003650188446044922 	 6.181727886199951 	 2.6188864707946777 	 0.0022323131561279297 	 0.44545984268188477 	 
2025-07-30 21:10:47.349070 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-10, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-10, ) 	 25436160 	 1000 	 7.19474983215332 	 6.275513410568237 	 0.0032088756561279297 	 0.0015463829040527344 	 20.593945741653442 	 6.788234233856201 	 0.016443967819213867 	 0.4621572494506836 	 
2025-07-30 21:11:29.420821 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-2, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 690, 32, 32],"float64"), n=-2, ) 	 25436160 	 1000 	 4.72456431388855 	 5.044350624084473 	 0.00032973289489746094 	 0.0003795623779296875 	 6.185385227203369 	 2.621563673019409 	 0.002215862274169922 	 0.44641804695129395 	 
2025-07-30 21:11:49.159052 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 573, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 2, 573, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.456820487976074 	 17.091437578201294 	 0.34368324279785156 	 0.34986329078674316 	 46.56072545051575 	 42.753700494766235 	 0.36517858505249023 	 0.4274880886077881 	 
2025-07-30 21:13:54.287035 test begin: paddle.linalg.matrix_power(x=Tensor([3, 573, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([3, 573, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25413696 	 1000 	 17.470625400543213 	 17.09471821784973 	 0.34395360946655273 	 0.35001063346862793 	 46.540332555770874 	 42.71870160102844 	 0.3642306327819824 	 0.42761921882629395 	 
2025-07-30 21:15:59.379383 test begin: paddle.linalg.matrix_power(x=Tensor([860, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Prof] paddle.linalg.matrix_power 	 paddle.linalg.matrix_power(x=Tensor([860, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, ) 	 25428480 	 1000 	 17.453490734100342 	 17.123119354248047 	 0.3492593765258789 	 0.35051631927490234 	 46.664021730422974 	 42.850539445877075 	 0.37148356437683105 	 0.4275088310241699 	 
2025-07-30 21:18:04.769936 test begin: paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.009052753448486328 	 0.007161378860473633 	 1.5020370483398438e-05 	 2.1696090698242188e-05 	 0.04729771614074707 	 0.06384706497192383 	 3.409385681152344e-05 	 6.604194641113281e-05 	 combined
2025-07-30 21:18:26.571403 test begin: paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.004369497299194336 	 0.0037860870361328125 	 1.0967254638671875e-05 	 2.0742416381835938e-05 	 0.04018664360046387 	 0.05684471130371094 	 4.029273986816406e-05 	 3.600120544433594e-05 	 combined
2025-07-30 21:18:42.837633 test begin: paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.linalg.matrix_transpose 	 paddle.linalg.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.004300832748413086 	 0.003789663314819336 	 9.059906005859375e-06 	 2.3365020751953125e-05 	 0.039933204650878906 	 0.06161689758300781 	 2.6702880859375e-05 	 5.3882598876953125e-05 	 combined
2025-07-30 21:18:59.297923 test begin: paddle.linalg.multi_dot(list[Tensor([25401601],"float64"),Tensor([25401601, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([25401601],"float64"),Tensor([25401601, 31],"float64"),], ) 	 812851232 	 1000 	 6.248050212860107 	 6.249944686889648 	 3.1939945220947266 	 3.1956698894500732 	 12.58313775062561 	 12.568638801574707 	 0.500457763671875 	 0.4987480640411377 	 
2025-07-30 21:19:55.779291 test begin: paddle.linalg.multi_dot(list[Tensor([4, 4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4, 4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401620 	 1000 	 0.7790300846099854 	 0.7750885486602783 	 0.1133580207824707 	 0.11313176155090332 	 2.032928705215454 	 2.051609516143799 	 0.2307603359222412 	 0.23248624801635742 	 
2025-07-30 21:20:02.414771 test begin: paddle.linalg.multi_dot(list[Tensor([4233601, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4233601, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 25401656 	 1000 	 2.1571731567382812 	 1.430774450302124 	 0.31496262550354004 	 0.15358543395996094 	 5.270535230636597 	 2.0273585319519043 	 0.2384779453277588 	 0.18807291984558105 	 
2025-07-30 21:20:14.703718 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401608 	 1000 	 0.19404816627502441 	 0.1941211223602295 	 0.17534685134887695 	 0.1691114902496338 	 0.5754845142364502 	 0.568619966506958 	 0.06535863876342773 	 0.06443643569946289 	 
2025-07-30 21:20:16.896693 test begin: paddle.linalg.multi_dot(list[Tensor([6350401, 4],"float64"),Tensor([4, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([6350401, 4],"float64"),Tensor([4, 31],"float64"),], ) 	 25401728 	 1000 	 1.7769412994384766 	 1.8030979633331299 	 0.25958895683288574 	 0.2642519474029541 	 3.4306161403656006 	 3.7566471099853516 	 0.38855504989624023 	 0.4271080493927002 	 
2025-07-30 21:20:33.411399 test begin: paddle.linalg.multi_dot(list[Tensor([8, 3175201],"float64"),Tensor([3175201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 3175201],"float64"),Tensor([3175201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 34927243 	 1000 	 0.4025728702545166 	 0.40820741653442383 	 0.10264039039611816 	 0.10408473014831543 	 1.960508108139038 	 1.6148936748504639 	 0.11122465133666992 	 0.13712692260742188 	 
2025-07-30 21:20:40.358380 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 6350401],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 6350401],"float64"),], ) 	 25401682 	 1000 	 1.3653080463409424 	 1.408193826675415 	 0.15506720542907715 	 0.16006064414978027 	 3.4757256507873535 	 2.1334707736968994 	 0.1476142406463623 	 0.16834306716918945 	 
2025-07-30 21:20:50.748874 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 5080321],"float64"),Tensor([5080321, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 5080321],"float64"),Tensor([5080321, 5],"float64"),], ) 	 40642634 	 1000 	 0.6508288383483887 	 0.6361057758331299 	 0.16592741012573242 	 0.16211652755737305 	 3.063199996948242 	 2.5034079551696777 	 0.15758728981018066 	 0.18268489837646484 	 
2025-07-30 21:21:00.250907 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 8467201],"float64"),Tensor([8467201, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 8467201],"float64"),Tensor([8467201, 5],"float64"),], ) 	 67737674 	 1000 	 1.0518581867218018 	 1.0306921005249023 	 0.2675611972808838 	 0.2624928951263428 	 5.050674915313721 	 4.168296575546265 	 0.1846299171447754 	 0.19332528114318848 	 
2025-07-30 21:21:13.702518 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 4233601],"float64"),Tensor([4233601, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 4233601],"float64"),Tensor([4233601, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 42336078 	 1000 	 0.5293452739715576 	 0.5304892063140869 	 0.13603544235229492 	 0.13527131080627441 	 2.5914785861968994 	 2.138798713684082 	 0.13217782974243164 	 0.15603137016296387 	 
2025-07-30 21:21:20.374046 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 6350401],"float64"),Tensor([6350401, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 6350401],"float64"),Tensor([6350401, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 63504078 	 1000 	 0.7755093574523926 	 0.7780632972717285 	 0.19739127159118652 	 0.19841384887695312 	 3.8543968200683594 	 3.199042558670044 	 0.16589140892028809 	 0.18344569206237793 	 
2025-07-30 21:21:30.404577 test begin: paddle.linalg.multi_dot(list[Tensor([8, 8467201],"float64"),Tensor([8467201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([8, 8467201],"float64"),Tensor([8467201, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 5],"float64"),], ) 	 93139243 	 1000 	 1.02054762840271 	 1.0290050506591797 	 0.26023149490356445 	 0.2624359130859375 	 5.11714768409729 	 4.262737989425659 	 0.18622803688049316 	 0.19751358032226562 	 
2025-07-30 21:21:44.680668 test begin: paddle.linalg.multi_dot(list[Tensor([819407],"float64"),Tensor([819407, 31],"float64"),], )
[Prof] paddle.linalg.multi_dot 	 paddle.linalg.multi_dot(list[Tensor([819407],"float64"),Tensor([819407, 31],"float64"),], ) 	 26221024 	 1000 	 0.16644787788391113 	 0.16579771041870117 	 0.08565807342529297 	 0.08460330963134766 	 0.4506673812866211 	 0.33775830268859863 	 0.230804443359375 	 0.17177939414978027 	 
2025-07-30 21:21:46.355396 test begin: paddle.linalg.norm(Tensor([12700801, 1, 4],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([12700801, 1, 4],"float32"), p=1.0, axis=-1, ) 	 50803204 	 1000 	 0.4058403968811035 	 0.4903717041015625 	 0.3837471008300781 	 0.4705009460449219 	 1.9899349212646484 	 0.6424262523651123 	 1.9348747730255127 	 0.3280947208404541 	 
2025-07-30 21:21:50.951455 test begin: paddle.linalg.norm(Tensor([25402, 50, 20],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([25402, 50, 20],"float64"), p=2.0, axis=-1, ) 	 25402000 	 1000 	 0.320051908493042 	 0.2674741744995117 	 0.16350865364074707 	 0.24003362655639648 	 1.4692378044128418 	 0.9350824356079102 	 1.4058237075805664 	 0.23903179168701172 	 
2025-07-30 21:21:54.537038 test begin: paddle.linalg.norm(Tensor([50, 25402, 20],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50, 25402, 20],"float64"), p=2.0, axis=-1, ) 	 25402000 	 1000 	 0.32142019271850586 	 0.2684504985809326 	 0.16489624977111816 	 0.24797964096069336 	 1.4692423343658447 	 0.9366862773895264 	 1.4148285388946533 	 0.2390592098236084 	 
2025-07-30 21:21:58.084656 test begin: paddle.linalg.norm(Tensor([50, 50, 10161],"float64"), p=2.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50, 50, 10161],"float64"), p=2.0, axis=-1, ) 	 25402500 	 1000 	 0.15767240524291992 	 0.1519944667816162 	 0.08055448532104492 	 0.1331796646118164 	 1.4812250137329102 	 0.9105720520019531 	 1.4270203113555908 	 0.2328026294708252 	 
2025-07-30 21:22:02.693248 test begin: paddle.linalg.norm(Tensor([50803201],"float32"), p=2, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([50803201],"float32"), p=2, ) 	 50803201 	 1000 	 0.15268564224243164 	 0.15239262580871582 	 0.05190086364746094 	 0.07783985137939453 	 0.9990847110748291 	 0.9143037796020508 	 0.9453437328338623 	 0.23389244079589844 	 
2025-07-30 21:22:06.426270 test begin: paddle.linalg.norm(Tensor([8550, 1, 5942],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([8550, 1, 5942],"float32"), p=1.0, axis=-1, ) 	 50804100 	 1000 	 0.1504044532775879 	 0.15722990036010742 	 0.1315913200378418 	 0.13356757164001465 	 1.9223477840423584 	 0.6058981418609619 	 1.8681399822235107 	 0.309558629989624 	 
2025-07-30 21:22:10.117518 test begin: paddle.linalg.norm(Tensor([8550, 1486, 4],"float32"), p=1.0, axis=-1, )
[Prof] paddle.linalg.norm 	 paddle.linalg.norm(Tensor([8550, 1486, 4],"float32"), p=1.0, axis=-1, ) 	 50821200 	 1000 	 0.40770745277404785 	 0.4891941547393799 	 0.37984299659729004 	 0.46146154403686523 	 1.987668514251709 	 0.6396434307098389 	 1.9243414402008057 	 0.32677507400512695 	 
2025-07-30 21:22:14.765971 test begin: paddle.linalg.pinv(Tensor([21, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([21, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 	 2520 	 1000 	 54.92759847640991 	 0.40737366676330566 	 4.839897155761719e-05 	 7.677078247070312e-05 	 0.46464109420776367 	 0.28864407539367676 	 3.361701965332031e-05 	 6.389617919921875e-05 	 
2025-07-30 21:23:11.272740 test begin: paddle.linalg.pinv(Tensor([22, 20, 3],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([22, 20, 3],"float64"), rcond=1e-15, hermitian=False, ) 	 1320 	 1000 	 9.537219285964966 	 0.3660244941711426 	 4.220008850097656e-05 	 9.918212890625e-05 	 0.47455263137817383 	 0.2900815010070801 	 6.031990051269531e-05 	 5.459785461425781e-05 	 
2025-07-30 21:23:21.959412 test begin: paddle.linalg.pinv(Tensor([3, 22, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(Tensor([3, 22, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 	 1320 	 1000 	 29.490753650665283 	 0.3756678104400635 	 4.673004150390625e-05 	 7.772445678710938e-05 	 0.4670426845550537 	 0.28739309310913086 	 3.9577484130859375e-05 	 7.081031799316406e-05 	 
2025-07-30 21:23:52.618756 test begin: paddle.linalg.pinv(x=Tensor([58, 4, 4],"float64"), )
[Prof] paddle.linalg.pinv 	 paddle.linalg.pinv(x=Tensor([58, 4, 4],"float64"), ) 	 928 	 1000 	 25.161487102508545 	 0.3450050354003906 	 3.9577484130859375e-05 	 7.176399230957031e-05 	 0.4143493175506592 	 0.2853696346282959 	 4.100799560546875e-05 	 6.508827209472656e-05 	 
2025-07-30 21:24:18.859223 test begin: paddle.linalg.qr(Tensor([105, 3, 50, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([105, 3, 50, 8],"float64"), ) 	 126000 	 1000 	 29.7188458442688 	 10.65242862701416 	 0.00010132789611816406 	 0.0037741661071777344 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:24:59.302628 test begin: paddle.linalg.qr(Tensor([112, 3, 20, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([112, 3, 20, 6],"float64"), ) 	 40320 	 1000 	 29.040711641311646 	 10.444107294082642 	 0.00010919570922851562 	 0.003488779067993164 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:25:39.480805 test begin: paddle.linalg.qr(Tensor([2, 105, 100, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 105, 100, 12],"float64"), ) 	 252000 	 1000 	 30.130915641784668 	 7.841171741485596 	 0.00010609626770019531 	 0.004126787185668945 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:26:17.502891 test begin: paddle.linalg.qr(Tensor([2, 158, 100, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 158, 100, 8],"float64"), ) 	 252800 	 1000 	 30.800640106201172 	 11.21388840675354 	 0.000102996826171875 	 0.003970623016357422 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:26:59.675981 test begin: paddle.linalg.qr(Tensor([2, 211, 100, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 211, 100, 6],"float64"), ) 	 253200 	 1000 	 39.9605872631073 	 14.36164379119873 	 0.00011110305786132812 	 0.003786802291870117 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:27:54.155479 test begin: paddle.linalg.qr(Tensor([2, 3, 100, 423],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 100, 423],"float64"), ) 	 253800 	 1000 	 4.474885702133179 	 47.412964820861816 	 8.702278137207031e-05 	 0.5695433616638184 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:28:46.125087 test begin: paddle.linalg.qr(Tensor([2, 3, 3528, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 3528, 12],"float64"), ) 	 254016 	 1000 	 1.7941014766693115 	 1.5241649150848389 	 3.552436828613281e-05 	 0.020134925842285156 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:28:49.455769 test begin: paddle.linalg.qr(Tensor([2, 3, 529201, 8],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 529201, 8],"float64"), ) 	 25401648 	 1000 	 12.762089967727661 	 11.248284578323364 	 0.0008969306945800781 	 0.13890290260314941 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:29:14.123020 test begin: paddle.linalg.qr(Tensor([2, 3, 705601, 6],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([2, 3, 705601, 6],"float64"), ) 	 25401636 	 1000 	 13.783600807189941 	 12.13579249382019 	 0.0008909702301025391 	 0.15089058876037598 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:29:42.373979 test begin: paddle.linalg.qr(Tensor([70, 3, 50, 12],"float64"), )
[Prof] paddle.linalg.qr 	 paddle.linalg.qr(Tensor([70, 3, 50, 12],"float64"), ) 	 126000 	 1000 	 23.366861820220947 	 7.575332403182983 	 0.0001068115234375 	 0.00400543212890625 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:30:13.356238 test begin: paddle.linalg.slogdet(Tensor([3, 6773, 5, 5],"float32"), )
[Prof] paddle.linalg.slogdet 	 paddle.linalg.slogdet(Tensor([3, 6773, 5, 5],"float32"), ) 	 507975 	 1000 	 6.627780914306641 	 0.16037440299987793 	 0.0001087188720703125 	 7.200241088867188e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 3, 6773]) and output[0] has a shape of torch.Size([3, 6773]).
2025-07-30 21:30:21.363473 test begin: paddle.linalg.slogdet(Tensor([6773, 3, 5, 5],"float32"), )
[Prof] paddle.linalg.slogdet 	 paddle.linalg.slogdet(Tensor([6773, 3, 5, 5],"float32"), ) 	 507975 	 1000 	 6.885903835296631 	 0.22014236450195312 	 0.00012159347534179688 	 7.772445678710938e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 6773, 3]) and output[0] has a shape of torch.Size([6773, 3]).
2025-07-30 21:30:29.757238 test begin: paddle.linalg.solve(x=Tensor([129601, 14, 14],"float64"), y=Tensor([129601, 14, 2],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([129601, 14, 14],"float64"), y=Tensor([129601, 14, 2],"float64"), ) 	 29030624 	 1000 	 3.7141902446746826 	 2.3824069499969482 	 0.0012135505676269531 	 0.00023555755615234375 	 6.014758110046387 	 2.778374433517456 	 0.0026679039001464844 	 0.26067686080932617 	 
2025-07-30 21:30:45.506081 test begin: paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 1814401],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 1814401],"float64"), ) 	 25401810 	 1000 	 5.035860538482666 	 3.805565118789673 	 0.00391840934753418 	 0.00021505355834960938 	 6.0321691036224365 	 4.0563881397247314 	 0.0045375823974609375 	 0.46065664291381836 	 
2025-07-30 21:31:07.597222 test begin: paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 453601],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 453601],"float64"), ) 	 25402440 	 1000 	 4.185548543930054 	 2.8938310146331787 	 0.003048419952392578 	 0.00020599365234375 	 11.00824522972107 	 10.282426357269287 	 0.00948476791381836 	 0.585223913192749 	 
2025-07-30 21:31:37.331998 test begin: paddle.linalg.solve(x=Tensor([907201, 14, 14],"float64"), y=Tensor([907201, 14, 2],"float64"), )
[Prof] paddle.linalg.solve 	 paddle.linalg.solve(x=Tensor([907201, 14, 14],"float64"), y=Tensor([907201, 14, 2],"float64"), ) 	 203213024 	 1000 	 26.80612826347351 	 15.521310806274414 	 0.008506536483764648 	 0.0002524852752685547 	 42.719993352890015 	 19.00276279449463 	 0.01883864402770996 	 0.41597819328308105 	 
2025-07-30 21:33:26.525422 test begin: paddle.linalg.svdvals(Tensor([10, 3, 8467],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 3, 8467],"float64"), ) 	 254010 	 1000 	 6.8626532554626465 	 6.528552532196045 	 4.601478576660156e-05 	 0.0002505779266357422 	 15.422203779220581 	 0.09733915328979492 	 9.107589721679688e-05 	 6.175041198730469e-05 	 
2025-07-30 21:33:55.539005 test begin: paddle.linalg.svdvals(Tensor([10, 4233, 6],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 4233, 6],"float64"), ) 	 253980 	 1000 	 7.9547038078308105 	 7.664831638336182 	 0.00010514259338378906 	 0.0002532005310058594 	 19.354827165603638 	 0.11148285865783691 	 9.608268737792969e-05 	 6.747245788574219e-05 	 
2025-07-30 21:34:30.677541 test begin: paddle.linalg.svdvals(Tensor([10, 5080],"float32"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([10, 5080],"float32"), ) 	 50800 	 1000 	 2.359363317489624 	 0.8398807048797607 	 4.4345855712890625e-05 	 8.20159912109375e-05 	 6.451585531234741 	 0.0830228328704834 	 4.267692565917969e-05 	 7.987022399902344e-05 	 
2025-07-30 21:34:40.486133 test begin: paddle.linalg.svdvals(Tensor([40, 6350],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([40, 6350],"float64"), ) 	 254000 	 1000 	 35.586097240448 	 3.029543399810791 	 9.703636169433594e-05 	 7.271766662597656e-05 	 103.52642250061035 	 0.10249114036560059 	 9.012222290039062e-05 	 8.058547973632812e-05 	 
2025-07-30 21:37:02.895794 test begin: paddle.linalg.svdvals(Tensor([611, 3, 6],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([611, 3, 6],"float64"), ) 	 10998 	 1000 	 4.320061922073364 	 0.5061581134796143 	 5.054473876953125e-05 	 0.0002238750457763672 	 5.474744081497192 	 0.09790253639221191 	 8.845329284667969e-05 	 6.222724914550781e-05 	 
2025-07-30 21:37:13.316865 test begin: paddle.linalg.svdvals(Tensor([623, 12],"float32"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([623, 12],"float32"), ) 	 7476 	 1000 	 0.4278564453125 	 0.8390400409698486 	 4.0531158447265625e-05 	 7.224082946777344e-05 	 1.4130451679229736 	 0.08269596099853516 	 3.838539123535156e-05 	 5.245208740234375e-05 	 
2025-07-30 21:37:17.860638 test begin: paddle.linalg.svdvals(Tensor([635, 40],"float64"), )
[Prof] paddle.linalg.svdvals 	 paddle.linalg.svdvals(Tensor([635, 40],"float64"), ) 	 25400 	 1000 	 3.7308266162872314 	 2.909388780593872 	 4.4345855712890625e-05 	 0.0002052783966064453 	 11.584270238876343 	 0.13837623596191406 	 7.82012939453125e-05 	 4.649162292480469e-05 	 
2025-07-30 21:37:37.330614 test begin: paddle.log(Tensor([192, 40, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([192, 40, 6625],"float32"), ) 	 50880000 	 1000 	 0.29592275619506836 	 0.30729174613952637 	 0.28711485862731934 	 0.2860543727874756 	 0.45169711112976074 	 0.4517078399658203 	 0.39792609214782715 	 0.38813257217407227 	 
2025-07-30 21:37:40.551924 test begin: paddle.log(Tensor([307, 25, 6626],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([307, 25, 6626],"float32"), ) 	 50854550 	 1000 	 0.29731249809265137 	 0.30139756202697754 	 0.28841567039489746 	 0.2867472171783447 	 0.4488344192504883 	 0.4501314163208008 	 0.3953702449798584 	 0.38779377937316895 	 
2025-07-30 21:37:43.677614 test begin: paddle.log(Tensor([64, 120, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 120, 6625],"float32"), ) 	 50880000 	 1000 	 0.29587864875793457 	 0.31322526931762695 	 0.2870361804962158 	 0.28794193267822266 	 0.45160365104675293 	 0.45027732849121094 	 0.3980731964111328 	 0.38871097564697266 	 
2025-07-30 21:37:46.893162 test begin: paddle.log(Tensor([64, 120, 6626],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 120, 6626],"float32"), ) 	 50887680 	 1000 	 0.2960531711578369 	 0.2999258041381836 	 0.28712987899780273 	 0.2878551483154297 	 0.45181941986083984 	 0.4504227638244629 	 0.3984091281890869 	 0.3861362934112549 	 
2025-07-30 21:37:50.044474 test begin: paddle.log(Tensor([64, 25, 31753],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 25, 31753],"float32"), ) 	 50804800 	 1000 	 0.2954554557800293 	 0.2975938320159912 	 0.2867414951324463 	 0.28652310371398926 	 0.44994688034057617 	 0.44971728324890137 	 0.39655256271362305 	 0.3883633613586426 	 
2025-07-30 21:37:53.174897 test begin: paddle.log(Tensor([64, 40, 19846],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 40, 19846],"float32"), ) 	 50805760 	 1000 	 0.2967398166656494 	 0.3019602298736572 	 0.2878990173339844 	 0.28766298294067383 	 0.45114850997924805 	 0.4495668411254883 	 0.39716172218322754 	 0.38527750968933105 	 
2025-07-30 21:37:56.368579 test begin: paddle.log(Tensor([64, 80, 9923],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([64, 80, 9923],"float32"), ) 	 50805760 	 1000 	 0.2954840660095215 	 0.30429553985595703 	 0.2850189208984375 	 0.2877485752105713 	 0.4483814239501953 	 0.44960498809814453 	 0.39455413818359375 	 0.3872549533843994 	 
2025-07-30 21:37:59.526908 test begin: paddle.log(Tensor([96, 80, 6625],"float32"), )
[Prof] paddle.log 	 paddle.log(Tensor([96, 80, 6625],"float32"), ) 	 50880000 	 1000 	 0.29725217819213867 	 0.2980055809020996 	 0.2884712219238281 	 0.2866988182067871 	 0.45036888122558594 	 0.4503295421600342 	 0.39665985107421875 	 0.38889145851135254 	 
2025-07-30 21:38:02.684868 test begin: paddle.log10(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29666638374328613 	 0.3177461624145508 	 0.28786253929138184 	 0.2876851558685303 	 0.44930100440979004 	 0.7459380626678467 	 0.39576172828674316 	 0.3810920715332031 	 
2025-07-30 21:38:06.139506 test begin: paddle.log10(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29551005363464355 	 0.29759955406188965 	 0.2867860794067383 	 0.28671979904174805 	 0.45095324516296387 	 0.7483532428741455 	 0.39753055572509766 	 0.3835909366607666 	 
2025-07-30 21:38:09.605831 test begin: paddle.log10(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.log10 	 paddle.log10(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2955758571624756 	 0.3011939525604248 	 0.28688907623291016 	 0.28769445419311523 	 0.4495091438293457 	 0.746981143951416 	 0.3961524963378906 	 0.381023645401001 	 
2025-07-30 21:38:13.082286 test begin: paddle.log10(x=Tensor([12700801, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.30753660202026367 	 0.3067970275878906 	 0.29864978790283203 	 0.29559898376464844 	 0.44729137420654297 	 0.7450854778289795 	 0.39052796363830566 	 0.3801412582397461 	 
2025-07-30 21:38:15.927281 test begin: paddle.log10(x=Tensor([2, 12700801],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.3073246479034424 	 0.3067893981933594 	 0.2986459732055664 	 0.2957282066345215 	 0.44757723808288574 	 0.7474856376647949 	 0.39411306381225586 	 0.3818504810333252 	 
2025-07-30 21:38:18.824200 test begin: paddle.log10(x=Tensor([2, 3, 2, 2116801],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3, 2, 2116801],"float64"), ) 	 25401612 	 1000 	 0.30617618560791016 	 0.30671238899230957 	 0.2973933219909668 	 0.29558801651000977 	 0.44755983352661133 	 0.7450246810913086 	 0.3950510025024414 	 0.3805723190307617 	 
2025-07-30 21:38:22.831065 test begin: paddle.log10(x=Tensor([2, 3, 2116801, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3, 2116801, 2],"float64"), ) 	 25401612 	 1000 	 0.30771684646606445 	 1.0420589447021484 	 0.2982797622680664 	 0.2953684329986572 	 0.4473848342895508 	 0.7474091053009033 	 0.39259791374206543 	 0.38300228118896484 	 
2025-07-30 21:38:26.996495 test begin: paddle.log10(x=Tensor([2, 3175201, 2, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2, 3175201, 2, 2],"float64"), ) 	 25401608 	 1000 	 0.30757856369018555 	 0.30672335624694824 	 0.2986290454864502 	 0.2955772876739502 	 0.44760727882385254 	 0.7448868751525879 	 0.3942692279815674 	 0.3805832862854004 	 
2025-07-30 21:38:29.873940 test begin: paddle.log10(x=Tensor([2116801, 3, 2, 2],"float64"), )
[Prof] paddle.log10 	 paddle.log10(x=Tensor([2116801, 3, 2, 2],"float64"), ) 	 25401612 	 1000 	 0.30616116523742676 	 0.3067803382873535 	 0.28898143768310547 	 0.29521942138671875 	 0.45017504692077637 	 0.7461531162261963 	 0.39710259437561035 	 0.3805820941925049 	 
2025-07-30 21:38:32.789965 test begin: paddle.log1p(Tensor([10, 16935, 300],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([10, 16935, 300],"float32"), ) 	 50805000 	 1000 	 0.2954728603363037 	 0.2989945411682129 	 0.2866368293762207 	 0.28783488273620605 	 0.4495277404785156 	 0.7461762428283691 	 0.3964810371398926 	 0.3811326026916504 	 
2025-07-30 21:38:37.499910 test begin: paddle.log1p(Tensor([10, 200, 25402],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([10, 200, 25402],"float32"), ) 	 50804000 	 1000 	 0.2955970764160156 	 0.3012375831604004 	 0.28671956062316895 	 0.2879359722137451 	 0.44952917098999023 	 0.7484936714172363 	 0.3969581127166748 	 0.38367199897766113 	 
2025-07-30 21:38:41.545522 test begin: paddle.log1p(Tensor([1016065, 5, 5],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([1016065, 5, 5],"float64"), ) 	 25401625 	 1000 	 0.305387020111084 	 0.3367726802825928 	 0.29675841331481934 	 0.31945109367370605 	 0.44765663146972656 	 0.7450840473175049 	 0.38537096977233887 	 0.38065052032470703 	 
2025-07-30 21:38:44.475909 test begin: paddle.log1p(Tensor([108, 157920, 3],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([108, 157920, 3],"float32"), ) 	 51166080 	 1000 	 0.2978339195251465 	 0.30098724365234375 	 0.2889845371246338 	 0.2901883125305176 	 0.45389342308044434 	 0.7512438297271729 	 0.40110230445861816 	 0.3838317394256592 	 
2025-07-30 21:38:47.946201 test begin: paddle.log1p(Tensor([4, 157920, 81],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([4, 157920, 81],"float32"), ) 	 51166080 	 1000 	 0.29791951179504395 	 0.3176238536834717 	 0.28908586502075195 	 0.29125499725341797 	 0.45269346237182617 	 0.7540500164031982 	 0.3992044925689697 	 0.38526463508605957 	 
2025-07-30 21:38:51.473309 test begin: paddle.log1p(Tensor([4, 4233601, 3],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([4, 4233601, 3],"float32"), ) 	 50803212 	 1000 	 0.29545092582702637 	 0.3140144348144531 	 0.2864999771118164 	 0.2880396842956543 	 0.44953250885009766 	 0.7472739219665527 	 0.39612388610839844 	 0.3824481964111328 	 
2025-07-30 21:38:54.924870 test begin: paddle.log1p(Tensor([50000, 102, 5],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([50000, 102, 5],"float64"), ) 	 25500000 	 1000 	 0.30773138999938965 	 0.3379814624786377 	 0.29894065856933594 	 0.3269944190979004 	 0.4490809440612793 	 0.7477943897247314 	 0.39655089378356934 	 0.38202786445617676 	 
2025-07-30 21:38:57.895786 test begin: paddle.log1p(Tensor([50000, 5, 102],"float64"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([50000, 5, 102],"float64"), ) 	 25500000 	 1000 	 0.30631017684936523 	 0.34010839462280273 	 0.2975904941558838 	 0.32811641693115234 	 0.4492030143737793 	 0.7490952014923096 	 0.3938865661621094 	 0.38207578659057617 	 
2025-07-30 21:39:00.828699 test begin: paddle.log1p(Tensor([847, 200, 300],"float32"), )
[Prof] paddle.log1p 	 paddle.log1p(Tensor([847, 200, 300],"float32"), ) 	 50820000 	 1000 	 0.2957615852355957 	 0.29898858070373535 	 0.28696203231811523 	 0.28822994232177734 	 0.44954872131347656 	 0.748664379119873 	 0.39636754989624023 	 0.3824605941772461 	 
2025-07-30 21:39:04.280684 test begin: paddle.log2(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.2954423427581787 	 0.2976253032684326 	 0.2866363525390625 	 0.28653788566589355 	 0.4493064880371094 	 0.745959997177124 	 0.3955984115600586 	 0.3811614513397217 	 
2025-07-30 21:39:07.766388 test begin: paddle.log2(Tensor([10, 2540161],"float64"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 2540161],"float64"), ) 	 25401610 	 1000 	 0.30615973472595215 	 0.3097715377807617 	 0.2976861000061035 	 0.29694342613220215 	 0.4486658573150635 	 0.7450301647186279 	 0.3957216739654541 	 0.38062596321105957 	 
2025-07-30 21:39:10.642446 test begin: paddle.log2(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.29549360275268555 	 0.29761457443237305 	 0.28670310974121094 	 0.286557674407959 	 0.45101332664489746 	 0.7483792304992676 	 0.397083044052124 	 0.3835160732269287 	 
2025-07-30 21:39:14.140055 test begin: paddle.log2(Tensor([10, 5080321],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29557275772094727 	 0.2976081371307373 	 0.2867588996887207 	 0.2865865230560303 	 0.44964027404785156 	 0.7471089363098145 	 0.3959822654724121 	 0.38233375549316406 	 
2025-07-30 21:39:17.603578 test begin: paddle.log2(Tensor([2116801, 12],"float64"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([2116801, 12],"float64"), ) 	 25401612 	 1000 	 0.30615663528442383 	 0.3066883087158203 	 0.29766392707824707 	 0.29561805725097656 	 0.4488072395324707 	 0.744988203048706 	 0.39614295959472656 	 0.3806602954864502 	 
2025-07-30 21:39:20.467146 test begin: paddle.log2(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2954988479614258 	 0.29759788513183594 	 0.2866995334625244 	 0.28648853302001953 	 0.449552059173584 	 0.7497258186340332 	 0.39553260803222656 	 0.382310152053833 	 
2025-07-30 21:39:23.903797 test begin: paddle.log2(Tensor([4233601, 12],"float32"), )
[Prof] paddle.log2 	 paddle.log2(Tensor([4233601, 12],"float32"), ) 	 50803212 	 1000 	 0.29549074172973633 	 0.2975935935974121 	 0.2865486145019531 	 0.28659939765930176 	 0.44974613189697266 	 0.747316837310791 	 0.39594435691833496 	 0.3810999393463135 	 
2025-07-30 21:39:27.445056 test begin: paddle.logaddexp(Tensor([10, 16935, 300],"float32"), Tensor([10, 16935, 300],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 16935, 300],"float32"), Tensor([10, 16935, 300],"float32"), ) 	 101610000 	 1000 	 2.533724784851074 	 1.3918752670288086 	 0.36954164505004883 	 0.432558536529541 	 4.626972436904907 	 2.9824116230010986 	 0.5245053768157959 	 0.38047027587890625 	 
2025-07-30 21:39:42.933794 test begin: paddle.logaddexp(Tensor([10, 16935, 300],"int32"), Tensor([10, 16935, 300],"int32"), )
W0730 21:39:47.588158 31139 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 16935, 300],"int32"), Tensor([10, 16935, 300],"int32"), ) 	 101610000 	 1000 	 2.829157829284668 	 0.45066237449645996 	 0.36218786239624023 	 0.4395151138305664 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:39:48.287740 test begin: paddle.logaddexp(Tensor([10, 200, 12701],"int64"), Tensor([10, 200, 12701],"int64"), )
W0730 21:39:51.698948 31520 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 12701],"int64"), Tensor([10, 200, 12701],"int64"), ) 	 50804000 	 1000 	 2.3224332332611084 	 0.2299032211303711 	 0.2963242530822754 	 0.21840763092041016 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:39:52.104575 test begin: paddle.logaddexp(Tensor([10, 200, 25402],"float32"), Tensor([10, 200, 25402],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 25402],"float32"), Tensor([10, 200, 25402],"float32"), ) 	 101608000 	 1000 	 2.533801555633545 	 0.45174074172973633 	 0.370898962020874 	 0.4388771057128906 	 4.626730442047119 	 2.9807512760162354 	 0.5257413387298584 	 0.3804283142089844 	 
2025-07-30 21:40:05.544994 test begin: paddle.logaddexp(Tensor([10, 200, 25402],"int32"), Tensor([10, 200, 25402],"int32"), )
W0730 21:40:10.253933 32676 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 200, 25402],"int32"), Tensor([10, 200, 25402],"int32"), ) 	 101608000 	 1000 	 2.8275396823883057 	 0.45186758041381836 	 0.3609144687652588 	 0.4407329559326172 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:40:10.983467 test begin: paddle.logaddexp(Tensor([10, 8468, 300],"int64"), Tensor([10, 8468, 300],"int64"), )
W0730 21:40:14.402829 33054 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([10, 8468, 300],"int64"), Tensor([10, 8468, 300],"int64"), ) 	 50808000 	 1000 	 2.323975086212158 	 0.22992491722106934 	 0.2964193820953369 	 0.21842217445373535 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:40:14.882429 test begin: paddle.logaddexp(Tensor([424, 200, 300],"int64"), Tensor([424, 200, 300],"int64"), )
W0730 21:40:18.257731 33310 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int64) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():9.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([424, 200, 300],"int64"), Tensor([424, 200, 300],"int64"), ) 	 50880000 	 1000 	 2.326990842819214 	 0.2434699535369873 	 0.2969682216644287 	 0.2185988426208496 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:40:18.732487 test begin: paddle.logaddexp(Tensor([847, 200, 300],"float32"), Tensor([847, 200, 300],"float32"), )
[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([847, 200, 300],"float32"), Tensor([847, 200, 300],"float32"), ) 	 101640000 	 1000 	 2.5322694778442383 	 0.4520735740661621 	 0.369565486907959 	 0.44065022468566895 	 4.627046346664429 	 2.98291277885437 	 0.5243704319000244 	 0.3818085193634033 	 
2025-07-30 21:40:31.978220 test begin: paddle.logaddexp(Tensor([847, 200, 300],"int32"), Tensor([847, 200, 300],"int32"), )
W0730 21:40:36.686573 34399 backward.cc:462] While running Node (AbsGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (int32) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():7.] (at ../paddle/phi/core/dense_tensor.cc:153)

[Prof] paddle.logaddexp 	 paddle.logaddexp(Tensor([847, 200, 300],"int32"), Tensor([847, 200, 300],"int32"), ) 	 101640000 	 1000 	 2.8261919021606445 	 0.46393680572509766 	 0.36103248596191406 	 0.4327683448791504 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:40:40.348336 test begin: paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=-1, ) 	 50803300 	 1000 	 3.386676073074341 	 2.4896903038024902 	 3.3770558834075928 	 2.477936267852783 	 10.91281795501709 	 10.836679935455322 	 1.0136723518371582 	 0.5529532432556152 	 
2025-07-30 21:41:11.162468 test begin: paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=0, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 10, 508033],"float32"), axis=0, ) 	 50803300 	 1000 	 23.83889937400818 	 0.36038994789123535 	 8.152286529541016 	 0.3435852527618408 	 192.51009440422058 	 6.571565628051758 	 13.089646816253662 	 0.3354475498199463 	 
2025-07-30 21:44:56.481379 test begin: paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=-1, ) 	 50803300 	 1000 	 22.89402961730957 	 103.92983078956604 	 22.884530067443848 	 103.9180097579956 	 190.64946460723877 	 213.50802969932556 	 17.737671375274658 	 10.885618686676025 	 
2025-07-30 21:53:50.533605 test begin: paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=0, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([10, 508033, 10],"float32"), axis=0, ) 	 50803300 	 1000 	 23.78912091255188 	 0.36249756813049316 	 8.11063265800476 	 0.3422231674194336 	 192.66138982772827 	 6.573398113250732 	 13.10279631614685 	 0.33546900749206543 	 
2025-07-30 21:57:37.517950 test begin: paddle.logcumsumexp(Tensor([508033, 10, 10],"float32"), axis=-1, )
[Prof] paddle.logcumsumexp 	 paddle.logcumsumexp(Tensor([508033, 10, 10],"float32"), axis=-1, ) 	 50803300 	 1000 	 22.927457571029663 	 103.98185992240906 	 22.917913913726807 	 103.96281552314758 	 190.74232029914856 	 213.82843255996704 	 17.743645191192627 	 10.90546703338623 	 
2025-07-30 22:06:31.275684 test begin: paddle.logical_and(Tensor([138, 369303],"bool"), Tensor([138, 369303],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([138, 369303],"bool"), Tensor([138, 369303],"bool"), ) 	 101927628 	 1000 	 0.11804986000061035 	 0.12561416625976562 	 0.10910677909851074 	 0.10385775566101074 	 None 	 None 	 None 	 None 	 
2025-07-30 22:06:33.125384 test begin: paddle.logical_and(Tensor([146, 349866],"bool"), Tensor([146, 349866],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([146, 349866],"bool"), Tensor([146, 349866],"bool"), ) 	 102160872 	 1000 	 0.11844968795776367 	 0.11986017227172852 	 0.10933923721313477 	 0.10399174690246582 	 None 	 None 	 None 	 None 	 
2025-07-30 22:06:34.829107 test begin: paddle.logical_and(Tensor([49, 1036801],"bool"), Tensor([49, 1036801],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([49, 1036801],"bool"), Tensor([49, 1036801],"bool"), ) 	 101606498 	 1000 	 0.1181180477142334 	 0.11845898628234863 	 0.10876584053039551 	 0.10279440879821777 	 None 	 None 	 None 	 None 	 
2025-07-30 22:06:39.320564 test begin: paddle.logical_and(Tensor([53, 958551],"bool"), Tensor([53, 958551],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([53, 958551],"bool"), Tensor([53, 958551],"bool"), ) 	 101606406 	 1000 	 0.1181173324584961 	 0.14558148384094238 	 0.10157442092895508 	 0.09400415420532227 	 None 	 None 	 None 	 None 	 
2025-07-30 22:06:41.455298 test begin: paddle.logical_and(Tensor([55, 923695],"bool"), Tensor([55, 923695],"bool"), )
[Prof] paddle.logical_and 	 paddle.logical_and(Tensor([55, 923695],"bool"), Tensor([55, 923695],"bool"), ) 	 101606450 	 1000 	 0.11808896064758301 	 0.11629557609558105 	 0.1015937328338623 	 0.1027064323425293 	 None 	 None 	 None 	 None 	 
2025-07-30 22:06:43.121984 test begin: paddle.logical_not(Tensor([2150400, 237],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2150400, 237],"bool"), ) 	 509644800 	 1000 	 0.7895560264587402 	 0.7494709491729736 	 0.7808036804199219 	 0.7365930080413818 	 None 	 None 	 None 	 None 	 
2025-07-30 22:06:52.372292 test begin: paddle.logical_not(Tensor([2204160, 231],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2204160, 231],"bool"), ) 	 509160960 	 1000 	 0.7834727764129639 	 0.7514116764068604 	 0.7746331691741943 	 0.7372729778289795 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:02.133560 test begin: paddle.logical_not(Tensor([2257920, 226],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([2257920, 226],"bool"), ) 	 510289920 	 1000 	 0.789334774017334 	 0.7573652267456055 	 0.7806024551391602 	 0.7409892082214355 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:10.890269 test begin: paddle.logical_not(Tensor([6350410, 80],"bool"), )
[Prof] paddle.logical_not 	 paddle.logical_not(Tensor([6350410, 80],"bool"), ) 	 508032800 	 1000 	 0.7854592800140381 	 0.751279354095459 	 0.7766742706298828 	 0.7384524345397949 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:19.776931 test begin: paddle.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11758017539978027 	 0.11592936515808105 	 0.10880017280578613 	 0.10076236724853516 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:21.442533 test begin: paddle.logical_or(Tensor([640, 79381],"bool"), Tensor([640, 79381],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([640, 79381],"bool"), Tensor([640, 79381],"bool"), ) 	 101607680 	 1000 	 0.11759090423583984 	 0.11494731903076172 	 0.10868573188781738 	 0.10184168815612793 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:23.252492 test begin: paddle.logical_or(Tensor([79381, 640],"bool"), Tensor([79381, 640],"bool"), )
[Prof] paddle.logical_or 	 paddle.logical_or(Tensor([79381, 640],"bool"), Tensor([79381, 640],"bool"), ) 	 101607680 	 1000 	 0.11911797523498535 	 0.11757540702819824 	 0.11017084121704102 	 0.10176968574523926 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:25.150077 test begin: paddle.logical_xor(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 50803600 	 1000 	 0.19085073471069336 	 0.23816776275634766 	 0.1732172966003418 	 0.21754956245422363 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:26.407453 test begin: paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 1],"float32"), ) 	 50803600 	 1000 	 0.18869590759277344 	 0.238525390625 	 0.1780695915222168 	 0.22112512588500977 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:27.671658 test begin: paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 20, 254017],"float32"), Tensor([10, 20, 254017],"float32"), ) 	 101606800 	 1000 	 0.3277587890625 	 0.3430945873260498 	 0.3186819553375244 	 0.314666748046875 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:30.115926 test begin: paddle.logical_xor(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([10, 5080321, 1],"float32"), Tensor([10, 5080321, 1],"float32"), ) 	 101606420 	 1000 	 0.32656431198120117 	 0.32790589332580566 	 0.3171236515045166 	 0.31430530548095703 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:32.590424 test begin: paddle.logical_xor(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.logical_xor 	 paddle.logical_xor(Tensor([2540161, 20, 1],"float32"), Tensor([2540161, 20, 1],"float32"), ) 	 101606440 	 1000 	 0.3279550075531006 	 0.3329939842224121 	 0.3186666965484619 	 0.31587815284729004 	 None 	 None 	 None 	 None 	 
2025-07-30 22:07:35.098455 test begin: paddle.logit(Tensor([10, 20, 254017],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([10, 20, 254017],"float32"), 0.001, ) 	 50803400 	 1000 	 0.29756617546081543 	 0.7466728687286377 	 0.2808358669281006 	 0.280029296875 	 0.44964599609375 	 0.4500424861907959 	 0.38751769065856934 	 0.38135671615600586 	 
2025-07-30 22:07:39.822356 test begin: paddle.logit(Tensor([10, 5080321, 1],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([10, 5080321, 1],"float32"), 0.001, ) 	 50803210 	 1000 	 0.2996203899383545 	 0.2997870445251465 	 0.2905564308166504 	 0.28734254837036133 	 0.4509871006011963 	 0.44995665550231934 	 0.39811277389526367 	 0.3886730670928955 	 
2025-07-30 22:07:43.009781 test begin: paddle.logit(Tensor([2540161, 20, 1],"float32"), 0.001, )
[Prof] paddle.logit 	 paddle.logit(Tensor([2540161, 20, 1],"float32"), 0.001, ) 	 50803220 	 1000 	 0.29837822914123535 	 0.30121302604675293 	 0.28607892990112305 	 0.2883272171020508 	 0.45092344284057617 	 0.45005011558532715 	 0.3744356632232666 	 0.38875341415405273 	 
2025-07-30 22:07:46.507361 test begin: paddle.logit(Tensor([50803201],"float32"), 1e-08, )
[Prof] paddle.logit 	 paddle.logit(Tensor([50803201],"float32"), 1e-08, ) 	 50803201 	 1000 	 0.2983839511871338 	 0.299940824508667 	 0.2892639636993408 	 0.2805328369140625 	 0.44969797134399414 	 0.4514634609222412 	 0.39658236503601074 	 0.3754091262817383 	 
2025-07-30 22:07:49.829990 test begin: paddle.logit(x=Tensor([4, 3, 2, 1058401],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 3, 2, 1058401],"float64"), eps=0.2, ) 	 25401624 	 1000 	 0.325366735458374 	 0.3174111843109131 	 0.3088114261627197 	 0.2895841598510742 	 0.4469022750854492 	 0.4488489627838135 	 0.3850057125091553 	 0.38656067848205566 	 
2025-07-30 22:07:52.476392 test begin: paddle.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, ) 	 25401660 	 1000 	 0.32529258728027344 	 0.30529212951660156 	 0.31600165367126465 	 0.2914745807647705 	 0.44287610054016113 	 0.4500584602355957 	 0.38991475105285645 	 0.37505149841308594 	 
2025-07-30 22:07:55.088340 test begin: paddle.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, ) 	 25401640 	 1000 	 0.32686781883239746 	 0.30290889739990234 	 0.31734538078308105 	 0.2901604175567627 	 0.4441053867340088 	 0.44884490966796875 	 0.39005208015441895 	 0.38672304153442383 	 
2025-07-30 22:07:57.681408 test begin: paddle.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.logit 	 paddle.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, ) 	 25401630 	 1000 	 0.32534360885620117 	 0.30292773246765137 	 0.3159940242767334 	 0.28847312927246094 	 0.4467594623565674 	 0.44884324073791504 	 0.3929119110107422 	 0.38274073600769043 	 
2025-07-30 22:08:00.293554 test begin: paddle.logsumexp(Tensor([1024, 49613],"float32"), axis=1, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([1024, 49613],"float32"), axis=1, ) 	 50803712 	 1000 	 0.711979866027832 	 0.9359514713287354 	 0.10392642021179199 	 0.1062459945678711 	 0.8146605491638184 	 0.9057369232177734 	 0.7604742050170898 	 0.3084573745727539 	 
2025-07-30 22:08:05.623047 test begin: paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=-1, keepdim=False, ) 	 50808000 	 1000 	 0.6360187530517578 	 0.9401743412017822 	 0.1307086944580078 	 0.10687518119812012 	 1.2136352062225342 	 0.9095706939697266 	 1.158987045288086 	 0.30985283851623535 	 
2025-07-30 22:08:10.194408 test begin: paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 200, 8468],"float32"), axis=list[0,2,], keepdim=False, ) 	 50808000 	 1000 	 0.7348315715789795 	 0.9876506328582764 	 0.10835576057434082 	 0.09163880348205566 	 1.2118580341339111 	 0.9128005504608154 	 1.1485164165496826 	 0.31090760231018066 	 
2025-07-30 22:08:14.982841 test begin: paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=-1, keepdim=False, ) 	 50804400 	 1000 	 0.667733907699585 	 1.6340925693511963 	 0.34182047843933105 	 0.18549394607543945 	 1.2357728481292725 	 0.9216921329498291 	 1.1816859245300293 	 0.3144500255584717 	 
2025-07-30 22:08:20.307506 test begin: paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([30, 42337, 40],"float32"), axis=list[0,2,], keepdim=False, ) 	 50804400 	 1000 	 0.7250254154205322 	 0.9499809741973877 	 0.14768409729003906 	 0.10812783241271973 	 1.220909595489502 	 0.9164025783538818 	 1.1564090251922607 	 0.31259727478027344 	 
2025-07-30 22:08:25.001162 test begin: paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=-1, keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=-1, keepdim=False, ) 	 50808000 	 1000 	 0.6664621829986572 	 1.634345293045044 	 0.3397634029388428 	 0.18545079231262207 	 1.2374155521392822 	 0.9206027984619141 	 1.1829781532287598 	 0.31307291984558105 	 
2025-07-30 22:08:30.374715 test begin: paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=list[0,2,], keepdim=False, )
[Prof] paddle.logsumexp 	 paddle.logsumexp(Tensor([6351, 200, 40],"float32"), axis=list[0,2,], keepdim=False, ) 	 50808000 	 1000 	 0.7405614852905273 	 0.992743730545044 	 0.1079263687133789 	 0.09206819534301758 	 1.211160659790039 	 0.9138534069061279 	 1.1567296981811523 	 0.31084299087524414 	 
2025-07-30 22:08:35.134760 test begin: paddle.masked_fill(Tensor([20, 127009, 20],"int32"), Tensor([20, 127009, 20],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([20, 127009, 20],"int32"), Tensor([20, 127009, 20],"bool"), 0, ) 	 101607200 	 1000 	 0.38291263580322266 	 0.6573944091796875 	 0.09790539741516113 	 0.22150254249572754 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:08:39.934046 test begin: paddle.masked_fill(Tensor([20, 60, 42337],"int32"), Tensor([20, 60, 42337],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([20, 60, 42337],"int32"), Tensor([20, 60, 42337],"bool"), 0, ) 	 101608800 	 1000 	 0.3804435729980469 	 0.6512126922607422 	 0.0969545841217041 	 0.22174286842346191 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:08:43.179853 test begin: paddle.masked_fill(Tensor([28225, 60, 30],"int32"), Tensor([28225, 60, 30],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([28225, 60, 30],"int32"), Tensor([28225, 60, 30],"bool"), 0, ) 	 101610000 	 1000 	 0.38316774368286133 	 0.6563427448272705 	 0.0979914665222168 	 0.22151541709899902 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:08:46.479226 test begin: paddle.masked_fill(Tensor([30, 56449, 30],"int32"), Tensor([30, 56449, 30],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([30, 56449, 30],"int32"), Tensor([30, 56449, 30],"bool"), 0, ) 	 101608200 	 1000 	 0.3833763599395752 	 0.650766134262085 	 0.09802985191345215 	 0.22155165672302246 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:08:49.877056 test begin: paddle.masked_fill(Tensor([30, 60, 28225],"int32"), Tensor([30, 60, 28225],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([30, 60, 28225],"int32"), Tensor([30, 60, 28225],"bool"), 0, ) 	 101610000 	 1000 	 0.3831441402435303 	 0.6522841453552246 	 0.09798312187194824 	 0.22302556037902832 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:08:53.652794 test begin: paddle.masked_fill(Tensor([42337, 60, 20],"int32"), Tensor([42337, 60, 20],"bool"), 0, )
[Prof] paddle.masked_fill 	 paddle.masked_fill(Tensor([42337, 60, 20],"int32"), Tensor([42337, 60, 20],"bool"), 0, ) 	 101608800 	 1000 	 0.3815925121307373 	 0.651177167892456 	 0.09818387031555176 	 0.22167277336120605 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:08:56.921513 test begin: paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([169345, 300],"float32"), ) 	 50839620 	 1000 	 0.6160120964050293 	 0.049599409103393555 	 2.2411346435546875e-05 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:08:58.715335 test begin: paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([120],"float32"), Tensor([300, 120],"bool"), Tensor([300, 169345],"float32"), ) 	 50839620 	 1000 	 0.461714506149292 	 0.03639698028564453 	 2.002716064453125e-05 	 6.580352783203125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:00.262239 test begin: paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([169345, 300],"float32"), ) 	 50815540 	 1000 	 0.5576093196868896 	 0.04716229438781738 	 4.1484832763671875e-05 	 9.083747863769531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:02.116788 test begin: paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([300, 40],"float32"), Tensor([40],"bool"), Tensor([300, 169345],"float32"), ) 	 50815540 	 1000 	 0.45615482330322266 	 0.04525184631347656 	 3.0279159545898438e-05 	 6.771087646484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:03.611619 test begin: paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([169345, 300],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([169345, 300],"float32"), ) 	 50819052 	 1000 	 0.4382917881011963 	 0.034963369369506836 	 1.9550323486328125e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:05.070952 test begin: paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([300, 169345],"float32"), )
[Prof] paddle.masked_scatter 	 paddle.masked_scatter(Tensor([6, 8, 9, 18],"float32"), Tensor([6, 8, 9, 18],"bool"), Tensor([300, 169345],"float32"), ) 	 50819052 	 1000 	 0.43471360206604004 	 0.034812211990356445 	 1.9788742065429688e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:08.091716 test begin: paddle.masked_select(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"bool"), ) 	 101802624 	 1000 	 1.3978323936462402 	 3.1682236194610596 	 0.0008761882781982422 	 0.0030159950256347656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:17.122247 test begin: paddle.masked_select(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"bool"), ) 	 101669568 	 1000 	 1.3841171264648438 	 3.1569106578826904 	 0.0008640289306640625 	 0.0030171871185302734 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:25.538543 test begin: paddle.masked_select(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"bool"), ) 	 101799936 	 1000 	 1.3945376873016357 	 3.1441333293914795 	 0.0008554458618164062 	 0.0030062198638916016 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:34.301634 test begin: paddle.masked_select(Tensor([16, 46695, 68],"float32"), Tensor([16, 46695, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([16, 46695, 68],"float32"), Tensor([16, 46695, 68],"bool"), ) 	 101608320 	 1000 	 1.393977165222168 	 3.1442196369171143 	 0.0008687973022460938 	 0.002997875213623047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:42.780010 test begin: paddle.masked_select(Tensor([62, 12096, 68],"float32"), Tensor([62, 12096, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([62, 12096, 68],"float32"), Tensor([62, 12096, 68],"bool"), ) 	 101993472 	 1000 	 1.3889520168304443 	 3.1629340648651123 	 0.0008616447448730469 	 0.0030312538146972656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:09:51.424490 test begin: paddle.masked_select(Tensor([68, 11109, 68],"float32"), Tensor([68, 11109, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([68, 11109, 68],"float32"), Tensor([68, 11109, 68],"bool"), ) 	 102736032 	 1000 	 1.4090237617492676 	 3.1868412494659424 	 0.0008745193481445312 	 0.0030829906463623047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:10:00.048951 test begin: paddle.masked_select(Tensor([74, 10164, 68],"float32"), Tensor([74, 10164, 68],"bool"), )
[Prof] paddle.masked_select 	 paddle.masked_select(Tensor([74, 10164, 68],"float32"), Tensor([74, 10164, 68],"bool"), ) 	 102290496 	 1000 	 1.3982431888580322 	 3.150052070617676 	 0.0008726119995117188 	 0.0030400753021240234 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:10:08.471034 test begin: paddle.matmul(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), ) 	 67633152 	 1000 	 1.6545400619506836 	 1.6520576477050781 	 1.6416773796081543 	 1.6290500164031982 	 1.8399536609649658 	 1.8402037620544434 	 0.9401731491088867 	 0.9424948692321777 	 
2025-07-30 22:10:18.022070 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 128],"float32"), ) 	 553648128 	 1000 	 8.219985246658325 	 8.20917296409607 	 8.206577777862549 	 8.174751996994019 	 16.407217741012573 	 16.4076247215271 	 8.385414600372314 	 8.38075065612793 	 
2025-07-30 22:11:21.052307 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 388],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 32, 4096, 388],"float32"), ) 	 587726848 	 1000 	 31.247368335723877 	 31.21579337120056 	 31.23395562171936 	 31.19256281852722 	 55.4160521030426 	 55.33723473548889 	 28.314493656158447 	 28.275691032409668 	 
2025-07-30 22:14:27.761793 test begin: paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), ) 	 603979776 	 1000 	 31.30595898628235 	 43.627458810806274 	 0.00011110305786132812 	 8.934107780456543 	 71.86889719963074 	 81.2771863937378 	 0.0077626705169677734 	 13.82130479812622 	 
2025-07-30 22:18:29.876240 test begin: paddle.matmul(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 128],"float32"), ) 	 69206016 	 1000 	 1.6508636474609375 	 2.08599591255188 	 1.6368615627288818 	 1.6235973834991455 	 2.683544635772705 	 2.6857569217681885 	 1.3711216449737549 	 1.3721692562103271 	 
2025-07-30 22:18:41.887973 test begin: paddle.matmul(Tensor([1, 97, 4096, 4096],"float32"), Tensor([1, 97, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1, 97, 4096, 4096],"float32"), Tensor([1, 97, 4096, 128],"float32"), ) 	 1678245888 	 1000 	 23.81364607810974 	 23.77514886856079 	 23.80006694793701 	 23.741816997528076 	 48.61597275733948 	 48.612276554107666 	 24.84051489830017 	 24.847585678100586 	 
2025-07-30 22:21:47.757219 test begin: paddle.matmul(Tensor([10, 23, 499, 3600],"float32"), Tensor([10, 23, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 23, 499, 3600],"float32"), Tensor([10, 23, 3600, 64],"float32"), ) 	 466164000 	 1000 	 6.475707054138184 	 6.4852635860443115 	 6.454076290130615 	 6.452898025512695 	 9.920385122299194 	 9.921873331069946 	 5.068673133850098 	 5.069391250610352 	 
2025-07-30 22:22:29.835580 test begin: paddle.matmul(Tensor([10, 3, 499, 3600],"float32"), Tensor([10, 3, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 3, 499, 3600],"float32"), Tensor([10, 3, 3600, 64],"float32"), ) 	 60804000 	 1000 	 1.453228235244751 	 1.451554298400879 	 1.4401686191558838 	 1.4166340827941895 	 1.4046587944030762 	 1.4033377170562744 	 0.7177591323852539 	 0.7169051170349121 	 
2025-07-30 22:22:39.281115 test begin: paddle.matmul(Tensor([10, 8, 177, 3600],"float32"), Tensor([10, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 177, 3600],"float32"), Tensor([10, 8, 3600, 64],"float32"), ) 	 69408000 	 1000 	 1.4521915912628174 	 1.4514119625091553 	 1.4309656620025635 	 1.406036376953125 	 1.4758000373840332 	 1.4817330837249756 	 0.7540714740753174 	 0.7569947242736816 	 
2025-07-30 22:22:46.325897 test begin: paddle.matmul(Tensor([10, 8, 499, 1273],"float32"), Tensor([10, 8, 1273, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 1273],"float32"), Tensor([10, 8, 1273, 64],"float32"), ) 	 57335920 	 1000 	 0.7811644077301025 	 0.7833011150360107 	 0.7601146697998047 	 0.7590789794921875 	 1.2659430503845215 	 1.2652013301849365 	 0.6481163501739502 	 0.6450355052947998 	 
2025-07-30 22:22:51.636993 test begin: paddle.matmul(Tensor([10, 8, 499, 3600],"float32"), Tensor([10, 8, 3600, 177],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 3600],"float32"), Tensor([10, 8, 3600, 177],"float32"), ) 	 194688000 	 1000 	 4.340090036392212 	 4.342577219009399 	 4.319152116775513 	 4.317729711532593 	 7.680826425552368 	 7.684272050857544 	 3.9259581565856934 	 3.9266233444213867 	 
2025-07-30 22:23:19.756461 test begin: paddle.matmul(Tensor([10, 8, 499, 9923],"float32"), Tensor([10, 8, 9923, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([10, 8, 499, 9923],"float32"), Tensor([10, 8, 9923, 64],"float32"), ) 	 446931920 	 1000 	 5.974546909332275 	 5.975225448608398 	 5.961350679397583 	 5.95185923576355 	 9.309941530227661 	 9.310694932937622 	 4.75712513923645 	 4.758108615875244 	 
2025-07-30 22:23:57.941463 test begin: paddle.matmul(Tensor([1379, 4, 256, 256],"float32"), Tensor([1379, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([1379, 4, 256, 256],"float32"), Tensor([1379, 4, 256, 36],"float32"), ) 	 412332032 	 1000 	 5.365561246871948 	 5.360905885696411 	 5.344571828842163 	 5.337592840194702 	 7.312232732772827 	 7.303549528121948 	 3.7351343631744385 	 3.7292914390563965 	 
2025-07-30 22:24:32.617676 test begin: paddle.matmul(Tensor([194, 4, 256, 256],"float32"), Tensor([194, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([194, 4, 256, 256],"float32"), Tensor([194, 4, 256, 36],"float32"), ) 	 58007552 	 1000 	 0.7929425239562988 	 0.7930428981781006 	 0.7769489288330078 	 0.7564113140106201 	 1.074077844619751 	 1.074045181274414 	 0.5487616062164307 	 0.5492358207702637 	 
2025-07-30 22:24:39.554378 test begin: paddle.matmul(Tensor([28, 8, 499, 3600],"float32"), Tensor([28, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([28, 8, 499, 3600],"float32"), Tensor([28, 8, 3600, 64],"float32"), ) 	 454003200 	 1000 	 6.477006912231445 	 6.477770090103149 	 6.463649749755859 	 6.454397916793823 	 9.702736616134644 	 9.704203844070435 	 4.958459377288818 	 4.957995176315308 	 
2025-07-30 22:25:20.853751 test begin: paddle.matmul(Tensor([4, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([4, 32, 4096, 4096],"float32"), Tensor([4, 32, 4096, 128],"float32"), ) 	 2214592512 	 1000 	 31.292654037475586 	 31.2368483543396 	 31.26871943473816 	 31.201194763183594 	 64.02999496459961 	 63.98733639717102 	 32.71643042564392 	 32.69721722602844 	 
2025-07-30 22:29:21.474520 test begin: paddle.matmul(Tensor([4, 8, 499, 3600],"float32"), Tensor([4, 8, 3600, 64],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([4, 8, 499, 3600],"float32"), Tensor([4, 8, 3600, 64],"float32"), ) 	 64857600 	 1000 	 1.4485726356506348 	 1.449082374572754 	 1.4355902671813965 	 1.4261841773986816 	 1.4382455348968506 	 1.437790870666504 	 0.7368342876434326 	 0.7345530986785889 	 
2025-07-30 22:29:28.435165 test begin: paddle.matmul(Tensor([512, 11, 256, 256],"float32"), Tensor([512, 11, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 11, 256, 256],"float32"), Tensor([512, 11, 256, 36],"float32"), ) 	 421003264 	 1000 	 5.460870265960693 	 5.470677852630615 	 5.447818994522095 	 5.429988384246826 	 7.449577331542969 	 7.4504430294036865 	 3.8071858882904053 	 3.805476665496826 	 
2025-07-30 22:30:02.725687 test begin: paddle.matmul(Tensor([512, 2, 256, 256],"float32"), Tensor([512, 2, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 2, 256, 256],"float32"), Tensor([512, 2, 256, 36],"float32"), ) 	 76546048 	 1000 	 1.0013611316680908 	 1.0038115978240967 	 0.9881844520568848 	 0.9791665077209473 	 1.374199390411377 	 1.371284008026123 	 0.7007396221160889 	 0.7019357681274414 	 
2025-07-30 22:30:08.923935 test begin: paddle.matmul(Tensor([512, 4, 256, 256],"float32"), Tensor([512, 4, 256, 97],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 4, 256, 256],"float32"), Tensor([512, 4, 256, 97],"float32"), ) 	 185073664 	 1000 	 2.005673408508301 	 2.0070252418518066 	 1.9926657676696777 	 1.9839859008789062 	 3.711141347885132 	 3.706568717956543 	 1.894989013671875 	 1.8932204246520996 	 
2025-07-30 22:30:24.281400 test begin: paddle.matmul(Tensor([512, 4, 97, 256],"float32"), Tensor([512, 4, 256, 36],"float32"), )
[Prof] paddle.matmul 	 paddle.matmul(Tensor([512, 4, 97, 256],"float32"), Tensor([512, 4, 256, 36],"float32"), ) 	 69730304 	 1000 	 1.0006721019744873 	 1.0005722045898438 	 0.9784610271453857 	 0.9775724411010742 	 1.223834753036499 	 1.226454734802246 	 0.6253032684326172 	 0.6265435218811035 	 
2025-07-30 22:30:30.259025 test begin: paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 12700801, 4],"float16"), ) 	 1016064080 	 1000 	 0.008840322494506836 	 0.003860950469970703 	 1.2874603271484375e-05 	 1.7881393432617188e-05 	 0.04024529457092285 	 0.05216383934020996 	 2.09808349609375e-05 	 3.8623809814453125e-05 	 combined
2025-07-30 22:31:15.278409 test begin: paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 16934401],"float16"), ) 	 1016064060 	 1000 	 0.004293918609619141 	 0.0037937164306640625 	 1.8358230590820312e-05 	 1.8596649169921875e-05 	 0.04023170471191406 	 0.05866265296936035 	 3.8623809814453125e-05 	 6.937980651855469e-05 	 combined
2025-07-30 22:32:01.142746 test begin: paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 4233601],"float64"), ) 	 254016060 	 1000 	 0.004274129867553711 	 0.003897428512573242 	 1.4066696166992188e-05 	 1.9311904907226562e-05 	 0.04079890251159668 	 0.05303025245666504 	 5.4836273193359375e-05 	 7.271766662597656e-05 	 combined
2025-07-30 22:32:11.866603 test begin: paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3, 8467201],"float32"), ) 	 508032060 	 1000 	 0.012828826904296875 	 0.010818958282470703 	 1.7404556274414062e-05 	 6.103515625e-05 	 0.04714059829711914 	 0.053107500076293945 	 5.555152893066406e-05 	 7.43865966796875e-05 	 combined
2025-07-30 22:32:32.616813 test begin: paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 3175201, 4],"float64"), ) 	 254016080 	 1000 	 0.00884556770324707 	 0.007222175598144531 	 1.3828277587890625e-05 	 1.9550323486328125e-05 	 0.050074100494384766 	 0.05923199653625488 	 4.9591064453125e-05 	 5.8650970458984375e-05 	 combined
2025-07-30 22:32:45.966412 test begin: paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([20, 6350401, 4],"float32"), ) 	 508032080 	 1000 	 0.004290342330932617 	 0.0038809776306152344 	 1.1205673217773438e-05 	 1.9788742065429688e-05 	 0.04018259048461914 	 0.05174994468688965 	 4.38690185546875e-05 	 4.553794860839844e-05 	 combined
2025-07-30 22:33:03.621391 test begin: paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([21168010, 3, 4],"float64"), ) 	 254016120 	 1000 	 0.004329681396484375 	 0.007170200347900391 	 1.1920928955078125e-05 	 1.9788742065429688e-05 	 0.04727673530578613 	 0.07778739929199219 	 6.198883056640625e-05 	 9.655952453613281e-05 	 combined
2025-07-30 22:33:14.300152 test begin: paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([42336010, 3, 4],"float32"), ) 	 508032120 	 1000 	 0.008870124816894531 	 0.003793001174926758 	 1.4543533325195312e-05 	 2.3365020751953125e-05 	 0.054860830307006836 	 0.0693514347076416 	 7.677078247070312e-05 	 7.43865966796875e-05 	 combined
2025-07-30 22:33:32.909798 test begin: paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), )
[Prof] paddle.matrix_transpose 	 paddle.matrix_transpose(Tensor([84672010, 3, 4],"float16"), ) 	 1016064120 	 1000 	 0.004339694976806641 	 0.0037736892700195312 	 1.4066696166992188e-05 	 1.8358230590820312e-05 	 0.04014277458190918 	 0.05201292037963867 	 3.123283386230469e-05 	 6.270408630371094e-05 	 combined
2025-07-30 22:34:11.638950 test begin: paddle.max(Tensor([416, 50, 10, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 50, 10, 256],"float32"), axis=1, ) 	 53248000 	 1000 	 0.1952977180480957 	 0.16027355194091797 	 0.18335795402526855 	 0.14522194862365723 	 1.1452438831329346 	 1.3968069553375244 	 0.29294848442077637 	 0.2847757339477539 	 
2025-07-30 22:34:15.508781 test begin: paddle.max(Tensor([416, 50, 7, 349],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 50, 7, 349],"float32"), axis=1, ) 	 50814400 	 1000 	 0.19673633575439453 	 0.16260218620300293 	 0.18496012687683105 	 0.14709687232971191 	 1.1098229885101318 	 1.339733362197876 	 0.2846384048461914 	 0.27418065071105957 	 
2025-07-30 22:34:19.193240 test begin: paddle.max(Tensor([416, 69, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([416, 69, 7, 256],"float32"), axis=1, ) 	 51437568 	 1000 	 0.19289731979370117 	 0.15674543380737305 	 0.18090295791625977 	 0.13973331451416016 	 1.0967562198638916 	 1.3421170711517334 	 0.2799818515777588 	 0.2748699188232422 	 
2025-07-30 22:34:22.952011 test begin: paddle.max(Tensor([49, 1024, 1024],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([49, 1024, 1024],"float32"), axis=-1, keepdim=True, ) 	 51380224 	 1000 	 0.15536999702453613 	 0.14959263801574707 	 0.14308762550354004 	 0.1357719898223877 	 1.0588843822479248 	 1.2894337177276611 	 0.27029991149902344 	 0.2633821964263916 	 
2025-07-30 22:34:27.824238 test begin: paddle.max(Tensor([512, 50, 7, 284],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 50, 7, 284],"float32"), axis=1, ) 	 50892800 	 1000 	 0.20385217666625977 	 0.15604615211486816 	 0.18375158309936523 	 0.13422274589538574 	 1.1176698207855225 	 1.3427343368530273 	 0.28561949729919434 	 0.2741866111755371 	 
2025-07-30 22:34:31.984466 test begin: paddle.max(Tensor([512, 50, 8, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 50, 8, 256],"float32"), axis=1, ) 	 52428800 	 1000 	 0.19258475303649902 	 0.15736865997314453 	 0.18079733848571777 	 0.14257574081420898 	 1.127882957458496 	 1.3735549449920654 	 0.28790783882141113 	 0.28054356575012207 	 
2025-07-30 22:34:38.988946 test begin: paddle.max(Tensor([512, 56, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([512, 56, 7, 256],"float32"), axis=1, ) 	 51380224 	 1000 	 0.19800710678100586 	 0.16788554191589355 	 0.18586349487304688 	 0.13966727256774902 	 1.1046671867370605 	 1.340402603149414 	 0.2822575569152832 	 0.2737855911254883 	 
2025-07-30 22:34:42.679813 test begin: paddle.max(Tensor([568, 50, 7, 256],"float32"), axis=1, )
[Prof] paddle.max 	 paddle.max(Tensor([568, 50, 7, 256],"float32"), axis=1, ) 	 50892800 	 1000 	 0.18938541412353516 	 0.15366554260253906 	 0.17714595794677734 	 0.13339662551879883 	 1.097797155380249 	 1.3395664691925049 	 0.2810487747192383 	 0.2739114761352539 	 
2025-07-30 22:34:46.470652 test begin: paddle.max(Tensor([8, 1024, 6202],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([8, 1024, 6202],"float32"), axis=-1, keepdim=True, ) 	 50806784 	 1000 	 0.15184354782104492 	 0.16369986534118652 	 0.1315929889678955 	 0.13699030876159668 	 1.0491132736206055 	 1.2946772575378418 	 0.2679767608642578 	 0.2651066780090332 	 
2025-07-30 22:34:50.011916 test begin: paddle.max(Tensor([8, 6202, 1024],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.max 	 paddle.max(Tensor([8, 6202, 1024],"float32"), axis=-1, keepdim=True, ) 	 50806784 	 1000 	 0.15523767471313477 	 0.14812397956848145 	 0.14289593696594238 	 0.13188600540161133 	 1.0456643104553223 	 1.2755141258239746 	 0.2672097682952881 	 0.26049041748046875 	 
2025-07-30 22:34:53.456176 test begin: paddle.maximum(Tensor([11585, 4386],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([11585, 4386],"float32"), Tensor([1],"float32"), ) 	 50811811 	 1000 	 0.29805827140808105 	 0.3045539855957031 	 0.28775501251220703 	 0.29259800910949707 	 0.7423360347747803 	 3.3112332820892334 	 0.25340771675109863 	 0.2825734615325928 	 
2025-07-30 22:34:59.777931 test begin: paddle.maximum(Tensor([120961, 420],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([120961, 420],"float32"), Tensor([1],"float32"), ) 	 50803621 	 1000 	 0.2968714237213135 	 0.30447840690612793 	 0.2864820957183838 	 0.28601646423339844 	 0.7410838603973389 	 3.3131041526794434 	 0.25208497047424316 	 0.2812309265136719 	 
2025-07-30 22:35:06.179003 test begin: paddle.maximum(Tensor([121539, 418],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([121539, 418],"float32"), Tensor([1],"float32"), ) 	 50803303 	 1000 	 0.2967832088470459 	 0.31620335578918457 	 0.2788527011871338 	 0.28585290908813477 	 0.743436336517334 	 3.3049864768981934 	 0.2532074451446533 	 0.28218984603881836 	 
2025-07-30 22:35:12.600911 test begin: paddle.maximum(Tensor([14877, 3415],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([14877, 3415],"float32"), Tensor([1],"float32"), ) 	 50804956 	 1000 	 0.29894542694091797 	 0.30448436737060547 	 0.28094029426574707 	 0.2861762046813965 	 0.742206335067749 	 3.3049588203430176 	 0.2519989013671875 	 0.2819514274597168 	 
2025-07-30 22:35:18.927947 test begin: paddle.maximum(Tensor([16121, 3152],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([16121, 3152],"float32"), Tensor([1],"float32"), ) 	 50813393 	 1000 	 0.2966017723083496 	 0.305828332901001 	 0.28627538681030273 	 0.29390454292297363 	 0.7406506538391113 	 3.3064498901367188 	 0.2519211769104004 	 0.2806668281555176 	 
2025-07-30 22:35:25.366603 test begin: paddle.maximum(Tensor([62643, 811],"float32"), Tensor([1],"float32"), )
[Prof] paddle.maximum 	 paddle.maximum(Tensor([62643, 811],"float32"), Tensor([1],"float32"), ) 	 50803474 	 1000 	 0.2967541217803955 	 0.3136579990386963 	 0.2864532470703125 	 0.2952859401702881 	 0.742081880569458 	 3.305217742919922 	 0.25194597244262695 	 0.2810215950012207 	 
2025-07-30 22:35:33.188053 test begin: paddle.mean(Tensor([7573, 11, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7573, 11, 1280],"bfloat16"), axis=1, ) 	 106627840 	 1000 	 0.2102038860321045 	 0.21015691757202148 	 0.19838762283325195 	 0.17760992050170898 	 0.3437206745147705 	 0.4510006904602051 	 0.2808361053466797 	 0.23038959503173828 	 
2025-07-30 22:35:41.364227 test begin: paddle.mean(Tensor([7573, 8, 1678],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7573, 8, 1678],"bfloat16"), axis=1, ) 	 101659952 	 1000 	 0.18629860877990723 	 0.18269610404968262 	 0.17506694793701172 	 0.16445684432983398 	 0.3475627899169922 	 0.444260835647583 	 0.2855541706085205 	 0.22693133354187012 	 
2025-07-30 22:35:44.443981 test begin: paddle.mean(Tensor([7710, 11, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7710, 11, 1280],"bfloat16"), axis=1, ) 	 108556800 	 1000 	 0.2140367031097412 	 0.2025752067565918 	 0.20276618003845215 	 0.18433547019958496 	 0.3507802486419678 	 0.46057724952697754 	 0.29056859016418457 	 0.23600363731384277 	 
2025-07-30 22:35:47.691898 test begin: paddle.mean(Tensor([7710, 8, 1648],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([7710, 8, 1648],"bfloat16"), axis=1, ) 	 101648640 	 1000 	 0.18551874160766602 	 0.17988872528076172 	 0.17424440383911133 	 0.16300559043884277 	 0.34993529319763184 	 0.44657444953918457 	 0.280637264251709 	 0.2281358242034912 	 
2025-07-30 22:35:50.726070 test begin: paddle.mean(Tensor([8162, 10, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([8162, 10, 1280],"bfloat16"), axis=1, ) 	 104473600 	 1000 	 0.20435214042663574 	 0.19202756881713867 	 0.18140339851379395 	 0.16954350471496582 	 0.34361982345581055 	 0.44922542572021484 	 0.2723217010498047 	 0.22949790954589844 	 
2025-07-30 22:35:53.876694 test begin: paddle.mean(Tensor([8162, 8, 1557],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([8162, 8, 1557],"bfloat16"), axis=1, ) 	 101665872 	 1000 	 0.18523406982421875 	 0.2202298641204834 	 0.17383670806884766 	 0.20119166374206543 	 0.3483572006225586 	 0.46283769607543945 	 0.2876863479614258 	 0.23568129539489746 	 
2025-07-30 22:35:57.177326 test begin: paddle.mean(Tensor([9923, 8, 1280],"bfloat16"), axis=1, )
[Prof] paddle.mean 	 paddle.mean(Tensor([9923, 8, 1280],"bfloat16"), axis=1, ) 	 101611520 	 1000 	 0.1823863983154297 	 0.1777510643005371 	 0.17107605934143066 	 0.16183161735534668 	 0.35135674476623535 	 0.4537525177001953 	 0.2908778190612793 	 0.231825590133667 	 
2025-07-30 22:36:00.211320 test begin: paddle.median(Tensor([2, 254016],"float32"), axis=1, mode="min", )
[Prof] paddle.median 	 paddle.median(Tensor([2, 254016],"float32"), axis=1, mode="min", ) 	 508032 	 1000 	 9.92721438407898 	 1.104341983795166 	 0.20043253898620605 	 1.0855116844177246 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:36:11.595958 test begin: paddle.median(Tensor([254016],"int64"), )
W0730 22:36:17.535874 14744 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.median 	 paddle.median(Tensor([254016],"int64"), ) 	 254016 	 1000 	 5.927646636962891 	 0.1806354522705078 	 0.2497255802154541 	 0.0002391338348388672 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:36:17.723874 test begin: paddle.median(Tensor([5080, 100],"float32"), axis=1, mode="min", )
[Prof] paddle.median 	 paddle.median(Tensor([5080, 100],"float32"), axis=1, mode="min", ) 	 508000 	 1000 	 2.7157130241394043 	 0.04342818260192871 	 0.07175397872924805 	 0.024444580078125 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 22:36:20.709489 test begin: paddle.median(Tensor([508032],"float32"), )
[Prof] paddle.median 	 paddle.median(Tensor([508032],"float32"), ) 	 508032 	 1000 	 6.8933515548706055 	 0.1599259376525879 	 0.38988471031188965 	 0.009575843811035156 	 0.5178558826446533 	 0.16214990615844727 	 0.04435563087463379 	 7.176399230957031e-05 	 combined
2025-07-30 22:36:28.463271 test begin: paddle.min(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.2724897861480713 	 0.1544325351715088 	 0.00018334388732910156 	 0.13956093788146973 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:36:30.546576 test begin: paddle.min(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.3409268856048584 	 0.15470337867736816 	 0.00024580955505371094 	 0.07905745506286621 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:36:32.720952 test begin: paddle.min(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402412 	 1000 	 7.5253424644470215 	 0.16314959526062012 	 0.0074880123138427734 	 0.08332991600036621 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:36:46.765287 test begin: paddle.min(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 8.216124534606934 	 0.15939640998840332 	 0.008078575134277344 	 0.08078956604003906 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:37:02.147375 test begin: paddle.min(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 7.535743474960327 	 0.1641855239868164 	 0.007471323013305664 	 0.0844719409942627 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:37:16.235996 test begin: paddle.min(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.21146535873413086 	 0.1722548007965088 	 0.0001697540283203125 	 0.08775448799133301 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:37:18.263359 test begin: paddle.min(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.min 	 paddle.min(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.3318753242492676 	 0.17650461196899414 	 0.00023436546325683594 	 0.09019303321838379 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:37:20.460416 test begin: paddle.min(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.min 	 paddle.min(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402007 	 1000 	 1.180980920791626 	 0.1607968807220459 	 0.0011398792266845703 	 0.08214259147644043 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:37:24.018574 test begin: paddle.min(Tensor([64, 1, 28, 28351],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1, 28, 28351],"float32"), ) 	 50804992 	 1000 	 0.1520991325378418 	 0.15315961837768555 	 0.07770895957946777 	 0.07822751998901367 	 1.0474214553833008 	 1.2523572444915771 	 0.213698148727417 	 0.21416664123535156 	 
2025-07-30 22:37:27.543637 test begin: paddle.min(Tensor([64, 1, 28351, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1, 28351, 28],"float32"), ) 	 50804992 	 1000 	 0.15212178230285645 	 0.15432476997375488 	 0.07772493362426758 	 0.07943367958068848 	 1.0464255809783936 	 1.250938892364502 	 0.21371746063232422 	 0.21268653869628906 	 
2025-07-30 22:37:31.016329 test begin: paddle.min(Tensor([64, 1013, 28, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64, 1013, 28, 28],"float32"), ) 	 50828288 	 1000 	 0.1520397663116455 	 0.15315961837768555 	 0.07770323753356934 	 0.07825160026550293 	 1.0480194091796875 	 1.2532615661621094 	 0.21500849723815918 	 0.21436190605163574 	 
2025-07-30 22:37:34.468696 test begin: paddle.min(Tensor([64801, 1, 28, 28],"float32"), )
[Prof] paddle.min 	 paddle.min(Tensor([64801, 1, 28, 28],"float32"), ) 	 50803984 	 1000 	 0.15198707580566406 	 0.15313124656677246 	 0.07766270637512207 	 0.07820725440979004 	 1.0447807312011719 	 1.2494397163391113 	 0.21370244026184082 	 0.212660551071167 	 
2025-07-30 22:37:40.152195 test begin: paddle.minimum(Tensor([13, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([13, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980628 	 1000 	 3.7944347858428955 	 4.114004611968994 	 3.774951457977295 	 2.0977835655212402 	 18.954289436340332 	 47.19293570518494 	 4.83520770072937 	 2.189697504043579 	 
2025-07-30 22:39:08.715402 test begin: paddle.minimum(Tensor([13, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([13, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803228 	 1000 	 3.779726505279541 	 4.102614879608154 	 3.7613134384155273 	 2.1078054904937744 	 32.40556049346924 	 46.75956869125366 	 8.27288031578064 	 2.16255521774292 	 
2025-07-30 22:40:49.139750 test begin: paddle.minimum(Tensor([16, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([16, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980967 	 1000 	 4.667973518371582 	 5.043641090393066 	 4.657403230667114 	 2.581165313720703 	 23.028701305389404 	 57.400830030441284 	 5.878704786300659 	 2.661942481994629 	 
2025-07-30 22:42:34.709649 test begin: paddle.minimum(Tensor([16, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([16, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803234 	 1000 	 4.64032244682312 	 5.0227251052856445 	 4.629701614379883 	 2.563227415084839 	 38.67582154273987 	 58.81444597244263 	 9.870869636535645 	 2.721742630004883 	 
2025-07-30 22:44:40.313310 test begin: paddle.minimum(Tensor([9, 1, 113],"float32"), Tensor([451143, 113],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([9, 1, 113],"float32"), Tensor([451143, 113],"float32"), ) 	 50980176 	 1000 	 2.6280980110168457 	 2.8341569900512695 	 2.6174392700195312 	 2.821070432662964 	 13.348435401916504 	 32.091036319732666 	 3.4079794883728027 	 2.522656202316284 	 
2025-07-30 22:45:42.125695 test begin: paddle.minimum(Tensor([9, 1, 2],"float32"), Tensor([25401601, 2],"float32"), )
[Prof] paddle.minimum 	 paddle.minimum(Tensor([9, 1, 2],"float32"), Tensor([25401601, 2],"float32"), ) 	 50803220 	 1000 	 2.6138393878936768 	 2.826714038848877 	 2.6032891273498535 	 2.8132572174072266 	 23.627836227416992 	 32.03011894226074 	 6.030010938644409 	 2.5183138847351074 	 
2025-07-30 22:46:52.697549 test begin: paddle.mm(Tensor([1838, 6, 144, 144],"float32"), Tensor([1838, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([1838, 6, 144, 144],"float32"), Tensor([1838, 6, 144, 32],"float32"), ) 	 279493632 	 1000 	 6.076934099197388 	 6.078022718429565 	 6.056105375289917 	 6.043972969055176 	 9.517947435379028 	 9.517186880111694 	 4.863409757614136 	 4.863077878952026 	 
2025-07-30 22:47:29.567313 test begin: paddle.mm(Tensor([2048, 2, 144, 144],"float32"), Tensor([2048, 2, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 2, 144, 144],"float32"), Tensor([2048, 2, 144, 32],"float32"), ) 	 103809024 	 1000 	 2.2663567066192627 	 2.270554304122925 	 2.244042158126831 	 2.230504035949707 	 3.550335645675659 	 3.5502679347991943 	 1.8121285438537598 	 1.8145136833190918 	 
2025-07-30 22:47:45.980079 test begin: paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 29],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 29],"float32"), ) 	 306118656 	 1000 	 6.761961460113525 	 6.764770746231079 	 6.740873575210571 	 6.739823579788208 	 10.337693929672241 	 10.3367338180542 	 5.282923936843872 	 5.282516717910767 	 
2025-07-30 22:48:26.590488 test begin: paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 144, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), ) 	 311427072 	 1000 	 6.758739233016968 	 6.775109052658081 	 6.736695051193237 	 6.745763301849365 	 10.5970458984375 	 10.595953464508057 	 5.414775371551514 	 5.414490461349487 	 
2025-07-30 22:49:08.370484 test begin: paddle.mm(Tensor([2048, 6, 29, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2048, 6, 29, 144],"float32"), Tensor([2048, 6, 144, 32],"float32"), ) 	 107937792 	 1000 	 3.392486810684204 	 3.400973320007324 	 3.370605945587158 	 3.3610618114471436 	 3.7517242431640625 	 3.748180389404297 	 1.9158501625061035 	 1.917816400527954 	 
2025-07-30 22:49:24.985335 test begin: paddle.mm(Tensor([2757, 4, 144, 144],"float32"), Tensor([2757, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([2757, 4, 144, 144],"float32"), Tensor([2757, 4, 144, 32],"float32"), ) 	 279493632 	 1000 	 6.076847076416016 	 6.074561357498169 	 6.06359338760376 	 6.0413877964019775 	 9.519581317901611 	 9.518126487731934 	 4.865175008773804 	 4.8632166385650635 	 
2025-07-30 22:50:02.732656 test begin: paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 1, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 1, 144, 32],"float32"), ) 	 97320960 	 1000 	 2.1382265090942383 	 2.145986318588257 	 2.125131130218506 	 2.1193222999572754 	 3.3436102867126465 	 3.342176675796509 	 1.7065975666046143 	 1.708960771560669 	 
2025-07-30 22:50:15.760313 test begin: paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 1, 144, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), ) 	 150405120 	 1000 	 9.591727495193481 	 9.92874550819397 	 6.794929504394531e-05 	 5.0736165046691895 	 14.667972326278687 	 14.378053426742554 	 0.0011892318725585938 	 4.8892502784729 	 
2025-07-30 22:51:08.267600 test begin: paddle.mm(Tensor([3840, 3, 144, 144],"float32"), Tensor([3840, 3, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 3, 144, 144],"float32"), Tensor([3840, 3, 144, 32],"float32"), ) 	 291962880 	 1000 	 6.344563245773315 	 6.386027097702026 	 6.323497295379639 	 6.358419418334961 	 9.937949657440186 	 9.936001062393188 	 5.078041076660156 	 5.076984643936157 	 
2025-07-30 22:51:48.572828 test begin: paddle.mm(Tensor([3840, 4, 144, 144],"float32"), Tensor([3840, 4, 144, 23],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 4, 144, 144],"float32"), Tensor([3840, 4, 144, 23],"float32"), ) 	 369377280 	 1000 	 8.449145317077637 	 8.447045803070068 	 8.435909748077393 	 8.42218804359436 	 11.959883689880371 	 11.963331699371338 	 6.110844612121582 	 6.1098809242248535 	 
2025-07-30 22:52:40.106913 test begin: paddle.mm(Tensor([3840, 4, 23, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([3840, 4, 23, 144],"float32"), Tensor([3840, 4, 144, 32],"float32"), ) 	 121651200 	 1000 	 4.230445623397827 	 4.251874685287476 	 4.2171385288238525 	 4.202683687210083 	 4.2331719398498535 	 4.231791257858276 	 2.1645474433898926 	 2.163026809692383 	 
2025-07-30 22:52:59.409994 test begin: paddle.mm(Tensor([409, 6, 144, 144],"float32"), Tensor([409, 6, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([409, 6, 144, 144],"float32"), Tensor([409, 6, 144, 32],"float32"), ) 	 62194176 	 1000 	 1.3717100620269775 	 1.3751890659332275 	 1.3586857318878174 	 1.3491733074188232 	 2.1463210582733154 	 2.143772840499878 	 1.0960252285003662 	 1.0962836742401123 	 
2025-07-30 22:53:08.286365 test begin: paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 1, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 1, 144, 32],"float32"), ) 	 103809024 	 1000 	 2.267176866531372 	 2.2831358909606934 	 2.25185227394104 	 2.23445200920105 	 3.550502300262451 	 3.550889253616333 	 1.8135063648223877 	 1.8169786930084229 	 
2025-07-30 22:53:22.104185 test begin: paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 1, 144, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), ) 	 160432128 	 1000 	 10.267875909805298 	 10.58714509010315 	 0.00013685226440429688 	 5.408623933792114 	 15.62082052230835 	 15.338554859161377 	 0.0012433528900146484 	 5.221084833145142 	 
2025-07-30 22:54:18.199171 test begin: paddle.mm(Tensor([4096, 3, 144, 144],"float32"), Tensor([4096, 3, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 3, 144, 144],"float32"), Tensor([4096, 3, 144, 32],"float32"), ) 	 311427072 	 1000 	 6.7598981857299805 	 6.760396480560303 	 6.7466113567352295 	 6.736973762512207 	 10.593271732330322 	 10.595084428787231 	 5.4139204025268555 	 5.4135918617248535 	 
2025-07-30 22:54:59.669686 test begin: paddle.mm(Tensor([4096, 4, 144, 144],"float32"), Tensor([4096, 4, 144, 22],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 4, 144, 144],"float32"), Tensor([4096, 4, 144, 22],"float32"), ) 	 391643136 	 1000 	 9.010179996490479 	 9.002661943435669 	 8.99731993675232 	 8.979097604751587 	 12.751720905303955 	 12.754921913146973 	 6.520807504653931 	 6.520186185836792 	 

2025-07-30 19:24:23.245199 test begin: paddle.mm(Tensor([4096, 4, 22, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), )
W0730 19:24:25.292330 23815 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.mm 	 paddle.mm(Tensor([4096, 4, 22, 144],"float32"), Tensor([4096, 4, 144, 32],"float32"), ) 	 127401984 	 1000 	 4.492326021194458 	 4.492844104766846 	 4.479162693023682 	 4.464272499084473 	 4.491032123565674 	 4.493708610534668 	 2.2948977947235107 	 2.2947254180908203 	 
2025-07-30 19:24:44.300714 test begin: paddle.mm(Tensor([613, 4, 144, 144],"float32"), Tensor([613, 4, 144, 32],"float32"), )
[Prof] paddle.mm 	 paddle.mm(Tensor([613, 4, 144, 144],"float32"), Tensor([613, 4, 144, 32],"float32"), ) 	 62143488 	 1000 	 1.3675429821014404 	 1.3676114082336426 	 1.3547050952911377 	 1.3436970710754395 	 2.137456178665161 	 2.13765811920166 	 1.0921752452850342 	 1.092149019241333 	 
2025-07-30 19:24:52.584258 test begin: paddle.mod(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.44829893112182617 	 0.44820189476013184 	 0.4383394718170166 	 0.4351835250854492 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:24:55.675023 test begin: paddle.mod(Tensor([10, 5080321],"int32"), Tensor([10, 5080321],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([10, 5080321],"int32"), Tensor([10, 5080321],"int32"), ) 	 101606420 	 1000 	 0.4517092704772949 	 0.4581794738769531 	 0.4408912658691406 	 0.43153905868530273 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:02.634139 test begin: paddle.mod(Tensor([1270081, 2, 4, 5],"int32"), Tensor([1270081, 2, 4, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([1270081, 2, 4, 5],"int32"), Tensor([1270081, 2, 4, 5],"int32"), ) 	 101606480 	 1000 	 0.45096874237060547 	 0.44957399368286133 	 0.4411771297454834 	 0.4375917911529541 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:06.534748 test begin: paddle.mod(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4488794803619385 	 0.44933247566223145 	 0.4375271797180176 	 0.4353935718536377 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:09.479715 test begin: paddle.mod(Tensor([2540161, 20],"int32"), Tensor([2540161, 20],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([2540161, 20],"int32"), Tensor([2540161, 20],"int32"), ) 	 101606440 	 1000 	 0.4511294364929199 	 0.4577648639678955 	 0.44133710861206055 	 0.4368479251861572 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:13.445036 test begin: paddle.mod(Tensor([6, 2, 4, 1058401],"int32"), Tensor([6, 2, 4, 1058401],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 2, 4, 1058401],"int32"), Tensor([6, 2, 4, 1058401],"int32"), ) 	 101606496 	 1000 	 0.4530603885650635 	 0.4495706558227539 	 0.4412853717803955 	 0.4378852844238281 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:17.300794 test begin: paddle.mod(Tensor([6, 2, 846721, 5],"int32"), Tensor([6, 2, 846721, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 2, 846721, 5],"int32"), Tensor([6, 2, 846721, 5],"int32"), ) 	 101606520 	 1000 	 0.45104265213012695 	 0.4497230052947998 	 0.4338400363922119 	 0.4318861961364746 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:21.327405 test begin: paddle.mod(Tensor([6, 423361, 4, 5],"int32"), Tensor([6, 423361, 4, 5],"int32"), )
[Prof] paddle.mod 	 paddle.mod(Tensor([6, 423361, 4, 5],"int32"), Tensor([6, 423361, 4, 5],"int32"), ) 	 101606640 	 1000 	 0.4509434700012207 	 0.4496035575866699 	 0.4410669803619385 	 0.4378197193145752 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:25.285225 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), -1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), -1, ) 	 240 	 1000 	 8.687251567840576 	 0.01906418800354004 	 9.226799011230469e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:34.096099 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), -1, keepdim=True, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), -1, keepdim=True, ) 	 240 	 1000 	 8.691524505615234 	 0.02060222625732422 	 8.511543273925781e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:42.881831 test begin: paddle.mode(Tensor([2, 10, 12],"float64"), 1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 10, 12],"float64"), 1, ) 	 240 	 1000 	 10.514913082122803 	 0.03867030143737793 	 9.1552734375e-05 	 5.8650970458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:25:53.535697 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), -1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), -1, ) 	 240 	 1000 	 10.340538024902344 	 0.019203901290893555 	 9.608268737792969e-05 	 5.125999450683594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:26:04.582713 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), -1, keepdim=True, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), -1, keepdim=True, ) 	 240 	 1000 	 10.443169832229614 	 0.016805648803710938 	 9.083747863769531e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:26:15.112655 test begin: paddle.mode(Tensor([2, 12, 10],"float64"), 1, )
[Prof] paddle.mode 	 paddle.mode(Tensor([2, 12, 10],"float64"), 1, ) 	 240 	 1000 	 8.663796186447144 	 0.03144502639770508 	 8.559226989746094e-05 	 6.270408630371094e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:26:23.887868 test begin: paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 120961, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018100 	 1000 	 0.008681774139404297 	 0.006037473678588867 	 1.1444091796875e-05 	 2.09808349609375e-05 	 0.03971266746520996 	 0.0577392578125 	 2.0265579223632812e-05 	 5.555152893066406e-05 	 
2025-07-30 19:26:34.510847 test begin: paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 151201, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017680 	 1000 	 0.008156299591064453 	 0.0061075687408447266 	 1.2636184692382812e-05 	 2.193450927734375e-05 	 0.041648149490356445 	 0.055895090103149414 	 2.574920654296875e-05 	 5.793571472167969e-05 	 
2025-07-30 19:26:45.426170 test begin: paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 3, 4, 5, 211681],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254017200 	 1000 	 0.007874250411987305 	 0.006117343902587891 	 1.2874603271484375e-05 	 2.09808349609375e-05 	 0.04009413719177246 	 0.05496478080749512 	 2.3365020751953125e-05 	 3.838539123535156e-05 	 
2025-07-30 19:26:56.049142 test begin: paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([20, 90721, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254018800 	 1000 	 0.007913589477539062 	 0.006119251251220703 	 1.6689300537109375e-05 	 2.288818359375e-05 	 0.03997039794921875 	 0.05508732795715332 	 1.9073486328125e-05 	 3.3855438232421875e-05 	 
2025-07-30 19:27:06.803774 test begin: paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], )
[Prof] paddle.moveaxis 	 paddle.moveaxis(Tensor([604810, 3, 4, 5, 7],"float64"), list[0,4,3,2,], list[1,3,2,0,], ) 	 254020200 	 1000 	 0.007965087890625 	 0.005946159362792969 	 1.0967254638671875e-05 	 2.2411346435546875e-05 	 0.041037559509277344 	 0.0555567741394043 	 2.6464462280273438e-05 	 6.198883056640625e-05 	 
2025-07-30 19:27:18.603117 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.007071256637573242 	 0.004670381546020508 	 1.4066696166992188e-05 	 2.002716064453125e-05 	 0.04032182693481445 	 0.05635404586791992 	 4.315376281738281e-05 	 5.340576171875e-05 	 
2025-07-30 19:27:29.202496 test begin: paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.007351398468017578 	 0.006003141403198242 	 1.3828277587890625e-05 	 2.09808349609375e-05 	 0.03978562355041504 	 0.058135032653808594 	 1.9311904907226562e-05 	 5.793571472167969e-05 	 
2025-07-30 19:27:40.220043 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.006948709487915039 	 0.006349325180053711 	 1.0728836059570312e-05 	 7.152557373046875e-05 	 0.04006505012512207 	 0.05966520309448242 	 3.600120544433594e-05 	 7.009506225585938e-05 	 
2025-07-30 19:27:51.090753 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007396697998046875 	 0.008180618286132812 	 1.430511474609375e-05 	 6.079673767089844e-05 	 0.04021143913269043 	 0.05730295181274414 	 2.0742416381835938e-05 	 4.458427429199219e-05 	 
2025-07-30 19:28:01.937810 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.0068399906158447266 	 0.004694938659667969 	 1.239776611328125e-05 	 1.9073486328125e-05 	 0.041243791580200195 	 0.055405616760253906 	 2.9325485229492188e-05 	 4.363059997558594e-05 	 
2025-07-30 19:28:12.748505 test begin: paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.007296323776245117 	 0.005954265594482422 	 7.3909759521484375e-06 	 2.0503997802734375e-05 	 0.0449376106262207 	 0.05572700500488281 	 2.9802322387695312e-05 	 4.649162292480469e-05 	 
2025-07-30 19:28:23.484433 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.006958723068237305 	 0.007117033004760742 	 1.2636184692382812e-05 	 6.937980651855469e-05 	 0.04502105712890625 	 0.056055545806884766 	 3.075599670410156e-05 	 4.7206878662109375e-05 	 
2025-07-30 19:28:34.343793 test begin: paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.007535457611083984 	 0.005917549133300781 	 8.58306884765625e-06 	 2.0503997802734375e-05 	 0.04017472267150879 	 0.05502438545227051 	 2.7179718017578125e-05 	 3.361701965332031e-05 	 
2025-07-30 19:28:44.995600 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.008760690689086914 	 0.004727363586425781 	 3.361701965332031e-05 	 2.0265579223632812e-05 	 0.041425228118896484 	 0.05968022346496582 	 3.1948089599609375e-05 	 5.340576171875e-05 	 
2025-07-30 19:28:56.036662 test begin: paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.moveaxis 	 paddle.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007398128509521484 	 0.006057262420654297 	 9.5367431640625e-06 	 2.193450927734375e-05 	 0.04025626182556152 	 0.05875253677368164 	 2.4080276489257812e-05 	 7.534027099609375e-05 	 
2025-07-30 19:29:06.849695 test begin: paddle.multigammaln(Tensor([10, 2540161],"float64"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([10, 2540161],"float64"), 2, ) 	 25401610 	 1000 	 2.957388401031494 	 2.8043906688690186 	 0.5035700798034668 	 0.5729150772094727 	 4.038045167922974 	 3.674957275390625 	 1.032930612564087 	 0.7506117820739746 	 
2025-07-30 19:29:21.949346 test begin: paddle.multigammaln(Tensor([10, 5080321],"float32"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([10, 5080321],"float32"), 2, ) 	 50803210 	 1000 	 2.405282497406006 	 2.5861172676086426 	 0.4098994731903076 	 0.5288257598876953 	 3.4619522094726562 	 3.9882044792175293 	 0.8854749202728271 	 0.8148720264434814 	 
2025-07-30 19:29:37.896213 test begin: paddle.multigammaln(Tensor([1270081, 20],"float64"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([1270081, 20],"float64"), 2, ) 	 25401620 	 1000 	 2.9547488689422607 	 2.803079605102539 	 0.5029993057250977 	 0.5725524425506592 	 4.035330772399902 	 3.6717941761016846 	 1.0321331024169922 	 0.749993085861206 	 
2025-07-30 19:29:52.528748 test begin: paddle.multigammaln(Tensor([2540161, 20],"float32"), 2, )
[Prof] paddle.multigammaln 	 paddle.multigammaln(Tensor([2540161, 20],"float32"), 2, ) 	 50803220 	 1000 	 2.404083013534546 	 2.5840346813201904 	 0.40965938568115234 	 0.5284292697906494 	 3.4596729278564453 	 3.9872806072235107 	 0.884737491607666 	 0.8148272037506104 	 
2025-07-30 19:30:06.737727 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([127, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([127, 1],"int32"), ) 	 101606535 	 1000 	 0.6896617412567139 	 4.130063533782959 	 4.38690185546875e-05 	 0.00010633468627929688 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:14.051734 test begin: paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([12700801, 4],"float32"),Tensor([12700801, 4],"float32"),], index=Tensor([601, 1],"int32"), ) 	 101607009 	 1000 	 2.1195144653320312 	 16.661921977996826 	 8.153915405273438e-05 	 0.0002453327178955078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:37.473770 test begin: paddle.multiplex(inputs=list[Tensor([7, 7257601],"float32"),Tensor([7, 7257601],"float32"),], index=Tensor([6, 1],"int32"), )
[Prof] paddle.multiplex 	 paddle.multiplex(inputs=list[Tensor([7, 7257601],"float32"),Tensor([7, 7257601],"float32"),], index=Tensor([6, 1],"int32"), ) 	 101606420 	 1000 	 0.3332850933074951 	 0.46372389793395996 	 0.00028586387634277344 	 0.0002894401550292969 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:41.263570 test begin: paddle.multiply(Tensor([298, 872, 14, 14],"float32"), Tensor([298, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([298, 872, 14, 14],"float32"), Tensor([298, 872, 1, 1],"float32"), ) 	 51191632 	 1000 	 0.29677271842956543 	 0.30892181396484375 	 0.2861926555633545 	 0.29456305503845215 	 0.8793854713439941 	 0.9115109443664551 	 0.4492831230163574 	 0.31033897399902344 	 
2025-07-30 19:30:45.408991 test begin: paddle.multiply(Tensor([512, 507, 14, 14],"float32"), Tensor([512, 507, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 507, 14, 14],"float32"), Tensor([512, 507, 1, 1],"float32"), ) 	 51138048 	 1000 	 0.2965700626373291 	 0.3068089485168457 	 0.28606486320495605 	 0.29425692558288574 	 0.8775851726531982 	 0.9105761051177979 	 0.4481472969055176 	 0.3099710941314697 	 
2025-07-30 19:30:49.498147 test begin: paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 1],"float32"), ) 	 56700928 	 1000 	 0.3277723789215088 	 0.3396022319793701 	 0.3172433376312256 	 0.3268551826477051 	 0.8970925807952881 	 1.0294909477233887 	 0.45831727981567383 	 0.35052037239074707 	 
2025-07-30 19:30:53.891758 test begin: paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 9],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 14, 9],"float32"), Tensor([512, 872, 1, 9],"float32"), ) 	 60272640 	 1000 	 0.33813047409057617 	 0.3580315113067627 	 0.32743096351623535 	 0.3422844409942627 	 0.872241735458374 	 1.0397264957427979 	 0.4456501007080078 	 0.3540496826171875 	 
2025-07-30 19:30:58.378167 test begin: paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 1, 1],"float32"), ) 	 56700928 	 1000 	 0.3277871608734131 	 0.33960747718811035 	 0.31725049018859863 	 0.3267979621887207 	 0.8972010612487793 	 1.0294244289398193 	 0.45830821990966797 	 0.35052943229675293 	 
2025-07-30 19:31:02.812220 test begin: paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 9, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(Tensor([512, 872, 9, 14],"float32"), Tensor([512, 872, 9, 1],"float32"), ) 	 60272640 	 1000 	 0.3381617069244385 	 0.3704841136932373 	 0.32768845558166504 	 0.33834218978881836 	 0.9329066276550293 	 1.1870715618133545 	 0.47658562660217285 	 0.40418457984924316 	 
2025-07-30 19:31:10.911908 test begin: paddle.multiply(x=Tensor([128, 127, 56, 56],"float32"), y=Tensor([128, 127, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 127, 56, 56],"float32"), y=Tensor([128, 127, 1, 1],"float32"), ) 	 50995072 	 1000 	 0.29601144790649414 	 0.3090250492095947 	 0.28455042839050293 	 0.2964177131652832 	 0.7409360408782959 	 0.9047198295593262 	 0.378568172454834 	 0.3080730438232422 	 
2025-07-30 19:31:14.821969 test begin: paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 1, 1],"float32"), ) 	 51408896 	 1000 	 0.2986466884613037 	 0.3128664493560791 	 0.28769540786743164 	 0.3003718852996826 	 0.7461631298065186 	 0.9126622676849365 	 0.38121581077575684 	 0.3107433319091797 	 
2025-07-30 19:31:18.806939 test begin: paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 32, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 32, 56],"float32"), y=Tensor([128, 224, 32, 1],"float32"), ) 	 52297728 	 1000 	 0.30162692070007324 	 0.312274694442749 	 0.2905759811401367 	 0.2998628616333008 	 0.8606231212615967 	 1.0896251201629639 	 0.43966197967529297 	 0.3711543083190918 	 
2025-07-30 19:31:23.070504 test begin: paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 1],"float32"), ) 	 51408896 	 1000 	 0.29865193367004395 	 0.3147745132446289 	 0.28766322135925293 	 0.3003690242767334 	 0.7461037635803223 	 0.9126484394073486 	 0.38121843338012695 	 0.31067585945129395 	 
2025-07-30 19:31:26.995190 test begin: paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 32],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 224, 56, 32],"float32"), y=Tensor([128, 224, 1, 32],"float32"), ) 	 52297728 	 1000 	 0.3014342784881592 	 0.31558728218078613 	 0.2905106544494629 	 0.30339479446411133 	 0.7847068309783936 	 0.9182839393615723 	 0.40090465545654297 	 0.31268787384033203 	 
2025-07-30 19:31:32.270918 test begin: paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 1, 1],"float32"), ) 	 51412992 	 1000 	 0.2986116409301758 	 0.3331613540649414 	 0.28763365745544434 	 0.29291439056396484 	 0.7489142417907715 	 0.9133374691009521 	 0.38267016410827637 	 0.3109753131866455 	 
2025-07-30 19:31:37.720285 test begin: paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 28, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 28, 56],"float32"), y=Tensor([128, 256, 28, 1],"float32"), ) 	 52297728 	 1000 	 0.30164361000061035 	 0.32180190086364746 	 0.2831854820251465 	 0.2935161590576172 	 0.8614161014556885 	 1.0901641845703125 	 0.44002723693847656 	 0.3712348937988281 	 
2025-07-30 19:31:42.008857 test begin: paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 1],"float32"), ) 	 51412992 	 1000 	 0.2986595630645752 	 0.31206846237182617 	 0.28009748458862305 	 0.2933380603790283 	 0.7489559650421143 	 0.9133059978485107 	 0.3826625347137451 	 0.3109602928161621 	 
2025-07-30 19:31:45.943329 test begin: paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 28],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([128, 256, 56, 28],"float32"), y=Tensor([128, 256, 1, 28],"float32"), ) 	 52297728 	 1000 	 0.3014841079711914 	 0.31629133224487305 	 0.282698392868042 	 0.2974574565887451 	 1.0075287818908691 	 0.9229090213775635 	 0.5147655010223389 	 0.31418776512145996 	 
2025-07-30 19:31:50.147688 test begin: paddle.multiply(x=Tensor([64, 256, 56, 56],"float32"), y=Tensor([64, 256, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([64, 256, 56, 56],"float32"), y=Tensor([64, 256, 1, 1],"float32"), ) 	 51396608 	 1000 	 0.29868626594543457 	 0.31146669387817383 	 0.2801036834716797 	 0.29256391525268555 	 0.7472999095916748 	 0.9115347862243652 	 0.3818051815032959 	 0.3103642463684082 	 
2025-07-30 19:31:54.114505 test begin: paddle.multiply(x=Tensor([73, 224, 56, 56],"float32"), y=Tensor([73, 224, 1, 1],"float32"), )
[Prof] paddle.multiply 	 paddle.multiply(x=Tensor([73, 224, 56, 56],"float32"), y=Tensor([73, 224, 1, 1],"float32"), ) 	 51296224 	 1000 	 0.2982513904571533 	 0.3108854293823242 	 0.2796361446380615 	 0.2922954559326172 	 0.7463226318359375 	 0.9098114967346191 	 0.38127827644348145 	 0.30977725982666016 	 
2025-07-30 19:31:58.063078 test begin: paddle.mv(Tensor([1411201, 36],"float32"), Tensor([36],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([1411201, 36],"float32"), Tensor([36],"float32"), ) 	 50803272 	 1000 	 0.19773316383361816 	 0.1941826343536377 	 0.1860523223876953 	 0.1782054901123047 	 0.4918942451477051 	 0.4165811538696289 	 0.16730546951293945 	 0.1419060230255127 	 
2025-07-30 19:32:00.319964 test begin: paddle.mv(Tensor([254017, 100],"float64"), Tensor([100],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([254017, 100],"float64"), Tensor([100],"float64"), ) 	 25401800 	 1000 	 0.15969467163085938 	 0.15609264373779297 	 0.14055252075195312 	 0.12917637825012207 	 0.3360278606414795 	 0.3300817012786865 	 0.11435604095458984 	 0.11233925819396973 	 
2025-07-30 19:32:01.868573 test begin: paddle.mv(Tensor([3, 16934401],"float32"), Tensor([16934401],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([3, 16934401],"float32"), Tensor([16934401],"float32"), ) 	 67737604 	 1000 	 0.23671507835388184 	 0.23479866981506348 	 0.12092041969299316 	 0.11993908882141113 	 0.6300089359283447 	 0.6084411144256592 	 0.3216288089752197 	 0.3106575012207031 	 
2025-07-30 19:32:04.705397 test begin: paddle.mv(Tensor([3, 50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([3, 50803201],"float32"), Tensor([50803201],"float32"), ) 	 203212804 	 1000 	 0.6764059066772461 	 0.6768875122070312 	 0.3456122875213623 	 0.3459453582763672 	 1.8674416542053223 	 1.8021254539489746 	 0.95404052734375 	 0.9209034442901611 	 
2025-07-30 19:32:13.209683 test begin: paddle.mv(Tensor([5, 25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([5, 25401601],"float64"), Tensor([25401601],"float64"), ) 	 152409606 	 1000 	 0.9622311592102051 	 0.932875394821167 	 0.4917020797729492 	 0.4767324924468994 	 2.4079818725585938 	 2.408651113510132 	 1.230461597442627 	 1.2307608127593994 	 
2025-07-30 19:32:23.311167 test begin: paddle.mv(Tensor([5, 5080321],"float64"), Tensor([5080321],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([5, 5080321],"float64"), Tensor([5080321],"float64"), ) 	 30481926 	 1000 	 0.23322319984436035 	 0.22516894340515137 	 0.1192317008972168 	 0.11510348320007324 	 0.49181556701660156 	 0.49243950843811035 	 0.25124454498291016 	 0.2515571117401123 	 
2025-07-30 19:32:25.419011 test begin: paddle.mv(Tensor([64, 396901],"float64"), Tensor([396901],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([64, 396901],"float64"), Tensor([396901],"float64"), ) 	 25798565 	 1000 	 0.15496444702148438 	 0.1553490161895752 	 0.0791618824005127 	 0.07936835289001465 	 0.32555556297302246 	 0.3297441005706787 	 0.1663055419921875 	 0.16845989227294922 	 
2025-07-30 19:32:26.951823 test begin: paddle.mv(Tensor([793801, 32],"float64"), Tensor([32],"float64"), )
[Prof] paddle.mv 	 paddle.mv(Tensor([793801, 32],"float64"), Tensor([32],"float64"), ) 	 25401664 	 1000 	 0.1730184555053711 	 0.1624433994293213 	 0.1598672866821289 	 0.1438145637512207 	 0.3337230682373047 	 0.335512638092041 	 0.11360669136047363 	 0.1142275333404541 	 
2025-07-30 19:32:28.503271 test begin: paddle.nan_to_num(Tensor([148, 114422, 3],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([148, 114422, 3],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803368 	 1000 	 3.007141590118408 	 0.2980189323425293 	 0.27947998046875 	 0.28439855575561523 	 1.2712070941925049 	 1.159379243850708 	 0.4329521656036377 	 0.23696541786193848 	 
2025-07-30 19:32:37.348692 test begin: paddle.nan_to_num(Tensor([148, 5, 68653],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([148, 5, 68653],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803220 	 1000 	 3.725148916244507 	 0.31931066513061523 	 0.2794356346130371 	 0.2775101661682129 	 1.2712714672088623 	 1.1590166091918945 	 0.43308520317077637 	 0.23687505722045898 	 
2025-07-30 19:32:46.879303 test begin: paddle.nan_to_num(Tensor([1948, 26080],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([1948, 26080],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803840 	 1000 	 3.0065836906433105 	 0.29785585403442383 	 0.2794625759124756 	 0.2843210697174072 	 1.2646055221557617 	 1.15826416015625 	 0.4307851791381836 	 0.2367541790008545 	 
2025-07-30 19:32:54.337744 test begin: paddle.nan_to_num(Tensor([25401601, 1],"float64"), neginf=-2.220446049250313e-16, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([25401601, 1],"float64"), neginf=-2.220446049250313e-16, ) 	 25401601 	 1000 	 2.8821499347686768 	 0.2989382743835449 	 0.26786375045776367 	 0.27873802185058594 	 0.9844379425048828 	 1.0293259620666504 	 0.3353235721588135 	 0.21030592918395996 	 
2025-07-30 19:33:00.664745 test begin: paddle.nan_to_num(Tensor([25401601, 2],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([25401601, 2],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803202 	 1000 	 3.0064852237701416 	 0.2978794574737549 	 0.27945899963378906 	 0.28048133850097656 	 1.2712597846984863 	 1.158891201019287 	 0.43306422233581543 	 0.23691058158874512 	 
2025-07-30 19:33:08.124720 test begin: paddle.nan_to_num(Tensor([3386881, 5, 3],"float32"), neginf=-1.1920928955078125e-07, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([3386881, 5, 3],"float32"), neginf=-1.1920928955078125e-07, ) 	 50803215 	 1000 	 3.00639009475708 	 0.30029726028442383 	 0.27942895889282227 	 0.2775688171386719 	 1.2712745666503906 	 1.1590263843536377 	 0.4330556392669678 	 0.2369074821472168 	 
2025-07-30 19:33:15.607328 test begin: paddle.nan_to_num(Tensor([400, 63505],"float64"), neginf=-2.220446049250313e-16, )
[Prof] paddle.nan_to_num 	 paddle.nan_to_num(Tensor([400, 63505],"float64"), neginf=-2.220446049250313e-16, ) 	 25402000 	 1000 	 2.8816044330596924 	 0.2990448474884033 	 0.26787590980529785 	 0.2855362892150879 	 0.9853410720825195 	 1.0300347805023193 	 0.33565211296081543 	 0.21050477027893066 	 
2025-07-30 19:33:21.998287 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), -1, False, ) 	 50803240 	 1000 	 2.4866700172424316 	 1.690377950668335 	 0.2538154125213623 	 0.28790950775146484 	 0.7141783237457275 	 0.7392685413360596 	 0.24343395233154297 	 0.18889379501342773 	 
2025-07-30 19:33:28.726873 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), 2, True, ) 	 50803240 	 1000 	 2.825707197189331 	 1.3767023086547852 	 0.2884793281555176 	 0.23446178436279297 	 0.7454855442047119 	 0.7864093780517578 	 0.2540006637573242 	 0.2009427547454834 	 
2025-07-30 19:33:37.564935 test begin: paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 1270081, 4, 5],"float32"), None, False, ) 	 50803240 	 1000 	 1.9844729900360107 	 1.100862979888916 	 0.16862034797668457 	 0.14067745208740234 	 0.5612173080444336 	 0.5939257144927979 	 0.19132590293884277 	 0.1518089771270752 	 
2025-07-30 19:33:42.676539 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), -1, False, ) 	 50803230 	 1000 	 2.4860079288482666 	 1.700199842453003 	 0.2537212371826172 	 0.2879776954650879 	 0.7140223979949951 	 0.7393784523010254 	 0.24331188201904297 	 0.18892192840576172 	 
2025-07-30 19:33:53.199384 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), 2, True, ) 	 50803230 	 1000 	 14.134862661361694 	 1.1297082901000977 	 1.2018160820007324 	 0.14435935020446777 	 0.5658237934112549 	 0.6304018497467041 	 0.1927638053894043 	 0.16110658645629883 	 
2025-07-30 19:34:10.563869 test begin: paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 1693441, 5],"float32"), None, False, ) 	 50803230 	 1000 	 1.9840168952941895 	 1.1009564399719238 	 0.16861891746520996 	 0.14067554473876953 	 0.561244010925293 	 0.593970537185669 	 0.1913142204284668 	 0.15181374549865723 	 
2025-07-30 19:34:15.716216 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), -1, False, ) 	 50803224 	 1000 	 2.0460076332092285 	 1.1009714603424072 	 0.17395615577697754 	 0.14072799682617188 	 0.5622854232788086 	 0.6114342212677002 	 0.19169068336486816 	 0.15630435943603516 	 
2025-07-30 19:34:20.900216 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), 2, True, ) 	 50803224 	 1000 	 2.331972122192383 	 1.3750019073486328 	 0.2381126880645752 	 0.23407530784606934 	 0.7610313892364502 	 0.7907962799072266 	 0.25933313369750977 	 0.2020430564880371 	 
2025-07-30 19:34:27.212692 test begin: paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([2, 3, 4, 2116801],"float32"), None, False, ) 	 50803224 	 1000 	 1.984053134918213 	 1.1009056568145752 	 0.1687171459197998 	 0.14068007469177246 	 0.561220645904541 	 0.5940310955047607 	 0.19131994247436523 	 0.15183711051940918 	 
2025-07-30 19:34:32.292588 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), -1, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), -1, False, ) 	 50803260 	 1000 	 2.4863781929016113 	 1.6916277408599854 	 0.25379323959350586 	 0.2879607677459717 	 0.713970422744751 	 0.7392623424530029 	 0.24332451820373535 	 0.18888258934020996 	 
2025-07-30 19:34:40.475966 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), 2, True, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), 2, True, ) 	 50803260 	 1000 	 2.82564640045166 	 1.3790793418884277 	 0.2884409427642822 	 0.23443055152893066 	 0.7454462051391602 	 0.7864444255828857 	 0.2540593147277832 	 0.20085811614990234 	 
2025-07-30 19:34:47.304901 test begin: paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), None, False, )
[Prof] paddle.nanmean 	 paddle.nanmean(Tensor([846721, 3, 4, 5],"float32"), None, False, ) 	 50803260 	 1000 	 1.9837636947631836 	 1.1007773876190186 	 0.16864681243896484 	 0.14058899879455566 	 0.5612003803253174 	 0.5939185619354248 	 0.191314697265625 	 0.15181183815002441 	 
2025-07-30 19:34:52.431519 test begin: paddle.nanmedian(Tensor([2, 254016],"float32"), axis=1, mode="min", )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([2, 254016],"float32"), axis=1, mode="min", ) 	 508032 	 1000 	 3.5261166095733643 	 1.2500050067901611 	 0.003412485122680664 	 1.230983018875122 	 None 	 None 	 None 	 None 	 combined
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:34:57.748865 test begin: paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, ) 	 508032 	 1000 	 6.865333557128906 	 0.27620840072631836 	 0.0067615509033203125 	 7.510185241699219e-05 	 0.05690908432006836 	 0.541193962097168 	 3.933906555175781e-05 	 0.00033664703369140625 	 combined
2025-07-30 19:35:06.062673 test begin: paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, mode="min", )
[Prof] paddle.nanmedian 	 paddle.nanmedian(Tensor([508032],"float32"), keepdim=False, mode="min", ) 	 508032 	 1000 	 6.8630359172821045 	 0.34560608863830566 	 0.00673985481262207 	 9.1552734375e-05 	 0.06752276420593262 	 0.14817523956298828 	 2.3603439331054688e-05 	 6.532669067382812e-05 	 combined
2025-07-30 19:35:13.555088 test begin: paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0, axis=1, )
W0730 19:35:13.567981 28937 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 0.5027275085449219 	 0.3334357738494873 	 0.013563156127929688 	 0.005385160446166992 	 0.212752103805542 	 0.24503111839294434 	 3.218650817871094e-05 	 6.771087646484375e-05 	 
2025-07-30 19:35:14.986708 test begin: paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 10584, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 18.98882555961609 	 0.21891188621520996 	 0.5884683132171631 	 8.225440979003906e-05 	 0.17095732688903809 	 0.20791029930114746 	 3.933906555175781e-05 	 6.866455078125e-05 	 
2025-07-30 19:35:34.635579 test begin: paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0, axis=1, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 16.328076124191284 	 0.22741174697875977 	 0.4571833610534668 	 7.510185241699219e-05 	 0.2026071548461914 	 0.2270221710205078 	 3.0517578125e-05 	 3.457069396972656e-05 	 
2025-07-30 19:35:51.674161 test begin: paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([4, 7, 9072],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 0.40372633934020996 	 0.3067147731781006 	 0.00014662742614746094 	 8.487701416015625e-05 	 0.16748046875 	 0.21543097496032715 	 2.193450927734375e-05 	 4.6253204345703125e-05 	 
2025-07-30 19:35:52.783960 test begin: paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0, axis=1, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0, axis=1, ) 	 254016 	 1000 	 16.33514380455017 	 0.22283267974853516 	 0.4573934078216553 	 7.963180541992188e-05 	 0.19847464561462402 	 0.2324199676513672 	 3.0994415283203125e-05 	 6.890296936035156e-05 	 
2025-07-30 19:36:09.832818 test begin: paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[Prof] paddle.nanquantile 	 paddle.nanquantile(Tensor([6048, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 	 254016 	 1000 	 18.984619140625 	 0.21459317207336426 	 0.5881078243255615 	 8.0108642578125e-05 	 0.17175817489624023 	 0.2468888759613037 	 4.1961669921875e-05 	 6.794929504394531e-05 	 
2025-07-30 19:36:29.482877 test begin: paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803240 	 1000 	 1.0094709396362305 	 0.1528339385986328 	 0.20606613159179688 	 0.07805585861206055 	 0.5597634315490723 	 0.5898125171661377 	 0.2859053611755371 	 0.20079660415649414 	 
2025-07-30 19:36:32.630981 test begin: paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 1270081, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803240 	 1000 	 1.0096087455749512 	 0.15278029441833496 	 0.2060708999633789 	 0.07805085182189941 	 0.5597753524780273 	 0.5897994041442871 	 0.2859537601470947 	 0.20074963569641113 	 
2025-07-30 19:36:37.752812 test begin: paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803230 	 1000 	 1.0101754665374756 	 0.152876615524292 	 0.20606541633605957 	 0.0781092643737793 	 0.5597436428070068 	 0.5896594524383545 	 0.2859001159667969 	 0.20079898834228516 	 
2025-07-30 19:36:41.495180 test begin: paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 1693441, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803230 	 1000 	 1.0094633102416992 	 0.1528489589691162 	 0.20607924461364746 	 0.07805275917053223 	 0.5597443580627441 	 0.589832067489624 	 0.2859525680541992 	 0.2007739543914795 	 
2025-07-30 19:36:44.698634 test begin: paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=False, name=None, ) 	 50803224 	 1000 	 1.0095772743225098 	 0.15279579162597656 	 0.2060999870300293 	 0.07807040214538574 	 0.5598232746124268 	 0.5897922515869141 	 0.28592586517333984 	 0.20077776908874512 	 
2025-07-30 19:36:47.778750 test begin: paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([2, 3, 4, 2116801],"float32"), axis=None, keepdim=True, name=None, ) 	 50803224 	 1000 	 1.009558916091919 	 0.1528334617614746 	 0.20609307289123535 	 0.07807469367980957 	 0.559849739074707 	 0.5897817611694336 	 0.28597164154052734 	 0.20081329345703125 	 
2025-07-30 19:36:50.889323 test begin: paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 	 50803260 	 1000 	 1.009531021118164 	 0.15279388427734375 	 0.2060716152191162 	 0.07806277275085449 	 0.5598692893981934 	 0.5896539688110352 	 0.2859475612640381 	 0.20073437690734863 	 
2025-07-30 19:36:54.026474 test begin: paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[Prof] paddle.nansum 	 paddle.nansum(Tensor([846721, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 	 50803260 	 1000 	 1.0094728469848633 	 0.15286612510681152 	 0.20607304573059082 	 0.07813382148742676 	 0.5598537921905518 	 0.5897061824798584 	 0.2859385013580322 	 0.2007608413696289 	 
2025-07-30 19:36:57.129310 test begin: paddle.nansum(x=Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0636420249938965 	 0.18945670127868652 	 0.27195167541503906 	 0.17363452911376953 	 0.5273716449737549 	 0.44130873680114746 	 0.26941967010498047 	 0.1502392292022705 	 
2025-07-30 19:37:00.012455 test begin: paddle.nansum(x=Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0649371147155762 	 0.1893765926361084 	 0.2722787857055664 	 0.16661310195922852 	 0.5274181365966797 	 0.44141268730163574 	 0.269395112991333 	 0.15031170845031738 	 
2025-07-30 19:37:02.957737 test begin: paddle.nansum(x=Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401780 	 1000 	 5.732242822647095 	 0.17400765419006348 	 1.2552449703216553 	 0.0888972282409668 	 0.4653048515319824 	 0.41740918159484863 	 0.23772192001342773 	 0.1420886516571045 	 
2025-07-30 19:37:10.609842 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401744 	 1000 	 0.9734394550323486 	 0.19003891944885254 	 0.24886655807495117 	 0.17435979843139648 	 0.5110592842102051 	 0.44348669052124023 	 0.2610819339752197 	 0.15100717544555664 	 
2025-07-30 19:37:13.414820 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 0.9746613502502441 	 0.1903083324432373 	 0.2491462230682373 	 0.16765046119689941 	 0.5113155841827393 	 0.4439067840576172 	 0.2612009048461914 	 0.15113496780395508 	 
2025-07-30 19:37:16.189985 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, ) 	 25402320 	 1000 	 0.9736332893371582 	 0.19013190269470215 	 0.24889183044433594 	 0.17310309410095215 	 0.5111732482910156 	 0.44516611099243164 	 0.26117825508117676 	 0.15158629417419434 	 
2025-07-30 19:37:18.964526 test begin: paddle.nansum(x=Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.nansum 	 paddle.nansum(x=Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 1.0643839836120605 	 0.189439058303833 	 0.27219223976135254 	 0.16647052764892578 	 0.529808521270752 	 0.4416162967681885 	 0.27068018913269043 	 0.15035486221313477 	 
2025-07-30 19:37:21.902122 test begin: paddle.neg(Tensor([3175201, 8],"float64"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([3175201, 8],"float64"), ) 	 25401608 	 1000 	 0.2979130744934082 	 0.29825615882873535 	 0.27605676651000977 	 0.2811925411224365 	 0.298128604888916 	 0.2980034351348877 	 0.2188563346862793 	 0.19976019859313965 	 
2025-07-30 19:37:24.139518 test begin: paddle.neg(Tensor([32, 1587601],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 0.2955479621887207 	 0.29790353775024414 	 0.2783231735229492 	 0.2787952423095703 	 0.29578328132629395 	 0.29767346382141113 	 0.2350611686706543 	 0.2235727310180664 	 
2025-07-30 19:37:27.014454 test begin: paddle.neg(Tensor([32, 793801],"float64"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([32, 793801],"float64"), ) 	 25401632 	 1000 	 0.2979440689086914 	 0.2982656955718994 	 0.28108859062194824 	 0.28087306022644043 	 0.2981071472167969 	 0.29799985885620117 	 0.2375349998474121 	 0.22349858283996582 	 
2025-07-30 19:37:29.253675 test begin: paddle.neg(Tensor([6350401, 8],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([6350401, 8],"float32"), ) 	 50803208 	 1000 	 0.2955329418182373 	 0.29785585403442383 	 0.2856941223144531 	 0.2866394519805908 	 0.29575586318969727 	 0.2976555824279785 	 0.2443528175354004 	 0.23106861114501953 	 
2025-07-30 19:37:32.116314 test begin: paddle.neg(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.29541873931884766 	 0.3017568588256836 	 0.27817392349243164 	 0.28066134452819824 	 0.2955210208892822 	 0.2976713180541992 	 0.2351386547088623 	 0.22147822380065918 	 
2025-07-30 19:37:35.003175 test begin: paddle.neg(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29570889472961426 	 0.3225741386413574 	 0.28586888313293457 	 0.2865598201751709 	 0.2957160472869873 	 0.2976853847503662 	 0.24436306953430176 	 0.2293555736541748 	 
2025-07-30 19:37:40.870115 test begin: paddle.neg(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.neg 	 paddle.neg(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2957642078399658 	 0.29828929901123047 	 0.2858848571777344 	 0.286914587020874 	 0.29589033126831055 	 0.29773616790771484 	 0.24460291862487793 	 0.22616314888000488 	 
2025-07-30 19:37:43.688990 test begin: paddle.negative(Tensor([1693441, 3, 4, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([1693441, 3, 4, 5],"float16"), ) 	 101606460 	 1000 	 0.2984037399291992 	 0.2961914539337158 	 0.2859182357788086 	 0.2847599983215332 	 0.29857301712036133 	 0.2960190773010254 	 0.24400758743286133 	 0.2285311222076416 	 
2025-07-30 19:37:48.706356 test begin: paddle.negative(Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 1270081, 4, 5],"float32"), ) 	 50803240 	 1000 	 0.29554271697998047 	 0.29834771156311035 	 0.2829766273498535 	 0.28644728660583496 	 0.2957773208618164 	 0.297652006149292 	 0.2443561553955078 	 0.2266983985900879 	 
2025-07-30 19:37:51.538201 test begin: paddle.negative(Tensor([2, 2540161, 4, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 2540161, 4, 5],"float16"), ) 	 101606440 	 1000 	 0.29842424392700195 	 0.296220064163208 	 0.2858889102935791 	 0.28451991081237793 	 0.2986178398132324 	 0.2960801124572754 	 0.24608302116394043 	 0.22628021240234375 	 
2025-07-30 19:37:56.622575 test begin: paddle.negative(Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 1693441, 5],"float32"), ) 	 50803230 	 1000 	 0.2955904006958008 	 0.3007392883300781 	 0.2783493995666504 	 0.2797091007232666 	 0.29573559761047363 	 0.2977159023284912 	 0.2444899082183838 	 0.226334810256958 	 
2025-07-30 19:37:59.532836 test begin: paddle.negative(Tensor([2, 3, 3386881, 5],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 3386881, 5],"float16"), ) 	 101606430 	 1000 	 0.29842066764831543 	 0.29659175872802734 	 0.2857816219329834 	 0.28457117080688477 	 0.29856300354003906 	 0.29605793952941895 	 0.24579787254333496 	 0.2270374298095703 	 
2025-07-30 19:38:04.589791 test begin: paddle.negative(Tensor([2, 3, 4, 1058401],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 1058401],"float64"), ) 	 25401624 	 1000 	 0.2979414463043213 	 0.29818034172058105 	 0.28551769256591797 	 0.28678226470947266 	 0.29810595512390137 	 0.29806947708129883 	 0.24717020988464355 	 0.23042702674865723 	 
2025-07-30 19:38:06.848306 test begin: paddle.negative(Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 2116801],"float32"), ) 	 50803224 	 1000 	 0.2955813407897949 	 0.2978212833404541 	 0.28307342529296875 	 0.28634071350097656 	 0.2958347797393799 	 0.2976562976837158 	 0.24310827255249023 	 0.229292631149292 	 
2025-07-30 19:38:09.686019 test begin: paddle.negative(Tensor([2, 3, 4, 4233601],"float16"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 4, 4233601],"float16"), ) 	 101606424 	 1000 	 0.2984020709991455 	 0.5357601642608643 	 0.28598952293395996 	 0.2846243381500244 	 0.2985565662384033 	 0.2960035800933838 	 0.24727201461791992 	 0.2273411750793457 	 
2025-07-30 19:38:16.398650 test begin: paddle.negative(Tensor([2, 3, 846721, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 3, 846721, 5],"float64"), ) 	 25401630 	 1000 	 0.297985315322876 	 0.29827451705932617 	 0.28557586669921875 	 0.28677845001220703 	 0.29819822311401367 	 0.2979738712310791 	 0.24455833435058594 	 0.22480559349060059 	 
2025-07-30 19:38:18.687347 test begin: paddle.negative(Tensor([2, 635041, 4, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([2, 635041, 4, 5],"float64"), ) 	 25401640 	 1000 	 0.29781436920166016 	 0.29825687408447266 	 0.28530359268188477 	 0.28490710258483887 	 0.29809093475341797 	 0.2980079650878906 	 0.2250077724456787 	 0.22944140434265137 	 
2025-07-30 19:38:20.968018 test begin: paddle.negative(Tensor([423361, 3, 4, 5],"float64"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([423361, 3, 4, 5],"float64"), ) 	 25401660 	 1000 	 0.2978208065032959 	 0.29822754859924316 	 0.28537416458129883 	 0.28667616844177246 	 0.298062801361084 	 0.2979919910430908 	 0.24206256866455078 	 0.22688674926757812 	 
2025-07-30 19:38:23.216512 test begin: paddle.negative(Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.negative 	 paddle.negative(Tensor([846721, 3, 4, 5],"float32"), ) 	 50803260 	 1000 	 0.2955973148345947 	 0.29782938957214355 	 0.28310513496398926 	 0.286301851272583 	 0.2957799434661865 	 0.2976858615875244 	 0.24344682693481445 	 0.22947931289672852 	 
2025-07-30 19:38:26.058188 test begin: paddle.nextafter(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 1270081, 4, 5],"float32"), Tensor([2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 0.4506969451904297 	 0.4491004943847656 	 0.4403238296508789 	 0.43712759017944336 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:28.607557 test begin: paddle.nextafter(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 3, 1693441, 5],"float32"), Tensor([2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 0.45066070556640625 	 0.4488968849182129 	 0.44146108627319336 	 0.4368271827697754 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:31.190895 test begin: paddle.nextafter(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([2, 3, 4, 2116801],"float32"), Tensor([2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 0.45067763328552246 	 0.4489014148712158 	 0.44145894050598145 	 0.4372539520263672 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:33.716797 test begin: paddle.nextafter(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), )
W0730 19:38:34.552269 29969 dygraph_functions.cc:57914] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 0.6831316947937012 	 0.39817023277282715 	 0.34905147552490234 	 0.3753025531768799 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:40.483702 test begin: paddle.nextafter(Tensor([4, 3, 2116801],"float64"), Tensor([4, 3, 2116801],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 2116801],"float64"), Tensor([4, 3, 2116801],"float32"), ) 	 50803224 	 1000 	 0.6821208000183105 	 0.3836367130279541 	 0.34851574897766113 	 0.37169957160949707 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:42.505943 test begin: paddle.nextafter(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), ) 	 101606424 	 1000 	 1.3604888916015625 	 0.7663121223449707 	 0.6951134204864502 	 0.7544963359832764 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:46.577025 test begin: paddle.nextafter(Tensor([4, 3, 4233601],"float64"), Tensor([4, 3, 4233601],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3, 4233601],"float64"), Tensor([4, 3, 4233601],"float32"), ) 	 101606424 	 1000 	 1.3594517707824707 	 0.7587666511535645 	 0.6945798397064209 	 0.7469367980957031 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:50.624143 test begin: paddle.nextafter(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 0.6829776763916016 	 0.3876495361328125 	 0.3490116596221924 	 0.37465572357177734 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:52.659248 test begin: paddle.nextafter(Tensor([4, 3175201, 2],"float64"), Tensor([4, 3175201, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 3175201, 2],"float64"), Tensor([4, 3175201, 2],"float32"), ) 	 50803216 	 1000 	 0.6820371150970459 	 0.3835921287536621 	 0.348466157913208 	 0.3716869354248047 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:54.697483 test begin: paddle.nextafter(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), ) 	 101606416 	 1000 	 1.3608019351959229 	 0.7663290500640869 	 0.6952531337738037 	 0.7533950805664062 	 None 	 None 	 None 	 None 	 
2025-07-30 19:38:58.779524 test begin: paddle.nextafter(Tensor([4, 6350401, 2],"float64"), Tensor([4, 6350401, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4, 6350401, 2],"float64"), Tensor([4, 6350401, 2],"float32"), ) 	 101606416 	 1000 	 1.359691858291626 	 0.758737325668335 	 0.6946773529052734 	 0.7406580448150635 	 None 	 None 	 None 	 None 	 
2025-07-30 19:39:02.838708 test begin: paddle.nextafter(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 0.6830084323883057 	 0.38753223419189453 	 0.3489725589752197 	 0.37574219703674316 	 None 	 None 	 None 	 None 	 
2025-07-30 19:39:04.882644 test begin: paddle.nextafter(Tensor([4233601, 3, 2],"float64"), Tensor([4233601, 3, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([4233601, 3, 2],"float64"), Tensor([4233601, 3, 2],"float32"), ) 	 50803212 	 1000 	 0.6820735931396484 	 0.38367557525634766 	 0.3485126495361328 	 0.3717803955078125 	 None 	 None 	 None 	 None 	 
2025-07-30 19:39:06.930091 test begin: paddle.nextafter(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), ) 	 101606412 	 1000 	 1.360306739807129 	 0.766331672668457 	 0.6951847076416016 	 0.7543749809265137 	 None 	 None 	 None 	 None 	 
2025-07-30 19:39:10.983880 test begin: paddle.nextafter(Tensor([8467201, 3, 2],"float64"), Tensor([8467201, 3, 2],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([8467201, 3, 2],"float64"), Tensor([8467201, 3, 2],"float32"), ) 	 101606412 	 1000 	 1.359520435333252 	 0.7587201595306396 	 0.6946489810943604 	 0.7467668056488037 	 None 	 None 	 None 	 None 	 
2025-07-30 19:39:15.058121 test begin: paddle.nextafter(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), )
[Prof] paddle.nextafter 	 paddle.nextafter(Tensor([846721, 3, 4, 5],"float32"), Tensor([846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 0.45075106620788574 	 0.4556565284729004 	 0.4393298625946045 	 0.4306015968322754 	 None 	 None 	 None 	 None 	 
2025-07-30 19:39:19.478735 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 1536, 267],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 1536, 267],"float32"), 1, None, ) 	 50853888 	 1000 	 0.3018772602081299 	 0.17634820938110352 	 0.2570953369140625 	 0.1559593677520752 	 0.8404343128204346 	 0.1699051856994629 	 0.42934107780456543 	 0.07701301574707031 	 
2025-07-30 19:39:22.114878 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 8362, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([124, 8362, 49],"float32"), 1, None, ) 	 50807512 	 1000 	 0.3549776077270508 	 0.37698793411254883 	 0.3091568946838379 	 0.358015775680542 	 0.8660573959350586 	 0.17425298690795898 	 0.4424915313720703 	 0.0796058177947998 	 
2025-07-30 19:39:24.751451 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 1536, 259],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 1536, 259],"float32"), 1, None, ) 	 50921472 	 1000 	 0.2851710319519043 	 0.15372443199157715 	 0.24032258987426758 	 0.13442754745483398 	 0.8399925231933594 	 0.1703200340270996 	 0.4291839599609375 	 0.07379031181335449 	 
2025-07-30 19:39:27.029657 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 8101, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([128, 8101, 49],"float32"), 1, None, ) 	 50809472 	 1000 	 0.35486674308776855 	 0.3770296573638916 	 0.3097245693206787 	 0.35794734954833984 	 0.8667638301849365 	 0.17427587509155273 	 0.44280290603637695 	 0.08154654502868652 	 
2025-07-30 19:39:29.662631 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([345, 1024, 144],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([345, 1024, 144],"float32"), 1, None, ) 	 50872320 	 1000 	 0.4588186740875244 	 0.21928715705871582 	 0.413585901260376 	 0.2003777027130127 	 0.8480255603790283 	 0.17082977294921875 	 0.4332103729248047 	 0.07556653022766113 	 
2025-07-30 19:39:32.182080 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 1024, 776],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 1024, 776],"float32"), 1, None, ) 	 50855936 	 1000 	 0.1894998550415039 	 0.15395379066467285 	 0.1445314884185791 	 0.1351778507232666 	 0.8245420455932617 	 0.17171025276184082 	 0.4210362434387207 	 0.07614374160766602 	 
2025-07-30 19:39:34.351540 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 5513, 144],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([64, 5513, 144],"float32"), 1, None, ) 	 50807808 	 1000 	 0.4583714008331299 	 0.6227176189422607 	 0.41347193717956543 	 0.19942283630371094 	 0.8487894535064697 	 0.17044568061828613 	 0.43372058868408203 	 0.03550314903259277 	 
2025-07-30 19:39:39.480263 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([676, 1536, 49],"float32"), 1, None, )
[Prof] paddle.nn.functional.adaptive_avg_pool1d 	 paddle.nn.functional.adaptive_avg_pool1d(Tensor([676, 1536, 49],"float32"), 1, None, ) 	 50878464 	 1000 	 0.35570812225341797 	 0.3784067630767822 	 0.30989837646484375 	 0.35965967178344727 	 0.8669817447662354 	 0.17451810836791992 	 0.44300365447998047 	 0.07960677146911621 	 
2025-07-30 19:39:42.167919 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 2, 7],"float32"), output_size=1, ) 	 58404864 	 1000 	 0.3004276752471924 	 0.3642256259918213 	 0.26859426498413086 	 0.34410905838012695 	 1.0281727313995361 	 0.22441339492797852 	 0.5253217220306396 	 0.14827942848205566 	 
2025-07-30 19:39:45.112222 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 2048, 7, 2],"float32"), output_size=1, ) 	 58404864 	 1000 	 0.30036497116088867 	 0.3724629878997803 	 0.2590048313140869 	 0.33614516258239746 	 1.0283396244049072 	 0.22440719604492188 	 0.5254535675048828 	 0.1423656940460205 	 
2025-07-30 19:39:48.034922 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 509, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2037, 509, 7, 7],"float32"), output_size=1, ) 	 50804817 	 1000 	 0.354891300201416 	 0.37699198722839355 	 0.3134732246398926 	 0.346970796585083 	 0.8658766746520996 	 0.17427492141723633 	 0.4424400329589844 	 0.09262824058532715 	 
2025-07-30 19:39:50.648723 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 2, 7],"float32"), output_size=1, ) 	 58634240 	 1000 	 0.3014547824859619 	 0.365980863571167 	 0.26988959312438965 	 0.3460085391998291 	 1.0329270362854004 	 0.22545719146728516 	 0.5277755260467529 	 0.14832305908203125 	 
2025-07-30 19:39:53.606668 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 2048, 7, 2],"float32"), output_size=1, ) 	 58634240 	 1000 	 0.3014373779296875 	 0.3667120933532715 	 0.2696089744567871 	 0.3452725410461426 	 1.032912015914917 	 0.22509074211120605 	 0.5277421474456787 	 0.1500535011291504 	 
2025-07-30 19:39:56.579812 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 507, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2045, 507, 7, 7],"float32"), output_size=1, ) 	 50803935 	 1000 	 0.35494422912597656 	 0.3769383430480957 	 0.31957054138183594 	 0.357097864151001 	 0.8680291175842285 	 0.17424273490905762 	 0.4434480667114258 	 0.09966516494750977 	 
2025-07-30 19:39:59.195376 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 2, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 2, 7],"float32"), output_size=1, ) 	 58720256 	 1000 	 0.3018345832824707 	 0.3661315441131592 	 0.26467394828796387 	 0.3459897041320801 	 1.034522533416748 	 0.22539782524108887 	 0.5286276340484619 	 0.150864839553833 	 
2025-07-30 19:40:02.152178 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 7, 2],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 2048, 7, 2],"float32"), output_size=1, ) 	 58720256 	 1000 	 0.3021094799041748 	 0.3665013313293457 	 0.270366907119751 	 0.3460981845855713 	 1.0348119735717773 	 0.22541403770446777 	 0.5285930633544922 	 0.15008139610290527 	 
2025-07-30 19:40:05.123426 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 507, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([2048, 507, 7, 7],"float32"), output_size=1, ) 	 50878464 	 1000 	 0.3558049201965332 	 0.37753963470458984 	 0.31567811965942383 	 0.35773324966430664 	 0.8671257495880127 	 0.17450499534606934 	 0.4430696964263916 	 0.0989236831665039 	 
2025-07-30 19:40:07.739411 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([507, 2048, 7, 7],"float32"), output_size=1, )
[Prof] paddle.nn.functional.adaptive_avg_pool2d 	 paddle.nn.functional.adaptive_avg_pool2d(Tensor([507, 2048, 7, 7],"float32"), output_size=1, ) 	 50878464 	 1000 	 0.3557274341583252 	 0.3775620460510254 	 0.3242628574371338 	 0.3568754196166992 	 0.8669862747192383 	 0.17449951171875 	 0.44301295280456543 	 0.09877443313598633 	 
2025-07-30 19:40:10.350535 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 45361, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 45361, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804320 	 1000 	 0.8985490798950195 	 0.14878439903259277 	 0.8729424476623535 	 0.12638616561889648 	 2.2324790954589844 	 0.17289447784423828 	 1.140512466430664 	 0.0738227367401123 	 
2025-07-30 19:40:14.646560 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804208 	 1000 	 0.5082767009735107 	 0.15147876739501953 	 0.4827892780303955 	 0.12824630737304688 	 2.2661609649658203 	 0.17274236679077148 	 1.1576695442199707 	 0.09726357460021973 	 
2025-07-30 19:40:18.629292 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 50401, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50804208 	 1000 	 0.5471162796020508 	 0.15152692794799805 	 0.5211594104766846 	 0.12888836860656738 	 2.2654836177825928 	 0.17277169227600098 	 1.1575052738189697 	 0.09747123718261719 	 
2025-07-30 19:40:25.235290 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50851584 	 1000 	 15.889002799987793 	 0.15045976638793945 	 15.863287448883057 	 0.12574291229248047 	 2.2645580768585205 	 0.16530132293701172 	 1.1569750308990479 	 0.09003138542175293 	 
2025-07-30 19:40:44.595241 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 1051, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50851584 	 1000 	 19.29443383216858 	 0.15043258666992188 	 19.26841950416565 	 0.12750029563903809 	 2.4168434143066406 	 0.16539239883422852 	 1.3077759742736816 	 0.09029412269592285 	 
2025-07-30 19:41:08.607644 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 414, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 414, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.384976625442505 	 0.14949560165405273 	 39.35951590538025 	 0.11730504035949707 	 2.2261064052581787 	 0.16586542129516602 	 1.137200117111206 	 0.08605098724365234 	 
2025-07-30 19:41:51.459944 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 460, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 460, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.25639629364014 	 0.14946293830871582 	 39.22957158088684 	 0.12675857543945312 	 2.225823163986206 	 0.1654679775238037 	 1.1372179985046387 	 0.06811666488647461 	 
2025-07-30 19:42:35.608791 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 591, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 591, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50835456 	 1000 	 24.487778425216675 	 0.1498560905456543 	 24.462061405181885 	 0.12745141983032227 	 2.2247512340545654 	 0.16549277305603027 	 1.1366479396820068 	 0.08402180671691895 	 
2025-07-30 19:43:03.525412 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 591],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 591],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50835456 	 1000 	 23.239964723587036 	 0.14980030059814453 	 23.212753295898438 	 0.12740468978881836 	 2.1656341552734375 	 0.1652674674987793 	 1.1064105033874512 	 0.08836793899536133 	 
2025-07-30 19:43:30.116603 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 9, 460],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 9, 460],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50872320 	 1000 	 39.15227508544922 	 0.14948153495788574 	 39.12673211097717 	 0.1239919662475586 	 2.167039155960083 	 0.16553020477294922 	 1.1070890426635742 	 0.08897066116333008 	 
2025-07-30 19:44:12.650216 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 946, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 946, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 50856960 	 1000 	 17.39176654815674 	 0.1496446132659912 	 17.366031885147095 	 0.12676310539245605 	 2.228147268295288 	 0.16555523872375488 	 1.1383991241455078 	 0.08822107315063477 	 
2025-07-30 19:44:33.463798 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([60, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([60, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51609600 	 1000 	 0.9027705192565918 	 0.1509871482849121 	 0.8738799095153809 	 0.12842631340026855 	 2.27052903175354 	 0.17571449279785156 	 1.159956932067871 	 0.08990859985351562 	 
2025-07-30 19:44:40.175504 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 7, 9],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51093504 	 1000 	 0.5092034339904785 	 0.15219950675964355 	 0.4836101531982422 	 0.12139511108398438 	 2.281130075454712 	 0.17383861541748047 	 1.1653923988342285 	 0.0976252555847168 	 
2025-07-30 19:44:44.115318 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
[Prof] paddle.nn.functional.adaptive_avg_pool3d 	 paddle.nn.functional.adaptive_avg_pool3d(Tensor([66, 768, 16, 9, 7],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, ) 	 51093504 	 1000 	 0.5483169555664062 	 0.15218591690063477 	 0.5226118564605713 	 0.12981677055358887 	 2.2803955078125 	 0.1738431453704834 	 1.165161371231079 	 0.0973820686340332 	 
2025-07-30 19:44:48.132525 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 3175201],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
W0730 19:44:48.907925 32373 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 3175201],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 50805392 	 1000 	 12.283169746398926 	 8.200768232345581 	 0.009477615356445312 	 0.006608247756958008 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:45:28.266778 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([25401601, 16],"float32"), Tensor([25401601],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([25401601, 16],"float32"), Tensor([25401601],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 431827345 	 1000 	 50.03377914428711 	 21.039834022521973 	 0.007111787796020508 	 0.00618743896484375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:47:26.965164 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([3175201, 16],"float32"), Tensor([3175201],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
[Prof] paddle.nn.functional.adaptive_log_softmax_with_loss 	 paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([3175201, 16],"float32"), Tensor([3175201],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, ) 	 53978545 	 1000 	 6.782023191452026 	 3.398378372192383 	 0.0008060932159423828 	 0.0005638599395751953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:47:43.048873 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 4233601],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 4233601],"float64"), 8, False, None, ) 	 25401606 	 1000 	 62.44653606414795 	 61.34971499443054 	 62.422043800354004 	 61.32532548904419 	 0.4508788585662842 	 0.13774418830871582 	 0.23005366325378418 	 0.04652070999145508 	 
2025-07-30 19:49:48.141746 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), 16, False, None, ) 	 50803206 	 1000 	 48.683305740356445 	 41.186429262161255 	 48.658496379852295 	 41.162829637527466 	 0.7637877464294434 	 0.13727355003356934 	 0.39014649391174316 	 0.04586148262023926 	 
2025-07-30 19:51:20.965942 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 8467201],"float32"), output_size=16, ) 	 50803206 	 1000 	 48.65338492393494 	 41.19205069541931 	 48.61977434158325 	 41.16812801361084 	 0.7638609409332275 	 0.1372671127319336 	 0.39009523391723633 	 0.04649186134338379 	 
2025-07-30 19:52:52.650806 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 396901, 32],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 396901, 32],"float64"), 8, False, None, ) 	 25401664 	 1000 	 0.20821166038513184 	 0.8706984519958496 	 0.1741940975189209 	 0.8395519256591797 	 0.5244636535644531 	 0.7765438556671143 	 0.26792335510253906 	 0.39672064781188965 	 
2025-07-30 19:52:55.697244 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), 16, False, None, ) 	 50803264 	 1000 	 0.4093174934387207 	 1.7107179164886475 	 0.38449764251708984 	 1.6867353916168213 	 0.8954610824584961 	 1.4099886417388916 	 0.4575202465057373 	 0.7203967571258545 	 
2025-07-30 19:53:01.379123 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 793801, 32],"float32"), output_size=16, ) 	 50803264 	 1000 	 0.40929484367370605 	 1.7108054161071777 	 0.38425540924072266 	 1.6869077682495117 	 0.8958554267883301 	 1.4099409580230713 	 0.4576735496520996 	 0.7203974723815918 	 
2025-07-30 19:53:07.008162 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([264601, 3, 32],"float64"), 8, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([264601, 3, 32],"float64"), 8, False, None, ) 	 25401696 	 1000 	 0.2083268165588379 	 3.4139633178710938 	 0.18406200408935547 	 3.3746275901794434 	 0.5220186710357666 	 3.3264241218566895 	 0.2666497230529785 	 1.6997301578521729 	 
2025-07-30 19:53:15.164422 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), 16, False, None, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), 16, False, None, ) 	 50803296 	 1000 	 0.40926361083984375 	 6.810673475265503 	 0.3848445415496826 	 6.7864885330200195 	 0.8941376209259033 	 6.510155200958252 	 0.45685505867004395 	 3.3266024589538574 	 
2025-07-30 19:53:31.088218 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), output_size=16, )
[Prof] paddle.nn.functional.adaptive_max_pool1d 	 paddle.nn.functional.adaptive_max_pool1d(Tensor([529201, 3, 32],"float32"), output_size=16, ) 	 50803296 	 1000 	 0.40926599502563477 	 6.819819688796997 	 0.38159990310668945 	 6.77529239654541 	 0.8939535617828369 	 6.510229825973511 	 0.4567139148712158 	 3.326589584350586 	 
2025-07-30 19:53:48.728864 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 1209601, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 1209601, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803242 	 1000 	 328.26174759864807 	 136.30095505714417 	 328.24808526039124 	 136.28085160255432 	 0.781545877456665 	 0.13848185539245605 	 0.3993194103240967 	 0.06547689437866211 	 
2025-07-30 20:01:37.438169 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803242 	 1000 	 113.43784070014954 	 56.187968254089355 	 113.4244909286499 	 56.16938829421997 	 0.8051857948303223 	 0.1373608112335205 	 0.41131067276000977 	 0.0620880126953125 	 
2025-07-30 20:04:29.030801 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 	 50803242 	 1000 	 178.14181542396545 	 78.2334635257721 	 178.1285378932953 	 78.21254825592041 	 0.7706148624420166 	 0.13714909553527832 	 0.39372944831848145 	 0.06433320045471191 	 
2025-07-30 20:08:47.421197 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 1209601],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 	 50803242 	 1000 	 222.80201411247253 	 94.62045621871948 	 222.7889120578766 	 94.59510231018066 	 0.7812530994415283 	 0.137282133102417 	 0.3991861343383789 	 0.06467199325561523 	 
2025-07-30 20:14:06.965444 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803298 	 1000 	 0.5825655460357666 	 4.68846583366394 	 0.561100959777832 	 4.660382032394409 	 1.0922398567199707 	 1.182161569595337 	 0.5580332279205322 	 0.6040298938751221 	 
2025-07-30 20:14:15.841537 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 	 50803298 	 1000 	 0.4389822483062744 	 2.6374807357788086 	 0.41764187812805176 	 2.6080970764160156 	 1.0127780437469482 	 0.9678254127502441 	 0.5174722671508789 	 0.4944770336151123 	 
2025-07-30 20:14:21.902142 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool2d 	 paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 518401, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 	 50803298 	 1000 	 0.38836097717285156 	 3.283602237701416 	 0.3670969009399414 	 3.2541470527648926 	 1.0366482734680176 	 1.0013766288757324 	 0.5296728610992432 	 0.5116441249847412 	 
2025-07-30 20:14:28.619462 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803690 	 1000 	 1.9650380611419678 	 10.29694151878357 	 1.9435386657714844 	 0.6577739715576172 	 1.262160062789917 	 1.490736484527588 	 0.6449229717254639 	 0.08963727951049805 	 
2025-07-30 20:14:44.902040 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803690 	 1000 	 1.5632567405700684 	 5.542918920516968 	 1.5417311191558838 	 0.8091850280761719 	 0.4792768955230713 	 0.5968990325927734 	 0.24483990669250488 	 0.0762474536895752 	 
2025-07-30 20:14:54.029165 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 103681, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803690 	 1000 	 1.9157943725585938 	 6.869012355804443 	 1.8943805694580078 	 0.7016925811767578 	 0.5802187919616699 	 0.8124868869781494 	 0.29641056060791016 	 0.07541584968566895 	 
2025-07-30 20:15:05.140009 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803494 	 1000 	 30.417057037353516 	 39.932878255844116 	 30.395461797714233 	 39.90549302101135 	 0.15437030792236328 	 0.13838911056518555 	 0.07878446578979492 	 0.0652930736541748 	 
2025-07-30 20:16:17.218500 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803494 	 1000 	 102.73911833763123 	 135.5643892288208 	 102.71719455718994 	 135.54278540611267 	 0.15065717697143555 	 0.13741827011108398 	 0.07694411277770996 	 0.06443285942077637 	 
2025-07-30 20:20:16.897453 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 172801, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803494 	 1000 	 72.09804511070251 	 91.11481761932373 	 72.08465266227722 	 91.09334897994995 	 0.15071892738342285 	 0.13740110397338867 	 0.05667734146118164 	 0.06431436538696289 	 
2025-07-30 20:23:01.423712 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803410 	 1000 	 23.923638820648193 	 29.988560676574707 	 23.904741287231445 	 29.96941351890564 	 0.1537623405456543 	 0.1375598907470703 	 0.0784907341003418 	 0.06418704986572266 	 
2025-07-30 20:23:56.930056 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803410 	 1000 	 106.15030980110168 	 136.5638210773468 	 106.1364963054657 	 136.5428442955017 	 0.15112614631652832 	 0.13745903968811035 	 0.07718229293823242 	 0.06280899047851562 	 
2025-07-30 20:28:01.054006 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 241921, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803410 	 1000 	 109.22001433372498 	 134.30752778053284 	 109.20636010169983 	 134.286381483078 	 0.15112972259521484 	 0.1374680995941162 	 0.07715559005737305 	 0.06077408790588379 	 
2025-07-30 20:32:05.993594 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803410 	 1000 	 10.180121898651123 	 11.835793733596802 	 10.16631531715393 	 11.817375183105469 	 0.15376567840576172 	 0.13758349418640137 	 0.07861137390136719 	 0.051973581314086914 	 
2025-07-30 20:32:29.188926 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803410 	 1000 	 31.036663055419922 	 36.09780788421631 	 31.02329158782959 	 36.07672715187073 	 0.15096712112426758 	 0.13762760162353516 	 0.07712316513061523 	 0.039971351623535156 	 
2025-07-30 20:33:39.235177 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 241921],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803410 	 1000 	 48.34783124923706 	 59.00445342063904 	 48.33442211151123 	 58.98322319984436 	 0.15112733840942383 	 0.13735699653625488 	 0.0771188735961914 	 0.0638892650604248 	 
2025-07-30 20:35:27.827706 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 	 50803935 	 1000 	 1.965132236480713 	 10.296260118484497 	 1.951631784439087 	 0.6576542854309082 	 1.2610177993774414 	 1.4904241561889648 	 0.6443185806274414 	 0.08956646919250488 	 
2025-07-30 20:35:46.131508 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 	 50803935 	 1000 	 1.5634212493896484 	 5.55253529548645 	 1.5422203540802002 	 0.8092226982116699 	 0.4800865650177002 	 0.5966513156890869 	 0.24529099464416504 	 0.07619094848632812 	 
2025-07-30 20:35:55.443752 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[Prof] paddle.nn.functional.adaptive_max_pool3d 	 paddle.nn.functional.adaptive_max_pool3d(Tensor([69121, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 	 50803935 	 1000 	 1.9159092903137207 	 6.8690314292907715 	 1.894545316696167 	 0.7016801834106445 	 0.5801177024841309 	 0.8123645782470703 	 0.2963571548461914 	 0.07538962364196777 	 
2025-07-30 20:36:06.549192 test begin: paddle.nn.functional.avg_pool1d(Tensor([13, 1, 3907939],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([13, 1, 3907939],"float32"), 25, 1, 0, True, False, None, ) 	 50803207 	 1000 	 36.750624656677246 	 1.5827269554138184 	 36.700809478759766 	 1.5669519901275635 	 45.80970048904419 	 3.7328529357910156 	 45.72955679893494 	 3.646679401397705 	 
2025-07-30 20:37:37.341121 test begin: paddle.nn.functional.avg_pool1d(Tensor([13, 32567, 120],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([13, 32567, 120],"float32"), 25, 1, 0, True, False, None, ) 	 50804520 	 1000 	 7.489216566085815 	 1.381298542022705 	 7.439754962921143 	 1.3571317195892334 	 11.498456239700317 	 3.8481743335723877 	 11.401598453521729 	 3.760850429534912 	 
2025-07-30 20:38:03.728158 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 1, 3175201],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 1, 3175201],"float32"), 25, 1, 0, True, False, None, ) 	 50803216 	 1000 	 36.70234990119934 	 1.5825259685516357 	 36.6527054309845 	 1.5639853477478027 	 45.749183654785156 	 3.72902250289917 	 45.65362882614136 	 3.6407318115234375 	 
2025-07-30 20:39:33.340285 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 2, 1587601],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 2, 1587601],"float32"), 25, 1, 0, True, False, None, ) 	 50803232 	 1000 	 18.45956540107727 	 1.5810344219207764 	 18.39189052581787 	 1.563981056213379 	 22.928783178329468 	 3.7344107627868652 	 22.83285403251648 	 3.6354424953460693 	 
2025-07-30 20:40:21.829750 test begin: paddle.nn.functional.avg_pool1d(Tensor([16, 26461, 120],"float32"), 25, 1, 0, True, False, None, )
[Prof] paddle.nn.functional.avg_pool1d 	 paddle.nn.functional.avg_pool1d(Tensor([16, 26461, 120],"float32"), 25, 1, 0, True, False, None, ) 	 50805120 	 1000 	 7.497298955917358 	 1.3822968006134033 	 7.451972723007202 	 1.3663451671600342 	 11.41269040107727 	 3.852069616317749 	 11.331262588500977 	 3.748417854309082 	 
2025-07-30 20:40:47.564717 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 127, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 127, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50978816 	 1000 	 0.194319486618042 	 0.41657447814941406 	 0.16558265686035156 	 0.39652228355407715 	 0.35346198081970215 	 1.570887565612793 	 0.2823812961578369 	 1.4702808856964111 	 
2025-07-30 20:40:51.158792 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 256, 28, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 256, 28, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.19877171516418457 	 0.4202432632446289 	 0.17069673538208008 	 0.40185976028442383 	 0.33348894119262695 	 1.5793859958648682 	 0.26250219345092773 	 1.5080609321594238 	 
2025-07-30 20:40:54.739985 test begin: paddle.nn.functional.avg_pool2d(Tensor([128, 256, 56, 28],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([128, 256, 56, 28],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.19970178604125977 	 0.4196202754974365 	 0.17959928512573242 	 0.40719103813171387 	 0.3348963260650635 	 1.5799670219421387 	 0.27304649353027344 	 1.5109138488769531 	 
2025-07-30 20:40:58.318424 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 128, 256, 97],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 128, 256, 97],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50855936 	 1000 	 0.1922307014465332 	 0.41002798080444336 	 0.16922307014465332 	 0.39821505546569824 	 0.3308265209197998 	 1.5640902519226074 	 0.26936817169189453 	 1.4948627948760986 	 
2025-07-30 20:41:01.842195 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 128, 97, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 128, 97, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 50855936 	 1000 	 0.1902756690979004 	 0.40646862983703613 	 0.163344144821167 	 0.39447593688964844 	 0.32988405227661133 	 1.5512900352478027 	 0.2681264877319336 	 1.4832403659820557 	 
2025-07-30 20:41:07.595081 test begin: paddle.nn.functional.avg_pool2d(Tensor([16, 49, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([16, 49, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.19619441032409668 	 0.42580389976501465 	 0.17343664169311523 	 0.3948514461517334 	 0.3536064624786377 	 1.5692164897918701 	 0.29199910163879395 	 1.493429183959961 	 
2025-07-30 20:41:13.987642 test begin: paddle.nn.functional.avg_pool2d(Tensor([4, 256, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([4, 256, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 58982400 	 1000 	 0.22298479080200195 	 1.4217183589935303 	 0.20298552513122559 	 0.4609205722808838 	 0.38245224952697754 	 1.8114683628082275 	 0.3209664821624756 	 1.7367000579833984 	 
2025-07-30 20:41:19.244576 test begin: paddle.nn.functional.avg_pool2d(Tensor([64, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([64, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51380224 	 1000 	 0.1956157684326172 	 0.4199206829071045 	 0.17549395561218262 	 0.40793919563293457 	 0.3541703224182129 	 1.5832364559173584 	 0.2902793884277344 	 1.5068368911743164 	 
2025-07-30 20:41:22.835501 test begin: paddle.nn.functional.avg_pool2d(Tensor([7, 128, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([7, 128, 256, 256],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 58720256 	 1000 	 0.22081828117370605 	 0.4722254276275635 	 0.19814085960388184 	 0.4603135585784912 	 0.38157057762145996 	 1.7922539710998535 	 0.31801581382751465 	 1.7242136001586914 	 
2025-07-30 20:41:26.868817 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 111, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 111, 240, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51148800 	 1000 	 0.19450855255126953 	 0.41684937477111816 	 0.1741633415222168 	 0.40451765060424805 	 0.3359992504119873 	 1.5709002017974854 	 0.27437520027160645 	 1.494375467300415 	 
2025-07-30 20:41:30.397196 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 256, 104, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 256, 104, 240],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51118080 	 1000 	 0.194258451461792 	 0.4166443347930908 	 0.17402291297912598 	 0.40442466735839844 	 0.33374619483947754 	 1.5689184665679932 	 0.27182602882385254 	 1.498600721359253 	 
2025-07-30 20:41:33.980551 test begin: paddle.nn.functional.avg_pool2d(Tensor([8, 256, 240, 104],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.avg_pool2d 	 paddle.nn.functional.avg_pool2d(Tensor([8, 256, 240, 104],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, ) 	 51118080 	 1000 	 0.19336414337158203 	 1.3522779941558838 	 0.1731562614440918 	 0.40351128578186035 	 0.3341679573059082 	 1.6450450420379639 	 0.27057647705078125 	 1.5560784339904785 	 
2025-07-30 20:41:40.188046 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 776, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(Tensor([2, 776, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", ) 	 50855936 	 1000 	 0.1767570972442627 	 0.42305874824523926 	 0.1573619842529297 	 0.40893054008483887 	 0.4252023696899414 	 0.49809885025024414 	 0.3621222972869873 	 0.2544684410095215 	 
2025-07-30 20:41:42.649822 test begin: paddle.nn.functional.avg_pool3d(Tensor([517, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(Tensor([517, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", ) 	 50823168 	 1000 	 0.17828369140625 	 0.4227766990661621 	 0.15893054008483887 	 0.4050145149230957 	 0.5583159923553467 	 0.49779701232910156 	 0.49687981605529785 	 0.2543191909790039 	 
2025-07-30 20:41:45.285839 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([127, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([127, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50978816 	 1000 	 0.24007940292358398 	 2.246411085128784 	 0.21735739707946777 	 0.5740261077880859 	 3.144230842590332 	 2.8959922790527344 	 3.082141160964966 	 0.17410016059875488 	 
2025-07-30 20:41:54.675242 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([127, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([127, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50978816 	 1000 	 0.2624673843383789 	 1.9923076629638672 	 0.2397453784942627 	 1.9786429405212402 	 2.8919577598571777 	 2.8770289421081543 	 2.8301663398742676 	 0.1729297637939453 	 
2025-07-30 20:42:03.519638 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 111, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 111, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.3412199020385742 	 10.941614151000977 	 0.31837916374206543 	 10.927262783050537 	 4.437199592590332 	 4.756313323974609 	 4.351114988327026 	 1.6216669082641602 	 
2025-07-30 20:42:24.847107 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 111],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 111],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.38463902473449707 	 0.771068811416626 	 0.3619370460510254 	 0.7572176456451416 	 3.0795624256134033 	 0.982311487197876 	 3.0116469860076904 	 0.3348226547241211 	 
2025-07-30 20:42:30.941641 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 64, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 64, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 51380224 	 1000 	 0.31815171241760254 	 7.908153533935547 	 0.29550886154174805 	 0.5050835609436035 	 4.321954011917114 	 4.3599324226379395 	 4.2591187953948975 	 0.24757051467895508 	 
2025-07-30 20:42:49.786395 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 111, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 111, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.3572812080383301 	 10.57925009727478 	 0.33416295051574707 	 10.564288139343262 	 4.428794860839844 	 4.7488110065460205 	 4.367030143737793 	 1.6191914081573486 	 
2025-07-30 20:43:10.775688 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 111],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 111],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50921472 	 1000 	 0.4143486022949219 	 0.9839267730712891 	 0.39131927490234375 	 0.9666194915771484 	 3.068012237548828 	 0.961113691329956 	 3.006049156188965 	 0.3275876045227051 	 
2025-07-30 20:43:17.074448 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 507, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 507, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50878464 	 1000 	 2.215121269226074 	 51.1176872253418 	 2.174469232559204 	 3.4425101280212402 	 15.123781681060791 	 17.59882640838623 	 15.060014724731445 	 1.0579662322998047 	 
2025-07-30 20:44:44.921209 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 32401, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 32401, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", ) 	 50804768 	 1000 	 0.2399277687072754 	 2.239124059677124 	 0.21716928482055664 	 0.5720703601837158 	 3.1341283321380615 	 2.885244369506836 	 3.0722496509552 	 0.1734321117401123 	 
2025-07-30 20:44:54.304353 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([8, 4051, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.avg_pool3d 	 paddle.nn.functional.avg_pool3d(x=Tensor([8, 4051, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", ) 	 50815744 	 1000 	 0.2663540840148926 	 1.986520528793335 	 0.24347400665283203 	 1.9728899002075195 	 2.883030652999878 	 2.867332696914673 	 2.8211495876312256 	 0.1723496913909912 	 
2025-07-30 20:45:03.135074 test begin: paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), Tensor([847],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50823388 	 1000 	 0.3759644031524658 	 0.3726794719696045 	 0.35663866996765137 	 0.34407782554626465 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 40, 50, 847]) and output[0] has a shape of torch.Size([30, 847, 40, 50]).
2025-07-30 20:45:09.745596 test begin: paddle.nn.functional.batch_norm(Tensor([30, 40, 706, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 40, 706, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50832240 	 1000 	 0.3696901798248291 	 0.3681020736694336 	 0.350283145904541 	 0.33936142921447754 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 40, 706, 60]) and output[0] has a shape of torch.Size([30, 60, 40, 706]).
2025-07-30 20:45:15.657922 test begin: paddle.nn.functional.batch_norm(Tensor([30, 565, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([30, 565, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50850240 	 1000 	 0.37698841094970703 	 0.3729081153869629 	 0.35767459869384766 	 0.34410619735717773 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([30, 565, 50, 60]) and output[0] has a shape of torch.Size([30, 60, 565, 50]).
2025-07-30 20:45:21.762790 test begin: paddle.nn.functional.batch_norm(Tensor([424, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
[Prof] paddle.nn.functional.batch_norm 	 paddle.nn.functional.batch_norm(Tensor([424, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", ) 	 50880240 	 1000 	 0.3399817943572998 	 0.33878445625305176 	 0.3204963207244873 	 0.3096907138824463 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([424, 40, 50, 60]) and output[0] has a shape of torch.Size([424, 60, 40, 50]).
2025-07-30 20:45:27.471311 test begin: paddle.nn.functional.bilinear(Tensor([25401601, 1],"float32"), Tensor([25401601, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([25401601, 1],"float32"), Tensor([25401601, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, ) 	 76204815 	 1000 	 15.047353744506836 	 118.79457139968872 	 0.14671111106872559 	 0.0731201171875 	 30.284027099609375 	 125.45835447311401 	 0.24991774559020996 	 0.07916069030761719 	 
2025-07-30 20:50:20.394960 test begin: paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 12700801],"float32"), Tensor([4, 1, 12700801],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 12700801],"float32"), Tensor([4, 1, 12700801],"float32"), Tensor([1, 4],"float32"), None, ) 	 88905614 	 1000 	 3.3965024948120117 	 45.262094259262085 	 0.05341386795043945 	 0.7466824054718018 	 6.648566722869873 	 50.3328161239624 	 0.09045767784118652 	 0.5585155487060547 	 
2025-07-30 20:52:07.659507 test begin: paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 16934401],"float32"), Tensor([4, 1, 16934401],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([3, 1],"float32"), Tensor([3, 16934401],"float32"), Tensor([4, 1, 16934401],"float32"), Tensor([1, 4],"float32"), None, ) 	 118540814 	 1000 	 4.567755699157715 	 60.594120264053345 	 0.057694435119628906 	 0.8024537563323975 	 8.798783779144287 	 66.64134311676025 	 0.09818172454833984 	 0.6083152294158936 	 
2025-07-30 20:54:31.152682 test begin: paddle.nn.functional.bilinear(Tensor([5, 5],"float32"), Tensor([5, 10161],"float32"), Tensor([1000, 5, 10161],"float32"), Tensor([1, 1000],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([5, 5],"float32"), Tensor([5, 10161],"float32"), Tensor([1000, 5, 10161],"float32"), Tensor([1, 1000],"float32"), None, ) 	 50856830 	 1000 	 31.441219806671143 	 43.15316653251648 	 0.008003950119018555 	 0.00029158592224121094 	 38.74987769126892 	 112.37312865257263 	 0.006494760513305664 	 0.0002701282501220703 	 
2025-07-30 20:58:17.968920 test begin: paddle.nn.functional.bilinear(Tensor([50803201, 1],"float32"), Tensor([50803201, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, )
[Prof] paddle.nn.functional.bilinear 	 paddle.nn.functional.bilinear(Tensor([50803201, 1],"float32"), Tensor([50803201, 2],"float32"), Tensor([4, 1, 2],"float32"), Tensor([1, 4],"float32"), None, ) 	 152409615 	 1000 	 30.0466206073761 	 237.16136622428894 	 0.15538477897644043 	 0.07437896728515625 	 60.31952524185181 	 250.25019001960754 	 0.27916550636291504 	 0.09035420417785645 	 
2025-07-30 21:08:03.636429 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"float32"), weight=Tensor([16, 10164, 313],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 10164, 313],"float32"), Tensor([16, 10164, 313],"float32"), weight=Tensor([16, 10164, 313],"float32"), reduction="sum", ) 	 152703936 	 1000 	 1.0485270023345947 	 1.0566599369049072 	 0.2675600051879883 	 0.215409517288208 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:10.109442 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"float32"), weight=Tensor([16, 11109, 286],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 11109, 286],"float32"), Tensor([16, 11109, 286],"float32"), weight=Tensor([16, 11109, 286],"float32"), reduction="sum", ) 	 152504352 	 1000 	 1.0470831394195557 	 1.0556068420410156 	 0.2671213150024414 	 0.21542620658874512 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:16.410203 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"float32"), weight=Tensor([16, 12096, 263],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 12096, 263],"float32"), Tensor([16, 12096, 263],"float32"), weight=Tensor([16, 12096, 263],"float32"), reduction="sum", ) 	 152699904 	 1000 	 1.050851821899414 	 1.0551538467407227 	 0.2687873840332031 	 0.21535682678222656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:22.851739 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="sum", ) 	 152413440 	 1000 	 1.0467479228973389 	 1.0563311576843262 	 0.2670743465423584 	 0.21538186073303223 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:29.144206 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([53, 12096, 80],"float32"), Tensor([53, 12096, 80],"float32"), weight=Tensor([53, 12096, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([53, 12096, 80],"float32"), Tensor([53, 12096, 80],"float32"), weight=Tensor([53, 12096, 80],"float32"), reduction="sum", ) 	 153861120 	 1000 	 1.0574324131011963 	 1.0692238807678223 	 0.27079033851623535 	 0.21696877479553223 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:39.593063 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([58, 11109, 80],"float32"), Tensor([58, 11109, 80],"float32"), weight=Tensor([58, 11109, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([58, 11109, 80],"float32"), Tensor([58, 11109, 80],"float32"), weight=Tensor([58, 11109, 80],"float32"), reduction="sum", ) 	 154637280 	 1000 	 1.0616044998168945 	 1.0731117725372314 	 0.2708706855773926 	 0.21847248077392578 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:48.240428 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([63, 10164, 80],"float32"), Tensor([63, 10164, 80],"float32"), weight=Tensor([63, 10164, 80],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.binary_cross_entropy 	 paddle.nn.functional.binary_cross_entropy(Tensor([63, 10164, 80],"float32"), Tensor([63, 10164, 80],"float32"), weight=Tensor([63, 10164, 80],"float32"), reduction="sum", ) 	 153679680 	 1000 	 1.0551021099090576 	 1.061840295791626 	 0.2691960334777832 	 0.21681952476501465 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:08:54.740770 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 300, 10585],"float32"), Tensor([16, 300, 10585],"float32"), weight=Tensor([16, 300, 10585],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 300, 10585],"float32"), Tensor([16, 300, 10585],"float32"), weight=Tensor([16, 300, 10585],"float32"), reduction="none", ) 	 152424000 	 1000 	 1.0384578704833984 	 2.2268588542938232 	 0.35398077964782715 	 0.37719154357910156 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:03.627120 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([16, 39691, 80],"float32"), Tensor([16, 39691, 80],"float32"), weight=Tensor([16, 39691, 80],"float32"), reduction="none", ) 	 152413440 	 1000 	 1.0392625331878662 	 2.2165887355804443 	 0.3542184829711914 	 0.3772010803222656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:12.391092 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2117, 300, 80],"float32"), Tensor([2117, 300, 80],"float32"), weight=Tensor([2117, 300, 80],"float32"), reduction="none", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2117, 300, 80],"float32"), Tensor([2117, 300, 80],"float32"), weight=Tensor([2117, 300, 80],"float32"), reduction="none", ) 	 152424000 	 1000 	 1.043274164199829 	 2.216181993484497 	 0.35397934913635254 	 0.3771834373474121 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:20.899266 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), weight=Tensor([300, 169345],"float32"), reduction="none", pos_weight=None, )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 169345],"float32"), Tensor([300, 169345],"float32"), weight=Tensor([300, 169345],"float32"), reduction="none", pos_weight=None, ) 	 152410500 	 1000 	 1.0406591892242432 	 2.2160651683807373 	 0.3552405834197998 	 0.377124547958374 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:29.320719 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([50804, 1000],"float32"), Tensor([50804, 1000],"float32"), weight=Tensor([50804, 1000],"float32"), reduction="none", pos_weight=None, )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([50804, 1000],"float32"), Tensor([50804, 1000],"float32"), weight=Tensor([50804, 1000],"float32"), reduction="none", pos_weight=None, ) 	 152412000 	 1000 	 1.039447546005249 	 2.2314319610595703 	 0.3552670478820801 	 0.3772907257080078 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:40.665474 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 28, 3544],"float32"), Tensor([512, 28, 3544],"float32"), weight=Tensor([512, 1, 3544],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 28, 3544],"float32"), Tensor([512, 28, 3544],"float32"), weight=Tensor([512, 1, 3544],"float32"), reduction="mean", ) 	 103428096 	 1000 	 1.0424160957336426 	 2.2437660694122314 	 0.2128276824951172 	 0.2864041328430176 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:47.384824 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 3544, 28],"float32"), Tensor([512, 3544, 28],"float32"), weight=Tensor([512, 3544, 1],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 3544, 28],"float32"), Tensor([512, 3544, 28],"float32"), weight=Tensor([512, 3544, 1],"float32"), reduction="mean", ) 	 103428096 	 1000 	 1.0416462421417236 	 2.236284017562866 	 0.21266865730285645 	 0.28588294982910156 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:09:57.068279 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), weight=Tensor([64801, 1, 1],"float32"), reduction="mean", )
[Prof] paddle.nn.functional.binary_cross_entropy_with_logits 	 paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([64801, 28, 28],"float32"), Tensor([64801, 28, 28],"float32"), weight=Tensor([64801, 1, 1],"float32"), reduction="mean", ) 	 101672769 	 1000 	 1.0372071266174316 	 2.2329306602478027 	 0.21177220344543457 	 0.28502345085144043 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:10:03.671525 test begin: paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 0.2, None, ) 	 25401616 	 1000 	 0.30817246437072754 	 0.30387163162231445 	 0.2991158962249756 	 0.28682851791381836 	 0.44829511642456055 	 0.4493105411529541 	 0.39537906646728516 	 0.38085007667541504 	 
2025-07-30 21:10:06.248648 test begin: paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([1587601, 4, 4],"float64"), 1.0, None, ) 	 25401616 	 1000 	 0.30817675590515137 	 0.3039250373840332 	 0.2991337776184082 	 0.2867457866668701 	 0.4481801986694336 	 0.44931864738464355 	 0.39513587951660156 	 0.38074493408203125 	 
2025-07-30 21:10:08.807750 test begin: paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 0.2, None, ) 	 25401608 	 1000 	 0.30811119079589844 	 0.3038802146911621 	 0.2988262176513672 	 0.28059887886047363 	 0.44818115234375 	 0.45060205459594727 	 0.39343881607055664 	 0.381756067276001 	 
2025-07-30 21:10:11.390476 test begin: paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 3175201, 4],"float64"), 1.0, None, ) 	 25401608 	 1000 	 0.3093125820159912 	 0.30389881134033203 	 0.3002915382385254 	 0.28679776191711426 	 0.4481987953186035 	 0.4493749141693115 	 0.39454030990600586 	 0.3809545040130615 	 
2025-07-30 21:10:13.998396 test begin: paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 0.2, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 0.2, None, ) 	 25401608 	 1000 	 0.30814337730407715 	 0.3038766384124756 	 0.2991816997528076 	 0.28322935104370117 	 0.4495217800140381 	 0.44937801361083984 	 0.39573121070861816 	 0.3800852298736572 	 
2025-07-30 21:10:16.546369 test begin: paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 1.0, None, )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(Tensor([2, 4, 3175201],"float64"), 1.0, None, ) 	 25401608 	 1000 	 0.3081519603729248 	 0.3038945198059082 	 0.2990763187408447 	 0.2867617607116699 	 0.44817066192626953 	 0.4493591785430908 	 0.3947887420654297 	 0.3772735595703125 	 
2025-07-30 21:10:19.091466 test begin: paddle.nn.functional.celu(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.3080892562866211 	 0.303955078125 	 0.29878878593444824 	 0.2870066165924072 	 0.44820261001586914 	 0.45088696479797363 	 0.3914647102355957 	 0.3802344799041748 	 
2025-07-30 21:10:21.633364 test begin: paddle.nn.functional.celu(x=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([2, 3175201, 4],"float64"), ) 	 25401608 	 1000 	 0.30820202827453613 	 0.30390024185180664 	 0.29889965057373047 	 0.2870326042175293 	 0.4481775760650635 	 0.44932079315185547 	 0.3952827453613281 	 0.38106560707092285 	 
2025-07-30 21:10:24.215060 test begin: paddle.nn.functional.celu(x=Tensor([2, 4, 3175201],"float64"), )
[Prof] paddle.nn.functional.celu 	 paddle.nn.functional.celu(x=Tensor([2, 4, 3175201],"float64"), ) 	 25401608 	 1000 	 0.30941295623779297 	 0.3055386543273926 	 0.30001091957092285 	 0.2869398593902588 	 0.4495117664337158 	 0.4493236541748047 	 0.39578723907470703 	 0.3796398639678955 	 
2025-07-30 21:10:26.754749 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", ) 	 25401744 	 1000 	 0.3148767948150635 	 0.2974381446838379 	 0.30443549156188965 	 0.27788209915161133 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([176401, 4, 4, 9]) and output[0] has a shape of torch.Size([176401, 9, 4, 4]).
2025-07-30 21:10:28.714837 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 4, 4, 9],"float64"), 3, "NHWC", None, ) 	 25401744 	 1000 	 0.31494832038879395 	 0.3110942840576172 	 0.3045976161956787 	 0.27799320220947266 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([176401, 4, 4, 9]) and output[0] has a shape of torch.Size([176401, 9, 4, 4]).
2025-07-30 21:10:30.702928 test begin: paddle.nn.functional.channel_shuffle(Tensor([176401, 9, 4, 4],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([176401, 9, 4, 4],"float64"), 3, "NCHW", ) 	 25401744 	 1000 	 0.31351518630981445 	 0.3027987480163574 	 0.30312442779541016 	 0.2833237648010254 	 0.3136751651763916 	 0.3027026653289795 	 0.26085400581359863 	 0.22056055068969727 	 
2025-07-30 21:10:32.973549 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", ) 	 25401672 	 1000 	 0.3160562515258789 	 1.3187880516052246 	 0.30560731887817383 	 1.2755792140960693 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 352801, 4, 9]) and output[0] has a shape of torch.Size([2, 9, 352801, 4]).
2025-07-30 21:10:37.416387 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 352801, 4, 9],"float64"), 3, "NHWC", None, ) 	 25401672 	 1000 	 0.31487441062927246 	 1.3233230113983154 	 0.30446791648864746 	 1.28497314453125 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 352801, 4, 9]) and output[0] has a shape of torch.Size([2, 9, 352801, 4]).
2025-07-30 21:10:41.405719 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", ) 	 25401672 	 1000 	 0.3148491382598877 	 1.3078835010528564 	 0.3043057918548584 	 1.2748501300811768 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 4, 352801, 9]) and output[0] has a shape of torch.Size([2, 9, 4, 352801]).
2025-07-30 21:10:44.500552 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", None, )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 4, 352801, 9],"float64"), 3, "NHWC", None, ) 	 25401672 	 1000 	 0.31627559661865234 	 1.3039467334747314 	 0.3058016300201416 	 1.2845616340637207 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([2, 4, 352801, 9]) and output[0] has a shape of torch.Size([2, 9, 4, 352801]).
2025-07-30 21:10:47.579502 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 9, 352801, 4],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 9, 352801, 4],"float64"), 3, "NCHW", ) 	 25401672 	 1000 	 0.31421804428100586 	 0.30269455909729004 	 0.29602837562561035 	 0.2649552822113037 	 0.3145911693572998 	 0.30234408378601074 	 0.2530059814453125 	 0.19412875175476074 	 
2025-07-30 21:10:49.987552 test begin: paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 352801],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.channel_shuffle 	 paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 352801],"float64"), 3, "NCHW", ) 	 25401672 	 1000 	 0.3141472339630127 	 0.30261921882629395 	 0.3037266731262207 	 0.28167724609375 	 0.31447839736938477 	 0.30269598960876465 	 0.2622809410095215 	 0.18197298049926758 	 
2025-07-30 21:10:52.268691 test begin: paddle.nn.functional.conv1d(Tensor([16, 125, 25500],"float32"), Tensor([1, 125, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([16, 125, 25500],"float32"), Tensor([1, 125, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51000126 	 1000 	 0.32352757453918457 	 0.16598725318908691 	 0.09731578826904297 	 0.08300232887268066 	 0.8271162509918213 	 0.33730578422546387 	 0.14088964462280273 	 0.06843996047973633 	 
2025-07-30 21:10:55.091893 test begin: paddle.nn.functional.conv1d(Tensor([16, 64, 49613],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([16, 64, 49613],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50803777 	 1000 	 0.33719801902770996 	 0.16836857795715332 	 0.06991457939147949 	 0.08592486381530762 	 0.7339069843292236 	 0.36331915855407715 	 0.12498307228088379 	 0.07406997680664062 	 
2025-07-30 21:10:59.710887 test begin: paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52040609 	 1000 	 0.3940863609313965 	 0.18471908569335938 	 0.13399410247802734 	 0.09433889389038086 	 0.7709550857543945 	 0.3988518714904785 	 0.13128662109375 	 0.08134222030639648 	 
2025-07-30 21:11:04.179567 test begin: paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([28, 32, 58081],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52041632 	 1000 	 0.6792137622833252 	 1.7182908058166504 	 0.17371773719787598 	 0.5096781253814697 	 1.2894558906555176 	 12.842381715774536 	 0.16475820541381836 	 2.619814395904541 	 
2025-07-30 21:11:23.911537 test begin: paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([1, 32, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50803745 	 1000 	 0.3844280242919922 	 0.1780683994293213 	 0.13075637817382812 	 0.09097433090209961 	 0.7408237457275391 	 0.3707296848297119 	 0.12597894668579102 	 0.07559490203857422 	 
2025-07-30 21:11:26.446982 test begin: paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 32, 49613],"float32"), Tensor([32, 32, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50804768 	 1000 	 0.6590244770050049 	 0.9493498802185059 	 0.16816067695617676 	 0.4837002754211426 	 1.285482406616211 	 11.112369060516357 	 0.16563749313354492 	 2.2697908878326416 	 
2025-07-30 21:11:42.098426 test begin: paddle.nn.functional.conv1d(Tensor([32, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d 	 paddle.nn.functional.conv1d(Tensor([32, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", ) 	 52224065 	 1000 	 0.34662699699401855 	 0.1710062026977539 	 0.11782360076904297 	 0.08726620674133301 	 0.6395955085754395 	 0.3483736515045166 	 0.08167648315429688 	 0.07102298736572266 	 
2025-07-30 21:11:44.475805 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50978641 	 1000 	 2.254599094390869 	 2.3613955974578857 	 0.767812967300415 	 0.8056948184967041 	 1.333489179611206 	 1.0718193054199219 	 0.2731144428253174 	 0.2738497257232666 	 
2025-07-30 21:11:52.436853 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50822772 	 1000 	 0.266345739364624 	 0.2688252925872803 	 0.0907292366027832 	 0.09141397476196289 	 21.003518104553223 	 9.600874423980713 	 4.2838239669799805 	 2.4500787258148193 	 
2025-07-30 21:12:24.546081 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50859776 	 1000 	 0.2638084888458252 	 0.26636385917663574 	 0.08977580070495605 	 0.0905768871307373 	 21.03900647163391 	 20.039604902267456 	 4.291465520858765 	 4.091532945632935 	 
2025-07-30 21:13:07.085791 test begin: paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 99226],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([1, 512, 99226],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51852544 	 1000 	 14.545410871505737 	 14.662107706069946 	 4.9595348834991455 	 4.996791839599609 	 40.054863691329956 	 26.75743269920349 	 6.832363128662109 	 4.549383878707886 	 
2025-07-30 21:14:45.992120 test begin: paddle.nn.functional.conv1d_transpose(Tensor([14176, 512, 7],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([14176, 512, 7],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51855616 	 1000 	 62.83865165710449 	 63.27105522155762 	 21.426785230636597 	 21.568833351135254 	 128.74009108543396 	 128.7316222190857 	 22.00670623779297 	 21.88073754310608 	 
2025-07-30 21:21:12.703491 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 24807, 7],"float32"), Tensor([24807, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51152290 	 1000 	 2.2381739616394043 	 2.3417606353759766 	 0.7626562118530273 	 0.798987865447998 	 1.3264744281768799 	 1.6011590957641602 	 0.27228403091430664 	 0.4103584289550781 	 
2025-07-30 21:21:21.225364 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 128, 1551],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 128, 1551],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50837632 	 1000 	 0.4949381351470947 	 0.5030121803283691 	 0.16920161247253418 	 0.16968393325805664 	 18.069642066955566 	 38.49255585670471 	 3.684927225112915 	 7.855855703353882 	 
2025-07-30 21:22:19.762406 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 24807, 8],"float32"), bias=Tensor([24807],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 28],"float32"), Tensor([256, 24807, 8],"float32"), bias=Tensor([24807],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50843879 	 1000 	 0.5454583168029785 	 1.0427632331848145 	 0.18585562705993652 	 0.35510945320129395 	 44.13867449760437 	 20.547277450561523 	 7.51360821723938 	 5.241159677505493 	 
2025-07-30 21:23:27.410094 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 99226],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 256, 99226],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51065984 	 1000 	 7.9074718952178955 	 7.991679906845093 	 2.697528600692749 	 2.7222087383270264 	 17.14418053627014 	 13.636972904205322 	 2.9210000038146973 	 2.3199498653411865 	 
2025-07-30 21:24:16.762881 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 49613, 28],"float32"), Tensor([49613, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 49613, 28],"float32"), Tensor([49613, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 53582168 	 1000 	 4.437205791473389 	 4.636384963989258 	 1.5139286518096924 	 1.5794060230255127 	 1.8351476192474365 	 1.8895761966705322 	 0.31203627586364746 	 0.4817023277282715 	 
2025-07-30 21:24:30.469789 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 49613],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 49613],"float32"), Tensor([512, 256, 8],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51852544 	 1000 	 14.563318014144897 	 14.69161319732666 	 4.967471599578857 	 5.009814500808716 	 29.555941820144653 	 26.772002696990967 	 5.037065505981445 	 4.5521416664123535 	 
2025-07-30 21:25:58.804003 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 12404, 8],"float32"), bias=Tensor([12404],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50826356 	 1000 	 0.4763636589050293 	 1.111448049545288 	 0.1616966724395752 	 0.30132389068603516 	 21.023140907287598 	 9.615262985229492 	 4.288783311843872 	 2.4508450031280518 	 
2025-07-30 21:26:32.697925 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 512, 7],"float32"), Tensor([512, 256, 388],"float32"), bias=Tensor([256],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 50863360 	 1000 	 0.47060680389404297 	 0.4776041507720947 	 0.1601874828338623 	 0.1619722843170166 	 20.81448483467102 	 20.092268466949463 	 3.5357542037963867 	 4.100671291351318 	 
2025-07-30 21:27:15.527230 test begin: paddle.nn.functional.conv1d_transpose(Tensor([2, 907201, 28],"float32"), Tensor([907201, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([2, 907201, 28],"float32"), Tensor([907201, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 979777208 	 1000 	 81.04559755325317 	 84.63281631469727 	 27.62727403640747 	 28.864238023757935 	 35.735941886901855 	 36.048503398895264 	 6.096225738525391 	 7.3736655712127686 	 
2025-07-30 21:31:29.937278 test begin: paddle.nn.functional.conv1d_transpose(Tensor([7088, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
[Prof] paddle.nn.functional.conv1d_transpose 	 paddle.nn.functional.conv1d_transpose(Tensor([7088, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", ) 	 51069056 	 1000 	 8.887927770614624 	 8.987553119659424 	 3.028963565826416 	 3.065911054611206 	 23.32524800300598 	 22.069237232208252 	 3.9823100566864014 	 3.750539541244507 	 
2025-07-30 21:32:37.101741 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 191, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 191, 4],"float32"), ) 	 50852604 	 1000 	 0.37575793266296387 	 0.37804508209228516 	 0.3322722911834717 	 0.35776638984680176 	 69.9428973197937 	 4.023565053939819 	 23.781086921691895 	 1.0257794857025146 	 
2025-07-30 21:33:53.045194 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 191, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50851856 	 1000 	 1.0993967056274414 	 1.1063337326049805 	 1.0451972484588623 	 1.085019826889038 	 11.907954692840576 	 13.112509965896606 	 4.065732479095459 	 4.469905138015747 	 
2025-07-30 21:34:22.132941 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 192, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 192, 4],"float32"), ) 	 50922240 	 1000 	 0.9608604907989502 	 1.1973750591278076 	 0.4905228614807129 	 1.163989782333374 	 70.29142880439758 	 70.89297318458557 	 23.900694131851196 	 24.102322816848755 	 
2025-07-30 21:36:47.497930 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 192, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50921488 	 1000 	 1.1031627655029297 	 1.110908031463623 	 1.0605974197387695 	 1.0888187885284424 	 11.855538606643677 	 13.127928972244263 	 4.048198938369751 	 4.473755598068237 	 
2025-07-30 21:37:17.880020 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 193, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 193, 4],"float32"), ) 	 50989828 	 1000 	 0.9819586277008057 	 0.37596988677978516 	 0.5014994144439697 	 0.35315990447998047 	 70.86486649513245 	 71.34444165229797 	 24.105523586273193 	 24.255455017089844 	 
2025-07-30 21:39:42.478066 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 193, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50989072 	 1000 	 1.1037118434906006 	 1.1102674007415771 	 1.0605957508087158 	 1.0892422199249268 	 11.866071224212646 	 13.147972106933594 	 4.042325973510742 	 4.4821391105651855 	 
2025-07-30 21:40:11.527833 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 193],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 193],"float32"), ) 	 50989828 	 1000 	 1.3653762340545654 	 2.853323459625244 	 0.6976244449615479 	 2.8322062492370605 	 58.77269792556763 	 58.80067038536072 	 19.984243631362915 	 19.995452880859375 	 
2025-07-30 21:42:14.416117 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 193],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50989072 	 1000 	 1.1077396869659424 	 1.1167399883270264 	 1.06473708152771 	 1.0742275714874268 	 11.988106966018677 	 13.157153606414795 	 4.06811261177063 	 4.485791444778442 	 
2025-07-30 21:42:43.534743 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 68161552 	 1000 	 1.4771268367767334 	 1.4891078472137451 	 1.434251070022583 	 1.467560052871704 	 16.002275228500366 	 17.619364976882935 	 5.453798770904541 	 6.0062315464019775 	 
2025-07-30 21:43:22.461688 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 192],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 192],"float32"), ) 	 50922240 	 1000 	 2.311840295791626 	 2.2671074867248535 	 1.180013656616211 	 2.2429587841033936 	 58.45273566246033 	 58.47851514816284 	 19.87785506248474 	 19.887962818145752 	 
2025-07-30 21:45:25.176378 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 192],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50921488 	 1000 	 1.1064858436584473 	 1.13228178024292 	 1.06376051902771 	 1.0974524021148682 	 12.023661375045776 	 13.133010864257812 	 4.115996360778809 	 4.477116823196411 	 
2025-07-30 21:45:54.385765 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 68690960 	 1000 	 1.4853119850158691 	 1.4992966651916504 	 1.4425363540649414 	 1.4757428169250488 	 16.10354995727539 	 17.785938262939453 	 5.483912944793701 	 6.061337947845459 	 
2025-07-30 21:46:33.852740 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 191],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 191],"float32"), ) 	 50852604 	 1000 	 2.817424774169922 	 2.979416847229004 	 2.773942470550537 	 2.95908784866333 	 57.73777174949646 	 3.270174264907837 	 19.634785890579224 	 0.8374760150909424 	 
2025-07-30 21:47:42.317164 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 191],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50851856 	 1000 	 1.103149175643921 	 1.110854148864746 	 1.0570952892303467 	 1.0764048099517822 	 11.973917484283447 	 13.129504442214966 	 4.085482597351074 	 4.474881887435913 	 
2025-07-30 21:48:11.379441 test begin: paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([1024, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 69222416 	 1000 	 1.499244213104248 	 1.5068180561065674 	 1.4540681838989258 	 1.4850249290466309 	 16.340972661972046 	 17.921462774276733 	 5.56562352180481 	 6.110432863235474 	 
2025-07-30 21:48:51.045688 test begin: paddle.nn.functional.conv2d(Tensor([752, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([752, 1, 260, 260],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50835216 	 1000 	 1.1003990173339844 	 1.108109712600708 	 1.0576891899108887 	 1.087207555770874 	 12.643004417419434 	 12.742861986160278 	 4.30930757522583 	 4.343415021896362 	 
2025-07-30 21:49:22.274265 test begin: paddle.nn.functional.conv2d(Tensor([758, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([758, 1, 259, 259],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50847414 	 1000 	 1.1677820682525635 	 1.3407433032989502 	 1.1248915195465088 	 1.08907151222229 	 12.608948945999146 	 12.696232080459595 	 4.296645641326904 	 4.327580451965332 	 
2025-07-30 21:49:53.682216 test begin: paddle.nn.functional.conv2d(Tensor([764, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[Prof] paddle.nn.functional.conv2d 	 paddle.nn.functional.conv2d(Tensor([764, 1, 258, 258],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 	 50854912 	 1000 	 1.1043462753295898 	 1.113645315170288 	 1.0617363452911377 	 1.0920183658599854 	 12.509236574172974 	 12.649197101593018 	 4.264342308044434 	 4.311532497406006 	 
2025-07-30 21:50:22.863954 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 32, 320, 320],"float32"), Tensor([32, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 32, 320, 320],"float32"), Tensor([32, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 52428929 	 1000 	 0.6294510364532471 	 0.630800724029541 	 0.21471476554870605 	 0.21439504623413086 	 0.6691045761108398 	 0.6205089092254639 	 0.09759879112243652 	 0.10541796684265137 	 
2025-07-30 21:50:26.433840 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 156, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 156, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51118337 	 1000 	 0.5181534290313721 	 0.5317428112030029 	 0.17682218551635742 	 0.17803215980529785 	 0.5612545013427734 	 0.5404081344604492 	 0.08190488815307617 	 0.0916147232055664 	 
2025-07-30 21:50:31.579853 test begin: paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 320, 156],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([16, 64, 320, 156],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51118337 	 1000 	 0.5218024253845215 	 0.5204238891601562 	 0.17637419700622559 	 0.17740464210510254 	 0.5514843463897705 	 0.5405724048614502 	 0.0804281234741211 	 0.09170889854431152 	 
2025-07-30 21:50:34.568348 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 56, 480, 480],"float32"), Tensor([56, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 56, 480, 480],"float32"), Tensor([56, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51609825 	 1000 	 0.5355203151702881 	 0.5433974266052246 	 0.18226194381713867 	 0.18329262733459473 	 0.6113955974578857 	 0.6096365451812744 	 0.08915925025939941 	 0.1036534309387207 	 
2025-07-30 21:50:39.663864 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 414, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 414, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5144593715667725 	 0.5359740257263184 	 0.17506194114685059 	 0.17638683319091797 	 0.5821127891540527 	 0.5692806243896484 	 0.08451366424560547 	 0.09676098823547363 	 
2025-07-30 21:50:42.790992 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 414],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 414],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.5144195556640625 	 0.5192468166351318 	 0.1754000186920166 	 0.17778372764587402 	 0.5805544853210449 	 0.5707173347473145 	 0.08464407920837402 	 0.09672045707702637 	 
2025-07-30 21:50:45.945297 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 480, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 58982657 	 1000 	 0.5944733619689941 	 0.5964486598968506 	 0.2024853229522705 	 0.20331597328186035 	 0.6644940376281738 	 0.6565430164337158 	 0.09693527221679688 	 0.11161017417907715 	 
2025-07-30 21:50:49.474017 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 28, 480, 480],"float32"), Tensor([28, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 28, 480, 480],"float32"), Tensor([28, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 51609713 	 1000 	 0.7031216621398926 	 0.7039337158203125 	 0.23879718780517578 	 0.23993492126464844 	 0.7001838684082031 	 0.6649930477142334 	 0.10192179679870605 	 0.1131131649017334 	 
2025-07-30 21:50:53.208724 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 207, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 207, 480],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.513852596282959 	 0.5186100006103516 	 0.1751105785369873 	 0.17757511138916016 	 0.563854455947876 	 0.5526695251464844 	 0.08186864852905273 	 0.09385204315185547 	 
2025-07-30 21:50:56.359086 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 320, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 320, 320],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 52429057 	 1000 	 0.5303411483764648 	 0.5343403816223145 	 0.18075823783874512 	 0.1817307472229004 	 0.5683445930480957 	 0.5622715950012207 	 0.08287692070007324 	 0.09534335136413574 	 
2025-07-30 21:50:59.566701 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 480, 207],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[Prof] paddle.nn.functional.conv2d_transpose 	 paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 480, 207],"float32"), Tensor([64, 1, 2, 2],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 	 50872577 	 1000 	 0.515183687210083 	 0.5173990726470947 	 0.17510485649108887 	 0.17635703086853027 	 0.5576972961425781 	 0.5536034107208252 	 0.08132219314575195 	 0.09404230117797852 	 
2025-07-30 21:51:02.628172 test begin: paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 6.520917892456055 	 1.4977142810821533 	 6.423818111419678 	 1.463507890701294 	 44.1768524646759 	 18.302037477493286 	 22.569091320037842 	 9.344266176223755 	 
2025-07-30 21:52:14.815860 test begin: paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([16538, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.049659252166748 	 12.105449676513672 	 11.947513818740845 	 12.058196306228638 	 81.19702339172363 	 22.988962173461914 	 20.78131413459778 	 5.873430490493774 	 
2025-07-30 21:54:25.682604 test begin: paddle.nn.functional.conv3d(Tensor([33076, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([33076, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50805146 	 1000 	 19.01712965965271 	 26.406563997268677 	 9.715450525283813 	 13.48499321937561 	 241.24814343452454 	 47.27754235267639 	 35.22793388366699 	 6.901627779006958 	 
2025-07-30 22:00:03.639840 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 66151, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 66151, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 19.26033067703247 	 19.239901304244995 	 9.838195323944092 	 9.825292110443115 	 263.23015999794006 	 278.42540669441223 	 44.97557234764099 	 47.331711769104004 	 
2025-07-30 22:09:47.619741 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 8, 66151, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 8, 66151, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 15.296662330627441 	 15.479121685028076 	 7.815265417098999 	 7.908705234527588 	 214.37135362625122 	 224.91327023506165 	 36.638163566589355 	 38.23668313026428 	 
2025-07-30 22:17:41.704763 test begin: paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 66151],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 66151],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", ) 	 50804378 	 1000 	 14.971965789794922 	 15.464498281478882 	 7.646405458450317 	 7.900725603103638 	 197.0282163619995 	 222.33486580848694 	 33.67255711555481 	 37.80178165435791 	 
2025-07-30 22:25:14.669526 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.479891538619995 	 1.9732322692871094 	 8.362537860870361 	 1.9419660568237305 	 59.11926078796387 	 22.207674264907837 	 30.218268632888794 	 11.344346523284912 	 
2025-07-30 22:26:48.495054 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 33076, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.230492353439331 	 12.26679015159607 	 12.11163592338562 	 12.212629318237305 	 89.1216938495636 	 87.25167870521545 	 18.27109670639038 	 22.24744701385498 	 
2025-07-30 22:30:12.000299 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.56843900680542 	 1.9684762954711914 	 8.459767580032349 	 1.9457974433898926 	 58.50011682510376 	 12.237583875656128 	 29.895040035247803 	 6.253126859664917 	 
2025-07-30 22:31:39.054953 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 33076, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 12.050082921981812 	 12.098911762237549 	 11.933742046356201 	 12.027048349380493 	 88.47165489196777 	 94.28148150444031 	 18.137829303741455 	 32.01819133758545 	 
2025-07-30 22:35:08.234650 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([12, 1, 3, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", ) 	 50805060 	 1000 	 8.49642300605774 	 2.026996374130249 	 8.399867057800293 	 1.9968888759613037 	 59.81199264526367 	 13.272517681121826 	 30.566916704177856 	 6.784411430358887 	 
2025-07-30 22:36:34.052712 test begin: paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d 	 paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 33076],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805392 	 1000 	 11.945225715637207 	 12.005533695220947 	 11.846967220306396 	 11.952434062957764 	 94.53210139274597 	 100.9475646018982 	 19.398517847061157 	 34.293509006500244 	 
2025-07-30 22:40:15.737692 test begin: paddle.nn.functional.conv3d_transpose(Tensor([2, 2451, 2, 2, 2],"float32"), Tensor([2451, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([2, 2451, 2, 2, 2],"float32"), Tensor([2451, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", ) 	 50863164 	 1000 	 3.125753879547119 	 0.6340913772583008 	 1.064225673675537 	 0.21612882614135742 	 4.524776935577393 	 4.529366970062256 	 0.7704637050628662 	 1.154416561126709 	 
2025-07-30 22:40:29.439255 test begin: paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50805066 	 1000 	 15.704014539718628 	 27.00094509124756 	 8.026150226593018 	 13.790114641189575 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([24807, 6, 8, 6, 8]) and output[0] has a shape of torch.Size([24807, 6, 10, 10, 10]).
2025-07-30 22:43:15.027398 test begin: paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([24807, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", ) 	 50805172 	 1000 	 21.276507139205933 	 20.101987600326538 	 7.140098810195923 	 6.856188535690308 	 135.0494453907013 	 25.627782106399536 	 23.069035530090332 	 5.221774101257324 	 
2025-07-30 22:46:43.547443 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 49613, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 49613, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 5.697596788406372 	 31.42574691772461 	 2.9142138957977295 	 16.054974794387817 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 49613, 6, 8]) and output[0] has a shape of torch.Size([4, 6, 49615, 10, 10]).
2025-07-30 22:49:40.323005 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 49613, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 49613, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 7.413442611694336 	 28.632911443710327 	 3.7901437282562256 	 14.62837553024292 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 8, 49611, 8]) and output[0] has a shape of torch.Size([4, 6, 10, 49615, 10]).
2025-07-30 22:52:40.111750 test begin: paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 49613],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
[Prof] paddle.nn.functional.conv3d_transpose 	 paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 49613],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", ) 	 50804042 	 1000 	 5.622888088226318 	 30.63849973678589 	 2.8745081424713135 	 15.653361320495605 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([4, 6, 8, 6, 49613]) and output[0] has a shape of torch.Size([4, 6, 10, 10, 49615]).
2025-07-30 22:55:18.849059 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), Tensor([10],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), Tensor([10],"int64"), margin=0.5, reduction="mean", name=None, ) 	 101606430 	 1000 	 1.7177355289459229 	 1.6337082386016846 	 0.06800270080566406 	 0.06612515449523926 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:55:27.392200 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([16934401, 3],"float32"), Tensor([16934401, 3],"float32"), Tensor([16934401],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([16934401, 3],"float32"), Tensor([16934401, 3],"float32"), Tensor([16934401],"int64"), margin=0.5, reduction="mean", name=None, ) 	 118540807 	 1000 	 3.9613802433013916 	 3.9410483837127686 	 0.16783618927001953 	 0.17319846153259277 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:55:43.989468 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([25401601, 3],"float32"), Tensor([25401601, 3],"float32"), Tensor([25401601],"int64"), margin=0.5, reduction="mean", name=None, )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([25401601, 3],"float32"), Tensor([25401601, 3],"float32"), Tensor([25401601],"int64"), margin=0.5, reduction="mean", name=None, ) 	 177811207 	 1000 	 5.894116640090942 	 5.8314049243927 	 0.24958300590515137 	 0.2577986717224121 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:56:07.190993 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="mean", ) 	 50803215 	 1000 	 1.8624958992004395 	 1.5823471546173096 	 0.07103109359741211 	 0.06418895721435547 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:56:15.362393 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5],"int32"), margin=0.5, reduction="none", ) 	 50803215 	 1000 	 1.857344627380371 	 1.5752477645874023 	 0.07534241676330566 	 0.06628608703613281 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:56:24.410477 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="mean", ) 	 355622407 	 1000 	 19.426755666732788 	 19.43853235244751 	 0.8225705623626709 	 0.8635621070861816 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:57:41.232311 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([50803201, 3],"float64"), Tensor([50803201, 3],"float64"), Tensor([50803201],"int32"), margin=0.5, reduction="none", ) 	 355622407 	 1000 	 19.150372743606567 	 19.186400413513184 	 0.8858909606933594 	 0.9292595386505127 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:59:00.422755 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="mean", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="mean", ) 	 59270407 	 1000 	 3.339054584503174 	 3.342136859893799 	 0.14110875129699707 	 0.14787864685058594 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:59:13.340285 test begin: paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="none", )
[Prof] paddle.nn.functional.cosine_embedding_loss 	 paddle.nn.functional.cosine_embedding_loss(Tensor([8467201, 3],"float64"), Tensor([8467201, 3],"float64"), Tensor([8467201],"int32"), margin=0.5, reduction="none", ) 	 59270407 	 1000 	 3.2816195487976074 	 3.2891361713409424 	 0.15150785446166992 	 0.15878510475158691 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 22:59:26.652455 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 12, 423361],"float32"), Tensor([10, 1, 423361],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 12, 423361],"float32"), Tensor([10, 1, 423361],"float32"), axis=2, eps=1e-06, ) 	 55036930 	 1000 	 1.0631558895111084 	 1.423933982849121 	 0.08271193504333496 	 0.11209440231323242 	 3.1546740531921387 	 7.067154407501221 	 0.2014310359954834 	 0.2684025764465332 	 
2025-07-30 22:59:40.545841 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, ) 	 50803400 	 1000 	 1.4055755138397217 	 2.100090265274048 	 0.1426389217376709 	 0.17923688888549805 	 7.7007975578308105 	 7.865765571594238 	 0.4373636245727539 	 0.30934643745422363 	 
2025-07-30 23:00:00.671913 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 508033, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([10, 508033, 10],"float32"), Tensor([10, 508033, 10],"float32"), axis=2, eps=1e-06, ) 	 101606600 	 1000 	 2.210418701171875 	 2.566533327102661 	 0.22516441345214844 	 0.22006773948669434 	 5.811353921890259 	 7.814037084579468 	 0.42325806617736816 	 0.33183979988098145 	 
2025-07-30 23:00:20.960171 test begin: paddle.nn.functional.cosine_similarity(Tensor([210, 241921],"float32"), Tensor([210, 241921],"float32"), axis=-1, eps=1e-08, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([210, 241921],"float32"), Tensor([210, 241921],"float32"), axis=-1, eps=1e-08, ) 	 101606820 	 1000 	 1.5901215076446533 	 1.5588345527648926 	 0.12552475929260254 	 0.12265229225158691 	 5.344573497772217 	 7.019038200378418 	 0.39061927795410156 	 0.2757568359375 	 
2025-07-30 23:00:39.547729 test begin: paddle.nn.functional.cosine_similarity(Tensor([32, 1587601],"float32"), Tensor([32, 1587601],"float32"), )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([32, 1587601],"float32"), Tensor([32, 1587601],"float32"), ) 	 101606464 	 1000 	 1.5335850715637207 	 1.631748914718628 	 0.12012743949890137 	 0.1272449493408203 	 5.345476388931274 	 7.065196514129639 	 0.38965630531311035 	 0.27733540534973145 	 
2025-07-30 23:01:00.288009 test begin: paddle.nn.functional.cosine_similarity(Tensor([396901, 128],"float32"), Tensor([396901, 128],"float32"), )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([396901, 128],"float32"), Tensor([396901, 128],"float32"), ) 	 101606656 	 1000 	 2.3397605419158936 	 1.6006453037261963 	 0.23827624320983887 	 0.13581371307373047 	 5.391277551651001 	 7.060840606689453 	 0.3927772045135498 	 0.30010414123535156 	 
2025-07-30 23:01:19.397710 test begin: paddle.nn.functional.cosine_similarity(Tensor([423361, 12, 10],"float32"), Tensor([423361, 1, 10],"float32"), axis=2, eps=1e-06, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([423361, 12, 10],"float32"), Tensor([423361, 1, 10],"float32"), axis=2, eps=1e-06, ) 	 55036930 	 1000 	 1.4691746234893799 	 2.1304619312286377 	 0.15228056907653809 	 0.1811068058013916 	 3.5546715259552 	 7.864951848983765 	 0.22829556465148926 	 0.32082319259643555 	 
2025-07-30 23:01:39.472835 test begin: paddle.nn.functional.cosine_similarity(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), axis=-1, eps=1e-08, )
[Prof] paddle.nn.functional.cosine_similarity 	 paddle.nn.functional.cosine_similarity(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), axis=-1, eps=1e-08, ) 	 101607424 	 1000 	 1.496659278869629 	 1.5342466831207275 	 0.15266871452331543 	 0.15651226043701172 	 5.350711822509766 	 7.02862548828125 	 0.3900148868560791 	 0.2986879348754883 	 
2025-07-30 23:01:58.662540 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 1024, 50304],"float32"), Tensor([1, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 1024, 50304],"float32"), Tensor([1, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 51512320 	 1000 	 0.6512100696563721 	 86.23589611053467 	 0.1329967975616455 	 29.405717849731445 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 1024, 1]) and output[0] has a shape of torch.Size([1, 1024]).
2025-07-30 23:03:27.407805 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2048, 151936],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 2048, 151936],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 311166976 	 1000 	 3.781022310256958 	 270.8292136192322 	 0.7731125354766846 	 92.36584424972534 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 2048, 1]) and output[0] has a shape of torch.Size([1, 2048]).
2025-07-30 23:08:10.480983 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2048, 24807],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 2048, 24807],"float32"), Tensor([1, 2048, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50806784 	 1000 	 0.4740931987762451 	 43.0069694519043 	 0.09705734252929688 	 14.662348747253418 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 2048, 1]) and output[0] has a shape of torch.Size([1, 2048]).
2025-07-30 23:08:55.351487 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 335, 151936],"float32"), Tensor([1, 335, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 335, 151936],"float32"), Tensor([1, 335, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50898895 	 1000 	 0.6801919937133789 	 239.0744481086731 	 0.1391594409942627 	 81.51842403411865 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 335, 1]) and output[0] has a shape of torch.Size([1, 335]).
2025-07-30 23:12:56.682546 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 4096, 100352],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 4096, 100352],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 411045888 	 1000 	 4.961259603500366 	 190.48358702659607 	 1.0184252262115479 	 64.95628428459167 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 4096, 1]) and output[0] has a shape of torch.Size([1, 4096]).
2025-07-30 23:16:25.156017 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 4096, 12404],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 4096, 12404],"float32"), Tensor([1, 4096, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50810880 	 1000 	 0.3932158946990967 	 22.2266206741333 	 0.08029651641845703 	 7.575682640075684 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 4096, 1]) and output[0] has a shape of torch.Size([1, 4096]).
2025-07-30 23:16:49.209296 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 507, 100352],"float32"), Tensor([1, 507, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([1, 507, 100352],"float32"), Tensor([1, 507, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50878971 	 1000 	 0.648291826248169 	 161.2990517616272 	 0.13261961936950684 	 54.99328541755676 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([1, 507, 1]) and output[0] has a shape of torch.Size([1, 507]).
2025-07-30 23:19:32.626676 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 1024, 6202],"float32"), Tensor([8, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([8, 1024, 6202],"float32"), Tensor([8, 1024, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 50814976 	 1000 	 0.43599748611450195 	 11.624772787094116 	 0.08935713768005371 	 3.9627320766448975 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 1024, 1]) and output[0] has a shape of torch.Size([8, 1024]).
2025-07-30 23:19:46.238443 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 127, 50304],"float32"), Tensor([8, 127, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, )
[Prof] paddle.nn.functional.cross_entropy 	 paddle.nn.functional.cross_entropy(Tensor([8, 127, 50304],"float32"), Tensor([8, 127, 1],"int64"), weight=None, ignore_index=-100, reduction="none", soft_label=False, axis=-1, use_softmax=True, label_smoothing=0.0, name=None, ) 	 51109880 	 1000 	 0.6445231437683105 	 72.58790755271912 	 0.1320955753326416 	 24.753880500793457 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 127, 1]) and output[0] has a shape of torch.Size([8, 127]).
2025-07-30 23:21:00.843001 test begin: paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([75760, 13412],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016093120 	 1000 	 0.0010979175567626953 	 0.007088899612426758 	 9.059906005859375e-06 	 3.695487976074219e-05 	 0.03202176094055176 	 4.487216234207153 	 2.4080276489257812e-05 	 2.2950916290283203 	 combined
2025-07-30 23:21:42.043644 test begin: paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([77120, 13176],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016133120 	 1000 	 0.0010385513305664062 	 0.007009983062744141 	 8.106231689453125e-06 	 2.6702880859375e-05 	 0.03207135200500488 	 4.495843887329102 	 3.0517578125e-05 	 2.3008408546447754 	 combined
2025-07-30 23:22:30.517735 test begin: paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([793810, 1280],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016076800 	 1000 	 0.0010139942169189453 	 0.0070264339447021484 	 1.4066696166992188e-05 	 2.3603439331054688e-05 	 0.03360581398010254 	 4.494805812835693 	 5.7220458984375e-05 	 2.298645496368408 	 combined
2025-07-30 23:23:13.868544 test begin: paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", )
[Prof] paddle.nn.functional.dropout 	 paddle.nn.functional.dropout(Tensor([81680, 12440],"bfloat16"), 0.0, training=True, mode="upscale_in_train", ) 	 1016099200 	 1000 	 0.0010180473327636719 	 0.011793375015258789 	 7.867813110351562e-06 	 7.319450378417969e-05 	 0.03209352493286133 	 4.490352392196655 	 2.1457672119140625e-05 	 2.2928545475006104 	 combined
2025-07-30 23:23:55.018536 test begin: paddle.nn.functional.elu(Tensor([1, 21504, 2363],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1, 21504, 2363],"float32"), ) 	 50813952 	 1000 	 0.2969365119934082 	 0.2993745803833008 	 0.2874917984008789 	 0.28240180015563965 	 0.4499790668487549 	 0.44867610931396484 	 0.39536118507385254 	 0.3478279113769531 	 
2025-07-30 23:23:58.316225 test begin: paddle.nn.functional.elu(Tensor([1, 25401601, 2],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1, 25401601, 2],"float32"), ) 	 50803202 	 1000 	 0.29539036750793457 	 0.31424808502197266 	 0.2858924865722656 	 0.28380656242370605 	 0.45088911056518555 	 0.44965553283691406 	 0.39643311500549316 	 0.37827086448669434 	 
2025-07-30 23:24:01.527776 test begin: paddle.nn.functional.elu(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29552531242370605 	 0.2998030185699463 	 0.2859823703765869 	 0.2747480869293213 	 0.449920654296875 	 0.4513545036315918 	 0.39362382888793945 	 0.35355377197265625 	 
2025-07-30 23:24:04.921209 test begin: paddle.nn.functional.elu(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2965817451477051 	 0.3025352954864502 	 0.2871668338775635 	 0.2834610939025879 	 0.4495522975921631 	 0.4498922824859619 	 0.3948814868927002 	 0.3781747817993164 	 
2025-07-30 23:24:08.098039 test begin: paddle.nn.functional.elu(Tensor([1182, 21504, 2],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([1182, 21504, 2],"float32"), ) 	 50835456 	 1000 	 0.2968001365661621 	 0.30263733863830566 	 0.2873518466949463 	 0.28382229804992676 	 0.45157861709594727 	 0.4488492012023926 	 0.39686036109924316 	 0.38028645515441895 	 
2025-07-30 23:24:11.257845 test begin: paddle.nn.functional.elu(Tensor([15, 3386881],"float32"), 1.0, )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([15, 3386881],"float32"), 1.0, ) 	 50803215 	 1000 	 0.2965564727783203 	 0.30309319496154785 	 0.28719139099121094 	 0.28342533111572266 	 0.44959211349487305 	 0.4485142230987549 	 0.39482855796813965 	 0.3762810230255127 	 
2025-07-30 23:24:14.502288 test begin: paddle.nn.functional.elu(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2966344356536865 	 0.3034517765045166 	 0.2871103286743164 	 0.2835533618927002 	 0.45098304748535156 	 0.44852781295776367 	 0.3961207866668701 	 0.3573122024536133 	 
2025-07-30 23:24:17.691957 test begin: paddle.nn.functional.elu(Tensor([2540161, 20],"float32"), 1.0, )
[Prof] paddle.nn.functional.elu 	 paddle.nn.functional.elu(Tensor([2540161, 20],"float32"), 1.0, ) 	 50803220 	 1000 	 0.29535722732543945 	 0.3146517276763916 	 0.2858469486236572 	 0.2822608947753906 	 0.44960641860961914 	 0.44846510887145996 	 0.3947713375091553 	 0.3790707588195801 	 
2025-07-30 23:24:20.946961 test begin: paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([12404, 8192],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 23:24:23.112160 143458 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([1, 4097],"int64"), weight=Tensor([12404, 8192],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101617665 	 1000 	 0.1530897617340088 	 0.3979213237762451 	 0.14137864112854004 	 0.3732790946960449 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 23:24:23.695217 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 23:24:26.565649 143843 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([151936, 669],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101748608 	 1000 	 0.3727076053619385 	 0.9205105304718018 	 0.3609426021575928 	 0.8982689380645752 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 23:24:27.840306 test begin: paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 23:24:39.423461 144359 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 1024],"int64"), weight=Tensor([24807, 4096],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 101712896 	 1000 	 1.7970829010009766 	 5.525477409362793 	 1.7719204425811768 	 5.472336530685425 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 23:24:46.009051 test begin: paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
W0730 23:24:55.711736 146003 backward.cc:462] While running Node (EmbeddingGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([101, 4097],"int64"), weight=Tensor([100352, 1013],"bfloat16"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 	 102070373 	 1000 	 1.8890354633331299 	 5.553446292877197 	 1.875577688217163 	 5.520461797714233 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 23:25:02.189887 test begin: paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([24807, 4096],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([8, 1024],"int64"), weight=Tensor([24807, 4096],"float16"), padding_idx=None, sparse=False, name=None, ) 	 101617664 	 1000 	 0.15174555778503418 	 0.4417440891265869 	 0.140594482421875 	 0.4195375442504883 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 23:25:05.829216 test begin: paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, )
[Prof] paddle.nn.functional.embedding 	 paddle.nn.functional.embedding(Tensor([801, 1024],"int64"), weight=Tensor([50304, 2020],"float16"), padding_idx=None, sparse=False, name=None, ) 	 102434304 	 1000 	 7.201829433441162 	 22.33308982849121 	 7.190419912338257 	 22.275616884231567 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 23:26:18.472502 test begin: paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 4, 8],"int64"), Tensor([100, 4, 8],"int64"), ) 	 6400 	 1000 	 0.010976076126098633 	 215.7601306438446 	 2.1457672119140625e-05 	 0.00028586387634277344 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:29:54.697232 test begin: paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([100, 8, 4],"int64"), Tensor([100, 8, 4],"int64"), ) 	 6400 	 1000 	 0.011104822158813477 	 220.6026360988617 	 1.811981201171875e-05 	 0.0002753734588623047 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:33:36.317338 test begin: paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 28, 8],"int64"), Tensor([20, 28, 8],"int64"), ) 	 8960 	 1000 	 0.011121988296508789 	 295.77729177474976 	 1.430511474609375e-05 	 0.0002865791320800781 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:38:32.427058 test begin: paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 30, 4],"int64"), Tensor([20, 30, 4],"int64"), ) 	 4800 	 1000 	 0.011087894439697266 	 158.62694478034973 	 1.8835067749023438e-05 	 0.0002770423889160156 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:41:11.294010 test begin: paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 4, 57],"int64"), Tensor([20, 4, 57],"int64"), ) 	 9120 	 1000 	 0.011289119720458984 	 311.3605065345764 	 1.239776611328125e-05 	 0.00030493736267089844 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:46:22.986255 test begin: paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 57, 4],"int64"), Tensor([20, 57, 4],"int64"), ) 	 9120 	 1000 	 0.015223026275634766 	 301.88985300064087 	 1.2636184692382812e-05 	 0.00028324127197265625 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:51:25.222893 test begin: paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([20, 8, 15],"int64"), Tensor([20, 8, 15],"int64"), ) 	 4800 	 1000 	 0.011093616485595703 	 162.52715015411377 	 1.6927719116210938e-05 	 0.00029015541076660156 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:54:07.942683 test begin: paddle.nn.functional.gather_tree(Tensor([200, 4, 4],"int64"), Tensor([200, 4, 4],"int64"), )
[Prof] paddle.nn.functional.gather_tree 	 paddle.nn.functional.gather_tree(Tensor([200, 4, 4],"int64"), Tensor([200, 4, 4],"int64"), ) 	 6400 	 1000 	 0.011989831924438477 	 219.2984597682953 	 3.24249267578125e-05 	 0.0002808570861816406 	 None 	 None 	 None 	 None 	 combined
2025-07-30 23:57:47.576423 test begin: paddle.nn.functional.gelu(Tensor([11, 96, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([11, 96, 96, 512],"float32"), False, None, ) 	 51904512 	 1000 	 0.3479471206665039 	 0.30474162101745605 	 0.3383796215057373 	 0.2869431972503662 	 0.45833277702331543 	 0.4607200622558594 	 0.3914635181427002 	 0.3844914436340332 	 
2025-07-30 23:57:51.275451 test begin: paddle.nn.functional.gelu(Tensor([124, 9, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 9, 96, 512],"float32"), False, None, ) 	 54853632 	 1000 	 0.3672504425048828 	 0.32452845573425293 	 0.35817909240722656 	 0.30948305130004883 	 0.48456716537475586 	 0.48653483390808105 	 0.43068385124206543 	 0.40044426918029785 	 
2025-07-30 23:57:54.887338 test begin: paddle.nn.functional.gelu(Tensor([124, 96, 9, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 96, 9, 512],"float32"), False, None, ) 	 54853632 	 1000 	 0.3682520389556885 	 0.3212544918060303 	 0.3593177795410156 	 0.30994439125061035 	 0.4832124710083008 	 0.4867112636566162 	 0.4299027919769287 	 0.4153861999511719 	 
2025-07-30 23:57:58.413721 test begin: paddle.nn.functional.gelu(Tensor([124, 96, 96, 45],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([124, 96, 96, 45],"float32"), False, None, ) 	 51425280 	 1000 	 0.347090482711792 	 0.3065323829650879 	 0.33809566497802734 	 0.29143238067626953 	 0.45476698875427246 	 0.45502495765686035 	 0.40131449699401855 	 0.385601282119751 	 
2025-07-30 23:58:01.680256 test begin: paddle.nn.functional.gelu(Tensor([128, 6, 96, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 6, 96, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.3797743320465088 	 0.3355131149291992 	 0.370708703994751 	 0.32117438316345215 	 0.49829936027526855 	 0.5017986297607422 	 0.4445230960845947 	 0.43265247344970703 	 
2025-07-30 23:58:05.231805 test begin: paddle.nn.functional.gelu(Tensor([128, 9, 96, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 9, 96, 512],"float32"), False, None, ) 	 56623104 	 1000 	 0.3785669803619385 	 0.3316500186920166 	 0.36965227127075195 	 0.32010650634765625 	 0.49976348876953125 	 0.5006251335144043 	 0.445483922958374 	 0.4314453601837158 	 
2025-07-30 23:58:08.859518 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 6, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 6, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.37999939918518066 	 0.33156371116638184 	 0.37104082107543945 	 0.3203465938568115 	 0.49849987030029297 	 0.5016934871673584 	 0.444871187210083 	 0.43150901794433594 	 
2025-07-30 23:58:12.446838 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 9, 512],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 9, 512],"float32"), False, None, ) 	 56623104 	 1000 	 0.3800842761993408 	 0.3363645076751709 	 0.3710329532623291 	 0.32201457023620605 	 0.49869441986083984 	 0.5005893707275391 	 0.4450960159301758 	 0.42901015281677246 	 
2025-07-30 23:58:16.071855 test begin: paddle.nn.functional.gelu(Tensor([128, 96, 96, 44],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([128, 96, 96, 44],"float32"), False, None, ) 	 51904512 	 1000 	 0.3480045795440674 	 0.30877184867858887 	 0.33142971992492676 	 0.2936255931854248 	 0.45667219161987305 	 0.4607055187225342 	 0.3988511562347412 	 0.37166738510131836 	 
2025-07-30 23:58:19.453324 test begin: paddle.nn.functional.gelu(Tensor([8, 96, 96, 768],"float32"), False, None, )
[Prof] paddle.nn.functional.gelu 	 paddle.nn.functional.gelu(Tensor([8, 96, 96, 768],"float32"), False, None, ) 	 56623104 	 1000 	 0.3798818588256836 	 0.33153581619262695 	 0.37082433700561523 	 0.3202633857727051 	 0.498323917388916 	 0.502084493637085 	 0.44431400299072266 	 0.4054069519042969 	 
2025-07-30 23:58:22.978154 test begin: paddle.nn.functional.glu(Tensor([200, 498, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([200, 498, 512],"float32"), -1, None, ) 	 50995200 	 1000 	 0.723278284072876 	 0.24848508834838867 	 0.24664640426635742 	 0.22480082511901855 	 1.1116228103637695 	 0.38007283210754395 	 0.37887072563171387 	 0.30972766876220703 	 
2025-07-30 23:58:26.846710 test begin: paddle.nn.functional.glu(Tensor([209, 477, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([209, 477, 512],"float32"), -1, None, ) 	 51042816 	 1000 	 0.7204887866973877 	 0.2619020938873291 	 0.24528837203979492 	 0.22469544410705566 	 1.1134307384490967 	 0.3805062770843506 	 0.3782486915588379 	 0.300753116607666 	 
2025-07-30 23:58:30.674115 test begin: paddle.nn.functional.glu(Tensor([218, 457, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([218, 457, 512],"float32"), -1, None, ) 	 51008512 	 1000 	 0.7213742733001709 	 0.2483217716217041 	 0.24518179893493652 	 0.22472381591796875 	 1.1138908863067627 	 0.3802981376647949 	 0.3807096481323242 	 0.3036465644836426 	 
2025-07-30 23:58:36.208585 test begin: paddle.nn.functional.glu(Tensor([30, 3308, 512],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([30, 3308, 512],"float32"), -1, None, ) 	 50810880 	 1000 	 0.7174859046936035 	 0.26294732093811035 	 0.24434685707092285 	 0.22400426864624023 	 1.1043360233306885 	 0.378765344619751 	 0.3760213851928711 	 0.27114295959472656 	 
2025-07-30 23:58:41.197732 test begin: paddle.nn.functional.glu(Tensor([30, 457, 3706],"float32"), -1, None, )
[Prof] paddle.nn.functional.glu 	 paddle.nn.functional.glu(Tensor([30, 457, 3706],"float32"), -1, None, ) 	 50809260 	 1000 	 0.7443146705627441 	 0.2686333656311035 	 0.25340771675109863 	 0.2276768684387207 	 1.1731934547424316 	 0.38373684883117676 	 0.3999159336090088 	 0.29403185844421387 	 
2025-07-30 23:58:45.162495 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 254017, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 1, 254017, 2],"float32"), align_corners=False, ) 	 109785800 	 1000 	 0.7062437534332275 	 0.7260501384735107 	 0.6942529678344727 	 0.7066836357116699 	 2.719287395477295 	 2.761199474334717 	 1.3900179862976074 	 1.4142694473266602 	 
2025-07-30 23:58:54.531472 test begin: paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 1, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, ) 	 111667200 	 1000 	 0.7319619655609131 	 0.7526164054870605 	 0.7197518348693848 	 0.7331111431121826 	 2.8126204013824463 	 2.8595197200775146 	 1.4364042282104492 	 1.462439775466919 	 
2025-07-30 23:59:04.113151 test begin: paddle.nn.functional.grid_sample(Tensor([100, 21, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([100, 21, 768, 768],"float32"), Tensor([100, 21, 12544, 2],"float32"), align_corners=False, ) 	 1291315200 	 1000 	 17.111762285232544 	 15.038422346115112 	 17.098915815353394 	 15.011706352233887 	 58.3234601020813 	 58.32003426551819 	 29.799556255340576 	 11.953033924102783 	 
2025-07-31 00:02:09.458533 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.556511402130127 	 0.5493016242980957 	 0.5444917678833008 	 0.5300967693328857 	 3.303813934326172 	 3.0700600147247314 	 1.690871238708496 	 1.5720853805541992 	 
2025-07-31 00:02:25.795748 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 662, 768],"float32"), Tensor([1000, 1, 662, 2],"float32"), align_corners=False, ) 	 509740000 	 1000 	 0.10376667976379395 	 0.09873819351196289 	 0.08353877067565918 	 0.07981657981872559 	 1.8080575466156006 	 1.594273567199707 	 0.9250607490539551 	 0.8137989044189453 	 
2025-07-31 00:02:41.536601 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 662],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 533504000 	 1000 	 0.570838212966919 	 0.5805597305297852 	 0.5501725673675537 	 0.5413525104522705 	 3.375931978225708 	 3.158782720565796 	 1.726485013961792 	 1.6154558658599854 	 
2025-07-31 00:03:00.655622 test begin: paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1000, 1, 768, 768],"float32"), Tensor([1000, 1, 12544, 2],"float32"), align_corners=False, ) 	 614912000 	 1000 	 0.5993959903717041 	 0.5871233940124512 	 0.587385892868042 	 0.567866325378418 	 3.6394810676574707 	 3.3600316047668457 	 1.856269121170044 	 1.1421337127685547 	 
2025-07-31 00:03:19.655423 test begin: paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([1720, 1, 544, 544],"float32"), Tensor([1720, 1, 12544, 2],"float32"), align_corners=False, ) 	 552161280 	 1000 	 0.7204372882843018 	 1.4034910202026367 	 0.70047926902771 	 0.7191221714019775 	 4.034105062484741 	 3.8527355194091797 	 2.0593788623809814 	 1.9649689197540283 	 
2025-07-31 00:03:42.882716 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 127009, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 1, 127009, 2],"float32"), align_corners=False, ) 	 109990800 	 1000 	 0.6678850650787354 	 0.6952705383300781 	 0.6558876037597656 	 0.6758131980895996 	 2.656733989715576 	 2.692471981048584 	 1.3568203449249268 	 1.375032901763916 	 
2025-07-31 00:03:52.057686 test begin: paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 1, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, ) 	 114380800 	 1000 	 0.7234535217285156 	 0.7447426319122314 	 0.7033669948577881 	 0.7183017730712891 	 2.868365526199341 	 2.9092109203338623 	 1.4636070728302002 	 1.4855504035949707 	 
2025-07-31 00:04:01.731005 test begin: paddle.nn.functional.grid_sample(Tensor([200, 11, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([200, 11, 544, 544],"float32"), Tensor([200, 11, 12544, 2],"float32"), align_corners=False, ) 	 706252800 	 1000 	 8.735492467880249 	 8.055782794952393 	 8.723240852355957 	 8.0272216796875 	 28.824886798858643 	 28.6736478805542 	 14.733454465866089 	 9.777498245239258 	 
2025-07-31 00:05:33.219645 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7881839275360107 	 0.8158426284790039 	 0.7762420177459717 	 0.7968597412109375 	 4.305431127548218 	 4.130633592605591 	 2.1997389793395996 	 2.10701322555542 	 
2025-07-31 00:05:53.294894 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 467, 544],"float32"), Tensor([2000, 1, 467, 2],"float32"), align_corners=False, ) 	 509964000 	 1000 	 0.13503003120422363 	 0.12972593307495117 	 0.12249374389648438 	 0.1109476089477539 	 1.9033253192901611 	 1.6834807395935059 	 0.972926139831543 	 0.8585944175720215 	 
2025-07-31 00:06:05.663139 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 467],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 558272000 	 1000 	 0.7894957065582275 	 0.8292715549468994 	 0.7695252895355225 	 0.7885942459106445 	 4.352205991744995 	 4.18051290512085 	 2.223646879196167 	 2.137474298477173 	 
2025-07-31 00:06:26.789928 test begin: paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2000, 1, 544, 544],"float32"), Tensor([2000, 1, 12544, 2],"float32"), align_corners=False, ) 	 642048000 	 1000 	 0.834747314453125 	 0.8585433959960938 	 0.8227660655975342 	 0.83951735496521 	 4.6900315284729 	 4.473495721817017 	 2.3916661739349365 	 1.5240347385406494 	 
2025-07-31 00:06:52.577326 test begin: paddle.nn.functional.grid_sample(Tensor([2026, 1, 544, 544],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2026, 1, 544, 544],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, ) 	 650394624 	 1000 	 0.8466002941131592 	 0.8765883445739746 	 0.8264675140380859 	 0.8534576892852783 	 4.759310007095337 	 4.521837949752808 	 2.4311680793762207 	 1.5431594848632812 	 
2025-07-31 00:07:15.659355 test begin: paddle.nn.functional.grid_sample(Tensor([2026, 1, 768, 768],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([2026, 1, 768, 768],"float32"), Tensor([2026, 1, 12544, 2],"float32"), align_corners=False, ) 	 1245811712 	 1000 	 1.2161343097686768 	 1.1869184970855713 	 1.203040361404419 	 1.1626496315002441 	 7.3891706466674805 	 6.78245735168457 	 3.7746760845184326 	 1.3873927593231201 	 
2025-07-31 00:07:57.418650 test begin: paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(Tensor([870, 1, 768, 768],"float32"), Tensor([870, 1, 12544, 2],"float32"), align_corners=False, ) 	 534973440 	 1000 	 0.5233471393585205 	 0.5179846286773682 	 0.5112788677215576 	 0.49455809593200684 	 3.1641767024993896 	 2.9176182746887207 	 1.615356206893921 	 1.492222547531128 	 
2025-07-31 00:08:15.747971 test begin: paddle.nn.functional.grid_sample(x=Tensor([1, 64, 80, 94, 311],"float32"), grid=Tensor([1, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([1, 64, 80, 94, 311],"float32"), grid=Tensor([1, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 157574080 	 1000 	 14.65699315071106 	 11.5623619556427 	 14.644552230834961 	 11.541743040084839 	 99.8413770198822 	 97.21215534210205 	 51.11260199546814 	 49.68157911300659 	 
2025-07-31 00:12:04.923831 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 87713280 	 1000 	 5.364659070968628 	 3.6663711071014404 	 5.352246522903442 	 3.6353659629821777 	 11.201850891113281 	 12.070874691009521 	 5.723944664001465 	 6.163339376449585 	 
2025-07-31 00:12:41.278179 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 6, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 6, 80, 94, 311],"float32"), grid=Tensor([4, 6, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 56806080 	 1000 	 0.13975954055786133 	 0.09829139709472656 	 0.12728595733642578 	 0.07910561561584473 	 0.4500749111175537 	 0.45919156074523926 	 0.22984528541564941 	 0.2346034049987793 	 
2025-07-31 00:12:43.416118 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 83971328 	 1000 	 35.22768306732178 	 34.231863260269165 	 35.20956897735596 	 34.20792269706726 	 110.29383373260498 	 119.55246686935425 	 56.36224937438965 	 61.095645904541016 	 
2025-07-31 00:17:56.031359 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 7, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 7, 94, 311],"float32"), grid=Tensor([4, 280, 7, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 52975328 	 1000 	 0.8012611865997314 	 0.7143609523773193 	 0.7888834476470947 	 0.694974422454834 	 2.4554965496063232 	 2.666520595550537 	 1.2559726238250732 	 1.3632874488830566 	 
2025-07-31 00:18:03.902965 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 82538240 	 1000 	 36.48311805725098 	 34.000062227249146 	 36.46220850944519 	 33.977317571640015 	 109.53706741333008 	 119.4089252948761 	 55.96940302848816 	 61.018938064575195 	 
2025-07-31 00:23:17.167823 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 8, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 8, 311],"float32"), grid=Tensor([4, 280, 376, 8, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 61061120 	 1000 	 12.412543773651123 	 10.87169885635376 	 12.400044679641724 	 10.84424090385437 	 35.45690155029297 	 37.92749047279358 	 18.117043495178223 	 19.38261389732361 	 
2025-07-31 00:24:58.916494 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 27],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[Prof] paddle.nn.functional.grid_sample 	 paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 27],"float32"), grid=Tensor([4, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 	 83562240 	 1000 	 39.08902955055237 	 35.242674112319946 	 38.22823762893677 	 35.21805167198181 	 114.47244453430176 	 126.01929116249084 	 58.489760875701904 	 64.39461851119995 	 
2025-07-31 00:30:28.206210 test begin: paddle.nn.functional.label_smooth(label=Tensor([48, 32, 33712],"float32"), epsilon=0.1, )
[Prof] paddle.nn.functional.label_smooth 	 paddle.nn.functional.label_smooth(label=Tensor([48, 32, 33712],"float32"), epsilon=0.1, ) 	 51781632 	 1000 	 0.3013627529144287 	 0.6160409450531006 	 0.29128217697143555 	 0.20973801612854004 	 0.3011908531188965 	 0.3044605255126953 	 0.24919915199279785 	 0.2232346534729004 	 combined
2025-07-31 00:30:31.478333 test begin: paddle.nn.functional.label_smooth(label=Tensor([76, 20, 33712],"float32"), epsilon=0.1, )
[Prof] paddle.nn.functional.label_smooth 	 paddle.nn.functional.label_smooth(label=Tensor([76, 20, 33712],"float32"), epsilon=0.1, ) 	 51242240 	 1000 	 0.2981297969818115 	 0.6121728420257568 	 0.2882823944091797 	 0.20766830444335938 	 0.29930782318115234 	 0.3002173900604248 	 0.2478961944580078 	 0.22284793853759766 	 combined
2025-07-31 00:30:34.667346 test begin: paddle.nn.functional.layer_norm(Tensor([115, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([115, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 51227648 	 1000 	 0.302173376083374 	 0.33893251419067383 	 0.2865126132965088 	 0.2951374053955078 	 0.47186279296875 	 1.0162403583526611 	 0.24110746383666992 	 0.5192506313323975 	 
2025-07-31 00:30:39.314319 test begin: paddle.nn.functional.layer_norm(Tensor([174, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([174, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50960384 	 1000 	 0.30065488815307617 	 0.3146066665649414 	 0.2850687503814697 	 0.29079627990722656 	 0.4709913730621338 	 1.0108392238616943 	 0.2400059700012207 	 0.5164613723754883 	 
2025-07-31 00:30:43.098241 test begin: paddle.nn.functional.layer_norm(Tensor([226, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([226, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50915328 	 1000 	 0.3004579544067383 	 0.32513976097106934 	 0.279677152633667 	 0.2919881343841553 	 0.4691915512084961 	 1.0139267444610596 	 0.23969030380249023 	 0.517418622970581 	 
2025-07-31 00:30:46.904480 test begin: paddle.nn.functional.layer_norm(Tensor([7, 7088, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
[Prof] paddle.nn.functional.layer_norm 	 paddle.nn.functional.layer_norm(Tensor([7, 7088, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, ) 	 50808832 	 1000 	 0.29964566230773926 	 0.3149588108062744 	 0.28402209281921387 	 0.29146432876586914 	 0.46739745140075684 	 1.0106019973754883 	 0.23871803283691406 	 0.5176434516906738 	 
2025-07-31 00:30:50.668225 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 26, 304, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 26, 304, 544],"float32"), 0.1, ) 	 51597312 	 1000 	 0.30174875259399414 	 0.3039982318878174 	 0.2910134792327881 	 0.28695225715637207 	 0.4568922519683838 	 0.4535353183746338 	 0.3989834785461426 	 0.3783290386199951 	 
2025-07-31 00:30:53.989276 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 32, 122, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 32, 122, 1088],"float32"), 0.1, ) 	 50970624 	 1000 	 0.2980985641479492 	 0.3133721351623535 	 0.28882694244384766 	 0.2744719982147217 	 0.45283985137939453 	 0.44828224182128906 	 0.3731410503387451 	 0.3705415725708008 	 
2025-07-31 00:30:57.185249 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 32, 608, 218],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 32, 608, 218],"float32"), 0.1, ) 	 50896896 	 1000 	 0.2974851131439209 	 0.3004031181335449 	 0.2835683822631836 	 0.2825639247894287 	 0.4508049488067627 	 0.4487943649291992 	 0.39728546142578125 	 0.36124634742736816 	 
2025-07-31 00:31:00.400871 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 64, 122, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 64, 122, 544],"float32"), 0.1, ) 	 50970624 	 1000 	 0.29674530029296875 	 0.3159353733062744 	 0.28742313385009766 	 0.28288936614990234 	 0.45137667655944824 	 0.44960880279541016 	 0.3973548412322998 	 0.376528263092041 	 
2025-07-31 00:31:03.576524 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 64, 304, 218],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 64, 304, 218],"float32"), 0.1, ) 	 50896896 	 1000 	 0.2975175380706787 	 0.7466614246368408 	 0.2882273197174072 	 0.281322717666626 	 0.4506542682647705 	 0.4487721920013428 	 0.39693355560302734 	 0.37559056282043457 	 
2025-07-31 00:31:09.878251 test begin: paddle.nn.functional.leaky_relu(Tensor([12, 7, 608, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([12, 7, 608, 1088],"float32"), 0.1, ) 	 55566336 	 1000 	 0.3243288993835449 	 0.329456090927124 	 0.3148665428161621 	 0.3074667453765869 	 0.4915657043457031 	 0.4881429672241211 	 0.43775177001953125 	 0.40057849884033203 	 
2025-07-31 00:31:13.352297 test begin: paddle.nn.functional.leaky_relu(Tensor([13, 64, 256, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([13, 64, 256, 256],"float32"), 0.1, None, ) 	 54525952 	 1000 	 0.31722545623779297 	 0.32416629791259766 	 0.3047444820404053 	 0.29991793632507324 	 0.4835929870605469 	 0.4803347587585449 	 0.4300503730773926 	 0.39923977851867676 	 
2025-07-31 00:31:16.830538 test begin: paddle.nn.functional.leaky_relu(Tensor([3, 32, 608, 1088],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([3, 32, 608, 1088],"float32"), 0.1, ) 	 63504384 	 1000 	 0.3686032295227051 	 0.38446712493896484 	 0.35929203033447266 	 0.35576415061950684 	 0.562624454498291 	 0.5572702884674072 	 0.5089831352233887 	 0.48102664947509766 	 
2025-07-31 00:31:20.919661 test begin: paddle.nn.functional.leaky_relu(Tensor([5, 64, 304, 544],"float32"), 0.1, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([5, 64, 304, 544],"float32"), 0.1, ) 	 52920320 	 1000 	 0.3094661235809326 	 0.31015539169311523 	 0.29976797103881836 	 0.29315686225891113 	 0.46839141845703125 	 0.46642374992370605 	 0.41394591331481934 	 0.37244200706481934 	 
2025-07-31 00:31:24.373349 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 13, 256, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 13, 256, 256],"float32"), 0.1, None, ) 	 54525952 	 1000 	 0.31714725494384766 	 1.0045130252838135 	 0.307910680770874 	 0.29466915130615234 	 0.4837226867675781 	 0.47909021377563477 	 0.42668890953063965 	 0.4009668827056885 	 
2025-07-31 00:31:31.125634 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 64, 256, 49],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 64, 256, 49],"float32"), 0.1, None, ) 	 51380224 	 1000 	 0.3014030456542969 	 0.3011972904205322 	 0.29184460639953613 	 0.28403615951538086 	 0.45478391647338867 	 0.4516942501068115 	 0.4004404544830322 	 0.3508586883544922 	 
2025-07-31 00:31:34.294794 test begin: paddle.nn.functional.leaky_relu(Tensor([64, 64, 49, 256],"float32"), 0.1, None, )
[Prof] paddle.nn.functional.leaky_relu 	 paddle.nn.functional.leaky_relu(Tensor([64, 64, 49, 256],"float32"), 0.1, None, ) 	 51380224 	 1000 	 0.299030065536499 	 1.1877119541168213 	 0.2897298336029053 	 0.27958250045776367 	 0.4547874927520752 	 0.4517204761505127 	 0.400834321975708 	 0.36949658393859863 	 
2025-07-31 00:31:40.140695 test begin: paddle.nn.functional.linear(x=Tensor([1, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
Warning: The core code of paddle.nn.functional.linear is too complex.
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([1, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 50823284 	 1000 	 0.15843868255615234 	 0.15684223175048828 	 0.053902387619018555 	 0.1337745189666748 	 0.3153996467590332 	 0.317899227142334 	 0.08035397529602051 	 0.1081092357635498 	 
2025-07-31 00:31:41.943619 test begin: paddle.nn.functional.linear(x=Tensor([1, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([1, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, ) 	 50855402 	 1000 	 0.16791653633117676 	 0.15544557571411133 	 0.05707073211669922 	 0.1301276683807373 	 0.31984472274780273 	 0.3216395378112793 	 0.08179783821105957 	 0.10945010185241699 	 
2025-07-31 00:31:43.752309 test begin: paddle.nn.functional.linear(x=Tensor([2, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2, 12404],"float32"), weight=Tensor([12404, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 50835688 	 1000 	 0.21575713157653809 	 0.24650835990905762 	 0.07312297821044922 	 0.06262731552124023 	 0.43481874465942383 	 0.4250476360321045 	 0.07382059097290039 	 0.08650779724121094 	 
2025-07-31 00:31:45.984060 test begin: paddle.nn.functional.linear(x=Tensor([2, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2, 25088],"float32"), weight=Tensor([25088, 2026],"float32"), bias=Tensor([2026],"float32"), name=None, ) 	 50880490 	 1000 	 0.2293686866760254 	 0.31336283683776855 	 0.07792139053344727 	 0.0802147388458252 	 0.3332479000091553 	 0.33458518981933594 	 0.08521723747253418 	 0.11381030082702637 	 
2025-07-31 00:31:48.020455 test begin: paddle.nn.functional.linear(x=Tensor([2026, 25088],"float32"), weight=Tensor([25088, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([2026, 25088],"float32"), weight=Tensor([25088, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, ) 	 153592832 	 1000 	 23.888795375823975 	 24.835625410079956 	 12.208996295928955 	 24.804370880126953 	 48.06023144721985 	 47.961507081985474 	 9.852618932723999 	 12.232061386108398 	 
2025-07-31 00:34:15.818885 test begin: paddle.nn.functional.linear(x=Tensor([4051, 12544],"float32"), weight=Tensor([12544, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4051, 12544],"float32"), weight=Tensor([12544, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 63661824 	 1000 	 6.281014680862427 	 6.260495901107788 	 3.21022367477417 	 6.234073162078857 	 12.185260534286499 	 12.132035732269287 	 2.4984090328216553 	 3.0978140830993652 	 
2025-07-31 00:34:55.375931 test begin: paddle.nn.functional.linear(x=Tensor([4096, 12404],"float32"), weight=Tensor([12404, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 12404],"float32"), weight=Tensor([12404, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 63509504 	 1000 	 6.214357852935791 	 6.201040983200073 	 3.17289662361145 	 6.176248073577881 	 12.087700605392456 	 12.056005716323853 	 2.475904703140259 	 3.073641061782837 	 
2025-07-31 00:35:33.167224 test begin: paddle.nn.functional.linear(x=Tensor([4096, 12544],"float32"), weight=Tensor([12544, 4051],"float32"), bias=Tensor([4051],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 12544],"float32"), weight=Tensor([12544, 4051],"float32"), bias=Tensor([4051],"float32"), name=None, ) 	 102200019 	 1000 	 24.094093084335327 	 23.96589183807373 	 12.309491634368896 	 23.9434974193573 	 48.029191732406616 	 47.89659881591797 	 9.850350856781006 	 12.21133303642273 	 
2025-07-31 00:37:59.341820 test begin: paddle.nn.functional.linear(x=Tensor([4096, 49613],"float32"), weight=Tensor([49613, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, )
[Prof] paddle.nn.functional.linear 	 paddle.nn.functional.linear(x=Tensor([4096, 49613],"float32"), weight=Tensor([49613, 1024],"float32"), bias=Tensor([1024],"float32"), name=None, ) 	 254019584 	 1000 	 24.776610374450684 	 24.768884420394897 	 12.66164255142212 	 24.73680019378662 	 47.9142062664032 	 47.83477854728699 	 9.818359613418579 	 12.200400114059448 	 
2025-07-31 00:40:30.058481 test begin: paddle.nn.functional.local_response_norm(Tensor([10585, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([10585, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50808000 	 1000 	 4.262424468994141 	 5.115362882614136 	 0.7237637042999268 	 0.6542942523956299 	 8.925960063934326 	 8.666666984558105 	 1.012413740158081 	 0.5211870670318604 	 
2025-07-31 00:40:58.854208 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 10585, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 10585, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50808000 	 1000 	 3.4414377212524414 	 4.782726526260376 	 0.5860700607299805 	 0.609976053237915 	 7.220932960510254 	 7.581851243972778 	 0.817671537399292 	 0.4862344264984131 	 
2025-07-31 00:41:24.148928 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 3, 141121, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 3, 141121, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50803560 	 1000 	 4.340670824050903 	 5.331603765487671 	 0.740619421005249 	 0.7304730415344238 	 9.065197944641113 	 8.87796401977539 	 1.08815598487854 	 0.567434549331665 	 
2025-07-31 00:41:53.589233 test begin: paddle.nn.functional.local_response_norm(Tensor([3, 3, 40, 141121],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(Tensor([3, 3, 40, 141121],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, ) 	 50803560 	 1000 	 4.338906526565552 	 4.3325910568237305 	 0.7375013828277588 	 0.5516417026519775 	 8.967993259429932 	 7.938129663467407 	 1.0147254467010498 	 0.5061197280883789 	 
2025-07-31 00:42:21.095158 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 40, 47041],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 40, 47041],"float32"), size=5, data_format="NCDHW", ) 	 50804280 	 1000 	 4.327219724655151 	 4.696839809417725 	 0.7358345985412598 	 0.6014664173126221 	 9.153183937072754 	 8.593727827072144 	 1.2494711875915527 	 0.5495879650115967 	 
2025-07-31 00:42:50.448711 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 47041, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3, 47041, 40],"float32"), size=5, data_format="NCDHW", ) 	 50804280 	 1000 	 4.3366076946258545 	 4.692201852798462 	 0.7386841773986816 	 0.5982155799865723 	 8.911348819732666 	 8.596415519714355 	 1.0098812580108643 	 0.5481209754943848 	 
2025-07-31 00:43:18.794781 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3529, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 3529, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 4.3289525508880615 	 4.261554479598999 	 0.7375020980834961 	 0.5437054634094238 	 8.980456113815308 	 7.857520341873169 	 1.0198829174041748 	 0.503300666809082 	 
2025-07-31 00:43:46.900769 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 40, 3529],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 40, 3529],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.125338554382324 	 4.825890779495239 	 1.2124300003051758 	 0.617546558380127 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 40, 40, 3529]) and output[0] has a shape of torch.Size([3, 3529, 3, 40, 40]).
2025-07-31 00:44:14.510203 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 47041, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 40, 47041, 3],"float32"), size=5, data_format="NDHWC", ) 	 50804280 	 1000 	 7.923595905303955 	 4.9971702098846436 	 1.3506455421447754 	 0.6380634307861328 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 40, 47041, 3]) and output[0] has a shape of torch.Size([3, 3, 3, 40, 47041]).
2025-07-31 00:44:54.746993 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 47041, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3, 47041, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50804280 	 1000 	 7.928773403167725 	 5.01105809211731 	 1.3492600917816162 	 0.6387112140655518 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3, 47041, 40, 3]) and output[0] has a shape of torch.Size([3, 3, 3, 47041, 40]).
2025-07-31 00:45:35.396015 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 3, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 3.428626298904419 	 4.261019468307495 	 0.5834720134735107 	 0.5416820049285889 	 7.1837990283966064 	 7.359237909317017 	 0.8154911994934082 	 0.4700889587402344 	 
2025-07-31 00:45:59.447208 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3, 3529, 40, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.92444634437561 	 4.5689849853515625 	 1.3494009971618652 	 0.5821273326873779 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3, 3529, 40, 40, 3]) and output[0] has a shape of torch.Size([3, 3, 3529, 40, 40]).
2025-07-31 00:46:39.780624 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", ) 	 50817600 	 1000 	 4.25360894203186 	 4.552486419677734 	 0.7225866317749023 	 0.5809710025787354 	 8.807130813598633 	 8.575258255004883 	 1.002317190170288 	 0.5479958057403564 	 
2025-07-31 00:47:07.882471 test begin: paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
[Prof] paddle.nn.functional.local_response_norm 	 paddle.nn.functional.local_response_norm(x=Tensor([3529, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", ) 	 50817600 	 1000 	 7.927294731140137 	 4.555444002151489 	 1.3472704887390137 	 0.5813033580780029 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([3529, 3, 40, 40, 3]) and output[0] has a shape of torch.Size([3529, 3, 3, 40, 40]).
2025-07-31 00:47:47.790946 test begin: paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), )
[Prof] paddle.nn.functional.log_loss 	 paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), ) 	 101606402 	 1000 	 0.4954349994659424 	 3.4213974475860596 	 0.48575448989868164 	 0.3496968746185303 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-31 00:47:56.062023 test begin: paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), epsilon=1e-07, )
[Prof] paddle.nn.functional.log_loss 	 paddle.nn.functional.log_loss(Tensor([50803201, 1],"float32"), Tensor([50803201, 1],"float32"), epsilon=1e-07, ) 	 101606402 	 1000 	 0.4954650402069092 	 3.4257805347442627 	 0.4852931499481201 	 0.34984612464904785 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-31 00:48:03.182431 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 10, 254017],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 10, 254017],"float64"), None, ) 	 25401700 	 1000 	 0.4404623508453369 	 0.45567870140075684 	 0.43131446838378906 	 0.4419064521789551 	 0.45256829261779785 	 0.4508078098297119 	 0.39886474609375 	 0.3816516399383545 	 
2025-07-31 00:48:06.057759 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 10, 508033],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 10, 508033],"float32"), None, ) 	 50803300 	 1000 	 0.3006281852722168 	 0.2983717918395996 	 0.29137539863586426 	 0.28470540046691895 	 0.4514436721801758 	 0.45152831077575684 	 0.3977382183074951 	 0.381105899810791 	 
2025-07-31 00:48:09.826789 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 254017, 10],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 254017, 10],"float64"), None, ) 	 25401700 	 1000 	 0.4413602352142334 	 0.4564032554626465 	 0.432178258895874 	 0.4427011013031006 	 0.45145606994628906 	 0.4521613121032715 	 0.39756155014038086 	 0.3724219799041748 	 
2025-07-31 00:48:12.753815 test begin: paddle.nn.functional.log_sigmoid(Tensor([10, 508033, 10],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([10, 508033, 10],"float32"), None, ) 	 50803300 	 1000 	 0.300631046295166 	 0.2984335422515869 	 0.29148197174072266 	 0.28477048873901367 	 0.45131850242614746 	 0.45030927658081055 	 0.39783263206481934 	 0.37833070755004883 	 
2025-07-31 00:48:16.125395 test begin: paddle.nn.functional.log_sigmoid(Tensor([254017, 10, 10],"float64"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([254017, 10, 10],"float64"), None, ) 	 25401700 	 1000 	 0.44101428985595703 	 0.4556748867034912 	 0.4250054359436035 	 0.4419064521789551 	 0.4512617588043213 	 0.45218849182128906 	 0.34918665885925293 	 0.38199782371520996 	 
2025-07-31 00:48:18.986523 test begin: paddle.nn.functional.log_sigmoid(Tensor([508033, 10, 10],"float32"), None, )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(Tensor([508033, 10, 10],"float32"), None, ) 	 50803300 	 1000 	 0.30065441131591797 	 0.2984638214111328 	 0.284395694732666 	 0.2781801223754883 	 0.45003604888916016 	 0.4516794681549072 	 0.3870241641998291 	 0.36394214630126953 	 
2025-07-31 00:48:22.227255 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([10, 10, 508033],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([10, 10, 508033],"float32"), ) 	 50803300 	 1000 	 0.30069589614868164 	 0.29846763610839844 	 0.2841224670410156 	 0.27664661407470703 	 0.45027780532836914 	 0.451662540435791 	 0.38768649101257324 	 0.38239026069641113 	 
2025-07-31 00:48:25.543675 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([10, 508033, 10],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([10, 508033, 10],"float32"), ) 	 50803300 	 1000 	 0.3017759323120117 	 0.3013012409210205 	 0.29225897789001465 	 0.285811185836792 	 0.45020270347595215 	 0.4526245594024658 	 0.3964228630065918 	 0.3829076290130615 	 
2025-07-31 00:48:28.828447 test begin: paddle.nn.functional.log_sigmoid(x=Tensor([508033, 10, 10],"float32"), )
[Prof] paddle.nn.functional.log_sigmoid 	 paddle.nn.functional.log_sigmoid(x=Tensor([508033, 10, 10],"float32"), ) 	 50803300 	 1000 	 0.3019275665283203 	 0.30321431159973145 	 0.29247570037841797 	 0.28281211853027344 	 0.4502854347229004 	 0.45148205757141113 	 0.39603209495544434 	 0.36766958236694336 	 
2025-07-31 00:48:31.977974 test begin: paddle.nn.functional.log_softmax(Tensor([128, 396901],"float32"), axis=-1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([128, 396901],"float32"), axis=-1, ) 	 50803328 	 1000 	 0.7134246826171875 	 1.300126075744629 	 0.7044386863708496 	 0.6114120483398438 	 1.3977527618408203 	 0.6517698764801025 	 1.3398711681365967 	 0.5840156078338623 	 
2025-07-31 00:48:39.463737 test begin: paddle.nn.functional.log_softmax(Tensor([264, 192612],"float32"), axis=-1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([264, 192612],"float32"), axis=-1, ) 	 50849568 	 1000 	 0.6224710941314697 	 0.6487545967102051 	 0.6134421825408936 	 0.6291987895965576 	 0.8684239387512207 	 0.6642816066741943 	 0.811504602432251 	 0.594465970993042 	 
2025-07-31 00:48:43.992307 test begin: paddle.nn.functional.log_softmax(Tensor([2944, 17257],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([2944, 17257],"float32"), axis=1, ) 	 50804608 	 1000 	 0.3304405212402344 	 0.3377366065979004 	 0.3202018737792969 	 0.32280611991882324 	 0.646615743637085 	 0.5220980644226074 	 0.5892739295959473 	 0.44922590255737305 	 
2025-07-31 00:48:47.569136 test begin: paddle.nn.functional.log_softmax(Tensor([4224, 12028],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([4224, 12028],"float32"), axis=1, ) 	 50806272 	 1000 	 0.3054161071777344 	 0.31891965866088867 	 0.29499125480651855 	 0.2940337657928467 	 0.6317684650421143 	 0.4557182788848877 	 0.5752096176147461 	 0.3879079818725586 	 
2025-07-31 00:48:51.208948 test begin: paddle.nn.functional.log_softmax(Tensor([7664, 6629],"float32"), axis=1, )
[Prof] paddle.nn.functional.log_softmax 	 paddle.nn.functional.log_softmax(Tensor([7664, 6629],"float32"), axis=1, ) 	 50804656 	 1000 	 0.3031008243560791 	 0.3047342300415039 	 0.2928130626678467 	 0.2848355770111084 	 0.5972797870635986 	 0.5165860652923584 	 0.5397233963012695 	 0.4352073669433594 	 
2025-07-31 00:48:54.617458 test begin: paddle.nn.functional.lp_pool1d(Tensor([2, 3, 8467201],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([2, 3, 8467201],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803206 	 1000 	 0.9356865882873535 	 1.9184021949768066 	 0.9063358306884766 	 0.24433088302612305 	 1.425595998764038 	 4.961360454559326 	 0.7284681797027588 	 0.31920719146728516 	 
2025-07-31 00:49:05.494818 test begin: paddle.nn.functional.lp_pool1d(Tensor([2, 793801, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([2, 793801, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803264 	 1000 	 0.9337937831878662 	 1.9501543045043945 	 0.9044198989868164 	 0.2476503849029541 	 1.4285461902618408 	 5.157222509384155 	 0.7292215824127197 	 0.3303568363189697 	 
2025-07-31 00:49:16.235588 test begin: paddle.nn.functional.lp_pool1d(Tensor([529201, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
[Prof] paddle.nn.functional.lp_pool1d 	 paddle.nn.functional.lp_pool1d(Tensor([529201, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, ) 	 50803296 	 1000 	 0.9326882362365723 	 1.9484937191009521 	 0.9027512073516846 	 0.24762320518493652 	 1.429502010345459 	 5.156560659408569 	 0.730431318283081 	 0.3291449546813965 	 
2025-07-31 00:49:26.950420 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50804736 	 1000 	 2.1094889640808105 	 3.507007122039795 	 2.092890501022339 	 0.446270227432251 	 2.2568633556365967 	 6.826225996017456 	 1.1529359817504883 	 0.46419501304626465 	 
2025-07-31 00:49:44.172225 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50804736 	 1000 	 0.5566360950469971 	 1.2167291641235352 	 0.5403003692626953 	 0.15376782417297363 	 0.999539852142334 	 3.6632509231567383 	 0.5117881298065186 	 0.2495412826538086 	 
2025-07-31 00:49:51.711669 test begin: paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([16538, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, ) 	 50804736 	 1000 	 0.9403457641601562 	 0.7906677722930908 	 0.9224948883056641 	 0.10038328170776367 	 1.9249446392059326 	 3.301558017730713 	 0.9848220348358154 	 0.2245042324066162 	 
2025-07-31 00:49:59.823427 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50804736 	 1000 	 2.1074087619781494 	 3.531693458557129 	 2.0906615257263184 	 0.44622278213500977 	 2.2568373680114746 	 6.827661752700806 	 1.1517484188079834 	 0.465130090713501 	 
2025-07-31 00:50:16.471732 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50804736 	 1000 	 0.5558779239654541 	 1.2108073234558105 	 0.5397298336029053 	 0.1560840606689453 	 0.9964933395385742 	 3.6586291790008545 	 0.5091598033905029 	 0.24924421310424805 	 
2025-07-31 00:50:24.222415 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 24807, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, ) 	 50804736 	 1000 	 0.9419968128204346 	 0.7940471172332764 	 0.9254555702209473 	 0.10039401054382324 	 1.9237139225006104 	 3.3053171634674072 	 0.9822664260864258 	 0.22490668296813965 	 
2025-07-31 00:50:32.250767 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50803392 	 1000 	 2.1758840084075928 	 3.548088550567627 	 2.1592257022857666 	 0.44859933853149414 	 2.300400733947754 	 6.960750341415405 	 1.174957513809204 	 0.4442274570465088 	 
2025-07-31 00:50:49.764781 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 264601, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50803392 	 1000 	 0.557410478591919 	 1.209458589553833 	 0.541022777557373 	 0.15524649620056152 	 1.002511739730835 	 3.6687965393066406 	 0.5107884407043457 	 0.23412299156188965 	 
2025-07-31 00:50:57.363728 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, ) 	 50803392 	 1000 	 2.0961856842041016 	 3.5905532836914062 	 2.0789105892181396 	 0.45722484588623047 	 2.3051462173461914 	 6.945191860198975 	 1.1767652034759521 	 0.4447336196899414 	 
2025-07-31 00:51:15.357956 test begin: paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
[Prof] paddle.nn.functional.lp_pool2d 	 paddle.nn.functional.lp_pool2d(Tensor([2, 3, 32, 264601],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, ) 	 50803392 	 1000 	 0.555483341217041 	 1.2167167663574219 	 0.5300643444061279 	 0.15575242042541504 	 0.9967715740203857 	 3.6196627616882324 	 0.5092620849609375 	 0.23080778121948242 	 
2025-07-31 00:51:22.854003 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([1373060, 37],"float32"), Tensor([1373060],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([1373060, 37],"float32"), Tensor([1373060],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 52176280 	 1000 	 2.994826555252075 	 1.6590161323547363 	 0.3390977382659912 	 0.11255002021789551 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:51:29.268109 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float16"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float16"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 965260838 	 1000 	 52.61590600013733 	 19.46686291694641 	 5.972951173782349 	 1.3233609199523926 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:53:25.628309 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float32"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([25401601, 37],"float32"), Tensor([25401601],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 965260838 	 1000 	 55.192527532577515 	 30.239838123321533 	 6.259817600250244 	 1.8150334358215332 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:55:18.695413 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([2746119, 37],"float16"), Tensor([2746119],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([2746119, 37],"float16"), Tensor([2746119],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 104352522 	 1000 	 5.869185447692871 	 2.1573359966278076 	 0.6652626991271973 	 0.14632678031921387 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:55:30.952748 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([5, 10160641],"float32"), Tensor([5],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([5, 10160641],"float32"), Tensor([5],"int64"), return_softmax=False, margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, group=None, reduction=None, ) 	 50803210 	 1000 	 70.27961206436157 	 6.184863805770874 	 6.536462306976318 	 0.42020344734191895 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:56:49.631584 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", ) 	 25401610 	 1000 	 42.08022665977478 	 15.926072835922241 	 3.6175649166107178 	 1.0893664360046387 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:57:49.461479 test begin: paddle.nn.functional.margin_cross_entropy(Tensor([686530, 37],"float64"), Tensor([686530],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", )
[Prof] paddle.nn.functional.margin_cross_entropy 	 paddle.nn.functional.margin_cross_entropy(Tensor([686530, 37],"float64"), Tensor([686530],"int64"), margin1=1.0, margin2=0.5, margin3=0.0, scale=2.0, return_softmax=True, reduction="mean", ) 	 26088140 	 1000 	 2.5161540508270264 	 25.830126762390137 	 0.23478460311889648 	 1.7801692485809326 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-31 00:58:21.274290 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", ) 	 76204830 	 1000 	 1.3401641845703125 	 1.9507830142974854 	 0.2742784023284912 	 0.2839651107788086 	 1.8115811347961426 	 2.1132938861846924 	 0.4633324146270752 	 0.2698204517364502 	 
2025-07-31 00:58:30.131041 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), Tensor([10, 2540161],"float64"), 0.0, "mean", None, ) 	 76204830 	 1000 	 1.3390848636627197 	 1.9408292770385742 	 0.273073673248291 	 0.282637357711792 	 1.8119513988494873 	 2.1094868183135986 	 0.4636111259460449 	 0.26993656158447266 	 
2025-07-31 00:58:40.502398 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", ) 	 76204830 	 1000 	 1.3428852558135986 	 1.94431471824646 	 0.2731039524078369 	 0.2839775085449219 	 1.807755947113037 	 2.111867666244507 	 0.46217799186706543 	 0.26977038383483887 	 
2025-07-31 00:58:49.309893 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), Tensor([2540161, 10],"float64"), 0.0, "mean", None, ) 	 76204830 	 1000 	 1.3431344032287598 	 1.941915512084961 	 0.2742922306060791 	 0.2826850414276123 	 1.8091256618499756 	 2.1097331047058105 	 0.4621903896331787 	 0.26981043815612793 	 
2025-07-31 00:58:58.662863 test begin: paddle.nn.functional.margin_ranking_loss(Tensor([50803201],"float32"), Tensor([50803201],"float32"), Tensor([50803201],"float32"), 0.5, "mean", None, )
[Prof] paddle.nn.functional.margin_ranking_loss 	 paddle.nn.functional.margin_ranking_loss(Tensor([50803201],"float32"), Tensor([50803201],"float32"), Tensor([50803201],"float32"), 0.5, "mean", None, ) 	 152409603 	 1000 	 1.645977258682251 	 1.9450244903564453 	 0.23979568481445312 	 0.28320765495300293 	 2.20269775390625 	 2.253509759902954 	 0.5621128082275391 	 0.28766679763793945 	 
2025-07-31 00:59:09.537404 test begin: paddle.nn.functional.max_pool1d(Tensor([2, 3, 8467201],"float32"), 2, None, 0, False, False, None, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([2, 3, 8467201],"float32"), 2, None, 0, False, False, None, ) 	 50803206 	 1000 	 0.2696225643157959 	 0.41737961769104004 	 0.23761630058288574 	 0.3813467025756836 	 0.7847089767456055 	 1.304373025894165 	 0.4015026092529297 	 0.6664378643035889 	 
2025-07-31 00:59:13.564829 test begin: paddle.nn.functional.max_pool1d(Tensor([226801, 32, 7],"float32"), 7, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([226801, 32, 7],"float32"), 7, ) 	 50803424 	 1000 	 0.31481432914733887 	 0.21578717231750488 	 0.28279638290405273 	 0.18076562881469727 	 18.258336782455444 	 4.431747198104858 	 18.172258377075195 	 2.271627426147461 	 
2025-07-31 00:59:39.154098 test begin: paddle.nn.functional.max_pool1d(Tensor([91, 32, 17447],"float32"), 7, )
[Prof] paddle.nn.functional.max_pool1d 	 paddle.nn.functional.max_pool1d(Tensor([91, 32, 17447],"float32"), 7, ) 	 50805664 	 1000 	 0.3146672248840332 	 0.2382802963256836 	 0.28228330612182617 	 0.18924880027770996 	 0.7494394779205322 	 1.2654609680175781 	 0.38276171684265137 	 0.6465651988983154 	 
2025-07-31 00:59:42.675484 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 128, 480, 83],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 128, 480, 83],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50995200 	 1000 	 0.20863103866577148 	 0.28322768211364746 	 0.18860530853271484 	 0.2563338279724121 	 0.6734614372253418 	 1.3485116958618164 	 0.34463953971862793 	 0.6878008842468262 	 
2025-07-31 00:59:46.289068 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 128, 83, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 128, 83, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50995200 	 1000 	 0.19663786888122559 	 0.27310776710510254 	 0.17833256721496582 	 0.25354599952697754 	 0.6648612022399902 	 1.3475446701049805 	 0.33971643447875977 	 0.6884069442749023 	 
2025-07-31 00:59:49.812741 test begin: paddle.nn.functional.max_pool2d(Tensor([10, 23, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([10, 23, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 52992000 	 1000 	 0.21082186698913574 	 0.2882394790649414 	 0.19244861602783203 	 0.26854586601257324 	 0.6971249580383301 	 1.3991296291351318 	 0.35617876052856445 	 0.7149546146392822 	 
2025-07-31 00:59:53.478547 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 24, 112, 13],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 24, 112, 13],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 53673984 	 1000 	 0.36437034606933594 	 0.39061951637268066 	 0.3458249568939209 	 0.3631165027618408 	 0.5013637542724609 	 1.4664909839630127 	 0.43830370903015137 	 0.7493093013763428 	 
2025-07-31 00:59:57.368933 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 24, 13, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 24, 13, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 53673984 	 1000 	 0.3386540412902832 	 0.3685452938079834 	 0.32027459144592285 	 0.3491189479827881 	 0.4915916919708252 	 1.4511134624481201 	 0.4091494083404541 	 0.7393560409545898 	 
2025-07-31 01:00:01.256008 test begin: paddle.nn.functional.max_pool2d(Tensor([1536, 3, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([1536, 3, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 57802752 	 1000 	 0.4022197723388672 	 0.3779428005218506 	 0.3839428424835205 	 0.3584611415863037 	 0.9155697822570801 	 1.5650560855865479 	 0.4692211151123047 	 0.7993595600128174 	 
2025-07-31 01:00:06.174181 test begin: paddle.nn.functional.max_pool2d(Tensor([169, 24, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([169, 24, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 50878464 	 1000 	 0.3032832145690918 	 0.33338403701782227 	 0.27693819999694824 	 0.306804895401001 	 0.8061165809631348 	 1.3823082447052002 	 0.41185855865478516 	 0.706275463104248 	 
2025-07-31 01:00:10.057081 test begin: paddle.nn.functional.max_pool2d(Tensor([2, 128, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([2, 128, 480, 480],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, ) 	 58982400 	 1000 	 0.23003888130187988 	 0.33817052841186523 	 0.21153664588928223 	 0.3010528087615967 	 0.7771778106689453 	 1.5604782104492188 	 0.39703989028930664 	 0.7950088977813721 	 
2025-07-31 01:00:14.237374 test begin: paddle.nn.functional.max_pool2d(Tensor([2, 64, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([2, 64, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 63438848 	 1000 	 0.38325047492980957 	 0.42172837257385254 	 0.36552953720092773 	 0.39916515350341797 	 1.0106532573699951 	 1.7566163539886475 	 0.5177998542785645 	 0.8955721855163574 	 
2025-07-31 01:00:19.164456 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 13, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 13, 704, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 51544064 	 1000 	 0.35291171073913574 	 0.3444538116455078 	 0.335040807723999 	 0.3221011161804199 	 0.8264846801757812 	 1.4313340187072754 	 0.4236419200897217 	 0.7298932075500488 	 
2025-07-31 01:00:23.183941 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 64, 141, 704],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 64, 141, 704],"float32"), kernel_size=3, stride=2, padding=1, ) 	 50823168 	 1000 	 0.30877065658569336 	 0.3411273956298828 	 0.2911074161529541 	 0.31909656524658203 	 0.8062975406646729 	 1.4111402034759521 	 0.4119737148284912 	 0.7210116386413574 	 
2025-07-31 01:00:27.103320 test begin: paddle.nn.functional.max_pool2d(Tensor([8, 64, 704, 141],"float32"), kernel_size=3, stride=2, padding=1, )
[Prof] paddle.nn.functional.max_pool2d 	 paddle.nn.functional.max_pool2d(Tensor([8, 64, 704, 141],"float32"), kernel_size=3, stride=2, padding=1, ) 	 50823168 	 1000 	 0.3091127872467041 	 0.33870530128479004 	 0.29136133193969727 	 0.319974422454834 	 0.8083443641662598 	 1.3890173435211182 	 0.41296815872192383 	 0.7096598148345947 	 
2025-07-31 01:00:30.999530 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 101606406 	 1000 	 2.2201614379882812 	 2.3463733196258545 	 1.1355597972869873 	 1.1966638565063477 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:00:42.304959 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 16934401],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606406 	 1000 	 2.2267956733703613 	 2.3419315814971924 	 1.1375901699066162 	 1.1905291080474854 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:00:53.741413 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 76204806 	 1000 	 1.125314712524414 	 1.1754462718963623 	 0.5747420787811279 	 0.6011972427368164 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:00:59.186689 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204806 	 1000 	 1.1225428581237793 	 1.1904149055480957 	 0.5720999240875244 	 0.6027696132659912 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:04.567896 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, ) 	 50803206 	 1000 	 1.119849443435669 	 1.197108268737793 	 0.5724208354949951 	 0.6012020111083984 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:13.944308 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8467201],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803206 	 1000 	 1.1224379539489746 	 1.181567907333374 	 0.5735890865325928 	 0.5996520519256592 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:19.283132 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401627 	 1000 	 1.122246265411377 	 1.1737611293792725 	 0.5720598697662354 	 0.5996453762054443 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:24.603789 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8467201],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401627 	 1000 	 1.1193740367889404 	 1.1753308773040771 	 0.5719656944274902 	 0.6011490821838379 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:30.085728 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2540162448 	 1000 	 0.04191732406616211 	 0.04159903526306152 	 3.0517578125e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:30.330975 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 5080322448 	 1000 	 0.03625345230102539 	 0.03992128372192383 	 3.552436828613281e-05 	 7.653236389160156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:30.489369 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([211680101, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5080322448 	 1000 	 0.03707098960876465 	 0.039733171463012695 	 3.743171691894531e-05 	 7.295608520507812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:30.657774 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401632 	 1000 	 1.123774528503418 	 1.1789662837982178 	 0.5733656883239746 	 0.5996875762939453 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:39.394216 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401632 	 1000 	 1.1253185272216797 	 1.182020664215088 	 0.5748903751373291 	 0.6025562286376953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:44.965368 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, ) 	 50803216 	 1000 	 1.1220011711120605 	 1.1802175045013428 	 0.5717575550079346 	 0.602675199508667 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:50.371341 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 3175201, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803216 	 1000 	 1.119342565536499 	 1.1829760074615479 	 0.5720851421356201 	 0.60249924659729 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:01:55.780717 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 76204816 	 1000 	 1.1208610534667969 	 1.1783626079559326 	 0.5734524726867676 	 0.6012132167816162 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:02:01.164454 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 3175201, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204816 	 1000 	 1.1210944652557373 	 1.1750659942626953 	 0.5720005035400391 	 0.5996944904327393 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:02:06.497636 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 101606416 	 1000 	 2.2220869064331055 	 2.332536220550537 	 1.1349976062774658 	 1.191314935684204 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:02:18.107812 test begin: paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1, 6350401, 8],"float64"), Tensor([1, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606416 	 1000 	 2.2259786128997803 	 2.3604955673217773 	 1.1360836029052734 	 1.1920242309570312 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-31 01:02:28.937565 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 16934401],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262247006 	 1000 	 0.042870521545410156 	 0.04792165756225586 	 2.3365020751953125e-05 	 6.747245788574219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:26.146960 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
W0730 19:24:26.352840 23934 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
/root/paddlejob/workspace/env_run/ningzs/PaddleAPITest/tester/api_config/config_analyzer.py:1878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).
  self.paddle_tensor = paddle.to_tensor(
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696685406 	 1000 	 0.05311298370361328 	 0.04341602325439453 	 2.2411346435546875e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:26.980109 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 16934401],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131125927 	 1000 	 0.042066335678100586 	 0.042220115661621094 	 2.288818359375e-05 	 7.152557373046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:27.149654 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8467201],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131123806 	 1000 	 0.04201149940490723 	 0.04150867462158203 	 1.9788742065429688e-05 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:27.315659 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3, 8467201],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564327 	 1000 	 0.04168820381164551 	 0.04139304161071777 	 1.1920928955078125e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:27.480730 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2565564832 	 1000 	 0.041829586029052734 	 0.0413355827331543 	 1.4066696166992188e-05 	 5.698204040527344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:27.645556 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 25404048 	 1000 	 0.04163479804992676 	 0.04104781150817871 	 2.288818359375e-05 	 6.222724914550781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:27.810590 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, ) 	 5131125927 	 1000 	 0.03682732582092285 	 0.03981637954711914 	 2.3365020751953125e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:27.975991 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 3, 16934401],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131125927 	 1000 	 0.051789045333862305 	 0.040088653564453125 	 2.3365020751953125e-05 	 5.054473876953125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:28.170350 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, ) 	 5131126432 	 1000 	 0.03624868392944336 	 0.0399017333984375 	 1.430511474609375e-05 	 4.9591064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:28.328092 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([101, 6350401, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 5131126432 	 1000 	 0.05182290077209473 	 0.03947758674621582 	 2.1219253540039062e-05 	 4.124641418457031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:28.522134 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50805648 	 1000 	 0.03606700897216797 	 0.042369842529296875 	 1.239776611328125e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:28.683534 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50805648 	 1000 	 0.036740779876708984 	 0.039487600326538086 	 1.430511474609375e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:28.842366 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 3175201, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131124816 	 1000 	 0.042795419692993164 	 0.04109644889831543 	 1.6689300537109375e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:29.009106 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5131126432 	 1000 	 0.04250669479370117 	 0.04285025596618652 	 1.5974044799804688e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:29.177236 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 3175201, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 7696686416 	 1000 	 0.041778564453125 	 0.0435335636138916 	 1.33514404296875e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:29.344567 test begin: paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([101, 6350401, 8],"float32"), Tensor([101, 6350401, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10262248016 	 1000 	 0.042371511459350586 	 0.04126381874084473 	 1.7881393432617188e-05 	 6.29425048828125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:29.513205 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 25401648 	 1000 	 1.1147687435150146 	 1.1737337112426758 	 0.5690481662750244 	 0.5997216701507568 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:34.794587 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 25401648 	 1000 	 1.1232757568359375 	 1.1914079189300537 	 0.5723538398742676 	 0.601301908493042 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:41.774035 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 50803248 	 1000 	 1.114912986755371 	 1.1739497184753418 	 0.5692801475524902 	 0.5996954441070557 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:47.061012 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([1058401, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 50803248 	 1000 	 1.1150157451629639 	 1.1737942695617676 	 0.5691468715667725 	 0.599684476852417 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:52.308770 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 76204848 	 1000 	 1.1152949333190918 	 1.1738510131835938 	 0.5694904327392578 	 0.5997345447540283 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:24:58.904883 test begin: paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([1058401, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 76204848 	 1000 	 1.1176362037658691 	 1.1738183498382568 	 0.5692799091339111 	 0.5997319221496582 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:06.192576 test begin: paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([105840101, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080324848 	 1000 	 0.041954755783081055 	 0.041321754455566406 	 3.0279159545898438e-05 	 8.058547973632812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:06.362556 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 50805648 	 1000 	 0.041585683822631836 	 0.04160022735595703 	 3.123283386230469e-05 	 8.20159912109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:06.531148 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float32"), Tensor([105840101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 2590965648 	 1000 	 0.04181265830993652 	 0.04408001899719238 	 2.5272369384765625e-05 	 7.557868957519531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:06.700678 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, ) 	 101606448 	 1000 	 2.2172627449035645 	 2.331214427947998 	 1.1324546337127686 	 1.1904196739196777 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:17.301068 test begin: paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([2116801, 3, 8],"float64"), Tensor([2116801, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, ) 	 101606448 	 1000 	 2.217729330062866 	 2.331104278564453 	 1.132662057876587 	 1.1908369064331055 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:27.833857 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5080322448 	 1000 	 0.04166007041931152 	 0.04112982749938965 	 1.7881393432617188e-05 	 4.863739013671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:28.003987 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([1058401, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 5105724048 	 1000 	 0.04266214370727539 	 0.054229021072387695 	 0.0001385211944580078 	 0.00010132789611816406 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:28.206663 test begin: paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
[Prof] paddle.nn.functional.max_unpool1d 	 paddle.nn.functional.max_unpool1d(Tensor([211680101, 3, 8],"float32"), Tensor([211680101, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], ) 	 10160644848 	 1000 	 0.04157710075378418 	 0.04114580154418945 	 1.33514404296875e-05 	 3.910064697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:28.372728 test begin: paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([1894, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.05871105194091797 	 0.08545112609863281 	 0.02998495101928711 	 0.04350590705871582 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:28.812310 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164015264 	 1000 	 0.05868029594421387 	 0.08541607856750488 	 0.02993464469909668 	 0.04349398612976074 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:29.232854 test begin: paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([189401, 8, 86, 39],"float32"), Tensor([64, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.0587000846862793 	 0.08539271354675293 	 0.029970884323120117 	 0.04349780082702637 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:29.648377 test begin: paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([3887, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.04575657844543457 	 0.041783809661865234 	 1.8835067749023438e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:29.932220 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10162198944 	 1000 	 0.021730661392211914 	 0.030828237533569336 	 2.2649765014648438e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:30.126276 test begin: paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([388701, 16, 43, 19],"float32"), Tensor([64, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.021881580352783203 	 0.030897855758666992 	 2.3126602172851562e-05 	 3.743171691894531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:30.321840 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 16, 43, 19],"float32"), Tensor([388701, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5081936080 	 1000 	 0.030788421630859375 	 0.045244693756103516 	 2.6464462280273438e-05 	 6.389617919921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:30.558467 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.021790027618408203 	 0.030927181243896484 	 1.6450881958007812e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:30.717021 test begin: paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([64, 8, 86, 39],"float32"), Tensor([189401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5083724880 	 1000 	 0.05875802040100098 	 0.08858418464660645 	 0.0300595760345459 	 0.043526649475097656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:31.141068 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10165402496 	 1000 	 0.02199387550354004 	 0.030698299407958984 	 2.3365020751953125e-05 	 4.673004150390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:31.339258 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 2612, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.022255897521972656 	 0.031137704849243164 	 2.3603439331054688e-05 	 7.915496826171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:31.535682 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10164173504 	 1000 	 0.021889925003051758 	 0.0309293270111084 	 2.3603439331054688e-05 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:31.731182 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 1154],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.021836280822753906 	 0.031165599822998047 	 2.2649765014648438e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:31.931581 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([3887, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 134484736 	 1000 	 0.031130313873291016 	 0.03994584083557129 	 2.0742416381835938e-05 	 6.031990051269531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:32.155616 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 2612, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166375120 	 1000 	 0.02201390266418457 	 0.030571937561035156 	 2.2411346435546875e-05 	 4.076957702636719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:32.352310 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 16, 43, 1154],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5165760624 	 1000 	 0.021768808364868164 	 0.03061509132385254 	 2.288818359375e-05 	 5.412101745605469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:32.547042 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 16, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.021907567977905273 	 0.0305483341217041 	 2.3126602172851562e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:32.742230 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10176284196 	 1000 	 0.05872464179992676 	 0.08541059494018555 	 0.03001093864440918 	 0.04349064826965332 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:33.159621 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 237, 86, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.0588221549987793 	 0.08552694320678711 	 0.027761220932006836 	 0.04352927207946777 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:33.598526 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10168679808 	 1000 	 0.029024600982666016 	 0.03171253204345703 	 3.457069396972656e-05 	 5.7220458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:33.784971 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 1182],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.02280449867248535 	 0.05615735054016113 	 1.9311904907226562e-05 	 5.030632019042969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:33.996348 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 1182],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5123053152 	 1000 	 0.022039175033569336 	 0.033606529235839844 	 1.52587890625e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:34.153935 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.02213120460510254 	 0.05962681770324707 	 1.5735626220703125e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:34.341745 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.023756980895996094 	 0.03336334228515625 	 1.5497207641601562e-05 	 3.6716461181640625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:34.504704 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 21, 9],"float32"), Tensor([8401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.02225637435913086 	 0.032819271087646484 	 1.430511474609375e-05 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:34.664502 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121209664 	 1000 	 0.02221512794494629 	 0.031525373458862305 	 1.6450881958007812e-05 	 3.9577484130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:34.819748 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 32, 2757, 9],"float32"), Tensor([6401, 32, 2757, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164992832 	 1000 	 0.022294044494628906 	 0.03304767608642578 	 1.4781951904296875e-05 	 3.647804260253906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:34.979685 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5121036837 	 1000 	 0.02168726921081543 	 0.03596162796020508 	 1.5020370483398438e-05 	 4.601478576660156e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:36.401890 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 4201, 21, 9],"float32"), Tensor([6401, 4201, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10164647178 	 1000 	 0.021869421005249023 	 0.4149813652038574 	 1.6927719116210938e-05 	 8.58306884765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:37.615170 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10165300080 	 1000 	 0.05878949165344238 	 0.0993504524230957 	 0.02997589111328125 	 0.043596744537353516 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:39.985301 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 2545, 39],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.05870461463928223 	 0.10444092750549316 	 0.02998065948486328 	 0.04358696937561035 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:40.487530 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 10164173504 	 1000 	 0.05869603157043457 	 0.11121010780334473 	 0.029961347579956055 	 0.043495893478393555 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:40.966363 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 1154],"float32"), Tensor([6401, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.058645009994506836 	 0.09622430801391602 	 0.029949426651000977 	 0.04351973533630371 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:41.418151 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([1894, 8, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 222571440 	 1000 	 0.05869340896606445 	 0.08543586730957031 	 0.029962778091430664 	 0.04349231719970703 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:41.838566 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 237, 86, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5259893730 	 1000 	 0.05866074562072754 	 0.0899038314819336 	 0.029941082000732422 	 0.04352307319641113 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:42.270317 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 2545, 39],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5254401672 	 1000 	 0.058687448501586914 	 0.08543801307678223 	 0.029937028884887695 	 0.043534040451049805 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:42.685920 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 8, 86, 39],"float32"), Tensor([6401, 8, 86, 1154],"int32"), 2, 2, output_size=list[64,8,172,79,], ) 	 5253838384 	 1000 	 0.05893564224243164 	 0.08548331260681152 	 0.028012752532958984 	 0.04351520538330078 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:43.162112 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 16, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 5166861596 	 1000 	 0.022356033325195312 	 0.03557848930358887 	 2.3365020751953125e-05 	 4.696846008300781e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:43.377219 test begin: paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([6401, 972, 43, 19],"float32"), Tensor([6401, 972, 43, 19],"int32"), 2, 2, output_size=list[64,16,86,39,], ) 	 10166375448 	 1000 	 0.022064685821533203 	 0.03055095672607422 	 2.3365020751953125e-05 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:43.571706 test begin: paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([8401, 32, 21, 9],"float32"), Tensor([6401, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 89522496 	 1000 	 0.021913528442382812 	 0.0312955379486084 	 1.71661376953125e-05 	 4.100799560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:43.727554 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([64, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 5081317920 	 1000 	 0.0216519832611084 	 0.030897140502929688 	 1.5020370483398438e-05 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:43.883420 test begin: paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], )
[Prof] paddle.nn.functional.max_unpool2d 	 paddle.nn.functional.max_unpool2d(Tensor([840101, 32, 21, 9],"float32"), Tensor([840101, 32, 21, 9],"int32"), 2, 2, output_size=list[64,32,43,19,], ) 	 10161861696 	 1000 	 0.02230358123779297 	 0.030977487564086914 	 1.5735626220703125e-05 	 3.695487976074219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:44.042093 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803440 	 1000 	 1.7010540962219238 	 1.7669777870178223 	 0.8688836097717285 	 0.16348576545715332 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:25:54.540508 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803440 	 1000 	 2.6334164142608643 	 2.6027920246124268 	 1.3446338176727295 	 0.18938970565795898 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:26:11.231119 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803440 	 1000 	 1.7259089946746826 	 1.7693288326263428 	 0.880948543548584 	 0.16375446319580078 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:26:22.338053 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 1.7010571956634521 	 1.7672789096832275 	 0.8689837455749512 	 0.16359329223632812 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:26:32.226183 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402080 	 1000 	 2.636345624923706 	 2.595987558364868 	 1.3448152542114258 	 0.18947935104370117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:26:47.359671 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402080 	 1000 	 1.725304126739502 	 1.7667250633239746 	 0.8814897537231445 	 0.1635878086090088 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:26:57.191271 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76205040 	 1000 	 1.7019124031066895 	 1.7659893035888672 	 0.8688020706176758 	 0.1633768081665039 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:27:07.056939 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 211681, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76205040 	 1000 	 2.640315055847168 	 2.595374584197998 	 1.3459346294403076 	 0.18944144248962402 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:27:23.581115 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5080356720 	 1000 	 0.02916121482849121 	 0.03384113311767578 	 1.8358230590820312e-05 	 5.91278076171875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:27:23.713211 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([14112101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5080356720 	 1000 	 0.029392242431640625 	 0.03364920616149902 	 1.621246337890625e-05 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:27:23.840734 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([7056101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2540196720 	 1000 	 0.029221057891845703 	 0.03364872932434082 	 1.5497207641601562e-05 	 3.743171691894531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:27:23.971690 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101606640 	 1000 	 3.382237195968628 	 3.547258138656616 	 1.7272589206695557 	 0.16363239288330078 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:27:44.524620 test begin: paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([1, 423361, 4, 5, 6],"float64"), Tensor([1, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101606640 	 1000 	 5.261022567749023 	 5.179909944534302 	 2.6873252391815186 	 0.18809914588928223 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:15.624367 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.029121875762939453 	 0.0339357852935791 	 2.002716064453125e-05 	 7.271766662597656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:15.776362 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131141380 	 1000 	 0.029117822647094727 	 0.03459763526916504 	 3.0279159545898438e-05 	 8.678436279296875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:15.931364 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131141380 	 1000 	 0.02877354621887207 	 0.033899545669555664 	 9.918212890625e-05 	 3.743171691894531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:16.085602 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.029201507568359375 	 0.0342254638671875 	 1.2874603271484375e-05 	 7.152557373046875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:17.599087 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565607050 	 1000 	 0.029281139373779297 	 0.04148983955383301 	 1.7404556274414062e-05 	 8.630752563476562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:18.324691 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.04770374298095703 	 0.03400230407714844 	 3.9577484130859375e-05 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:18.498402 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696702980 	 1000 	 0.047779083251953125 	 0.03389739990234375 	 2.5510787963867188e-05 	 7.128715515136719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:18.681151 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 282241, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696702980 	 1000 	 0.04665732383728027 	 0.03399991989135742 	 1.8596649169921875e-05 	 7.319450378417969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:18.866564 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.03827857971191406 	 0.04381871223449707 	 2.8371810913085938e-05 	 4.2438507080078125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:19.030639 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131137744 	 1000 	 0.03826642036437988 	 0.04364156723022461 	 1.4066696166992188e-05 	 6.389617919921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:19.197445 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131137744 	 1000 	 0.03803205490112305 	 0.043946266174316406 	 1.4781951904296875e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:19.359861 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.039853811264038086 	 0.04349088668823242 	 1.9550323486328125e-05 	 4.9591064453125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:19.524412 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565605232 	 1000 	 0.038045644760131836 	 0.04371500015258789 	 1.6450881958007812e-05 	 6.699562072753906e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:19.689669 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.0382387638092041 	 0.04361724853515625 	 2.5510787963867188e-05 	 8.0108642578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:19.855654 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696699344 	 1000 	 0.038097381591796875 	 0.043714046478271484 	 2.4318695068359375e-05 	 7.033348083496094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.019548 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 352801, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696699344 	 1000 	 0.030271291732788086 	 0.04543709754943848 	 2.2411346435546875e-05 	 7.700920104980469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.170867 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.030040979385375977 	 0.04378056526184082 	 2.4557113647460938e-05 	 6.318092346191406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.324653 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131135320 	 1000 	 0.02942514419555664 	 0.03944253921508789 	 2.4318695068359375e-05 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.473844 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131135320 	 1000 	 0.02935647964477539 	 0.037012577056884766 	 1.7642974853515625e-05 	 6.961822509765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.619888 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.029529094696044922 	 0.03418111801147461 	 1.7642974853515625e-05 	 5.555152893066406e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.755257 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 2565604020 	 1000 	 0.02914571762084961 	 0.036638736724853516 	 1.1444091796875e-05 	 4.220008850097656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:20.899936 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.02983260154724121 	 0.03416323661804199 	 1.6927719116210938e-05 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.036373 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 7696696920 	 1000 	 0.029343605041503906 	 0.03391146659851074 	 1.1920928955078125e-05 	 4.315376281738281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.184489 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 423361],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 7696696920 	 1000 	 0.02910470962524414 	 0.03412294387817383 	 1.2636184692382812e-05 	 3.695487976074219e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.323826 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 211681, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565610080 	 1000 	 0.03106975555419922 	 0.034407615661621094 	 2.002716064453125e-05 	 5.14984130859375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.470883 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 282241, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565607050 	 1000 	 0.029115676879882812 	 0.03390765190124512 	 1.2636184692382812e-05 	 4.315376281738281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.611927 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 352801, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565605232 	 1000 	 0.04372525215148926 	 0.04343414306640625 	 1.71661376953125e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.788602 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 423361],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 2565604020 	 1000 	 0.029337406158447266 	 0.03470969200134277 	 1.1444091796875e-05 	 5.841255187988281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:21.928550 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131165620 	 1000 	 0.02937912940979004 	 0.03391242027282715 	 1.3828277587890625e-05 	 3.981590270996094e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.066900 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131165620 	 1000 	 0.0296328067779541 	 0.0343172550201416 	 1.4066696166992188e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.203649 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131166832 	 1000 	 0.028978824615478516 	 0.03583979606628418 	 1.1444091796875e-05 	 3.0517578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.338271 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131166832 	 1000 	 0.02979874610900879 	 0.04343104362487793 	 1.4781951904296875e-05 	 3.409385681152344e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.494069 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131168650 	 1000 	 0.029347896575927734 	 0.03387570381164551 	 1.0728836059570312e-05 	 2.86102294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.626182 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131168650 	 1000 	 0.029508113861083984 	 0.03434133529663086 	 1.3828277587890625e-05 	 5.269050598144531e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.771324 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 5131171680 	 1000 	 0.029546260833740234 	 0.03600001335144043 	 1.1920928955078125e-05 	 4.4345855712890625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:22.909331 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([101, 423361, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 5131171680 	 1000 	 0.029676198959350586 	 0.034110307693481445 	 1.2636184692382812e-05 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.045196 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50839920 	 1000 	 0.029395103454589844 	 0.034120798110961914 	 1.1682510375976562e-05 	 5.2928924560546875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.178531 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50839920 	 1000 	 0.029334306716918945 	 0.03420901298522949 	 1.2159347534179688e-05 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.314596 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25438320 	 1000 	 0.029348373413085938 	 0.0338437557220459 	 1.1682510375976562e-05 	 6.103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.447832 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262258520 	 1000 	 0.0294497013092041 	 0.033904075622558594 	 1.2159347534179688e-05 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.581411 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 5, 846721],"float64"), Tensor([101, 3, 4, 5, 846721],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262258520 	 1000 	 0.029656648635864258 	 0.03412914276123047 	 1.3589859008789062e-05 	 6.365776062011719e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.721121 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262260944 	 1000 	 0.028937339782714844 	 0.0366518497467041 	 1.1682510375976562e-05 	 7.390975952148438e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.857073 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 4, 705601, 6],"float64"), Tensor([101, 3, 4, 705601, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262260944 	 1000 	 0.02946329116821289 	 0.03420901298522949 	 1.239776611328125e-05 	 5.7220458984375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:23.996764 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 10262264580 	 1000 	 0.02930426597595215 	 0.03408622741699219 	 1.3113021850585938e-05 	 6.413459777832031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:24.130830 test begin: paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([101, 3, 564481, 5, 6],"float64"), Tensor([101, 3, 564481, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 10262264580 	 1000 	 0.029542922973632812 	 0.03406357765197754 	 1.6927719116210938e-05 	 6.771087646484375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:24.267610 test begin: paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 101607120 	 1000 	 3.3823375701904297 	 3.5638628005981445 	 1.7277214527130127 	 0.16505694389343262 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:28:46.619414 test begin: paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([141121, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 101607120 	 1000 	 5.260426044464111 	 5.178028345108032 	 2.686929225921631 	 0.18795108795166016 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:29:16.224984 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 1.7006778717041016 	 1.7664642333984375 	 0.8682737350463867 	 0.16348004341125488 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:29:27.021273 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 25402320 	 1000 	 2.631237030029297 	 2.614389419555664 	 1.343876600265503 	 0.1894841194152832 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:29:43.715795 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 25402320 	 1000 	 1.7303507328033447 	 1.7674059867858887 	 0.8816311359405518 	 0.16327834129333496 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:29:53.951391 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 76205520 	 1000 	 1.702852725982666 	 1.763014554977417 	 0.8691713809967041 	 0.16312623023986816 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:04.149116 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([141121, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 76205520 	 1000 	 2.6331779956817627 	 2.5924956798553467 	 1.34501314163208 	 0.18928766250610352 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:19.685592 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 1.7017426490783691 	 1.7754197120666504 	 0.8691825866699219 	 0.16330289840698242 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:32.133734 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, ) 	 50803920 	 1000 	 2.640927314758301 	 2.595106363296509 	 1.3461642265319824 	 0.18930745124816895 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:47.780983 test begin: paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
[Prof] paddle.nn.functional.max_unpool3d 	 paddle.nn.functional.max_unpool3d(Tensor([70561, 3, 4, 5, 6],"float64"), Tensor([70561, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, ) 	 50803920 	 1000 	 1.7256877422332764 	 1.7658214569091797 	 0.8814296722412109 	 0.1633901596069336 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:30:58.029577 test begin: paddle.nn.functional.mish(Tensor([12, 10585, 20, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 10585, 20, 20],"float32"), ) 	 50808000 	 1000 	 0.3049330711364746 	 0.3001675605773926 	 0.2959866523742676 	 0.2845015525817871 	 0.45339298248291016 	 0.45445728302001953 	 0.39865875244140625 	 0.38405847549438477 	 
2025-07-30 19:31:01.209100 test begin: paddle.nn.functional.mish(Tensor([12, 128, 40, 827],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 128, 40, 827],"float32"), ) 	 50810880 	 1000 	 0.3053421974182129 	 0.3001422882080078 	 0.2958967685699463 	 0.28462910652160645 	 0.45351743698120117 	 0.45439648628234863 	 0.40001344680786133 	 0.3904273509979248 	 
2025-07-30 19:31:04.357857 test begin: paddle.nn.functional.mish(Tensor([12, 128, 827, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 128, 827, 40],"float32"), ) 	 50810880 	 1000 	 0.3054087162017822 	 0.3096315860748291 	 0.2960689067840576 	 0.2845587730407715 	 0.45339202880859375 	 0.4543917179107666 	 0.398648738861084 	 0.38892221450805664 	 
2025-07-30 19:31:10.891117 test begin: paddle.nn.functional.mish(Tensor([12, 256, 40, 414],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 256, 40, 414],"float32"), ) 	 50872320 	 1000 	 0.30544233322143555 	 0.300462007522583 	 0.2889084815979004 	 0.277681827545166 	 0.45402956008911133 	 0.454679012298584 	 0.39190006256103516 	 0.38756299018859863 	 
2025-07-30 19:31:14.084958 test begin: paddle.nn.functional.mish(Tensor([12, 256, 414, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 256, 414, 40],"float32"), ) 	 50872320 	 1000 	 0.30518531799316406 	 0.3004271984100342 	 0.2962682247161865 	 0.2845320701599121 	 0.4545013904571533 	 0.45468711853027344 	 0.39885544776916504 	 0.39048314094543457 	 
2025-07-30 19:31:17.223633 test begin: paddle.nn.functional.mish(Tensor([12, 2647, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 2647, 40, 40],"float32"), ) 	 50822400 	 1000 	 0.30559802055358887 	 0.30031919479370117 	 0.2967386245727539 	 0.28473520278930664 	 0.4537844657897949 	 0.45453548431396484 	 0.40042924880981445 	 0.3865852355957031 	 
2025-07-30 19:31:20.522385 test begin: paddle.nn.functional.mish(Tensor([12, 512, 20, 414],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 512, 20, 414],"float32"), ) 	 50872320 	 1000 	 0.3051738739013672 	 0.3004577159881592 	 0.29616212844848633 	 0.2846341133117676 	 0.45439863204956055 	 0.4547576904296875 	 0.4013671875 	 0.3900613784790039 	 
2025-07-30 19:31:23.648625 test begin: paddle.nn.functional.mish(Tensor([12, 512, 414, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([12, 512, 414, 20],"float32"), ) 	 50872320 	 1000 	 0.30528950691223145 	 0.302656888961792 	 0.29643988609313965 	 0.28438615798950195 	 0.45443129539489746 	 0.4548008441925049 	 0.40163660049438477 	 0.3899970054626465 	 
2025-07-30 19:31:26.761117 test begin: paddle.nn.functional.mish(Tensor([125, 256, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([125, 256, 40, 40],"float32"), ) 	 51200000 	 1000 	 0.3075716495513916 	 0.30765390396118164 	 0.2981898784637451 	 0.2865123748779297 	 0.4570794105529785 	 0.457660436630249 	 0.4040358066558838 	 0.39370250701904297 	 
2025-07-30 19:31:29.922794 test begin: paddle.nn.functional.mish(Tensor([249, 128, 40, 40],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([249, 128, 40, 40],"float32"), ) 	 50995200 	 1000 	 0.7538151741027832 	 0.31568360328674316 	 0.2968003749847412 	 0.28533244132995605 	 0.45525145530700684 	 0.4558074474334717 	 0.40191078186035156 	 0.39174580574035645 	 
2025-07-30 19:31:37.473436 test begin: paddle.nn.functional.mish(Tensor([249, 512, 20, 20],"float32"), )
[Prof] paddle.nn.functional.mish 	 paddle.nn.functional.mish(Tensor([249, 512, 20, 20],"float32"), ) 	 50995200 	 1000 	 0.8184890747070312 	 0.3056466579437256 	 0.2967689037322998 	 0.28548455238342285 	 0.45549845695495605 	 0.45578646659851074 	 0.3885805606842041 	 0.376265287399292 	 
2025-07-30 19:31:42.103596 test begin: paddle.nn.functional.mse_loss(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), "mean", ) 	 101608320 	 1000 	 0.8935902118682861 	 0.6024727821350098 	 0.22804713249206543 	 0.20354795455932617 	 1.0596282482147217 	 1.159907579421997 	 0.36111903190612793 	 0.2963137626647949 	 
2025-07-30 19:31:47.665639 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), "mean", ) 	 101671488 	 1000 	 0.8949708938598633 	 0.5988876819610596 	 0.2281181812286377 	 0.20367217063903809 	 1.0601937770843506 	 1.160426378250122 	 0.36138248443603516 	 0.29641056060791016 	 
2025-07-30 19:31:52.986579 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", )
/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Using a target size (torch.Size([3548, 12, 170, 8])) that is different to the input size (torch.Size([3548, 12, 170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", ) 	 65141280 	 1000 	 0.8666391372680664 	 0.5753862857818604 	 0.22061729431152344 	 0.19575715065002441 	 1.545924186706543 	 1.6168816089630127 	 0.39507293701171875 	 0.3307795524597168 	 
2025-07-30 19:31:58.672488 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), "mean", )
/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Using a target size (torch.Size([3548, 12, 170, 1])) that is different to the input size (torch.Size([3548, 12, 170, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return func(*args, **kwargs)
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), "mean", ) 	 65141280 	 1000 	 0.8655338287353516 	 0.5741167068481445 	 0.22087812423706055 	 0.19530558586120605 	 1.1362605094909668 	 1.6167664527893066 	 0.38722705841064453 	 0.33081626892089844 	 
2025-07-30 19:32:03.892629 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), "mean", ) 	 115806720 	 1000 	 1.01621675491333 	 0.7092006206512451 	 0.2593202590942383 	 0.24123620986938477 	 1.2052395343780518 	 1.3184571266174316 	 0.4107940196990967 	 0.3368556499481201 	 
2025-07-30 19:32:10.035199 test begin: paddle.nn.functional.mse_loss(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), "mean", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), "mean", ) 	 102537200 	 1000 	 0.9017372131347656 	 0.6045353412628174 	 0.2301180362701416 	 0.20543909072875977 	 1.0685298442840576 	 1.1699316501617432 	 0.36414170265197754 	 0.29891347885131836 	 
2025-07-30 19:32:15.485156 test begin: paddle.nn.functional.mse_loss(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), "none", ) 	 101646336 	 1000 	 0.7460262775421143 	 0.4469945430755615 	 0.3811190128326416 	 0.4154036045074463 	 0.9243757724761963 	 1.4458816051483154 	 0.4722898006439209 	 0.36934351921081543 	 
2025-07-30 19:32:21.496316 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), "none", ) 	 101670912 	 1000 	 0.7468264102935791 	 0.44705796241760254 	 0.3812136650085449 	 0.4230802059173584 	 0.924318790435791 	 1.4459950923919678 	 0.4722588062286377 	 0.3693704605102539 	 
2025-07-30 19:32:27.643112 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), "none", ) 	 101744640 	 1000 	 0.7468032836914062 	 0.44726085662841797 	 0.38152241706848145 	 0.4228849411010742 	 0.9252054691314697 	 1.4469854831695557 	 0.47272253036499023 	 0.36963629722595215 	 
2025-07-30 19:32:33.691938 test begin: paddle.nn.functional.mse_loss(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), "none", ) 	 103809024 	 1000 	 0.7669684886932373 	 0.46256470680236816 	 0.38909268379211426 	 0.43233227729797363 	 0.9443671703338623 	 1.4761848449707031 	 0.4824409484863281 	 0.37735986709594727 	 
2025-07-30 19:32:45.371298 test begin: paddle.nn.functional.mse_loss(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), "none", ) 	 103809024 	 1000 	 0.7616143226623535 	 0.4564230442047119 	 0.38907337188720703 	 0.4325404167175293 	 0.9442024230957031 	 1.4760158061981201 	 0.4824094772338867 	 0.3770582675933838 	 
2025-07-30 19:32:51.544893 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), "none", ) 	 104857600 	 1000 	 0.7693593502044678 	 0.46073174476623535 	 0.39305830001831055 	 0.4315629005432129 	 0.9517714977264404 	 1.4906270503997803 	 0.4863014221191406 	 0.3807837963104248 	 
2025-07-30 19:32:57.715594 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), "none", ) 	 101646336 	 1000 	 0.7459864616394043 	 0.4468867778778076 	 0.38111400604248047 	 0.4228992462158203 	 0.9240260124206543 	 1.4458673000335693 	 0.47214722633361816 	 0.36934471130371094 	 
2025-07-30 19:33:03.746097 test begin: paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), "none", ) 	 101646336 	 1000 	 0.7459633350372314 	 0.4468092918395996 	 0.38108348846435547 	 0.4228339195251465 	 0.9240877628326416 	 1.4454548358917236 	 0.4721822738647461 	 0.3692317008972168 	 
2025-07-30 19:33:09.725313 test begin: paddle.nn.functional.mse_loss(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), "none", )
[Prof] paddle.nn.functional.mse_loss 	 paddle.nn.functional.mse_loss(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), "none", ) 	 101744640 	 1000 	 0.7466535568237305 	 0.45668864250183105 	 0.3814072608947754 	 0.4226198196411133 	 0.9254376888275146 	 1.447066307067871 	 0.4727623462677002 	 0.3695957660675049 	 
2025-07-30 19:33:15.715241 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=None, ) 	 50803210 	 1000 	 3.3696985244750977 	 3.3241007328033447 	 0.31303930282592773 	 0.2825314998626709 	 4.629478931427002 	 4.30022120475769 	 0.364976167678833 	 0.3386657238006592 	 
2025-07-30 19:33:32.461751 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=Tensor([5, 5080321],"float64"), )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), reduction="mean", weight=Tensor([5, 5080321],"float64"), ) 	 76204815 	 1000 	 3.8217546939849854 	 3.76515531539917 	 0.3248927593231201 	 0.29555749893188477 	 5.375892400741577 	 5.062752962112427 	 0.3923676013946533 	 0.34510040283203125 	 
2025-07-30 19:33:54.257038 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), weight=Tensor([5, 5080321],"float64"), reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), weight=Tensor([5, 5080321],"float64"), reduction="mean", name=None, ) 	 76204815 	 1000 	 3.820526361465454 	 3.765018939971924 	 0.32494378089904785 	 0.2955636978149414 	 5.374397277832031 	 5.062371253967285 	 0.39226484298706055 	 0.3451251983642578 	 
2025-07-30 19:34:14.057291 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=None, ) 	 50803210 	 1000 	 3.390148878097534 	 3.485671281814575 	 0.31482529640197754 	 0.29631567001342773 	 4.714418172836304 	 4.456084251403809 	 0.37159156799316406 	 0.35082197189331055 	 
2025-07-30 19:34:31.265168 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=Tensor([5080321, 5],"float64"), )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), reduction="mean", weight=Tensor([5080321, 5],"float64"), ) 	 76204815 	 1000 	 3.838691473007202 	 3.929550886154175 	 0.3263511657714844 	 0.30857205390930176 	 5.459810495376587 	 5.210923194885254 	 0.39851975440979004 	 0.3552436828613281 	 
2025-07-30 19:34:52.073094 test begin: paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), weight=Tensor([5080321, 5],"float64"), reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_label_soft_margin_loss 	 paddle.nn.functional.multi_label_soft_margin_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), weight=Tensor([5080321, 5],"float64"), reduction="mean", name=None, ) 	 76204815 	 1000 	 3.8471364974975586 	 3.9298486709594727 	 0.32624220848083496 	 0.308513879776001 	 5.459770202636719 	 5.210770130157471 	 0.3985273838043213 	 0.35520434379577637 	 
2025-07-30 19:35:14.846395 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
W0730 19:35:15.552201 28939 dygraph_functions.cc:93089] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 38102403 	 1000 	 3.8754515647888184 	 16.226356983184814 	 0.00013637542724609375 	 5.517024993896484 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:35:40.018789 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 38102403 	 1000 	 3.7841506004333496 	 16.16069006919861 	 0.00013637542724609375 	 16.122212648391724 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:36:05.360573 test begin: paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([12700801, 2],"float64"), Tensor([12700801],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 38102403 	 1000 	 3.860430955886841 	 16.229193925857544 	 0.00019931793212890625 	 5.518003463745117 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:36:30.456642 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 76204803 	 1000 	 7.514685392379761 	 32.43816566467285 	 0.0004208087921142578 	 11.029189586639404 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:37:20.158462 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 76204803 	 1000 	 7.375360012054443 	 33.42046904563904 	 0.00027942657470703125 	 32.37373113632202 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:38:12.828736 test begin: paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([25401601, 2],"float64"), Tensor([25401601],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 76204803 	 1000 	 7.52113938331604 	 32.4374840259552 	 0.0004024505615234375 	 11.028940439224243 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:39:04.162236 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, ) 	 25401610 	 1000 	 1.2811875343322754 	 6.023107290267944 	 2.384185791015625e-05 	 3.077526807785034 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:39:14.368586 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, ) 	 25401610 	 1000 	 1.252851963043213 	 6.019460678100586 	 3.0279159545898438e-05 	 5.990074396133423 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:39:25.052378 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
[Prof] paddle.nn.functional.multi_margin_loss 	 paddle.nn.functional.multi_margin_loss(Tensor([5, 5080321],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, ) 	 25401610 	 1000 	 1.2735364437103271 	 6.024152040481567 	 1.8596649169921875e-05 	 3.0781519412994385 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:39:36.503781 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="mean", name=None, ) 	 25443143 	 1000 	 0.028285503387451172 	 0.042504072189331055 	 2.09808349609375e-05 	 6.842613220214844e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:39:41.389831 test begin: paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, )
[Prof] paddle.nn.functional.nll_loss 	 paddle.nn.functional.nll_loss(Tensor([5, 40643, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([40643],"float64"), ignore_index=-100, reduction="none", name=None, ) 	 25443143 	 1000 	 0.029356002807617188 	 0.025269508361816406 	 2.3365020751953125e-05 	 4.982948303222656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 19:39:42.216085 test begin: paddle.nn.functional.normalize(Tensor([2009, 25288],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2009, 25288],"float32"), ) 	 50803592 	 1000 	 0.4778447151184082 	 0.46916866302490234 	 0.09708189964294434 	 0.15973782539367676 	 2.68042254447937 	 3.2003281116485596 	 0.5487015247344971 	 0.23359036445617676 	 
2025-07-30 19:39:51.293486 test begin: paddle.nn.functional.normalize(Tensor([2081, 24413],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2081, 24413],"float32"), ) 	 50803453 	 1000 	 0.4765019416809082 	 0.4708375930786133 	 0.09747719764709473 	 0.1603386402130127 	 2.682880163192749 	 3.2019381523132324 	 0.5491456985473633 	 0.23371100425720215 	 
2025-07-30 19:39:59.727776 test begin: paddle.nn.functional.normalize(Tensor([2331, 21795],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([2331, 21795],"float32"), ) 	 50804145 	 1000 	 0.47142624855041504 	 0.47039031982421875 	 0.09633517265319824 	 0.16016793251037598 	 2.6907176971435547 	 3.201799154281616 	 0.5508224964141846 	 0.2337179183959961 	 
2025-07-30 19:40:08.247481 test begin: paddle.nn.functional.normalize(Tensor([99226, 512],"float32"), )
[Prof] paddle.nn.functional.normalize 	 paddle.nn.functional.normalize(Tensor([99226, 512],"float32"), ) 	 50803712 	 1000 	 0.48855137825012207 	 0.46758079528808594 	 0.09990668296813965 	 0.15921974182128906 	 2.709882974624634 	 3.211442708969116 	 0.5546870231628418 	 0.23440074920654297 	 
2025-07-30 19:40:16.782393 test begin: paddle.nn.functional.npair_loss(Tensor([18, 2822401],"float32"), positive=Tensor([18, 2822401],"float32"), labels=Tensor([18],"float32"), l2_reg=0.002, )
[Prof] paddle.nn.functional.npair_loss 	 paddle.nn.functional.npair_loss(Tensor([18, 2822401],"float32"), positive=Tensor([18, 2822401],"float32"), labels=Tensor([18],"float32"), l2_reg=0.002, ) 	 101606454 	 1000 	 1.4830560684204102 	 1.4157500267028809 	 0.0632779598236084 	 0.07203817367553711 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 19:40:28.584673 test begin: paddle.nn.functional.pad(Tensor([7573, 11, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7573, 11, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 106627840 	 1000 	 1.235377311706543 	 0.46943020820617676 	 1.223989725112915 	 0.15960907936096191 	 0.9860129356384277 	 0.8024446964263916 	 0.9289617538452148 	 0.2730867862701416 	 
2025-07-30 19:40:37.878606 test begin: paddle.nn.functional.pad(Tensor([7573, 8, 1678],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7573, 8, 1678],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 101659952 	 1000 	 1.1866531372070312 	 0.4474313259124756 	 1.1669235229492188 	 0.1523745059967041 	 0.9404091835021973 	 0.7653944492340088 	 0.8850002288818359 	 0.2604634761810303 	 
2025-07-30 19:40:45.974452 test begin: paddle.nn.functional.pad(Tensor([7710, 11, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7710, 11, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 108556800 	 1000 	 1.2575843334197998 	 0.4769408702850342 	 1.2460782527923584 	 0.16238832473754883 	 1.0041351318359375 	 0.8163511753082275 	 0.9391002655029297 	 0.2778301239013672 	 
2025-07-30 19:40:53.252059 test begin: paddle.nn.functional.pad(Tensor([7710, 8, 1648],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([7710, 8, 1648],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 101648640 	 1000 	 1.1782503128051758 	 0.44706034660339355 	 1.1665732860565186 	 0.15222477912902832 	 0.9402487277984619 	 0.7649576663970947 	 0.884711742401123 	 0.2603490352630615 	 
2025-07-30 19:40:59.850411 test begin: paddle.nn.functional.pad(Tensor([8162, 10, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([8162, 10, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 104473600 	 1000 	 1.2115273475646973 	 1.235698938369751 	 1.2003624439239502 	 0.15658926963806152 	 0.9662172794342041 	 0.7867474555969238 	 0.90102219581604 	 0.2677292823791504 	 
2025-07-30 19:41:11.167833 test begin: paddle.nn.functional.pad(Tensor([8162, 8, 1557],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([8162, 8, 1557],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 101665872 	 1000 	 1.1781039237976074 	 0.4476172924041748 	 1.166538953781128 	 0.15240001678466797 	 0.9409017562866211 	 0.7655916213989258 	 0.8849570751190186 	 0.2605416774749756 	 
2025-07-30 19:41:17.677653 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,2,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1776306629180908 	 0.4445202350616455 	 1.1660630702972412 	 0.22699284553527832 	 0.9400670528411865 	 0.7620508670806885 	 0.8842651844024658 	 0.3893551826477051 	 
2025-07-30 19:41:24.359913 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,3,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1809179782867432 	 0.46306657791137695 	 1.1662492752075195 	 0.22705459594726562 	 0.9399881362915039 	 0.7620890140533447 	 0.8841590881347656 	 0.3893876075744629 	 
2025-07-30 19:41:33.730175 test begin: paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, )
[Prof] paddle.nn.functional.pad 	 paddle.nn.functional.pad(Tensor([9923, 8, 1280],"bfloat16"), list[0,6,0,0,0,0,], mode="constant", value=0, ) 	 101611520 	 1000 	 1.1886041164398193 	 0.44727182388305664 	 1.1662259101867676 	 0.2270512580871582 	 0.9398765563964844 	 0.7621848583221436 	 0.8840906620025635 	 0.3894045352935791 	 
2025-07-30 19:41:42.862573 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, False, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, False, None, ) 	 101606600 	 1000 	 1.1408660411834717 	 1.06221604347229 	 0.19397735595703125 	 0.271207332611084 	 1.8942575454711914 	 2.775271415710449 	 0.9679508209228516 	 0.2836461067199707 	 
2025-07-30 19:41:51.341539 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, True, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([100, 508033],"float32"), Tensor([100, 508033],"float32"), -1, 1e-06, True, None, ) 	 101606600 	 1000 	 1.1401498317718506 	 1.0618741512298584 	 0.19381332397460938 	 0.27114295959472656 	 1.8946683406829834 	 2.7749290466308594 	 0.9681243896484375 	 0.28357553482055664 	 
2025-07-30 19:41:59.919929 test begin: paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, False, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, False, None, ) 	 101606600 	 1000 	 1.5242595672607422 	 1.6449759006500244 	 0.31173181533813477 	 0.560093879699707 	 1.9806184768676758 	 2.7859909534454346 	 1.0120701789855957 	 0.2847602367401123 	 
2025-07-30 19:42:09.471758 test begin: paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, True, None, )
[Prof] paddle.nn.functional.pairwise_distance 	 paddle.nn.functional.pairwise_distance(Tensor([508033, 100],"float32"), Tensor([508033, 100],"float32"), -1, 1e-06, True, None, ) 	 101606600 	 1000 	 1.524261474609375 	 1.643667459487915 	 0.31172728538513184 	 0.5600767135620117 	 1.9801256656646729 	 2.7860307693481445 	 1.0117888450622559 	 0.28471803665161133 	 
2025-07-30 19:42:19.075985 test begin: paddle.nn.functional.pixel_shuffle(Tensor([13, 256, 128, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([13, 256, 128, 128],"float32"), 2, "NCHW", None, ) 	 54525952 	 1000 	 0.41079020500183105 	 0.35152602195739746 	 0.38921499252319336 	 0.32497429847717285 	 0.39540529251098633 	 0.3428945541381836 	 0.33379602432250977 	 0.26653575897216797 	 
2025-07-30 19:42:22.370276 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 128, 388],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 128, 388],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.37552332878112793 	 0.3334329128265381 	 0.36572813987731934 	 0.31488513946533203 	 0.4007716178894043 	 0.3265697956085205 	 0.34853506088256836 	 0.25026631355285645 	 
2025-07-30 19:42:25.457202 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 388, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 256, 388, 128],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.38360023498535156 	 0.3338789939880371 	 0.3737678527832031 	 0.31507158279418945 	 0.4001576900482178 	 0.322282075881958 	 0.34781503677368164 	 0.24085521697998047 	 
2025-07-30 19:42:28.552923 test begin: paddle.nn.functional.pixel_shuffle(Tensor([4, 776, 128, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([4, 776, 128, 128],"float32"), 2, "NCHW", None, ) 	 50855936 	 1000 	 0.37785768508911133 	 0.328341007232666 	 0.3680274486541748 	 0.3068196773529053 	 0.36750364303588867 	 0.3202362060546875 	 0.31519246101379395 	 0.24365806579589844 	 
2025-07-30 19:42:31.578360 test begin: paddle.nn.functional.pixel_shuffle(Tensor([49, 256, 64, 64],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([49, 256, 64, 64],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.38549017906188965 	 0.34497857093811035 	 0.3742187023162842 	 0.30947279930114746 	 0.3634188175201416 	 0.3275303840637207 	 0.3110957145690918 	 0.25187158584594727 	 
2025-07-30 19:42:36.315437 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 128, 25],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 128, 25],"float32"), 2, "NCHW", None, ) 	 52428800 	 1000 	 1.3542203903198242 	 1.10414719581604 	 0.3685476779937744 	 0.319659948348999 	 0.3896903991699219 	 0.34145569801330566 	 0.3259432315826416 	 0.25140810012817383 	 
2025-07-30 19:42:44.673375 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 25, 128],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 25, 128],"float32"), 2, "NCHW", None, ) 	 52428800 	 1000 	 0.3936808109283447 	 0.3387024402618408 	 0.38379573822021484 	 0.32005906105041504 	 0.379439115524292 	 0.32206082344055176 	 0.32715368270874023 	 0.247114896774292 	 
2025-07-30 19:42:47.801531 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 49, 64],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 49, 64],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.3860352039337158 	 0.3427736759185791 	 0.37630772590637207 	 0.31800079345703125 	 0.36543893814086914 	 0.31868457794189453 	 0.31295275688171387 	 0.24300360679626465 	 
2025-07-30 19:42:50.964575 test begin: paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 64, 49],"float32"), 2, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_shuffle 	 paddle.nn.functional.pixel_shuffle(Tensor([64, 256, 64, 49],"float32"), 2, "NCHW", None, ) 	 51380224 	 1000 	 0.37857842445373535 	 0.331728458404541 	 0.36874866485595703 	 0.312849760055542 	 0.3751659393310547 	 0.3339536190032959 	 0.32241225242614746 	 0.25934720039367676 	 
2025-07-30 19:42:54.119311 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", ) 	 25401744 	 1000 	 0.3176863193511963 	 0.3018643856048584 	 0.30573153495788574 	 0.2830350399017334 	 0.3161144256591797 	 0.3021726608276367 	 0.264188289642334 	 0.22729730606079102 	 
2025-07-30 19:42:56.451964 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([176401, 1, 12, 12],"float64"), 3, "NCHW", None, ) 	 25401744 	 1000 	 0.3188667297363281 	 0.3019101619720459 	 0.3070366382598877 	 0.2829468250274658 	 0.31615424156188965 	 0.30216026306152344 	 0.26421141624450684 	 0.2275400161743164 	 
2025-07-30 19:42:58.747530 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 176401, 12, 12],"float32"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 176401, 12, 12],"float32"), 3, "NCHW", ) 	 50803488 	 1000 	 0.3661668300628662 	 0.32750868797302246 	 0.3557126522064209 	 0.3082308769226074 	 0.3622121810913086 	 0.32271790504455566 	 0.30928897857666016 	 0.24828052520751953 	 
2025-07-30 19:43:01.768312 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", ) 	 25401888 	 1000 	 0.3174912929534912 	 0.3018631935119629 	 0.3069586753845215 	 0.2830214500427246 	 0.316159725189209 	 0.3021845817565918 	 0.26453328132629395 	 0.22722816467285156 	 
2025-07-30 19:43:04.051464 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", None, )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([2, 88201, 12, 12],"float64"), 3, "NCHW", None, ) 	 25401888 	 1000 	 0.31745290756225586 	 0.3018827438354492 	 0.3069136142730713 	 0.28307604789733887 	 0.31619834899902344 	 0.3021411895751953 	 0.2619462013244629 	 0.22221732139587402 	 
2025-07-30 19:43:06.342971 test begin: paddle.nn.functional.pixel_unshuffle(Tensor([352801, 1, 12, 12],"float32"), 3, "NCHW", )
[Prof] paddle.nn.functional.pixel_unshuffle 	 paddle.nn.functional.pixel_unshuffle(Tensor([352801, 1, 12, 12],"float32"), 3, "NCHW", ) 	 50803344 	 1000 	 0.3654050827026367 	 0.32747721672058105 	 0.35506629943847656 	 0.3083982467651367 	 0.36208295822143555 	 0.32274842262268066 	 0.30985045433044434 	 0.24712705612182617 	 
2025-07-30 19:43:09.351058 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"bfloat16"), )
W0730 19:43:12.405714 32084 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"bfloat16"), ) 	 203212812 	 1000 	 3.150120496749878 	 2.593834161758423 	 0.5357797145843506 	 0.5294172763824463 	 5.699411392211914 	 4.809740304946899 	 0.9702451229095459 	 0.702202320098877 	 
2025-07-30 19:43:29.113728 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([16934401, 3, 2],"float32"), Tensor([16934401, 3, 2],"float16"), ) 	 203212812 	 1000 	 3.1488866806030273 	 2.588374376296997 	 0.5355784893035889 	 0.5283446311950684 	 5.701450824737549 	 4.807302474975586 	 0.9705848693847656 	 0.7017958164215088 	 
2025-07-30 19:43:50.679556 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"bfloat16"), ) 	 203212816 	 1000 	 3.1553733348846436 	 2.5927035808563232 	 0.5356318950653076 	 0.5291869640350342 	 5.701695919036865 	 4.8099284172058105 	 0.9706380367279053 	 0.7022037506103516 	 
2025-07-30 19:44:10.718785 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 12700801, 2],"float32"), Tensor([4, 12700801, 2],"float16"), ) 	 203212816 	 1000 	 3.1509180068969727 	 2.5884742736816406 	 0.5356721878051758 	 0.5283534526824951 	 5.700643062591553 	 4.807157754898071 	 0.9704630374908447 	 0.7018425464630127 	 
2025-07-30 19:44:30.670501 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 2116801],"float32"), Tensor([4, 3, 2116801],"float64"), ) 	 50803224 	 1000 	 1.6687400341033936 	 1.0730092525482178 	 0.24366497993469238 	 0.21801114082336426 	 2.2725255489349365 	 2.1706011295318604 	 0.33174824714660645 	 0.277327299118042 	 
2025-07-30 19:44:40.768900 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"bfloat16"), ) 	 101606424 	 1000 	 1.5863432884216309 	 1.3127741813659668 	 0.2698686122894287 	 0.26793336868286133 	 2.863415241241455 	 2.4204232692718506 	 0.48748326301574707 	 0.3533668518066406 	 
2025-07-30 19:44:52.775982 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float16"), ) 	 101606424 	 1000 	 1.5908920764923096 	 1.3107426166534424 	 0.26987314224243164 	 0.2675342559814453 	 2.862617254257202 	 2.4187633991241455 	 0.48725152015686035 	 0.35307955741882324 	 
2025-07-30 19:45:04.300016 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 4233601],"float32"), Tensor([4, 3, 4233601],"float64"), ) 	 101606424 	 1000 	 3.3070976734161377 	 2.1021056175231934 	 0.4828224182128906 	 0.4291112422943115 	 4.51348090171814 	 4.298940658569336 	 0.6589996814727783 	 0.5493762493133545 	 
2025-07-30 19:45:20.576006 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"bfloat16"), ) 	 203212824 	 1000 	 3.1499998569488525 	 2.592719793319702 	 0.5356049537658691 	 0.5292775630950928 	 5.698467254638672 	 4.810149908065796 	 0.9700512886047363 	 0.7022759914398193 	 
2025-07-30 19:45:41.576144 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3, 8467201],"float32"), Tensor([4, 3, 8467201],"float16"), ) 	 203212824 	 1000 	 3.1489737033843994 	 2.589876651763916 	 0.5356428623199463 	 0.5286850929260254 	 5.700619220733643 	 4.8088438510894775 	 0.9705607891082764 	 0.7018556594848633 	 
2025-07-30 19:46:02.583469 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 3175201, 2],"float32"), Tensor([4, 3175201, 2],"float64"), ) 	 50803216 	 1000 	 1.6686956882476807 	 1.068011999130249 	 0.2436356544494629 	 0.21805572509765625 	 2.2725253105163574 	 2.1702115535736084 	 0.3317873477935791 	 0.27731752395629883 	 
2025-07-30 19:46:10.718711 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"bfloat16"), ) 	 101606416 	 1000 	 1.586275339126587 	 1.3140921592712402 	 0.2697937488555908 	 0.26821112632751465 	 2.8633861541748047 	 2.420417547225952 	 0.4874260425567627 	 0.3533589839935303 	 
2025-07-30 19:46:20.522095 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float16"), ) 	 101606416 	 1000 	 1.5861639976501465 	 1.310701608657837 	 0.2698214054107666 	 0.2675199508666992 	 2.8627192974090576 	 2.4186389446258545 	 0.48723602294921875 	 0.3530995845794678 	 
2025-07-30 19:46:30.578877 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4, 6350401, 2],"float32"), Tensor([4, 6350401, 2],"float64"), ) 	 101606416 	 1000 	 3.307062864303589 	 2.105289936065674 	 0.4827907085418701 	 0.4288330078125 	 4.513672590255737 	 4.299000024795532 	 0.6590361595153809 	 0.5494184494018555 	 
2025-07-30 19:46:47.117451 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([4233601, 3, 2],"float32"), Tensor([4233601, 3, 2],"float64"), ) 	 50803212 	 1000 	 1.6688640117645264 	 1.0679922103881836 	 0.2436079978942871 	 0.2180490493774414 	 2.2726972103118896 	 2.1702988147735596 	 0.3317735195159912 	 0.2773420810699463 	 
2025-07-30 19:46:55.338658 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"bfloat16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"bfloat16"), ) 	 101606412 	 1000 	 1.5865778923034668 	 1.3214316368103027 	 0.26978158950805664 	 0.2679612636566162 	 2.8633341789245605 	 2.420444965362549 	 0.4874577522277832 	 0.3533346652984619 	 
2025-07-30 19:47:08.135270 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float16"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float16"), ) 	 101606412 	 1000 	 1.5861730575561523 	 1.311408281326294 	 0.26980137825012207 	 0.26753902435302734 	 2.8628158569335938 	 2.418684482574463 	 0.48740124702453613 	 0.35308337211608887 	 
2025-07-30 19:47:18.170672 test begin: paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), )
[Prof] paddle.nn.functional.poisson_nll_loss 	 paddle.nn.functional.poisson_nll_loss(Tensor([8467201, 3, 2],"float32"), Tensor([8467201, 3, 2],"float64"), ) 	 101606412 	 1000 	 3.306663990020752 	 2.100736618041992 	 0.4829120635986328 	 0.4288935661315918 	 4.513250827789307 	 4.298791885375977 	 0.6589488983154297 	 0.5494041442871094 	 
2025-07-30 19:47:34.424189 test begin: paddle.nn.functional.prelu(Tensor([104, 128, 56, 69],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 128, 56, 69],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51437696 	 1000 	 0.8098025321960449 	 0.31270503997802734 	 0.29210448265075684 	 0.28917360305786133 	 1.1029119491577148 	 0.7966513633728027 	 0.37511157989501953 	 0.2710566520690918 	 
2025-07-30 19:47:41.846868 test begin: paddle.nn.functional.prelu(Tensor([104, 128, 69, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 128, 69, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51437696 	 1000 	 0.30451226234436035 	 0.3126087188720703 	 0.2921473979949951 	 0.29662227630615234 	 1.1001696586608887 	 0.7958817481994629 	 0.3741884231567383 	 0.2706899642944336 	 
2025-07-30 19:47:46.047576 test begin: paddle.nn.functional.prelu(Tensor([104, 156, 56, 56],"float32"), Tensor([156],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([104, 156, 56, 56],"float32"), Tensor([156],"float32"), data_format="NCHW", ) 	 50878620 	 1000 	 0.3038451671600342 	 0.30903148651123047 	 0.2887756824493408 	 0.2931406497955322 	 1.0823020935058594 	 0.7935037612915039 	 0.36814403533935547 	 0.26993584632873535 	 
2025-07-30 19:47:50.238149 test begin: paddle.nn.functional.prelu(Tensor([127, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([127, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 50978944 	 1000 	 0.3046557903289795 	 0.30957865715026855 	 0.2894418239593506 	 0.2935209274291992 	 1.086888313293457 	 0.7874181270599365 	 0.3697073459625244 	 0.26790881156921387 	 
2025-07-30 19:47:54.397699 test begin: paddle.nn.functional.prelu(Tensor([128, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 128, 56, 56],"float32"), Tensor([128],"float32"), data_format="NCHW", ) 	 51380352 	 1000 	 0.30426907539367676 	 0.31193995475769043 	 0.2895674705505371 	 0.29533982276916504 	 1.0941476821899414 	 0.7937922477722168 	 0.3721463680267334 	 0.2700462341308594 	 
2025-07-30 19:47:58.582214 test begin: paddle.nn.functional.prelu(Tensor([128, 256, 28, 56],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 256, 28, 56],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 51380480 	 1000 	 0.30428314208984375 	 0.3119678497314453 	 0.29198169708251953 	 0.2961444854736328 	 1.093827247619629 	 0.7938508987426758 	 0.372020959854126 	 0.2700784206390381 	 
2025-07-30 19:48:02.770117 test begin: paddle.nn.functional.prelu(Tensor([128, 256, 56, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 256, 56, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 51380480 	 1000 	 0.3042457103729248 	 0.31197071075439453 	 0.2918729782104492 	 0.29585909843444824 	 1.093888282775879 	 0.7946710586547852 	 0.37206053733825684 	 0.2702667713165283 	 
2025-07-30 19:48:08.579792 test begin: paddle.nn.functional.prelu(Tensor([128, 507, 28, 28],"float32"), Tensor([507],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([128, 507, 28, 28],"float32"), Tensor([507],"float32"), data_format="NCHW", ) 	 50878971 	 1000 	 0.7826516628265381 	 0.30904340744018555 	 0.2885429859161377 	 0.29313182830810547 	 1.0740818977355957 	 0.7802503108978271 	 0.36531734466552734 	 0.39865541458129883 	 
2025-07-30 19:48:13.611268 test begin: paddle.nn.functional.prelu(Tensor([254, 256, 28, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", )
[Prof] paddle.nn.functional.prelu 	 paddle.nn.functional.prelu(Tensor([254, 256, 28, 28],"float32"), Tensor([256],"float32"), data_format="NCHW", ) 	 50979072 	 1000 	 0.3018219470977783 	 0.3096165657043457 	 0.28166842460632324 	 0.2862834930419922 	 1.0874249935150146 	 0.7896127700805664 	 0.369830846786499 	 0.2686333656311035 	 
2025-07-30 19:48:17.819041 test begin: paddle.nn.functional.relu(Tensor([10, 128, 480, 83],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 128, 480, 83],"float32"), None, ) 	 50995200 	 1000 	 0.2968425750732422 	 0.2989051342010498 	 0.28824496269226074 	 0.2749171257019043 	 0.45195770263671875 	 0.4484226703643799 	 0.3981492519378662 	 0.37947893142700195 	 
2025-07-30 19:48:20.965557 test begin: paddle.nn.functional.relu(Tensor([10, 128, 83, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 128, 83, 480],"float32"), None, ) 	 50995200 	 1000 	 0.2968273162841797 	 0.29886865615844727 	 0.28827810287475586 	 0.28291988372802734 	 0.4518711566925049 	 0.4483616352081299 	 0.39846253395080566 	 0.3797752857208252 	 
2025-07-30 19:48:24.142757 test begin: paddle.nn.functional.relu(Tensor([10, 23, 480, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([10, 23, 480, 480],"float32"), None, ) 	 52992000 	 1000 	 0.3081343173980713 	 0.3105030059814453 	 0.2993490695953369 	 0.2944495677947998 	 0.4698212146759033 	 0.4658668041229248 	 0.4153163433074951 	 0.37539219856262207 	 
2025-07-30 19:48:27.485427 test begin: paddle.nn.functional.relu(Tensor([2, 128, 480, 480],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([2, 128, 480, 480],"float32"), None, ) 	 58982400 	 1000 	 0.3443734645843506 	 0.34487295150756836 	 0.33405351638793945 	 0.3290576934814453 	 0.5219204425811768 	 0.5178601741790771 	 0.4683802127838135 	 0.44933605194091797 	 
2025-07-30 19:48:31.136975 test begin: paddle.nn.functional.relu(Tensor([2, 256, 352, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([2, 256, 352, 352],"float32"), ) 	 63438848 	 1000 	 0.3686258792877197 	 0.3704538345336914 	 0.3599586486816406 	 0.35448336601257324 	 0.5608184337615967 	 0.5566501617431641 	 0.507457971572876 	 0.48787474632263184 	 
2025-07-30 19:48:35.056283 test begin: paddle.nn.functional.relu(Tensor([64, 64, 112, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([64, 64, 112, 112],"float32"), None, ) 	 51380224 	 1000 	 0.8012082576751709 	 0.306793212890625 	 0.29046130180358887 	 0.2850348949432373 	 0.45539331436157227 	 0.4517209529876709 	 0.40116381645202637 	 0.3835270404815674 	 
2025-07-30 19:48:39.977214 test begin: paddle.nn.functional.relu(Tensor([640, 64, 112, 12],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 64, 112, 12],"float32"), None, ) 	 55050240 	 1000 	 0.3200507164001465 	 0.3222188949584961 	 0.31146788597106934 	 0.30657458305358887 	 0.4876692295074463 	 0.48357558250427246 	 0.4321887493133545 	 0.41548585891723633 	 
2025-07-30 19:48:43.410772 test begin: paddle.nn.functional.relu(Tensor([640, 64, 12, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 64, 12, 112],"float32"), None, ) 	 55050240 	 1000 	 0.32004261016845703 	 0.3231008052825928 	 0.3115098476409912 	 0.30644702911376953 	 0.48751378059387207 	 0.4836277961730957 	 0.43422770500183105 	 0.4153711795806885 	 
2025-07-30 19:48:46.801318 test begin: paddle.nn.functional.relu(Tensor([640, 7, 112, 112],"float32"), None, )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([640, 7, 112, 112],"float32"), None, ) 	 56197120 	 1000 	 0.33051443099975586 	 0.3288257122039795 	 0.3180828094482422 	 0.31279969215393066 	 0.4975395202636719 	 0.4936184883117676 	 0.4437143802642822 	 0.42493677139282227 	 
2025-07-30 19:48:50.268719 test begin: paddle.nn.functional.relu(Tensor([8, 256, 352, 71],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 256, 352, 71],"float32"), ) 	 51183616 	 1000 	 0.29854512214660645 	 0.2999246120452881 	 0.2893402576446533 	 0.28401708602905273 	 0.4535963535308838 	 0.4500119686126709 	 0.40015077590942383 	 0.38222265243530273 	 
2025-07-30 19:48:53.458587 test begin: paddle.nn.functional.relu(Tensor([8, 256, 71, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 256, 71, 352],"float32"), ) 	 51183616 	 1000 	 0.29793310165405273 	 0.29993104934692383 	 0.28939175605773926 	 0.28412938117980957 	 0.4535491466522217 	 0.4499931335449219 	 0.40065717697143555 	 0.3821413516998291 	 
2025-07-30 19:48:56.597634 test begin: paddle.nn.functional.relu(Tensor([8, 52, 352, 352],"float32"), )
[Prof] paddle.nn.functional.relu 	 paddle.nn.functional.relu(Tensor([8, 52, 352, 352],"float32"), ) 	 51544064 	 1000 	 0.30005383491516113 	 0.3056600093841553 	 0.29160046577453613 	 0.28591275215148926 	 0.4566366672515869 	 0.45307350158691406 	 0.4035806655883789 	 0.38376927375793457 	 
2025-07-30 19:48:59.772686 test begin: paddle.nn.functional.relu6(Tensor([128, 144, 112, 25],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 144, 112, 25],"float32"), ) 	 51609600 	 1000 	 0.300412654876709 	 0.30243897438049316 	 0.28769731521606445 	 0.28351879119873047 	 0.4572291374206543 	 0.4538121223449707 	 0.40401244163513184 	 0.3856544494628906 	 
2025-07-30 19:49:02.989252 test begin: paddle.nn.functional.relu6(Tensor([128, 144, 25, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 144, 25, 112],"float32"), ) 	 51609600 	 1000 	 0.3004467487335205 	 0.30243444442749023 	 0.28484153747558594 	 0.27565979957580566 	 0.45720982551574707 	 0.45368075370788574 	 0.39520716667175293 	 0.3785688877105713 	 
2025-07-30 19:49:06.309077 test begin: paddle.nn.functional.relu6(Tensor([128, 192, 112, 19],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 192, 112, 19],"float32"), ) 	 52297728 	 1000 	 0.30416154861450195 	 0.30643200874328613 	 0.29544496536254883 	 0.2878713607788086 	 0.4633655548095703 	 0.45963430404663086 	 0.4107091426849365 	 0.3925032615661621 	 
2025-07-30 19:49:09.538463 test begin: paddle.nn.functional.relu6(Tensor([128, 192, 19, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 192, 19, 112],"float32"), ) 	 52297728 	 1000 	 0.30425143241882324 	 0.9753556251525879 	 0.29549288749694824 	 0.2877163887023926 	 0.4634263515472412 	 0.4596841335296631 	 0.410412073135376 	 0.3850693702697754 	 
2025-07-30 19:49:15.506568 test begin: paddle.nn.functional.relu6(Tensor([128, 32, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([128, 32, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.3001883029937744 	 0.3011598587036133 	 0.29045534133911133 	 0.28046727180480957 	 0.4552881717681885 	 0.4516901969909668 	 0.40232324600219727 	 0.38463854789733887 	 
2025-07-30 19:49:18.689723 test begin: paddle.nn.functional.relu6(Tensor([22, 192, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([22, 192, 112, 112],"float32"), ) 	 52985856 	 1000 	 0.3080742359161377 	 0.31043004989624023 	 0.29937028884887695 	 0.2913377285003662 	 0.4694037437438965 	 0.4655611515045166 	 0.41675424575805664 	 0.3979148864746094 	 
2025-07-30 19:49:21.955175 test begin: paddle.nn.functional.relu6(Tensor([256, 16, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 16, 112, 112],"float32"), ) 	 51380224 	 1000 	 0.2991666793823242 	 0.3011038303375244 	 0.29047250747680664 	 0.28237223625183105 	 0.45529985427856445 	 0.4516623020172119 	 0.4024808406829834 	 0.38407039642333984 	 
2025-07-30 19:49:25.134811 test begin: paddle.nn.functional.relu6(Tensor([256, 96, 112, 19],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 96, 112, 19],"float32"), ) 	 52297728 	 1000 	 0.30571961402893066 	 0.3064398765563965 	 0.2953066825866699 	 0.2879221439361572 	 0.4633772373199463 	 0.459644079208374 	 0.4106411933898926 	 0.3925173282623291 	 
2025-07-30 19:49:28.362340 test begin: paddle.nn.functional.relu6(Tensor([256, 96, 19, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([256, 96, 19, 112],"float32"), ) 	 52297728 	 1000 	 0.30421018600463867 	 0.3064076900482178 	 0.2955188751220703 	 0.28793907165527344 	 0.4632761478424072 	 0.4596595764160156 	 0.4102823734283447 	 0.39232563972473145 	 
2025-07-30 19:49:31.562169 test begin: paddle.nn.functional.relu6(Tensor([29, 144, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([29, 144, 112, 112],"float32"), ) 	 52383744 	 1000 	 0.30466461181640625 	 0.3162519931793213 	 0.2890479564666748 	 0.2803165912628174 	 0.46404170989990234 	 0.46045351028442383 	 0.4018523693084717 	 0.38594579696655273 	 
2025-07-30 19:49:34.830394 test begin: paddle.nn.functional.relu6(Tensor([43, 96, 112, 112],"float32"), )
[Prof] paddle.nn.functional.relu6 	 paddle.nn.functional.relu6(Tensor([43, 96, 112, 112],"float32"), ) 	 51781632 	 1000 	 1.1890103816986084 	 0.30546069145202637 	 0.2855098247528076 	 0.28476810455322266 	 0.4589066505432129 	 0.4551234245300293 	 0.39240574836730957 	 0.3874807357788086 	 
2025-07-30 19:49:40.493256 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 4233601],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2, 3, 4233601],"float64"), 0.05, 0.25, training=False, ) 	 25401606 	 1000 	 0.48232245445251465 	 0.2988467216491699 	 0.47205567359924316 	 0.2761261463165283 	 0.584169864654541 	 0.44320011138916016 	 0.5318045616149902 	 0.3752329349517822 	 
2025-07-30 19:49:43.369225 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3175201, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2, 3175201, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401608 	 1000 	 0.48226261138916016 	 0.2987985610961914 	 0.4650440216064453 	 0.26748013496398926 	 0.5841631889343262 	 0.44321537017822266 	 0.5227181911468506 	 0.3682892322540283 	 
2025-07-30 19:49:46.238060 test begin: paddle.nn.functional.rrelu(Tensor([1, 2116801, 3, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1, 2116801, 3, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401612 	 1000 	 0.48232412338256836 	 0.2987527847290039 	 0.4650707244873047 	 0.2674524784088135 	 0.584132194519043 	 0.4431333541870117 	 0.5225939750671387 	 0.36849212646484375 	 
2025-07-30 19:49:49.123904 test begin: paddle.nn.functional.rrelu(Tensor([1058401, 2, 3, 4],"float64"), 0.05, 0.25, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([1058401, 2, 3, 4],"float64"), 0.05, 0.25, training=False, ) 	 25401624 	 1000 	 0.48226189613342285 	 0.29877567291259766 	 0.46494603157043457 	 0.26754164695739746 	 0.5841410160064697 	 0.443218469619751 	 0.5230414867401123 	 0.36856794357299805 	 
2025-07-30 19:49:52.027252 test begin: paddle.nn.functional.rrelu(Tensor([2, 1270081, 4, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 1270081, 4, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803240 	 1000 	 0.4916799068450928 	 0.29823851585388184 	 0.4745616912841797 	 0.26679348945617676 	 0.603316068649292 	 0.44661712646484375 	 0.5416111946105957 	 0.34582042694091797 	 
2025-07-30 19:49:55.492776 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 1693441, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 1693441, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803230 	 1000 	 0.4916958808898926 	 0.29803967475891113 	 0.4746086597442627 	 0.266965389251709 	 0.6030383110046387 	 0.44652247428894043 	 0.5417633056640625 	 0.37186098098754883 	 
2025-07-30 19:49:58.985377 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 1058401],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 4, 1058401],"float64"), 0.1, 0.3, training=False, ) 	 25401624 	 1000 	 0.48224639892578125 	 0.2986888885498047 	 0.4723207950592041 	 0.27623653411865234 	 0.5841169357299805 	 0.4431793689727783 	 0.5317275524139404 	 0.36382007598876953 	 
2025-07-30 19:50:01.844492 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 2116801],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 4, 2116801],"float32"), 0.1, 0.3, training=False, ) 	 50803224 	 1000 	 0.4917469024658203 	 0.29805564880371094 	 0.4816153049468994 	 0.2758462429046631 	 0.6030728816986084 	 0.4465615749359131 	 0.5501534938812256 	 0.3781561851501465 	 
2025-07-30 19:50:05.324463 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 846721, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 3, 846721, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401630 	 1000 	 0.4822967052459717 	 0.29877519607543945 	 0.4722437858581543 	 0.26647520065307617 	 0.5841667652130127 	 0.4432249069213867 	 0.5226290225982666 	 0.35172080993652344 	 
2025-07-30 19:50:08.107900 test begin: paddle.nn.functional.rrelu(Tensor([2, 635041, 4, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([2, 635041, 4, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401640 	 1000 	 0.48191356658935547 	 0.29879307746887207 	 0.47188448905944824 	 0.276522159576416 	 0.5841028690338135 	 0.44313907623291016 	 0.5320980548858643 	 0.3757307529449463 	 
2025-07-30 19:50:11.007342 test begin: paddle.nn.functional.rrelu(Tensor([423361, 3, 4, 5],"float64"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([423361, 3, 4, 5],"float64"), 0.1, 0.3, training=False, ) 	 25401660 	 1000 	 0.48181891441345215 	 0.3003878593444824 	 0.4717543125152588 	 0.2763783931732178 	 0.5841269493103027 	 0.4433121681213379 	 0.53179931640625 	 0.28122997283935547 	 
2025-07-30 19:50:13.895870 test begin: paddle.nn.functional.rrelu(Tensor([846721, 3, 4, 5],"float32"), 0.1, 0.3, training=False, )
[Prof] paddle.nn.functional.rrelu 	 paddle.nn.functional.rrelu(Tensor([846721, 3, 4, 5],"float32"), 0.1, 0.3, training=False, ) 	 50803260 	 1000 	 0.4917275905609131 	 0.31258654594421387 	 0.48168349266052246 	 0.27594423294067383 	 0.6030621528625488 	 0.44655919075012207 	 0.5510299205780029 	 0.37192845344543457 	 
2025-07-30 19:50:20.642605 test begin: paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.2997128963470459 	 1.8278963565826416 	 0.2837049961090088 	 0.31108522415161133 	 0.4480431079864502 	 2.124269723892212 	 0.38193321228027344 	 0.27159643173217773 	 
2025-07-30 19:50:26.455016 test begin: paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([101607, 5, 5, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.30149102210998535 	 1.826002836227417 	 0.2826852798461914 	 0.3112461566925049 	 0.4476196765899658 	 2.124239921569824 	 0.38726377487182617 	 0.27160167694091797 	 
2025-07-30 19:50:32.207547 test begin: paddle.nn.functional.selu(Tensor([2822401, 3, 3],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([2822401, 3, 3],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.29974794387817383 	 1.825549602508545 	 0.28356480598449707 	 0.31110715866088867 	 0.4480302333831787 	 2.1243889331817627 	 0.38724851608276367 	 0.2715926170349121 	 
2025-07-30 19:50:40.059488 test begin: paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.3029146194458008 	 1.825819492340088 	 0.28317952156066895 	 0.31113767623901367 	 0.4477066993713379 	 2.1242568492889404 	 0.3846287727355957 	 0.27161622047424316 	 
2025-07-30 19:50:45.834843 test begin: paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 169345, 5, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.29967355728149414 	 1.825784683227539 	 0.29074597358703613 	 0.31121110916137695 	 0.4481081962585449 	 2.124250888824463 	 0.3966028690338135 	 0.271587610244751 	 
2025-07-30 19:50:51.593442 test begin: paddle.nn.functional.selu(Tensor([3, 2822401, 3],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 2822401, 3],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.2997441291809082 	 1.8260490894317627 	 0.2908318042755127 	 0.3111591339111328 	 0.4481186866760254 	 2.1244916915893555 	 0.3964548110961914 	 0.27161526679992676 	 
2025-07-30 19:50:57.396573 test begin: paddle.nn.functional.selu(Tensor([3, 3, 2822401],"float64"), 1.0507009873554805, 0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 3, 2822401],"float64"), 1.0507009873554805, 0, None, ) 	 25401609 	 1000 	 0.30301403999328613 	 1.8259778022766113 	 0.29066014289855957 	 0.31122660636901855 	 0.447399377822876 	 2.1245977878570557 	 0.3964054584503174 	 0.27158570289611816 	 
2025-07-30 19:51:03.296105 test begin: paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, ) 	 25401750 	 1000 	 0.2996962070465088 	 1.826704978942871 	 0.2909691333770752 	 0.31123900413513184 	 0.4480299949645996 	 2.1245625019073486 	 0.39638400077819824 	 0.27161240577697754 	 
2025-07-30 19:51:10.690556 test begin: paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 169345, 10],"float64"), 1.5, 2.0, None, ) 	 25401750 	 1000 	 0.2996988296508789 	 1.825706958770752 	 0.29095029830932617 	 0.3111701011657715 	 0.4478902816772461 	 2.1242239475250244 	 0.3939034938812256 	 0.271575927734375 	 
2025-07-30 19:51:16.447249 test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, ) 	 25401675 	 1000 	 0.30082035064697266 	 1.8255956172943115 	 0.2886924743652344 	 0.31107068061828613 	 0.44799351692199707 	 2.1242270469665527 	 0.39665818214416504 	 0.2715890407562256 	 
2025-07-30 19:51:23.305875 test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, None, )
[Prof] paddle.nn.functional.selu 	 paddle.nn.functional.selu(Tensor([3, 5, 5, 338689],"float64"), 1.5, 2.0, None, ) 	 25401675 	 1000 	 1.0624687671661377 	 1.8257813453674316 	 0.2912294864654541 	 0.31119728088378906 	 0.4473550319671631 	 2.1242830753326416 	 0.39579153060913086 	 0.27156877517700195 	 
2025-07-30 19:51:30.879315 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 705601],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 705601],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7784950733184814 	 1.4818241596221924 	 0.7669012546539307 	 0.5052139759063721 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:51:33.680433 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 705601, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 705601, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 0.7794158458709717 	 1.4824655055999756 	 0.7669780254364014 	 0.5051677227020264 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:51:37.481601 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 2, 705601, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 2, 705601, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401636 	 1000 	 1.4986741542816162 	 1.4895026683807373 	 0.7668311595916748 	 0.5052018165588379 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:51:41.915280 test begin: paddle.nn.functional.sequence_mask(Tensor([2, 470401, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([2, 470401, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401654 	 1000 	 0.7784159183502197 	 1.499117136001587 	 0.7669661045074463 	 0.5051734447479248 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:51:44.747396 test begin: paddle.nn.functional.sequence_mask(Tensor([470401, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([470401, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), ) 	 25401654 	 1000 	 0.7785496711730957 	 1.4820497035980225 	 0.7588238716125488 	 0.5052807331085205 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:51:47.588769 test begin: paddle.nn.functional.sequence_mask(Tensor([50803201],"int32"), maxlen=4, dtype="float32", )
[Prof] paddle.nn.functional.sequence_mask 	 paddle.nn.functional.sequence_mask(Tensor([50803201],"int32"), maxlen=4, dtype="float32", ) 	 50803201 	 1000 	 1.2108325958251953 	 2.424962043762207 	 1.1990506649017334 	 0.8266100883483887 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:51:52.329237 test begin: paddle.nn.functional.sigmoid(Tensor([10, 32, 400, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([10, 32, 400, 400],"float32"), ) 	 51200000 	 1000 	 0.2971954345703125 	 0.3006134033203125 	 0.2886333465576172 	 0.2894630432128906 	 0.45371389389038086 	 0.45009565353393555 	 0.4000263214111328 	 0.381915807723999 	 
2025-07-30 19:51:55.532259 test begin: paddle.nn.functional.sigmoid(Tensor([364, 304, 460],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([364, 304, 460],"float32"), ) 	 50901760 	 1000 	 0.2955949306488037 	 0.3017878532409668 	 0.27984619140625 	 0.28107213973999023 	 0.45101451873779297 	 0.44751453399658203 	 0.38858985900878906 	 0.35897088050842285 	 
2025-07-30 19:51:58.738150 test begin: paddle.nn.functional.sigmoid(Tensor([364, 416, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([364, 416, 336],"float32"), ) 	 50878464 	 1000 	 0.2953944206237793 	 0.29871177673339844 	 0.279620885848999 	 0.28090429306030273 	 0.45077943801879883 	 0.44728684425354004 	 0.3879404067993164 	 0.3718280792236328 	 
2025-07-30 19:52:01.916696 test begin: paddle.nn.functional.sigmoid(Tensor([372, 304, 450],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([372, 304, 450],"float32"), ) 	 50889600 	 1000 	 0.2955756187438965 	 0.29876708984375 	 0.2796955108642578 	 0.2810349464416504 	 0.4508786201477051 	 0.447406530380249 	 0.38874363899230957 	 0.3726010322570801 	 
2025-07-30 19:52:05.038041 test begin: paddle.nn.functional.sigmoid(Tensor([372, 407, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([372, 407, 336],"float32"), ) 	 50871744 	 1000 	 0.29538846015930176 	 0.2986743450164795 	 0.27955031394958496 	 0.28105950355529785 	 0.45084166526794434 	 0.4472055435180664 	 0.3884925842285156 	 0.37259960174560547 	 
2025-07-30 19:52:08.151931 test begin: paddle.nn.functional.sigmoid(Tensor([498, 304, 336],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([498, 304, 336],"float32"), ) 	 50867712 	 1000 	 0.29723477363586426 	 0.2986900806427002 	 0.27934813499450684 	 0.2810218334197998 	 0.4507901668548584 	 0.4471876621246338 	 0.384793758392334 	 0.3717496395111084 	 
2025-07-30 19:52:11.275462 test begin: paddle.nn.functional.sigmoid(Tensor([8, 32, 400, 497],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 32, 400, 497],"float32"), ) 	 50892800 	 1000 	 0.29695868492126465 	 0.2987949848175049 	 0.27971911430358887 	 0.28106093406677246 	 0.4509282112121582 	 0.44739603996276855 	 0.38861584663391113 	 0.37188720703125 	 
2025-07-30 19:52:14.451260 test begin: paddle.nn.functional.sigmoid(Tensor([8, 32, 497, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 32, 497, 400],"float32"), ) 	 50892800 	 1000 	 0.2954885959625244 	 0.2988317012786865 	 0.27971863746643066 	 0.28107357025146484 	 0.4510011672973633 	 0.44739341735839844 	 0.38771510124206543 	 0.374239444732666 	 
2025-07-30 19:52:17.587353 test begin: paddle.nn.functional.sigmoid(Tensor([8, 40, 400, 400],"float32"), )
[Prof] paddle.nn.functional.sigmoid 	 paddle.nn.functional.sigmoid(Tensor([8, 40, 400, 400],"float32"), ) 	 51200000 	 1000 	 0.29718852043151855 	 0.3023686408996582 	 0.27910757064819336 	 0.28205299377441406 	 0.4536886215209961 	 0.4501073360443115 	 0.38796496391296387 	 0.3789708614349365 	 
2025-07-30 19:52:20.729729 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803248 	 1000 	 6.903697729110718 	 5.646468162536621 	 0.0006604194641113281 	 0.30344080924987793 	 9.25638723373413 	 9.165089130401611 	 0.41155028343200684 	 0.37468528747558594 	 combined
2025-07-30 19:52:54.615127 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803249 	 1000 	 7.20363712310791 	 5.93951940536499 	 0.0009732246398925781 	 0.30310821533203125 	 10.011929512023926 	 10.961952686309814 	 0.3936164379119873 	 0.35036778450012207 	 combined
2025-07-30 19:53:29.800385 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 1058401],"float64"), Tensor([2, 3, 4, 1058401],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803249 	 1000 	 7.202758073806763 	 5.939434766769409 	 0.0009779930114746094 	 0.3030259609222412 	 10.016162395477295 	 10.962196350097656 	 0.39370083808898926 	 0.35031628608703613 	 combined
2025-07-30 19:54:05.618120 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803320 	 1000 	 6.905172348022461 	 5.6389710903167725 	 0.0006804466247558594 	 0.30329465866088867 	 9.258964538574219 	 9.166471242904663 	 0.41169166564941406 	 0.37470221519470215 	 combined
2025-07-30 19:54:38.832659 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803321 	 1000 	 7.198748588562012 	 5.939247369766235 	 0.0009810924530029297 	 0.30306458473205566 	 10.01737666130066 	 10.962484359741211 	 0.39377355575561523 	 0.3503437042236328 	 combined
2025-07-30 19:55:14.506722 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 423361, 10],"float64"), Tensor([2, 3, 423361, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803321 	 1000 	 7.198271036148071 	 5.939785480499268 	 0.0009834766387939453 	 0.30303287506103516 	 10.013936996459961 	 10.963050365447998 	 0.39368224143981934 	 0.35038089752197266 	 combined
2025-07-30 19:55:49.660283 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803360 	 1000 	 6.9768226146698 	 5.6388537883758545 	 0.0006892681121826172 	 0.30335402488708496 	 9.256793737411499 	 9.164987564086914 	 0.4115614891052246 	 0.37466979026794434 	 combined
2025-07-30 19:56:22.947185 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803361 	 1000 	 7.200500965118408 	 5.951953887939453 	 0.0009818077087402344 	 0.30303096771240234 	 10.01503586769104 	 10.962814807891846 	 0.3936805725097656 	 0.35033416748046875 	 combined
2025-07-30 19:56:58.271227 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 317521, 4, 10],"float64"), Tensor([2, 317521, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803361 	 1000 	 7.1971752643585205 	 5.939084053039551 	 0.0009744167327880859 	 0.3030080795288086 	 10.016912937164307 	 10.96241569519043 	 0.3937985897064209 	 0.3503153324127197 	 combined
2025-07-30 19:57:33.499882 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803440 	 1000 	 6.896000623703003 	 5.638635635375977 	 0.0006952285766601562 	 0.30330538749694824 	 9.2579984664917 	 9.164971828460693 	 0.411693811416626 	 0.37479138374328613 	 combined
2025-07-30 19:58:05.522818 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 	 50803441 	 1000 	 7.194671630859375 	 5.939460039138794 	 0.0009770393371582031 	 0.30304813385009766 	 10.007803678512573 	 10.96340537071228 	 0.39344024658203125 	 0.3503715991973877 	 combined
2025-07-30 19:58:42.527036 test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
[Prof] paddle.nn.functional.sigmoid_focal_loss 	 paddle.nn.functional.sigmoid_focal_loss(Tensor([211681, 3, 4, 10],"float64"), Tensor([211681, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 	 50803441 	 1000 	 7.194662570953369 	 5.939394474029541 	 0.0009827613830566406 	 0.30310702323913574 	 10.005562543869019 	 10.96331000328064 	 0.39337754249572754 	 0.3503091335296631 	 combined
2025-07-30 19:59:17.723677 test begin: paddle.nn.functional.silu(Tensor([128, 128, 128, 25],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 128, 128, 25],"float32"), None, ) 	 52428800 	 1000 	 0.30530595779418945 	 0.30828070640563965 	 0.28907012939453125 	 0.2922794818878174 	 0.46434688568115234 	 0.4645977020263672 	 0.4105386734008789 	 0.3837165832519531 	 
2025-07-30 19:59:20.967942 test begin: paddle.nn.functional.silu(Tensor([128, 128, 25, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 128, 25, 128],"float32"), None, ) 	 52428800 	 1000 	 0.3048686981201172 	 0.30753278732299805 	 0.2959749698638916 	 0.2921607494354248 	 0.4646646976470947 	 0.46451783180236816 	 0.4108755588531494 	 0.3975558280944824 	 
2025-07-30 19:59:24.212333 test begin: paddle.nn.functional.silu(Tensor([128, 25, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 25, 128, 128],"float32"), None, ) 	 52428800 	 1000 	 0.3047165870666504 	 0.3075385093688965 	 0.29596972465515137 	 0.2921872138977051 	 0.4646570682525635 	 0.4645199775695801 	 0.4108431339263916 	 0.39705371856689453 	 
2025-07-30 19:59:27.427020 test begin: paddle.nn.functional.silu(Tensor([128, 256, 25, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 256, 25, 64],"float32"), None, ) 	 52428800 	 1000 	 0.304718017578125 	 0.30750298500061035 	 0.2959458827972412 	 0.2920417785644531 	 0.4646308422088623 	 0.46450209617614746 	 0.41084790229797363 	 0.39624524116516113 	 
2025-07-30 19:59:30.637776 test begin: paddle.nn.functional.silu(Tensor([128, 256, 64, 25],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 256, 64, 25],"float32"), None, ) 	 52428800 	 1000 	 0.3048360347747803 	 0.30895519256591797 	 0.2960193157196045 	 0.29218196868896484 	 0.46469688415527344 	 0.46451425552368164 	 0.411175012588501 	 0.3967421054840088 	 
2025-07-30 19:59:33.888499 test begin: paddle.nn.functional.silu(Tensor([128, 64, 128, 49],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 64, 128, 49],"float32"), None, ) 	 51380224 	 1000 	 0.298419713973999 	 1.214698314666748 	 0.28969717025756836 	 0.28612661361694336 	 0.4556434154510498 	 0.4553670883178711 	 0.40161681175231934 	 0.38776421546936035 	 
2025-07-30 19:59:39.849316 test begin: paddle.nn.functional.silu(Tensor([128, 64, 49, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 64, 49, 128],"float32"), None, ) 	 51380224 	 1000 	 0.29840755462646484 	 0.3074924945831299 	 0.2897322177886963 	 0.28597569465637207 	 0.45549535751342773 	 0.4553794860839844 	 0.3992612361907959 	 0.3881511688232422 	 
2025-07-30 19:59:43.007426 test begin: paddle.nn.functional.silu(Tensor([128, 97, 64, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([128, 97, 64, 64],"float32"), None, ) 	 50855936 	 1000 	 0.29555201530456543 	 0.2986564636230469 	 0.2798428535461426 	 0.2760920524597168 	 0.4508178234100342 	 0.4506840705871582 	 0.3880634307861328 	 0.36190295219421387 	 
2025-07-30 19:59:46.109492 test begin: paddle.nn.functional.silu(Tensor([25, 128, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([25, 128, 128, 128],"float32"), None, ) 	 52428800 	 1000 	 0.30475831031799316 	 0.3075282573699951 	 0.2960050106048584 	 0.2920980453491211 	 0.46468377113342285 	 0.46452808380126953 	 0.41126418113708496 	 0.39522719383239746 	 
2025-07-30 19:59:49.337769 test begin: paddle.nn.functional.silu(Tensor([49, 256, 64, 64],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([49, 256, 64, 64],"float32"), None, ) 	 51380224 	 1000 	 0.30119967460632324 	 0.30158042907714844 	 0.28272151947021484 	 0.27900123596191406 	 0.4555325508117676 	 0.4553825855255127 	 0.39280056953430176 	 0.3600955009460449 	 
2025-07-30 19:59:52.476760 test begin: paddle.nn.functional.silu(Tensor([49, 64, 128, 128],"float32"), None, )
[Prof] paddle.nn.functional.silu 	 paddle.nn.functional.silu(Tensor([49, 64, 128, 128],"float32"), None, ) 	 51380224 	 1000 	 0.29831981658935547 	 0.30147385597229004 	 0.2897157669067383 	 0.28584980964660645 	 0.4555244445800781 	 0.45528244972229004 	 0.4017214775085449 	 0.38808178901672363 	 
2025-07-30 19:59:55.630423 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"float32"), reduction="none", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"float32"), reduction="none", ) 	 101606500 	 1000 	 0.811936616897583 	 0.4470210075378418 	 0.4147646427154541 	 0.4129369258880615 	 1.6258139610290527 	 1.4462621212005615 	 0.4153017997741699 	 0.3694119453430176 	 
2025-07-30 20:00:02.486164 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1017, 50000],"float32"), Tensor([1017, 50000],"float32"), reduction="mean", delta=1.0, name=None, )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1017, 50000],"float32"), Tensor([1017, 50000],"float32"), reduction="mean", delta=1.0, name=None, ) 	 101700000 	 1000 	 0.9680817127227783 	 0.5983405113220215 	 0.24646878242492676 	 0.20356965065002441 	 1.7654955387115479 	 1.1611926555633545 	 0.36098432540893555 	 0.2966170310974121 	 
2025-07-30 20:00:08.710406 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([1914, 26543],"float32"), Tensor([1914, 26543],"float32"), reduction="none", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([1914, 26543],"float32"), Tensor([1914, 26543],"float32"), reduction="none", ) 	 101606604 	 1000 	 0.8109285831451416 	 0.44684457778930664 	 0.41425132751464844 	 0.4214155673980713 	 1.6257071495056152 	 1.4467687606811523 	 0.4152848720550537 	 0.3694436550140381 	 
2025-07-30 20:00:15.473928 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([33960, 187, 8],"float32"), Tensor([33960, 187, 8],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([33960, 187, 8],"float32"), Tensor([33960, 187, 8],"float32"), reduction="sum", ) 	 101608320 	 1000 	 0.9640283584594727 	 0.5986275672912598 	 0.24595952033996582 	 0.2036442756652832 	 1.7623169422149658 	 1.1616334915161133 	 0.3602588176727295 	 0.296417236328125 	 
2025-07-30 20:00:22.844223 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([64, 187, 4245],"float32"), Tensor([64, 187, 4245],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([64, 187, 4245],"float32"), Tensor([64, 187, 4245],"float32"), reduction="sum", ) 	 101608320 	 1000 	 0.9652969837188721 	 0.5990798473358154 	 0.2462761402130127 	 0.20417046546936035 	 1.7607133388519287 	 1.1605877876281738 	 0.36005520820617676 	 0.29646992683410645 	 
2025-07-30 20:00:29.050779 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([64, 99226, 8],"float32"), Tensor([64, 99226, 8],"float32"), reduction="sum", )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([64, 99226, 8],"float32"), Tensor([64, 99226, 8],"float32"), reduction="sum", ) 	 101607424 	 1000 	 0.9653453826904297 	 0.5985627174377441 	 0.24622869491577148 	 0.20363354682922363 	 1.7610628604888916 	 1.1607980728149414 	 0.3600287437438965 	 0.29656505584716797 	 
2025-07-30 20:00:37.023696 test begin: paddle.nn.functional.smooth_l1_loss(Tensor([7, 7257601],"float32"), Tensor([7, 7257601],"float32"), reduction="mean", delta=1.0, name=None, )
[Prof] paddle.nn.functional.smooth_l1_loss 	 paddle.nn.functional.smooth_l1_loss(Tensor([7, 7257601],"float32"), Tensor([7, 7257601],"float32"), reduction="mean", delta=1.0, name=None, ) 	 101606414 	 1000 	 0.9685001373291016 	 0.5984807014465332 	 0.24605250358581543 	 0.2035353183746338 	 1.7620046138763428 	 1.1605830192565918 	 0.36020731925964355 	 0.2964611053466797 	 
2025-07-30 20:00:43.611458 test begin: paddle.nn.functional.softmax(Tensor([10, 2304, 2304],"float32"), axis=-1, )
W0730 20:00:44.446913 38404 gpu_resources.cc:243] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([10, 2304, 2304],"float32"), axis=-1, ) 	 53084160 	 1000 	 0.31557750701904297 	 0.5291440486907959 	 0.3053121566772461 	 0.5139665603637695 	 0.48882341384887695 	 0.9308266639709473 	 0.43068957328796387 	 0.4755675792694092 	 
2025-07-30 20:00:47.706165 test begin: paddle.nn.functional.softmax(Tensor([3840, 1, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 1, 144, 144],"float32"), -1, name=None, ) 	 79626240 	 1000 	 0.4660055637359619 	 0.5025098323822021 	 0.453507661819458 	 0.4871187210083008 	 0.7009522914886475 	 1.392624855041504 	 0.6461336612701416 	 0.7116026878356934 	 
2025-07-30 20:00:53.413183 test begin: paddle.nn.functional.softmax(Tensor([3840, 4, 144, 23],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 4, 144, 23],"float32"), -1, name=None, ) 	 50872320 	 1000 	 0.36611008644104004 	 0.5028181076049805 	 0.3575289249420166 	 0.48726940155029297 	 0.4508228302001953 	 0.8944792747497559 	 0.3979523181915283 	 0.4570143222808838 	 
2025-07-30 20:00:57.297315 test begin: paddle.nn.functional.softmax(Tensor([3840, 4, 23, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([3840, 4, 23, 144],"float32"), -1, name=None, ) 	 50872320 	 1000 	 0.2970585823059082 	 0.3237335681915283 	 0.28101491928100586 	 0.3008239269256592 	 0.4497513771057129 	 0.8922855854034424 	 0.3889031410217285 	 0.4559502601623535 	 
2025-07-30 20:01:00.957738 test begin: paddle.nn.functional.softmax(Tensor([4096, 1, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 1, 144, 144],"float32"), -1, name=None, ) 	 84934656 	 1000 	 0.4932434558868408 	 0.5350251197814941 	 0.48427462577819824 	 0.519514799118042 	 0.7473070621490479 	 1.4849112033843994 	 0.6954517364501953 	 0.758643627166748 	 
2025-07-30 20:01:08.012459 test begin: paddle.nn.functional.softmax(Tensor([4096, 4, 144, 22],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 4, 144, 22],"float32"), -1, name=None, ) 	 51904512 	 1000 	 0.9230294227600098 	 0.5355112552642822 	 0.4519650936126709 	 0.5202648639678955 	 0.463451623916626 	 0.9143967628479004 	 0.409404993057251 	 0.46721601486206055 	 
2025-07-30 20:01:12.961448 test begin: paddle.nn.functional.softmax(Tensor([4096, 4, 22, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([4096, 4, 22, 144],"float32"), -1, name=None, ) 	 51904512 	 1000 	 0.30370402336120605 	 0.33000779151916504 	 0.2941160202026367 	 0.31476473808288574 	 0.4586975574493408 	 0.910506010055542 	 0.40500712394714355 	 0.4652392864227295 	 
2025-07-30 20:01:16.676131 test begin: paddle.nn.functional.softmax(Tensor([60, 2304, 368],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([60, 2304, 368],"float32"), axis=-1, ) 	 50872320 	 1000 	 0.30063295364379883 	 0.30275464057922363 	 0.2919754981994629 	 0.28723978996276855 	 0.4503951072692871 	 0.8929967880249023 	 0.39868879318237305 	 0.45624423027038574 	 
2025-07-30 20:01:20.280220 test begin: paddle.nn.functional.softmax(Tensor([60, 368, 2304],"float32"), axis=-1, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([60, 368, 2304],"float32"), axis=-1, ) 	 50872320 	 1000 	 0.3025197982788086 	 0.507317066192627 	 0.2921895980834961 	 0.4921269416809082 	 0.4692244529724121 	 0.8922092914581299 	 0.41299962997436523 	 0.45586395263671875 	 
2025-07-30 20:01:24.147873 test begin: paddle.nn.functional.softmax(Tensor([613, 4, 144, 144],"float32"), -1, name=None, )
[Prof] paddle.nn.functional.softmax 	 paddle.nn.functional.softmax(Tensor([613, 4, 144, 144],"float32"), -1, name=None, ) 	 50844672 	 1000 	 1.005378246307373 	 0.3241536617279053 	 0.28815793991088867 	 0.29906225204467773 	 0.44954752922058105 	 0.8919305801391602 	 0.3885791301727295 	 0.4556925296783447 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:01:33.435712 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([1551, 16, 32, 64],"float32"), Tensor([1551, 16, 32, 1],"int64"), axis=3, ) 	 51617280 	 1000 	 0.35738682746887207 	 1.279144048690796 	 0.3268697261810303 	 0.26009631156921387 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:01:37.452760 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 1, 64],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 1, 64],"int64"), axis=2, ) 	 52394496 	 1000 	 1.5047783851623535 	 2.2416605949401855 	 0.6499881744384766 	 0.3811008930206299 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:01:43.825203 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=-1, ) 	 51600640 	 1000 	 0.34710693359375 	 1.2745139598846436 	 0.32627415657043457 	 0.26003193855285645 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:01:46.893894 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 12404, 32, 64],"float32"), Tensor([2, 12404, 32, 1],"int64"), axis=3, ) 	 51600640 	 1000 	 0.35228800773620605 	 1.2745249271392822 	 0.32654285430908203 	 0.26001906394958496 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:01:49.917496 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, ) 	 50806784 	 1000 	 25.770275115966797 	 1.5038683414459229 	 13.168635606765747 	 0.2555546760559082 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:02:18.675107 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=-1, ) 	 51598560 	 1000 	 0.3438284397125244 	 1.274484395980835 	 0.3261258602142334 	 0.2600734233856201 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:02:21.709979 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 24807, 64],"float32"), Tensor([2, 16, 24807, 1],"int64"), axis=3, ) 	 51598560 	 1000 	 0.34381675720214844 	 1.2744851112365723 	 0.32592225074768066 	 0.260012149810791 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:02:24.735167 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 1, 49613],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 1, 49613],"int64"), axis=2, ) 	 52391328 	 1000 	 1.538424015045166 	 2.2163913249969482 	 0.7861201763153076 	 0.3768882751464844 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:02:31.253470 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, ) 	 50804736 	 1000 	 1.3335986137390137 	 1.076371192932129 	 0.622028112411499 	 0.2191300392150879 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:02:37.059455 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 49613],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, ) 	 50804736 	 1000 	 0.8638238906860352 	 1.0774784088134766 	 0.6216950416564941 	 0.21916961669921875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:02:40.771670 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 793801],"float32"), Tensor([2, 16, 1, 793801],"int64"), axis=2, )
[Prof] paddle.nn.functional.softmax_with_cross_entropy 	 paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 793801],"float32"), Tensor([2, 16, 1, 793801],"int64"), axis=2, ) 	 838253856 	 1000 	 23.986441373825073 	 44.50923681259155 	 12.256728172302246 	 5.040889501571655 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:04:12.624663 test begin: paddle.nn.functional.softplus(Tensor([113401, 7, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([113401, 7, 64],"float32"), ) 	 50803648 	 1000 	 0.3008005619049072 	 0.2999999523162842 	 0.29167890548706055 	 0.28850460052490234 	 0.450641393661499 	 0.4506235122680664 	 0.3967719078063965 	 0.3761429786682129 	 
2025-07-30 20:04:15.794779 test begin: paddle.nn.functional.softplus(Tensor([13, 10, 390794],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 10, 390794],"float32"), ) 	 50803220 	 1000 	 0.3009634017944336 	 0.2999389171600342 	 0.28440093994140625 	 0.28206515312194824 	 0.4506113529205322 	 0.45050930976867676 	 0.3882105350494385 	 0.3763246536254883 	 
2025-07-30 20:04:19.000652 test begin: paddle.nn.functional.softplus(Tensor([13, 1007, 3881],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 1007, 3881],"float32"), ) 	 50806171 	 1000 	 0.3008439540863037 	 0.29993748664855957 	 0.2917745113372803 	 0.28847527503967285 	 0.45061731338500977 	 0.4505743980407715 	 0.39737391471862793 	 0.3836030960083008 	 
2025-07-30 20:04:22.127205 test begin: paddle.nn.functional.softplus(Tensor([13, 61062, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([13, 61062, 64],"float32"), ) 	 50803584 	 1000 	 0.29938602447509766 	 0.29990243911743164 	 0.2902491092681885 	 0.28842830657958984 	 0.4505434036254883 	 0.45050954818725586 	 0.39782261848449707 	 0.3817873001098633 	 
2025-07-30 20:04:25.284852 test begin: paddle.nn.functional.softplus(Tensor([14, 56701, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([14, 56701, 64],"float32"), ) 	 50804096 	 1000 	 0.2994844913482666 	 0.2998943328857422 	 0.2903740406036377 	 0.2884407043457031 	 0.4504384994506836 	 0.45052528381347656 	 0.39714813232421875 	 0.38376569747924805 	 
2025-07-30 20:04:28.403588 test begin: paddle.nn.functional.softplus(Tensor([14, 7, 518401],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([14, 7, 518401],"float32"), ) 	 50803298 	 1000 	 0.2995610237121582 	 0.2999393939971924 	 0.29041075706481934 	 0.2819337844848633 	 0.4504678249359131 	 0.4505281448364258 	 0.3880479335784912 	 0.38056015968322754 	 
2025-07-30 20:04:31.542259 test begin: paddle.nn.functional.softplus(Tensor([789, 1007, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([789, 1007, 64],"float32"), ) 	 50849472 	 1000 	 0.30130553245544434 	 0.3002357482910156 	 0.29228997230529785 	 0.2887566089630127 	 0.45099806785583496 	 0.45092058181762695 	 0.39220571517944336 	 0.38338398933410645 	 
2025-07-30 20:04:34.663302 test begin: paddle.nn.functional.softplus(Tensor([79381, 10, 64],"float32"), )
[Prof] paddle.nn.functional.softplus 	 paddle.nn.functional.softplus(Tensor([79381, 10, 64],"float32"), ) 	 50803840 	 1000 	 0.2994067668914795 	 0.7615540027618408 	 0.290496826171875 	 0.28168582916259766 	 0.4504659175872803 	 0.4506998062133789 	 0.3878822326660156 	 0.381772518157959 	 
2025-07-30 20:04:39.520308 test begin: paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 0, None, ) 	 25401609 	 1000 	 0.29830431938171387 	 0.2991044521331787 	 0.281876802444458 	 0.28027844429016113 	 0.4482440948486328 	 0.44587063789367676 	 0.38569188117980957 	 0.3717050552368164 	 
2025-07-30 20:04:42.101966 test begin: paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([2822401, 3, 3],"float64"), 5, None, ) 	 25401609 	 1000 	 0.2982950210571289 	 0.7529349327087402 	 0.28929853439331055 	 0.2799499034881592 	 0.44811177253723145 	 0.4458587169647217 	 0.3951430320739746 	 0.3719618320465088 	 
2025-07-30 20:04:47.920233 test begin: paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 0, None, ) 	 25401609 	 1000 	 0.29825830459594727 	 0.3024876117706299 	 0.2891080379486084 	 0.28671860694885254 	 0.4480457305908203 	 0.4458920955657959 	 0.39491891860961914 	 0.379194974899292 	 
2025-07-30 20:04:50.457503 test begin: paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 2822401, 3],"float64"), 5, None, ) 	 25401609 	 1000 	 0.2982776165008545 	 0.2987246513366699 	 0.2893366813659668 	 0.2865428924560547 	 0.4480733871459961 	 0.4458484649658203 	 0.39382410049438477 	 0.37851548194885254 	 
2025-07-30 20:04:53.034915 test begin: paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 0, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 0, None, ) 	 25401609 	 1000 	 0.2982656955718994 	 0.29905223846435547 	 0.2892320156097412 	 0.2867918014526367 	 0.44809865951538086 	 0.44583582878112793 	 0.3932645320892334 	 0.37835192680358887 	 
2025-07-30 20:04:55.582970 test begin: paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 5, None, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([3, 3, 2822401],"float64"), 5, None, ) 	 25401609 	 1000 	 0.2982673645019531 	 0.2987394332885742 	 0.28931140899658203 	 0.28655195236206055 	 0.44801878929138184 	 0.44585227966308594 	 0.3948934078216553 	 0.378558874130249 	 
2025-07-30 20:04:58.142238 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 207, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 207, 8, 32, 2],"float32"), threshold=0.01, ) 	 50872320 	 1000 	 0.2960855960845947 	 0.29876160621643066 	 0.28574371337890625 	 0.28589916229248047 	 0.4510350227355957 	 0.4473154544830322 	 0.3968074321746826 	 0.3775136470794678 	 
2025-07-30 20:05:01.259599 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 207, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 207, 32, 2],"float32"), threshold=0.01, ) 	 50872320 	 1000 	 0.2960476875305176 	 0.298738956451416 	 0.28674936294555664 	 0.2859220504760742 	 0.45100998878479004 	 0.44733095169067383 	 0.3970334529876709 	 0.3736748695373535 	 
2025-07-30 20:05:04.385580 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 32, 52],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 32, 52],"float32"), threshold=0.01, ) 	 51118080 	 1000 	 0.2973942756652832 	 0.3001899719238281 	 0.28809380531311035 	 0.2873528003692627 	 0.4531128406524658 	 0.4494612216949463 	 0.39918065071105957 	 0.3753235340118408 	 
2025-07-30 20:05:07.521453 test begin: paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 827, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 15, 8, 8, 827, 2],"float32"), threshold=0.01, ) 	 50810880 	 1000 	 0.29572558403015137 	 0.3011493682861328 	 0.28646135330200195 	 0.2854290008544922 	 0.4503664970397949 	 0.4467024803161621 	 0.3966977596282959 	 0.37247610092163086 	 
2025-07-30 20:05:10.684519 test begin: paddle.nn.functional.softshrink(Tensor([32, 388, 8, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([32, 388, 8, 8, 32, 2],"float32"), threshold=0.01, ) 	 50855936 	 1000 	 0.29603028297424316 	 0.2987344264984131 	 0.27924227714538574 	 0.27938127517700195 	 0.4508833885192871 	 0.44717931747436523 	 0.387784481048584 	 0.3706057071685791 	 
2025-07-30 20:05:13.833381 test begin: paddle.nn.functional.softshrink(Tensor([827, 15, 8, 8, 32, 2],"float32"), threshold=0.01, )
[Prof] paddle.nn.functional.softshrink 	 paddle.nn.functional.softshrink(Tensor([827, 15, 8, 8, 32, 2],"float32"), threshold=0.01, ) 	 50810880 	 1000 	 0.29569315910339355 	 0.2984123229980469 	 0.28630566596984863 	 0.285830020904541 	 0.4504091739654541 	 0.44667840003967285 	 0.39693570137023926 	 0.3780062198638916 	 
2025-07-30 20:05:16.961437 test begin: paddle.nn.functional.softsign(Tensor([12404, 4096],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([12404, 4096],"float32"), ) 	 50806784 	 1000 	 0.2951951026916504 	 1.0431363582611084 	 0.2864561080932617 	 0.3553440570831299 	 0.45035243034362793 	 3.2803709506988525 	 0.3966405391693115 	 0.41875362396240234 	 
2025-07-30 20:05:23.665712 test begin: paddle.nn.functional.softsign(Tensor([2822401, 3, 3],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([2822401, 3, 3],"float64"), None, ) 	 25401609 	 1000 	 0.29929590225219727 	 1.0428154468536377 	 0.29088544845581055 	 0.3552591800689697 	 0.44762134552001953 	 3.2696754932403564 	 0.3952653408050537 	 0.41765689849853516 	 
2025-07-30 20:05:29.790861 test begin: paddle.nn.functional.softsign(Tensor([3, 2822401, 3],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([3, 2822401, 3],"float64"), None, ) 	 25401609 	 1000 	 0.29929089546203613 	 1.0427465438842773 	 0.2909269332885742 	 0.3552727699279785 	 0.4474823474884033 	 3.2696571350097656 	 0.39445996284484863 	 0.4176158905029297 	 
2025-07-30 20:05:37.280975 test begin: paddle.nn.functional.softsign(Tensor([3, 3, 2822401],"float64"), None, )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([3, 3, 2822401],"float64"), None, ) 	 25401609 	 1000 	 0.29927492141723633 	 1.057929515838623 	 0.28364109992980957 	 0.3551950454711914 	 0.44761157035827637 	 3.2697503566741943 	 0.39489126205444336 	 0.41760802268981934 	 
2025-07-30 20:05:44.109327 test begin: paddle.nn.functional.softsign(Tensor([300, 169345],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([300, 169345],"float32"), ) 	 50803500 	 1000 	 0.29526567459106445 	 1.043205738067627 	 0.2858917713165283 	 0.35545992851257324 	 0.4501824378967285 	 3.278731107711792 	 0.3961198329925537 	 0.41880249977111816 	 
2025-07-30 20:05:51.526261 test begin: paddle.nn.functional.softsign(Tensor([32, 1587601],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 0.29517364501953125 	 1.0499989986419678 	 0.27913451194763184 	 0.35536742210388184 	 0.45038509368896484 	 3.2789463996887207 	 0.388033390045166 	 0.41873860359191895 	 
2025-07-30 20:05:59.007118 test begin: paddle.nn.functional.softsign(Tensor([396901, 128],"float32"), )
[Prof] paddle.nn.functional.softsign 	 paddle.nn.functional.softsign(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29502129554748535 	 1.0430934429168701 	 0.27929139137268066 	 0.35532593727111816 	 0.44996047019958496 	 3.2788784503936768 	 0.38763880729675293 	 0.41880345344543457 	 
2025-07-30 20:06:05.720433 test begin: paddle.nn.functional.square_error_cost(Tensor([10161, 100, 100],"float16"), Tensor([10161, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([10161, 100, 100],"float16"), Tensor([10161, 100, 100],"float32"), ) 	 203220000 	 1000 	 1.961660623550415 	 1.402374505996704 	 0.6684038639068604 	 0.7165303230285645 	 2.280594825744629 	 3.1372931003570557 	 0.7767982482910156 	 0.5344221591949463 	 combined
2025-07-30 20:06:19.837777 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), ) 	 25401624 	 1000 	 0.5991318225860596 	 0.598991870880127 	 0.3061330318450928 	 0.30597662925720215 	 4.133960247039795 	 1.516761302947998 	 1.057288646697998 	 0.22138738632202148 	 combined
2025-07-30 20:06:27.736866 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 4233601],"float64"), label=Tensor([3, 2, 1, 4233601],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 4233601],"float64"), label=Tensor([3, 2, 1, 4233601],"float64"), ) 	 50803212 	 1000 	 0.742609977722168 	 0.7412495613098145 	 0.3794527053833008 	 0.37867069244384766 	 0.9244904518127441 	 1.3522732257843018 	 0.47232913970947266 	 0.2765510082244873 	 combined
2025-07-30 20:06:33.148338 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 1, 2],"float64"), ) 	 25401624 	 1000 	 0.5971405506134033 	 0.615297794342041 	 0.3051316738128662 	 0.3059518337249756 	 3.831437349319458 	 1.5159275531768799 	 1.305967092514038 	 0.22133493423461914 	 combined
2025-07-30 20:06:41.287073 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 2, 2116801, 2],"float64"), label=Tensor([3, 2, 2116801, 2],"float64"), ) 	 50803224 	 1000 	 0.7426354885101318 	 0.7413442134857178 	 0.3794891834259033 	 0.37873411178588867 	 0.9246683120727539 	 1.352344274520874 	 0.47243547439575195 	 0.2766423225402832 	 combined
2025-07-30 20:06:46.694445 test begin: paddle.nn.functional.square_error_cost(Tensor([3, 4233601, 1, 2],"float64"), label=Tensor([3, 4233601, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([3, 4233601, 1, 2],"float64"), label=Tensor([3, 4233601, 1, 2],"float64"), ) 	 50803212 	 1000 	 0.742640495300293 	 0.7413065433502197 	 0.37947630882263184 	 0.37869930267333984 	 0.9248096942901611 	 1.352210283279419 	 0.4725189208984375 	 0.27661895751953125 	 combined
2025-07-30 20:06:52.004500 test begin: paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float16"), Tensor([5081, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float16"), Tensor([5081, 100, 100],"float32"), ) 	 101620000 	 1000 	 0.985497236251831 	 0.7159297466278076 	 0.33577609062194824 	 0.3609809875488281 	 1.1460418701171875 	 1.5801546573638916 	 0.39034485816955566 	 0.2691383361816406 	 combined
2025-07-30 20:07:00.392185 test begin: paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float32"), Tensor([5081, 100, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([5081, 100, 100],"float32"), Tensor([5081, 100, 100],"float32"), ) 	 101620000 	 1000 	 0.7451932430267334 	 0.7431273460388184 	 0.38080692291259766 	 0.37966346740722656 	 0.9210124015808105 	 1.3531081676483154 	 0.47059106826782227 	 0.2767508029937744 	 combined
2025-07-30 20:07:06.575514 test begin: paddle.nn.functional.square_error_cost(Tensor([6350401, 2, 1, 2],"float64"), label=Tensor([6350401, 2, 1, 2],"float64"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([6350401, 2, 1, 2],"float64"), label=Tensor([6350401, 2, 1, 2],"float64"), ) 	 50803208 	 1000 	 0.7426252365112305 	 0.7412464618682861 	 0.37946248054504395 	 0.37868690490722656 	 0.9246478080749512 	 1.3522288799285889 	 0.4724738597869873 	 0.2765696048736572 	 combined
2025-07-30 20:07:11.887641 test begin: paddle.nn.functional.square_error_cost(Tensor([8, 100, 63505],"float32"), Tensor([8, 100, 63505],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([8, 100, 63505],"float32"), Tensor([8, 100, 63505],"float32"), ) 	 101608000 	 1000 	 0.745124101638794 	 0.7442824840545654 	 0.3807339668273926 	 0.37958216667175293 	 0.9206609725952148 	 1.3530399799346924 	 0.4703841209411621 	 0.2767481803894043 	 combined
2025-07-30 20:07:18.060681 test begin: paddle.nn.functional.square_error_cost(Tensor([8, 63505, 100],"float32"), Tensor([8, 63505, 100],"float32"), )
[Prof] paddle.nn.functional.square_error_cost 	 paddle.nn.functional.square_error_cost(Tensor([8, 63505, 100],"float32"), Tensor([8, 63505, 100],"float32"), ) 	 101608000 	 1000 	 0.7451610565185547 	 0.7429671287536621 	 0.38076186180114746 	 0.37955617904663086 	 0.9208407402038574 	 1.3530352115631104 	 0.47053050994873047 	 0.2767183780670166 	 combined
2025-07-30 20:07:24.322090 test begin: paddle.nn.functional.tanh(Tensor([1016065, 50],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([1016065, 50],"float32"), None, ) 	 50803250 	 1000 	 0.29549503326416016 	 0.29816627502441406 	 0.28696751594543457 	 0.2868950366973877 	 0.4501638412475586 	 0.44649481773376465 	 0.3964061737060547 	 0.3804283142089844 	 
2025-07-30 20:07:27.456767 test begin: paddle.nn.functional.tanh(Tensor([147015, 346],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([147015, 346],"float32"), None, ) 	 50867190 	 1000 	 0.29609131813049316 	 0.29862022399902344 	 0.2878258228302002 	 0.2871692180633545 	 0.4507312774658203 	 0.4470975399017334 	 0.3971130847930908 	 0.3798074722290039 	 
2025-07-30 20:07:30.570069 test begin: paddle.nn.functional.tanh(Tensor([282600, 180],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([282600, 180],"float32"), None, ) 	 50868000 	 1000 	 0.2957446575164795 	 0.29843974113464355 	 0.28733110427856445 	 0.2871417999267578 	 0.45052242279052734 	 0.4471099376678467 	 0.3967130184173584 	 0.3793606758117676 	 
2025-07-30 20:07:33.716008 test begin: paddle.nn.functional.tanh(Tensor([564481, 90],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([564481, 90],"float32"), None, ) 	 50803290 	 1000 	 0.2953977584838867 	 0.7534937858581543 	 0.2868473529815674 	 0.28719472885131836 	 0.4500589370727539 	 0.4464905261993408 	 0.39660215377807617 	 0.3671131134033203 	 
2025-07-30 20:07:39.153995 test begin: paddle.nn.functional.tanh(Tensor([93401, 544],"float32"), None, )
[Prof] paddle.nn.functional.tanh 	 paddle.nn.functional.tanh(Tensor([93401, 544],"float32"), None, ) 	 50810144 	 1000 	 0.295529842376709 	 0.2980482578277588 	 0.2870783805847168 	 0.2870967388153076 	 0.450070858001709 	 0.44652843475341797 	 0.39629077911376953 	 0.3797180652618408 	 
2025-07-30 20:07:42.306308 test begin: paddle.nn.functional.tanhshrink(Tensor([2822401, 3, 3],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([2822401, 3, 3],"float64"), None, ) 	 25401609 	 1000 	 0.29924750328063965 	 0.7431352138519287 	 0.2908501625061035 	 0.3796212673187256 	 0.4474303722381592 	 1.1848716735839844 	 0.3945927619934082 	 0.4036679267883301 	 
2025-07-30 20:07:46.024634 test begin: paddle.nn.functional.tanhshrink(Tensor([3, 2822401, 3],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([3, 2822401, 3],"float64"), None, ) 	 25401609 	 1000 	 0.2992241382598877 	 0.7430002689361572 	 0.2907843589782715 	 0.3795897960662842 	 0.447676420211792 	 1.1848807334899902 	 0.3951568603515625 	 0.40372276306152344 	 
2025-07-30 20:07:49.738972 test begin: paddle.nn.functional.tanhshrink(Tensor([3, 3, 2822401],"float64"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([3, 3, 2822401],"float64"), None, ) 	 25401609 	 1000 	 0.2992513179779053 	 0.7430500984191895 	 0.29083943367004395 	 0.3796107769012451 	 0.447462797164917 	 1.1849002838134766 	 0.39475178718566895 	 0.40366506576538086 	 
2025-07-30 20:07:53.464445 test begin: paddle.nn.functional.tanhshrink(Tensor([50803201],"float32"), None, )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(Tensor([50803201],"float32"), None, ) 	 50803201 	 1000 	 0.29544854164123535 	 0.7431597709655762 	 0.28687000274658203 	 0.3796570301055908 	 0.45019102096557617 	 1.1889984607696533 	 0.3935546875 	 0.4051351547241211 	 
2025-07-30 20:07:57.760617 test begin: paddle.nn.functional.tanhshrink(x=Tensor([2822401, 3, 3],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([2822401, 3, 3],"float64"), ) 	 25401609 	 1000 	 0.2992391586303711 	 0.7430882453918457 	 0.29067564010620117 	 0.3795952796936035 	 0.44774818420410156 	 1.1853070259094238 	 0.3924825191497803 	 0.40392160415649414 	 
2025-07-30 20:08:02.578610 test begin: paddle.nn.functional.tanhshrink(x=Tensor([3, 2822401, 3],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([3, 2822401, 3],"float64"), ) 	 25401609 	 1000 	 0.29925060272216797 	 0.751976728439331 	 0.2906951904296875 	 0.3796079158782959 	 0.447634220123291 	 1.1848700046539307 	 0.3947765827178955 	 0.40372633934020996 	 
2025-07-30 20:08:07.093740 test begin: paddle.nn.functional.tanhshrink(x=Tensor([3, 3, 2822401],"float64"), )
[Prof] paddle.nn.functional.tanhshrink 	 paddle.nn.functional.tanhshrink(x=Tensor([3, 3, 2822401],"float64"), ) 	 25401609 	 1000 	 0.29921603202819824 	 0.7430951595306396 	 0.2905449867248535 	 0.3796086311340332 	 0.44747233390808105 	 1.1848499774932861 	 0.3945777416229248 	 0.40370965003967285 	 
2025-07-30 20:08:10.806381 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 28225, 3, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 28225, 3, 3],"float64"), 1.0, 0.0, None, ) 	 25402500 	 1000 	 0.297954797744751 	 0.29825520515441895 	 0.2888929843902588 	 0.2788662910461426 	 0.44820261001586914 	 0.44576191902160645 	 0.39542102813720703 	 0.36339855194091797 	 
2025-07-30 20:08:13.357977 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 21169, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 21169, 3],"float64"), 1.0, 0.0, None, ) 	 25402800 	 1000 	 0.29784679412841797 	 0.2983207702636719 	 0.28156018257141113 	 0.26961851119995117 	 0.447979211807251 	 0.44590282440185547 	 0.385941743850708 	 0.37095165252685547 	 
2025-07-30 20:08:15.953618 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 21169],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 21169],"float64"), 1.0, 0.0, None, ) 	 25402800 	 1000 	 0.2979166507720947 	 0.2983870506286621 	 0.281538724899292 	 0.27164125442504883 	 0.44802379608154297 	 0.4458155632019043 	 0.3856830596923828 	 0.37134313583374023 	 
2025-07-30 20:08:18.528536 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 42337],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 3, 42337],"float32"), 1.0, 0.0, None, ) 	 50804400 	 1000 	 0.29569220542907715 	 0.29821133613586426 	 0.286578893661499 	 0.2712593078613281 	 0.45020270347595215 	 0.446596622467041 	 0.39705824851989746 	 0.37157130241394043 	 
2025-07-30 20:08:21.656641 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 4, 42337, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 4, 42337, 3],"float32"), 1.0, 0.0, None, ) 	 50804400 	 1000 	 0.29571008682250977 	 0.29809999465942383 	 0.2867758274078369 	 0.27118539810180664 	 0.45014405250549316 	 0.44664835929870605 	 0.3874061107635498 	 0.35707712173461914 	 
2025-07-30 20:08:24.787040 test begin: paddle.nn.functional.thresholded_relu(Tensor([100, 56449, 3, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([100, 56449, 3, 3],"float32"), 1.0, 0.0, None, ) 	 50804100 	 1000 	 0.2958066463470459 	 0.2981564998626709 	 0.27940821647644043 	 0.2711470127105713 	 0.450314998626709 	 0.44669342041015625 	 0.387631893157959 	 0.35500025749206543 	 
2025-07-30 20:08:28.071240 test begin: paddle.nn.functional.thresholded_relu(Tensor([1411201, 4, 3, 3],"float32"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([1411201, 4, 3, 3],"float32"), 1.0, 0.0, None, ) 	 50803236 	 1000 	 0.29578137397766113 	 0.29807353019714355 	 0.2865407466888428 	 0.2781815528869629 	 0.45023393630981445 	 0.44656968116760254 	 0.39649105072021484 	 0.3784801959991455 	 
2025-07-30 20:08:31.212257 test begin: paddle.nn.functional.thresholded_relu(Tensor([705601, 4, 3, 3],"float64"), 1.0, 0.0, None, )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(Tensor([705601, 4, 3, 3],"float64"), 1.0, 0.0, None, ) 	 25401636 	 1000 	 0.2978169918060303 	 0.3021559715270996 	 0.288738489151001 	 0.2790188789367676 	 0.447920560836792 	 0.44579386711120605 	 0.3952031135559082 	 0.35625505447387695 	 
2025-07-30 20:08:33.744133 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 42337],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 42337],"float32"), ) 	 50804400 	 1000 	 0.2957327365875244 	 0.7490265369415283 	 0.2863004207611084 	 0.27886223793029785 	 0.45014166831970215 	 0.4465830326080322 	 0.3968648910522461 	 0.37839627265930176 	 
2025-07-30 20:08:39.413972 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 42337, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 42337, 3],"float32"), ) 	 50804400 	 1000 	 0.295745849609375 	 0.2980210781097412 	 0.2862391471862793 	 0.27901458740234375 	 0.45014071464538574 	 0.4465956687927246 	 0.39685630798339844 	 0.37042951583862305 	 
2025-07-30 20:08:42.570009 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([100, 56449, 3, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([100, 56449, 3, 3],"float32"), ) 	 50804100 	 1000 	 0.29573750495910645 	 0.3056654930114746 	 0.2861335277557373 	 0.2768828868865967 	 0.45020604133605957 	 0.44661402702331543 	 0.3968076705932617 	 0.3771960735321045 	 
2025-07-30 20:08:45.711329 test begin: paddle.nn.functional.thresholded_relu(x=Tensor([1411201, 4, 3, 3],"float32"), )
[Prof] paddle.nn.functional.thresholded_relu 	 paddle.nn.functional.thresholded_relu(x=Tensor([1411201, 4, 3, 3],"float32"), ) 	 50803236 	 1000 	 0.29575657844543457 	 0.2980961799621582 	 0.2862091064453125 	 0.27885985374450684 	 0.4502143859863281 	 0.44659996032714844 	 0.39656710624694824 	 0.3681356906890869 	 
2025-07-30 20:08:48.847707 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 	 76204815 	 1000 	 2.3370773792266846 	 1.8214163780212402 	 3.075599670410156e-05 	 0.1547863483428955 	 4.068735361099243 	 2.8677756786346436 	 0.463728666305542 	 0.18348121643066406 	 
2025-07-30 20:09:01.588699 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 	 76204815 	 1000 	 2.3066794872283936 	 1.8195197582244873 	 1.8835067749023438e-05 	 0.16862010955810547 	 4.0652337074279785 	 2.8644351959228516 	 0.5203979015350342 	 0.19551634788513184 	 
2025-07-30 20:09:15.241267 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), Tensor([5, 5080321],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 	 76204815 	 1000 	 2.3477251529693604 	 1.8217964172363281 	 4.458427429199219e-05 	 0.15487051010131836 	 4.0684404373168945 	 2.864253282546997 	 0.4636058807373047 	 0.19547629356384277 	 
2025-07-30 20:09:28.103793 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 	 76204815 	 1000 	 2.77571177482605 	 2.236018419265747 	 0.00018525123596191406 	 0.20728039741516113 	 4.416933536529541 	 3.255802869796753 	 0.5032827854156494 	 0.2082972526550293 	 
2025-07-30 20:09:44.802831 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 	 76204815 	 1000 	 2.7384088039398193 	 2.1968374252319336 	 0.00016117095947265625 	 0.24898242950439453 	 4.38286280632019 	 3.224254846572876 	 0.5609197616577148 	 0.21998882293701172 	 
2025-07-30 20:09:59.232745 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[Prof] paddle.nn.functional.triplet_margin_with_distance_loss 	 paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), Tensor([5080321, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 	 76204815 	 1000 	 2.775181770324707 	 2.2333173751831055 	 0.0001842975616455078 	 0.20727300643920898 	 4.416319370269775 	 3.2006239891052246 	 0.5031406879425049 	 0.21838641166687012 	 
2025-07-30 20:10:13.555316 test begin: paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50831360 	 1000 	 2.271110773086548 	 2.6414954662323 	 0.17808914184570312 	 0.24532866477966309 	 3.7352287769317627 	 7.166230916976929 	 0.3472480773925781 	 7.099724054336548 	 
2025-07-30 20:10:39.536917 test begin: paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 1241, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50831360 	 1000 	 1.7451300621032715 	 2.6416587829589844 	 0.1780860424041748 	 0.24539446830749512 	 3.7353086471557617 	 7.166209936141968 	 0.34720516204833984 	 7.092687129974365 	 
2025-07-30 20:11:03.309333 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50805120 	 1000 	 1.8219175338745117 	 2.663853883743286 	 0.1860218048095703 	 0.2256791591644287 	 3.7782130241394043 	 7.212598562240601 	 0.3512418270111084 	 7.138512372970581 	 
2025-07-30 20:11:28.827222 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 26461, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50805120 	 1000 	 1.8219497203826904 	 2.6499218940734863 	 0.18597197532653809 	 0.22566771507263184 	 3.7779970169067383 	 7.212655067443848 	 0.35123586654663086 	 7.138650894165039 	 
2025-07-30 20:11:52.808902 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50805120 	 1000 	 2.152479648590088 	 2.9866867065429688 	 0.2198038101196289 	 0.2543606758117676 	 3.7101030349731445 	 7.0853118896484375 	 0.3449244499206543 	 7.015923976898193 	 
2025-07-30 20:12:17.212138 test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([10, 3, 64, 26461],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50805120 	 1000 	 2.154956579208374 	 2.9868526458740234 	 0.21977019309997559 	 0.2544112205505371 	 3.708906412124634 	 7.085490465164185 	 0.3446686267852783 	 7.009680509567261 	 
2025-07-30 20:12:41.429726 test begin: paddle.nn.functional.unfold(Tensor([338, 3, 224, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([338, 3, 224, 224],"float32"), 16, 16, ) 	 50878464 	 1000 	 24.228683710098267 	 24.05241084098816 	 0.07324743270874023 	 0.07274079322814941 	 3.2824528217315674 	 2.105984687805176 	 0.009863615036010742 	 2.0274295806884766 	 
2025-07-30 20:13:37.319939 test begin: paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 	 50810880 	 1000 	 36.54311013221741 	 30.77810502052307 	 0.008986711502075195 	 0.007516384124755859 	 80.54317212104797 	 7.163246393203735 	 0.019826650619506836 	 7.092906475067139 	 
2025-07-30 20:16:21.111435 test begin: paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([4135, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 	 50810880 	 1000 	 36.455158710479736 	 30.781415462493896 	 0.008992671966552734 	 0.007503986358642578 	 80.545574426651 	 7.16309118270874 	 0.019837617874145508 	 7.095441579818726 	 
2025-07-30 20:19:04.668336 test begin: paddle.nn.functional.unfold(Tensor([64, 16, 224, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 16, 224, 224],"float32"), 16, 16, ) 	 51380224 	 1000 	 15.36509084701538 	 7.886104345321655 	 0.24536371231079102 	 0.1259629726409912 	 1.8629662990570068 	 2.126671314239502 	 0.029197216033935547 	 2.053645372390747 	 
2025-07-30 20:19:33.642073 test begin: paddle.nn.functional.unfold(Tensor([64, 3, 1182, 224],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 3, 1182, 224],"float32"), 16, 16, ) 	 50835456 	 1000 	 15.335436344146729 	 7.856205463409424 	 0.24487781524658203 	 0.12545180320739746 	 1.8566954135894775 	 2.4047329425811768 	 0.029096603393554688 	 1.228757619857788 	 
2025-07-30 20:20:03.501298 test begin: paddle.nn.functional.unfold(Tensor([64, 3, 224, 1182],"float32"), 16, 16, )
[Prof] paddle.nn.functional.unfold 	 paddle.nn.functional.unfold(Tensor([64, 3, 224, 1182],"float32"), 16, 16, ) 	 50835456 	 1000 	 15.761922359466553 	 7.9590489864349365 	 0.2516779899597168 	 0.1271367073059082 	 1.8589909076690674 	 2.407200574874878 	 0.029114961624145508 	 1.2300212383270264 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:20:35.072948 test begin: paddle.nn.functional.zeropad2d(Tensor([338, 3, 224, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([338, 3, 224, 224],"float32"), list[2,2,2,2,], ) 	 50878464 	 1000 	 0.628868818283081 	 1.1434552669525146 	 0.5958638191223145 	 0.23912358283996582 	 0.7503595352172852 	 0.31159520149230957 	 0.3834052085876465 	 0.23465251922607422 	 combined
2025-07-30 20:20:40.284119 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"float64"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"float64"), list[2,2,2,2,], ) 	 25489408 	 1000 	 0.3239595890045166 	 0.45896100997924805 	 0.2759559154510498 	 0.23442292213439941 	 0.46132802963256836 	 0.3038637638092041 	 0.2356107234954834 	 0.21458983421325684 	 combined
2025-07-30 20:20:42.953787 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"int64"), Tensor([4],"int32"), )
W0730 20:20:44.046593 45749 backward.cc:462] While running Node (Pad3dGradNode) raises an EnforceNotMet exception
[Error] (NotFound) The kernel with key (GPU, Undefined(AnyLayout), int64) of kernel `pad3d_grad` is not registered and fail to fallback to CPU one. Selected wrong DataType `int64`. Paddle support following DataTypes: float64, complex128, float16, float32, complex64, bfloat16.
  [Hint: Expected kernel_iter != iter->second.end(), but received kernel_iter == iter->second.end().] (at ../paddle/phi/core/kernel_factory.cc:380)

[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 127, 224, 224],"int64"), Tensor([4],"int32"), ) 	 25489412 	 1000 	 0.3756997585296631 	 0.5359463691711426 	 0.0003161430358886719 	 0.0004405975341796875 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:20:44.700931 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 254, 224, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 254, 224, 224],"float32"), list[2,2,2,2,], ) 	 50978816 	 1000 	 0.6297721862792969 	 0.4690284729003906 	 0.5815932750701904 	 0.23955535888671875 	 0.7578651905059814 	 0.3122124671936035 	 0.3871786594390869 	 0.22703838348388672 	 combined
2025-07-30 20:20:48.562012 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 18901, 224],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 18901, 224],"float32"), list[2,2,2,2,], ) 	 50805888 	 1000 	 0.6179656982421875 	 0.46495819091796875 	 0.5850105285644531 	 0.23750519752502441 	 0.746110200881958 	 0.31096696853637695 	 0.381237268447876 	 0.23393774032592773 	 combined
2025-07-30 20:20:52.376743 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 18901],"float32"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 18901],"float32"), list[2,2,2,2,], ) 	 50805888 	 1000 	 0.6163420677185059 	 0.44440770149230957 	 0.5830411911010742 	 0.22693681716918945 	 0.7459230422973633 	 0.30841803550720215 	 0.3810899257659912 	 0.2277235984802246 	 combined
2025-07-30 20:20:56.194731 test begin: paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 9451],"float64"), list[2,2,2,2,], )
[Prof] paddle.nn.functional.zeropad2d 	 paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 9451],"float64"), list[2,2,2,2,], ) 	 25404288 	 1000 	 0.3192861080169678 	 0.44007086753845215 	 0.2863428592681885 	 0.22473692893981934 	 0.46033310890197754 	 0.2998838424682617 	 0.23514914512634277 	 0.22278380393981934 	 combined
2025-07-30 20:20:58.810212 test begin: paddle.nonzero(Tensor([510, 128, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 128, 28, 28],"float32"), ) 	 51179520 	 1000 	 7.43100118637085 	 2.3348169326782227 	 0.005475759506225586 	 0.0021278858184814453 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:10.511243 test begin: paddle.nonzero(Tensor([510, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 80, 28, 45],"float32"), ) 	 51408000 	 1000 	 7.957289695739746 	 2.335136651992798 	 0.005575418472290039 	 0.0021288394927978516 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:21.669110 test begin: paddle.nonzero(Tensor([510, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([510, 80, 45, 28],"float32"), ) 	 51408000 	 1000 	 7.535227060317993 	 2.340043306350708 	 0.005552768707275391 	 0.002124786376953125 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:32.416328 test begin: paddle.nonzero(Tensor([511, 127, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 127, 28, 28],"float32"), ) 	 50879248 	 1000 	 7.452153444290161 	 2.3371691703796387 	 0.005466461181640625 	 0.002142667770385742 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:43.189324 test begin: paddle.nonzero(Tensor([511, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 80, 28, 45],"float32"), ) 	 51508800 	 1000 	 7.547022342681885 	 2.3427670001983643 	 0.005524635314941406 	 0.002144336700439453 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:53.974497 test begin: paddle.nonzero(Tensor([511, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([511, 80, 45, 28],"float32"), ) 	 51508800 	 1000 	 7.544503927230835 	 2.3440263271331787 	 0.005531787872314453 	 0.0021419525146484375 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:04.700874 test begin: paddle.nonzero(Tensor([512, 127, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 127, 28, 28],"float32"), ) 	 50978816 	 1000 	 7.410488605499268 	 2.318171262741089 	 0.0054476261138916016 	 0.0021169185638427734 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:17.657309 test begin: paddle.nonzero(Tensor([512, 80, 28, 45],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 80, 28, 45],"float32"), ) 	 51609600 	 1000 	 8.517421245574951 	 2.344489574432373 	 0.005491495132446289 	 0.002133607864379883 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:29.478514 test begin: paddle.nonzero(Tensor([512, 80, 45, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([512, 80, 45, 28],"float32"), ) 	 51609600 	 1000 	 7.506618499755859 	 2.589249849319458 	 0.005524396896362305 	 0.0021355152130126953 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:42.160000 test begin: paddle.nonzero(Tensor([811, 80, 28, 28],"float32"), )
[Prof] paddle.nonzero 	 paddle.nonzero(Tensor([811, 80, 28, 28],"float32"), ) 	 50865920 	 1000 	 7.395501375198364 	 2.3108713626861572 	 0.0054473876953125 	 0.0021588802337646484 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:52.733502 test begin: paddle.not_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 15266, 16, 4, 1],"int64"), Tensor([13, 15266, 16, 1, 8],"int64"), ) 	 38103936 	 1000 	 0.551790714263916 	 0.5217044353485107 	 0.5421717166900635 	 0.5021834373474121 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:54.446083 test begin: paddle.not_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 122124, 4, 1],"int64"), Tensor([13, 2, 122124, 1, 8],"int64"), ) 	 38102688 	 1000 	 0.5619194507598877 	 0.515031099319458 	 0.5522487163543701 	 0.5014266967773438 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:56.161848 test begin: paddle.not_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 4, 15266],"int64"), Tensor([13, 2, 16, 1, 15266],"int64"), ) 	 31753280 	 1000 	 0.21288633346557617 	 0.21918749809265137 	 0.20312261581420898 	 0.20714473724365234 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:57.111378 test begin: paddle.not_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 4, 1],"int64"), Tensor([13, 2, 16, 1, 61062],"int64"), ) 	 25403456 	 1000 	 0.5628170967102051 	 0.47181081771850586 	 0.5531847476959229 	 0.4594075679779053 	 None 	 None 	 None 	 None 	 
2025-07-30 20:22:58.585836 test begin: paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 1, 8],"int64"), ) 	 25405120 	 1000 	 1.0402162075042725 	 0.9494812488555908 	 1.0305087566375732 	 0.9354763031005859 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:01.013354 test begin: paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 16, 61062, 1],"int64"), Tensor([13, 2, 16, 61062, 8],"int64"), ) 	 228616128 	 1000 	 1.7959043979644775 	 1.5709202289581299 	 1.7860963344573975 	 1.5556268692016602 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:08.443016 test begin: paddle.not_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 2, 244247, 4, 1],"int64"), Tensor([13, 2, 244247, 1, 8],"int64"), ) 	 76205064 	 1000 	 1.1169018745422363 	 1.0237011909484863 	 1.1068503856658936 	 1.0051662921905518 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:11.933300 test begin: paddle.not_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([13, 30531, 16, 4, 1],"int64"), Tensor([13, 30531, 16, 1, 8],"int64"), ) 	 76205376 	 1000 	 1.1087970733642578 	 1.0238566398620605 	 1.0915391445159912 	 1.005171775817871 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:15.317310 test begin: paddle.not_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([198451, 2, 16, 4, 1],"int64"), Tensor([198451, 2, 16, 1, 8],"int64"), ) 	 76205184 	 1000 	 1.0965790748596191 	 1.0237603187561035 	 1.0810930728912354 	 1.0114665031433105 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:18.646490 test begin: paddle.not_equal(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 0.310046911239624 	 0.31309938430786133 	 0.3013637065887451 	 0.3023860454559326 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:20.083896 test begin: paddle.not_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), )
[Prof] paddle.not_equal 	 paddle.not_equal(Tensor([99226, 2, 16, 4, 1],"int64"), Tensor([99226, 2, 16, 1, 8],"int64"), ) 	 38102784 	 1000 	 0.5516674518585205 	 0.5149986743927002 	 0.5419180393218994 	 0.4961707592010498 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:23.162140 test begin: paddle.numel(Tensor([508032010],"float32"), )
[Prof] paddle.numel 	 paddle.numel(Tensor([508032010],"float32"), ) 	 508032010 	 1000 	 0.008547782897949219 	 0.029343605041503906 	 1.2874603271484375e-05 	 3.910064697265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:31.237504 test begin: paddle.ones_like(Tensor([144, 392, 901],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([144, 392, 901],"float32"), ) 	 50859648 	 1000 	 0.13396334648132324 	 0.13430333137512207 	 0.12346601486206055 	 0.12235546112060547 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:32.378774 test begin: paddle.ones_like(Tensor([144, 901, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([144, 901, 392],"float32"), ) 	 50859648 	 1000 	 0.13399934768676758 	 0.1342926025390625 	 0.12359166145324707 	 0.12218475341796875 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:33.470536 test begin: paddle.ones_like(Tensor([160, 392, 811],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([160, 392, 811],"float32"), ) 	 50865920 	 1000 	 0.1340172290802002 	 0.13437891006469727 	 0.12348508834838867 	 0.1223154067993164 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:34.562116 test begin: paddle.ones_like(Tensor([160, 811, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([160, 811, 392],"float32"), ) 	 50865920 	 1000 	 0.13405060768127441 	 0.3679060935974121 	 0.12377691268920898 	 0.1160275936126709 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:39.094652 test begin: paddle.ones_like(Tensor([176, 392, 737],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([176, 392, 737],"float32"), ) 	 50847104 	 1000 	 0.13399028778076172 	 0.1408991813659668 	 0.12362241744995117 	 0.12239670753479004 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:40.211776 test begin: paddle.ones_like(Tensor([176, 737, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([176, 737, 392],"float32"), ) 	 50847104 	 1000 	 0.13396048545837402 	 0.13949799537658691 	 0.12371087074279785 	 0.12236785888671875 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:41.310182 test begin: paddle.ones_like(Tensor([331, 392, 392],"float32"), )
[Prof] paddle.ones_like 	 paddle.ones_like(Tensor([331, 392, 392],"float32"), ) 	 50862784 	 1000 	 0.13393402099609375 	 0.1377866268157959 	 0.12355995178222656 	 0.1220695972442627 	 None 	 None 	 None 	 None 	 
2025-07-30 20:23:42.414154 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([2],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([2],"float32"), ) 	 50803203 	 1000 	 5.271377801895142 	 0.5227766036987305 	 0.10992956161499023 	 0.5028700828552246 	 3.710392951965332 	 2.611804962158203 	 1.2619431018829346 	 0.5329892635345459 	 
2025-07-30 20:23:57.045963 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([32],"float32"), )
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([32],"float32"), ) 	 50803233 	 1000 	 5.3834452629089355 	 5.543250799179077 	 0.11227297782897949 	 1.4160525798797607 	 None 	 None 	 None 	 None 	 
2025-07-30 20:25:00.891966 test begin: paddle.outer(Tensor([50803201],"float32"), Tensor([4],"float32"), )
W0730 20:25:01.941957 47732 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.outer 	 paddle.outer(Tensor([50803201],"float32"), Tensor([4],"float32"), ) 	 50803205 	 1000 	 5.28289794921875 	 0.949066162109375 	 0.11017036437988281 	 0.9235670566558838 	 4.341421365737915 	 5.062161684036255 	 1.4768507480621338 	 1.0332963466644287 	 
2025-07-30 20:25:21.425813 test begin: paddle.pdist(Tensor([10, 5080321],"float32"), 0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([10, 5080321],"float32"), 0, ) 	 50803210 	 1000 	 5.937195062637329 	 9.017016649246216 	 6.389617919921875e-05 	 9.004608869552612 	 5.63170862197876 	 0.13436293601989746 	 0.0055027008056640625 	 0.049965858459472656 	 
2025-07-30 20:25:43.940137 test begin: paddle.pdist(Tensor([10, 5080321],"float32"), 1.0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([10, 5080321],"float32"), 1.0, ) 	 50803210 	 1000 	 5.919532060623169 	 8.374597787857056 	 5.1021575927734375e-05 	 8.363648653030396 	 22.80238151550293 	 13.583757638931274 	 0.022675514221191406 	 6.941673994064331 	 
2025-07-30 20:26:37.948923 test begin: paddle.pdist(Tensor([50, 508033],"float64"), 2.0, )
[Prof] paddle.pdist 	 paddle.pdist(Tensor([50, 508033],"float64"), 2.0, ) 	 25401650 	 1000 	 23.39496898651123 	 2.1460602283477783 	 5.5789947509765625e-05 	 2.134274482727051 	 87.92545413970947 	 39.32323336601257 	 0.08774471282958984 	 4.449186325073242 	 
2025-07-30 20:29:13.434948 test begin: paddle.polar(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 793801, 64],"float32"), Tensor([1, 793801, 64],"float32"), ) 	 101606528 	 1000 	 2.077854633331299 	 2.0737905502319336 	 0.4249536991119385 	 0.4240577220916748 	 4.615867614746094 	 5.035780668258667 	 0.6737825870513916 	 0.46774959564208984 	 combined
2025-07-30 20:29:30.164323 test begin: paddle.polar(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 8192, 6202],"float32"), Tensor([1, 8192, 6202],"float32"), ) 	 101613568 	 1000 	 2.0780701637268066 	 2.1027801036834717 	 0.42495179176330566 	 0.42413902282714844 	 4.614092588424683 	 5.036463499069214 	 0.6735928058624268 	 0.4677848815917969 	 combined
2025-07-30 20:29:48.724621 test begin: paddle.polar(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([1, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 51380224 	 1000 	 1.7935998439788818 	 1.803051471710205 	 0.36675310134887695 	 0.3686962127685547 	 3.4986724853515625 	 4.650879859924316 	 0.3968203067779541 	 0.3654448986053467 	 combined
2025-07-30 20:30:02.401866 test begin: paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([1, 8192, 64],"float32"), ) 	 51380224 	 1000 	 1.2098925113677979 	 1.2634308338165283 	 0.24767637252807617 	 0.2484731674194336 	 2.6080710887908936 	 2.8952908515930176 	 0.29530930519104004 	 0.22748351097106934 	 combined
2025-07-30 20:30:15.795909 test begin: paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), )
[Prof] paddle.polar 	 paddle.polar(Tensor([97, 8192, 64],"float32"), Tensor([97, 8192, 64],"float32"), ) 	 101711872 	 1000 	 2.079794406890869 	 2.075847625732422 	 0.4252619743347168 	 0.4244875907897949 	 4.618833303451538 	 5.0411670207977295 	 0.6743063926696777 	 0.4682488441467285 	 combined
2025-07-30 20:30:32.301046 test begin: paddle.polygamma(Tensor([10, 20, 254017],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([10, 20, 254017],"float32"), 1, ) 	 50803400 	 1000 	 5.574629545211792 	 0.6266849040985107 	 5.565706491470337 	 0.6158208847045898 	 9.066806554794312 	 10.255741357803345 	 9.011449813842773 	 5.240790128707886 	 
2025-07-30 20:31:00.068918 test begin: paddle.polygamma(Tensor([10, 5080321, 1],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([10, 5080321, 1],"float32"), 1, ) 	 50803210 	 1000 	 5.575730800628662 	 1.0870885848999023 	 5.567092418670654 	 0.616152286529541 	 9.067381143569946 	 10.265918493270874 	 9.012474298477173 	 5.245939016342163 	 
2025-07-30 20:31:29.981014 test begin: paddle.polygamma(Tensor([2, 12700801],"float64"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 12700801],"float64"), 1, ) 	 25401602 	 1000 	 9.256713628768921 	 0.645371675491333 	 9.248077630996704 	 0.6287550926208496 	 11.419313907623291 	 21.506543159484863 	 11.364313840866089 	 10.989789724349976 	 
2025-07-30 20:32:14.659081 test begin: paddle.polygamma(Tensor([2, 2, 6350401],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 2, 6350401],"float64"), 2, ) 	 25401604 	 1000 	 11.36266016960144 	 21.998845100402832 	 11.35300612449646 	 21.00819706916809 	 9.143970012664795 	 9.233739376068115 	 9.089508771896362 	 4.7179694175720215 	 
2025-07-30 20:33:08.932630 test begin: paddle.polygamma(Tensor([2, 2116801, 6],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2, 2116801, 6],"float64"), 2, ) 	 25401612 	 1000 	 11.36177134513855 	 21.051061868667603 	 11.353250980377197 	 21.040439128875732 	 9.114057302474976 	 9.230184078216553 	 9.058979034423828 	 4.71870756149292 	 
2025-07-30 20:34:00.850332 test begin: paddle.polygamma(Tensor([2116801, 2, 6],"float64"), 2, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2116801, 2, 6],"float64"), 2, ) 	 25401612 	 1000 	 11.36106824874878 	 21.041724920272827 	 11.352535724639893 	 21.03120708465576 	 9.113255977630615 	 9.236335515975952 	 9.046699047088623 	 4.7176923751831055 	 
2025-07-30 20:34:52.779844 test begin: paddle.polygamma(Tensor([2540161, 20, 1],"float32"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([2540161, 20, 1],"float32"), 1, ) 	 50803220 	 1000 	 5.574997663497925 	 0.6265707015991211 	 5.566083192825317 	 0.6161477565765381 	 9.06661343574524 	 10.246191263198853 	 9.010154724121094 	 5.235574960708618 	 
2025-07-30 20:35:20.020620 test begin: paddle.polygamma(Tensor([4233601, 6],"float64"), 1, )
[Prof] paddle.polygamma 	 paddle.polygamma(Tensor([4233601, 6],"float64"), 1, ) 	 25401606 	 1000 	 9.246544599533081 	 0.6396639347076416 	 9.237942934036255 	 0.629202127456665 	 11.418787002563477 	 21.479206562042236 	 11.362667322158813 	 10.975291967391968 	 
2025-07-30 20:36:03.969783 test begin: paddle.positive(Tensor([100, 5080321],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.0018451213836669922 	 0.00021314620971679688 	 1.1205673217773438e-05 	 1.52587890625e-05 	 0.031029701232910156 	 0.04700732231140137 	 3.4332275390625e-05 	 5.91278076171875e-05 	 combined
2025-07-30 20:36:19.958306 test begin: paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([16934410, 3, 4, 5],"float16"), ) 	 1016064600 	 1000 	 0.0018630027770996094 	 0.00020551681518554688 	 1.8596649169921875e-05 	 1.4543533325195312e-05 	 0.032228946685791016 	 0.047563791275024414 	 5.340576171875e-05 	 4.863739013671875e-05 	 combined
2025-07-30 20:36:58.670070 test begin: paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 1270081, 4, 5],"float32"), ) 	 508032400 	 1000 	 0.0018301010131835938 	 0.0001995563507080078 	 6.9141387939453125e-06 	 1.4543533325195312e-05 	 0.031112194061279297 	 0.04790806770324707 	 4.696846008300781e-05 	 5.7697296142578125e-05 	 combined
2025-07-30 20:37:15.131769 test begin: paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 2540161, 4, 5],"float16"), ) 	 1016064400 	 1000 	 0.0018448829650878906 	 0.00020623207092285156 	 7.152557373046875e-06 	 2.09808349609375e-05 	 0.030750036239624023 	 0.048525094985961914 	 2.384185791015625e-05 	 6.794929504394531e-05 	 combined
2025-07-30 20:37:53.123223 test begin: paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 1693441, 5],"float32"), ) 	 508032300 	 1000 	 0.001889944076538086 	 0.00020003318786621094 	 9.5367431640625e-06 	 1.3828277587890625e-05 	 0.03092646598815918 	 0.049872398376464844 	 3.337860107421875e-05 	 7.510185241699219e-05 	 combined
2025-07-30 20:38:09.836412 test begin: paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 3386881, 5],"float16"), ) 	 1016064300 	 1000 	 0.0018565654754638672 	 0.00020074844360351562 	 2.47955322265625e-05 	 1.52587890625e-05 	 0.030887603759765625 	 0.0480189323425293 	 2.288818359375e-05 	 6.890296936035156e-05 	 combined
2025-07-30 20:38:47.736559 test begin: paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 2116801],"float32"), ) 	 508032240 	 1000 	 0.0018465518951416016 	 0.00019931793212890625 	 1.0728836059570312e-05 	 1.430511474609375e-05 	 0.03366708755493164 	 0.050223350524902344 	 2.7418136596679688e-05 	 7.104873657226562e-05 	 combined
2025-07-30 20:39:06.321290 test begin: paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([20, 3, 4, 4233601],"float16"), ) 	 1016064240 	 1000 	 0.0018532276153564453 	 0.00020623207092285156 	 3.5762786865234375e-05 	 1.5497207641601562e-05 	 0.030940771102905273 	 0.04738736152648926 	 2.0503997802734375e-05 	 4.8160552978515625e-05 	 combined
2025-07-30 20:39:44.151169 test begin: paddle.positive(Tensor([496130, 1024],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([496130, 1024],"float32"), ) 	 508037120 	 1000 	 0.0018429756164550781 	 0.00020384788513183594 	 1.0728836059570312e-05 	 1.3589859008789062e-05 	 0.031002044677734375 	 0.04648232460021973 	 2.3365020751953125e-05 	 4.57763671875e-05 	 combined
2025-07-30 20:40:00.717599 test begin: paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), )
[Prof] paddle.positive 	 paddle.positive(Tensor([8467210, 3, 4, 5],"float32"), ) 	 508032600 	 1000 	 0.003063201904296875 	 0.00019979476928710938 	 3.528594970703125e-05 	 1.4543533325195312e-05 	 0.030966997146606445 	 0.04744768142700195 	 2.9325485229492188e-05 	 3.147125244140625e-05 	 combined
2025-07-30 20:40:17.224158 test begin: paddle.pow(Tensor([1024, 1024, 25],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 1024, 25],"float64"), 2, ) 	 26214400 	 1000 	 0.5897228717803955 	 0.307858943939209 	 0.5806503295898438 	 0.2951927185058594 	 0.6224257946014404 	 1.0846562385559082 	 0.5665240287780762 	 0.3695220947265625 	 
2025-07-30 20:40:20.987863 test begin: paddle.pow(Tensor([1024, 1024, 49],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 1024, 49],"float32"), 2, ) 	 51380224 	 1000 	 0.3724822998046875 	 0.30109572410583496 	 0.36341261863708496 	 0.28854799270629883 	 0.45774102210998535 	 1.0641238689422607 	 0.39858341217041016 	 0.3625810146331787 	 
2025-07-30 20:40:24.955293 test begin: paddle.pow(Tensor([1024, 3101, 8],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 3101, 8],"float64"), 2, ) 	 25403392 	 1000 	 0.5716843605041504 	 0.29837608337402344 	 0.5626320838928223 	 0.2848210334777832 	 0.6036620140075684 	 1.0511894226074219 	 0.5481653213500977 	 0.35812950134277344 	 
2025-07-30 20:40:28.546933 test begin: paddle.pow(Tensor([1024, 6202, 8],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([1024, 6202, 8],"float32"), 2, ) 	 50806784 	 1000 	 0.3685286045074463 	 0.30202794075012207 	 0.35887718200683594 	 0.2852959632873535 	 0.4525430202484131 	 1.0526728630065918 	 0.3961808681488037 	 0.358614444732666 	 
2025-07-30 20:40:32.391274 test begin: paddle.pow(Tensor([22, 81, 94, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([22, 81, 94, 311],"float32"), 2.0, ) 	 52094988 	 1000 	 0.3781452178955078 	 0.31291961669921875 	 0.3690216541290283 	 0.2891108989715576 	 0.46339893341064453 	 1.0819566249847412 	 0.404832124710083 	 0.2765932083129883 	 
2025-07-30 20:40:39.480977 test begin: paddle.pow(Tensor([3101, 1024, 8],"float64"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([3101, 1024, 8],"float64"), 2, ) 	 25403392 	 1000 	 0.5716001987457275 	 0.29833459854125977 	 0.5626718997955322 	 0.28591012954711914 	 0.6036663055419922 	 1.0513272285461426 	 0.5473201274871826 	 0.35816097259521484 	 
2025-07-30 20:40:43.069692 test begin: paddle.pow(Tensor([4, 435, 94, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 435, 94, 311],"float32"), 2.0, ) 	 50867160 	 1000 	 0.368943452835083 	 0.29819393157958984 	 0.3597850799560547 	 0.2849407196044922 	 0.4528319835662842 	 1.0568172931671143 	 0.3966708183288574 	 0.27024078369140625 	 
2025-07-30 20:40:46.920134 test begin: paddle.pow(Tensor([4, 81, 505, 311],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 81, 505, 311],"float32"), 2.0, ) 	 50885820 	 1000 	 0.3694634437561035 	 0.29831790924072266 	 0.36028552055358887 	 0.28484582901000977 	 0.4529862403869629 	 1.0568578243255615 	 0.396594762802124 	 0.27025461196899414 	 
2025-07-30 20:40:50.835276 test begin: paddle.pow(Tensor([4, 81, 94, 1669],"float32"), 2.0, )
[Prof] paddle.pow 	 paddle.pow(Tensor([4, 81, 94, 1669],"float32"), 2.0, ) 	 50831064 	 1000 	 0.36878323554992676 	 0.29801368713378906 	 0.3595564365386963 	 0.28519725799560547 	 0.4527106285095215 	 1.0562047958374023 	 0.39652061462402344 	 0.27007365226745605 	 
2025-07-30 20:40:54.666410 test begin: paddle.pow(Tensor([6202, 1024, 8],"float32"), 2, )
[Prof] paddle.pow 	 paddle.pow(Tensor([6202, 1024, 8],"float32"), 2, ) 	 50806784 	 1000 	 0.36848020553588867 	 0.29788851737976074 	 0.359450101852417 	 0.2852349281311035 	 0.4523961544036865 	 1.0527253150939941 	 0.3965446949005127 	 0.3586537837982178 	 
2025-07-30 20:40:58.513249 test begin: paddle.prod(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
Warning: The core code of paddle.prod is too complex.
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 10, 28225, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 5.562676191329956 	 0.035182952880859375 	 0.005441188812255859 	 3.695487976074219e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9]) and output[0] has a shape of torch.Size([1, 1, 1, 9]).
2025-07-30 20:41:07.659286 test begin: paddle.prod(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 10, 9, 28225],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402502 	 1000 	 0.32761120796203613 	 0.035402774810791016 	 0.0002257823944091797 	 6.580352783203125e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([28225]) and output[0] has a shape of torch.Size([1, 1, 1, 28225]).
2025-07-30 20:41:10.242832 test begin: paddle.prod(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 31361, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402412 	 1000 	 0.2545461654663086 	 0.024161815643310547 	 0.00022339820861816406 	 3.4332275390625e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([10, 31361]) and output[0] has a shape of torch.Size([10, 31361, 1, 1]).
2025-07-30 20:41:14.018492 test begin: paddle.prod(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 31361, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.3272664546966553 	 0.03544354438781738 	 0.00023293495178222656 	 4.482269287109375e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9]) and output[0] has a shape of torch.Size([1, 1, 9, 1]).
2025-07-30 20:41:16.916687 test begin: paddle.prod(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 5, 56449, 9],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.5077600479125977 	 0.023321151733398438 	 0.0004405975341796875 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([5, 9]) and output[0] has a shape of torch.Size([1, 5, 1, 9]).
2025-07-30 20:41:18.835630 test begin: paddle.prod(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([10, 5, 9, 56449],"float64"), Tensor([2],"int64"), ) 	 25402052 	 1000 	 0.20315194129943848 	 0.023624658584594727 	 0.00016641616821289062 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([5, 9]) and output[0] has a shape of torch.Size([1, 5, 9, 1]).
2025-07-30 20:41:20.443762 test begin: paddle.prod(Tensor([16, 3175201],"float32"), -1, )
[Prof] paddle.prod 	 paddle.prod(Tensor([16, 3175201],"float32"), -1, ) 	 50803216 	 1000 	 0.17807841300964355 	 0.15290164947509766 	 0.0909724235534668 	 0.07797765731811523 	 0.7915198802947998 	 1.5822327136993408 	 0.7335178852081299 	 0.0006387233734130859 	 
2025-07-30 20:41:24.008560 test begin: paddle.prod(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], )
[Prof] paddle.prod 	 paddle.prod(Tensor([31361, 10, 9, 9],"float64"), list[0,Tensor([1],"int64"),Tensor([1],"int64"),], ) 	 25402412 	 1000 	 0.33106017112731934 	 0.03526902198791504 	 0.00023055076599121094 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([9]) and output[0] has a shape of torch.Size([1, 1, 9, 1]).
2025-07-30 20:41:25.748320 test begin: paddle.prod(Tensor([49613, 1024],"float32"), -1, )
[Prof] paddle.prod 	 paddle.prod(Tensor([49613, 1024],"float32"), -1, ) 	 50803712 	 1000 	 0.14637994766235352 	 0.1473386287689209 	 0.1309819221496582 	 0.13383889198303223 	 0.7914688587188721 	 1.59464430809021 	 0.7336468696594238 	 0.0006394386291503906 	 
2025-07-30 20:41:29.246544 test begin: paddle.prod(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[Prof] paddle.prod 	 paddle.prod(Tensor([62721, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 	 25402007 	 1000 	 0.5637052059173584 	 0.024237871170043945 	 0.0005321502685546875 	 4.553794860839844e-05 	 None 	 None 	 None 	 None 	 
[Error] Mismatch in shape: grad_output[0] has a shape of torch.Size([62721, 9]) and output[0] has a shape of torch.Size([62721, 1, 1, 9]).
2025-07-30 20:41:31.231660 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 25402750 	 1000 	 39.06670069694519 	 52.33450174331665 	 0.03848099708557129 	 17.847639560699463 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:44:00.437268 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([2032129, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([2032129, 5, 5],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13192200660705566 	 0.025959014892578125 	 2.288818359375e-05 	 5.245208740234375e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:44:00.690685 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 2032129, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 2032129, 5],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13431763648986816 	 0.026036739349365234 	 3.8623809814453125e-05 	 4.673004150390625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:44:00.948606 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 2032129],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 2032129],"float32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13497138023376465 	 0.025959491729736328 	 2.2172927856445312e-05 	 5.078315734863281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:44:01.207744 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 2032129, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 2032129, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 49.84231972694397 	 45.746018171310425 	 0.04895472526550293 	 15.595741987228394 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:47:33.446382 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([2032129, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([2032129, 5, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13092398643493652 	 0.025987863540649414 	 2.5272369384765625e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:47:33.702232 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 2032129, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 2032129, 5],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.1370255947113037 	 0.0263974666595459 	 2.6464462280273438e-05 	 6.437301635742188e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:47:33.985231 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 2032129],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 2032129],"int32"), 1, "mul", True, False, ) 	 50804350 	 1000 	 0.13146281242370605 	 0.026241064071655273 	 2.2411346435546875e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:47:34.242465 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 1016065, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 24.248110055923462 	 25.308806657791138 	 0.02467513084411621 	 8.630460739135742 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:22.771576 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([1016065, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([1016065, 5, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.13491272926330566 	 0.02603626251220703 	 1.71661376953125e-05 	 3.123283386230469e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:23.029472 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 1016065, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 1016065, 5],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.13277769088745117 	 0.02637958526611328 	 1.4543533325195312e-05 	 4.792213439941406e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:23.283756 test begin: paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 1016065],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 1016065],"int64"), 1, "mul", True, False, ) 	 25402750 	 1000 	 0.13216185569763184 	 0.025905847549438477 	 1.9788742065429688e-05 	 3.24249267578125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:23.534359 test begin: paddle.put_along_axis(Tensor([10, 10, 254017],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 254017],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.378436803817749 	 0.6311697959899902 	 0.0003046989440917969 	 0.12872934341430664 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:25.759422 test begin: paddle.put_along_axis(Tensor([10, 10, 508033],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 508033],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37162160873413086 	 0.6305725574493408 	 0.00030422210693359375 	 0.1286153793334961 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:49:28.857452 test begin: paddle.put_along_axis(Tensor([10, 10, 508033],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 10, 508033],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37043213844299316 	 0.63089919090271 	 0.0003025531768798828 	 0.12869548797607422 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:31.494995 test begin: paddle.put_along_axis(Tensor([10, 254017, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 254017, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.37926673889160156 	 0.6301970481872559 	 0.00030922889709472656 	 0.12853050231933594 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:33.909425 test begin: paddle.put_along_axis(Tensor([10, 508033, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 508033, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37293267250061035 	 0.6344313621520996 	 0.0003027915954589844 	 0.12854623794555664 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:49:39.419715 test begin: paddle.put_along_axis(Tensor([10, 508033, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([10, 508033, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.37153029441833496 	 0.630178689956665 	 0.0003020763397216797 	 0.12853574752807617 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:42.269622 test begin: paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([254017, 5, 5],"int64"), Tensor([254017, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([254017, 5, 5],"int64"), Tensor([254017, 5, 5],"int64"), 1, "mul", True, False, ) 	 38102550 	 1000 	 0.8293349742889404 	 1.0303242206573486 	 0.000621795654296875 	 0.21059465408325195 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:49:58.679109 test begin: paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([254017, 10, 10],"int64"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"int64"), 1, "mul", True, False, ) 	 25401950 	 1000 	 0.37907958030700684 	 0.8653924465179443 	 0.0003101825714111328 	 0.12873005867004395 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:50:04.675009 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([254017, 5, 5],"int64"), Tensor([508033, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([254017, 5, 5],"int64"), Tensor([508033, 5, 5],"float32"), 1, "mul", True, False, ) 	 69854550 	 1000 	 0.7764074802398682 	 0.9565629959106445 	 0.0005738735198974609 	 0.19541120529174805 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:50:21.474365 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"float32"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"float32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.3727724552154541 	 0.6315708160400391 	 0.00030517578125 	 0.12862563133239746 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:50:24.577711 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([5, 5, 5],"int32"), Tensor([5, 5, 5],"int32"), 1, "mul", True, False, ) 	 50803550 	 1000 	 0.371412992477417 	 0.6307027339935303 	 0.0003027915954589844 	 0.1286470890045166 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:50:27.225844 test begin: paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([508033, 5, 5],"int32"), Tensor([508033, 5, 5],"int32"), 1, "mul", True, False, )
[Prof] paddle.put_along_axis 	 paddle.put_along_axis(Tensor([508033, 10, 10],"int32"), Tensor([508033, 5, 5],"int32"), Tensor([508033, 5, 5],"int32"), 1, "mul", True, False, ) 	 76204950 	 1000 	 1.0504896640777588 	 1.259343147277832 	 0.0008373260498046875 	 0.25761890411376953 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:50:56.647140 test begin: paddle.rad2deg(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.295642614364624 	 0.2978525161743164 	 0.2804393768310547 	 0.28374385833740234 	 0.29561328887939453 	 0.29782700538635254 	 0.2418067455291748 	 0.2290048599243164 	 
2025-07-30 20:50:59.476814 test begin: paddle.rad2deg(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.2957744598388672 	 0.29784727096557617 	 0.2809133529663086 	 0.2837953567504883 	 0.29601407051086426 	 0.29784297943115234 	 0.24288153648376465 	 0.21078753471374512 	 
2025-07-30 20:51:02.330872 test begin: paddle.rad2deg(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.29573535919189453 	 0.29789257049560547 	 0.27889180183410645 	 0.28386998176574707 	 0.29575061798095703 	 0.2978169918060303 	 0.24268126487731934 	 0.20828819274902344 	 
2025-07-30 20:51:07.550767 test begin: paddle.rad2deg(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.2980175018310547 	 0.31882739067077637 	 0.2833125591278076 	 0.28439927101135254 	 0.2980997562408447 	 0.2984178066253662 	 0.24565577507019043 	 0.22876286506652832 	 
2025-07-30 20:51:13.999803 test begin: paddle.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.29790687561035156 	 0.3037087917327881 	 0.28289008140563965 	 0.28455209732055664 	 0.29814910888671875 	 0.29840970039367676 	 0.24543547630310059 	 0.22986865043640137 	 
2025-07-30 20:51:17.031637 test begin: paddle.rad2deg(x=Tensor([4, 1587601, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 1587601, 4],"float64"), ) 	 25401616 	 1000 	 0.2979912757873535 	 0.29842543601989746 	 0.28299546241760254 	 0.2848806381225586 	 0.2981290817260742 	 0.29838109016418457 	 0.24436116218566895 	 0.23073768615722656 	 
2025-07-30 20:51:19.282066 test begin: paddle.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.29785847663879395 	 0.30115723609924316 	 0.2828178405761719 	 0.2844080924987793 	 0.29817771911621094 	 0.29851436614990234 	 0.2453629970550537 	 0.22814369201660156 	 
2025-07-30 20:51:21.532321 test begin: paddle.rad2deg(x=Tensor([4, 4, 1587601],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 1587601],"float64"), ) 	 25401616 	 1000 	 0.2980215549468994 	 0.29938578605651855 	 0.2829303741455078 	 0.2845571041107178 	 0.2981407642364502 	 0.2983665466308594 	 0.24544763565063477 	 0.2294750213623047 	 
2025-07-30 20:51:23.772741 test begin: paddle.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.29796671867370605 	 0.29845166206359863 	 0.2829554080963135 	 0.28457188606262207 	 0.2981429100036621 	 0.29834771156311035 	 0.2451019287109375 	 0.22978568077087402 	 
2025-07-30 20:51:26.034254 test begin: paddle.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.rad2deg 	 paddle.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.2979161739349365 	 0.2985076904296875 	 0.2828176021575928 	 0.2842099666595459 	 0.2981700897216797 	 0.2984287738800049 	 0.24327898025512695 	 0.23012471199035645 	 
2025-07-30 20:51:28.278106 test begin: paddle.rank(input=Tensor([1270080101, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([1270080101, 2],"float64"), ) 	 2540160202 	 1000 	 0.06293678283691406 	 0.027922391891479492 	 3.6716461181640625e-05 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
Error: Can not import paddle core while this file exists: /usr/local/lib/python3.10/dist-packages/paddle/base/libpaddle.so

2025-07-30 19:24:29.018809 test begin: paddle.Tensor.__abs__(Tensor([10, 5080321],"float32"), )
W0730 19:24:30.046461 24004 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.298450231552124 	 0.29905128479003906 	 0.28693652153015137 	 0.28423643112182617 	 0.4504666328430176 	 0.7428188323974609 	 0.3944988250732422 	 0.37946200370788574 	 
2025-07-30 19:24:33.122561 test begin: paddle.Tensor.__abs__(Tensor([49613, 1024],"float32"), )
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([49613, 1024],"float32"), ) 	 50803712 	 1000 	 0.3035621643066406 	 0.7518537044525146 	 0.2870066165924072 	 0.28496885299682617 	 0.4503517150878906 	 0.7427208423614502 	 0.39681458473205566 	 0.3794705867767334 	 
2025-07-30 19:24:39.339215 test begin: paddle.Tensor.__abs__(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.__abs__ 	 paddle.Tensor.__abs__(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.3114752769470215 	 0.2977750301361084 	 0.28835582733154297 	 0.28496742248535156 	 0.45179200172424316 	 0.7426931858062744 	 0.39530253410339355 	 0.37946319580078125 	 
2025-07-30 19:24:42.788258 test begin: paddle.Tensor.__add__(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 1, 388, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 388, 4096],"float32"), Tensor([1, 1, 388, 4096],"float32"), ) 	 52445184 	 1000 	 0.33673906326293945 	 0.3239786624908447 	 0.32231736183166504 	 0.31141042709350586 	 0.47664856910705566 	 0.153761625289917 	 0.24347949028015137 	 0.08450531959533691 	 
2025-07-30 19:24:45.880400 test begin: paddle.Tensor.__add__(Tensor([1, 32, 4096, 388],"float32"), Tensor([1, 1, 4096, 388],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 4096, 388],"float32"), Tensor([1, 1, 4096, 388],"float32"), ) 	 52445184 	 1000 	 0.3358783721923828 	 0.32402610778808594 	 0.32563114166259766 	 0.3114936351776123 	 0.47649216651916504 	 0.15366220474243164 	 0.24343609809875488 	 0.08490157127380371 	 
2025-07-30 19:24:48.864629 test begin: paddle.Tensor.__add__(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 32, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), ) 	 553648128 	 1000 	 4.703588247299194 	 4.625918865203857 	 4.682546854019165 	 4.612982273101807 	 4.966688632965088 	 1.5599236488342285 	 1.690347671508789 	 1.4915432929992676 	 
2025-07-30 19:25:24.403380 test begin: paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 1, 4096, 4096],"float32"), ) 	 83886080 	 1000 	 0.5928382873535156 	 0.5831987857818604 	 0.5825059413909912 	 0.566662073135376 	 0.6633658409118652 	 0.24399805068969727 	 0.3389260768890381 	 0.17496395111083984 	 
2025-07-30 19:25:28.971730 test begin: paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 4096],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([1, 4, 4096, 4096],"float32"), Tensor([1, 4, 4096, 4096],"float32"), ) 	 134217728 	 1000 	 0.593480110168457 	 0.5881760120391846 	 0.5841195583343506 	 0.576833963394165 	 0.6364848613739014 	 0.053253889083862305 	 0.5782949924468994 	 4.6253204345703125e-05 	 
2025-07-30 19:25:34.150725 test begin: paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float16"), Tensor([2, 256, 336, 336],"float32"), )
W0730 19:25:36.145833 24974 dygraph_functions.cc:87088] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float16"), Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.783583402633667 	 0.49311304092407227 	 0.40038442611694336 	 0.4541351795196533 	 0.8027966022491455 	 0.26030945777893066 	 0.41011738777160645 	 0.1916348934173584 	 
2025-07-30 19:25:40.808705 test begin: paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float32"), Tensor([2, 256, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([2, 256, 336, 336],"float32"), Tensor([2, 256, 336, 336],"float32"), ) 	 115605504 	 1000 	 0.5118389129638672 	 0.5075902938842773 	 0.5024967193603516 	 0.49590587615966797 	 0.5487639904022217 	 0.05399155616760254 	 0.4896724224090576 	 3.886222839355469e-05 	 
2025-07-30 19:25:45.235534 test begin: paddle.Tensor.__add__(Tensor([4, 256, 336, 336],"float16"), Tensor([4, 256, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([4, 256, 336, 336],"float16"), Tensor([4, 256, 336, 336],"float32"), ) 	 231211008 	 1000 	 1.562009334564209 	 0.9312660694122314 	 0.7981264591217041 	 0.9140713214874268 	 1.600684642791748 	 0.5155181884765625 	 0.817786455154419 	 0.4463939666748047 	 
2025-07-30 19:25:55.883966 test begin: paddle.Tensor.__add__(Tensor([8, 113, 336, 336],"float16"), Tensor([8, 113, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 113, 336, 336],"float16"), Tensor([8, 113, 336, 336],"float32"), ) 	 204115968 	 1000 	 1.379850149154663 	 0.8188674449920654 	 0.7051045894622803 	 0.8063924312591553 	 1.4155821800231934 	 0.45560312271118164 	 0.7233262062072754 	 0.3849635124206543 	 
2025-07-30 19:26:08.023379 test begin: paddle.Tensor.__add__(Tensor([8, 256, 336, 74],"float32"), Tensor([8, 256, 336, 74],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 256, 336, 74],"float32"), Tensor([8, 256, 336, 74],"float32"), ) 	 101842944 	 1000 	 0.45140910148620605 	 0.4476749897003174 	 0.43817758560180664 	 0.4355323314666748 	 0.4839160442352295 	 0.05360746383666992 	 0.4241955280303955 	 3.695487976074219e-05 	 
2025-07-30 19:26:12.076504 test begin: paddle.Tensor.__add__(Tensor([8, 256, 74, 336],"float32"), Tensor([8, 256, 74, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 256, 74, 336],"float32"), Tensor([8, 256, 74, 336],"float32"), ) 	 101842944 	 1000 	 0.45134496688842773 	 0.447723388671875 	 0.44203782081604004 	 0.4359126091003418 	 0.4838705062866211 	 0.053444623947143555 	 0.4185361862182617 	 4.100799560546875e-05 	 
2025-07-30 19:26:16.023653 test begin: paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float16"), Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float16"), Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.6988303661346436 	 0.41618919372558594 	 0.3571343421936035 	 0.3990445137023926 	 0.7165505886077881 	 0.23235130310058594 	 0.36601877212524414 	 0.16330480575561523 	 
2025-07-30 19:26:20.844588 test begin: paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float32"), Tensor([8, 57, 336, 336],"float32"), )
[Prof] paddle.Tensor.__add__ 	 paddle.Tensor.__add__(Tensor([8, 57, 336, 336],"float32"), Tensor([8, 57, 336, 336],"float32"), ) 	 102961152 	 1000 	 0.4564027786254883 	 0.45261335372924805 	 0.4469773769378662 	 0.44060230255126953 	 0.4891359806060791 	 0.05371236801147461 	 0.43052196502685547 	 4.1484832763671875e-05 	 
2025-07-30 19:26:24.978296 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.1611950397491455 	 0.2267162799835205 	 0.15118956565856934 	 0.21184873580932617 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:26.204658 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.1611621379852295 	 0.22676539421081543 	 0.15138554573059082 	 0.21365952491760254 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:27.400098 test begin: paddle.Tensor.__and__(Tensor([1, 1, 2048, 24807],"bool"), Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 2048, 24807],"bool"), Tensor([1, 1, 2048, 24807],"bool"), ) 	 101609472 	 1000 	 0.1177213191986084 	 0.11544346809387207 	 0.10889291763305664 	 0.10277628898620605 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:29.049507 test begin: paddle.Tensor.__and__(Tensor([1, 1, 24807, 2048],"bool"), Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 1, 24807, 2048],"bool"), Tensor([1, 1, 24807, 2048],"bool"), ) 	 101609472 	 1000 	 0.11771893501281738 	 0.11540460586547852 	 0.10889911651611328 	 0.10318374633789062 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:30.713208 test begin: paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.18054509162902832 	 0.22663140296936035 	 0.1705949306488037 	 0.21382641792297363 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:31.955613 test begin: paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([1, 13, 2048, 2048],"bool"), Tensor([1, 13, 2048, 2048],"bool"), ) 	 109051904 	 1000 	 0.12560725212097168 	 0.12335658073425293 	 0.11666083335876465 	 0.11153435707092285 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:33.713100 test begin: paddle.Tensor.__and__(Tensor([13, 1, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), ) 	 65913185 	 1000 	 0.1847221851348877 	 0.2388746738433838 	 0.1738142967224121 	 0.22510266304016113 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:35.060850 test begin: paddle.Tensor.__and__(Tensor([13, 1, 1007, 3881],"bool"), Tensor([13, 1, 1007, 3881],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 1007, 3881],"bool"), Tensor([13, 1, 1007, 3881],"bool"), ) 	 101612342 	 1000 	 0.11799478530883789 	 0.11907100677490234 	 0.10869216918945312 	 0.1035313606262207 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:39.707958 test begin: paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([1, 1, 2048, 2048],"bool"), ) 	 58720256 	 1000 	 0.1805400848388672 	 0.231154203414917 	 0.17065024375915527 	 0.21386456489562988 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:40.945710 test begin: paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 2048, 2048],"bool"), Tensor([13, 1, 2048, 2048],"bool"), ) 	 109051904 	 1000 	 0.12562251091003418 	 0.12343358993530273 	 0.11673974990844727 	 0.11140084266662598 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:42.732873 test begin: paddle.Tensor.__and__(Tensor([13, 1, 3881, 1007],"bool"), Tensor([13, 1, 3881, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 1, 3881, 1007],"bool"), Tensor([13, 1, 3881, 1007],"bool"), ) 	 101612342 	 1000 	 0.1180257797241211 	 0.11589789390563965 	 0.10907530784606934 	 0.10365581512451172 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:44.392298 test begin: paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 1, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 1, 1007, 1007],"bool"), ) 	 65913185 	 1000 	 0.19786572456359863 	 0.2387845516204834 	 0.18787837028503418 	 0.22574925422668457 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:45.734649 test begin: paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([13, 4, 1007, 1007],"bool"), Tensor([13, 4, 1007, 1007],"bool"), ) 	 105461096 	 1000 	 0.12277579307556152 	 0.12073564529418945 	 0.113861083984375 	 0.10803961753845215 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:47.487307 test begin: paddle.Tensor.__and__(Tensor([194, 1, 512, 512],"bool"), Tensor([194, 1, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([194, 1, 512, 512],"bool"), Tensor([194, 1, 512, 512],"bool"), ) 	 101711872 	 1000 	 0.11780166625976562 	 0.11760640144348145 	 0.10460209846496582 	 0.10330486297607422 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:49.160944 test begin: paddle.Tensor.__and__(Tensor([51, 1, 1007, 1007],"bool"), Tensor([51, 1, 1007, 1007],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([51, 1, 1007, 1007],"bool"), Tensor([51, 1, 1007, 1007],"bool"), ) 	 103432998 	 1000 	 0.11940860748291016 	 0.11774921417236328 	 0.11049938201904297 	 0.10594367980957031 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:50.884317 test begin: paddle.Tensor.__and__(Tensor([8, 1, 12404, 512],"bool"), Tensor([8, 1, 12404, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 12404, 512],"bool"), Tensor([8, 1, 12404, 512],"bool"), ) 	 101613568 	 1000 	 0.11776351928710938 	 0.11540699005126953 	 0.10861015319824219 	 0.10312056541442871 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:52.577944 test begin: paddle.Tensor.__and__(Tensor([8, 1, 512, 12404],"bool"), Tensor([8, 1, 512, 12404],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 512, 12404],"bool"), Tensor([8, 1, 512, 12404],"bool"), ) 	 101613568 	 1000 	 0.1176905632019043 	 0.11890316009521484 	 0.1087195873260498 	 0.10310888290405273 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:54.259252 test begin: paddle.Tensor.__and__(Tensor([8, 1, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 1, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), ) 	 54525952 	 1000 	 0.183607816696167 	 0.23565101623535156 	 0.17378664016723633 	 0.2228386402130127 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:55.443919 test begin: paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 1, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 1, 512, 512],"bool"), ) 	 54525952 	 1000 	 0.19349932670593262 	 0.2356407642364502 	 0.18358540534973145 	 0.22228384017944336 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:56.636971 test begin: paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), )
[Prof] paddle.Tensor.__and__ 	 paddle.Tensor.__and__(Tensor([8, 25, 512, 512],"bool"), Tensor([8, 25, 512, 512],"bool"), ) 	 104857600 	 1000 	 0.1209559440612793 	 0.11905598640441895 	 0.11205577850341797 	 0.10702800750732422 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:58.354564 test begin: paddle.Tensor.__div__(Tensor([8, 16, 396901],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([8, 16, 396901],"float32"), 2, ) 	 50803328 	 1000 	 0.295642614364624 	 0.29799532890319824 	 0.2867441177368164 	 0.2836263179779053 	 0.295635461807251 	 0.29769039154052734 	 0.24436068534851074 	 0.23581767082214355 	 
2025-07-30 19:27:01.219365 test begin: paddle.Tensor.__div__(Tensor([8, 198451, 32],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([8, 198451, 32],"float32"), 2, ) 	 50803456 	 1000 	 0.29578590393066406 	 0.29788637161254883 	 0.28688716888427734 	 0.2836611270904541 	 0.29605650901794434 	 0.29765868186950684 	 0.23868155479431152 	 0.23619437217712402 	 
2025-07-30 19:27:04.099996 test begin: paddle.Tensor.__div__(Tensor([99226, 16, 32],"float32"), 2, )
[Prof] paddle.Tensor.__div__ 	 paddle.Tensor.__div__(Tensor([99226, 16, 32],"float32"), 2, ) 	 50803712 	 1000 	 0.2957878112792969 	 0.2979292869567871 	 0.2861499786376953 	 0.28386402130126953 	 0.2957949638366699 	 0.29776763916015625 	 0.24436688423156738 	 0.23536896705627441 	 
2025-07-30 19:27:06.953121 test begin: paddle.Tensor.__eq__(Tensor([138, 369303],"float32"), Tensor([138, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([138, 369303],"float32"), Tensor([138, 1],"float32"), ) 	 50963952 	 1000 	 0.1920619010925293 	 0.24213600158691406 	 0.18244099617004395 	 0.22954106330871582 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:09.853302 test begin: paddle.Tensor.__eq__(Tensor([146, 349866],"float32"), Tensor([146, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([146, 349866],"float32"), Tensor([146, 1],"float32"), ) 	 51080582 	 1000 	 0.19232845306396484 	 0.24893617630004883 	 0.18272876739501953 	 0.2300243377685547 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:13.380765 test begin: paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1036801],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1036801],"float32"), ) 	 101606498 	 1000 	 0.32683515548706055 	 0.32779622077941895 	 0.31798791885375977 	 0.31589770317077637 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:15.671152 test begin: paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([49, 1036801],"float32"), Tensor([49, 1],"float32"), ) 	 50803298 	 1000 	 0.191694974899292 	 0.24135255813598633 	 0.18037867546081543 	 0.2268984317779541 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:16.939159 test begin: paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 1],"float32"), ) 	 50803256 	 1000 	 0.19169330596923828 	 0.24149656295776367 	 0.18210983276367188 	 0.22900795936584473 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:18.224124 test begin: paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 958551],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([53, 958551],"float32"), Tensor([53, 958551],"float32"), ) 	 101606406 	 1000 	 0.3267998695373535 	 0.32783985137939453 	 0.3179359436035156 	 0.31606125831604004 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:20.522225 test begin: paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 1],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 1],"float32"), ) 	 50803280 	 1000 	 0.19161176681518555 	 0.24135851860046387 	 0.18130779266357422 	 0.2291107177734375 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:21.793607 test begin: paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 923695],"float32"), )
[Prof] paddle.Tensor.__eq__ 	 paddle.Tensor.__eq__(Tensor([55, 923695],"float32"), Tensor([55, 923695],"float32"), ) 	 101606450 	 1000 	 0.32688260078430176 	 0.32781267166137695 	 0.31589722633361816 	 0.3160395622253418 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:24.143800 test begin: paddle.Tensor.__floordiv__(Tensor([10, 10160641],"float32"), Tensor([10, 10160641],"float16"), )
W0730 19:27:27.532939 25797 dygraph_functions.cc:89596] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 10160641],"float32"), Tensor([10, 10160641],"float16"), ) 	 203212820 	 1000 	 1.3718900680541992 	 1.191807508468628 	 0.7010092735290527 	 1.1745107173919678 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:30.402046 test begin: paddle.Tensor.__floordiv__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.4477391242980957 	 0.4477548599243164 	 0.439150333404541 	 0.4308638572692871 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:32.112397 test begin: paddle.Tensor.__floordiv__(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float16"), ) 	 101606420 	 1000 	 0.6895387172698975 	 0.6002695560455322 	 0.35234880447387695 	 0.5830278396606445 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:37.258016 test begin: paddle.Tensor.__floordiv__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.447953462600708 	 0.45264410972595215 	 0.43946385383605957 	 0.430570125579834 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:40.228727 test begin: paddle.Tensor.__floordiv__(Tensor([4, 6350401],"int64"), 4, )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([4, 6350401],"int64"), 4, ) 	 25401604 	 1000 	 0.30457448959350586 	 0.3075273036956787 	 0.1556103229522705 	 0.28476738929748535 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:41.276521 test begin: paddle.Tensor.__floordiv__(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float16"), ) 	 101607424 	 1000 	 0.6902890205383301 	 0.6004462242126465 	 0.3527209758758545 	 0.5832805633544922 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:44.364208 test begin: paddle.Tensor.__floordiv__(Tensor([84673, 300],"int64"), 4, )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([84673, 300],"int64"), 4, ) 	 25401900 	 1000 	 0.3047168254852295 	 0.3026118278503418 	 0.15569496154785156 	 0.28465747833251953 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:45.392978 test begin: paddle.Tensor.__floordiv__(Tensor([99226, 1024],"float32"), Tensor([99226, 1024],"float16"), )
[Prof] paddle.Tensor.__floordiv__ 	 paddle.Tensor.__floordiv__(Tensor([99226, 1024],"float32"), Tensor([99226, 1024],"float16"), ) 	 203214848 	 1000 	 1.374084711074829 	 1.191741704940796 	 0.7023119926452637 	 1.1747066974639893 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:51.539416 test begin: paddle.Tensor.__ge__(Tensor([50803201],"int32"), 0, )
[Prof] paddle.Tensor.__ge__ 	 paddle.Tensor.__ge__(Tensor([50803201],"int32"), 0, ) 	 50803201 	 1000 	 0.4688699245452881 	 0.18602561950683594 	 0.23952078819274902 	 0.1719975471496582 	 None 	 None 	 None 	 None 	 
2025-07-30 19:27:52.775500 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), )
W0730 19:28:18.299302 25883 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 2715238400, memory's size is 1939456000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):2715238400 > memory_size():1939456000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 12800],"bfloat16"), slice(None,-3,None), ) 	 969728000 	 1000 	 0.00546717643737793 	 0.006122589111328125 	 1.0728836059570312e-05 	 6.151199340820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:27.077079 test begin: paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), )
W0730 19:28:59.172585 26070 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3557386560, memory's size is 2540990464.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3557386560 > memory_size():2540990464.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7576, 16770],"bfloat16"), slice(None,-3,None), ) 	 1270495200 	 1000 	 0.005129337310791016 	 0.005151033401489258 	 1.0251998901367188e-05 	 2.1219253540039062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:10.088805 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), )
W0730 19:29:37.873842 26613 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3158835200, memory's size is 1974272000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3158835200 > memory_size():1974272000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 12800],"bfloat16"), slice(None,-2,None), ) 	 987136000 	 1000 	 0.005154132843017578 	 0.0051801204681396484 	 2.288818359375e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:29:49.174929 test begin: paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), )
W0730 19:30:23.141633 26729 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064532480, memory's size is 2540332800.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064532480 > memory_size():2540332800.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 7712, 16470],"bfloat16"), slice(None,-2,None), ) 	 1270166400 	 1000 	 0.005163908004760742 	 0.013180017471313477 	 9.775161743164062e-06 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:40.141276 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), )
W0730 19:31:02.100212 26888 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 12800],"bfloat16"), slice(None,-6,None), ) 	 1045504000 	 1000 	 0.005152225494384766 	 0.0052340030670166016 	 9.775161743164062e-06 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:31:08.451438 test begin: paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), )
W0730 19:31:35.150319 27367 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 8168, 15550],"bfloat16"), slice(None,-6,None), ) 	 1270124000 	 1000 	 0.005335092544555664 	 0.0051729679107666016 	 9.298324584960938e-06 	 2.5510787963867188e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:31:45.566705 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), )
W0730 19:32:19.301831 27487 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 4064460800, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):4064460800 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-2,None), ) 	 1270144000 	 1000 	 0.005141019821166992 	 0.005198001861572266 	 1.0967254638671875e-05 	 3.933906555175781e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:32:31.533621 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), )
W0730 19:33:03.447395 27627 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 3556403200, memory's size is 2540288000.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):3556403200 > memory_size():2540288000.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-3,None), ) 	 1270144000 	 1000 	 0.005173206329345703 	 0.005152463912963867 	 9.059906005859375e-06 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:14.582021 test begin: paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), )
W0730 19:33:41.323266 28153 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.Tensor.__getitem__ 	 paddle.Tensor.__getitem__(Tensor([10, 9923, 12800],"bfloat16"), slice(None,-6,None), ) 	 1270144000 	 1000 	 0.005128145217895508 	 0.005137205123901367 	 1.2636184692382812e-05 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:49.427719 test begin: paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 0, ) 	 50803600 	 1000 	 0.4702014923095703 	 0.43244194984436035 	 0.24028849601745605 	 0.17166519165039062 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:53.400838 test begin: paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 400, 127009],"float32"), 1e-09, ) 	 50803600 	 1000 	 0.47052955627441406 	 0.20759248733520508 	 0.24032855033874512 	 0.17147088050842285 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:54.907480 test begin: paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 0, ) 	 50840832 	 1000 	 0.47107458114624023 	 0.1861250400543213 	 0.24069476127624512 	 0.17177796363830566 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:56.377470 test begin: paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([1, 772, 65856],"float32"), 1e-09, ) 	 50840832 	 1000 	 0.4709944725036621 	 0.18607139587402344 	 0.24065637588500977 	 0.17055869102478027 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:57.864413 test begin: paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 0, ) 	 52684800 	 1000 	 0.48711371421813965 	 0.1925675868988037 	 0.24893951416015625 	 0.17838716506958008 	 None 	 None 	 None 	 None 	 
2025-07-30 19:33:59.404111 test begin: paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 1e-09, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([2, 400, 65856],"float32"), 1e-09, ) 	 52684800 	 1000 	 0.48715829849243164 	 0.19253826141357422 	 0.2489149570465088 	 0.17792153358459473 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:00.965773 test begin: paddle.Tensor.__gt__(Tensor([324000, 157],"float32"), 0.0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([324000, 157],"float32"), 0.0, ) 	 50868000 	 1000 	 0.47102808952331543 	 0.18640494346618652 	 0.24068307876586914 	 0.1715550422668457 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:02.441733 test begin: paddle.Tensor.__gt__(Tensor([635041, 80],"float32"), 0.0, )
[Prof] paddle.Tensor.__gt__ 	 paddle.Tensor.__gt__(Tensor([635041, 80],"float32"), 0.0, ) 	 50803280 	 1000 	 0.47055840492248535 	 0.18597149848937988 	 0.24047064781188965 	 0.1716926097869873 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:03.928038 test begin: paddle.Tensor.__le__(Tensor([243360, 209],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([243360, 209],"float32"), 0.0, ) 	 50862240 	 1000 	 0.47113561630249023 	 0.18619537353515625 	 0.24074363708496094 	 0.17012524604797363 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:05.435171 test begin: paddle.Tensor.__le__(Tensor([282240, 181],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([282240, 181],"float32"), 0.0, ) 	 51085440 	 1000 	 0.47298169136047363 	 0.18695783615112305 	 0.2416987419128418 	 0.1725926399230957 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:06.918841 test begin: paddle.Tensor.__le__(Tensor([324000, 157],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([324000, 157],"float32"), 0.0, ) 	 50868000 	 1000 	 0.47090721130371094 	 0.18622279167175293 	 0.2406330108642578 	 0.1717991828918457 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:08.423245 test begin: paddle.Tensor.__le__(Tensor([635041, 80],"float32"), 0.0, )
[Prof] paddle.Tensor.__le__ 	 paddle.Tensor.__le__(Tensor([635041, 80],"float32"), 0.0, ) 	 50803280 	 1000 	 0.4705350399017334 	 0.1859898567199707 	 0.24042391777038574 	 0.1716012954711914 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:09.915554 test begin: paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 1352, 376],"float32"), ) 	 508352000 	 1000 	 0.004688262939453125 	 0.004761219024658203 	 2.2411346435546875e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:18.011296 test begin: paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000, 376, 1352],"float32"), ) 	 508352000 	 1000 	 0.004709720611572266 	 0.004807949066162109 	 8.821487426757812e-06 	 2.288818359375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:26.056274 test begin: paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([1000000, 509],"float32"), ) 	 509000000 	 1000 	 0.004704952239990234 	 0.004789829254150391 	 5.9604644775390625e-06 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:34.130359 test begin: paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([230, 1501, 1501],"float32"), ) 	 518190230 	 1000 	 0.004628181457519531 	 0.0047283172607421875 	 5.9604644775390625e-06 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:42.366141 test begin: paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([3600, 376, 376],"float32"), ) 	 508953600 	 1000 	 0.004725217819213867 	 0.00476384162902832 	 5.7220458984375e-06 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:50.549267 test begin: paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 1501, 677],"float32"), ) 	 508088500 	 1000 	 0.004698276519775391 	 0.00478816032409668 	 5.9604644775390625e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:59.799621 test begin: paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([500, 677, 1501],"float32"), ) 	 508088500 	 1000 	 0.004705905914306641 	 0.004762172698974609 	 6.9141387939453125e-06 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:07.888128 test begin: paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), )
[Prof] paddle.Tensor.__len__ 	 paddle.Tensor.__len__(Tensor([5080330, 100],"float32"), ) 	 508033000 	 1000 	 0.004638195037841797 	 0.004786491394042969 	 6.9141387939453125e-06 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:15.983045 test begin: paddle.Tensor.__lshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.44971227645874023 	 0.44664764404296875 	 0.44016456604003906 	 0.4343390464782715 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:18.087215 test begin: paddle.Tensor.__lshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.4500603675842285 	 0.4467334747314453 	 0.4406166076660156 	 0.4342174530029297 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:20.198501 test begin: paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.44788479804992676 	 0.45004963874816895 	 0.43834829330444336 	 0.4377002716064453 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:23.069418 test begin: paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.44793200492858887 	 0.4501168727874756 	 0.43857669830322266 	 0.43770742416381836 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:25.931351 test begin: paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.4478466510772705 	 0.45015811920166016 	 0.438277006149292 	 0.43788790702819824 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:28.865635 test begin: paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.Tensor.__lshift__ 	 paddle.Tensor.__lshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.44769883155822754 	 0.4500703811645508 	 0.43756961822509766 	 0.4377279281616211 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:31.730699 test begin: paddle.Tensor.__lt__(Tensor([1034, 3, 64, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([1034, 3, 64, 128],"float64"), 1, ) 	 25411584 	 1000 	 0.45407772064208984 	 0.16836118698120117 	 0.23201918601989746 	 0.15355157852172852 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:32.886421 test begin: paddle.Tensor.__lt__(Tensor([256, 13, 64, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 13, 64, 128],"float64"), 1, ) 	 27262976 	 1000 	 0.48577165603637695 	 0.1861717700958252 	 0.24821734428405762 	 0.16569948196411133 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:34.164123 test begin: paddle.Tensor.__lt__(Tensor([256, 3, 259, 128],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 3, 259, 128],"float64"), 1, ) 	 25460736 	 1000 	 0.4548349380493164 	 0.1728522777557373 	 0.23244071006774902 	 0.15330862998962402 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:37.112393 test begin: paddle.Tensor.__lt__(Tensor([256, 3, 64, 517],"float64"), 1, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([256, 3, 64, 517],"float64"), 1, ) 	 25411584 	 1000 	 0.4540860652923584 	 0.6146361827850342 	 0.23202776908874512 	 0.15351653099060059 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:39.919947 test begin: paddle.Tensor.__lt__(Tensor([4, 157920, 81],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([4, 157920, 81],"float32"), 0.1111111111111111, ) 	 51166080 	 1000 	 0.4742124080657959 	 0.1962285041809082 	 0.24242162704467773 	 0.17255783081054688 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:41.424269 test begin: paddle.Tensor.__lt__(Tensor([4, 1814401, 7],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([4, 1814401, 7],"float32"), 0.1111111111111111, ) 	 50803228 	 1000 	 0.4706604480743408 	 0.20021557807922363 	 0.24049019813537598 	 0.1712636947631836 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:42.954562 test begin: paddle.Tensor.__lt__(Tensor([46, 157920, 7],"float32"), 0.1111111111111111, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([46, 157920, 7],"float32"), 0.1111111111111111, ) 	 50850240 	 1000 	 0.4706692695617676 	 0.1924724578857422 	 0.24051809310913086 	 0.17150545120239258 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:44.507292 test begin: paddle.Tensor.__lt__(Tensor([50803201],"float32"), 0.7, )
[Prof] paddle.Tensor.__lt__ 	 paddle.Tensor.__lt__(Tensor([50803201],"float32"), 0.7, ) 	 50803201 	 1000 	 0.47069764137268066 	 0.18599581718444824 	 0.24056577682495117 	 0.17188167572021484 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:46.017555 test begin: paddle.Tensor.__matmul__(Tensor([10, 2304, 2304],"float32"), Tensor([10, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([10, 2304, 2304],"float32"), Tensor([10, 2304, 64],"float32"), ) 	 54558720 	 1000 	 0.9308209419250488 	 0.9428143501281738 	 0.9184949398040771 	 0.9076704978942871 	 1.3783354759216309 	 1.3778769969940186 	 0.7042791843414307 	 0.7038564682006836 	 
2025-07-30 19:35:51.840330 test begin: paddle.Tensor.__matmul__(Tensor([111, 3, 392, 392],"float32"), Tensor([111, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([111, 3, 392, 392],"float32"), Tensor([111, 3, 392, 32],"float32"), ) 	 55347264 	 1000 	 1.0342035293579102 	 1.0343859195709229 	 1.0217392444610596 	 1.0109078884124756 	 1.4511353969573975 	 1.4507253170013428 	 0.7414653301239014 	 0.7412245273590088 	 
2025-07-30 19:35:57.858215 test begin: paddle.Tensor.__matmul__(Tensor([1351, 3, 392, 392],"float32"), Tensor([1351, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([1351, 3, 392, 392],"float32"), Tensor([1351, 3, 392, 32],"float32"), ) 	 673641024 	 1000 	 11.902791500091553 	 11.907513618469238 	 11.889905214309692 	 11.87111210823059 	 16.85859251022339 	 16.85573410987854 	 8.614629745483398 	 8.613116025924683 	 
2025-07-30 19:37:09.987686 test begin: paddle.Tensor.__matmul__(Tensor([176, 2, 392, 392],"float32"), Tensor([176, 2, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 2, 392, 392],"float32"), Tensor([176, 2, 392, 32],"float32"), ) 	 58505216 	 1000 	 1.1113407611846924 	 1.1115593910217285 	 1.0989196300506592 	 1.08768892288208 	 1.5516173839569092 	 1.5515789985656738 	 0.7928080558776855 	 0.7927424907684326 	 
2025-07-30 19:37:16.386124 test begin: paddle.Tensor.__matmul__(Tensor([176, 24, 392, 392],"float32"), Tensor([176, 24, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 24, 392, 392],"float32"), Tensor([176, 24, 392, 32],"float32"), ) 	 702062592 	 1000 	 12.381138324737549 	 12.38080382347107 	 12.368491888046265 	 12.356995105743408 	 17.544217824935913 	 17.54075837135315 	 8.964816093444824 	 8.962976455688477 	 
2025-07-30 19:38:30.464943 test begin: paddle.Tensor.__matmul__(Tensor([176, 3, 246, 392],"float32"), Tensor([176, 3, 392, 32],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 3, 246, 392],"float32"), Tensor([176, 3, 392, 32],"float32"), ) 	 57539328 	 1000 	 0.7994191646575928 	 0.7994744777679443 	 0.7868235111236572 	 0.7757244110107422 	 1.3494846820831299 	 1.3494670391082764 	 0.6894822120666504 	 0.689446210861206 	 
2025-07-30 19:38:37.795883 test begin: paddle.Tensor.__matmul__(Tensor([176, 3, 392, 392],"float32"), Tensor([176, 3, 392, 246],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([176, 3, 392, 392],"float32"), Tensor([176, 3, 392, 246],"float32"), ) 	 132050688 	 1000 	 3.171656608581543 	 3.1693880558013916 	 3.1519482135772705 	 3.1380324363708496 	 7.164949417114258 	 7.164973258972168 	 3.661250352859497 	 3.661165237426758 	 
2025-07-30 19:39:02.427497 test begin: paddle.Tensor.__matmul__(Tensor([345, 2304, 2304],"float32"), Tensor([345, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([345, 2304, 2304],"float32"), Tensor([345, 2304, 64],"float32"), ) 	 1882275840 	 1000 	 26.630470514297485 	 26.62978768348694 	 26.617809772491455 	 26.606297492980957 	 41.79797315597534 	 41.73432469367981 	 21.387778759002686 	 21.325836181640625 	 
2025-07-30 19:41:53.126247 test begin: paddle.Tensor.__matmul__(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([49, 1024, 1024],"float32"), Tensor([49, 1024, 64],"float32"), ) 	 54591488 	 1000 	 0.8289601802825928 	 0.8290908336639404 	 0.816246747970581 	 0.8055257797241211 	 1.2619197368621826 	 1.2623496055603027 	 0.644777774810791 	 0.6449754238128662 	 
2025-07-30 19:41:58.266496 test begin: paddle.Tensor.__matmul__(Tensor([60, 2304, 2304],"float32"), Tensor([60, 2304, 368],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([60, 2304, 2304],"float32"), Tensor([60, 2304, 368],"float32"), ) 	 369377280 	 1000 	 13.78908658027649 	 13.78683090209961 	 13.776779413223267 	 13.763159990310669 	 27.236282110214233 	 27.237927198410034 	 13.916002750396729 	 13.917862892150879 	 
2025-07-30 19:43:27.466093 test begin: paddle.Tensor.__matmul__(Tensor([60, 368, 2304],"float32"), Tensor([60, 2304, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([60, 368, 2304],"float32"), Tensor([60, 2304, 64],"float32"), ) 	 59719680 	 1000 	 0.9290361404418945 	 0.9289901256561279 	 0.9166035652160645 	 0.9059505462646484 	 1.1977996826171875 	 1.1979186534881592 	 0.6120085716247559 	 0.6120302677154541 	 
2025-07-30 19:43:32.703573 test begin: paddle.Tensor.__matmul__(Tensor([776, 1024, 1024],"float32"), Tensor([776, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([776, 1024, 1024],"float32"), Tensor([776, 1024, 64],"float32"), ) 	 864550912 	 1000 	 11.870950698852539 	 11.871004343032837 	 11.858328104019165 	 11.847549676895142 	 18.535678386688232 	 18.52612566947937 	 9.471590995788574 	 9.466645002365112 	 
2025-07-30 19:44:49.102824 test begin: paddle.Tensor.__matmul__(Tensor([96, 1024, 1024],"float32"), Tensor([96, 1024, 517],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([96, 1024, 1024],"float32"), Tensor([96, 1024, 517],"float32"), ) 	 151486464 	 1000 	 7.375382661819458 	 7.3753156661987305 	 7.362825155258179 	 7.352248907089233 	 13.351627111434937 	 13.356794834136963 	 6.822416305541992 	 6.825172185897827 	 
2025-07-30 19:45:34.155519 test begin: paddle.Tensor.__matmul__(Tensor([96, 517, 1024],"float32"), Tensor([96, 1024, 64],"float32"), )
[Prof] paddle.Tensor.__matmul__ 	 paddle.Tensor.__matmul__(Tensor([96, 517, 1024],"float32"), Tensor([96, 1024, 64],"float32"), ) 	 57114624 	 1000 	 1.169574499130249 	 1.040693998336792 	 1.1571574211120605 	 1.0079660415649414 	 1.3717756271362305 	 1.3720459938049316 	 0.7009053230285645 	 0.7009751796722412 	 
2025-07-30 19:45:42.275110 test begin: paddle.Tensor.__mod__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([10, 2540161],"int64"), Tensor([10, 2540161],"int64"), ) 	 50803220 	 1000 	 0.44725799560546875 	 0.4477260112762451 	 0.4381415843963623 	 0.4358551502227783 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:45:45.258234 test begin: paddle.Tensor.__mod__(Tensor([13, 2, 976985],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([13, 2, 976985],"int64"), 16, ) 	 25401610 	 1000 	 0.5828094482421875 	 0.3012197017669678 	 0.2977626323699951 	 0.2848682403564453 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:45:47.311337 test begin: paddle.Tensor.__mod__(Tensor([13, 30531, 64],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([13, 30531, 64],"int64"), 16, ) 	 25401792 	 1000 	 0.5824368000030518 	 0.29913759231567383 	 0.29759931564331055 	 0.28494811058044434 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:45:49.350193 test begin: paddle.Tensor.__mod__(Tensor([198451, 2, 64],"int64"), 16, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([198451, 2, 64],"int64"), 16, ) 	 25401728 	 1000 	 0.5828197002410889 	 0.30318689346313477 	 0.2977480888366699 	 0.2849905490875244 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:45:51.383463 test begin: paddle.Tensor.__mod__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([24807, 1024],"int64"), Tensor([24807, 1024],"int64"), ) 	 50804736 	 1000 	 0.4477732181549072 	 0.4501957893371582 	 0.43708276748657227 	 0.4358072280883789 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:45:54.270266 test begin: paddle.Tensor.__mod__(Tensor([26, 976985],"int64"), 64, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([26, 976985],"int64"), 64, ) 	 25401610 	 1000 	 0.5826945304870605 	 0.31839585304260254 	 0.29778552055358887 	 0.2850654125213623 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:45:58.132154 test begin: paddle.Tensor.__mod__(Tensor([396901, 64],"int64"), 64, )
[Prof] paddle.Tensor.__mod__ 	 paddle.Tensor.__mod__(Tensor([396901, 64],"int64"), 64, ) 	 25401664 	 1000 	 0.5823841094970703 	 0.5294859409332275 	 0.2975900173187256 	 0.2846531867980957 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:46:01.343354 test begin: paddle.Tensor.__mul__(Tensor([1, 1, 32768, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([1, 1, 32768, 32768],"float16"), 10000.0, ) 	 1073741824 	 1000 	 3.104656934738159 	 3.0918095111846924 	 3.0959081649780273 	 3.076974630355835 	 3.1048810482025146 	 3.091053009033203 	 3.053884983062744 	 3.023437261581421 	 
2025-07-30 19:46:54.694654 test begin: paddle.Tensor.__mul__(Tensor([108544, 469],"float32"), Tensor([108544, 469],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([108544, 469],"float32"), Tensor([108544, 469],"float32"), ) 	 101814272 	 1000 	 0.45084500312805176 	 0.44760608673095703 	 0.4396786689758301 	 0.43599724769592285 	 1.1063365936279297 	 0.8948938846588135 	 1.0446817874908447 	 0.45719027519226074 	 
2025-07-30 19:47:00.102490 test begin: paddle.Tensor.__mul__(Tensor([111616, 456],"float32"), Tensor([111616, 456],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([111616, 456],"float32"), Tensor([111616, 456],"float32"), ) 	 101793792 	 1000 	 0.450852632522583 	 0.4654388427734375 	 0.44179296493530273 	 0.43544507026672363 	 1.1714222431182861 	 0.8946595191955566 	 1.1099636554718018 	 0.45711278915405273 	 
2025-07-30 19:47:07.128017 test begin: paddle.Tensor.__mul__(Tensor([14176, 3584],"float32"), Tensor([14176, 3584],"float32"), )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([14176, 3584],"float32"), Tensor([14176, 3584],"float32"), ) 	 101613568 	 1000 	 0.45004844665527344 	 0.4466989040374756 	 0.44081950187683105 	 0.43523216247558594 	 1.1054482460021973 	 0.892972469329834 	 1.035722017288208 	 0.45622682571411133 	 
2025-07-30 19:47:12.487612 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 1551, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 1551, 32768],"float16"), 10000.0, ) 	 101646336 	 1000 	 0.2983086109161377 	 0.29640722274780273 	 0.2893850803375244 	 0.28241968154907227 	 0.298248291015625 	 0.2961902618408203 	 0.24650835990905762 	 0.22847557067871094 	 
2025-07-30 19:47:17.386615 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 32768, 1551],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 32768, 1551],"float16"), 10000.0, ) 	 101646336 	 1000 	 0.2982974052429199 	 0.2963438034057617 	 0.28949403762817383 	 0.28220367431640625 	 0.29825878143310547 	 0.29616665840148926 	 0.24636030197143555 	 0.22844934463500977 	 
2025-07-30 19:47:22.367325 test begin: paddle.Tensor.__mul__(Tensor([2, 1, 32768, 32768],"float16"), 10000.0, )
[Prof] paddle.Tensor.__mul__ 	 paddle.Tensor.__mul__(Tensor([2, 1, 32768, 32768],"float16"), 10000.0, ) 	 2147483648 	 1000 	 6.277548551559448 	 6.183816194534302 	 6.2676873207092285 	 3.1596004962921143 	 6.206346750259399 	 6.182631015777588 	 6.1553943157196045 	 3.1592535972595215 	 
2025-07-30 19:49:09.211126 test begin: paddle.Tensor.__ne__(Tensor([144, 392, 901],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([144, 392, 901],"float32"), 0, ) 	 50859648 	 1000 	 0.4711191654205322 	 0.18625211715698242 	 0.24073457717895508 	 0.17198681831359863 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:10.755753 test begin: paddle.Tensor.__ne__(Tensor([144, 901, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([144, 901, 392],"float32"), 0, ) 	 50859648 	 1000 	 0.471041202545166 	 0.8606531620025635 	 0.24068164825439453 	 0.17058420181274414 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:13.310299 test begin: paddle.Tensor.__ne__(Tensor([160, 392, 811],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([160, 392, 811],"float32"), 0, ) 	 50865920 	 1000 	 0.4714217185974121 	 0.4280252456665039 	 0.24086952209472656 	 0.17183232307434082 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:15.696452 test begin: paddle.Tensor.__ne__(Tensor([160, 811, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([160, 811, 392],"float32"), 0, ) 	 50865920 	 1000 	 0.4714534282684326 	 0.18988847732543945 	 0.24092555046081543 	 0.17195487022399902 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:17.230646 test begin: paddle.Tensor.__ne__(Tensor([176, 392, 737],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([176, 392, 737],"float32"), 0, ) 	 50847104 	 1000 	 0.47126317024230957 	 0.1861422061920166 	 0.2408144474029541 	 0.17191123962402344 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:18.723943 test begin: paddle.Tensor.__ne__(Tensor([176, 737, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([176, 737, 392],"float32"), 0, ) 	 50847104 	 1000 	 0.4713308811187744 	 0.18909716606140137 	 0.24087285995483398 	 0.1718740463256836 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:20.242226 test begin: paddle.Tensor.__ne__(Tensor([331, 392, 392],"float32"), 0, )
[Prof] paddle.Tensor.__ne__ 	 paddle.Tensor.__ne__(Tensor([331, 392, 392],"float32"), 0, ) 	 50862784 	 1000 	 0.4714395999908447 	 0.18618273735046387 	 0.24087762832641602 	 0.17182135581970215 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:21.740006 test begin: paddle.Tensor.__neg__(Tensor([128, 396901],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.2955143451690674 	 0.29777979850769043 	 0.284743070602417 	 0.2871370315551758 	 0.2955794334411621 	 0.297731876373291 	 0.24287867546081543 	 0.2328650951385498 	 
2025-07-30 19:49:24.690577 test begin: paddle.Tensor.__neg__(Tensor([128, 793801],"float16"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([128, 793801],"float16"), ) 	 101606528 	 1000 	 0.2984769344329834 	 0.29624390602111816 	 0.28942394256591797 	 0.2854959964752197 	 0.2985196113586426 	 0.29611873626708984 	 0.24617338180541992 	 0.2306206226348877 	 
2025-07-30 19:49:29.668075 test begin: paddle.Tensor.__neg__(Tensor([22, 81, 94, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([22, 81, 94, 311],"float32"), ) 	 52094988 	 1000 	 0.30312609672546387 	 0.3071420192718506 	 0.2942159175872803 	 0.2941255569458008 	 0.30312514305114746 	 0.30512022972106934 	 0.2518882751464844 	 0.23836684226989746 	 
2025-07-30 19:49:32.606442 test begin: paddle.Tensor.__neg__(Tensor([264, 192612],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([264, 192612],"float32"), ) 	 50849568 	 1000 	 0.29604387283325195 	 0.2980222702026367 	 0.2871243953704834 	 0.2872145175933838 	 0.2960984706878662 	 0.2980525493621826 	 0.24455738067626953 	 0.23241090774536133 	 
2025-07-30 19:49:37.169711 test begin: paddle.Tensor.__neg__(Tensor([4, 435, 94, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 435, 94, 311],"float32"), ) 	 50867160 	 1000 	 0.29601311683654785 	 0.3072938919067383 	 0.28701305389404297 	 0.28723597526550293 	 0.2962038516998291 	 0.2980988025665283 	 0.2448575496673584 	 0.23047709465026855 	 
2025-07-30 19:49:40.080001 test begin: paddle.Tensor.__neg__(Tensor([4, 81, 505, 311],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 81, 505, 311],"float32"), ) 	 50885820 	 1000 	 0.2961585521697998 	 0.3056058883666992 	 0.2870512008666992 	 0.2871713638305664 	 0.2962353229522705 	 0.2981534004211426 	 0.24472904205322266 	 0.23201942443847656 	 
2025-07-30 19:49:42.953637 test begin: paddle.Tensor.__neg__(Tensor([4, 81, 94, 1669],"float32"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([4, 81, 94, 1669],"float32"), ) 	 50831064 	 1000 	 0.29607725143432617 	 0.2979705333709717 	 0.2870621681213379 	 0.287278413772583 	 0.29604196548461914 	 0.29784297943115234 	 0.23330307006835938 	 0.23160624504089355 	 
2025-07-30 19:49:45.884290 test begin: paddle.Tensor.__neg__(Tensor([528, 192612],"float16"), )
[Prof] paddle.Tensor.__neg__ 	 paddle.Tensor.__neg__(Tensor([528, 192612],"float16"), ) 	 101699136 	 1000 	 0.2988612651824951 	 0.2965211868286133 	 0.289808988571167 	 0.2850642204284668 	 0.29889774322509766 	 0.29633045196533203 	 0.24779367446899414 	 0.23090887069702148 	 
2025-07-30 19:49:50.928123 test begin: paddle.Tensor.__or__(Tensor([1, 210, 241921],"bool"), Tensor([1, 210, 241921],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 210, 241921],"bool"), Tensor([1, 210, 241921],"bool"), ) 	 101606820 	 1000 	 0.1177060604095459 	 0.11654281616210938 	 0.1089322566986084 	 0.10423588752746582 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:52.595008 test begin: paddle.Tensor.__or__(Tensor([1, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), ) 	 79380000 	 1000 	 0.16185832023620605 	 0.2790651321411133 	 0.1522681713104248 	 0.26514649391174316 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:54.206025 test begin: paddle.Tensor.__or__(Tensor([1, 218, 233043],"bool"), Tensor([1, 218, 233043],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 218, 233043],"bool"), Tensor([1, 218, 233043],"bool"), ) 	 101606748 	 1000 	 0.11768341064453125 	 0.11646103858947754 	 0.10886573791503906 	 0.10413551330566406 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:55.942712 test begin: paddle.Tensor.__or__(Tensor([1, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), ) 	 77001960 	 1000 	 0.15716242790222168 	 0.2694435119628906 	 0.14736533164978027 	 0.25641512870788574 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:57.465549 test begin: paddle.Tensor.__or__(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"bool"), ) 	 101607200 	 1000 	 0.11697840690612793 	 0.11774468421936035 	 0.1080167293548584 	 0.10480999946594238 	 None 	 None 	 None 	 None 	 
2025-07-30 19:49:59.133422 test begin: paddle.Tensor.__or__(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), ) 	 79027200 	 1000 	 0.13494634628295898 	 0.2319638729095459 	 0.12386417388916016 	 0.21887969970703125 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:00.603898 test begin: paddle.Tensor.__or__(Tensor([1, 673, 75600],"bool"), Tensor([1, 673, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 673, 75600],"bool"), Tensor([1, 673, 75600],"bool"), ) 	 101757600 	 1000 	 0.11732697486877441 	 0.11537456512451172 	 0.1083674430847168 	 0.10290408134460449 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:02.294258 test begin: paddle.Tensor.__or__(Tensor([1, 720, 70644],"bool"), Tensor([1, 720, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 720, 70644],"bool"), Tensor([1, 720, 70644],"bool"), ) 	 101727360 	 1000 	 0.1177675724029541 	 0.12019014358520508 	 0.1090848445892334 	 0.10381269454956055 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:03.986929 test begin: paddle.Tensor.__or__(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"bool"), ) 	 101681664 	 1000 	 0.11776876449584961 	 0.11507201194763184 	 0.10886859893798828 	 0.1028144359588623 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:05.688059 test begin: paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"bool"), ) 	 79027200 	 1000 	 0.1752760410308838 	 0.23193907737731934 	 0.16563105583190918 	 0.21883678436279297 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:07.211522 test begin: paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"bool"), ) 	 105369600 	 1000 	 0.12108635902404785 	 0.11900067329406738 	 0.11222076416015625 	 0.10677528381347656 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:08.944929 test begin: paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([1, 210, 75600],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([1, 210, 75600],"bool"), ) 	 79380000 	 1000 	 0.21161437034606934 	 0.2782914638519287 	 0.20180511474609375 	 0.26525378227233887 	 None 	 None 	 None 	 None 	 
2025-07-30 19:50:10.538397 test begin: paddle.rank(input=Tensor([201, 12700801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([201, 12700801],"float64"), ) 	 2552861001 	 1000 	 0.04115653038024902 	 0.029021501541137695 	 2.2172927856445312e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:03.248372 test begin: paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2, 2116801],"float64"), ) 	 2548628404 	 1000 	 0.04025554656982422 	 0.028860807418823242 	 2.193450927734375e-05 	 4.1484832763671875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:51:55.603314 test begin: paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2, 2116801, 2],"float64"), ) 	 2548628404 	 1000 	 0.040503501892089844 	 0.028859376907348633 	 5.6743621826171875e-05 	 4.029273986816406e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:52:48.340488 test begin: paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([301, 2116801, 2, 2],"float64"), ) 	 2548628404 	 1000 	 0.0399928092956543 	 0.029043912887573242 	 2.2411346435546875e-05 	 5.793571472167969e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:53:43.944301 test begin: paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), )
[Prof] paddle.rank 	 paddle.rank(input=Tensor([317520101, 2, 2, 2],"float64"), ) 	 2540160808 	 1000 	 0.041289329528808594 	 0.02839207649230957 	 3.7670135498046875e-05 	 4.5299530029296875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:54:37.905307 test begin: paddle.reciprocal(Tensor([125, 1, 640, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([125, 1, 640, 640],"float32"), ) 	 51200000 	 1000 	 0.29757237434387207 	 0.3169708251953125 	 0.2889134883880615 	 0.28986525535583496 	 0.4531519412994385 	 1.0485963821411133 	 0.39920616149902344 	 0.3571596145629883 	 
2025-07-30 19:54:41.738709 test begin: paddle.reciprocal(Tensor([16, 1, 4962, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 1, 4962, 640],"float32"), ) 	 50810880 	 1000 	 0.2953054904937744 	 0.29815244674682617 	 0.28667330741882324 	 0.28771138191223145 	 0.4496805667877197 	 1.0406739711761475 	 0.3948497772216797 	 0.354511022567749 	 
2025-07-30 19:54:47.357594 test begin: paddle.reciprocal(Tensor([16, 1, 640, 4962],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 1, 640, 4962],"float32"), ) 	 50810880 	 1000 	 0.2953784465789795 	 0.3081486225128174 	 0.28685855865478516 	 0.2871592044830322 	 0.44967007637023926 	 1.040797472000122 	 0.39589643478393555 	 0.3546297550201416 	 
2025-07-30 19:54:52.474249 test begin: paddle.reciprocal(Tensor([16, 8, 640, 640],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([16, 8, 640, 640],"float32"), ) 	 52428800 	 1000 	 0.30449914932250977 	 0.30747127532958984 	 0.2956991195678711 	 0.2969932556152344 	 0.4638099670410156 	 1.073378324508667 	 0.3914361000061035 	 0.3656954765319824 	 
2025-07-30 19:54:56.350865 test begin: paddle.reciprocal(Tensor([4, 1, 13231, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 1, 13231, 960],"float32"), ) 	 50807040 	 1000 	 0.29546213150024414 	 0.2982039451599121 	 0.2857375144958496 	 0.2877004146575928 	 0.44948554039001465 	 1.040633201599121 	 0.39240264892578125 	 0.3545689582824707 	 
2025-07-30 19:55:00.112473 test begin: paddle.reciprocal(Tensor([4, 1, 960, 13231],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 1, 960, 13231],"float32"), ) 	 50807040 	 1000 	 0.29542970657348633 	 0.2981398105621338 	 0.2868013381958008 	 0.28768420219421387 	 0.4495842456817627 	 1.0406689643859863 	 0.3963649272918701 	 0.35457873344421387 	 
2025-07-30 19:55:03.907493 test begin: paddle.reciprocal(Tensor([4, 14, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([4, 14, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.2997112274169922 	 0.30656909942626953 	 0.29100942611694336 	 0.2918412685394287 	 0.45672011375427246 	 1.0568246841430664 	 0.4036383628845215 	 0.359999418258667 	 
2025-07-30 19:55:07.757247 test begin: paddle.reciprocal(Tensor([56, 1, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([56, 1, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.29970765113830566 	 0.3028295040130615 	 0.2910733222961426 	 0.2920043468475342 	 0.4567844867706299 	 1.0567588806152344 	 0.38425111770629883 	 0.3600270748138428 	 
2025-07-30 19:55:11.631538 test begin: paddle.reciprocal(Tensor([8, 1, 6616, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 1, 6616, 960],"float32"), ) 	 50810880 	 1000 	 0.295351505279541 	 0.29976344108581543 	 0.2867624759674072 	 0.2875542640686035 	 0.4496579170227051 	 1.040745496749878 	 0.3961756229400635 	 0.3545541763305664 	 
2025-07-30 19:55:15.412403 test begin: paddle.reciprocal(Tensor([8, 1, 960, 6616],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 1, 960, 6616],"float32"), ) 	 50810880 	 1000 	 0.29537367820739746 	 0.2981381416320801 	 0.28671932220458984 	 0.2877953052520752 	 0.4497556686401367 	 1.0406880378723145 	 0.38861918449401855 	 0.3545234203338623 	 
2025-07-30 19:55:19.139597 test begin: paddle.reciprocal(Tensor([8, 7, 960, 960],"float32"), )
[Prof] paddle.reciprocal 	 paddle.reciprocal(Tensor([8, 7, 960, 960],"float32"), ) 	 51609600 	 1000 	 0.29973936080932617 	 0.30280303955078125 	 0.29071879386901855 	 0.29200291633605957 	 0.456634521484375 	 1.0568382740020752 	 0.40335536003112793 	 0.360044002532959 	 
2025-07-30 19:55:22.959199 test begin: paddle.reduce_as(Tensor([30, 1270081, 40],"float32"), Tensor([1270081, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 1270081, 40],"float32"), Tensor([1270081, 40],"float32"), ) 	 1574900440 	 1000 	 5.178709030151367 	 5.343757152557373 	 5.167383432388306 	 1.3654022216796875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 19:56:10.119227 test begin: paddle.reduce_as(Tensor([30, 200, 254017],"float32"), Tensor([200, 254017],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 200, 254017],"float32"), Tensor([200, 254017],"float32"), ) 	 1574905400 	 1000 	 5.182734489440918 	 5.346756935119629 	 5.166030406951904 	 1.3655226230621338 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 19:56:56.868951 test begin: paddle.reduce_as(Tensor([30, 200, 8468],"float32"), Tensor([200, 8468],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 200, 8468],"float32"), Tensor([200, 8468],"float32"), ) 	 52501600 	 1000 	 0.17823314666748047 	 0.1587207317352295 	 0.1668868064880371 	 0.12115073204040527 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 19:56:58.311461 test begin: paddle.reduce_as(Tensor([30, 42337, 40],"float32"), Tensor([42337, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([30, 42337, 40],"float32"), Tensor([42337, 40],"float32"), ) 	 52497880 	 1000 	 0.17934370040893555 	 1.474806308746338 	 0.1681809425354004 	 0.12233781814575195 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 19:57:02.063172 test begin: paddle.reduce_as(Tensor([6351, 200, 40],"float32"), Tensor([200, 40],"float32"), )
[Prof] paddle.reduce_as 	 paddle.reduce_as(Tensor([6351, 200, 40],"float32"), Tensor([200, 40],"float32"), ) 	 50816000 	 1000 	 0.2597062587738037 	 0.15593910217285156 	 0.13269448280334473 	 0.07959318161010742 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 19:57:05.893907 test begin: paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"float32"), Tensor([1, 2, 1270081, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"float32"), Tensor([1, 2, 1270081, 4, 5],"float32"), ) 	 101606480 	 1000 	 0.45026159286499023 	 0.4492812156677246 	 0.4407339096069336 	 0.43785619735717773 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:08.496077 test begin: paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"int32"), Tensor([1, 2, 1270081, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 1270081, 4, 5],"int32"), Tensor([1, 2, 1270081, 4, 5],"int32"), ) 	 101606480 	 1000 	 0.4501516819000244 	 0.4495539665222168 	 0.4405524730682373 	 0.4381253719329834 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:10.614647 test begin: paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"float32"), Tensor([1, 2, 3, 1693441, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"float32"), Tensor([1, 2, 3, 1693441, 5],"float32"), ) 	 101606460 	 1000 	 0.4501216411590576 	 0.4492678642272949 	 0.4406459331512451 	 0.4376816749572754 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:13.228344 test begin: paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"int32"), Tensor([1, 2, 3, 1693441, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 1693441, 5],"int32"), Tensor([1, 2, 3, 1693441, 5],"int32"), ) 	 101606460 	 1000 	 0.4502270221710205 	 0.44953083992004395 	 0.43883395195007324 	 0.43813157081604004 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:15.308998 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 1058401],"float64"), Tensor([1, 2, 3, 4, 1058401],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 1058401],"float64"), Tensor([1, 2, 3, 4, 1058401],"float64"), ) 	 50803248 	 1000 	 0.4476015567779541 	 0.45650577545166016 	 0.43738222122192383 	 0.44519710540771484 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:17.311341 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"float32"), Tensor([1, 2, 3, 4, 2116801],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"float32"), Tensor([1, 2, 3, 4, 2116801],"float32"), ) 	 101606448 	 1000 	 0.45024561882019043 	 0.4492771625518799 	 0.44084739685058594 	 0.4376707077026367 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:19.963407 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"int32"), Tensor([1, 2, 3, 4, 2116801],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 2116801],"int32"), Tensor([1, 2, 3, 4, 2116801],"int32"), ) 	 101606448 	 1000 	 0.45017218589782715 	 0.44954729080200195 	 0.44068002700805664 	 0.43822622299194336 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:22.051008 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), ) 	 50803440 	 1000 	 0.2976670265197754 	 0.3314187526702881 	 0.28724074363708496 	 0.31940507888793945 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:23.527794 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), ) 	 25401840 	 1000 	 0.43823742866516113 	 0.37152719497680664 	 0.4280853271484375 	 0.3593926429748535 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:24.901696 test begin: paddle.remainder(Tensor([1, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), ) 	 50803440 	 1000 	 0.30091071128845215 	 0.34310269355773926 	 0.2902107238769531 	 0.33101534843444824 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:26.135540 test begin: paddle.remainder(Tensor([1, 2, 3, 846721, 5],"float64"), Tensor([1, 2, 3, 846721, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 3, 846721, 5],"float64"), Tensor([1, 2, 3, 846721, 5],"float64"), ) 	 50803260 	 1000 	 0.4474771022796631 	 0.456463098526001 	 0.43820905685424805 	 0.4450855255126953 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:28.102678 test begin: paddle.remainder(Tensor([1, 2, 635041, 4, 5],"float64"), Tensor([1, 2, 635041, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 2, 635041, 4, 5],"float64"), Tensor([1, 2, 635041, 4, 5],"float64"), ) 	 50803280 	 1000 	 0.44747161865234375 	 0.45647692680358887 	 0.43833017349243164 	 0.44504380226135254 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:30.082741 test begin: paddle.remainder(Tensor([1, 423361, 3, 4, 5],"float64"), Tensor([1, 423361, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 423361, 3, 4, 5],"float64"), Tensor([1, 423361, 3, 4, 5],"float64"), ) 	 50803320 	 1000 	 0.4474201202392578 	 0.4563751220703125 	 0.4383258819580078 	 0.4448585510253906 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:32.107454 test begin: paddle.remainder(Tensor([1, 846721, 3, 4, 5],"float32"), Tensor([1, 846721, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 846721, 3, 4, 5],"float32"), Tensor([1, 846721, 3, 4, 5],"float32"), ) 	 101606520 	 1000 	 0.4501838684082031 	 0.44933223724365234 	 0.439056396484375 	 0.4378788471221924 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:34.814504 test begin: paddle.remainder(Tensor([1, 846721, 3, 4, 5],"int32"), Tensor([1, 846721, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([1, 846721, 3, 4, 5],"int32"), Tensor([1, 846721, 3, 4, 5],"int32"), ) 	 101606520 	 1000 	 0.4500703811645508 	 0.4568314552307129 	 0.4404428005218506 	 0.43740177154541016 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:40.038695 test begin: paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([1, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([1, 2, 3, 4, 5],"float64"), ) 	 25401840 	 1000 	 0.4237689971923828 	 0.3890712261199951 	 0.4136989116668701 	 0.3716616630554199 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:41.394373 test begin: paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([211681, 2, 3, 4, 5],"float64"), Tensor([211681, 2, 3, 4, 5],"float64"), ) 	 50803440 	 1000 	 0.4474310874938965 	 0.4608287811279297 	 0.4382205009460449 	 0.44478678703308105 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:43.402706 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([1, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([1, 2, 3, 4, 5],"float32"), ) 	 50803440 	 1000 	 0.29681921005249023 	 0.3317286968231201 	 0.28611230850219727 	 0.31975340843200684 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:44.921228 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"float32"), Tensor([423361, 2, 3, 4, 5],"float32"), ) 	 101606640 	 1000 	 0.450070858001709 	 0.44925737380981445 	 0.4405503273010254 	 0.43781447410583496 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:47.495419 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([1, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([1, 2, 3, 4, 5],"int32"), ) 	 50803440 	 1000 	 0.29825258255004883 	 0.3381047248840332 	 0.2874600887298584 	 0.32611560821533203 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:48.715930 test begin: paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), )
[Prof] paddle.remainder 	 paddle.remainder(Tensor([423361, 2, 3, 4, 5],"int32"), Tensor([423361, 2, 3, 4, 5],"int32"), ) 	 101606640 	 1000 	 0.4502136707305908 	 0.4507300853729248 	 0.44028162956237793 	 0.4381375312805176 	 None 	 None 	 None 	 None 	 
2025-07-30 19:57:50.836696 test begin: paddle.renorm(Tensor([10, 20, 254017],"float32"), 1.0, -1, 2.05, )
[Prof] paddle.renorm 	 paddle.renorm(Tensor([10, 20, 254017],"float32"), 1.0, -1, 2.05, ) 	 50803400 	 1000 	 2.8540570735931396 	 0.48122644424438477 	 0.7282004356384277 	 0.16382122039794922 	 5.563721179962158 	 2.9179294109344482 	 1.4215397834777832 	 0.2290968894958496 	 
2025-07-30 19:58:04.504864 test begin: paddle.repeat_interleave(Tensor([1, 1500, 33869],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([1, 1500, 33869],"float32"), 5, axis=0, ) 	 50803500 	 1000 	 1.8588223457336426 	 1.508474588394165 	 0.9498169422149658 	 1.485755443572998 	 2.420198917388916 	 0.8741273880004883 	 0.8251032829284668 	 0.7809813022613525 	 
2025-07-30 19:58:16.212840 test begin: paddle.repeat_interleave(Tensor([1, 39691, 1280],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([1, 39691, 1280],"float32"), 5, axis=0, ) 	 50804480 	 1000 	 1.8647639751434326 	 1.4926471710205078 	 0.95285964012146 	 1.470134973526001 	 2.400076150894165 	 0.862635612487793 	 0.8182570934295654 	 0.7688663005828857 	 
2025-07-30 19:58:27.822043 test begin: paddle.repeat_interleave(Tensor([14, 1, 384, 9451],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 1, 384, 9451],"float32"), repeats=3, axis=1, ) 	 50808576 	 1000 	 1.1057977676391602 	 0.8488223552703857 	 0.5650367736816406 	 0.8254783153533936 	 1.226768970489502 	 0.5868663787841797 	 0.4181807041168213 	 0.49183130264282227 	 
2025-07-30 19:58:34.899637 test begin: paddle.repeat_interleave(Tensor([14, 1, 9451, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 1, 9451, 384],"float32"), repeats=3, axis=1, ) 	 50808576 	 1000 	 1.105783224105835 	 0.8676602840423584 	 0.5650122165679932 	 0.8251869678497314 	 1.2273523807525635 	 0.5869565010070801 	 0.4184749126434326 	 0.49326515197753906 	 
2025-07-30 19:58:42.633183 test begin: paddle.repeat_interleave(Tensor([14, 25, 384, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([14, 25, 384, 384],"float32"), repeats=3, axis=1, ) 	 51609600 	 1000 	 1.0452876091003418 	 0.7309153079986572 	 0.534104585647583 	 0.7065596580505371 	 1.212031602859497 	 0.6025476455688477 	 0.41314005851745605 	 0.5078916549682617 	 
2025-07-30 19:58:49.630484 test begin: paddle.repeat_interleave(Tensor([27, 1500, 1280],"float32"), 5, axis=0, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([27, 1500, 1280],"float32"), 5, axis=0, ) 	 51840000 	 1000 	 1.6907250881195068 	 1.110215425491333 	 0.863936185836792 	 1.0842094421386719 	 1.8621079921722412 	 0.8807909488677979 	 0.6348159313201904 	 0.7891604900360107 	 
2025-07-30 19:59:00.197240 test begin: paddle.repeat_interleave(Tensor([345, 1, 384, 384],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([345, 1, 384, 384],"float32"), repeats=3, axis=1, ) 	 50872320 	 1000 	 1.0300054550170898 	 0.720465898513794 	 0.5262773036956787 	 0.6963057518005371 	 1.1931617259979248 	 0.5940892696380615 	 0.40670108795166016 	 0.5013401508331299 	 
2025-07-30 19:59:07.128587 test begin: paddle.repeat_interleave(Tensor([5, 1, 13231, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 1, 13231, 768],"float32"), repeats=3, axis=1, ) 	 50807040 	 1000 	 1.1217308044433594 	 0.9134843349456787 	 0.5731632709503174 	 0.8776788711547852 	 1.496450662612915 	 0.586820125579834 	 0.510075569152832 	 0.49306225776672363 	 
2025-07-30 19:59:17.645424 test begin: paddle.repeat_interleave(Tensor([5, 1, 768, 13231],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 1, 768, 13231],"float32"), repeats=3, axis=1, ) 	 50807040 	 1000 	 1.121828317642212 	 0.9037697315216064 	 0.5731947422027588 	 0.8810915946960449 	 1.4959280490875244 	 0.5868115425109863 	 0.5099809169769287 	 0.49388837814331055 	 
2025-07-30 19:59:25.092411 test begin: paddle.repeat_interleave(Tensor([5, 18, 768, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([5, 18, 768, 768],"float32"), repeats=3, axis=1, ) 	 53084160 	 1000 	 1.0545382499694824 	 0.7035343647003174 	 0.5388500690460205 	 0.6807754039764404 	 1.2518095970153809 	 0.6253347396850586 	 0.42666125297546387 	 0.5319497585296631 	 
2025-07-30 19:59:32.190231 test begin: paddle.repeat_interleave(Tensor([87, 1, 768, 768],"float32"), repeats=3, axis=1, )
[Prof] paddle.repeat_interleave 	 paddle.repeat_interleave(Tensor([87, 1, 768, 768],"float32"), repeats=3, axis=1, ) 	 51314688 	 1000 	 1.019033432006836 	 0.7144999504089355 	 0.5206632614135742 	 0.6564536094665527 	 1.2098944187164307 	 0.6047244071960449 	 0.41231799125671387 	 0.511103630065918 	 
2025-07-30 19:59:40.617108 test begin: paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], )
[Prof] paddle.reshape 	 paddle.reshape(Tensor([141760, 7168],"bfloat16"), list[-1,7168,], ) 	 1016135680 	 1000 	 0.005318164825439453 	 0.004002809524536133 	 1.239776611328125e-05 	 3.600120544433594e-05 	 0.04525184631347656 	 4.681225061416626 	 3.6716461181640625e-05 	 2.482318639755249 	 
2025-07-30 20:00:20.223692 test begin: paddle.reverse(Tensor([12, 132301, 16],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 132301, 16],"float64"), axis=list[0,], ) 	 25401792 	 1000 	 0.5056233406066895 	 0.30690455436706543 	 0.49634718894958496 	 0.2879512310028076 	 0.5066642761230469 	 0.3037455081939697 	 0.4562551975250244 	 0.23619961738586426 	 
2025-07-30 20:00:23.555421 test begin: paddle.reverse(Tensor([12, 264601, 8],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 264601, 8],"float64"), axis=0, ) 	 25401696 	 1000 	 0.508018970489502 	 0.3040318489074707 	 0.4987154006958008 	 0.28558921813964844 	 0.50675368309021 	 0.3038921356201172 	 0.4563472270965576 	 0.23407268524169922 	 
2025-07-30 20:00:26.237379 test begin: paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=0, ) 	 25401648 	 1000 	 0.5077192783355713 	 0.303983211517334 	 0.4984447956085205 	 0.2898228168487549 	 0.507735013961792 	 0.30382776260375977 	 0.4564807415008545 	 0.23540139198303223 	 
2025-07-30 20:00:28.957732 test begin: paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([12, 4, 529201],"float64"), axis=list[0,], ) 	 25401648 	 1000 	 0.5077333450317383 	 0.3039968013763428 	 0.4979867935180664 	 0.2902090549468994 	 0.5077042579650879 	 0.30380868911743164 	 0.457472562789917 	 0.2354438304901123 	 
2025-07-30 20:00:31.650838 test begin: paddle.reverse(Tensor([396901, 4, 16],"float64"), axis=list[0,], )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([396901, 4, 16],"float64"), axis=list[0,], ) 	 25401664 	 1000 	 0.5028436183929443 	 0.30268073081970215 	 0.49358344078063965 	 0.2889728546142578 	 0.502711296081543 	 0.3025033473968506 	 0.4484684467315674 	 0.23482871055603027 	 
2025-07-30 20:00:34.373477 test begin: paddle.reverse(Tensor([4, 12, 529201],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([4, 12, 529201],"float64"), axis=1, ) 	 25401648 	 1000 	 0.5076489448547363 	 0.5341300964355469 	 0.4985044002532959 	 0.29158926010131836 	 0.5076563358306885 	 0.30564355850219727 	 0.457111120223999 	 0.2382957935333252 	 
2025-07-30 20:00:38.969194 test begin: paddle.reverse(Tensor([4, 198451, 32],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([4, 198451, 32],"float64"), axis=1, ) 	 25401728 	 1000 	 0.5031478404998779 	 0.3033123016357422 	 0.49398136138916016 	 0.28820109367370605 	 0.5031619071960449 	 0.30316758155822754 	 0.45252299308776855 	 0.23210716247558594 	 
2025-07-30 20:00:41.647047 test begin: paddle.reverse(Tensor([66151, 12, 32],"float64"), axis=1, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([66151, 12, 32],"float64"), axis=1, ) 	 25401984 	 1000 	 0.5018959045410156 	 0.3032643795013428 	 0.4927384853363037 	 0.2893702983856201 	 0.503410816192627 	 0.30335259437561035 	 0.45204997062683105 	 0.2361750602722168 	 
2025-07-30 20:00:44.315954 test begin: paddle.reverse(Tensor([793801, 4, 8],"float64"), axis=0, )
[Prof] paddle.reverse 	 paddle.reverse(Tensor([793801, 4, 8],"float64"), axis=0, ) 	 25401632 	 1000 	 0.5019094944000244 	 0.3029794692993164 	 0.4922468662261963 	 0.28775548934936523 	 0.5031716823577881 	 0.30274391174316406 	 0.45300722122192383 	 0.2330615520477295 	 
2025-07-30 20:00:46.991448 test begin: paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5455362796783447 	 0.7858607769012451 	 0.5338873863220215 	 0.4015634059906006 	 0.5454504489898682 	 0.783825159072876 	 0.4920825958251953 	 0.4004542827606201 	 
2025-07-30 20:00:51.342982 test begin: paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 37, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5452077388763428 	 0.7910702228546143 	 0.5331776142120361 	 0.4006035327911377 	 0.5456271171569824 	 0.7860927581787109 	 0.49268364906311035 	 0.40163707733154297 	 
2025-07-30 20:00:55.736662 test begin: paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5455446243286133 	 0.7887201309204102 	 0.5340065956115723 	 0.4030451774597168 	 0.5456864833831787 	 0.7867531776428223 	 0.4871537685394287 	 0.4019589424133301 	 
2025-07-30 20:01:00.099322 test begin: paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 37, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50921472 	 1000 	 0.5454671382904053 	 0.7871620655059814 	 0.5341217517852783 	 0.40221405029296875 	 0.5456154346466064 	 0.7888531684875488 	 0.4918785095214844 	 0.4030287265777588 	 
2025-07-30 20:01:04.482629 test begin: paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 50978816 	 1000 	 0.5458788871765137 	 0.7914042472839355 	 0.5344080924987793 	 0.4031224250793457 	 0.5460376739501953 	 0.7864179611206055 	 0.4929678440093994 	 0.40180253982543945 	 
2025-07-30 20:01:10.468825 test begin: paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([128, 56, 56, 127],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 50978816 	 1000 	 0.5459213256835938 	 0.7862915992736816 	 0.5344359874725342 	 0.40180134773254395 	 0.5459873676300049 	 0.788593053817749 	 0.492750883102417 	 0.4028816223144531 	 
2025-07-30 20:01:14.790221 test begin: paddle.roll(Tensor([44, 96, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([44, 96, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51904512 	 1000 	 0.5560097694396973 	 0.7973623275756836 	 0.5446016788482666 	 0.40744924545288086 	 0.5560877323150635 	 0.7946376800537109 	 0.5029346942901611 	 0.4059715270996094 	 
2025-07-30 20:01:19.217017 test begin: paddle.roll(Tensor([64, 65, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 65, 96, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51118080 	 1000 	 0.5477359294891357 	 0.7874164581298828 	 0.5364089012145996 	 0.4015023708343506 	 0.547743558883667 	 0.782914400100708 	 0.48080968856811523 	 0.400012731552124 	 
2025-07-30 20:01:23.584396 test begin: paddle.roll(Tensor([64, 96, 65, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 96, 65, 128],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51118080 	 1000 	 0.5477826595306396 	 0.792759895324707 	 0.5346994400024414 	 0.4019334316253662 	 0.5477194786071777 	 0.783747673034668 	 0.49443769454956055 	 0.40044260025024414 	 
2025-07-30 20:01:29.066798 test begin: paddle.roll(Tensor([64, 96, 96, 87],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([64, 96, 96, 87],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 	 51314688 	 1000 	 0.5496561527252197 	 0.7921407222747803 	 0.5382096767425537 	 0.4047698974609375 	 0.5497124195098877 	 0.7887706756591797 	 0.4958226680755615 	 0.40299224853515625 	 
2025-07-30 20:01:33.442607 test begin: paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 	 51179520 	 1000 	 0.5482196807861328 	 0.8002843856811523 	 0.5369670391082764 	 0.4033634662628174 	 0.5481958389282227 	 0.7870571613311768 	 0.49482131004333496 	 0.4021298885345459 	 
2025-07-30 20:01:39.634235 test begin: paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[Prof] paddle.roll 	 paddle.roll(Tensor([85, 56, 56, 192],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 	 51179520 	 1000 	 0.5481183528900146 	 0.7932755947113037 	 0.5366804599761963 	 0.40228843688964844 	 0.5483968257904053 	 0.789297342300415 	 0.4947936534881592 	 0.40325045585632324 	 
2025-07-30 20:01:44.072086 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5142984390258789 	 0.3032951354980469 	 0.48950910568237305 	 0.2877192497253418 	 0.824681282043457 	 0.3037874698638916 	 0.4213602542877197 	 0.22717809677124023 	 
2025-07-30 20:01:47.103221 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8200583457946777 	 0.30333900451660156 	 0.41906189918518066 	 0.28669095039367676 	 0.5144920349121094 	 0.3034200668334961 	 0.45712947845458984 	 0.2312164306640625 	 
2025-07-30 20:01:50.146759 test begin: paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.815730094909668 	 0.30335044860839844 	 0.41675615310668945 	 0.2866191864013672 	 0.514479398727417 	 0.30302977561950684 	 0.4569816589355469 	 0.23255038261413574 	 
2025-07-30 20:01:53.264977 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5175905227661133 	 0.3042337894439697 	 0.4934401512145996 	 0.2885720729827881 	 0.8279504776000977 	 0.30251574516296387 	 0.42301511764526367 	 0.2308943271636963 	 
2025-07-30 20:01:56.306669 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.9519598484039307 	 0.3042275905609131 	 0.48646092414855957 	 0.28765392303466797 	 0.5190603733062744 	 0.3042752742767334 	 0.461345911026001 	 0.23171305656433105 	 
2025-07-30 20:01:59.442288 test begin: paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8155713081359863 	 0.3033468723297119 	 0.4167518615722656 	 0.2855367660522461 	 0.5144226551055908 	 0.3030672073364258 	 0.4565904140472412 	 0.23205184936523438 	 
2025-07-30 20:02:02.486292 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.5191323757171631 	 0.3042111396789551 	 0.4944441318511963 	 0.2868833541870117 	 0.8282144069671631 	 0.3037400245666504 	 0.4231686592102051 	 0.2315986156463623 	 
2025-07-30 20:02:05.511070 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.831291675567627 	 0.30688023567199707 	 0.42471814155578613 	 0.28701066970825195 	 0.5144407749176025 	 0.30342698097229004 	 0.45653390884399414 	 0.23198843002319336 	 
2025-07-30 20:02:08.591053 test begin: paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8188991546630859 	 0.3043544292449951 	 0.41844654083251953 	 0.28769826889038086 	 0.5183358192443848 	 0.3059542179107666 	 0.46054816246032715 	 0.2340993881225586 	 
2025-07-30 20:02:11.618113 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.5200831890106201 	 0.3090062141418457 	 0.49362707138061523 	 0.2884376049041748 	 0.8281185626983643 	 0.30379152297973633 	 0.42308974266052246 	 0.22672128677368164 	 
2025-07-30 20:02:14.658341 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8286290168762207 	 0.3042581081390381 	 0.42342686653137207 	 0.28731799125671387 	 0.518667459487915 	 0.3064298629760742 	 0.4607875347137451 	 0.2361741065979004 	 
2025-07-30 20:02:17.773639 test begin: paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.rot90 	 paddle.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8101451396942139 	 0.3064725399017334 	 0.4139552116394043 	 0.2897069454193115 	 0.5143733024597168 	 0.30306243896484375 	 0.4517486095428467 	 0.2321314811706543 	 
2025-07-30 20:02:20.807266 test begin: paddle.round(Tensor([128, 396901],"float32"), )
[Prof] paddle.round 	 paddle.round(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.29554057121276855 	 0.29776787757873535 	 0.28646111488342285 	 0.2858607769012451 	 0.1339278221130371 	 0.13409972190856934 	 0.08389401435852051 	 0.06826519966125488 	 
2025-07-30 20:02:23.343222 test begin: paddle.round(Tensor([16, 1587601],"float64"), )
[Prof] paddle.round 	 paddle.round(Tensor([16, 1587601],"float64"), ) 	 25401616 	 1000 	 0.30438232421875 	 0.2983527183532715 	 0.2957484722137451 	 0.28748154640197754 	 0.1337745189666748 	 0.1345221996307373 	 0.0819551944732666 	 0.06752729415893555 	 
2025-07-30 20:02:25.276978 test begin: paddle.round(Tensor([396901, 128],"float32"), )
[Prof] paddle.round 	 paddle.round(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2955503463745117 	 0.2978074550628662 	 0.28667211532592773 	 0.2869534492492676 	 0.13390207290649414 	 0.13412833213806152 	 0.0812537670135498 	 0.06789708137512207 	 
2025-07-30 20:02:27.830403 test begin: paddle.round(Tensor([99226, 256],"float64"), )
[Prof] paddle.round 	 paddle.round(Tensor([99226, 256],"float64"), ) 	 25401856 	 1000 	 0.30486035346984863 	 0.2997126579284668 	 0.2962815761566162 	 0.2873671054840088 	 0.1338210105895996 	 0.13447785377502441 	 0.0839395523071289 	 0.0664834976196289 	 
2025-07-30 20:02:30.725871 test begin: paddle.round(x=Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 0.2953925132751465 	 0.306079626083374 	 0.286163330078125 	 0.28589773178100586 	 0.13398504257202148 	 0.1341688632965088 	 0.083770751953125 	 0.06434917449951172 	 
2025-07-30 20:02:34.115215 test begin: paddle.round(x=Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 0.2953972816467285 	 0.3100414276123047 	 0.28620171546936035 	 0.2868022918701172 	 0.13397812843322754 	 0.13411808013916016 	 0.0834510326385498 	 0.06774497032165527 	 
2025-07-30 20:02:39.007944 test begin: paddle.round(x=Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.round 	 paddle.round(x=Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 0.29545140266418457 	 0.29782629013061523 	 0.28490209579467773 	 0.28688764572143555 	 0.1340322494506836 	 0.13410067558288574 	 0.08351778984069824 	 0.06781196594238281 	 
2025-07-30 20:02:41.559603 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9382834434509277 	 0.9223191738128662 	 0.1598215103149414 	 0.9071865081787109 	 0.9433538913726807 	 0.07585382461547852 	 0.16066336631774902 	 4.3392181396484375e-05 	 
2025-07-30 20:02:47.758433 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3077425956726074 	 0.3130607604980469 	 0.15723085403442383 	 0.1598834991455078 	 0.31406140327453613 	 0.06096196174621582 	 0.16042327880859375 	 7.987022399902344e-05 	 
2025-07-30 20:02:49.817292 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3203096389770508 	 0.3233528137207031 	 0.0819857120513916 	 0.30883169174194336 	 0.31616950035095215 	 0.0773458480834961 	 0.08088874816894531 	 5.435943603515625e-05 	 
2025-07-30 20:02:51.934686 test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3220992088317871 	 0.3201885223388672 	 0.08211135864257812 	 0.3045504093170166 	 0.3219280242919922 	 0.07621002197265625 	 0.08205366134643555 	 3.337860107421875e-05 	 
2025-07-30 20:02:54.070239 test begin: paddle.row_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),Tensor([3, 4, 2116801],"float64"),], ) 	 76204836 	 1000 	 0.9467346668243408 	 0.9147593975067139 	 0.16128087043762207 	 0.899986743927002 	 0.9541914463043213 	 0.07500171661376953 	 0.1624748706817627 	 5.4836273193359375e-05 	 
2025-07-30 20:03:00.220959 test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.31937479972839355 	 0.32221031188964844 	 0.08175945281982422 	 0.3079080581665039 	 0.3166327476501465 	 0.0774223804473877 	 0.08100414276123047 	 7.486343383789062e-05 	 
2025-07-30 20:03:02.416191 test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.32096433639526367 	 0.31835126876831055 	 0.08184671401977539 	 0.3042638301849365 	 0.3230416774749756 	 0.07587289810180664 	 0.08235597610473633 	 3.7670135498046875e-05 	 
2025-07-30 20:03:04.525238 test begin: paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9496147632598877 	 0.9184601306915283 	 0.16175389289855957 	 0.9034337997436523 	 0.951789379119873 	 0.08089017868041992 	 0.16210317611694336 	 8.559226989746094e-05 	 
2025-07-30 20:03:10.732784 test begin: paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.315093994140625 	 0.3130455017089844 	 0.16101288795471191 	 0.15987014770507812 	 0.315934419631958 	 0.05835556983947754 	 0.16138720512390137 	 4.8160552978515625e-05 	 
2025-07-30 20:03:12.811981 test begin: paddle.row_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),Tensor([3, 4233601, 2],"float64"),], ) 	 76204818 	 1000 	 0.9420905113220215 	 0.9198102951049805 	 0.16045284271240234 	 0.9050838947296143 	 0.9306888580322266 	 0.0780632495880127 	 0.15850496292114258 	 4.3392181396484375e-05 	 
2025-07-30 20:03:18.929710 test begin: paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9447674751281738 	 0.9311301708221436 	 0.16093111038208008 	 0.913809061050415 	 0.9470353126525879 	 0.0766291618347168 	 0.16127490997314453 	 5.340576171875e-05 	 
2025-07-30 20:03:25.122732 test begin: paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.30778002738952637 	 0.3130760192871094 	 0.1572568416595459 	 0.15988945960998535 	 0.3140683174133301 	 0.058451175689697266 	 0.1604166030883789 	 5.221366882324219e-05 	 
2025-07-30 20:03:27.143145 test begin: paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 	 25401656 	 1000 	 0.31272435188293457 	 0.30842018127441406 	 0.07974386215209961 	 0.2943451404571533 	 0.3203299045562744 	 0.07702350616455078 	 0.08164715766906738 	 7.033348083496094e-05 	 
2025-07-30 20:03:29.198151 test begin: paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),Tensor([3175201, 4, 2],"float64"),], ) 	 76204824 	 1000 	 0.937903881072998 	 1.3922979831695557 	 0.15976381301879883 	 0.8999495506286621 	 0.9302706718444824 	 0.07615208625793457 	 0.15844416618347168 	 6.580352783203125e-05 	 
2025-07-30 20:03:39.574041 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3203611373901367 	 0.7653374671936035 	 0.08170533180236816 	 0.2967715263366699 	 0.3202803134918213 	 0.07627081871032715 	 0.08165550231933594 	 4.744529724121094e-05 	 
2025-07-30 20:03:43.674886 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9493095874786377 	 0.9224379062652588 	 0.16169285774230957 	 0.9003927707672119 	 0.9431865215301514 	 0.07784819602966309 	 0.1606431007385254 	 6.008148193359375e-05 	 
2025-07-30 20:03:49.838823 test begin: paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.row_stack 	 paddle.row_stack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.3151242733001709 	 0.31299495697021484 	 0.16103506088256836 	 0.15986132621765137 	 0.31592559814453125 	 0.0639801025390625 	 0.16138029098510742 	 7.200241088867188e-05 	 
2025-07-30 20:03:51.941837 test begin: paddle.rsqrt(Tensor([10000, 1694, 3],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 1694, 3],"float32"), ) 	 50820000 	 1000 	 0.29581236839294434 	 0.29805827140808105 	 0.28717827796936035 	 0.2870972156524658 	 0.4496033191680908 	 1.0406954288482666 	 0.38506460189819336 	 0.3545346260070801 	 
2025-07-30 20:03:55.876472 test begin: paddle.rsqrt(Tensor([10000, 2, 1271],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 2, 1271],"float64"), ) 	 25420000 	 1000 	 0.2978701591491699 	 0.29920172691345215 	 0.28949427604675293 	 0.28823184967041016 	 0.4485478401184082 	 1.0401246547698975 	 0.3952014446258545 	 0.3542759418487549 	 
2025-07-30 20:03:59.074109 test begin: paddle.rsqrt(Tensor([10000, 2, 2541],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 2, 2541],"float32"), ) 	 50820000 	 1000 	 0.295790433883667 	 0.2980079650878906 	 0.28725600242614746 	 0.2858700752258301 	 0.44945764541625977 	 1.040675401687622 	 0.393817663192749 	 0.3545262813568115 	 
2025-07-30 20:04:02.901421 test begin: paddle.rsqrt(Tensor([10000, 847, 3],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([10000, 847, 3],"float64"), ) 	 25410000 	 1000 	 0.29778361320495605 	 0.29904794692993164 	 0.2895081043243408 	 0.2882044315338135 	 0.4483053684234619 	 1.039726972579956 	 0.394791841506958 	 0.35419464111328125 	 
2025-07-30 20:04:06.122688 test begin: paddle.rsqrt(Tensor([13, 1007, 3881],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([13, 1007, 3881],"float32"), ) 	 50806171 	 1000 	 0.29559755325317383 	 0.297835111618042 	 0.28690218925476074 	 0.2870609760284424 	 0.4494743347167969 	 1.0404765605926514 	 0.39519214630126953 	 0.35452938079833984 	 
2025-07-30 20:04:09.881774 test begin: paddle.rsqrt(Tensor([13, 3907939, 1],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([13, 3907939, 1],"float32"), ) 	 50803207 	 1000 	 0.2954897880554199 	 0.29779839515686035 	 0.28690433502197266 	 0.2870469093322754 	 0.4495680332183838 	 1.0403690338134766 	 0.395688533782959 	 0.3544502258300781 	 
2025-07-30 20:04:13.746765 test begin: paddle.rsqrt(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.29857420921325684 	 0.29892826080322266 	 0.28946781158447266 	 0.28810834884643555 	 0.4483623504638672 	 1.0393502712249756 	 0.3882620334625244 	 0.3541262149810791 	 
2025-07-30 20:04:16.925348 test begin: paddle.rsqrt(Tensor([50451, 1007, 1],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([50451, 1007, 1],"float32"), ) 	 50804157 	 1000 	 0.2955591678619385 	 0.29777026176452637 	 0.2869069576263428 	 0.28705310821533203 	 0.44938111305236816 	 1.0403811931610107 	 0.39273834228515625 	 0.35443568229675293 	 
2025-07-30 20:04:20.747627 test begin: paddle.rsqrt(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.rsqrt 	 paddle.rsqrt(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2955055236816406 	 0.2978501319885254 	 0.28693079948425293 	 0.287111759185791 	 0.44956469535827637 	 1.0403966903686523 	 0.3916780948638916 	 0.3544619083404541 	 
2025-07-30 20:04:24.558606 test begin: paddle.scale(Tensor([2, 256, 256, 388],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 256, 256, 388],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29602575302124023 	 0.5960700511932373 	 0.2862851619720459 	 0.30458641052246094 	 0.2959113121032715 	 0.29811596870422363 	 0.22169804573059082 	 0.22392821311950684 	 combined
2025-07-30 20:04:27.694797 test begin: paddle.scale(Tensor([2, 256, 388, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 256, 388, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2960395812988281 	 0.5960614681243896 	 0.28436946868896484 	 0.30457329750061035 	 0.29592108726501465 	 0.29810142517089844 	 0.24461746215820312 	 0.2193601131439209 	 combined
2025-07-30 20:04:30.882183 test begin: paddle.scale(Tensor([2, 388, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([2, 388, 256, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.296008825302124 	 0.5960445404052734 	 0.286440372467041 	 0.30455565452575684 	 0.2959010601043701 	 0.2981142997741699 	 0.2434546947479248 	 0.2246706485748291 	 combined
2025-07-30 20:04:34.011086 test begin: paddle.scale(Tensor([4, 194, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 194, 256, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29602766036987305 	 0.606006383895874 	 0.2864820957183838 	 0.30461835861206055 	 0.2959301471710205 	 0.29809117317199707 	 0.24425411224365234 	 0.22343802452087402 	 combined
2025-07-30 20:04:39.523766 test begin: paddle.scale(Tensor([4, 256, 194, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 194, 256],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.2960021495819092 	 0.5960385799407959 	 0.2863273620605469 	 0.30454015731811523 	 0.29593825340270996 	 0.29810380935668945 	 0.24420619010925293 	 0.21967244148254395 	 combined
2025-07-30 20:04:42.670721 test begin: paddle.scale(Tensor([4, 256, 256, 194],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 194],"float32"), scale=1.1111111111111112, ) 	 50855936 	 1000 	 0.29601192474365234 	 0.6179947853088379 	 0.2863903045654297 	 0.3045172691345215 	 0.29594874382019043 	 0.29799437522888184 	 0.24323368072509766 	 0.2173922061920166 	 combined
2025-07-30 20:04:48.400011 test begin: paddle.scale(Tensor([4, 256, 256, 256],"float32"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 256],"float32"), scale=1.1111111111111112, ) 	 67108864 	 1000 	 0.389324426651001 	 0.7829291820526123 	 0.37967348098754883 	 0.40006422996520996 	 0.3893299102783203 	 0.39156484603881836 	 0.33301401138305664 	 0.31823158264160156 	 combined
2025-07-30 20:04:52.544254 test begin: paddle.scale(Tensor([4, 256, 256, 388],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 256, 388],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.29885363578796387 	 0.5932514667510986 	 0.28911757469177246 	 0.3028297424316406 	 0.29872798919677734 	 0.2964935302734375 	 0.245927095413208 	 0.22335577011108398 	 combined
2025-07-30 20:04:57.851196 test begin: paddle.scale(Tensor([4, 256, 388, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 256, 388, 256],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.2988874912261963 	 0.59269118309021 	 0.28928375244140625 	 0.3028249740600586 	 0.29871582984924316 	 0.2966196537017822 	 0.24621963500976562 	 0.2213292121887207 	 combined
2025-07-30 20:05:03.146744 test begin: paddle.scale(Tensor([4, 388, 256, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([4, 388, 256, 256],"float16"), scale=1.1111111111111112, ) 	 101711872 	 1000 	 0.2988440990447998 	 0.5926308631896973 	 0.28644728660583496 	 0.3028106689453125 	 0.29875946044921875 	 0.29651856422424316 	 0.24719858169555664 	 0.22214341163635254 	 combined
2025-07-30 20:05:08.564661 test begin: paddle.scale(Tensor([7, 256, 256, 256],"float16"), scale=1.1111111111111112, )
[Prof] paddle.scale 	 paddle.scale(Tensor([7, 256, 256, 256],"float16"), scale=1.1111111111111112, ) 	 117440512 	 1000 	 0.34423017501831055 	 0.6829390525817871 	 0.33445191383361816 	 0.34898948669433594 	 0.34441256523132324 	 0.3416323661804199 	 0.28928208351135254 	 0.2623271942138672 	 combined
2025-07-30 20:05:14.734513 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([197],"int32"), Tensor([197, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([197],"int32"), Tensor([197, 194],"float32"), overwrite=True, ) 	 50894351 	 1000 	 0.31996726989746094 	 6.881724834442139 	 0.16347622871398926 	 0.0002243518829345703 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:05:24.033992 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([205],"int32"), Tensor([205, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([205],"int32"), Tensor([205, 194],"float32"), overwrite=True, ) 	 50895911 	 1000 	 0.31990933418273926 	 6.966549873352051 	 0.16347479820251465 	 0.00024008750915527344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:05:33.357856 test begin: paddle.scatter(Tensor([262144, 194],"float32"), Tensor([219],"int32"), Tensor([219, 194],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 194],"float32"), Tensor([219],"int32"), Tensor([219, 194],"float32"), overwrite=True, ) 	 50898641 	 1000 	 0.32006049156188965 	 7.5200464725494385 	 0.16353559494018555 	 0.0002346038818359375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:05:44.910875 test begin: paddle.scatter(Tensor([262144, 2314],"float32"), Tensor([219],"int32"), Tensor([219, 2314],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2314],"float32"), Tensor([219],"int32"), Tensor([219, 2314],"float32"), overwrite=True, ) 	 607108201 	 1000 	 3.7026779651641846 	 7.570932149887085 	 1.2589561939239502 	 0.0002181529998779297 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:06:20.065500 test begin: paddle.scatter(Tensor([262144, 2476],"float32"), Tensor([205],"int32"), Tensor([205, 2476],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2476],"float32"), Tensor([205],"int32"), Tensor([205, 2476],"float32"), overwrite=True, ) 	 649576329 	 1000 	 3.9637303352355957 	 7.056135654449463 	 1.3477015495300293 	 0.00021910667419433594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:06:57.363845 test begin: paddle.scatter(Tensor([262144, 2569],"float32"), Tensor([197],"int32"), Tensor([197, 2569],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 2569],"float32"), Tensor([197],"int32"), Tensor([197, 2569],"float32"), overwrite=True, ) 	 673954226 	 1000 	 4.104910135269165 	 6.722087383270264 	 1.395723581314087 	 0.00022482872009277344 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:07:34.922090 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([197],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([197],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285445 	 1000 	 0.11265254020690918 	 7.2776429653167725 	 0.057559967041015625 	 0.0002307891845703125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:07:44.014491 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([205],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([205],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285453 	 1000 	 0.11263108253479004 	 7.126311540603638 	 0.057538747787475586 	 0.00023055076599121094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:07:51.953185 test begin: paddle.scatter(Tensor([262144, 64],"float32"), Tensor([219],"int32"), Tensor([7938, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([262144, 64],"float32"), Tensor([219],"int32"), Tensor([7938, 64],"float32"), overwrite=True, ) 	 17285467 	 1000 	 0.11269974708557129 	 7.647390604019165 	 0.0575718879699707 	 0.00023555755615234375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:08:00.451388 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([197],"int32"), Tensor([197, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([197],"int32"), Tensor([197, 64],"float32"), overwrite=True, ) 	 50816069 	 1000 	 0.3146076202392578 	 6.756695508956909 	 0.10699009895324707 	 0.00022459030151367188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:08:09.597767 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([205],"int32"), Tensor([205, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([205],"int32"), Tensor([205, 64],"float32"), overwrite=True, ) 	 50816589 	 1000 	 0.31438493728637695 	 7.084697484970093 	 0.10689592361450195 	 0.00022149085998535156 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:08:19.050747 test begin: paddle.scatter(Tensor([793801, 64],"float32"), Tensor([219],"int32"), Tensor([219, 64],"float32"), overwrite=True, )
[Prof] paddle.scatter 	 paddle.scatter(Tensor([793801, 64],"float32"), Tensor([219],"int32"), Tensor([219, 64],"float32"), overwrite=True, ) 	 50817499 	 1000 	 0.31441283226013184 	 7.473362922668457 	 0.10692477226257324 	 0.000232696533203125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:08:28.914529 test begin: paddle.scatter_nd(Tensor([1280, 2],"int64"), Tensor([1280, 9, 10],"float32"), list[3,5,9,10,], )
[Prof] paddle.scatter_nd 	 paddle.scatter_nd(Tensor([1280, 2],"int64"), Tensor([1280, 9, 10],"float32"), list[3,5,9,10,], ) 	 117760 	 1000 	 0.036777496337890625 	 155.22924542427063 	 1.5497207641601562e-05 	 0.00020003318786621094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:11:04.452563 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), ) 	 105808018 	 1000 	 0.40497255325317383 	 71.41722393035889 	 0.2069249153137207 	 0.00021195411682128906 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:12:21.064058 test begin: paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 14176, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), ) 	 105879718 	 1000 	 0.40540075302124023 	 72.28369975090027 	 0.20713114738464355 	 0.00021839141845703125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:13:40.352582 test begin: paddle.scatter_nd_add(Tensor([1, 8192, 12404],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 12404],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 8192, 12404],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 12404],"bfloat16"), ) 	 108895890 	 1000 	 0.5427589416503906 	 71.60478448867798 	 0.277329683303833 	 0.0002129077911376953 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:14:56.805173 test begin: paddle.scatter_nd_add(Tensor([1, 8192, 17069],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 17069],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([1, 8192, 17069],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 17069],"bfloat16"), ) 	 149986493 	 1000 	 0.9090182781219482 	 73.00292921066284 	 0.4644911289215088 	 0.00020170211791992188 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:16:16.842535 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([585, 2],"int64"), Tensor([585, 7168],"bfloat16"), ) 	 121634962 	 1000 	 0.45226073265075684 	 71.27099418640137 	 0.23105812072753906 	 0.00020837783813476562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:17:33.396791 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([587, 2],"int64"), Tensor([587, 7168],"bfloat16"), ) 	 121649302 	 1000 	 0.4522976875305176 	 71.76205611228943 	 0.23108410835266113 	 0.0002048015594482422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:18:51.232617 test begin: paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), )
[Prof] paddle.scatter_nd_add 	 paddle.scatter_nd_add(Tensor([2, 8192, 7168],"bfloat16"), Tensor([595, 2],"int64"), Tensor([595, 7168],"bfloat16"), ) 	 121706662 	 1000 	 0.4529414176940918 	 72.17556619644165 	 0.2314314842224121 	 0.00020694732666015625 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:20:08.642463 test begin: paddle.searchsorted(Tensor([1024],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"float32"), Tensor([50803201],"float32"), ) 	 50804225 	 1000 	 1.3769125938415527 	 1.038450002670288 	 1.368903636932373 	 1.021681308746338 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:11.883648 test begin: paddle.searchsorted(Tensor([1024],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"float64"), Tensor([25401601],"float64"), ) 	 25402625 	 1000 	 0.6655845642089844 	 0.5062508583068848 	 0.6570930480957031 	 0.49544382095336914 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:13.600251 test begin: paddle.searchsorted(Tensor([1024],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([1024],"int32"), Tensor([50803201],"int32"), ) 	 50804225 	 1000 	 1.350541114807129 	 1.0381457805633545 	 1.3425991535186768 	 1.0269358158111572 	 None 	 None 	 None 	 None 	 
2025-07-30 20:20:16.589231 test begin: paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([2540160101],"float64"), Tensor([512],"float64"), ) 	 2540160613 	 1000 	 0.00983285903930664 	 0.01085042953491211 	 0.001956462860107422 	 3.314018249511719e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:10.490157 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([25401601],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 1.3948602676391602 	 1.124385118484497 	 1.386855125427246 	 1.1118087768554688 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:15.067177 test begin: paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([25401601],"float64"), Tensor([51201],"float64"), ) 	 25452802 	 1000 	 0.010636329650878906 	 0.010692596435546875 	 0.0012669563293457031 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:15.628201 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 2.966327428817749 	 2.317779302597046 	 2.9583842754364014 	 2.3067877292633057 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:22.560741 test begin: paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"float32"), Tensor([51201],"float32"), ) 	 50854402 	 1000 	 0.01103973388671875 	 0.011111021041870117 	 0.0014798641204833984 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:23.436840 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([50803201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([50803201],"int32"), ) 	 101606402 	 1000 	 2.962815284729004 	 2.316617965698242 	 2.9547884464263916 	 2.305388927459717 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:30.009835 test begin: paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), )
[Prof] paddle.searchsorted 	 paddle.searchsorted(Tensor([50803201],"int32"), Tensor([51201],"int32"), ) 	 50854402 	 1000 	 0.011023998260498047 	 0.011058568954467773 	 0.0030717849731445312 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:21:30.620480 test begin: paddle.select_scatter(Tensor([12700801, 3, 4],"float32"), Tensor([12700801, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([12700801, 3, 4],"float32"), Tensor([12700801, 4],"float32"), 1, 1, ) 	 203212816 	 1000 	 0.7247233390808105 	 1.6640183925628662 	 0.7028772830963135 	 0.5619971752166748 	 3.243032693862915 	 1.7944660186767578 	 0.41408395767211914 	 0.45832252502441406 	 
2025-07-30 20:21:43.966551 test begin: paddle.select_scatter(Tensor([1693441, 3, 4, 5],"float64"), Tensor([1693441, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([1693441, 3, 4, 5],"float64"), Tensor([1693441, 3, 5],"float64"), 2, 1, ) 	 127008075 	 1000 	 0.7516682147979736 	 1.9847736358642578 	 0.7289679050445557 	 0.6755311489105225 	 3.4792191982269287 	 2.1312897205352783 	 0.44399499893188477 	 0.5441725254058838 	 
2025-07-30 20:21:57.178216 test begin: paddle.select_scatter(Tensor([2, 211681, 4, 5, 6],"int32"), Tensor([2, 211681, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 211681, 4, 5, 6],"int32"), Tensor([2, 211681, 5, 6],"int32"), 2, 1, ) 	 63504300 	 1000 	 0.17902064323425293 	 0.4917175769805908 	 0.15668964385986328 	 0.16730999946594238 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:22:00.163286 test begin: paddle.select_scatter(Tensor([2, 2540161, 4, 5],"float64"), Tensor([2, 2540161, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 2540161, 4, 5],"float64"), Tensor([2, 2540161, 5],"float64"), 2, 1, ) 	 127008050 	 1000 	 0.7511181831359863 	 1.985802173614502 	 0.7306070327758789 	 0.6753530502319336 	 3.479330062866211 	 2.1308467388153076 	 0.4441545009613037 	 0.5440151691436768 	 
2025-07-30 20:22:13.424575 test begin: paddle.select_scatter(Tensor([2, 3, 25401601],"float32"), Tensor([2, 25401601],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 25401601],"float32"), Tensor([2, 25401601],"float32"), 1, 1, ) 	 203212808 	 1000 	 0.3666238784790039 	 1.2278428077697754 	 0.3465383052825928 	 0.4176912307739258 	 2.6755154132843018 	 1.3624074459075928 	 0.3414771556854248 	 0.3476893901824951 	 
2025-07-30 20:22:24.807458 test begin: paddle.select_scatter(Tensor([2, 3, 4, 1411201, 6],"int32"), Tensor([2, 3, 1411201, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 1411201, 6],"int32"), Tensor([2, 3, 1411201, 6],"int32"), 2, 1, ) 	 254016180 	 1000 	 0.5413641929626465 	 1.535395860671997 	 0.520357608795166 	 0.5214142799377441 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:22:37.429875 test begin: paddle.select_scatter(Tensor([2, 3, 4, 352801, 6],"int32"), Tensor([2, 3, 352801, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 352801, 6],"int32"), Tensor([2, 3, 352801, 6],"int32"), 2, 1, ) 	 63504180 	 1000 	 0.13859868049621582 	 0.4068934917449951 	 0.11826848983764648 	 0.13343262672424316 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:22:40.404491 test begin: paddle.select_scatter(Tensor([2, 3, 4, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), 2, 1, ) 	 127008030 	 1000 	 0.3054642677307129 	 1.5313327312469482 	 0.284686803817749 	 0.5202879905700684 	 2.7551329135894775 	 1.6641113758087158 	 0.35138773918151855 	 0.42459893226623535 	 
2025-07-30 20:22:51.526970 test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 1693441],"int32"), Tensor([2, 3, 5, 1693441],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 5, 1693441],"int32"), Tensor([2, 3, 5, 1693441],"int32"), 2, 1, ) 	 254016150 	 1000 	 0.5399248600006104 	 1.5446534156799316 	 0.5193774700164795 	 0.5214674472808838 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:23:02.449319 test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 423361],"int32"), Tensor([2, 3, 5, 423361],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 4, 5, 423361],"int32"), Tensor([2, 3, 5, 423361],"int32"), 2, 1, ) 	 63504150 	 1000 	 0.1386263370513916 	 0.392317533493042 	 0.1185615062713623 	 0.13342809677124023 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:23:05.227544 test begin: paddle.select_scatter(Tensor([2, 3, 8467201],"float32"), Tensor([2, 8467201],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 3, 8467201],"float32"), Tensor([2, 8467201],"float32"), 1, 1, ) 	 67737608 	 1000 	 0.12493515014648438 	 0.42017531394958496 	 0.10471582412719727 	 0.1418452262878418 	 0.9044816493988037 	 0.46532177925109863 	 0.11546850204467773 	 0.1186983585357666 	 
2025-07-30 20:23:09.113741 test begin: paddle.select_scatter(Tensor([2, 635041, 4, 5],"float64"), Tensor([2, 635041, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 635041, 4, 5],"float64"), Tensor([2, 635041, 5],"float64"), 2, 1, ) 	 31752050 	 1000 	 0.18641352653503418 	 0.4978923797607422 	 0.1657414436340332 	 0.1694352626800537 	 0.9024548530578613 	 0.5468926429748535 	 0.11517214775085449 	 0.13956785202026367 	 
2025-07-30 20:23:12.497898 test begin: paddle.select_scatter(Tensor([2, 846721, 4, 5, 6],"int32"), Tensor([2, 846721, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([2, 846721, 4, 5, 6],"int32"), Tensor([2, 846721, 5, 6],"int32"), 2, 1, ) 	 254016300 	 1000 	 0.7057080268859863 	 2.640394926071167 	 0.68524169921875 	 0.672177791595459 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:23:26.742039 test begin: paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 282241, 5, 6],"int32"), Tensor([20, 3, 5, 6],"int32"), 2, 1, ) 	 508035600 	 1000 	 0.024754047393798828 	 3.0659921169281006 	 1.5974044799804688e-05 	 1.0422883033752441 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:23:44.563264 test begin: paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 4, 1058401],"float64"), Tensor([20, 3, 1058401],"float64"), 2, 1, ) 	 317520300 	 1000 	 0.7565298080444336 	 3.805630683898926 	 0.7356593608856201 	 1.2945470809936523 	 6.883141040802002 	 4.133225679397583 	 0.877976655960083 	 1.0546414852142334 	 
2025-07-30 20:24:12.405837 test begin: paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 3, 846721, 5],"float64"), Tensor([20, 3, 5],"float64"), 2, 1, ) 	 254016600 	 1000 	 0.021190643310546875 	 3.152561664581299 	 2.2411346435546875e-05 	 1.129241943359375 	 3.109285831451416 	 3.0644073486328125 	 0.39492177963256836 	 0.7813408374786377 	 
2025-07-30 20:24:32.576401 test begin: paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([20, 635040, 4],"float32"), Tensor([20, 4],"float32"), 1, 1, ) 	 50803280 	 1000 	 0.020097017288208008 	 0.3160707950592041 	 1.71661376953125e-05 	 0.10742902755737305 	 0.33021974563598633 	 0.31842541694641113 	 0.04194998741149902 	 0.08111739158630371 	 
2025-07-30 20:24:37.338750 test begin: paddle.select_scatter(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 4],"float32"), 1, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 4],"float32"), 1, 1, ) 	 67737616 	 1000 	 0.24446582794189453 	 0.5617122650146484 	 0.22380828857421875 	 0.1904125213623047 	 1.1076929569244385 	 0.6154797077178955 	 0.14150452613830566 	 0.15715718269348145 	 
2025-07-30 20:24:41.812187 test begin: paddle.select_scatter(Tensor([423361, 3, 4, 5],"float64"), Tensor([423361, 3, 5],"float64"), 2, 1, )
[Prof] paddle.select_scatter 	 paddle.select_scatter(Tensor([423361, 3, 4, 5],"float64"), Tensor([423361, 3, 5],"float64"), 2, 1, ) 	 31752075 	 1000 	 0.1869039535522461 	 0.49788665771484375 	 0.16484880447387695 	 0.1694202423095703 	 0.9023275375366211 	 0.5467548370361328 	 0.11522221565246582 	 0.13959765434265137 	 
2025-07-30 20:24:45.196107 test begin: paddle.sgn(Tensor([12, 1058401, 2],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 1058401, 2],"float64"), ) 	 25401624 	 1000 	 0.3088836669921875 	 0.2983574867248535 	 0.2919120788574219 	 0.28771400451660156 	 0.2974708080291748 	 0.0565495491027832 	 0.2464888095855713 	 4.5299530029296875e-05 	 
2025-07-30 20:24:47.231723 test begin: paddle.sgn(Tensor([12, 20, 105841],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 20, 105841],"float64"), ) 	 25401840 	 1000 	 0.309032678604126 	 0.2983391284942627 	 0.2922811508178711 	 0.2876770496368408 	 0.2978808879852295 	 0.056618452072143555 	 0.24700641632080078 	 5.125999450683594e-05 	 
2025-07-30 20:24:49.262493 test begin: paddle.sgn(Tensor([12, 20, 211681],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 20, 211681],"float32"), ) 	 50803440 	 1000 	 0.3452434539794922 	 0.29770755767822266 	 0.32934141159057617 	 0.2871367931365967 	 0.29572296142578125 	 0.05695652961730957 	 0.23971152305603027 	 4.172325134277344e-05 	 
2025-07-30 20:24:51.921446 test begin: paddle.sgn(Tensor([12, 2116801, 2],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([12, 2116801, 2],"float32"), ) 	 50803224 	 1000 	 0.34453511238098145 	 0.2993922233581543 	 0.3284461498260498 	 0.28690552711486816 	 0.2956538200378418 	 0.0576777458190918 	 0.24245834350585938 	 5.1975250244140625e-05 	 
2025-07-30 20:24:54.684405 test begin: paddle.sgn(Tensor([1270081, 20, 2],"float32"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([1270081, 20, 2],"float32"), ) 	 50803240 	 1000 	 0.34453892707824707 	 0.3087475299835205 	 0.3286566734313965 	 0.2869865894317627 	 0.29561948776245117 	 0.056828975677490234 	 0.24370956420898438 	 4.4345855712890625e-05 	 
2025-07-30 20:24:57.372817 test begin: paddle.sgn(Tensor([635041, 20, 2],"float64"), )
[Prof] paddle.sgn 	 paddle.sgn(Tensor([635041, 20, 2],"float64"), ) 	 25401640 	 1000 	 0.3091716766357422 	 0.29836106300354004 	 0.28681445121765137 	 0.28760290145874023 	 0.2979114055633545 	 0.05919194221496582 	 0.2465076446533203 	 6.508827209472656e-05 	 
2025-07-30 20:24:59.404926 test begin: paddle.shape(Tensor([10, 1600, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([10, 1600, 376, 280],"float32"), ) 	 1684480000 	 1000 	 0.004352569580078125 	 0.03137993812561035 	 1.4066696166992188e-05 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:25:27.006984 test begin: paddle.shape(Tensor([130, 128, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([130, 128, 256, 256],"float16"), ) 	 1090519040 	 1000 	 0.004338741302490234 	 0.031763315200805664 	 1.1920928955078125e-05 	 4.291534423828125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:25:47.244215 test begin: paddle.shape(Tensor([40, 121, 376, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 121, 376, 280],"float32"), ) 	 509555200 	 1000 	 0.004412651062011719 	 0.0316319465637207 	 1.1205673217773438e-05 	 4.863739013671875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:25:55.345702 test begin: paddle.shape(Tensor([40, 128, 256, 388],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 388],"float32"), ) 	 508559360 	 1000 	 0.0043337345123291016 	 0.030972003936767578 	 7.152557373046875e-06 	 4.315376281738281e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:26:03.782271 test begin: paddle.shape(Tensor([40, 128, 256, 776],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 256, 776],"float16"), ) 	 1017118720 	 1000 	 0.004313230514526367 	 0.031297922134399414 	 1.430511474609375e-05 	 4.935264587402344e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:26:22.919725 test begin: paddle.shape(Tensor([40, 128, 388, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 388, 256],"float32"), ) 	 508559360 	 1000 	 0.004374265670776367 	 0.031308650970458984 	 1.0967254638671875e-05 	 6.175041198730469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:26:30.928708 test begin: paddle.shape(Tensor([40, 128, 776, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 128, 776, 256],"float16"), ) 	 1017118720 	 1000 	 0.004314422607421875 	 0.0334782600402832 	 1.4066696166992188e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:26:50.322298 test begin: paddle.shape(Tensor([40, 1600, 29, 280],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 29, 280],"float32"), ) 	 519680000 	 1000 	 0.004385948181152344 	 0.03118586540222168 	 8.58306884765625e-06 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:26:58.567746 test begin: paddle.shape(Tensor([40, 1600, 376, 22],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 1600, 376, 22],"float32"), ) 	 529408000 	 1000 	 0.004344463348388672 	 0.03289151191711426 	 4.2438507080078125e-05 	 4.7206878662109375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:06.992822 test begin: paddle.shape(Tensor([40, 194, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 194, 256, 256],"float32"), ) 	 508559360 	 1000 	 0.004364967346191406 	 0.031136035919189453 	 4.4345855712890625e-05 	 3.838539123535156e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:15.141765 test begin: paddle.shape(Tensor([40, 388, 256, 256],"float16"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([40, 388, 256, 256],"float16"), ) 	 1017118720 	 1000 	 0.004361629486083984 	 0.03287672996520996 	 1.7404556274414062e-05 	 4.410743713378906e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:34.224118 test begin: paddle.shape(Tensor([70, 128, 256, 256],"float32"), )
[Prof] paddle.shape 	 paddle.shape(Tensor([70, 128, 256, 256],"float32"), ) 	 587202560 	 1000 	 0.006504535675048828 	 0.03189349174499512 	 4.38690185546875e-05 	 3.886222839355469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:43.488888 test begin: paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ) 	 25401602 	 1000 	 0.3090956211090088 	 2.045919895172119 	 0.3005077838897705 	 0.0006546974182128906 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:46.547506 test begin: paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([12700801, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, ) 	 25401602 	 1000 	 0.30904579162597656 	 2.0393972396850586 	 0.2985506057739258 	 0.0006663799285888672 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:49.549765 test begin: paddle.shard_index(input=Tensor([25401601, 1],"int64"), index_num=13, nshards=3, shard_id=0, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([25401601, 1],"int64"), index_num=13, nshards=3, shard_id=0, ) 	 25401601 	 1000 	 0.3095386028289795 	 2.233778476715088 	 0.30099940299987793 	 0.000762939453125 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:53.442122 test begin: paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ) 	 25401604 	 1000 	 0.30905747413635254 	 2.0567853450775146 	 0.300492525100708 	 0.0006551742553710938 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:27:59.147277 test begin: paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
[Prof] paddle.shard_index 	 paddle.shard_index(input=Tensor([4, 6350401, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, ) 	 25401604 	 1000 	 0.3090648651123047 	 2.0353477001190186 	 0.3004741668701172 	 0.0006651878356933594 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:28:02.149554 test begin: paddle.sign(Tensor([12404, 32, 128],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([12404, 32, 128],"float32"), ) 	 50806784 	 1000 	 0.3440885543823242 	 0.29773831367492676 	 0.33592724800109863 	 0.2870354652404785 	 0.2956726551055908 	 0.056474924087524414 	 0.24437284469604492 	 4.410743713378906e-05 	 
2025-07-30 20:28:04.775855 test begin: paddle.sign(Tensor([32, 12404, 128],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([32, 12404, 128],"float32"), ) 	 50806784 	 1000 	 0.3441479206085205 	 0.2977719306945801 	 0.3360178470611572 	 0.28713369369506836 	 0.2956268787384033 	 0.055854082107543945 	 0.244401216506958 	 4.363059997558594e-05 	 
2025-07-30 20:28:07.465895 test begin: paddle.sign(Tensor([32, 32, 49613],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([32, 32, 49613],"float32"), ) 	 50803712 	 1000 	 0.3451523780822754 	 0.297745943069458 	 0.33693408966064453 	 0.2870638370513916 	 0.2956092357635498 	 0.055968523025512695 	 0.24349427223205566 	 3.147125244140625e-05 	 
2025-07-30 20:28:10.111916 test begin: paddle.sign(Tensor([64, 1, 28, 28351],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1, 28, 28351],"float32"), ) 	 50804992 	 1000 	 0.345395565032959 	 0.29774045944213867 	 0.3372654914855957 	 0.28708553314208984 	 0.2957417964935303 	 0.058495521545410156 	 0.24245810508728027 	 4.9591064453125e-05 	 
2025-07-30 20:28:12.753670 test begin: paddle.sign(Tensor([64, 1, 28351, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1, 28351, 28],"float32"), ) 	 50804992 	 1000 	 0.34537649154663086 	 0.29970884323120117 	 0.3371543884277344 	 0.286968469619751 	 0.2957589626312256 	 0.0592954158782959 	 0.23992085456848145 	 5.698204040527344e-05 	 
2025-07-30 20:28:15.486801 test begin: paddle.sign(Tensor([64, 1013, 28, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64, 1013, 28, 28],"float32"), ) 	 50828288 	 1000 	 0.34392714500427246 	 0.2978377342224121 	 0.33569860458374023 	 0.28597474098205566 	 0.2958395481109619 	 0.056073665618896484 	 0.24297428131103516 	 2.6226043701171875e-05 	 
2025-07-30 20:28:18.107274 test begin: paddle.sign(Tensor([64801, 1, 28, 28],"float32"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([64801, 1, 28, 28],"float32"), ) 	 50803984 	 1000 	 0.344606876373291 	 0.29769349098205566 	 0.33652663230895996 	 0.2869844436645508 	 0.29561424255371094 	 0.05916762351989746 	 0.24406051635742188 	 4.315376281738281e-05 	 
2025-07-30 20:28:20.742960 test begin: paddle.sign(Tensor([66151, 1, 384],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([66151, 1, 384],"int64"), ) 	 25401984 	 1000 	 0.3080170154571533 	 0.2984273433685303 	 0.2946441173553467 	 0.2878391742706299 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:28:22.484729 test begin: paddle.sign(Tensor([7, 1, 3628801],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([7, 1, 3628801],"int64"), ) 	 25401607 	 1000 	 0.30759644508361816 	 0.29898548126220703 	 0.29946208000183105 	 0.28767919540405273 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:28:24.265972 test begin: paddle.sign(Tensor([7, 9451, 384],"int64"), )
[Prof] paddle.sign 	 paddle.sign(Tensor([7, 9451, 384],"int64"), ) 	 25404288 	 1000 	 0.3079819679260254 	 0.2983741760253906 	 0.29950857162475586 	 0.2872657775878906 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:28:26.039934 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([16, 3175201],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", ) 	 50803816 	 1000 	 19.418153524398804 	 4.760343790054321 	 2.4847872257232666 	 0.9755191802978516 	 43.31090235710144 	 33.87612986564636 	 2.9456987380981445 	 1.7281579971313477 	 
2025-07-30 20:30:15.722426 test begin: paddle.signal.stft(Tensor([16, 3175201],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([16, 3175201],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", ) 	 50804416 	 1000 	 19.772185802459717 	 4.980287313461304 	 2.5301027297973633 	 1.020512580871582 	 43.1211576461792 	 32.35552906990051 	 2.932762622833252 	 1.6506593227386475 	 
2025-07-30 20:32:02.000624 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([1993, 25500],"float32"), 1024, 120, 600, window=Tensor([600],"float32"), center=True, pad_mode="reflect", ) 	 50822100 	 1000 	 17.689101219177246 	 4.784940004348755 	 2.2634482383728027 	 0.9805092811584473 	 42.46058130264282 	 31.105921268463135 	 2.8880794048309326 	 1.5866484642028809 	 
2025-07-30 20:33:45.264521 test begin: paddle.signal.stft(Tensor([1993, 25500],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", )
[Prof] paddle.signal.stft 	 paddle.signal.stft(Tensor([1993, 25500],"float32"), 2048, 240, 1200, window=Tensor([1200],"float32"), center=True, pad_mode="reflect", ) 	 50822700 	 1000 	 18.137502670288086 	 5.060894966125488 	 2.320894241333008 	 1.036646842956543 	 42.80045771598816 	 31.485928773880005 	 2.9111669063568115 	 1.6061935424804688 	 
2025-07-30 20:35:28.523314 test begin: paddle.signbit(Tensor([11, 17, 271],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 17, 271],"int32"), ) 	 50677 	 1000 	 2.1949872970581055 	 0.01010894775390625 	 2.0742416381835938e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:30.772993 test begin: paddle.signbit(Tensor([11, 17, 543],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 17, 543],"int16"), ) 	 101541 	 1000 	 4.221031665802002 	 0.010173797607421875 	 3.457069396972656e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:35.046260 test begin: paddle.signbit(Tensor([11, 461, 10],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 461, 10],"int32"), ) 	 50710 	 1000 	 2.2437355518341064 	 0.01012277603149414 	 3.1948089599609375e-05 	 3.528594970703125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:37.589052 test begin: paddle.signbit(Tensor([11, 923, 10],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([11, 923, 10],"int16"), ) 	 101530 	 1000 	 4.1073997020721436 	 0.010161399841308594 	 3.4809112548828125e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:41.743392 test begin: paddle.signbit(Tensor([12, 20, 211],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([12, 20, 211],"float32"), ) 	 50640 	 1000 	 2.1833744049072266 	 0.010057926177978516 	 2.9802322387695312e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:45.444517 test begin: paddle.signbit(Tensor([12, 2116, 2],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([12, 2116, 2],"float32"), ) 	 50784 	 1000 	 2.1865620613098145 	 0.009980916976928711 	 2.1457672119140625e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:48.708957 test begin: paddle.signbit(Tensor([1270, 20, 2],"float32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([1270, 20, 2],"float32"), ) 	 50800 	 1000 	 2.236867666244507 	 0.010077476501464844 	 3.314018249511719e-05 	 2.3365020751953125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:50.988836 test begin: paddle.signbit(Tensor([298, 17, 10],"int32"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([298, 17, 10],"int32"), ) 	 50660 	 1000 	 2.1657662391662598 	 0.010210514068603516 	 3.409385681152344e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:53.196969 test begin: paddle.signbit(Tensor([597, 17, 10],"int16"), )
[Prof] paddle.signbit 	 paddle.signbit(Tensor([597, 17, 10],"int16"), ) 	 101490 	 1000 	 4.126865863800049 	 0.010148048400878906 	 3.1948089599609375e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:57.369767 test begin: paddle.sin(Tensor([128512, 396],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([128512, 396],"float32"), ) 	 50890752 	 1000 	 0.29616284370422363 	 0.29866933822631836 	 0.2873208522796631 	 0.2878153324127197 	 0.4505934715270996 	 0.7446260452270508 	 0.3976173400878906 	 0.38044095039367676 	 
2025-07-30 20:36:00.842408 test begin: paddle.sin(Tensor([254017, 200],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([254017, 200],"float32"), ) 	 50803400 	 1000 	 0.2954440116882324 	 0.2980649471282959 	 0.2865328788757324 	 0.28746891021728516 	 0.44971513748168945 	 0.7434358596801758 	 0.3955402374267578 	 0.3798561096191406 	 
2025-07-30 20:36:04.297147 test begin: paddle.sin(Tensor([50000, 1017],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([50000, 1017],"float32"), ) 	 50850000 	 1000 	 0.2958369255065918 	 0.29849910736083984 	 0.28706908226013184 	 0.2877516746520996 	 0.4502391815185547 	 0.7440288066864014 	 0.39701366424560547 	 0.3801438808441162 	 
2025-07-30 20:36:07.721886 test begin: paddle.sin(Tensor([508033, 100],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([508033, 100],"float32"), ) 	 50803300 	 1000 	 0.2954702377319336 	 0.2983086109161377 	 0.2867445945739746 	 0.28750181198120117 	 0.44976305961608887 	 0.7434811592102051 	 0.39680957794189453 	 0.37987256050109863 	 
2025-07-30 20:36:11.183884 test begin: paddle.sin(Tensor([68608, 741],"float32"), )
[Prof] paddle.sin 	 paddle.sin(Tensor([68608, 741],"float32"), ) 	 50838528 	 1000 	 0.29570817947387695 	 0.29838132858276367 	 0.2868807315826416 	 0.2877473831176758 	 0.450181245803833 	 0.7440283298492432 	 0.3971579074859619 	 0.38018178939819336 	 
2025-07-30 20:36:14.640878 test begin: paddle.sinc(Tensor([16, 1587601],"float64"), )
[Prof] paddle.sinc 	 paddle.sinc(Tensor([16, 1587601],"float64"), ) 	 25401616 	 1000 	 2.9504294395446777 	 0.3018465042114258 	 0.2514321804046631 	 0.29116392135620117 	 2.5944628715515137 	 3.7654502391815186 	 0.44167017936706543 	 0.32056641578674316 	 
2025-07-30 20:36:25.370640 test begin: paddle.sinc(Tensor([396901, 64],"float64"), )
[Prof] paddle.sinc 	 paddle.sinc(Tensor([396901, 64],"float64"), ) 	 25401664 	 1000 	 2.9495630264282227 	 0.30184030532836914 	 0.25134897232055664 	 0.2914144992828369 	 2.5941224098205566 	 3.7657413482666016 	 0.4416217803955078 	 0.32053709030151367 	 
2025-07-30 20:36:37.814916 test begin: paddle.sinh(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2953171730041504 	 0.3052394390106201 	 0.2865445613861084 	 0.2868659496307373 	 0.4496619701385498 	 0.743762731552124 	 0.39623093605041504 	 0.37997984886169434 	 
2025-07-30 20:36:41.789855 test begin: paddle.sinh(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29527926445007324 	 0.2982478141784668 	 0.2866504192352295 	 0.2874319553375244 	 0.4494948387145996 	 0.743783712387085 	 0.39666318893432617 	 0.3800320625305176 	 
2025-07-30 20:36:45.208507 test begin: paddle.sinh(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.sinh 	 paddle.sinh(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.295299768447876 	 0.29820966720581055 	 0.2865443229675293 	 0.2875213623046875 	 0.4494361877441406 	 0.7436611652374268 	 0.3957366943359375 	 0.3799154758453369 	 
2025-07-30 20:36:48.842270 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0730 20:37:06.546604 51623 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016099200 	 1000 	 0.007853031158447266 	 0.01302957534790039 	 2.8371810913085938e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:37:09.381859 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0730 20:37:24.667917 52072 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016099200 	 1000 	 0.0075795650482177734 	 0.013031482696533203 	 1.8596649169921875e-05 	 3.0279159545898438e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:37:27.219047 test begin: paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0730 20:37:42.639711 52114 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([653440, 1555],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016099200 	 1000 	 0.007524728775024414 	 0.012866497039794922 	 1.6450881958007812e-05 	 2.384185791015625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:37:45.139728 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], )
W0730 20:38:00.545440 52165 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[0,], ends=list[8168,], ) 	 1016076800 	 1000 	 0.007498264312744141 	 0.01312708854675293 	 3.314018249511719e-05 	 4.649162292480469e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:38:03.086730 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], )
W0730 20:38:18.523407 52209 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[16336,], ends=list[24504,], ) 	 1016076800 	 1000 	 0.0075778961181640625 	 0.012969493865966797 	 2.3126602172851562e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:38:21.066697 test begin: paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], )
W0730 20:38:36.347615 52258 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (InvalidArgument) The type of data we are trying to retrieve (bfloat16) does not match the type of data (float32) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():10 != phi::CppTypeToDataType<T>::Type():16.] (at ../paddle/phi/core/dense_tensor.cc:167)

[Prof] paddle.slice 	 paddle.slice(Tensor([793810, 1280],"bfloat16"), axes=list[0,], starts=list[24504,], ends=list[32672,], ) 	 1016076800 	 1000 	 0.007493495941162109 	 0.01287984848022461 	 1.4066696166992188e-05 	 3.0040740966796875e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:38:41.392977 test begin: paddle.slice_scatter(Tensor([8, 1058401, 3, 9],"float32"), Tensor([8, 1058401, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 1058401, 3, 9],"float32"), Tensor([8, 1058401, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 279417864 	 1000 	 1.4697165489196777 	 2.845261812210083 	 1.4543089866638184 	 0.9683792591094971 	 4.048348426818848 	 3.786642074584961 	 0.6892874240875244 	 0.7739064693450928 	 combined
2025-07-30 20:39:03.437805 test begin: paddle.slice_scatter(Tensor([8, 117601, 3, 9],"float64"), Tensor([8, 117601, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 117601, 3, 9],"float64"), Tensor([8, 117601, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 31046664 	 1000 	 0.23389434814453125 	 0.5527465343475342 	 0.21852993965148926 	 0.18743634223937988 	 0.8348491191864014 	 0.77419114112854 	 0.14215707778930664 	 0.1581897735595703 	 combined
2025-07-30 20:39:07.661140 test begin: paddle.slice_scatter(Tensor([8, 235201, 3, 9],"float32"), Tensor([8, 235201, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 235201, 3, 9],"float32"), Tensor([8, 235201, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 62093064 	 1000 	 0.32834315299987793 	 0.6412224769592285 	 0.3129909038543701 	 0.2183208465576172 	 0.9246366024017334 	 0.8651351928710938 	 0.15736007690429688 	 0.1768355369567871 	 combined
2025-07-30 20:39:12.225198 test begin: paddle.slice_scatter(Tensor([8, 529201, 3, 9],"float64"), Tensor([8, 529201, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 529201, 3, 9],"float64"), Tensor([8, 529201, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 139709064 	 1000 	 1.05804443359375 	 2.4535677433013916 	 1.0420958995819092 	 0.8351373672485352 	 3.6369388103485107 	 3.3912007808685303 	 0.6193356513977051 	 0.6929798126220703 	 combined
2025-07-30 20:39:28.156021 test begin: paddle.slice_scatter(Tensor([8, 6, 117601, 9],"float32"), Tensor([8, 6, 117601, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 117601, 9],"float32"), Tensor([8, 6, 117601, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 62093328 	 1000 	 0.32853221893310547 	 0.6413004398345947 	 0.31319260597229004 	 0.21831989288330078 	 0.934044361114502 	 0.8652913570404053 	 0.15903592109680176 	 0.17685747146606445 	 combined
2025-07-30 20:39:32.787580 test begin: paddle.slice_scatter(Tensor([8, 6, 211681, 5],"float32"), Tensor([8, 2, 211681, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 211681, 5],"float32"), Tensor([8, 2, 211681, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 67737920 	 1000 	 0.1833484172821045 	 0.42028260231018066 	 0.16811347007751465 	 0.14225482940673828 	 0.7737586498260498 	 0.5728912353515625 	 0.13177132606506348 	 0.11691498756408691 	 combined
2025-07-30 20:39:39.995057 test begin: paddle.slice_scatter(Tensor([8, 6, 264601, 9],"float64"), Tensor([8, 6, 264601, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 264601, 9],"float64"), Tensor([8, 6, 264601, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 139709328 	 1000 	 1.0579559803009033 	 2.4537980556488037 	 1.0424652099609375 	 0.8352563381195068 	 3.629251480102539 	 3.3912811279296875 	 0.6178724765777588 	 0.6929173469543457 	 combined
2025-07-30 20:39:55.977214 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 1058401],"float32"), Tensor([8, 2, 3, 1058401],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 1058401],"float32"), Tensor([8, 2, 3, 1058401],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 203212992 	 1000 	 0.5412347316741943 	 1.2301089763641357 	 0.5225670337677002 	 0.41846776008605957 	 2.287994861602783 	 1.6727750301361084 	 0.3896505832672119 	 0.34162020683288574 	 combined
2025-07-30 20:40:08.751512 test begin: paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 2, 3, 352801],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 3, 352801],"float32"), Tensor([8, 2, 3, 352801],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 67737792 	 1000 	 0.183335542678833 	 0.41997432708740234 	 0.1679532527923584 	 0.14223265647888184 	 0.7757489681243896 	 0.5723538398742676 	 0.13207769393920898 	 0.11688399314880371 	 combined
2025-07-30 20:40:12.700341 test begin: paddle.slice_scatter(Tensor([8, 6, 529201, 9],"float32"), Tensor([8, 6, 529201, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 529201, 9],"float32"), Tensor([8, 6, 529201, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 279418128 	 1000 	 1.4702060222625732 	 2.8444430828094482 	 1.4547228813171387 	 0.968458890914917 	 4.088500738143921 	 3.7867090702056885 	 0.6961288452148438 	 0.7740304470062256 	 combined
2025-07-30 20:40:33.328373 test begin: paddle.slice_scatter(Tensor([8, 6, 58801, 9],"float64"), Tensor([8, 6, 58801, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 58801, 9],"float64"), Tensor([8, 6, 58801, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 31046928 	 1000 	 0.23424887657165527 	 0.5604336261749268 	 0.21869468688964844 	 0.18737077713012695 	 0.8321664333343506 	 0.7741732597351074 	 0.14166808128356934 	 0.15819215774536133 	 combined
2025-07-30 20:40:39.737103 test begin: paddle.slice_scatter(Tensor([8, 6, 635041, 5],"float32"), Tensor([8, 2, 635041, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([8, 6, 635041, 5],"float32"), Tensor([8, 2, 635041, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 203213120 	 1000 	 0.5411381721496582 	 1.2301084995269775 	 0.5252130031585693 	 0.4184434413909912 	 2.2840964794158936 	 1.6728084087371826 	 0.38895535469055176 	 0.34164929389953613 	 combined
2025-07-30 20:40:51.249533 test begin: paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 423361, 3, 5],"float32"), Tensor([80, 2, 3, 5],"float32"), axes=list[1,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508035600 	 1000 	 0.015402555465698242 	 3.066068649291992 	 1.1444091796875e-05 	 1.0423400402069092 	 3.1018264293670654 	 3.069267511367798 	 0.5272936820983887 	 0.6260836124420166 	 combined
2025-07-30 20:41:17.714315 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 176401],"float64"), Tensor([80, 6, 3, 2],"float64"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 254020320 	 1000 	 0.015362739562988281 	 3.066418409347534 	 1.0728836059570312e-05 	 1.0424087047576904 	 3.0955026149749756 	 3.0697758197784424 	 0.5261902809143066 	 0.6262412071228027 	 combined
2025-07-30 20:41:37.632954 test begin: paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], )
[Prof] paddle.slice_scatter 	 paddle.slice_scatter(Tensor([80, 6, 3, 352801],"float32"), Tensor([80, 6, 3, 2],"float32"), axes=list[3,], starts=list[2,], ends=list[6,], strides=list[2,], ) 	 508036320 	 1000 	 0.015491962432861328 	 3.0662360191345215 	 1.049041748046875e-05 	 1.0423908233642578 	 3.0845563411712646 	 3.069437265396118 	 0.524329423904419 	 0.626152515411377 	 combined
2025-07-30 20:42:03.099786 test begin: paddle.sqrt(Tensor([128, 396901],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.29445648193359375 	 0.2989389896392822 	 0.28425049781799316 	 0.2881186008453369 	 0.4503481388092041 	 0.7471578121185303 	 0.38996362686157227 	 0.38172245025634766 	 
2025-07-30 20:42:06.598176 test begin: paddle.sqrt(Tensor([18, 15, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([18, 15, 3, 256, 256],"float32"), ) 	 53084160 	 1000 	 0.3074347972869873 	 0.3120155334472656 	 0.2977790832519531 	 0.30054473876953125 	 0.4701721668243408 	 0.7801141738891602 	 0.41559386253356934 	 0.3985762596130371 	 
2025-07-30 20:42:10.223354 test begin: paddle.sqrt(Tensor([259, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([259, 3, 256, 256],"float32"), ) 	 50921472 	 1000 	 0.2952275276184082 	 0.29956626892089844 	 0.28635525703430176 	 0.2883336544036865 	 0.4513840675354004 	 0.7489204406738281 	 0.39690494537353516 	 0.3825864791870117 	 
2025-07-30 20:42:13.690044 test begin: paddle.sqrt(Tensor([4, 15, 13, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 13, 256, 256],"float32"), ) 	 51118080 	 1000 	 0.296245813369751 	 0.30071544647216797 	 0.2874276638031006 	 0.28971004486083984 	 0.45279765129089355 	 0.7516739368438721 	 0.39910149574279785 	 0.38407039642333984 	 
2025-07-30 20:42:17.218985 test begin: paddle.sqrt(Tensor([4, 15, 3, 1103, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 3, 1103, 256],"float32"), ) 	 50826240 	 1000 	 0.2947118282318115 	 0.30745840072631836 	 0.28571081161499023 	 0.28812646865844727 	 0.4506044387817383 	 0.7474291324615479 	 0.3970775604248047 	 0.3818855285644531 	 
2025-07-30 20:42:23.408297 test begin: paddle.sqrt(Tensor([4, 15, 3, 256, 1103],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 15, 3, 256, 1103],"float32"), ) 	 50826240 	 1000 	 0.29471588134765625 	 0.30371809005737305 	 0.2858555316925049 	 0.288013219833374 	 0.4505000114440918 	 0.7473931312561035 	 0.3965778350830078 	 0.3818471431732178 	 
2025-07-30 20:42:26.989390 test begin: paddle.sqrt(Tensor([4, 65, 3, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([4, 65, 3, 256, 256],"float32"), ) 	 51118080 	 1000 	 0.2961902618408203 	 0.3007535934448242 	 0.287259578704834 	 0.2898695468902588 	 0.4528372287750244 	 0.7516698837280273 	 0.3984494209289551 	 0.38403940200805664 	 
2025-07-30 20:42:30.452211 test begin: paddle.sqrt(Tensor([544, 93431],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([544, 93431],"float32"), ) 	 50826464 	 1000 	 0.2946317195892334 	 0.30434465408325195 	 0.2856483459472656 	 0.2883141040802002 	 0.45057106018066406 	 0.7474370002746582 	 0.3820376396179199 	 0.3818666934967041 	 
2025-07-30 20:42:33.979561 test begin: paddle.sqrt(Tensor([64, 13, 256, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 13, 256, 256],"float32"), ) 	 54525952 	 1000 	 0.3156764507293701 	 0.3303709030151367 	 0.3067162036895752 	 0.30905652046203613 	 0.48296236991882324 	 0.8008980751037598 	 0.4292440414428711 	 0.4091470241546631 	 
2025-07-30 20:42:39.965470 test begin: paddle.sqrt(Tensor([64, 3, 1034, 256],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 3, 1034, 256],"float32"), ) 	 50823168 	 1000 	 0.29460692405700684 	 0.2990238666534424 	 0.2855958938598633 	 0.28765106201171875 	 0.45046353340148926 	 0.7474958896636963 	 0.3967578411102295 	 0.3819551467895508 	 
2025-07-30 20:42:43.404972 test begin: paddle.sqrt(Tensor([64, 3, 256, 1034],"float32"), )
[Prof] paddle.sqrt 	 paddle.sqrt(Tensor([64, 3, 256, 1034],"float32"), ) 	 50823168 	 1000 	 0.2946467399597168 	 0.2990694046020508 	 0.2858238220214844 	 0.28820228576660156 	 0.45057010650634766 	 0.7473859786987305 	 0.3953237533569336 	 0.3818399906158447 	 
2025-07-30 20:42:46.879363 test begin: paddle.square(Tensor([104, 488493],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([104, 488493],"float32"), ) 	 50803272 	 1000 	 0.29574155807495117 	 0.2978651523590088 	 0.28701210021972656 	 0.2861146926879883 	 0.44951581954956055 	 1.0552241802215576 	 0.3965623378753662 	 0.2698204517364502 	 
2025-07-30 20:42:50.614980 test begin: paddle.square(Tensor([128, 396901],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([128, 396901],"float32"), ) 	 50803328 	 1000 	 0.29571056365966797 	 0.29988765716552734 	 0.28705263137817383 	 0.2857096195220947 	 0.4494485855102539 	 1.0553240776062012 	 0.3968844413757324 	 0.26979589462280273 	 
2025-07-30 20:42:54.361344 test begin: paddle.square(Tensor([24904, 12, 170, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([24904, 12, 170, 1],"float32"), ) 	 50804160 	 1000 	 0.2956709861755371 	 0.29787325859069824 	 0.2868175506591797 	 0.2860524654388428 	 0.4494454860687256 	 1.0553669929504395 	 0.3957996368408203 	 0.2698538303375244 	 
2025-07-30 20:42:58.134076 test begin: paddle.square(Tensor([3548, 12, 1194, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 12, 1194, 1],"float32"), ) 	 50835744 	 1000 	 0.29575109481811523 	 0.2980363368988037 	 0.28703808784484863 	 0.28592562675476074 	 0.4497346878051758 	 1.0558125972747803 	 0.39566516876220703 	 0.2699425220489502 	 
2025-07-30 20:43:01.894039 test begin: paddle.square(Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 12, 170, 8],"float32"), ) 	 57903360 	 1000 	 0.3363919258117676 	 0.33863306045532227 	 0.32771849632263184 	 0.3264474868774414 	 0.511737585067749 	 1.2006428241729736 	 0.4589698314666748 	 0.30701518058776855 	 
2025-07-30 20:43:06.180758 test begin: paddle.square(Tensor([3548, 85, 170, 1],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([3548, 85, 170, 1],"float32"), ) 	 51268600 	 1000 	 0.29831552505493164 	 0.3005027770996094 	 0.28958559036254883 	 0.28873658180236816 	 0.4536862373352051 	 1.0648159980773926 	 0.40038084983825684 	 0.2722940444946289 	 
2025-07-30 20:43:09.964663 test begin: paddle.square(Tensor([544, 93431],"float32"), )
[Prof] paddle.square 	 paddle.square(Tensor([544, 93431],"float32"), ) 	 50826464 	 1000 	 0.2958836555480957 	 0.29795002937316895 	 0.28715085983276367 	 0.2862863540649414 	 0.44974207878112793 	 1.0554146766662598 	 0.3971066474914551 	 0.2698099613189697 	 
2025-07-30 20:43:13.744653 test begin: paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([100, 512, 1, 100, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.004670858383178711 	 0.007853269577026367 	 2.0265579223632812e-05 	 6.103515625e-05 	 0.04166126251220703 	 0.05890154838562012 	 7.486343383789062e-05 	 6.604194641113281e-05 	 
2025-07-30 20:43:30.305744 test begin: paddle.squeeze(Tensor([1053440, 483],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([1053440, 483],"float32"), ) 	 508811520 	 1000 	 0.003904581069946289 	 0.0036520957946777344 	 1.1920928955078125e-05 	 1.9550323486328125e-05 	 0.04145669937133789 	 0.0567781925201416 	 1.9788742065429688e-05 	 4.172325134277344e-05 	 
2025-07-30 20:43:46.535738 test begin: paddle.squeeze(Tensor([3969010, 128],"float32"), )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([3969010, 128],"float32"), ) 	 508033280 	 1000 	 0.0038535594940185547 	 0.0043981075286865234 	 7.867813110351562e-06 	 5.054473876953125e-05 	 0.04120039939880371 	 0.05214953422546387 	 3.123283386230469e-05 	 5.269050598144531e-05 	 
2025-07-30 20:44:03.336810 test begin: paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 25, 5],"float32"), axis=-1, ) 	 526400000 	 1000 	 0.004520416259765625 	 0.003961801528930664 	 1.0013580322265625e-05 	 1.71661376953125e-05 	 0.04138040542602539 	 0.05273270606994629 	 2.7418136596679688e-05 	 4.696846008300781e-05 	 
2025-07-30 20:44:20.378667 test begin: paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([4211200, 31, 4],"float32"), axis=-1, ) 	 522188800 	 1000 	 0.004984617233276367 	 0.0039789676666259766 	 3.0517578125e-05 	 2.2172927856445312e-05 	 0.043096303939819336 	 0.05432915687561035 	 3.0517578125e-05 	 6.437301635742188e-05 	 
2025-07-30 20:44:39.505823 test begin: paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([5080330, 25, 4],"float32"), axis=-1, ) 	 508033000 	 1000 	 0.004553079605102539 	 0.004822254180908203 	 9.298324584960938e-06 	 4.76837158203125e-05 	 0.04594564437866211 	 0.05259585380554199 	 8.487701416015625e-05 	 5.507469177246094e-05 	 
2025-07-30 20:44:56.045626 test begin: paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 100, 125],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.0055370330810546875 	 0.004970550537109375 	 2.86102294921875e-05 	 1.8835067749023438e-05 	 0.04314064979553223 	 0.056723833084106445 	 3.0040740966796875e-05 	 4.696846008300781e-05 	 
2025-07-30 20:45:12.788025 test begin: paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 1, 125, 100],"float32"), axis=list[2,], ) 	 512000000 	 1000 	 0.0046117305755615234 	 0.004951953887939453 	 8.58306884765625e-06 	 1.811981201171875e-05 	 0.044234514236450195 	 0.056975364685058594 	 7.009506225585938e-05 	 4.363059997558594e-05 	 
2025-07-30 20:45:29.661884 test begin: paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 512, 2, 100, 100],"float32"), axis=list[2,], ) 	 819200000 	 1000 	 0.004666566848754883 	 0.004988908767700195 	 7.152557373046875e-06 	 1.9311904907226562e-05 	 0.04138755798339844 	 0.05379891395568848 	 2.574920654296875e-05 	 3.9577484130859375e-05 	 
2025-07-30 20:45:55.691689 test begin: paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], )
[Prof] paddle.squeeze 	 paddle.squeeze(Tensor([80, 636, 1, 100, 100],"float32"), axis=list[2,], ) 	 508800000 	 1000 	 0.004595518112182617 	 0.0048980712890625 	 7.867813110351562e-06 	 1.9073486328125e-05 	 0.041570425033569336 	 0.05728888511657715 	 2.8133392333984375e-05 	 4.2438507080078125e-05 	 
2025-07-30 20:46:12.307034 test begin: paddle.stack(list[Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),Tensor([11, 32, 36828, 4],"float32"),], axis=-2, ) 	 259269120 	 1000 	 1.8524174690246582 	 7.123633146286011 	 1.8403894901275635 	 7.106452941894531 	 2.0438427925109863 	 0.09356975555419922 	 1.9676446914672852 	 4.8160552978515625e-05 	 
2025-07-30 20:46:32.034482 test begin: paddle.stack(list[Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),Tensor([11, 32, 38367, 4],"float32"),], axis=-2, ) 	 270103680 	 1000 	 1.9341328144073486 	 7.421662330627441 	 1.9224581718444824 	 7.404022455215454 	 2.1257002353668213 	 0.09079861640930176 	 2.0493009090423584 	 3.314018249511719e-05 	 
2025-07-30 20:46:52.664164 test begin: paddle.stack(list[Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),], axis=0, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),Tensor([14176, 7168],"bfloat16"),], axis=0, ) 	 609681408 	 1000 	 2.9492363929748535 	 2.581915855407715 	 2.9370765686035156 	 2.5650289058685303 	 4.611480712890625 	 2.7026851177215576 	 4.50677227973938 	 1.3809285163879395 	 
2025-07-30 20:47:25.435201 test begin: paddle.stack(list[Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),], axis=0, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),Tensor([7168, 14176],"bfloat16"),], axis=0, ) 	 609681408 	 1000 	 2.9492504596710205 	 2.58709716796875 	 2.9370481967926025 	 2.562584638595581 	 4.611423492431641 	 2.702721118927002 	 4.507760763168335 	 1.3809356689453125 	 
2025-07-30 20:48:01.186422 test begin: paddle.stack(list[Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),Tensor([8, 32, 36828, 6],"float32"),], axis=-2, ) 	 282839040 	 1000 	 2.03124737739563 	 8.135861873626709 	 2.0194125175476074 	 8.118214130401611 	 2.2319014072418213 	 0.0918889045715332 	 2.1564180850982666 	 4.553794860839844e-05 	 
2025-07-30 20:48:22.989564 test begin: paddle.stack(list[Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),Tensor([8, 32, 38367, 6],"float32"),], axis=-2, ) 	 294658560 	 1000 	 2.118410110473633 	 8.799676179885864 	 2.106853723526001 	 8.552864074707031 	 2.3563170433044434 	 0.09518790245056152 	 2.280827522277832 	 6.031990051269531e-05 	 
2025-07-30 20:48:49.034861 test begin: paddle.stack(list[Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),Tensor([8, 32, 49613, 4],"float32"),], axis=-2, ) 	 254018560 	 1000 	 1.8057286739349365 	 6.9778501987457275 	 1.7941415309906006 	 6.958370208740234 	 2.0004172325134277 	 0.09435367584228516 	 1.923762559890747 	 4.38690185546875e-05 	 
2025-07-30 20:49:08.302264 test begin: paddle.stack(list[Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),Tensor([8, 42, 38367, 4],"float32"),], axis=-2, ) 	 257826240 	 1000 	 1.8408658504486084 	 7.082937717437744 	 1.8290669918060303 	 7.0649003982543945 	 2.0338425636291504 	 0.09416079521179199 	 1.9557924270629883 	 6.580352783203125e-05 	 
2025-07-30 20:49:27.839859 test begin: paddle.stack(list[Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),], axis=-2, )
[Prof] paddle.stack 	 paddle.stack(list[Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),Tensor([8, 44, 36828, 4],"float32"),], axis=-2, ) 	 259269120 	 1000 	 1.8520734310150146 	 7.129154682159424 	 1.8404247760772705 	 7.104971408843994 	 2.043517589569092 	 0.1051018238067627 	 1.9666271209716797 	 4.506111145019531e-05 	 
2025-07-30 20:49:47.554378 test begin: paddle.stanh(x=Tensor([12700801, 2],"float64"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([12700801, 2],"float64"), scale_a=6.42, scale_b=3.58, ) 	 25401602 	 1000 	 0.30582356452941895 	 0.3068726062774658 	 0.29662346839904785 	 0.29604649543762207 	 0.44527149200439453 	 0.7410995960235596 	 0.3924093246459961 	 0.37865591049194336 	 
2025-07-30 20:49:50.472114 test begin: paddle.stanh(x=Tensor([2, 12700801],"float64"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 12700801],"float64"), scale_a=6.42, scale_b=3.58, ) 	 25401602 	 1000 	 0.30583834648132324 	 0.3068993091583252 	 0.2968025207519531 	 0.2962455749511719 	 0.44526124000549316 	 0.74111008644104 	 0.39241623878479004 	 0.37865447998046875 	 
2025-07-30 20:49:53.305476 test begin: paddle.stanh(x=Tensor([2, 25401601],"float32"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 25401601],"float32"), scale_a=6.42, scale_b=3.58, ) 	 50803202 	 1000 	 0.2946608066558838 	 0.29888415336608887 	 0.28532958030700684 	 0.2881748676300049 	 0.44997477531433105 	 0.7428534030914307 	 0.3950791358947754 	 0.37955617904663086 	 
2025-07-30 20:49:56.722614 test begin: paddle.stanh(x=Tensor([2, 3, 2, 2116801],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3, 2, 2116801],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.29955267906188965 	 0.300365686416626 	 0.2902259826660156 	 0.2895500659942627 	 0.4471435546875 	 0.7411420345306396 	 0.39469361305236816 	 0.37866854667663574 	 
2025-07-30 20:49:59.556209 test begin: paddle.stanh(x=Tensor([2, 3, 2116801, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3, 2116801, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.29955506324768066 	 0.3051464557647705 	 0.2903618812561035 	 0.28955912590026855 	 0.4471759796142578 	 0.741204023361206 	 0.393810510635376 	 0.37874341011047363 	 
2025-07-30 20:50:04.675272 test begin: paddle.stanh(x=Tensor([2, 3175201, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2, 3175201, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401608 	 1000 	 0.2995617389678955 	 0.30037975311279297 	 0.29029011726379395 	 0.2895972728729248 	 0.44702863693237305 	 0.7411918640136719 	 0.39351749420166016 	 0.3786580562591553 	 
2025-07-30 20:50:07.566530 test begin: paddle.stanh(x=Tensor([2116801, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([2116801, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, ) 	 25401612 	 1000 	 0.2995157241821289 	 0.3004631996154785 	 0.2902348041534424 	 0.28977012634277344 	 0.44704151153564453 	 0.741112470626831 	 0.39443206787109375 	 0.3786342144012451 	 
2025-07-30 20:50:10.398713 test begin: paddle.stanh(x=Tensor([25401601, 2],"float32"), scale_a=6.42, scale_b=3.58, )
[Prof] paddle.stanh 	 paddle.stanh(x=Tensor([25401601, 2],"float32"), scale_a=6.42, scale_b=3.58, ) 	 50803202 	 1000 	 0.2947998046875 	 0.30106306076049805 	 0.28446483612060547 	 0.28798556327819824 	 0.44987058639526367 	 0.7428081035614014 	 0.39656901359558105 	 0.3795144557952881 	 
2025-07-30 20:50:13.838058 test begin: paddle.std(Tensor([1, 1270081, 4, 10],"float32"), list[1,3,], True, False, )
W0730 20:50:14.590765 56836 dygraph_functions.cc:88394] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.std 	 paddle.std(Tensor([1, 1270081, 4, 10],"float32"), list[1,3,], True, False, ) 	 50803240 	 1000 	 1.2573344707489014 	 0.2311103343963623 	 3.337860107421875e-05 	 0.11814761161804199 	 1.4230473041534424 	 0.8019444942474365 	 0.18209528923034668 	 0.0914008617401123 	 
2025-07-30 20:50:18.431333 test begin: paddle.std(Tensor([1, 3, 1693441, 10],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 1693441, 10],"float32"), list[1,3,], True, False, ) 	 50803230 	 1000 	 1.5253145694732666 	 0.7937123775482178 	 1.9788742065429688e-05 	 0.7735037803649902 	 1.6478736400604248 	 1.0741145610809326 	 0.24059724807739258 	 0.13743090629577637 	 
2025-07-30 20:50:24.318300 test begin: paddle.std(Tensor([1, 3, 4, 2116801],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 4, 2116801],"float64"), 2, True, False, ) 	 25401612 	 1000 	 1.6424400806427002 	 0.21892571449279785 	 0.0001201629638671875 	 0.20105981826782227 	 2.022592544555664 	 1.486316442489624 	 0.29526829719543457 	 0.19005227088928223 	 
2025-07-30 20:50:30.418655 test begin: paddle.std(Tensor([1, 3, 4, 4233601],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 4, 4233601],"float32"), list[1,3,], True, False, ) 	 50803212 	 1000 	 1.208817481994629 	 0.23458051681518555 	 1.9550323486328125e-05 	 0.11985659599304199 	 1.403012752532959 	 0.7970256805419922 	 0.1795487403869629 	 0.09082770347595215 	 
2025-07-30 20:50:34.895615 test begin: paddle.std(Tensor([1, 3, 846721, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 3, 846721, 10],"float64"), 2, True, False, ) 	 25401630 	 1000 	 7.963856935501099 	 0.18533992767333984 	 3.981590270996094e-05 	 0.09467792510986328 	 4.809017181396484 	 0.7789463996887207 	 0.6154849529266357 	 0.08872413635253906 	 
2025-07-30 20:50:49.220126 test begin: paddle.std(Tensor([1, 635041, 4, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([1, 635041, 4, 10],"float64"), 2, True, False, ) 	 25401640 	 1000 	 1.754255771636963 	 0.1984875202178955 	 0.00012183189392089844 	 0.18075132369995117 	 1.9415700435638428 	 1.2670106887817383 	 0.2834320068359375 	 0.16195225715637207 	 
2025-07-30 20:50:55.092369 test begin: paddle.std(Tensor([1587601, 32],"float32"), )
[Prof] paddle.std 	 paddle.std(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 1.100104808807373 	 0.16627287864685059 	 2.86102294921875e-05 	 0.08481144905090332 	 1.3394520282745361 	 0.7757096290588379 	 0.1713871955871582 	 0.08835148811340332 	 
2025-07-30 20:50:59.351737 test begin: paddle.std(Tensor([211681, 3, 4, 10],"float64"), 2, True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([211681, 3, 4, 10],"float64"), 2, True, False, ) 	 25401720 	 1000 	 1.7586452960968018 	 0.19855260848999023 	 0.00012135505676269531 	 0.18073749542236328 	 1.9377107620239258 	 1.2670793533325195 	 0.28287816047668457 	 0.16193842887878418 	 
2025-07-30 20:51:07.558215 test begin: paddle.std(Tensor([32, 1587601],"float32"), )
[Prof] paddle.std 	 paddle.std(Tensor([32, 1587601],"float32"), ) 	 50803232 	 1000 	 1.0907626152038574 	 0.16617536544799805 	 2.5272369384765625e-05 	 0.08488345146179199 	 1.3403401374816895 	 0.7759039402008057 	 0.1713404655456543 	 0.08834981918334961 	 
2025-07-30 20:51:13.998623 test begin: paddle.std(Tensor([423361, 3, 4, 10],"float32"), list[1,3,], True, False, )
[Prof] paddle.std 	 paddle.std(Tensor([423361, 3, 4, 10],"float32"), list[1,3,], True, False, ) 	 50803320 	 1000 	 1.5146396160125732 	 0.8257131576538086 	 2.5987625122070312e-05 	 0.8077723979949951 	 1.6344997882843018 	 1.1020443439483643 	 0.23861145973205566 	 0.14101052284240723 	 
2025-07-30 20:51:19.921443 test begin: paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
[Prof] paddle.strided_slice 	 paddle.strided_slice(x=Tensor([301, 4, 3528, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], ) 	 25486272 	 1000 	 0.005765199661254883 	 0.2102503776550293 	 8.106231689453125e-06 	 7.987022399902344e-05 	 0.1550273895263672 	 0.24918103218078613 	 0.07913875579833984 	 0.009286642074584961 	 combined
2025-07-30 20:51:21.124464 test begin: paddle.subtract(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([24904, 12, 170, 1],"float32"), Tensor([24904, 12, 170, 1],"float32"), ) 	 101608320 	 1000 	 0.44977736473083496 	 0.4466361999511719 	 0.440157413482666 	 0.4351780414581299 	 0.4732029438018799 	 0.29767560958862305 	 0.4156167507171631 	 0.22402286529541016 	 
2025-07-30 20:51:25.213550 test begin: paddle.subtract(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 1194, 1],"float32"), Tensor([3548, 12, 1194, 1],"float32"), ) 	 101671488 	 1000 	 0.44991254806518555 	 0.4469149112701416 	 0.4402759075164795 	 0.43554019927978516 	 0.47414422035217285 	 0.29786086082458496 	 0.4165990352630615 	 0.2242875099182129 	 
2025-07-30 20:51:29.361455 test begin: paddle.subtract(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 1],"float32"), Tensor([3548, 12, 170, 8],"float32"), ) 	 65141280 	 1000 	 0.3570363521575928 	 0.3698000907897949 	 0.34649229049682617 	 0.35733699798583984 	 0.8868155479431152 	 0.8981943130493164 	 0.4531064033508301 	 0.4589247703552246 	 
2025-07-30 20:51:33.847633 test begin: paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 1],"float32"), ) 	 65141280 	 1000 	 0.35692811012268066 	 1.3305363655090332 	 0.3464210033416748 	 0.3569300174713135 	 0.8152570724487305 	 0.8983731269836426 	 0.2776329517364502 	 0.45899319648742676 	 
2025-07-30 20:51:41.270865 test begin: paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 12, 170, 8],"float32"), Tensor([3548, 12, 170, 8],"float32"), ) 	 115806720 	 1000 	 0.5119607448577881 	 0.5085034370422363 	 0.5023705959320068 	 0.49667906761169434 	 0.5390782356262207 	 0.33852219581604004 	 0.4792618751525879 	 0.2651634216308594 	 
2025-07-30 20:51:45.904877 test begin: paddle.subtract(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([3548, 85, 170, 1],"float32"), Tensor([3548, 85, 170, 1],"float32"), ) 	 102537200 	 1000 	 0.45381832122802734 	 0.4507744312286377 	 0.444049596786499 	 0.4393932819366455 	 0.47664499282836914 	 0.30050182342529297 	 0.418865442276001 	 0.2272491455078125 	 
2025-07-30 20:51:50.012634 test begin: paddle.subtract(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([517, 4, 3, 64, 128],"float32"), Tensor([517, 4, 3, 64, 128],"float32"), ) 	 101646336 	 1000 	 0.4500555992126465 	 0.4467611312866211 	 0.44037461280822754 	 0.43540167808532715 	 0.4734468460083008 	 0.29778575897216797 	 0.41565918922424316 	 0.2237868309020996 	 
2025-07-30 20:51:54.143662 test begin: paddle.subtract(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 3, 64, 1379],"float32"), Tensor([64, 3, 3, 64, 1379],"float32"), ) 	 101670912 	 1000 	 0.45003318786621094 	 0.4469447135925293 	 0.44034647941589355 	 0.43558526039123535 	 0.47373199462890625 	 0.2978549003601074 	 0.41392946243286133 	 0.22484588623046875 	 
2025-07-30 20:51:58.241611 test begin: paddle.subtract(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 3, 690, 128],"float32"), Tensor([64, 3, 3, 690, 128],"float32"), ) 	 101744640 	 1000 	 0.4503054618835449 	 0.4472649097442627 	 0.44068264961242676 	 0.4354441165924072 	 0.47371768951416016 	 0.2981071472167969 	 0.4150686264038086 	 0.2231433391571045 	 
2025-07-30 20:52:02.345516 test begin: paddle.subtract(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 3, 33, 64, 128],"float32"), Tensor([64, 3, 33, 64, 128],"float32"), ) 	 103809024 	 1000 	 0.4594864845275879 	 0.45624685287475586 	 0.4499225616455078 	 0.44484782218933105 	 0.4850649833679199 	 0.3040730953216553 	 0.427248477935791 	 0.23154830932617188 	 
2025-07-30 20:52:06.495266 test begin: paddle.subtract(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 33, 3, 64, 128],"float32"), Tensor([64, 33, 3, 64, 128],"float32"), ) 	 103809024 	 1000 	 0.45944905281066895 	 0.4562089443206787 	 0.44977545738220215 	 0.44475746154785156 	 0.485032320022583 	 0.3040900230407715 	 0.4261496067047119 	 0.2304670810699463 	 
2025-07-30 20:52:10.693947 test begin: paddle.subtract(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 25, 64, 128],"float32"), Tensor([64, 4, 25, 64, 128],"float32"), ) 	 104857600 	 1000 	 0.4640219211578369 	 0.46428346633911133 	 0.4541442394256592 	 0.4490492343902588 	 0.48740720748901367 	 0.3071937561035156 	 0.42957353591918945 	 0.22979164123535156 	 
2025-07-30 20:52:17.002177 test begin: paddle.subtract(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 3, 517, 128],"float32"), Tensor([64, 4, 3, 517, 128],"float32"), ) 	 101646336 	 1000 	 0.44999170303344727 	 0.4468352794647217 	 0.44033265113830566 	 0.4353160858154297 	 0.47357606887817383 	 0.29780006408691406 	 0.41509294509887695 	 0.22491788864135742 	 
2025-07-30 20:52:21.772001 test begin: paddle.subtract(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([64, 4, 3, 64, 1034],"float32"), Tensor([64, 4, 3, 64, 1034],"float32"), ) 	 101646336 	 1000 	 0.44995951652526855 	 0.44672489166259766 	 0.4401051998138428 	 0.434112548828125 	 0.47350597381591797 	 0.29778432846069336 	 0.41548657417297363 	 0.2230548858642578 	 
2025-07-30 20:52:25.939724 test begin: paddle.subtract(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), )
[Prof] paddle.subtract 	 paddle.subtract(Tensor([690, 3, 3, 64, 128],"float32"), Tensor([690, 3, 3, 64, 128],"float32"), ) 	 101744640 	 1000 	 0.45034027099609375 	 0.4472978115081787 	 0.44065332412719727 	 0.4353969097137451 	 0.4753258228302002 	 0.29810333251953125 	 0.4172227382659912 	 0.22066044807434082 	 
2025-07-30 20:52:30.144531 test begin: paddle.sum(Tensor([3544, 32, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([3544, 32, 896],"bfloat16"), axis=1, keepdim=False, ) 	 101613568 	 1000 	 0.1705625057220459 	 0.15978455543518066 	 0.15800261497497559 	 0.14240765571594238 	 0.2683539390563965 	 0.0835716724395752 	 0.18633055686950684 	 6.246566772460938e-05 	 
2025-07-30 20:52:32.488869 test begin: paddle.sum(Tensor([6017, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6017, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 102433408 	 1000 	 0.17451763153076172 	 0.17509222030639648 	 0.1629345417022705 	 0.15938258171081543 	 0.2711670398712158 	 0.08224749565124512 	 0.20671558380126953 	 6.0558319091796875e-05 	 
2025-07-30 20:52:34.956566 test begin: paddle.sum(Tensor([6017, 32, 528],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6017, 32, 528],"bfloat16"), axis=1, keepdim=False, ) 	 101663232 	 1000 	 0.1829700469970703 	 0.16360831260681152 	 0.17132186889648438 	 0.14683294296264648 	 0.26868724822998047 	 0.08344340324401855 	 0.20867419242858887 	 5.078315734863281e-05 	 
2025-07-30 20:52:39.294006 test begin: paddle.sum(Tensor([6036, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6036, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 102756864 	 1000 	 0.17504429817199707 	 0.17552495002746582 	 0.16338133811950684 	 0.16057205200195312 	 0.27185726165771484 	 0.08229899406433105 	 0.2095487117767334 	 4.6253204345703125e-05 	 
2025-07-30 20:52:41.765748 test begin: paddle.sum(Tensor([6036, 32, 527],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6036, 32, 527],"bfloat16"), axis=1, keepdim=False, ) 	 101791104 	 1000 	 0.1856081485748291 	 0.18024468421936035 	 0.17394232749938965 	 0.16486215591430664 	 0.2690598964691162 	 0.08489346504211426 	 0.2089986801147461 	 6.127357482910156e-05 	 
2025-07-30 20:52:44.213854 test begin: paddle.sum(Tensor([6078, 19, 896],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6078, 19, 896],"bfloat16"), axis=1, keepdim=False, ) 	 103471872 	 1000 	 0.17618942260742188 	 0.1767566204071045 	 0.16448211669921875 	 0.16191482543945312 	 0.273510217666626 	 0.08281373977661133 	 0.21332001686096191 	 6.127357482910156e-05 	 
2025-07-30 20:52:46.657120 test begin: paddle.sum(Tensor([6078, 32, 523],"bfloat16"), axis=1, keepdim=False, )
[Prof] paddle.sum 	 paddle.sum(Tensor([6078, 32, 523],"bfloat16"), axis=1, keepdim=False, ) 	 101721408 	 1000 	 0.18148136138916016 	 0.17833542823791504 	 0.1698930263519287 	 0.16210365295410156 	 0.26886868476867676 	 0.08342742919921875 	 0.2064225673675537 	 6.341934204101562e-05 	 
2025-07-30 20:52:49.093851 test begin: paddle.t(Tensor([100, 5080321],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([100, 5080321],"float32"), ) 	 508032100 	 1000 	 0.005097627639770508 	 0.003682374954223633 	 2.0742416381835938e-05 	 2.8133392333984375e-05 	 0.03947567939758301 	 0.05702710151672363 	 4.601478576660156e-05 	 4.553794860839844e-05 	 
2025-07-30 20:53:05.909818 test begin: paddle.t(Tensor([200, 2540161],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.004145622253417969 	 0.003604412078857422 	 8.106231689453125e-06 	 2.0503997802734375e-05 	 0.039740800857543945 	 0.0556182861328125 	 4.4345855712890625e-05 	 3.147125244140625e-05 	 
2025-07-30 20:53:24.544832 test begin: paddle.t(Tensor([25401610, 20],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.004156351089477539 	 0.0035316944122314453 	 8.106231689453125e-06 	 1.7642974853515625e-05 	 0.03953814506530762 	 0.05726885795593262 	 2.3126602172851562e-05 	 6.532669067382812e-05 	 
2025-07-30 20:53:42.026958 test begin: paddle.t(Tensor([496130, 512],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([496130, 512],"int64"), ) 	 254018560 	 1000 	 0.004123210906982422 	 0.0035686492919921875 	 1.1682510375976562e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:53:50.200118 test begin: paddle.t(Tensor([50803210, 10],"float32"), )
[Prof] paddle.t 	 paddle.t(Tensor([50803210, 10],"float32"), ) 	 508032100 	 1000 	 0.0041234493255615234 	 0.0035715103149414062 	 1.2874603271484375e-05 	 1.8358230590820312e-05 	 0.041680097579956055 	 0.056256771087646484 	 6.389617919921875e-05 	 6.175041198730469e-05 	 
2025-07-30 20:54:06.909423 test begin: paddle.t(Tensor([5120, 49613],"int64"), )
[Prof] paddle.t 	 paddle.t(Tensor([5120, 49613],"int64"), ) 	 254018560 	 1000 	 0.004180431365966797 	 0.003541707992553711 	 1.621246337890625e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:54:15.123008 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", ) 	 76204806 	 1000 	 3.1955878734588623 	 2.929419755935669 	 0.6541094779968262 	 0.42505931854248047 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:54:30.109801 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803807 	 1000 	 0.08693051338195801 	 0.12291407585144043 	 2.7418136596679688e-05 	 7.843971252441406e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:54:31.308555 test begin: paddle.take(Tensor([12700801, 4],"float32"), Tensor([6350401, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([12700801, 4],"float32"), Tensor([6350401, 3],"int64"), mode="raise", ) 	 69854407 	 1000 	 2.4050819873809814 	 2.2144179344177246 	 0.49251627922058105 	 0.32064199447631836 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:54:42.224881 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 3],"int64"), mode="raise", ) 	 50803209 	 1000 	 0.08429408073425293 	 0.131866455078125 	 1.3828277587890625e-05 	 6.580352783203125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:54:43.422738 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 8467201],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([2, 8467201],"int64"), mode="raise", ) 	 67737605 	 1000 	 2.145015001296997 	 1.9569118022918701 	 0.43892717361450195 	 0.28540945053100586 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:54:52.265720 test begin: paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 16934401],"float32"), Tensor([201, 3],"int64"), mode="raise", ) 	 50803806 	 1000 	 0.0906839370727539 	 0.12028717994689941 	 2.7179718017578125e-05 	 7.176399230957031e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:54:53.482456 test begin: paddle.take(Tensor([3, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float32"), Tensor([2, 12700801],"int64"), mode="raise", ) 	 25401614 	 1000 	 1.548194169998169 	 1.1424190998077393 	 0.3177647590637207 	 0.16675472259521484 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:55:07.726259 test begin: paddle.take(Tensor([3, 4],"float32"), Tensor([8467201, 3],"int64"), mode="raise", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float32"), Tensor([8467201, 3],"int64"), mode="raise", ) 	 25401615 	 1000 	 1.5481436252593994 	 1.1425015926361084 	 0.316328763961792 	 0.16673851013183594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:55:21.982373 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="clip", ) 	 25401620 	 1000 	 0.6445245742797852 	 0.6200101375579834 	 0.32932448387145996 	 0.30815839767456055 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:55:40.957456 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([3175201, 8],"int64"), mode="wrap", ) 	 25401620 	 1000 	 3.351172924041748 	 1.200850248336792 	 0.31147193908691406 	 0.30678653717041016 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:56:01.932073 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="clip", ) 	 25401617 	 1000 	 0.644385814666748 	 0.6059262752532959 	 0.32924461364746094 	 0.3080575466156006 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:56:19.612661 test begin: paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 4],"float64"), Tensor([5, 5080321],"int64"), mode="wrap", ) 	 25401617 	 1000 	 3.352201461791992 	 1.2124443054199219 	 0.31145620346069336 	 0.3068089485168457 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:56:42.137574 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="clip", ) 	 67737608 	 1000 	 3.990262985229492 	 4.007713317871094 	 2.0389509201049805 	 2.0470387935638428 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:57:00.533548 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8467201],"int64"), mode="wrap", ) 	 67737608 	 1000 	 8.467498779296875 	 4.9970862865448 	 0.7883388996124268 	 1.278494119644165 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:57:24.405303 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([5, 8],"int64"), mode="wrap", ) 	 25401643 	 1000 	 0.14380764961242676 	 0.07257676124572754 	 2.6464462280273438e-05 	 5.1975250244140625e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:57:25.325485 test begin: paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([3, 8467201],"float64"), Tensor([501, 8],"int64"), mode="clip", ) 	 25405611 	 1000 	 0.05554533004760742 	 0.044217586517333984 	 1.33514404296875e-05 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:57:26.106661 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", ) 	 25401644 	 1000 	 0.14302945137023926 	 0.07271146774291992 	 2.7894973754882812e-05 	 6.937980651855469e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:57:27.024879 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="clip", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="clip", ) 	 76204812 	 1000 	 4.785860776901245 	 4.804394006729126 	 2.4462475776672363 	 2.4544548988342285 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:57:49.269747 test begin: paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="wrap", )
[Prof] paddle.take 	 paddle.take(Tensor([6350401, 4],"float64"), Tensor([6350401, 8],"int64"), mode="wrap", ) 	 76204812 	 1000 	 10.145414352416992 	 5.992594957351685 	 0.943004846572876 	 1.5336310863494873 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:17.710793 test begin: paddle.take_along_axis(Tensor([1024, 384],"float32"), Tensor([1024, 24807],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 384],"float32"), Tensor([1024, 24807],"int64"), axis=-1, ) 	 25795584 	 1000 	 0.5829787254333496 	 0.2415454387664795 	 0.19848418235778809 	 0.22235751152038574 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:22.370414 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 24807],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 24807],"int64"), axis=-1, ) 	 76206080 	 1000 	 1.0050456523895264 	 0.4406728744506836 	 0.3424358367919922 	 0.42279529571533203 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:28.206077 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 7],"int64"), axis=-1, ) 	 50810880 	 1000 	 0.30431485176086426 	 0.017043113708496094 	 0.10374665260314941 	 3.910064697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:29.811440 test begin: paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1024, 49613],"float32"), Tensor([1024, 8],"int64"), axis=-1, ) 	 50811904 	 1000 	 0.3056607246398926 	 0.016998767852783203 	 0.1050717830657959 	 3.504753112792969e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:31.421490 test begin: paddle.take_along_axis(Tensor([1051, 63, 768],"float32"), axis=1, indices=Tensor([1051, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([1051, 63, 768],"float32"), axis=1, indices=Tensor([1051, 7, 768],"int64"), ) 	 56501760 	 1000 	 0.552288293838501 	 0.3106536865234375 	 0.18822693824768066 	 0.28893136978149414 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:34.261091 test begin: paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 7],"int64"), axis=-1, ) 	 51729691 	 1000 	 0.3642899990081787 	 0.05723309516906738 	 0.1241915225982666 	 0.0399167537689209 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:37.301605 test begin: paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([132301, 384],"float32"), Tensor([132301, 8],"int64"), axis=-1, ) 	 51861992 	 1000 	 0.37161922454833984 	 0.06677126884460449 	 0.12670207023620605 	 0.04519963264465332 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:58:40.316956 test begin: paddle.take_along_axis(Tensor([3175201, 384],"float32"), Tensor([3175201, 8],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([3175201, 384],"float32"), Tensor([3175201, 8],"int64"), axis=-1, ) 	 1244678792 	 1000 	 8.60407304763794 	 1.3755993843078613 	 2.932798147201538 	 0.3514223098754883 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:59:27.739616 test begin: paddle.take_along_axis(Tensor([3628801, 384],"float32"), Tensor([3628801, 7],"int64"), axis=-1, )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([3628801, 384],"float32"), Tensor([3628801, 7],"int64"), axis=-1, ) 	 1418861191 	 1000 	 9.638936519622803 	 1.4206173419952393 	 3.2860870361328125 	 0.36253833770751953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:21.256206 test begin: paddle.take_along_axis(Tensor([4726, 63, 768],"float32"), axis=1, indices=Tensor([4726, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([4726, 63, 768],"float32"), axis=1, indices=Tensor([4726, 7, 768],"int64"), ) 	 254069760 	 1000 	 2.4312503337860107 	 1.3837299346923828 	 0.8297033309936523 	 1.364060401916504 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:34.487418 test begin: paddle.take_along_axis(Tensor([8, 63, 100801],"float32"), axis=1, indices=Tensor([8, 7, 100801],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 100801],"float32"), axis=1, indices=Tensor([8, 7, 100801],"int64"), ) 	 56448560 	 1000 	 0.5714988708496094 	 0.3129596710205078 	 0.19477581977844238 	 0.2899036407470703 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:39.470380 test begin: paddle.take_along_axis(Tensor([8, 63, 453601],"float32"), axis=1, indices=Tensor([8, 7, 453601],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 453601],"float32"), axis=1, indices=Tensor([8, 7, 453601],"int64"), ) 	 254016560 	 1000 	 3.0373971462249756 	 1.588787317276001 	 1.0349550247192383 	 1.5693135261535645 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:00:56.185160 test begin: paddle.take_along_axis(Tensor([8, 63, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 63, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), ) 	 25792512 	 1000 	 0.6046056747436523 	 0.28467607498168945 	 0.20539355278015137 	 0.2654690742492676 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:01:00.093388 test begin: paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 4135, 768],"int64"), ) 	 76210176 	 1000 	 1.352806568145752 	 0.9545140266418457 	 0.4610598087310791 	 0.932734489440918 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:01:09.355497 test begin: paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 7, 768],"int64"), )
[Prof] paddle.take_along_axis 	 paddle.take_along_axis(Tensor([8, 8269, 768],"float32"), axis=1, indices=Tensor([8, 7, 768],"int64"), ) 	 50847744 	 1000 	 0.3073618412017822 	 0.01729416847229004 	 0.10480356216430664 	 3.24249267578125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:01:11.976798 test begin: paddle.tan(Tensor([8, 16, 396901],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([8, 16, 396901],"float32"), ) 	 50803328 	 1000 	 0.2949366569519043 	 0.3050966262817383 	 0.2862284183502197 	 0.28043293952941895 	 0.45120716094970703 	 1.0405194759368896 	 0.3984525203704834 	 0.3545527458190918 	 
2025-07-30 21:01:15.752078 test begin: paddle.tan(Tensor([8, 198451, 32],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([8, 198451, 32],"float32"), ) 	 50803456 	 1000 	 0.29494237899780273 	 0.2981534004211426 	 0.2863190174102783 	 0.2873823642730713 	 0.4511704444885254 	 1.0404052734375 	 0.3791658878326416 	 0.3544602394104004 	 
2025-07-30 21:01:19.543069 test begin: paddle.tan(Tensor([99226, 16, 32],"float32"), )
[Prof] paddle.tan 	 paddle.tan(Tensor([99226, 16, 32],"float32"), ) 	 50803712 	 1000 	 0.2949843406677246 	 0.29995155334472656 	 0.2864561080932617 	 0.2869534492492676 	 0.45067858695983887 	 1.040374755859375 	 0.3977673053741455 	 0.3544483184814453 	 
2025-07-30 21:01:23.341860 test begin: paddle.tanh(Tensor([16, 125, 25500],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([16, 125, 25500],"float32"), ) 	 51000000 	 1000 	 0.2965092658996582 	 0.2992427349090576 	 0.2879445552825928 	 0.2881662845611572 	 0.45237207412719727 	 0.4483492374420166 	 0.39815449714660645 	 0.3799889087677002 	 
2025-07-30 21:01:26.510209 test begin: paddle.tanh(Tensor([16, 64, 49613],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([16, 64, 49613],"float32"), ) 	 50803712 	 1000 	 0.29537367820739746 	 0.2981381416320801 	 0.2867758274078369 	 0.28740954399108887 	 0.44960904121398926 	 0.44660449028015137 	 0.39522552490234375 	 0.3784759044647217 	 
2025-07-30 21:01:29.661370 test begin: paddle.tanh(Tensor([28, 32, 241, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([28, 32, 241, 241],"float32"), ) 	 52040576 	 1000 	 0.302264928817749 	 0.3051118850708008 	 0.29378676414489746 	 0.29381370544433594 	 0.4603874683380127 	 0.4573225975036621 	 0.40636324882507324 	 0.38909435272216797 	 
2025-07-30 21:01:32.878283 test begin: paddle.tanh(Tensor([32, 64, 25500],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([32, 64, 25500],"float32"), ) 	 52224000 	 1000 	 0.3034658432006836 	 0.8252708911895752 	 0.29480719566345215 	 0.2950773239135742 	 0.4618871212005615 	 0.4588494300842285 	 0.408174991607666 	 0.39214491844177246 	 
2025-07-30 21:01:39.382893 test begin: paddle.tanh(Tensor([64, 26, 512, 1, 60],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 512, 1, 60],"float32"), ) 	 51118080 	 1000 	 0.2970242500305176 	 0.29990315437316895 	 0.28841352462768555 	 0.28892946243286133 	 0.4522111415863037 	 0.44930219650268555 	 0.39690232276916504 	 0.37960028648376465 	 
2025-07-30 21:01:42.595285 test begin: paddle.tanh(Tensor([64, 26, 512, 2, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 512, 2, 40],"float32"), ) 	 68157440 	 1000 	 0.39473485946655273 	 0.3979380130767822 	 0.3857448101043701 	 0.3867335319519043 	 0.6028397083282471 	 0.5974142551422119 	 0.5494875907897949 	 0.5295422077178955 	 
2025-07-30 21:01:46.801217 test begin: paddle.tanh(Tensor([64, 26, 764, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 26, 764, 1, 40],"float32"), ) 	 50851840 	 1000 	 0.2956268787384033 	 0.3003668785095215 	 0.2870063781738281 	 0.2876095771789551 	 0.44995737075805664 	 0.4484546184539795 	 0.39597487449645996 	 0.3813202381134033 	 
2025-07-30 21:01:50.016238 test begin: paddle.tanh(Tensor([64, 39, 512, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([64, 39, 512, 1, 40],"float32"), ) 	 51118080 	 1000 	 0.29700732231140137 	 0.2999143600463867 	 0.288393497467041 	 0.288787841796875 	 0.4521777629852295 	 0.4493136405944824 	 0.388582706451416 	 0.3815340995788574 	 
2025-07-30 21:01:53.191191 test begin: paddle.tanh(Tensor([8, 110, 241, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 110, 241, 241],"float32"), ) 	 51111280 	 1000 	 0.2968783378601074 	 0.2998950481414795 	 0.2883169651031494 	 0.28821778297424316 	 0.45208287239074707 	 0.44923901557922363 	 0.39394092559814453 	 0.38146090507507324 	 
2025-07-30 21:01:56.374376 test begin: paddle.tanh(Tensor([8, 32, 241, 824],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 32, 241, 824],"float32"), ) 	 50837504 	 1000 	 0.2954220771789551 	 0.29836487770080566 	 0.2868003845214844 	 0.2875988483428955 	 0.4499495029449463 	 0.44685959815979004 	 0.39595937728881836 	 0.37830233573913574 	 
2025-07-30 21:01:59.589989 test begin: paddle.tanh(Tensor([8, 32, 824, 241],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([8, 32, 824, 241],"float32"), ) 	 50837504 	 1000 	 0.29546689987182617 	 0.2983677387237549 	 0.2795901298522949 	 0.2875404357910156 	 0.4499180316925049 	 0.4468815326690674 	 0.39583420753479004 	 0.3796989917755127 	 
2025-07-30 21:02:02.749507 test begin: paddle.tanh(Tensor([96, 26, 512, 1, 40],"float32"), )
[Prof] paddle.tanh 	 paddle.tanh(Tensor([96, 26, 512, 1, 40],"float32"), ) 	 51118080 	 1000 	 0.29699254035949707 	 0.3000047206878662 	 0.28838253021240234 	 0.2888340950012207 	 0.45214390754699707 	 0.4492502212524414 	 0.3981020450592041 	 0.38170456886291504 	 
2025-07-30 21:02:05.957055 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, )
W0730 21:02:12.991474 69961 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.023866653442382812 	 0.009100675582885742 	 1.6927719116210938e-05 	 5.459785461425781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:15.168176 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0730 21:02:22.264482 70134 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.03031611442565918 	 0.008922815322875977 	 1.9311904907226562e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:23.378447 test begin: paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0730 21:02:30.409829 70308 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([2268010, 4, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.02385711669921875 	 0.007630109786987305 	 4.267692565917969e-05 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:31.515798 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, )
W0730 21:02:38.502938 70474 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.02327275276184082 	 0.0076541900634765625 	 8.58306884765625e-06 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:40.128788 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, )
W0730 21:02:47.050487 70573 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.029872417449951172 	 0.015175819396972656 	 1.239776611328125e-05 	 6.651878356933594e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:48.161965 test begin: paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, )
W0730 21:02:55.017382 70743 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 226801, 4, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.023346662521362305 	 0.007762432098388672 	 3.0279159545898438e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:02:56.101238 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, )
W0730 21:03:03.137621 70848 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,3,], axis=3, ) 	 254017120 	 1000 	 0.02287888526916504 	 0.0076406002044677734 	 1.0728836059570312e-05 	 2.0503997802734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:03:04.237810 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, )
W0730 21:03:11.174084 71407 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), list[2,4,6,], axis=3, ) 	 254017120 	 1000 	 0.030349254608154297 	 0.008952617645263672 	 1.71661376953125e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:03:12.250940 test begin: paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, )
W0730 21:03:19.085811 71581 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 226801, 7],"int64"), tuple(2,6,), axis=3, ) 	 254017120 	 1000 	 0.023523807525634766 	 0.007727622985839844 	 1.1920928955078125e-05 	 4.076957702636719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:03:22.094724 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, )
W0730 21:03:29.125294 71752 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,3,], axis=3, ) 	 254016640 	 1000 	 0.02322530746459961 	 0.0076482295989990234 	 1.1205673217773438e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:03:30.233322 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, )
W0730 21:03:37.185461 71851 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), list[2,4,6,], axis=3, ) 	 254016640 	 1000 	 0.030022144317626953 	 0.008813619613647461 	 1.6927719116210938e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:03:39.573319 test begin: paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, )
W0730 21:03:46.609352 72026 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.tensor_split 	 paddle.tensor_split(Tensor([40, 4, 4, 396901],"int64"), tuple(2,6,), axis=3, ) 	 254016640 	 1000 	 0.023687124252319336 	 0.007584333419799805 	 1.3113021850585938e-05 	 2.1457672119140625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn

2025-07-30 19:24:42.724156 test begin: paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), )
W0730 19:24:44.695096 24295 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 210, 75600],"bool"), Tensor([4, 210, 75600],"bool"), ) 	 127008000 	 1000 	 0.1542201042175293 	 0.1493222713470459 	 0.12944769859313965 	 0.12371158599853516 	 None 	 None 	 None 	 None 	 
2025-07-30 19:24:45.283616 test begin: paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([1, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([1, 218, 70644],"bool"), ) 	 77001960 	 1000 	 0.21311593055725098 	 0.2691025733947754 	 0.19573307037353516 	 0.2557258605957031 	 None 	 None 	 None 	 None 	 
2025-07-30 19:24:46.821337 test begin: paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), )
[Prof] paddle.Tensor.__or__ 	 paddle.Tensor.__or__(Tensor([4, 218, 70644],"bool"), Tensor([4, 218, 70644],"bool"), ) 	 123203136 	 1000 	 0.14147734642028809 	 0.15285110473632812 	 0.13259577751159668 	 0.12739968299865723 	 None 	 None 	 None 	 None 	 
2025-07-30 19:24:48.791349 test begin: paddle.Tensor.__pow__(Tensor([23, 17, 256, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([23, 17, 256, 256],"float64"), 2, ) 	 25624576 	 1000 	 0.579559326171875 	 0.3051888942718506 	 0.5704724788665771 	 0.28367114067077637 	 0.611114501953125 	 1.060455322265625 	 0.5535221099853516 	 0.36124229431152344 	 
2025-07-30 19:24:52.740393 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 244, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 244, 256],"float64"), 2, ) 	 25485312 	 1000 	 0.5757982730865479 	 0.30167555809020996 	 0.5668411254882812 	 0.28078150749206543 	 0.6076607704162598 	 1.0547263622283936 	 0.5553715229034424 	 0.3592705726623535 	 
2025-07-30 19:24:56.339969 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 256, 244],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 256, 244],"float64"), 2, ) 	 25485312 	 1000 	 1.4656116962432861 	 0.30861473083496094 	 0.5667452812194824 	 0.2820119857788086 	 0.6076302528381348 	 1.0546298027038574 	 0.5544297695159912 	 0.3592698574066162 	 
2025-07-30 19:25:03.453522 test begin: paddle.Tensor.__pow__(Tensor([24, 17, 256, 256],"float64"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([24, 17, 256, 256],"float64"), 2, ) 	 26738688 	 1000 	 0.6041736602783203 	 0.3138895034790039 	 0.5950868129730225 	 0.29691576957702637 	 0.637073278427124 	 1.1061019897460938 	 0.5843307971954346 	 0.37683558464050293 	 
2025-07-30 19:25:07.330810 test begin: paddle.Tensor.__pow__(Tensor([259, 3, 256, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([259, 3, 256, 256],"float32"), 2, ) 	 50921472 	 1000 	 0.3705747127532959 	 0.29860830307006836 	 0.36125946044921875 	 0.28101086616516113 	 0.45372939109802246 	 1.0549967288970947 	 0.3999214172363281 	 0.3594014644622803 	 
2025-07-30 19:25:11.428100 test begin: paddle.Tensor.__pow__(Tensor([28, 32, 241, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([28, 32, 241, 241],"float32"), 2, ) 	 52040576 	 1000 	 0.3789060115814209 	 0.30896997451782227 	 0.36266589164733887 	 0.28026676177978516 	 0.4631173610687256 	 1.0811541080474854 	 0.4000089168548584 	 0.2763853073120117 	 
2025-07-30 19:25:15.403003 test begin: paddle.Tensor.__pow__(Tensor([64, 13, 256, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 13, 256, 256],"float32"), 2, ) 	 54525952 	 1000 	 0.3969309329986572 	 0.31941819190979004 	 0.38741278648376465 	 0.3018958568572998 	 0.48523712158203125 	 1.1288268566131592 	 0.4284815788269043 	 0.38453149795532227 	 
2025-07-30 19:25:19.519158 test begin: paddle.Tensor.__pow__(Tensor([64, 3, 1034, 256],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 3, 1034, 256],"float32"), 2, ) 	 50823168 	 1000 	 0.37018537521362305 	 0.2994372844696045 	 0.3609201908111572 	 0.2727692127227783 	 0.4527595043182373 	 1.0529394149780273 	 0.38986754417419434 	 0.3587052822113037 	 
2025-07-30 19:25:23.374838 test begin: paddle.Tensor.__pow__(Tensor([64, 3, 256, 1034],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([64, 3, 256, 1034],"float32"), 2, ) 	 50823168 	 1000 	 0.36978673934936523 	 0.29810214042663574 	 0.36048221588134766 	 0.2694261074066162 	 0.4528524875640869 	 1.052870512008667 	 0.39899301528930664 	 0.35872936248779297 	 
2025-07-30 19:25:27.201309 test begin: paddle.Tensor.__pow__(Tensor([8, 110, 241, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 110, 241, 241],"float32"), 2, ) 	 51111280 	 1000 	 0.37210845947265625 	 0.2997162342071533 	 0.3562157154083252 	 0.2748985290527344 	 0.4550175666809082 	 1.061729907989502 	 0.39125680923461914 	 0.27143168449401855 	 
2025-07-30 19:25:31.069195 test begin: paddle.Tensor.__pow__(Tensor([8, 32, 241, 824],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 32, 241, 824],"float32"), 2, ) 	 50837504 	 1000 	 0.3724215030670166 	 0.30336999893188477 	 0.3540518283843994 	 0.27373385429382324 	 0.45304369926452637 	 1.053215742111206 	 0.39028000831604004 	 0.358823299407959 	 
2025-07-30 19:25:34.959157 test begin: paddle.Tensor.__pow__(Tensor([8, 32, 824, 241],"float32"), 2, )
[Prof] paddle.Tensor.__pow__ 	 paddle.Tensor.__pow__(Tensor([8, 32, 824, 241],"float32"), 2, ) 	 50837504 	 1000 	 0.9715137481689453 	 0.31082820892333984 	 0.3606536388397217 	 0.2813448905944824 	 0.45305728912353516 	 1.0532467365264893 	 0.3871114253997803 	 0.358814001083374 	 
2025-07-30 19:25:41.372668 test begin: paddle.Tensor.__radd__(Tensor([192, 104, 32, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 104, 32, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.30015039443969727 	 0.298201322555542 	 0.29122257232666016 	 0.2837188243865967 	 0.3002786636352539 	 0.05426740646362305 	 0.23476433753967285 	 4.291534423828125e-05 	 
2025-07-30 19:25:46.142761 test begin: paddle.Tensor.__radd__(Tensor([192, 128, 16, 259],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 128, 16, 259],"float16"), 0, ) 	 101842944 	 1000 	 0.3068699836730957 	 0.29710984230041504 	 0.2824842929840088 	 0.27498388290405273 	 0.299238920211792 	 0.06493616104125977 	 0.23996472358703613 	 8.153915405273438e-05 	 
2025-07-30 19:25:51.182837 test begin: paddle.Tensor.__radd__(Tensor([192, 128, 26, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 128, 26, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.30017924308776855 	 0.2980978488922119 	 0.2841148376464844 	 0.27633142471313477 	 0.3002941608428955 	 0.0667426586151123 	 0.2402799129486084 	 5.054473876953125e-05 	 
2025-07-30 19:25:55.914389 test begin: paddle.Tensor.__radd__(Tensor([192, 207, 16, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 207, 16, 160],"float16"), 0, ) 	 101744640 	 1000 	 0.29876232147216797 	 0.2967398166656494 	 0.28281140327453613 	 0.27446913719177246 	 0.29894518852233887 	 0.054880619049072266 	 0.2369532585144043 	 3.5762786865234375e-05 	 
2025-07-30 19:26:00.623594 test begin: paddle.Tensor.__radd__(Tensor([192, 240, 16, 138],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 240, 16, 138],"float16"), 0, ) 	 101744640 	 1000 	 0.5225570201873779 	 0.3102595806121826 	 0.28222131729125977 	 0.27454185485839844 	 0.2992112636566162 	 0.07274007797241211 	 0.23883771896362305 	 0.00021958351135253906 	 
2025-07-30 19:26:08.482206 test begin: paddle.Tensor.__radd__(Tensor([192, 240, 28, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 240, 28, 80],"float16"), 0, ) 	 103219200 	 1000 	 0.3029649257659912 	 0.3032052516937256 	 0.29402613639831543 	 0.2861599922180176 	 0.303145170211792 	 0.04891848564147949 	 0.25338172912597656 	 5.650520324707031e-05 	 
2025-07-30 19:26:13.278097 test begin: paddle.Tensor.__radd__(Tensor([192, 414, 16, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 414, 16, 80],"float16"), 0, ) 	 101744640 	 1000 	 0.2987492084503174 	 0.2966952323913574 	 0.28974342346191406 	 0.2819371223449707 	 0.29894399642944336 	 0.048494577407836914 	 0.24547028541564941 	 4.458427429199219e-05 	 
2025-07-30 19:26:18.080394 test begin: paddle.Tensor.__radd__(Tensor([192, 64, 32, 259],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 64, 32, 259],"float16"), 0, ) 	 101842944 	 1000 	 0.29917216300964355 	 0.2970085144042969 	 0.2900991439819336 	 0.28228139877319336 	 0.29920291900634766 	 0.0493922233581543 	 0.24673008918762207 	 3.5762786865234375e-05 	 
2025-07-30 19:26:22.959363 test begin: paddle.Tensor.__radd__(Tensor([192, 64, 52, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([192, 64, 52, 160],"float16"), 0, ) 	 102236160 	 1000 	 0.3001525402069092 	 0.29819631576538086 	 0.2912282943725586 	 0.2836883068084717 	 0.3002817630767822 	 0.048734426498413086 	 0.2485814094543457 	 5.9604644775390625e-05 	 
2025-07-30 19:26:27.653805 test begin: paddle.Tensor.__radd__(Tensor([311, 128, 16, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([311, 128, 16, 160],"float16"), 0, ) 	 101908480 	 1000 	 0.2991518974304199 	 0.2972891330718994 	 0.2901613712310791 	 0.28229260444641113 	 0.29934048652648926 	 0.04895925521850586 	 0.24771547317504883 	 4.935264587402344e-05 	 
2025-07-30 19:26:32.348477 test begin: paddle.Tensor.__radd__(Tensor([311, 64, 32, 160],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([311, 64, 32, 160],"float16"), 0, ) 	 101908480 	 1000 	 0.3038768768310547 	 0.571378231048584 	 0.28997063636779785 	 0.2823009490966797 	 0.29945802688598633 	 0.048514604568481445 	 0.24959921836853027 	 5.7220458984375e-05 	 
2025-07-30 19:26:40.181499 test begin: paddle.Tensor.__radd__(Tensor([331, 240, 16, 80],"float16"), 0, )
[Prof] paddle.Tensor.__radd__ 	 paddle.Tensor.__radd__(Tensor([331, 240, 16, 80],"float16"), 0, ) 	 101683200 	 1000 	 0.2986721992492676 	 0.29651689529418945 	 0.28968358039855957 	 0.28214335441589355 	 0.2986595630645752 	 0.048178672790527344 	 0.24867486953735352 	 3.3855438232421875e-05 	 
2025-07-30 19:26:44.907478 test begin: paddle.Tensor.__rlshift__(Tensor([169345, 300],"int32"), -223, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([169345, 300],"int32"), -223, ) 	 50803500 	 1000 	 0.29909729957580566 	 0.2978627681732178 	 0.15261435508728027 	 0.2709810733795166 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:46.101319 test begin: paddle.Tensor.__rlshift__(Tensor([200, 254017],"int32"), -223, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 254017],"int32"), -223, ) 	 50803400 	 1000 	 0.29923391342163086 	 0.29787707328796387 	 0.1526806354522705 	 0.27097511291503906 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:47.286542 test begin: paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), -212, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), -212, ) 	 101606600 	 1000 	 0.3372304439544678 	 0.3035888671875 	 0.0003075599670410156 	 0.26810622215270996 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:48.920190 test begin: paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), 63, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([200, 508033],"int16"), 63, ) 	 101606600 	 1000 	 0.33925509452819824 	 0.2950301170349121 	 0.0003056526184082031 	 0.26798248291015625 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:50.532336 test begin: paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), -212, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), -212, ) 	 101606700 	 1000 	 0.3389458656311035 	 0.2988626956939697 	 0.0003066062927246094 	 0.26798510551452637 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:52.159470 test begin: paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), 63, )
[Prof] paddle.Tensor.__rlshift__ 	 paddle.Tensor.__rlshift__(Tensor([338689, 300],"int16"), 63, ) 	 101606700 	 1000 	 0.33429551124572754 	 0.295135498046875 	 0.0003008842468261719 	 0.2758488655090332 	 None 	 None 	 None 	 None 	 
2025-07-30 19:26:53.769866 test begin: paddle.Tensor.__rmatmul__(Tensor([10160641, 5],"float32"), Tensor([2, 10160641],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([10160641, 5],"float32"), Tensor([2, 10160641],"float32"), ) 	 71124487 	 1000 	 1.3880045413970947 	 1.3859024047851562 	 0.7091844081878662 	 0.7082092761993408 	 2.098780393600464 	 2.0972402095794678 	 0.10718655586242676 	 0.10711407661437988 	 
2025-07-30 19:27:02.087713 test begin: paddle.Tensor.__rmatmul__(Tensor([25401601, 5],"float32"), Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([25401601, 5],"float32"), Tensor([2, 25401601],"float32"), ) 	 177811207 	 1000 	 3.4008357524871826 	 3.399142026901245 	 1.7379069328308105 	 1.7369394302368164 	 5.245611190795898 	 5.243809700012207 	 0.10719752311706543 	 0.10713386535644531 	 
2025-07-30 19:27:22.410560 test begin: paddle.Tensor.__rmatmul__(Tensor([3, 16934401],"float32"), Tensor([2, 3],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([3, 16934401],"float32"), Tensor([2, 3],"float32"), ) 	 50803209 	 1000 	 0.7673189640045166 	 0.7642014026641846 	 0.04611015319824219 	 0.04591679573059082 	 4.107458591461182 	 4.103983163833618 	 0.2191307544708252 	 0.22114348411560059 	 
2025-07-30 19:27:33.585004 test begin: paddle.Tensor.__rmatmul__(Tensor([3, 5],"float32"), Tensor([16934401, 3],"float32"), )
[Prof] paddle.Tensor.__rmatmul__ 	 paddle.Tensor.__rmatmul__(Tensor([3, 5],"float32"), Tensor([16934401, 3],"float32"), ) 	 50803218 	 1000 	 1.7902543544769287 	 1.7891294956207275 	 0.10745048522949219 	 0.10744476318359375 	 4.191215515136719 	 4.186752080917358 	 0.22582578659057617 	 0.22337698936462402 	 
2025-07-30 19:27:48.511449 test begin: paddle.Tensor.__rmod__(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), ) 	 101606412 	 1000 	 0.45116114616394043 	 0.449399471282959 	 0.4414479732513428 	 0.43332409858703613 	 1.051347255706787 	 1.197324514389038 	 0.9926908016204834 	 0.40776562690734863 	 
2025-07-30 19:27:54.277888 test begin: paddle.Tensor.__rmod__(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), ) 	 101606416 	 1000 	 0.45096278190612793 	 0.4493889808654785 	 0.4413106441497803 	 0.43294715881347656 	 1.051712989807129 	 1.1972339153289795 	 0.9939510822296143 	 0.40775012969970703 	 
2025-07-30 19:27:59.889998 test begin: paddle.Tensor.__rmod__(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.Tensor.__rmod__ 	 paddle.Tensor.__rmod__(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), ) 	 101606424 	 1000 	 0.4509270191192627 	 0.44927024841308594 	 0.44128870964050293 	 0.4332451820373535 	 1.0514800548553467 	 1.1973459720611572 	 0.9934055805206299 	 0.407789945602417 	 
2025-07-30 19:28:05.466525 test begin: paddle.Tensor.__rmul__(Tensor([176, 392, 737],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([176, 392, 737],"float32"), -100.0, ) 	 50847104 	 1000 	 0.2973508834838867 	 0.2982151508331299 	 0.28811168670654297 	 0.2836601734161377 	 0.296459436416626 	 0.298154354095459 	 0.2468111515045166 	 0.2006824016571045 	 
2025-07-30 19:28:08.298434 test begin: paddle.Tensor.__rmul__(Tensor([176, 737, 392],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([176, 737, 392],"float32"), -100.0, ) 	 50847104 	 1000 	 0.29649972915649414 	 0.2981398105621338 	 0.2877469062805176 	 0.28363776206970215 	 0.29659247398376465 	 0.2980458736419678 	 0.24661517143249512 	 0.2315366268157959 	 
2025-07-30 19:28:11.149209 test begin: paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 0.75, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 0.75, ) 	 50868000 	 1000 	 0.2982337474822998 	 0.29825305938720703 	 0.28774380683898926 	 0.2836027145385742 	 0.2967185974121094 	 0.2982361316680908 	 0.24672317504882812 	 0.23115873336791992 	 
2025-07-30 19:28:15.491814 test begin: paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 1.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([324000, 157],"float32"), 1.0, ) 	 50868000 	 1000 	 0.5982444286346436 	 0.30292725563049316 	 0.2801847457885742 	 0.28336071968078613 	 0.2966318130493164 	 0.2980630397796631 	 0.23549771308898926 	 0.23028135299682617 	 
2025-07-30 19:28:19.298332 test begin: paddle.Tensor.__rmul__(Tensor([331, 392, 392],"float32"), -100.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([331, 392, 392],"float32"), -100.0, ) 	 50862784 	 1000 	 0.2986609935760498 	 0.29828357696533203 	 0.28731489181518555 	 0.27981114387512207 	 0.29656434059143066 	 0.2980222702026367 	 0.24641132354736328 	 0.23032140731811523 	 
2025-07-30 19:28:22.140282 test begin: paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 0.75, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 0.75, ) 	 50803280 	 1000 	 0.29715991020202637 	 0.3168962001800537 	 0.28722357749938965 	 0.28329968452453613 	 0.2962203025817871 	 0.29787349700927734 	 0.24619674682617188 	 0.23039722442626953 	 
2025-07-30 19:28:24.983923 test begin: paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 1.0, )
[Prof] paddle.Tensor.__rmul__ 	 paddle.Tensor.__rmul__(Tensor([635041, 80],"float32"), 1.0, ) 	 50803280 	 1000 	 0.2959120273590088 	 0.2979466915130615 	 0.2872183322906494 	 0.2835819721221924 	 0.29622888565063477 	 0.2978031635284424 	 0.2464747428894043 	 0.2322545051574707 	 
2025-07-30 19:28:27.794115 test begin: paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), 5, ) 	 50803206 	 1000 	 0.2991158962249756 	 0.297961950302124 	 0.15263605117797852 	 0.283231258392334 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:28.975902 test begin: paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 3, 8467201],"int32"), True, ) 	 50803206 	 1000 	 0.29908061027526855 	 0.29795145988464355 	 0.15265464782714844 	 0.28283143043518066 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:30.151872 test begin: paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), 5, ) 	 50803210 	 1000 	 0.2991142272949219 	 0.2993741035461426 	 0.1526641845703125 	 0.28269505500793457 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:31.337184 test begin: paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([2, 5080321, 5],"int32"), True, ) 	 50803210 	 1000 	 0.29907917976379395 	 0.29792356491088867 	 0.15264415740966797 	 0.283125638961792 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:32.522128 test begin: paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), 5, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), 5, ) 	 50803215 	 1000 	 0.29953837394714355 	 0.29790377616882324 	 0.15266966819763184 	 0.28313255310058594 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:33.713378 test begin: paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), True, )
[Prof] paddle.Tensor.__ror__ 	 paddle.Tensor.__ror__(Tensor([3386881, 3, 5],"int32"), True, ) 	 50803215 	 1000 	 0.29996728897094727 	 0.3080565929412842 	 0.15267395973205566 	 0.2830932140350342 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:34.914236 test begin: paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000, )
[Prof] paddle.Tensor.__rpow__ 	 paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000, ) 	 50803201 	 1000 	 1.2464661598205566 	 0.6423499584197998 	 0.2979428768157959 	 0.32262754440307617 	 0.7022709846496582 	 0.743004322052002 	 0.6411759853363037 	 0.37960267066955566 	 
2025-07-30 19:28:41.026110 test begin: paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000.0, )
[Prof] paddle.Tensor.__rpow__ 	 paddle.Tensor.__rpow__(Tensor([50803201],"float32"), 10000.0, ) 	 50803201 	 1000 	 0.5831515789031982 	 0.6469376087188721 	 0.2978959083557129 	 0.32960939407348633 	 0.7018485069274902 	 0.7428896427154541 	 0.650890588760376 	 0.3795604705810547 	 
2025-07-30 19:28:45.380277 test begin: paddle.Tensor.__rrshift__(Tensor([169345, 300],"int32"), 232, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([169345, 300],"int32"), 232, ) 	 50803500 	 1000 	 0.30432653427124023 	 0.2979433536529541 	 0.15259814262390137 	 0.27809739112854004 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:46.580431 test begin: paddle.Tensor.__rrshift__(Tensor([200, 254017],"int32"), 232, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 254017],"int32"), 232, ) 	 50803400 	 1000 	 0.3023409843444824 	 0.297943115234375 	 0.15253663063049316 	 0.2783851623535156 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:47.754428 test begin: paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), -255, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), -255, ) 	 101606600 	 1000 	 0.33629345893859863 	 0.29616665840148926 	 0.00031185150146484375 	 0.2767646312713623 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:49.365434 test begin: paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), 11, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([200, 508033],"int16"), 11, ) 	 101606600 	 1000 	 0.33872246742248535 	 0.29608798027038574 	 0.0003104209899902344 	 0.2763020992279053 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:51.003922 test begin: paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), -255, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), -255, ) 	 101606700 	 1000 	 0.3378140926361084 	 0.2961897850036621 	 0.0003113746643066406 	 0.2768983840942383 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:52.611603 test begin: paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), 11, )
[Prof] paddle.Tensor.__rrshift__ 	 paddle.Tensor.__rrshift__(Tensor([338689, 300],"int16"), 11, ) 	 101606700 	 1000 	 0.3399808406829834 	 0.2982196807861328 	 0.0002968311309814453 	 0.27603769302368164 	 None 	 None 	 None 	 None 	 
2025-07-30 19:28:54.240377 test begin: paddle.Tensor.__rshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([169345, 300],"int32"), Tensor([169345, 300],"int32"), ) 	 101607000 	 1000 	 0.45069408416748047 	 0.4468064308166504 	 0.4412670135498047 	 0.43431687355041504 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:28:56.287889 test begin: paddle.Tensor.__rshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 254017],"int32"), Tensor([200, 254017],"int32"), ) 	 101606800 	 1000 	 0.45062708854675293 	 0.4477512836456299 	 0.44115281105041504 	 0.4325704574584961 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:28:58.340598 test begin: paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), ) 	 203213200 	 1000 	 0.4481699466705322 	 0.45020294189453125 	 0.43874168395996094 	 0.4377553462982178 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:29:01.170199 test begin: paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([200, 508033],"int16"), Tensor([200, 508033],"int16"), False, ) 	 203213200 	 1000 	 0.44852256774902344 	 3.113135814666748 	 0.4390842914581299 	 0.3536386489868164 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:29:06.710311 test begin: paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), ) 	 203213400 	 1000 	 0.4480733871459961 	 0.45026469230651855 	 0.43878650665283203 	 0.4378235340118408 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:29:09.646891 test begin: paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, )
[Prof] paddle.Tensor.__rshift__ 	 paddle.Tensor.__rshift__(Tensor([338689, 300],"int16"), Tensor([338689, 300],"int16"), False, ) 	 203213400 	 1000 	 0.44861626625061035 	 3.1134631633758545 	 0.4323298931121826 	 0.3536994457244873 	 None 	 None 	 None 	 None 	 combined
2025-07-30 19:29:15.212139 test begin: paddle.Tensor.__rsub__(Tensor([2, 1, 12404, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 1, 12404, 4096],"float16"), 1, ) 	 101613568 	 1000 	 0.2991769313812256 	 0.29636144638061523 	 0.2898213863372803 	 0.27731943130493164 	 0.29844045639038086 	 0.2961900234222412 	 0.24862933158874512 	 0.22544384002685547 	 
2025-07-30 19:29:21.939586 test begin: paddle.Tensor.__rsub__(Tensor([2, 1, 4096, 12404],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 1, 4096, 12404],"float16"), 1, ) 	 101613568 	 1000 	 0.5295207500457764 	 0.29641056060791016 	 0.28244614601135254 	 0.269428014755249 	 0.29851675033569336 	 0.2962663173675537 	 0.23795056343078613 	 0.222886323928833 	 
2025-07-30 19:29:27.966832 test begin: paddle.Tensor.__rsub__(Tensor([2, 4, 4096, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2, 4, 4096, 4096],"float16"), 1, ) 	 134217728 	 1000 	 0.39316487312316895 	 0.3901968002319336 	 0.3838627338409424 	 0.3711731433868408 	 0.39238762855529785 	 0.3900265693664551 	 0.3414344787597656 	 0.32242417335510254 	 
2025-07-30 19:29:34.525363 test begin: paddle.Tensor.__rsub__(Tensor([2944, 17257],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([2944, 17257],"float32"), 1, ) 	 50804608 	 1000 	 0.758429765701294 	 0.31774377822875977 	 0.28721189498901367 	 0.27827000617980957 	 0.29628729820251465 	 0.297910213470459 	 0.24554038047790527 	 0.21448516845703125 	 
2025-07-30 19:29:41.045520 test begin: paddle.Tensor.__rsub__(Tensor([4224, 12028],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([4224, 12028],"float32"), 1, ) 	 50806272 	 1000 	 0.296245813369751 	 0.2979466915130615 	 0.2875030040740967 	 0.2788510322570801 	 0.29631829261779785 	 0.297853946685791 	 0.24220514297485352 	 0.23363184928894043 	 
2025-07-30 19:29:43.840972 test begin: paddle.Tensor.__rsub__(Tensor([7, 1, 4096, 4096],"float16"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([7, 1, 4096, 4096],"float16"), 1, ) 	 117440512 	 1000 	 0.344728946685791 	 0.3448491096496582 	 0.32802486419677734 	 0.3149869441986084 	 0.3440718650817871 	 0.3416786193847656 	 0.28403568267822266 	 0.2644197940826416 	 
2025-07-30 19:29:49.730556 test begin: paddle.Tensor.__rsub__(Tensor([7664, 6629],"float32"), 1, )
[Prof] paddle.Tensor.__rsub__ 	 paddle.Tensor.__rsub__(Tensor([7664, 6629],"float32"), 1, ) 	 50804656 	 1000 	 0.2962222099304199 	 0.29984450340270996 	 0.28731489181518555 	 0.27898597717285156 	 0.29621052742004395 	 0.29785633087158203 	 0.24619078636169434 	 0.23284053802490234 	 
2025-07-30 19:29:52.642693 test begin: paddle.Tensor.__rtruediv__(Tensor([15548, 3268],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([15548, 3268],"float32"), 1.0, ) 	 50810864 	 1000 	 0.5840728282928467 	 0.5960304737091064 	 0.2983825206756592 	 0.30447936058044434 	 0.5859906673431396 	 1.3383595943450928 	 0.5312545299530029 	 0.34200096130371094 	 
2025-07-30 19:29:57.396426 test begin: paddle.Tensor.__rtruediv__(Tensor([16773, 3029],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([16773, 3029],"float32"), 1.0, ) 	 50805417 	 1000 	 0.5843427181243896 	 0.5958170890808105 	 0.29854297637939453 	 0.30434203147888184 	 0.5859425067901611 	 1.3382446765899658 	 0.5306615829467773 	 0.341961145401001 	 
2025-07-30 19:30:02.142429 test begin: paddle.Tensor.__rtruediv__(Tensor([26736, 1901],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([26736, 1901],"float32"), 1.0, ) 	 50825136 	 1000 	 0.5857656002044678 	 0.5988028049468994 	 0.2985243797302246 	 0.3045163154602051 	 0.5860898494720459 	 1.3387200832366943 	 0.5302245616912842 	 0.342083215713501 	 
2025-07-30 19:30:06.930070 test begin: paddle.Tensor.__rtruediv__(Tensor([37411, 1358],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([37411, 1358],"float32"), 1.0, ) 	 50804138 	 1000 	 0.5842502117156982 	 0.5958373546600342 	 0.2985055446624756 	 0.3043534755706787 	 0.5860109329223633 	 1.3382103443145752 	 0.5304720401763916 	 0.34198832511901855 	 
2025-07-30 19:30:11.673164 test begin: paddle.Tensor.__rtruediv__(Tensor([6684, 7601],"float32"), 1.0, )
[Prof] paddle.Tensor.__rtruediv__ 	 paddle.Tensor.__rtruediv__(Tensor([6684, 7601],"float32"), 1.0, ) 	 50805084 	 1000 	 0.5839986801147461 	 0.5961806774139404 	 0.2983260154724121 	 0.30437493324279785 	 0.5858306884765625 	 1.3382279872894287 	 0.5308964252471924 	 0.34198665618896484 	 
2025-07-30 19:30:16.392776 test begin: paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), 5, ) 	 50803206 	 1000 	 0.29981255531311035 	 0.29802870750427246 	 0.15272283554077148 	 0.28317952156066895 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:17.567328 test begin: paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 3, 8467201],"int32"), True, ) 	 50803206 	 1000 	 0.2991917133331299 	 0.2979912757873535 	 0.15272855758666992 	 0.2832469940185547 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:18.737539 test begin: paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), 5, ) 	 50803210 	 1000 	 0.29944586753845215 	 0.2979769706726074 	 0.15282273292541504 	 0.2831764221191406 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:19.919942 test begin: paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([2, 5080321, 5],"int32"), True, ) 	 50803210 	 1000 	 0.29920434951782227 	 0.2979707717895508 	 0.1527092456817627 	 0.2831695079803467 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:21.101911 test begin: paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), 5, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), 5, ) 	 50803215 	 1000 	 0.299166202545166 	 0.2980775833129883 	 0.15269184112548828 	 0.2760591506958008 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:22.292870 test begin: paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), True, )
[Prof] paddle.Tensor.__rxor__ 	 paddle.Tensor.__rxor__(Tensor([3386881, 3, 5],"int32"), True, ) 	 50803215 	 1000 	 0.2991766929626465 	 0.2979888916015625 	 0.1527266502380371 	 0.2792930603027344 	 None 	 None 	 None 	 None 	 
2025-07-30 19:30:23.458296 test begin: paddle.Tensor.__sub__(Tensor([1, 1, 32768, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([1, 1, 32768, 32768],"float16"), 1, ) 	 1073741824 	 1000 	 3.1089658737182617 	 3.091632127761841 	 3.096064805984497 	 3.0680389404296875 	 3.297215223312378 	 0.05851912498474121 	 3.2473673820495605 	 6.4849853515625e-05 	 
2025-07-30 19:31:15.609319 test begin: paddle.Tensor.__sub__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), ) 	 52174848 	 1000 	 0.3044006824493408 	 0.31596803665161133 	 0.2938053607940674 	 0.30318784713745117 	 0.5361356735229492 	 0.4554917812347412 	 0.2738912105560303 	 0.23267793655395508 	 
2025-07-30 19:31:18.913565 test begin: paddle.Tensor.__sub__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), ) 	 52174848 	 1000 	 0.304455041885376 	 0.3159365653991699 	 0.29374051094055176 	 0.3031303882598877 	 0.5360615253448486 	 0.45548295974731445 	 0.273876428604126 	 0.23271465301513672 	 
2025-07-30 19:31:22.227578 test begin: paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), ) 	 53084160 	 1000 	 0.30588412284851074 	 0.3197062015533447 	 0.29530835151672363 	 0.3065981864929199 	 0.48598742485046387 	 0.4623727798461914 	 0.248260498046875 	 0.23621511459350586 	 
2025-07-30 19:31:25.508663 test begin: paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), ) 	 103809024 	 1000 	 0.4601631164550781 	 0.4619934558868408 	 0.45053982734680176 	 0.44355201721191406 	 0.48394346237182617 	 0.3041574954986572 	 0.4273099899291992 	 0.22295784950256348 	 
2025-07-30 19:31:29.711724 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 1551, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 1551, 32768],"float16"), 1, ) 	 101646336 	 1000 	 0.2982769012451172 	 0.30245375633239746 	 0.2893838882446289 	 0.2817728519439697 	 0.2984490394592285 	 0.05364418029785156 	 0.24753189086914062 	 6.413459777832031e-05 	 
2025-07-30 19:31:35.222050 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 32768, 1551],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 32768, 1551],"float16"), 1, ) 	 101646336 	 1000 	 0.2982664108276367 	 0.3105640411376953 	 0.2892441749572754 	 0.2816474437713623 	 0.29845309257507324 	 0.05316638946533203 	 0.24823951721191406 	 6.937980651855469e-05 	 
2025-07-30 19:31:40.441649 test begin: paddle.Tensor.__sub__(Tensor([2, 1, 32768, 32768],"float16"), 1, )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([2, 1, 32768, 32768],"float16"), 1, ) 	 2147483648 	 1000 	 6.2085862159729 	 6.182863473892212 	 6.198905944824219 	 3.1591546535491943 	 6.206376314163208 	 0.05530977249145508 	 6.156710147857666 	 7.319450378417969e-05 	 
2025-07-30 19:33:20.692119 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 1],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 1],"float32"), ) 	 161966688 	 1000 	 0.7149276733398438 	 0.7091569900512695 	 0.7052886486053467 	 0.6968216896057129 	 0.7576217651367188 	 0.47150707244873047 	 0.7009685039520264 	 0.3976309299468994 	 
2025-07-30 19:33:27.372083 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 1],"float32"), Tensor([26736, 3029, 2],"float32"), ) 	 242950032 	 1000 	 1.1746792793273926 	 2.5695722103118896 	 1.163855791091919 	 1.1836681365966797 	 2.391052722930908 	 2.4686107635498047 	 1.2217354774475098 	 1.2613885402679443 	 
2025-07-30 19:33:44.545874 test begin: paddle.Tensor.__sub__(Tensor([26736, 3029, 2],"float32"), Tensor([26736, 3029, 1],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 3029, 2],"float32"), Tensor([26736, 3029, 1],"float32"), ) 	 242950032 	 1000 	 1.1737689971923828 	 1.1974053382873535 	 1.163170337677002 	 1.1843907833099365 	 2.2277145385742188 	 2.4687387943267822 	 0.7585866451263428 	 1.2615132331848145 	 
2025-07-30 19:33:58.362483 test begin: paddle.Tensor.__sub__(Tensor([26736, 951, 2],"float32"), Tensor([26736, 951, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([26736, 951, 2],"float32"), Tensor([26736, 951, 2],"float32"), ) 	 101703744 	 1000 	 0.45061683654785156 	 0.4470789432525635 	 0.4408578872680664 	 0.43504977226257324 	 0.47722744941711426 	 0.29793596267700195 	 0.4200718402862549 	 0.22385287284851074 	 
2025-07-30 19:34:02.492867 test begin: paddle.Tensor.__sub__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), ) 	 51581952 	 1000 	 0.3000600337982178 	 0.31820201873779297 	 0.2892723083496094 	 0.2992284297943115 	 0.4789133071899414 	 0.4501502513885498 	 0.2446439266204834 	 0.23000264167785645 	 
2025-07-30 19:34:05.684556 test begin: paddle.Tensor.__sub__(Tensor([8387, 3029, 2],"float32"), Tensor([8387, 3029, 2],"float32"), )
[Prof] paddle.Tensor.__sub__ 	 paddle.Tensor.__sub__(Tensor([8387, 3029, 2],"float32"), Tensor([8387, 3029, 2],"float32"), ) 	 101616892 	 1000 	 0.4504997730255127 	 0.4510471820831299 	 0.4407162666320801 	 0.43446898460388184 	 0.47630810737609863 	 0.29770493507385254 	 0.4175283908843994 	 0.22597193717956543 	 
2025-07-30 19:34:09.775085 test begin: paddle.Tensor.__truediv__(Tensor([124, 128, 34, 96],"float32"), Tensor([124, 1, 34, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 128, 34, 96],"float32"), Tensor([124, 1, 34, 96],"float32"), ) 	 52210944 	 1000 	 0.3036332130432129 	 0.3240807056427002 	 0.2928483486175537 	 0.3114490509033203 	 0.814934492111206 	 1.8856613636016846 	 0.4163522720336914 	 0.3210592269897461 	 
2025-07-30 19:34:14.780887 test begin: paddle.Tensor.__truediv__(Tensor([124, 128, 96, 34],"float32"), Tensor([124, 1, 96, 34],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 128, 96, 34],"float32"), Tensor([124, 1, 96, 34],"float32"), ) 	 52210944 	 1000 	 0.3036153316497803 	 0.32408595085144043 	 0.29273247718811035 	 0.31128835678100586 	 0.8149292469024658 	 1.8856875896453857 	 0.4163546562194824 	 0.32103657722473145 	 
2025-07-30 19:34:19.777447 test begin: paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 1, 96, 96],"float32"), ) 	 52568064 	 1000 	 0.3034040927886963 	 0.3241283893585205 	 0.29251742362976074 	 0.3110229969024658 	 0.7714748382568359 	 1.8846921920776367 	 0.3941659927368164 	 0.3208599090576172 	 
2025-07-30 19:34:24.726209 test begin: paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 45, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([124, 45, 96, 96],"float32"), Tensor([124, 45, 96, 96],"float32"), ) 	 102850560 	 1000 	 0.45610547065734863 	 0.45510411262512207 	 0.4463045597076416 	 0.44284915924072266 	 1.063612937927246 	 2.1171176433563232 	 1.0019476413726807 	 0.4328000545501709 	 
2025-07-30 19:34:31.285863 test begin: paddle.Tensor.__truediv__(Tensor([128, 128, 33, 96],"float32"), Tensor([128, 1, 33, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 128, 33, 96],"float32"), Tensor([128, 1, 33, 96],"float32"), ) 	 52310016 	 1000 	 0.30396556854248047 	 0.3247368335723877 	 0.29308152198791504 	 0.3119392395019531 	 0.8103170394897461 	 1.8900396823883057 	 0.41401124000549316 	 0.32175183296203613 	 
2025-07-30 19:34:37.474519 test begin: paddle.Tensor.__truediv__(Tensor([128, 128, 96, 33],"float32"), Tensor([128, 1, 96, 33],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 128, 96, 33],"float32"), Tensor([128, 1, 96, 33],"float32"), ) 	 52310016 	 1000 	 0.3040037155151367 	 0.40735530853271484 	 0.28588390350341797 	 0.3114750385284424 	 0.8103885650634766 	 1.8901047706604004 	 0.41407227516174316 	 0.3217756748199463 	 
2025-07-30 19:34:42.916613 test begin: paddle.Tensor.__truediv__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 192, 22, 96],"float32"), Tensor([128, 1, 22, 96],"float32"), ) 	 52174848 	 1000 	 0.3036670684814453 	 0.32416296005249023 	 0.28567051887512207 	 0.3047637939453125 	 0.8247549533843994 	 1.8865776062011719 	 0.42139530181884766 	 0.3211405277252197 	 
2025-07-30 19:34:47.973345 test begin: paddle.Tensor.__truediv__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 192, 96, 22],"float32"), Tensor([128, 1, 96, 22],"float32"), ) 	 52174848 	 1000 	 0.3036472797393799 	 0.32413721084594727 	 0.28554224967956543 	 0.3048367500305176 	 0.82474684715271 	 1.8866245746612549 	 0.4213392734527588 	 0.3211390972137451 	 
2025-07-30 19:34:53.024474 test begin: paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 1, 96, 96],"float32"), ) 	 53084160 	 1000 	 0.3063473701477051 	 0.33211636543273926 	 0.28824329376220703 	 0.3077816963195801 	 0.7764327526092529 	 1.9003808498382568 	 0.3967154026031494 	 0.3235127925872803 	 
2025-07-30 19:34:59.309574 test begin: paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([128, 44, 96, 96],"float32"), Tensor([128, 44, 96, 96],"float32"), ) 	 103809024 	 1000 	 0.46029233932495117 	 0.4594235420227051 	 0.4505293369293213 	 0.4472630023956299 	 1.0724525451660156 	 2.136829376220703 	 1.0116586685180664 	 0.43680906295776367 	 
2025-07-30 19:35:05.991666 test begin: paddle.Tensor.__truediv__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([29, 192, 96, 96],"float32"), Tensor([29, 1, 96, 96],"float32"), ) 	 51581952 	 1000 	 0.2999448776245117 	 0.32047295570373535 	 0.2818186283111572 	 0.3011608123779297 	 0.7648012638092041 	 1.864438533782959 	 0.39074230194091797 	 0.31739282608032227 	 
2025-07-30 19:35:10.974130 test begin: paddle.Tensor.__truediv__(Tensor([44, 128, 96, 96],"float32"), Tensor([44, 1, 96, 96],"float32"), )
[Prof] paddle.Tensor.__truediv__ 	 paddle.Tensor.__truediv__(Tensor([44, 128, 96, 96],"float32"), Tensor([44, 1, 96, 96],"float32"), ) 	 52310016 	 1000 	 0.30350303649902344 	 0.32987117767333984 	 0.2854645252227783 	 0.30525898933410645 	 0.7735648155212402 	 1.8880677223205566 	 0.39516782760620117 	 0.32142186164855957 	 
2025-07-30 19:35:16.036663 test begin: paddle.Tensor.__xor__(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 141121, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4488942623138428 	 0.45040369033813477 	 0.4403395652770996 	 0.4364943504333496 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:18.906769 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 141121, 3, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4487628936767578 	 0.45038342475891113 	 0.4401416778564453 	 0.43776416778564453 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:21.797455 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 141121, 4, 1, 5, 2],"int16"), ) 	 203214240 	 1000 	 0.4489874839782715 	 0.4504210948944092 	 0.4402773380279541 	 0.4376959800720215 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:24.722438 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 188161, 1, 5, 2],"int16"), ) 	 203213880 	 1000 	 0.44846153259277344 	 0.4503507614135742 	 0.4399387836456299 	 0.43770384788513184 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:27.582607 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"bool"), ) 	 101607264 	 1000 	 0.11699509620666504 	 0.11748409271240234 	 0.10855388641357422 	 0.10474967956542969 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:29.260242 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 117601, 2],"int32"), ) 	 101607264 	 1000 	 0.45031070709228516 	 0.4489467144012451 	 0.44113779067993164 	 0.43289828300476074 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:31.367901 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 235201, 2],"int16"), ) 	 203213664 	 1000 	 0.449141263961792 	 0.45383214950561523 	 0.4404020309448242 	 0.43745970726013184 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:34.217778 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.16854476928710938 	 0.22879385948181152 	 0.15167689323425293 	 0.20653510093688965 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:37.117793 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3144218921661377 	 1.030022144317627 	 0.3048677444458008 	 0.4650285243988037 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:40.437325 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2965097427368164 	 0.3115403652191162 	 0.2867457866668701 	 0.2941601276397705 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:41.631426 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"bool"), ) 	 101608560 	 1000 	 0.11766767501831055 	 0.11956405639648438 	 0.1090090274810791 	 0.10350990295410156 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:43.272312 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 47041],"int32"), ) 	 101608560 	 1000 	 0.4503448009490967 	 0.4506969451904297 	 0.44161415100097656 	 0.43261218070983887 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:45.336659 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 94081],"int16"), ) 	 203214960 	 1000 	 0.44806933403015137 	 0.4730823040008545 	 0.4394712448120117 	 0.43773841857910156 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:48.236828 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 50807520 	 1000 	 0.1771855354309082 	 0.22880148887634277 	 0.16020894050598145 	 0.20660924911499023 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:49.367883 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"bool"), ) 	 101610720 	 1000 	 0.11769461631774902 	 0.11872696876525879 	 0.10185599327087402 	 0.09702014923095703 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:51.061578 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 50807520 	 1000 	 0.2956523895263672 	 0.3124568462371826 	 0.2857353687286377 	 0.29398131370544434 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:52.235080 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), Tensor([2, 3, 3, 3, 4, 23521, 5, 2],"int32"), ) 	 101610720 	 1000 	 0.4505882263183594 	 0.44667983055114746 	 0.4415760040283203 	 0.43369460105895996 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:54.204934 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 101610720 	 1000 	 0.3455471992492676 	 0.47829246520996094 	 0.33585500717163086 	 0.45787954330444336 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:56.039460 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), Tensor([2, 3, 3, 3, 4, 47041, 5, 2],"int16"), ) 	 203217120 	 1000 	 0.44850945472717285 	 0.450275182723999 	 0.43982863426208496 	 0.4377753734588623 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:58.920307 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"bool"), ) 	 101607480 	 1000 	 0.11765408515930176 	 0.1364727020263672 	 0.10755181312561035 	 0.10058355331420898 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:01.951177 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), Tensor([2, 3, 3, 3, 94081, 1, 5, 2],"int32"), ) 	 101607480 	 1000 	 0.4503133296966553 	 0.45097827911376953 	 0.4347076416015625 	 0.427426815032959 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:05.360822 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11766648292541504 	 0.1169896125793457 	 0.10211682319641113 	 0.09620213508605957 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:07.016178 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), Tensor([2, 3, 3, 70561, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45058655738830566 	 0.44675469398498535 	 0.4348421096801758 	 0.425168514251709 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:09.100165 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11765861511230469 	 0.11554789543151855 	 0.09697484970092773 	 0.09611749649047852 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:10.732998 test begin: paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), Tensor([2, 3, 70561, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45065736770629883 	 0.44685959815979004 	 0.4350466728210449 	 0.42719054222106934 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:12.764436 test begin: paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101607840 	 1000 	 0.11770129203796387 	 0.11864924430847168 	 0.10168194770812988 	 0.09576892852783203 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:14.403021 test begin: paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), Tensor([2, 70561, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101607840 	 1000 	 0.45069169998168945 	 0.4467477798461914 	 0.43478941917419434 	 0.42755627632141113 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:16.447220 test begin: paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"bool"), ) 	 101608560 	 1000 	 0.11768984794616699 	 0.11628127098083496 	 0.10900235176086426 	 0.10362458229064941 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:18.101575 test begin: paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), Tensor([47041, 3, 3, 3, 4, 1, 5, 2],"int32"), ) 	 101608560 	 1000 	 0.45034289360046387 	 0.4468059539794922 	 0.43466806411743164 	 0.42760133743286133 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:20.174762 test begin: paddle.Tensor.__xor__(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), )
[Prof] paddle.Tensor.__xor__ 	 paddle.Tensor.__xor__(Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), Tensor([94081, 3, 3, 3, 4, 1, 5, 2],"int16"), ) 	 203214960 	 1000 	 0.4486124515533447 	 0.4502837657928467 	 0.4399135112762451 	 0.43775320053100586 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:23.002655 test begin: paddle.Tensor.abs(Tensor([243360, 209],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([243360, 209],"float32"), ) 	 50862240 	 1000 	 0.29617810249328613 	 0.2982654571533203 	 0.2870907783508301 	 0.28505969047546387 	 0.45110273361206055 	 0.7438914775848389 	 0.39896702766418457 	 0.3800809383392334 	 
2025-07-30 19:36:26.474654 test begin: paddle.Tensor.abs(Tensor([282240, 181],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([282240, 181],"float32"), ) 	 51085440 	 1000 	 0.29727840423583984 	 0.29940199851989746 	 0.28817105293273926 	 0.28577327728271484 	 0.45264148712158203 	 0.7469890117645264 	 0.40068960189819336 	 0.38161492347717285 	 
2025-07-30 19:36:29.925926 test begin: paddle.Tensor.abs(Tensor([324000, 157],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([324000, 157],"float32"), ) 	 50868000 	 1000 	 0.29633021354675293 	 0.29823780059814453 	 0.28717827796936035 	 0.2848842144012451 	 0.45084071159362793 	 0.7438580989837646 	 0.3987693786621094 	 0.3800520896911621 	 
2025-07-30 19:36:33.352225 test begin: paddle.Tensor.abs(Tensor([635041, 80],"float32"), )
[Prof] paddle.Tensor.abs 	 paddle.Tensor.abs(Tensor([635041, 80],"float32"), ) 	 50803280 	 1000 	 0.29573726654052734 	 1.3835484981536865 	 0.28656768798828125 	 0.283170223236084 	 0.4503498077392578 	 0.7431232929229736 	 0.39362478256225586 	 0.3796820640563965 	 
2025-07-30 19:36:40.683668 test begin: paddle.Tensor.add(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.add 	 paddle.Tensor.add(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.4503514766693115 	 0.4499490261077881 	 0.4407539367675781 	 0.434556245803833 	 0.48371338844299316 	 0.07250475883483887 	 0.42707324028015137 	 4.2438507080078125e-05 	 
2025-07-30 19:36:44.574102 test begin: paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 2048, 24807],"bool"), ) 	 508047360 	 1000 	 0.4652211666107178 	 0.5071783065795898 	 0.23770737648010254 	 0.25913476943969727 	 None 	 None 	 None 	 None 	 
2025-07-30 19:36:52.539180 test begin: paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 1, 24807, 2048],"bool"), ) 	 508047360 	 1000 	 0.4651515483856201 	 0.5072050094604492 	 0.23765349388122559 	 0.2591562271118164 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:00.462184 test begin: paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([10, 13, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.49860048294067383 	 0.5460689067840576 	 0.2547609806060791 	 0.27897000312805176 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:10.501454 test begin: paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([130, 1, 2048, 2048],"bool"), ) 	 545259520 	 1000 	 0.4985368251800537 	 0.5456695556640625 	 0.2547309398651123 	 0.2788267135620117 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:18.939999 test begin: paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([1590, 10, 32000],"bool"), ) 	 508800000 	 1000 	 0.4671797752380371 	 0.508662223815918 	 0.23871350288391113 	 0.2599008083343506 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:26.946874 test begin: paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 10, 2540161],"bool"), ) 	 508032200 	 1000 	 0.4681704044342041 	 0.5081729888916016 	 0.2391796112060547 	 0.25963807106018066 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:34.761442 test begin: paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 100, 256000],"bool"), ) 	 512000000 	 1000 	 0.4683246612548828 	 0.5158481597900391 	 0.2392880916595459 	 0.26357245445251465 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:42.768927 test begin: paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([20, 794, 32000],"bool"), ) 	 508160000 	 1000 	 0.46638035774230957 	 0.5075085163116455 	 0.2382831573486328 	 0.25931692123413086 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:50.578836 test begin: paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), )
[Prof] paddle.Tensor.all 	 paddle.Tensor.all(Tensor([200, 10, 256000],"bool"), ) 	 512000000 	 1000 	 0.46829748153686523 	 0.5158607959747314 	 0.23926401138305664 	 0.26360392570495605 	 None 	 None 	 None 	 None 	 
2025-07-30 19:37:58.626392 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803240 	 1000 	 0.45389533042907715 	 0.47198915481567383 	 0.44209837913513184 	 0.4575183391571045 	 1.316431999206543 	 1.6168601512908936 	 0.3362917900085449 	 0.3302605152130127 	 
2025-07-30 19:38:03.531014 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803240 	 1000 	 0.5139260292053223 	 0.18381643295288086 	 0.501276969909668 	 0.16699910163879395 	 1.3877124786376953 	 1.530625820159912 	 0.35448765754699707 	 0.31269359588623047 	 
2025-07-30 19:38:08.111094 test begin: paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803240 	 1000 	 0.15191268920898438 	 0.15287446975708008 	 0.07759571075439453 	 0.0780637264251709 	 1.0445969104766846 	 1.2482578754425049 	 0.21369266510009766 	 0.21251463890075684 	 
2025-07-30 19:38:12.797690 test begin: paddle.Tensor.amax(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, ) 	 50803230 	 1000 	 0.45381760597229004 	 0.4752373695373535 	 0.4419984817504883 	 0.45594024658203125 	 1.3163750171661377 	 1.6169586181640625 	 0.3363041877746582 	 0.3303093910217285 	 
2025-07-30 19:38:17.952685 test begin: paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, ) 	 50803224 	 1000 	 6.301739454269409 	 0.17168855667114258 	 3.220144271850586 	 0.08768081665039062 	 5.7264604568481445 	 1.341461181640625 	 1.1687958240509033 	 0.22838282585144043 	 
2025-07-30 19:38:32.393620 test begin: paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, ) 	 50803224 	 1000 	 0.15192055702209473 	 0.1529407501220703 	 0.07760143280029297 	 0.07813644409179688 	 1.044579029083252 	 1.248016595840454 	 0.21362876892089844 	 0.2124769687652588 	 
2025-07-30 19:38:37.040353 test begin: paddle.Tensor.amax(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, ) 	 50803224 	 1000 	 0.17434477806091309 	 0.15472197532653809 	 0.0890660285949707 	 0.07903409004211426 	 1.066206932067871 	 1.2750887870788574 	 0.21808314323425293 	 0.21707534790039062 	 
2025-07-30 19:38:41.940805 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, ) 	 50803230 	 1000 	 0.2084512710571289 	 0.2178666591644287 	 0.1968390941619873 	 0.20329022407531738 	 1.2640199661254883 	 1.5259120464324951 	 0.3230304718017578 	 0.31175708770751953 	 
2025-07-30 19:38:46.149402 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, ) 	 50803230 	 1000 	 0.15189075469970703 	 0.15288352966308594 	 0.0775899887084961 	 0.07811760902404785 	 1.0444614887237549 	 1.2479333877563477 	 0.21364331245422363 	 0.21247482299804688 	 
2025-07-30 19:38:49.564177 test begin: paddle.Tensor.amax(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803260 	 1000 	 0.4538440704345703 	 0.47193121910095215 	 0.44028282165527344 	 0.45748376846313477 	 1.3163175582885742 	 1.6168129444122314 	 0.3363051414489746 	 0.33027219772338867 	 
2025-07-30 19:38:54.487920 test begin: paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803260 	 1000 	 0.5138506889343262 	 0.18374276161193848 	 0.5011014938354492 	 0.16935253143310547 	 1.3876891136169434 	 1.5304968357086182 	 0.3544487953186035 	 0.31267619132995605 	 
2025-07-30 19:38:59.094370 test begin: paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amax 	 paddle.Tensor.amax(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803260 	 1000 	 0.15191984176635742 	 0.15286946296691895 	 0.07761549949645996 	 0.07809853553771973 	 1.0446088314056396 	 1.247945785522461 	 0.21370673179626465 	 0.21247315406799316 	 
2025-07-30 19:39:02.521404 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803240 	 1000 	 0.4538850784301758 	 0.47202229499816895 	 0.4408562183380127 	 0.4572787284851074 	 1.3164427280426025 	 1.6168015003204346 	 0.3363780975341797 	 0.3302445411682129 	 
2025-07-30 19:39:07.379511 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803240 	 1000 	 0.5138416290283203 	 0.18378353118896484 	 0.5008440017700195 	 0.16927599906921387 	 1.3876316547393799 	 1.5303905010223389 	 0.3544294834136963 	 0.3126535415649414 	 
2025-07-30 19:39:11.986300 test begin: paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([1270081, 2, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803240 	 1000 	 0.15189075469970703 	 0.15289306640625 	 0.07759523391723633 	 0.0781102180480957 	 1.0446932315826416 	 1.248037576675415 	 0.213623046875 	 0.21247363090515137 	 
2025-07-30 19:39:15.446681 test begin: paddle.Tensor.amin(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 1693441, 5],"float32"), axis=-1, keepdim=True, ) 	 50803230 	 1000 	 0.4537653923034668 	 0.47905874252319336 	 0.44150447845458984 	 0.4570004940032959 	 1.316270112991333 	 1.6167852878570557 	 0.33628034591674805 	 0.33031749725341797 	 
2025-07-30 19:39:21.703625 test begin: paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=2, keepdim=True, ) 	 50803224 	 1000 	 6.301707744598389 	 0.17172002792358398 	 3.2202258110046387 	 0.08771181106567383 	 5.726313829421997 	 1.3414466381072998 	 1.168691635131836 	 0.2283937931060791 	 
2025-07-30 19:39:38.572416 test begin: paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 2116801, 4],"float32"), axis=None, keepdim=False, ) 	 50803224 	 1000 	 0.1519029140472412 	 0.152909517288208 	 0.07759475708007812 	 0.07810091972351074 	 1.044614553451538 	 1.2479290962219238 	 0.21367406845092773 	 0.2124624252319336 	 
2025-07-30 19:39:42.862895 test begin: paddle.Tensor.amin(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 4, 2116801],"float32"), axis=-1, keepdim=True, ) 	 50803224 	 1000 	 0.17434406280517578 	 0.15466690063476562 	 0.08906793594360352 	 0.07900023460388184 	 1.0662689208984375 	 1.275083303451538 	 0.2180490493774414 	 0.21708440780639648 	 
2025-07-30 19:39:46.398916 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=2, keepdim=True, ) 	 50803230 	 1000 	 0.20846056938171387 	 0.21775317192077637 	 0.18836164474487305 	 0.2031574249267578 	 1.2638001441955566 	 1.5256717205047607 	 0.32292938232421875 	 0.31173133850097656 	 
2025-07-30 19:39:50.600123 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 2, 5, 1693441],"float32"), axis=None, keepdim=False, ) 	 50803230 	 1000 	 0.1519312858581543 	 0.1528794765472412 	 0.07759928703308105 	 0.07809233665466309 	 1.0445804595947266 	 1.2480545043945312 	 0.21367716789245605 	 0.21249175071716309 	 
2025-07-30 19:39:54.037375 test begin: paddle.Tensor.amin(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 4, 5],"float32"), axis=-1, keepdim=True, ) 	 50803260 	 1000 	 0.453779935836792 	 0.47185301780700684 	 0.4337756633758545 	 0.45023202896118164 	 1.3162808418273926 	 1.6167430877685547 	 0.3363215923309326 	 0.330244779586792 	 
2025-07-30 19:39:58.875708 test begin: paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=2, keepdim=True, ) 	 50803260 	 1000 	 0.5138587951660156 	 0.18378615379333496 	 0.49282217025756836 	 0.1621861457824707 	 1.387693166732788 	 1.530601978302002 	 0.35448694229125977 	 0.3127279281616211 	 
2025-07-30 19:40:03.501241 test begin: paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, )
[Prof] paddle.Tensor.amin 	 paddle.Tensor.amin(Tensor([3, 846721, 5, 4],"float32"), axis=None, keepdim=False, ) 	 50803260 	 1000 	 0.15191173553466797 	 0.1529233455657959 	 0.07760024070739746 	 0.07811617851257324 	 1.0445213317871094 	 1.2479791641235352 	 0.2136363983154297 	 0.21240782737731934 	 
2025-07-30 19:40:06.935403 test begin: paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1379, 192, 192],"bool"), axis=list[2,3,], ) 	 508354560 	 1000 	 0.4961705207824707 	 0.551720142364502 	 0.2535269260406494 	 0.5295219421386719 	 None 	 None 	 None 	 None 	 
2025-07-30 19:40:15.018222 test begin: paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 1501, 184, 184],"bool"), axis=list[2,3,], ) 	 508178560 	 1000 	 0.5064201354980469 	 0.5692257881164551 	 0.2587730884552002 	 0.5469009876251221 	 None 	 None 	 None 	 None 	 
2025-07-30 19:40:25.285135 test begin: paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 184, 921],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6382346153259277 	 0.5277979373931885 	 0.32611680030822754 	 0.5130641460418701 	 None 	 None 	 None 	 None 	 
2025-07-30 19:40:33.282075 test begin: paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 192, 883],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5425982475280762 	 0.5255296230316162 	 0.2772865295410156 	 0.5108330249786377 	 None 	 None 	 None 	 None 	 
2025-07-30 19:40:41.513066 test begin: paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 883, 192],"bool"), axis=list[2,3,], ) 	 508608000 	 1000 	 0.5425117015838623 	 0.5254960060119629 	 0.277209997177124 	 0.5108911991119385 	 None 	 None 	 None 	 None 	 
2025-07-30 19:40:49.509712 test begin: paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([10, 300, 921, 184],"bool"), axis=list[2,3,], ) 	 508392000 	 1000 	 0.6382179260253906 	 0.5278441905975342 	 0.3261287212371826 	 0.5131769180297852 	 None 	 None 	 None 	 None 	 
2025-07-30 19:40:57.592369 test begin: paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([100, 300, 136, 136],"bool"), axis=list[2,3,], ) 	 554880000 	 1000 	 0.5383942127227783 	 0.7137515544891357 	 0.5261497497558594 	 0.6990237236022949 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:08.624765 test begin: paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 1374, 136, 136],"bool"), axis=list[2,3,], ) 	 508270080 	 1000 	 0.4949367046356201 	 0.6545946598052979 	 0.48270487785339355 	 0.6399881839752197 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:16.805591 test begin: paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 136, 623],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6205108165740967 	 0.5372529029846191 	 0.3170747756958008 	 0.5226185321807861 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:24.839617 test begin: paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([20, 300, 623, 136],"bool"), axis=list[2,3,], ) 	 508368000 	 1000 	 0.6204845905303955 	 0.5349676609039307 	 0.31703925132751465 	 0.5203258991241455 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:33.680493 test begin: paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([50, 300, 192, 192],"bool"), axis=list[2,3,], ) 	 552960000 	 1000 	 0.5369925498962402 	 0.5991034507751465 	 0.27438855171203613 	 0.5770382881164551 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:42.254942 test begin: paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], )
[Prof] paddle.Tensor.any 	 paddle.Tensor.any(Tensor([60, 300, 184, 184],"bool"), axis=list[2,3,], ) 	 609408000 	 1000 	 0.6039068698883057 	 0.6799850463867188 	 0.30858778953552246 	 0.6649384498596191 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:51.848791 test begin: paddle.Tensor.argmax(Tensor([13, 498, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([13, 498, 8000],"float32"), axis=2, ) 	 51792000 	 1000 	 0.278489351272583 	 0.1698136329650879 	 0.26794910430908203 	 0.15580964088439941 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:53.136202 test begin: paddle.Tensor.argmax(Tensor([14, 457, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([14, 457, 8000],"float32"), axis=2, ) 	 51184000 	 1000 	 0.27522993087768555 	 0.16800642013549805 	 0.2648122310638428 	 0.1539459228515625 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:54.403596 test begin: paddle.Tensor.argmax(Tensor([14, 477, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([14, 477, 8000],"float32"), axis=2, ) 	 53424000 	 1000 	 0.2869863510131836 	 0.17361116409301758 	 0.2766458988189697 	 0.15964889526367188 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:55.712154 test begin: paddle.Tensor.argmax(Tensor([30, 212, 8000],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 212, 8000],"float32"), axis=2, ) 	 50880000 	 1000 	 0.2735869884490967 	 0.16736578941345215 	 0.2631525993347168 	 0.15333104133605957 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:56.967956 test begin: paddle.Tensor.argmax(Tensor([30, 457, 3706],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 457, 3706],"float32"), axis=2, ) 	 50809260 	 1000 	 0.34847307205200195 	 0.16276264190673828 	 0.33713483810424805 	 0.14875030517578125 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:58.308896 test begin: paddle.Tensor.argmax(Tensor([30, 477, 3551],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 477, 3551],"float32"), axis=2, ) 	 50814810 	 1000 	 0.35868382453918457 	 0.167402982711792 	 0.3484344482421875 	 0.15337204933166504 	 None 	 None 	 None 	 None 	 
2025-07-30 19:41:59.651389 test begin: paddle.Tensor.argmax(Tensor([30, 498, 3401],"float32"), axis=2, )
[Prof] paddle.Tensor.argmax 	 paddle.Tensor.argmax(Tensor([30, 498, 3401],"float32"), axis=2, ) 	 50810940 	 1000 	 0.37011027336120605 	 0.16520214080810547 	 0.3592076301574707 	 0.15117430686950684 	 None 	 None 	 None 	 None 	 
2025-07-30 19:42:01.010023 test begin: paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 388, 4096],"float32"), "float32", ) 	 508559360 	 1000 	 0.0033159255981445312 	 0.002236604690551758 	 6.9141387939453125e-06 	 1.5497207641601562e-05 	 0.028937101364135742 	 0.04704785346984863 	 2.4080276489257812e-05 	 4.410743713378906e-05 	 
2025-07-30 19:42:17.509934 test begin: paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 32, 4096, 388],"float32"), "float32", ) 	 508559360 	 1000 	 0.0032722949981689453 	 0.0022470951080322266 	 8.58306884765625e-06 	 1.6689300537109375e-05 	 0.02891683578491211 	 0.04669785499572754 	 2.002716064453125e-05 	 6.365776062011719e-05 	 
2025-07-30 19:42:33.827528 test begin: paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([10, 4, 4096, 4096],"float32"), "float32", ) 	 671088640 	 1000 	 0.003231048583984375 	 0.0041484832763671875 	 7.152557373046875e-06 	 5.91278076171875e-05 	 0.028939485549926758 	 0.051181793212890625 	 2.8848648071289062e-05 	 6.4849853515625e-05 	 
2025-07-30 19:42:55.261468 test begin: paddle.Tensor.astype(Tensor([100352, 1013],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([100352, 1013],"bfloat16"), "float32", ) 	 101656576 	 1000 	 0.48181843757629395 	 0.5592207908630371 	 0.4680476188659668 	 0.5450241565704346 	 0.4504997730255127 	 0.45385313034057617 	 0.395829439163208 	 0.37601685523986816 	 
2025-07-30 19:43:00.547109 test begin: paddle.Tensor.astype(Tensor([1013, 100352],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([1013, 100352],"bfloat16"), "float32", ) 	 101656576 	 1000 	 0.481781005859375 	 0.5588688850402832 	 0.46712684631347656 	 0.5452890396118164 	 0.45047593116760254 	 0.45382046699523926 	 0.3956422805786133 	 0.37592244148254395 	 
2025-07-30 19:43:05.754518 test begin: paddle.Tensor.astype(Tensor([12404, 8192],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([12404, 8192],"bfloat16"), "float32", ) 	 101613568 	 1000 	 0.4819159507751465 	 0.558666467666626 	 0.46808362007141113 	 0.5450570583343506 	 0.4512360095977783 	 0.4536724090576172 	 0.39591145515441895 	 0.37541723251342773 	 
2025-07-30 19:43:10.948019 test begin: paddle.Tensor.astype(Tensor([8192, 12404],"bfloat16"), "float32", )
[Prof] paddle.Tensor.astype 	 paddle.Tensor.astype(Tensor([8192, 12404],"bfloat16"), "float32", ) 	 101613568 	 1000 	 0.48178672790527344 	 0.5586578845977783 	 0.4594717025756836 	 0.5379440784454346 	 0.45108461380004883 	 0.45363283157348633 	 0.3866236209869385 	 0.35492491722106934 	 
2025-07-30 19:43:16.284534 test begin: paddle.Tensor.atanh(Tensor([1, 16934401, 3],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2971363067626953 	 0.2982773780822754 	 0.28122997283935547 	 0.28122711181640625 	 0.45058417320251465 	 1.6228783130645752 	 0.3893563747406006 	 0.3317255973815918 	 
2025-07-30 19:43:20.606055 test begin: paddle.Tensor.atanh(Tensor([1, 2, 12700801],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.444305419921875 	 0.40779685974121094 	 0.42790842056274414 	 0.3909261226654053 	 0.448244571685791 	 1.62095046043396 	 0.3872513771057129 	 0.3314554691314697 	 
2025-07-30 19:43:24.596427 test begin: paddle.Tensor.atanh(Tensor([1, 2, 25401601],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29718518257141113 	 0.3004322052001953 	 0.27858829498291016 	 0.28109240531921387 	 0.4504683017730713 	 1.6228892803192139 	 0.38879942893981934 	 0.3317549228668213 	 
2025-07-30 19:43:28.931816 test begin: paddle.Tensor.atanh(Tensor([1, 8467201, 3],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([1, 8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.44424891471862793 	 0.40779924392700195 	 0.42858433723449707 	 0.3907921314239502 	 0.44841480255126953 	 1.6211154460906982 	 0.3878004550933838 	 0.3314037322998047 	 
2025-07-30 19:43:32.918711 test begin: paddle.Tensor.atanh(Tensor([2, 12700801],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.4442296028137207 	 0.40779662132263184 	 0.42850780487060547 	 0.3905222415924072 	 0.4482600688934326 	 1.6218738555908203 	 0.38764238357543945 	 0.33138251304626465 	 
2025-07-30 19:43:40.251534 test begin: paddle.Tensor.atanh(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.4442412853240967 	 0.4077911376953125 	 0.4352109432220459 	 0.3901174068450928 	 0.44830894470214844 	 1.6211771965026855 	 0.3857152462005615 	 0.33147573471069336 	 
2025-07-30 19:43:44.234433 test begin: paddle.Tensor.atanh(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.44420504570007324 	 0.42581939697265625 	 0.43507838249206543 	 0.39365196228027344 	 0.448317289352417 	 1.6211225986480713 	 0.39670467376708984 	 0.3314025402069092 	 
2025-07-30 19:43:50.268266 test begin: paddle.Tensor.atanh(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.Tensor.atanh 	 paddle.Tensor.atanh(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.2971675395965576 	 0.29819798469543457 	 0.2878611087799072 	 0.28710293769836426 	 0.45043516159057617 	 1.6229593753814697 	 0.3976764678955078 	 0.3317580223083496 	 
2025-07-30 19:43:54.573724 test begin: paddle.Tensor.bmm(Tensor([1, 16934401, 3],"float32"), Tensor([1, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 16934401, 3],"float32"), Tensor([1, 3, 2],"float32"), ) 	 50803209 	 1000 	 1.781437873840332 	 1.781261920928955 	 0.10701775550842285 	 0.10698699951171875 	 4.1444783210754395 	 4.1408257484436035 	 0.22330141067504883 	 0.22104430198669434 	 
2025-07-30 19:44:07.857046 test begin: paddle.Tensor.bmm(Tensor([1, 170476, 299],"float32"), Tensor([1, 299, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 170476, 299],"float32"), Tensor([1, 299, 2],"float32"), ) 	 50972922 	 1000 	 0.2394554615020752 	 0.2395496368408203 	 0.20905470848083496 	 0.2124464511871338 	 0.4225945472717285 	 0.42299866676330566 	 0.14372801780700684 	 0.1439213752746582 	 
2025-07-30 19:44:10.021967 test begin: paddle.Tensor.bmm(Tensor([1, 179876, 283],"float32"), Tensor([1, 283, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 179876, 283],"float32"), Tensor([1, 283, 2],"float32"), ) 	 50905474 	 1000 	 0.24106144905090332 	 0.24118733406066895 	 0.21579289436340332 	 0.21262216567993164 	 0.4178152084350586 	 0.41807007789611816 	 0.14230799674987793 	 0.14233016967773438 	 
2025-07-30 19:44:12.201142 test begin: paddle.Tensor.bmm(Tensor([1, 191277, 266],"float32"), Tensor([1, 266, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([1, 191277, 266],"float32"), Tensor([1, 266, 2],"float32"), ) 	 50880214 	 1000 	 0.23390769958496094 	 0.23404645919799805 	 0.20872783660888672 	 0.20558762550354004 	 0.42108678817749023 	 0.42118310928344727 	 0.14334893226623535 	 0.14321231842041016 	 
2025-07-30 19:44:14.383207 test begin: paddle.Tensor.bmm(Tensor([100, 170476, 3],"float32"), Tensor([100, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([100, 170476, 3],"float32"), Tensor([100, 3, 2],"float32"), ) 	 51143400 	 1000 	 4.852464914321899 	 4.85188627243042 	 4.832252502441406 	 4.828095197677612 	 38.5385901927948 	 38.53675842285156 	 19.692612171173096 	 19.69155526161194 	 
2025-07-30 19:45:42.706242 test begin: paddle.Tensor.bmm(Tensor([89, 191277, 3],"float32"), Tensor([89, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([89, 191277, 3],"float32"), Tensor([89, 3, 2],"float32"), ) 	 51071493 	 1000 	 4.8431103229522705 	 4.844048738479614 	 4.830926895141602 	 4.828134536743164 	 42.6391122341156 	 42.64029002189636 	 21.788097620010376 	 21.789496660232544 	 
2025-07-30 19:47:19.861865 test begin: paddle.Tensor.bmm(Tensor([95, 179876, 3],"float32"), Tensor([95, 3, 2],"float32"), )
[Prof] paddle.Tensor.bmm 	 paddle.Tensor.bmm(Tensor([95, 179876, 3],"float32"), Tensor([95, 3, 2],"float32"), ) 	 51265230 	 1000 	 4.8653059005737305 	 4.869224786758423 	 4.851452112197876 	 4.836925268173218 	 40.409310817718506 	 40.41083645820618 	 20.64932656288147 	 20.650580644607544 	 
2025-07-30 19:48:53.959710 test begin: paddle.Tensor.cast(Tensor([128256, 793],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([128256, 793],"float16"), Dtype(float16), ) 	 101707008 	 1000 	 0.3071258068084717 	 0.001966714859008789 	 0.15691256523132324 	 1.6450881958007812e-05 	 0.3079719543457031 	 0.046532630920410156 	 0.15729641914367676 	 4.506111145019531e-05 	 combined
2025-07-30 19:48:58.473721 test begin: paddle.Tensor.cast(Tensor([152064, 669],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([152064, 669],"float16"), Dtype(float16), ) 	 101730816 	 1000 	 0.31473588943481445 	 0.0019769668579101562 	 0.16080498695373535 	 1.7404556274414062e-05 	 0.31461262702941895 	 0.05288267135620117 	 0.16070103645324707 	 5.173683166503906e-05 	 combined
2025-07-30 19:49:02.997037 test begin: paddle.Tensor.cast(Tensor([24807, 4096],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([24807, 4096],"float16"), Dtype(float16), ) 	 101609472 	 1000 	 0.3100881576538086 	 0.0019326210021972656 	 0.2990753650665283 	 1.6689300537109375e-05 	 0.31015992164611816 	 0.05359697341918945 	 0.25668978691101074 	 6.246566772460938e-05 	 combined
2025-07-30 19:49:07.493279 test begin: paddle.Tensor.cast(Tensor([28351, 3584],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([28351, 3584],"float16"), Dtype(float16), ) 	 101609984 	 1000 	 0.31440162658691406 	 0.0019736289978027344 	 0.16062688827514648 	 1.5735626220703125e-05 	 0.31429553031921387 	 0.04550790786743164 	 0.1605699062347412 	 3.0279159545898438e-05 	 combined
2025-07-30 19:49:12.882821 test begin: paddle.Tensor.cast(Tensor([3584, 28351],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([3584, 28351],"float16"), Dtype(float16), ) 	 101609984 	 1000 	 0.3143494129180908 	 0.0019423961639404297 	 0.16064453125 	 1.5974044799804688e-05 	 0.3143131732940674 	 0.045828819274902344 	 0.16056346893310547 	 4.410743713378906e-05 	 combined
2025-07-30 19:49:17.387609 test begin: paddle.Tensor.cast(Tensor([669, 152064],"float16"), Dtype(float16), )
[Prof] paddle.Tensor.cast 	 paddle.Tensor.cast(Tensor([669, 152064],"float16"), Dtype(float16), ) 	 101730816 	 1000 	 0.31473875045776367 	 0.001973867416381836 	 0.16082239151000977 	 1.7404556274414062e-05 	 0.31464219093322754 	 0.04526257514953613 	 0.16072487831115723 	 2.7418136596679688e-05 	 combined
2025-07-30 19:49:21.759158 test begin: paddle.Tensor.ceil(Tensor([1, 50803201],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([1, 50803201],"float32"), ) 	 50803201 	 1000 	 0.2957897186279297 	 0.29780030250549316 	 0.28688502311706543 	 0.2867310047149658 	 0.13416743278503418 	 0.13424062728881836 	 0.08471369743347168 	 0.06850051879882812 	 
2025-07-30 19:49:24.246267 test begin: paddle.Tensor.ceil(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29584288597106934 	 0.2978334426879883 	 0.2870523929595947 	 0.2867100238800049 	 0.1341414451599121 	 0.13414716720581055 	 0.08123517036437988 	 0.0679316520690918 	 
2025-07-30 19:49:26.778276 test begin: paddle.Tensor.ceil(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2958059310913086 	 0.297804594039917 	 0.28696346282958984 	 0.2867550849914551 	 0.13426613807678223 	 0.13418912887573242 	 0.08433127403259277 	 0.06857514381408691 	 
2025-07-30 19:49:29.262846 test begin: paddle.Tensor.ceil(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29580020904541016 	 0.29779672622680664 	 0.28703927993774414 	 0.2866485118865967 	 0.1341266632080078 	 0.13416671752929688 	 0.084930419921875 	 0.06851911544799805 	 
2025-07-30 19:49:31.746780 test begin: paddle.Tensor.ceil(Tensor([25401601, 2],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([25401601, 2],"float32"), ) 	 50803202 	 1000 	 0.2957601547241211 	 0.2979092597961426 	 0.28700757026672363 	 0.28693199157714844 	 0.13417506217956543 	 0.13421106338500977 	 0.08478713035583496 	 0.06922650337219238 	 
2025-07-30 19:49:34.226261 test begin: paddle.Tensor.ceil(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.295820951461792 	 0.31658029556274414 	 0.28690433502197266 	 0.2864723205566406 	 0.1341266632080078 	 0.1344594955444336 	 0.08475112915039062 	 0.05370187759399414 	 
2025-07-30 19:49:38.648051 test begin: paddle.Tensor.ceil(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.ceil 	 paddle.Tensor.ceil(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29580187797546387 	 0.2978219985961914 	 0.2800791263580322 	 0.28069114685058594 	 0.13414382934570312 	 0.1343691349029541 	 0.07552933692932129 	 0.06009554862976074 	 
2025-07-30 19:49:41.221288 test begin: paddle.Tensor.chunk(Tensor([1034, 32, 64, 48],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([1034, 32, 64, 48],"float16"), 2, axis=1, ) 	 101646336 	 1000 	 0.45819878578186035 	 0.006749391555786133 	 0.44255995750427246 	 2.2411346435546875e-05 	 0.3078029155731201 	 0.45259642601013184 	 0.2530934810638428 	 0.36793041229248047 	 
2025-07-30 19:49:46.319885 test begin: paddle.Tensor.chunk(Tensor([128, 2068, 192],"float32"), 3, axis=-1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([128, 2068, 192],"float32"), 3, axis=-1, ) 	 50823168 	 1000 	 0.3442356586456299 	 0.007750034332275391 	 0.32868170738220215 	 1.9550323486328125e-05 	 0.3092663288116455 	 0.3086831569671631 	 0.25236010551452637 	 0.2046642303466797 	 
2025-07-30 19:49:48.951977 test begin: paddle.Tensor.chunk(Tensor([512, 32, 130, 48],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 130, 48],"float16"), 2, axis=1, ) 	 102236160 	 1000 	 0.45527148246765137 	 0.006772756576538086 	 0.4412226676940918 	 2.002716064453125e-05 	 0.313509464263916 	 0.45415735244750977 	 0.25913238525390625 	 0.36498212814331055 	 
2025-07-30 19:49:53.953766 test begin: paddle.Tensor.chunk(Tensor([512, 32, 64, 49],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 64, 49],"float32"), 2, axis=1, ) 	 51380224 	 1000 	 0.3508751392364502 	 0.006696224212646484 	 0.3366420269012451 	 2.002716064453125e-05 	 0.3153359889984131 	 0.31348180770874023 	 0.2610485553741455 	 0.23001551628112793 	 
2025-07-30 19:49:56.594747 test begin: paddle.Tensor.chunk(Tensor([512, 32, 64, 97],"float16"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 64, 97],"float16"), 2, axis=1, ) 	 101711872 	 1000 	 0.454923152923584 	 0.006799221038818359 	 0.4406118392944336 	 2.0742416381835938e-05 	 0.31091809272766113 	 0.4521450996398926 	 0.25570106506347656 	 0.36721110343933105 	 
2025-07-30 19:50:01.517585 test begin: paddle.Tensor.chunk(Tensor([512, 32, 65, 48],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([512, 32, 65, 48],"float32"), 2, axis=1, ) 	 51118080 	 1000 	 0.35126161575317383 	 0.006745815277099609 	 0.3359408378601074 	 1.9073486328125e-05 	 0.31349706649780273 	 0.3117830753326416 	 0.25944018363952637 	 0.22617149353027344 	 
2025-07-30 19:50:04.133536 test begin: paddle.Tensor.chunk(Tensor([517, 32, 64, 48],"float32"), 2, axis=1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([517, 32, 64, 48],"float32"), 2, axis=1, ) 	 50823168 	 1000 	 0.3492698669433594 	 0.011783361434936523 	 0.33481884002685547 	 2.384185791015625e-05 	 0.30779290199279785 	 0.3124082088470459 	 0.2423994541168213 	 0.19807124137878418 	 
2025-07-30 19:50:06.782043 test begin: paddle.Tensor.chunk(Tensor([85, 3136, 192],"float32"), 3, axis=-1, )
[Prof] paddle.Tensor.chunk 	 paddle.Tensor.chunk(Tensor([85, 3136, 192],"float32"), 3, axis=-1, ) 	 51179520 	 1000 	 0.3454611301422119 	 0.007734060287475586 	 0.32964205741882324 	 1.9311904907226562e-05 	 0.31130146980285645 	 0.31093788146972656 	 0.25127458572387695 	 0.19472455978393555 	 
2025-07-30 19:50:09.326994 test begin: paddle.Tensor.clip(Tensor([1, 386, 65856, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 386, 65856, 2],"float32"), 0, ) 	 50840832 	 1000 	 0.2958948612213135 	 0.3055257797241211 	 0.2787754535675049 	 0.2848012447357178 	 0.4509906768798828 	 0.5962049961090088 	 0.3970675468444824 	 0.20318341255187988 	 
2025-07-30 19:50:12.806611 test begin: paddle.Tensor.clip(Tensor([1, 400, 63505, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 400, 63505, 2],"float32"), 0, ) 	 50804000 	 1000 	 0.29550600051879883 	 0.2978997230529785 	 0.2702000141143799 	 0.27755212783813477 	 0.45043420791625977 	 0.5956015586853027 	 0.3882291316986084 	 0.20303869247436523 	 
2025-07-30 19:50:16.452166 test begin: paddle.Tensor.clip(Tensor([1, 400, 65856, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([1, 400, 65856, 2],"float32"), 0, ) 	 52684800 	 1000 	 0.3065674304962158 	 0.769561767578125 	 0.28119492530822754 	 0.28839778900146484 	 0.46707868576049805 	 0.6164760589599609 	 0.4036862850189209 	 0.2101602554321289 	 
2025-07-30 19:50:21.652468 test begin: paddle.Tensor.clip(Tensor([2100, 12096, 3],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2100, 12096, 3],"float32"), 0, ) 	 76204800 	 1000 	 0.44142913818359375 	 0.44406795501708984 	 0.4158039093017578 	 0.423738956451416 	 0.6732726097106934 	 0.8847029209136963 	 0.6108119487762451 	 0.30161428451538086 	 
2025-07-30 19:50:26.655036 test begin: paddle.Tensor.clip(Tensor([2100, 12097, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2100, 12097, 2],"float32"), 0, ) 	 50807400 	 1000 	 0.29547619819641113 	 0.30034303665161133 	 0.2699134349822998 	 0.2775232791900635 	 0.4502241611480713 	 0.5956778526306152 	 0.388991117477417 	 0.20307135581970215 	 
2025-07-30 19:50:29.999142 test begin: paddle.Tensor.clip(Tensor([2101, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([2101, 12096, 2],"float32"), 0, ) 	 50827392 	 1000 	 0.2957167625427246 	 0.2979295253753662 	 0.2700779438018799 	 0.27758288383483887 	 0.45028066635131836 	 0.59580397605896 	 0.3884284496307373 	 0.2030947208404541 	 
2025-07-30 19:50:33.359804 test begin: paddle.Tensor.clip(Tensor([4, 525, 12096, 3],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 525, 12096, 3],"float32"), 0, ) 	 76204800 	 1000 	 0.4414370059967041 	 0.44717907905578613 	 0.4244256019592285 	 0.428485631942749 	 0.6733341217041016 	 0.884814977645874 	 0.6213028430938721 	 0.3016021251678467 	 
2025-07-30 19:50:40.043669 test begin: paddle.Tensor.clip(Tensor([4, 525, 12097, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 525, 12097, 2],"float32"), 0, ) 	 50807400 	 1000 	 0.2954244613647461 	 0.29782986640930176 	 0.2784881591796875 	 0.2846662998199463 	 0.4501640796661377 	 0.5956761837005615 	 0.3936316967010498 	 0.2030785083770752 	 
2025-07-30 19:50:43.365268 test begin: paddle.Tensor.clip(Tensor([4, 526, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([4, 526, 12096, 2],"float32"), 0, ) 	 50899968 	 1000 	 0.2961606979370117 	 0.2983989715576172 	 0.27884554862976074 	 0.2847418785095215 	 0.4513063430786133 	 0.5969076156616211 	 0.3993687629699707 	 0.20350956916809082 	 
2025-07-30 19:50:46.767113 test begin: paddle.Tensor.clip(Tensor([5, 525, 12096, 2],"float32"), 0, )
[Prof] paddle.Tensor.clip 	 paddle.Tensor.clip(Tensor([5, 525, 12096, 2],"float32"), 0, ) 	 63504000 	 1000 	 0.3680610656738281 	 0.3711388111114502 	 0.3510262966156006 	 0.357541561126709 	 0.5613009929656982 	 0.7396106719970703 	 0.5090951919555664 	 0.25215888023376465 	 
2025-07-30 19:50:50.895218 test begin: paddle.Tensor.clone(Tensor([3544, 32, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([3544, 32, 896],"bfloat16"), ) 	 101613568 	 1000 	 0.3098158836364746 	 0.31119608879089355 	 0.3010103702545166 	 0.2953341007232666 	 0.6155130863189697 	 0.45381951332092285 	 0.5595102310180664 	 0.3674941062927246 	 
2025-07-30 19:50:55.798209 test begin: paddle.Tensor.clone(Tensor([6017, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6017, 19, 896],"bfloat16"), ) 	 102433408 	 1000 	 0.31677699089050293 	 0.3155481815338135 	 0.1618516445159912 	 0.16116642951965332 	 0.6274693012237549 	 0.45729494094848633 	 0.3206062316894531 	 0.3770177364349365 	 
2025-07-30 19:51:00.997564 test begin: paddle.Tensor.clone(Tensor([6017, 32, 528],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6017, 32, 528],"bfloat16"), ) 	 101663232 	 1000 	 0.3144516944885254 	 0.31319165229797363 	 0.16066431999206543 	 0.15995287895202637 	 0.6218996047973633 	 0.45395970344543457 	 0.3177368640899658 	 0.3765079975128174 	 
2025-07-30 19:51:07.722841 test begin: paddle.Tensor.clone(Tensor([6036, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6036, 19, 896],"bfloat16"), ) 	 102756864 	 1000 	 0.31802964210510254 	 0.3163473606109619 	 0.16250991821289062 	 0.16153621673583984 	 0.6284635066986084 	 0.4587433338165283 	 0.3210880756378174 	 0.38045358657836914 	 
2025-07-30 19:51:12.733700 test begin: paddle.Tensor.clone(Tensor([6036, 32, 527],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6036, 32, 527],"bfloat16"), ) 	 101791104 	 1000 	 0.31479430198669434 	 0.3157792091369629 	 0.16084957122802734 	 0.16033267974853516 	 0.6231563091278076 	 0.4544212818145752 	 0.31837916374206543 	 0.3653254508972168 	 
2025-07-30 19:51:17.800291 test begin: paddle.Tensor.clone(Tensor([6078, 19, 896],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6078, 19, 896],"bfloat16"), ) 	 103471872 	 1000 	 0.31342458724975586 	 0.3230149745941162 	 0.1601572036743164 	 0.16291069984436035 	 0.6178123950958252 	 0.461899995803833 	 0.315624475479126 	 0.3552842140197754 	 
2025-07-30 19:51:26.208907 test begin: paddle.Tensor.clone(Tensor([6078, 32, 523],"bfloat16"), )
[Prof] paddle.Tensor.clone 	 paddle.Tensor.clone(Tensor([6078, 32, 523],"bfloat16"), ) 	 101721408 	 1000 	 0.3139927387237549 	 0.3135108947753906 	 0.1604466438293457 	 0.16008472442626953 	 0.6237945556640625 	 0.4541161060333252 	 0.31867337226867676 	 0.3711268901824951 	 
2025-07-30 19:51:31.206086 test begin: paddle.Tensor.conj(Tensor([10, 2540161],"float64"), )
[Prof] paddle.Tensor.conj 	 paddle.Tensor.conj(Tensor([10, 2540161],"float64"), ) 	 25401610 	 1000 	 0.2977921962738037 	 0.002332925796508789 	 0.28294897079467773 	 1.71661376953125e-05 	 0.2973916530609131 	 0.05437159538269043 	 0.2406327724456787 	 7.796287536621094e-05 	 
2025-07-30 19:51:32.982896 test begin: paddle.Tensor.conj(Tensor([1270081, 20],"float64"), )
[Prof] paddle.Tensor.conj 	 paddle.Tensor.conj(Tensor([1270081, 20],"float64"), ) 	 25401620 	 1000 	 0.2977449893951416 	 0.0016956329345703125 	 0.2829861640930176 	 1.5974044799804688e-05 	 0.2974679470062256 	 0.048549652099609375 	 0.24076414108276367 	 9.417533874511719e-05 	 
2025-07-30 19:51:34.712703 test begin: paddle.Tensor.cos(Tensor([131072, 388],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([131072, 388],"float32"), ) 	 50855936 	 1000 	 0.2957587242126465 	 0.2984352111816406 	 0.279965877532959 	 0.28763914108276367 	 0.45112013816833496 	 1.0422561168670654 	 0.38764142990112305 	 0.35506391525268555 	 
2025-07-30 19:51:40.428811 test begin: paddle.Tensor.cos(Tensor([3175201, 16],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([3175201, 16],"float32"), ) 	 50803216 	 1000 	 0.2954556941986084 	 0.30729055404663086 	 0.2860872745513916 	 0.28746604919433594 	 0.4506547451019287 	 1.0409653186798096 	 0.39743781089782715 	 0.3546464443206787 	 
2025-07-30 19:51:44.225871 test begin: paddle.Tensor.cos(Tensor([32768, 1551],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.29543614387512207 	 0.29819822311401367 	 0.28671860694885254 	 0.2875635623931885 	 0.45073485374450684 	 1.041353464126587 	 0.39867472648620605 	 0.3548014163970947 	 
2025-07-30 19:51:48.010067 test begin: paddle.Tensor.cos(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.cos 	 paddle.Tensor.cos(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.295304536819458 	 0.30182361602783203 	 0.28662657737731934 	 0.28734278678894043 	 0.45044517517089844 	 1.0410971641540527 	 0.3977489471435547 	 0.3546578884124756 	 
2025-07-30 19:51:51.763535 test begin: paddle.Tensor.cumprod(Tensor([25401601],"float64"), -1, )
[Prof] paddle.Tensor.cumprod 	 paddle.Tensor.cumprod(Tensor([25401601],"float64"), -1, ) 	 25401601 	 1000 	 0.32688236236572266 	 0.3273036479949951 	 0.16695833206176758 	 0.16718673706054688 	 2.7991795539855957 	 2.056293487548828 	 0.00031495094299316406 	 0.0013124942779541016 	 
2025-07-30 19:51:58.471918 test begin: paddle.Tensor.cumprod(Tensor([50803201],"float32"), -1, )
[Prof] paddle.Tensor.cumprod 	 paddle.Tensor.cumprod(Tensor([50803201],"float32"), -1, ) 	 50803201 	 1000 	 0.3274047374725342 	 0.32956671714782715 	 0.1673591136932373 	 0.16830730438232422 	 3.1315767765045166 	 2.1192803382873535 	 0.00029921531677246094 	 0.001313924789428711 	 
2025-07-30 19:52:06.073866 test begin: paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 1, ) 	 50803344 	 1000 	 1.2552237510681152 	 0.35605382919311523 	 0.4276418685913086 	 0.34354400634765625 	 6.405747890472412 	 0.9764308929443359 	 1.3097763061523438 	 0.33257532119750977 	 
2025-07-30 19:52:16.815334 test begin: paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 144, 352801],"float32"), 2, ) 	 50803344 	 1000 	 0.8878462314605713 	 1.0166635513305664 	 0.8781969547271729 	 1.0055394172668457 	 1.6873822212219238 	 1.6412277221679688 	 0.5749585628509521 	 0.559302806854248 	 
2025-07-30 19:52:23.737715 test begin: paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 1, ) 	 50803400 	 1000 	 1.4238533973693848 	 125.06226229667664 	 0.4851219654083252 	 125.04425382614136 	 2.162688970565796 	 122.97484755516052 	 0.44202303886413574 	 41.93532347679138 	 
2025-07-30 19:56:38.180493 test begin: paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1, 254017, 200],"float32"), 2, ) 	 50803400 	 1000 	 0.4054088592529297 	 2.8232901096343994 	 0.38848209381103516 	 2.812225580215454 	 4.159472703933716 	 3.446202516555786 	 1.4164798259735107 	 1.1747477054595947 	 
2025-07-30 19:56:50.758320 test begin: paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 1, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 1, ) 	 50832000 	 1000 	 1.2872371673583984 	 0.36853861808776855 	 0.4386146068572998 	 0.34479713439941406 	 6.441852569580078 	 0.9936063289642334 	 1.3171637058258057 	 0.3384833335876465 	 
2025-07-30 19:57:05.909134 test begin: paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 2, )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([1765, 144, 200],"float32"), 2, ) 	 50832000 	 1000 	 0.40563225746154785 	 2.8247745037078857 	 0.3957488536834717 	 2.813586473464966 	 4.158958196640015 	 3.447803020477295 	 1.4163634777069092 	 1.1753122806549072 	 
2025-07-30 19:57:18.471775 test begin: paddle.Tensor.cumsum(Tensor([211681, 120],"int64"), )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([211681, 120],"int64"), ) 	 25401720 	 1000 	 0.3467221260070801 	 0.3262500762939453 	 4.267692565917969e-05 	 0.16662812232971191 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:57:20.379648 test begin: paddle.Tensor.cumsum(Tensor([300, 84673],"int64"), )
[Prof] paddle.Tensor.cumsum 	 paddle.Tensor.cumsum(Tensor([300, 84673],"int64"), ) 	 25401900 	 1000 	 0.34544992446899414 	 0.3291893005371094 	 5.340576171875e-05 	 0.16666936874389648 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:57:22.284108 test begin: paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([1003520, 1013],"bfloat16"), ) 	 1016565760 	 1000 	 0.0007374286651611328 	 0.003418445587158203 	 6.9141387939453125e-06 	 5.53131103515625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:57:55.550631 test begin: paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([10130, 100352],"bfloat16"), ) 	 1016565760 	 1000 	 0.0007417201995849609 	 0.002832174301147461 	 1.1920928955078125e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:58:29.784990 test begin: paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007617473602294922 	 0.0028314590454101562 	 1.0013580322265625e-05 	 1.8835067749023438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:59:03.150804 test begin: paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([17720, 57344],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007617473602294922 	 0.002833843231201172 	 1.0967254638671875e-05 	 1.9788742065429688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:59:39.185914 test begin: paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), )
[Prof] paddle.Tensor.detach 	 paddle.Tensor.detach(Tensor([81920, 12404],"bfloat16"), ) 	 1016135680 	 1000 	 0.0007622241973876953 	 0.0030035972595214844 	 9.5367431640625e-06 	 4.696846008300781e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:00:12.413761 test begin: paddle.Tensor.diag_embed(Tensor([1, 25401601, 2],"float32"), )
[Prof] paddle.Tensor.diag_embed 	 paddle.Tensor.diag_embed(Tensor([1, 25401601, 2],"float32"), ) 	 50803202 	 1000 	 1.7780404090881348 	 1.0138232707977295 	 5.793571472167969e-05 	 0.5178864002227783 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:16.040746 test begin: paddle.Tensor.diag_embed(Tensor([25401601, 1, 2],"float32"), )
[Prof] paddle.Tensor.diag_embed 	 paddle.Tensor.diag_embed(Tensor([25401601, 1, 2],"float32"), ) 	 50803202 	 1000 	 1.770099401473999 	 1.0320014953613281 	 7.62939453125e-05 	 0.5178682804107666 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:22.807658 test begin: paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([301, 84672],"float64"), axis1=-2, axis2=-1, ) 	 25486272 	 1000 	 0.003845691680908203 	 0.004528999328613281 	 8.344650268554688e-06 	 1.7404556274414062e-05 	 0.1516554355621338 	 0.14026355743408203 	 0.07738661766052246 	 0.06524372100830078 	 
2025-07-30 20:00:23.708082 test begin: paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, )
[Prof] paddle.Tensor.diagonal 	 paddle.Tensor.diagonal(Tensor([8467201, 3],"float64"), axis1=-2, axis2=-1, ) 	 25401603 	 1000 	 0.0038259029388427734 	 0.004592180252075195 	 6.67572021484375e-06 	 2.09808349609375e-05 	 0.15170764923095703 	 0.1384115219116211 	 0.07750248908996582 	 0.06203961372375488 	 
2025-07-30 20:00:24.537348 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.944873571395874 	 0.2615683078765869 	 0.32187676429748535 	 0.24299240112304688 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:26.273807 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.9447157382965088 	 0.2615342140197754 	 0.3218414783477783 	 0.2422773838043213 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:28.017178 test begin: paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([396901, 4, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.944873571395874 	 0.2615227699279785 	 0.32199692726135254 	 0.24227643013000488 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:29.749698 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.870797872543335 	 0.2615668773651123 	 0.29665660858154297 	 0.24304604530334473 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:31.414013 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8707375526428223 	 0.26151323318481445 	 0.29662156105041504 	 0.24231839179992676 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:33.073204 test begin: paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 396901, 4, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 0.8707709312438965 	 0.26439380645751953 	 0.29667043685913086 	 0.24167704582214355 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:34.736642 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.8707365989685059 	 0.7178194522857666 	 0.29665136337280273 	 0.2427995204925537 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:38.263601 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=-2, ) 	 25401664 	 1000 	 1.0701868534088135 	 0.30494117736816406 	 0.36458325386047363 	 0.27977585792541504 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:40.211581 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 396901, 4],"float64"), axis=2, ) 	 25401664 	 1000 	 1.0701711177825928 	 0.2994251251220703 	 0.3646211624145508 	 0.2801222801208496 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:42.141877 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 1.0699667930603027 	 0.29944300651550293 	 0.36452722549438477 	 0.2726719379425049 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:44.042373 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=-2, ) 	 25401664 	 1000 	 0.8070323467254639 	 0.26623988151550293 	 0.27493715286254883 	 0.24326348304748535 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:45.682835 test begin: paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, )
[Prof] paddle.Tensor.diff 	 paddle.Tensor.diff(x=Tensor([4, 4, 4, 396901],"float64"), axis=2, ) 	 25401664 	 1000 	 0.807075023651123 	 0.26285290718078613 	 0.2749819755554199 	 0.24355125427246094 	 None 	 None 	 None 	 None 	 
2025-07-30 20:00:47.267997 test begin: paddle.Tensor.digamma(Tensor([4, 6350401],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 1.171541452407837 	 1.1453235149383545 	 1.1633391380310059 	 1.1328260898590088 	 8.57067346572876 	 1.0859456062316895 	 8.51919412612915 	 0.554854154586792 	 
2025-07-30 20:01:00.372669 test begin: paddle.Tensor.digamma(Tensor([453601, 7, 8],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([453601, 7, 8],"float64"), ) 	 25401656 	 1000 	 1.1714718341827393 	 1.144052267074585 	 1.1629035472869873 	 1.1337828636169434 	 8.569085121154785 	 1.0859148502349854 	 8.518831491470337 	 0.5547981262207031 	 
2025-07-30 20:01:13.514817 test begin: paddle.Tensor.digamma(Tensor([45361, 7, 8, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([45361, 7, 8, 10],"float64"), ) 	 25402160 	 1000 	 1.1713533401489258 	 2.521718740463257 	 1.1631824970245361 	 1.159820795059204 	 8.569491147994995 	 1.0859785079956055 	 8.518867015838623 	 0.5547518730163574 	 
2025-07-30 20:01:29.404897 test begin: paddle.Tensor.digamma(Tensor([5, 635041, 8],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 635041, 8],"float64"), ) 	 25401640 	 1000 	 1.1712732315063477 	 1.1440763473510742 	 1.1630210876464844 	 1.1337718963623047 	 8.568296194076538 	 1.0858566761016846 	 8.51763916015625 	 0.5547842979431152 	 
2025-07-30 20:01:42.534435 test begin: paddle.Tensor.digamma(Tensor([5, 63505, 8, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 63505, 8, 10],"float64"), ) 	 25402000 	 1000 	 1.1713664531707764 	 1.1439189910888672 	 1.1631388664245605 	 1.1333870887756348 	 8.566401958465576 	 1.08575439453125 	 8.515745401382446 	 0.5547404289245605 	 
2025-07-30 20:01:55.656662 test begin: paddle.Tensor.digamma(Tensor([5, 7, 725761],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 725761],"float64"), ) 	 25401635 	 1000 	 1.1710636615753174 	 1.143777847290039 	 1.1628735065460205 	 1.13346529006958 	 8.567357301712036 	 1.0856153964996338 	 8.516139507293701 	 0.5547158718109131 	 
2025-07-30 20:02:08.765286 test begin: paddle.Tensor.digamma(Tensor([5, 7, 72577, 10],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 72577, 10],"float64"), ) 	 25401950 	 1000 	 1.1709589958190918 	 1.1438236236572266 	 1.1627721786499023 	 1.1314034461975098 	 8.568172693252563 	 1.085679054260254 	 8.517593383789062 	 0.5546894073486328 	 
2025-07-30 20:02:21.897013 test begin: paddle.Tensor.digamma(Tensor([5, 7, 8, 90721],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5, 7, 8, 90721],"float64"), ) 	 25401880 	 1000 	 1.1711132526397705 	 1.1501917839050293 	 1.1627094745635986 	 1.1323752403259277 	 8.569449663162231 	 1.0856308937072754 	 8.518691301345825 	 0.5546655654907227 	 
2025-07-30 20:02:37.061067 test begin: paddle.Tensor.digamma(Tensor([5080321, 5],"float64"), )
[Prof] paddle.Tensor.digamma 	 paddle.Tensor.digamma(Tensor([5080321, 5],"float64"), ) 	 25401605 	 1000 	 1.2268195152282715 	 1.1444220542907715 	 1.2186875343322754 	 1.1332075595855713 	 8.567167282104492 	 1.0856683254241943 	 8.516536235809326 	 0.554710865020752 	 
2025-07-30 20:02:50.227669 test begin: paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([1116160, 911],"bfloat16"), ) 	 1016821760 	 1000 	 0.0006794929504394531 	 0.001535654067993164 	 8.821487426757812e-06 	 1.6450881958007812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:03:06.740693 test begin: paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([124040, 8192],"bfloat16"), ) 	 1016135680 	 1000 	 0.0006513595581054688 	 0.001538991928100586 	 1.0251998901367188e-05 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:03:23.310272 test begin: paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([141760, 7168],"bfloat16"), ) 	 1016135680 	 1000 	 0.0006418228149414062 	 0.0019741058349609375 	 1.049041748046875e-05 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:03:43.210893 test begin: paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([71680, 14176],"bfloat16"), ) 	 1016135680 	 1000 	 0.0006506443023681641 	 0.0015230178833007812 	 9.775161743164062e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:03:59.569227 test begin: paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([9110, 111616],"bfloat16"), ) 	 1016821760 	 1000 	 0.0006401538848876953 	 0.0015430450439453125 	 1.0013580322265625e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:15.833669 test begin: paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), )
[Prof] paddle.Tensor.dim 	 paddle.Tensor.dim(Tensor([958720, 1060],"bfloat16"), ) 	 1016243200 	 1000 	 0.0006520748138427734 	 0.001546621322631836 	 1.0728836059570312e-05 	 1.5974044799804688e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:32.087240 test begin: paddle.Tensor.dot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
Warning: The core code of paddle.Tensor.dot is too complex.
[Prof] paddle.Tensor.dot 	 paddle.Tensor.dot(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.296205997467041 	 0.29325366020202637 	 0.2871079444885254 	 0.14983367919921875 	 0.7120447158813477 	 0.6040003299713135 	 0.36380815505981445 	 0.3085968494415283 	 
2025-07-30 20:04:37.125125 test begin: paddle.Tensor.equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), ) 	 50803456 	 1000 	 0.3092474937438965 	 0.31862926483154297 	 0.2981116771697998 	 0.30136561393737793 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:39.925315 test begin: paddle.Tensor.equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), ) 	 50803456 	 1000 	 0.30919528007507324 	 0.31319737434387207 	 0.2986917495727539 	 0.3014194965362549 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:41.443382 test begin: paddle.Tensor.equal(Tensor([2, 12700801],"int64"), 3, )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([2, 12700801],"int64"), 3, ) 	 25401602 	 1000 	 0.17837762832641602 	 0.16826963424682617 	 0.09111356735229492 	 0.15406036376953125 	 None 	 None 	 None 	 None 	 
2025-07-30 20:04:42.210047 test begin: paddle.Tensor.equal(Tensor([2540161, 10],"int64"), 3, )
[Prof] paddle.Tensor.equal 	 paddle.Tensor.equal(Tensor([2540161, 10],"int64"), 3, ) 	 25401610 	 1000 	 0.17839884757995605 	 0.16822338104248047 	 0.09112071990966797 	 0.1539921760559082 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:23.593829 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([25401601],"int64"), )
W0730 20:05:24.492905 40499 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([25401601],"int64"), ) 	 50803202 	 1000 	 0.34079933166503906 	 0.3785223960876465 	 0.11591458320617676 	 9.036064147949219e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:25.551444 test begin: paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([25401601],"int64"), Tensor([801],"int64"), ) 	 25402402 	 1000 	 0.016640186309814453 	 0.0028455257415771484 	 4.410743713378906e-05 	 2.47955322265625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:25.987420 test begin: paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8, 3175201],"int64"), Tensor([8, 3175201],"int64"), ) 	 50803216 	 1000 	 0.34119343757629395 	 0.3845527172088623 	 0.11603689193725586 	 0.00010085105895996094 	 None 	 None 	 None 	 None 	 
2025-07-30 20:05:27.543842 test begin: paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3175201],"int64"), Tensor([801, 3],"int64"), ) 	 2543338404 	 1000 	 0.01741194725036621 	 0.0028727054595947266 	 2.4318695068359375e-05 	 3.3855438232421875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:08.465106 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([801, 3175201],"int64"), ) 	 2543338404 	 1000 	 0.016533851623535156 	 0.002804994583129883 	 2.8848648071289062e-05 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:50.079572 test begin: paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 25404006 	 1000 	 0.016283750534057617 	 0.0027463436126708984 	 1.621246337890625e-05 	 3.1948089599609375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:50.686686 test begin: paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([801],"int64"), Tensor([25401601],"int64"), ) 	 25402402 	 1000 	 0.016965627670288086 	 0.0026535987854003906 	 2.0503997802734375e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:51.176015 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([801, 3],"int64"), ) 	 25404006 	 1000 	 0.02031707763671875 	 0.0026514530181884766 	 2.574920654296875e-05 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:51.626112 test begin: paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8467201, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8467201, 3],"int64"), Tensor([8467201, 3],"int64"), ) 	 50803206 	 1000 	 0.3407766819000244 	 0.38329339027404785 	 0.11590933799743652 	 8.916854858398438e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:06:53.222700 test begin: paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([846720101, 3],"int64"), Tensor([8, 3],"int64"), ) 	 2540160327 	 1000 	 0.016391992568969727 	 0.002707242965698242 	 2.09808349609375e-05 	 2.002716064453125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:07:34.080177 test begin: paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), )
[Prof] paddle.Tensor.equal_all 	 paddle.Tensor.equal_all(Tensor([8],"int64"), Tensor([2540160101],"int64"), ) 	 2540160109 	 1000 	 0.01688551902770996 	 0.002676248550415039 	 1.6689300537109375e-05 	 1.7404556274414062e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:08:26.622668 test begin: paddle.Tensor.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([211681, 2, 3, 5, 4],"float64"), ) 	 25401720 	 1000 	 0.32606983184814453 	 0.30269598960876465 	 0.31546521186828613 	 0.29192471504211426 	 0.4481773376464844 	 1.643740177154541 	 0.39265966415405273 	 0.336045503616333 	 
2025-07-30 20:08:30.799792 test begin: paddle.Tensor.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 105841, 3, 5, 4],"float64"), ) 	 25401840 	 1000 	 0.32607102394104004 	 0.30261945724487305 	 0.3171982765197754 	 0.2922549247741699 	 0.44801926612854004 	 1.6437621116638184 	 0.3953273296356201 	 0.33608222007751465 	 
2025-07-30 20:08:34.593789 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 158761, 5, 4],"float64"), ) 	 25401760 	 1000 	 0.3259894847869873 	 0.7540271282196045 	 0.3174290657043457 	 0.2922389507293701 	 0.44755125045776367 	 1.6437547206878662 	 0.3950614929199219 	 0.3360283374786377 	 
2025-07-30 20:08:41.075617 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 1058401],"float64"), ) 	 25401624 	 1000 	 0.32604336738586426 	 0.3051481246948242 	 0.3172483444213867 	 0.2922811508178711 	 0.4476184844970703 	 1.6438243389129639 	 0.3938016891479492 	 0.3360166549682617 	 
2025-07-30 20:08:44.902789 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 264601, 4],"float64"), ) 	 25401696 	 1000 	 0.3259701728820801 	 0.3025705814361572 	 0.31705331802368164 	 0.29237794876098633 	 0.4475901126861572 	 1.643486738204956 	 0.3948695659637451 	 0.33599352836608887 	 
2025-07-30 20:08:48.686629 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 211681],"float64"), ) 	 25401720 	 1000 	 0.3263101577758789 	 0.30263519287109375 	 0.3177049160003662 	 0.29221367835998535 	 0.44814324378967285 	 1.6435062885284424 	 0.39550280570983887 	 0.3360249996185303 	 
2025-07-30 20:08:52.536499 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 3175201],"float64"), ) 	 25401608 	 1000 	 0.3266727924346924 	 0.30278515815734863 	 0.31816864013671875 	 0.292555570602417 	 0.44753432273864746 	 1.6436560153961182 	 0.39455223083496094 	 0.3359794616699219 	 
2025-07-30 20:08:56.395334 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2, 635041, 5],"float64"), ) 	 25401640 	 1000 	 0.3271000385284424 	 0.3040788173675537 	 0.3187108039855957 	 0.2936258316040039 	 0.4476938247680664 	 1.643531084060669 	 0.3940925598144531 	 0.3359808921813965 	 
2025-07-30 20:09:00.215775 test begin: paddle.Tensor.erfinv(x=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 2116801, 3],"float64"), ) 	 25401612 	 1000 	 0.3269765377044678 	 0.3059091567993164 	 0.3116607666015625 	 0.28815627098083496 	 0.4475998878479004 	 1.643484115600586 	 0.3856332302093506 	 0.33595728874206543 	 
2025-07-30 20:09:04.094673 test begin: paddle.Tensor.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4, 423361, 3, 5],"float64"), ) 	 25401660 	 1000 	 0.32752132415771484 	 0.9826450347900391 	 0.3120455741882324 	 0.29141998291015625 	 0.44777727127075195 	 1.6437163352966309 	 0.3780951499938965 	 0.33608436584472656 	 
2025-07-30 20:09:10.281240 test begin: paddle.Tensor.erfinv(x=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.32601070404052734 	 0.3072488307952881 	 0.3106358051300049 	 0.2868201732635498 	 0.4475216865539551 	 1.6434640884399414 	 0.3857877254486084 	 0.3360159397125244 	 
2025-07-30 20:09:14.202609 test begin: paddle.Tensor.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), )
[Prof] paddle.Tensor.erfinv 	 paddle.Tensor.erfinv(x=Tensor([846721, 2, 3, 5],"float64"), ) 	 25401630 	 1000 	 0.3260798454284668 	 0.30335235595703125 	 0.3135828971862793 	 0.293170690536499 	 0.447537899017334 	 1.6434388160705566 	 0.3952171802520752 	 0.3360602855682373 	 
2025-07-30 20:09:17.971419 test begin: paddle.Tensor.exp(Tensor([1000000, 26],"float64"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([1000000, 26],"float64"), ) 	 26000000 	 1000 	 0.3058803081512451 	 0.3075547218322754 	 0.2977449893951416 	 0.2962799072265625 	 0.45868825912475586 	 0.4547405242919922 	 0.4067392349243164 	 0.39253735542297363 	 
2025-07-30 20:09:20.643868 test begin: paddle.Tensor.exp(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29546475410461426 	 0.2980172634124756 	 0.28720712661743164 	 0.28685641288757324 	 0.44974231719970703 	 0.44664955139160156 	 0.3971986770629883 	 0.38454365730285645 	 
2025-07-30 20:09:23.805347 test begin: paddle.Tensor.exp(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2954883575439453 	 0.29787230491638184 	 0.2874162197113037 	 0.28676462173461914 	 0.4497048854827881 	 0.4467017650604248 	 0.39165782928466797 	 0.38584136962890625 	 
2025-07-30 20:09:26.960153 test begin: paddle.Tensor.exp(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.2995266914367676 	 0.3005213737487793 	 0.29152488708496094 	 0.28939104080200195 	 0.44768738746643066 	 0.44460415840148926 	 0.39382052421569824 	 0.38283467292785645 	 
2025-07-30 20:09:29.560085 test begin: paddle.Tensor.exp(Tensor([64, 793801],"float32"), )
[Prof] paddle.Tensor.exp 	 paddle.Tensor.exp(Tensor([64, 793801],"float32"), ) 	 50803264 	 1000 	 0.29552459716796875 	 0.2989540100097656 	 0.2873246669769287 	 0.28668832778930664 	 0.44980406761169434 	 0.446666955947876 	 0.3904879093170166 	 0.3829338550567627 	 
2025-07-30 20:09:32.848484 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 266, 477, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 266, 477, 401],"float32"), ) 	 50879683 	 1000 	 0.13529372215270996 	 0.004193782806396484 	 0.12418985366821289 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:34.903054 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 283, 466, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 283, 466, 386],"float32"), ) 	 50904909 	 1000 	 0.1351299285888672 	 0.006221294403076172 	 0.12424755096435547 	 2.5272369384765625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:39.050176 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 299, 391, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 299, 391, 436],"float32"), ) 	 50972325 	 1000 	 0.1352686882019043 	 0.004089832305908203 	 0.11636900901794434 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:41.033297 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 38841, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 38841, 436],"float32"), ) 	 50804029 	 1000 	 0.13495898246765137 	 0.007914304733276367 	 0.11616826057434082 	 2.0265579223632812e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:42.991524 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 391, 43311],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 391, 43311],"float32"), ) 	 50803804 	 1000 	 0.13487887382507324 	 0.007749080657958984 	 0.1161644458770752 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:44.986463 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 42231, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 42231, 401],"float32"), ) 	 50803894 	 1000 	 0.13502717018127441 	 0.008101701736450195 	 0.11630034446716309 	 5.650520324707031e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:46.959788 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 43872, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 43872, 386],"float32"), ) 	 50803777 	 1000 	 0.13476181030273438 	 0.004121541976928711 	 0.1238858699798584 	 1.9073486328125e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:48.944139 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 466, 36340],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 466, 36340],"float32"), ) 	 50803321 	 1000 	 0.13486003875732422 	 0.004014492034912109 	 0.12404704093933105 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:50.930328 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 477, 35502],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 477, 35502],"float32"), ) 	 50803363 	 1000 	 0.13478541374206543 	 0.00405430793762207 	 0.1239633560180664 	 1.7642974853515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:52.868167 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([100, 3, 391, 436],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([100, 3, 391, 436],"float32"), ) 	 51142801 	 1000 	 0.13574552536010742 	 0.004048824310302734 	 0.12493896484375 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:54.866377 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([89, 3, 477, 401],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([89, 3, 477, 401],"float32"), ) 	 51070960 	 1000 	 0.13566327095031738 	 0.0077321529388427734 	 0.1165621280670166 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:56.813299 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([95, 3, 466, 386],"float32"), )
[Prof] paddle.Tensor.expand_as 	 paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([95, 3, 466, 386],"float32"), ) 	 51264661 	 1000 	 0.1359727382659912 	 0.003997325897216797 	 0.12522268295288086 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 20:09:58.797683 test begin: paddle.Tensor.fill_(Tensor([50803201],"float32"), 0, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([50803201],"float32"), 0, ) 	 50803201 	 1000 	 0.14626598358154297 	 0.134033203125 	 0.1313612461090088 	 0.12541794776916504 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:00.795157 test begin: paddle.Tensor.fill_(Tensor([659782, 77],"float32"), value=-math.inf, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([659782, 77],"float32"), value=-math.inf, ) 	 50803214 	 1000 	 0.14614343643188477 	 0.13402414321899414 	 0.1309359073638916 	 0.12545442581176758 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:02.820745 test begin: paddle.Tensor.fill_(Tensor([77, 659782],"float32"), value=-math.inf, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(Tensor([77, 659782],"float32"), value=-math.inf, ) 	 50803214 	 1000 	 0.14630937576293945 	 0.13411641120910645 	 0.12935781478881836 	 0.1254558563232422 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:04.813723 test begin: paddle.Tensor.fill_(x=Tensor([10, 158761, 16],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([10, 158761, 16],"float64"), value=41.2, ) 	 25401760 	 1000 	 0.14601898193359375 	 0.13453364372253418 	 0.13086533546447754 	 0.1259303092956543 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:06.218131 test begin: paddle.Tensor.fill_(x=Tensor([10, 16, 158761],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([10, 16, 158761],"float64"), value=41.2, ) 	 25401760 	 1000 	 0.14586663246154785 	 0.1345205307006836 	 0.13077640533447266 	 0.1258077621459961 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:07.652615 test begin: paddle.Tensor.fill_(x=Tensor([99226, 16, 16],"float64"), value=41.2, )
[Prof] paddle.Tensor.fill_ 	 paddle.Tensor.fill_(x=Tensor([99226, 16, 16],"float64"), value=41.2, ) 	 25401856 	 1000 	 0.146559476852417 	 0.13461065292358398 	 0.131422758102417 	 0.12593579292297363 	 None 	 None 	 None 	 None 	 
2025-07-30 20:10:09.067761 test begin: paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([1280, 396901],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.022574901580810547 	 0.011423826217651367 	 2.956390380859375e-05 	 5.745887756347656e-05 	 0.04205632209777832 	 0.0431818962097168 	 5.650520324707031e-05 	 3.790855407714844e-05 	 combined
2025-07-30 20:10:25.866584 test begin: paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, )
[Prof] paddle.Tensor.fill_diagonal_ 	 paddle.Tensor.fill_diagonal_(Tensor([3969010, 128],"float32"), 0, wrap=False, ) 	 508033280 	 1000 	 0.022369384765625 	 0.010828971862792969 	 2.6464462280273438e-05 	 3.075599670410156e-05 	 0.03232240676879883 	 0.04325580596923828 	 2.4557113647460938e-05 	 6.365776062011719e-05 	 combined
2025-07-30 20:10:42.722652 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([12700801, 4, 7],"int32"), Tensor([12700801, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([12700801, 4, 7],"int32"), Tensor([12700801, 4],"int32"), 0, 1, 2, ) 	 406425632 	 1000 	 89.46120142936707 	 4.355571746826172 	 0.0036373138427734375 	 1.483083963394165 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:13:56.588626 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([1814401, 4, 7],"int32"), Tensor([1814401, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([1814401, 4, 7],"int32"), Tensor([1814401, 4],"int32"), 0, 1, 2, ) 	 58060832 	 1000 	 4.784582853317261 	 0.6301178932189941 	 0.0015721321105957031 	 0.21453213691711426 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:14:08.198310 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 3175201],"int64"), Tensor([2, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 3175201],"int64"), Tensor([2, 4],"int64"), 0, 1, 2, ) 	 25401616 	 1000 	 0.3217461109161377 	 0.31594038009643555 	 0.08209609985351562 	 0.10745453834533691 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:14:09.992220 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 6350401],"int32"), Tensor([2, 4],"int32"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4, 6350401],"int32"), Tensor([2, 4],"int32"), 0, 1, 2, ) 	 50803216 	 1000 	 0.3217930793762207 	 0.3158855438232422 	 0.08211231231689453 	 0.10741019248962402 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:14:12.151668 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4233601, 3, 2],"int32"), Tensor([2, 2, 3],"int32"), offset=0, dim1=1, dim2=2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([2, 4233601, 3, 2],"int32"), Tensor([2, 2, 3],"int32"), offset=0, dim1=1, dim2=2, ) 	 50803224 	 1000 	 0.32169461250305176 	 0.31607842445373535 	 0.08201169967651367 	 0.107421875 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:14:14.349956 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([6350401, 4, 7],"int64"), Tensor([6350401, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([6350401, 4, 7],"int64"), Tensor([6350401, 4],"int64"), 0, 1, 2, ) 	 203212832 	 1000 	 43.70463180541992 	 3.603471517562866 	 0.00179290771484375 	 1.2266769409179688 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:15:52.425248 test begin: paddle.Tensor.fill_diagonal_tensor(Tensor([907201, 4, 7],"int64"), Tensor([907201, 4],"int64"), 0, 1, 2, )
[Prof] paddle.Tensor.fill_diagonal_tensor 	 paddle.Tensor.fill_diagonal_tensor(Tensor([907201, 4, 7],"int64"), Tensor([907201, 4],"int64"), 0, 1, 2, ) 	 29030432 	 1000 	 2.330916166305542 	 0.5179710388183594 	 0.0008218288421630859 	 0.17634105682373047 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:15:58.655501 test begin: paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([10, 64, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 1684480000 	 1000 	 0.005823373794555664 	 0.00433659553527832 	 1.9550323486328125e-05 	 2.0265579223632812e-05 	 0.04734921455383301 	 0.05227303504943848 	 4.506111145019531e-05 	 5.7220458984375e-05 	 
2025-07-30 20:16:54.134554 test begin: paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 127, 56, 56],"float32"), 2, ) 	 509788160 	 1000 	 0.0053637027740478516 	 0.004236936569213867 	 1.1920928955078125e-05 	 1.8596649169921875e-05 	 0.041552066802978516 	 0.05351758003234863 	 3.528594970703125e-05 	 7.605552673339844e-05 	 
2025-07-30 20:17:11.041860 test begin: paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 254, 56, 56],"float16"), 2, ) 	 1019576320 	 1000 	 0.006197214126586914 	 0.004181861877441406 	 4.410743713378906e-05 	 1.9073486328125e-05 	 0.04162931442260742 	 0.05235409736633301 	 3.552436828613281e-05 	 6.508827209472656e-05 	 
2025-07-30 20:17:49.420864 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 14, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.0054662227630615234 	 0.004308223724365234 	 2.4557113647460938e-05 	 2.2411346435546875e-05 	 0.044947147369384766 	 0.0518183708190918 	 5.793571472167969e-05 	 3.552436828613281e-05 	 
2025-07-30 20:18:06.160652 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 28, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.0053369998931884766 	 0.004258871078491211 	 1.239776611328125e-05 	 1.9073486328125e-05 	 0.04148674011230469 	 0.05216073989868164 	 2.2411346435546875e-05 	 5.054473876953125e-05 	 
2025-07-30 20:18:44.666354 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 14],"float32"), 2, ) 	 513802240 	 1000 	 0.0053637027740478516 	 0.004319429397583008 	 1.239776611328125e-05 	 1.9788742065429688e-05 	 0.04149961471557617 	 0.06182384490966797 	 3.1948089599609375e-05 	 7.414817810058594e-05 	 
2025-07-30 20:19:02.143025 test begin: paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([1280, 512, 56, 28],"float16"), 2, ) 	 1027604480 	 1000 	 0.005341291427612305 	 0.004188060760498047 	 1.0728836059570312e-05 	 2.0265579223632812e-05 	 0.04160594940185547 	 0.05253124237060547 	 4.363059997558594e-05 	 5.5789947509765625e-05 	 
2025-07-30 20:19:41.137442 test begin: paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([320, 512, 56, 56],"float32"), 2, ) 	 513802240 	 1000 	 0.005347490310668945 	 0.004186868667602539 	 8.821487426757812e-06 	 1.9073486328125e-05 	 0.041800498962402344 	 0.05373358726501465 	 4.172325134277344e-05 	 8.106231689453125e-05 	 
2025-07-30 20:19:58.107604 test begin: paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 5, 25, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 526400000 	 1000 	 0.010781526565551758 	 0.00819849967956543 	 1.4543533325195312e-05 	 2.0503997802734375e-05 	 0.05426740646362305 	 0.06002473831176758 	 5.0067901611328125e-05 	 4.029273986816406e-05 	 
2025-07-30 20:20:15.756975 test begin: paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 2, 376, 280],"float32"), start_axis=1, stop_axis=2, ) 	 539033600 	 1000 	 0.005662441253662109 	 0.0043871402740478516 	 1.049041748046875e-05 	 1.9788742065429688e-05 	 0.04163646697998047 	 0.0564274787902832 	 3.933906555175781e-05 	 6.008148193359375e-05 	 
2025-07-30 20:20:33.582631 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 29, 280],"float32"), start_axis=1, stop_axis=2, ) 	 519680000 	 1000 	 0.005779743194580078 	 0.004332780838012695 	 1.811981201171875e-05 	 2.002716064453125e-05 	 0.04433870315551758 	 0.06157541275024414 	 2.6226043701171875e-05 	 7.510185241699219e-05 	 
2025-07-30 20:20:50.860477 test begin: paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([40, 64, 25, 376, 22],"float32"), start_axis=1, stop_axis=2, ) 	 529408000 	 1000 	 0.0056111812591552734 	 0.00433349609375 	 7.152557373046875e-06 	 2.002716064453125e-05 	 0.04175209999084473 	 0.057198286056518555 	 3.075599670410156e-05 	 6.008148193359375e-05 	 
2025-07-30 20:21:10.321165 test begin: paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, )
[Prof] paddle.Tensor.flatten 	 paddle.Tensor.flatten(Tensor([640, 512, 56, 56],"float16"), 2, ) 	 1027604480 	 1000 	 0.0053713321685791016 	 0.004245281219482422 	 1.5497207641601562e-05 	 1.9550323486328125e-05 	 0.04152631759643555 	 0.06029033660888672 	 2.6226043701171875e-05 	 7.605552673339844e-05 	 
2025-07-30 20:21:49.068556 test begin: paddle.Tensor.flip(Tensor([16, 3, 224, 4726],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 3, 224, 4726],"float32"), 0, ) 	 50813952 	 1000 	 0.9650752544403076 	 0.3114933967590332 	 0.9562945365905762 	 0.29698824882507324 	 0.9648349285125732 	 0.3112337589263916 	 0.915050745010376 	 0.247147798538208 	 
2025-07-30 20:21:53.339136 test begin: paddle.Tensor.flip(Tensor([16, 3, 4726, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 3, 4726, 224],"float32"), 0, ) 	 50813952 	 1000 	 0.9649922847747803 	 0.3114607334136963 	 0.9561903476715088 	 0.2970898151397705 	 0.9647912979125977 	 0.3112297058105469 	 0.914738655090332 	 0.24331045150756836 	 
2025-07-30 20:21:57.574796 test begin: paddle.Tensor.flip(Tensor([16, 64, 224, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([16, 64, 224, 224],"float32"), 0, ) 	 51380224 	 1000 	 0.9751870632171631 	 0.3151283264160156 	 0.9664413928985596 	 0.30082178115844727 	 0.9753127098083496 	 0.314922571182251 	 0.9130370616912842 	 0.2509922981262207 	 
2025-07-30 20:22:01.867485 test begin: paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-1,], ) 	 50804400 	 1000 	 0.9014756679534912 	 0.3125276565551758 	 0.8924391269683838 	 0.29787373542785645 	 0.9017760753631592 	 0.312389612197876 	 0.8512260913848877 	 0.24250125885009766 	 
2025-07-30 20:22:05.973034 test begin: paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 400, 42337],"float32"), axis=list[-2,], ) 	 50804400 	 1000 	 0.9013862609863281 	 0.3160538673400879 	 0.8923380374908447 	 0.3017609119415283 	 0.9020068645477295 	 0.31588077545166016 	 0.8467485904693604 	 0.2505805492401123 	 
2025-07-30 20:22:10.116671 test begin: paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-1,], ) 	 50804100 	 1000 	 0.9013521671295166 	 0.3126516342163086 	 0.8839230537414551 	 0.29095935821533203 	 0.9020669460296631 	 0.3126256465911865 	 0.8430628776550293 	 0.24193644523620605 	 
2025-07-30 20:22:14.281317 test begin: paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([3, 56449, 300],"float32"), axis=list[-2,], ) 	 50804100 	 1000 	 0.9013302326202393 	 0.3200688362121582 	 0.8849341869354248 	 0.2932913303375244 	 0.9021403789520264 	 0.3155066967010498 	 0.8439512252807617 	 0.2447197437286377 	 
2025-07-30 20:22:20.428425 test begin: paddle.Tensor.flip(Tensor([338, 3, 224, 224],"float32"), 0, )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([338, 3, 224, 224],"float32"), 0, ) 	 50878464 	 1000 	 0.9664876461029053 	 0.3121073246002197 	 0.9503014087677002 	 0.28987717628479004 	 0.9660899639129639 	 0.311908483505249 	 0.9074034690856934 	 0.23962068557739258 	 
2025-07-30 20:22:24.713925 test begin: paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-1,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-1,], ) 	 50880000 	 1000 	 0.9045367240905762 	 0.31386590003967285 	 0.8955233097076416 	 0.29764413833618164 	 0.9045116901397705 	 0.31298375129699707 	 0.8542582988739014 	 0.24893999099731445 	 
2025-07-30 20:22:28.840080 test begin: paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-2,], )
[Prof] paddle.Tensor.flip 	 paddle.Tensor.flip(Tensor([424, 400, 300],"float32"), axis=list[-2,], ) 	 50880000 	 1000 	 0.9046318531036377 	 0.31659388542175293 	 0.8956706523895264 	 0.30159640312194824 	 0.9045102596282959 	 0.3164846897125244 	 0.8539974689483643 	 0.251049280166626 	 
2025-07-30 20:22:32.998917 test begin: paddle.Tensor.floor(Tensor([12700801, 4],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([12700801, 4],"float32"), ) 	 50803204 	 1000 	 0.2956719398498535 	 0.3006255626678467 	 0.2872624397277832 	 0.2870311737060547 	 0.13395214080810547 	 0.13421392440795898 	 0.08300471305847168 	 0.06344342231750488 	 
2025-07-30 20:22:37.390058 test begin: paddle.Tensor.floor(Tensor([1857, 27358],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1857, 27358],"float32"), ) 	 50803806 	 1000 	 0.29551053047180176 	 0.31142139434814453 	 0.27995967864990234 	 0.2870197296142578 	 0.1341407299041748 	 0.13426947593688965 	 0.07537627220153809 	 0.06096315383911133 	 
2025-07-30 20:22:40.367481 test begin: paddle.Tensor.floor(Tensor([1872, 27139],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1872, 27139],"float32"), ) 	 50804208 	 1000 	 0.2957038879394531 	 0.29791927337646484 	 0.2801222801208496 	 0.28087854385375977 	 0.13396596908569336 	 0.13430523872375488 	 0.07338690757751465 	 0.06646442413330078 	 
2025-07-30 20:22:42.979161 test begin: paddle.Tensor.floor(Tensor([1915, 26530],"float32"), )
[Prof] paddle.Tensor.floor 	 paddle.Tensor.floor(Tensor([1915, 26530],"float32"), ) 	 50804950 	 1000 	 0.29589343070983887 	 0.2982370853424072 	 0.28029847145080566 	 0.279707670211792 	 0.13400840759277344 	 0.13412237167358398 	 0.0746607780456543 	 0.06553363800048828 	 
2025-07-30 20:22:45.536712 test begin: paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([40, 12700801],"float32"), Tensor([40, 1],"int64"), 1, ) 	 508032080 	 1000 	 0.01724529266357422 	 1.805687427520752 	 2.2649765014648438e-05 	 0.00010919570922851562 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:22:57.129217 test begin: paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([400, 1270080],"float32"), Tensor([400, 1],"int64"), 1, ) 	 508032400 	 1000 	 0.009581565856933594 	 13.303192377090454 	 1.3828277587890625e-05 	 0.00013136863708496094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:23:20.274782 test begin: paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, )
[Prof] paddle.Tensor.gather 	 paddle.Tensor.gather(Tensor([4000, 127008],"float32"), Tensor([4000, 1],"int64"), 1, ) 	 508036000 	 1000 	 0.17024993896484375 	 159.18385457992554 	 0.15330004692077637 	 0.0003108978271484375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:26:10.370728 test begin: paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([11, 53, 8],"float32"), Tensor([40, 50, 2],"int64"), ) 	 8664 	 1000 	 0.02256155014038086 	 187.39516592025757 	 3.075599670410156e-05 	 0.00021839141845703125 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:29:18.143211 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 15, 80, 8],"float32"), Tensor([516, 4],"int64"), ) 	 462864 	 1000 	 0.018561124801635742 	 85.6384596824646 	 1.5497207641601562e-05 	 0.00023651123046875 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:30:44.005892 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 156, 85],"float32"), Tensor([516, 4],"int64"), ) 	 50920464 	 1000 	 0.018584012985229492 	 81.93593788146973 	 1.33514404296875e-05 	 0.00023794174194335938 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:32:07.084014 test begin: paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 3, 80, 80, 166],"float32"), Tensor([516, 4],"int64"), ) 	 50997264 	 1000 	 0.018685102462768555 	 89.48977160453796 	 1.4781951904296875e-05 	 0.0002148151397705078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:33:37.908193 test begin: paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([16, 6, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.010736227035522461 	 80.61983323097229 	 1.1444091796875e-05 	 0.0002377033233642578 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:34:59.955293 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.010956525802612305 	 56.94934105873108 	 1.1920928955078125e-05 	 0.00023555755615234375 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:35:58.158436 test begin: paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([32, 3, 80, 80, 85],"float32"), Tensor([516, 4],"int64"), ) 	 52226064 	 1000 	 0.010771512985229492 	 76.75290536880493 	 1.3828277587890625e-05 	 0.00022554397583007812 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:37:16.012261 test begin: paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 12, 80, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 52225540 	 1000 	 0.01077890396118164 	 57.03211855888367 	 1.4066696166992188e-05 	 0.00021910667419433594 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:38:14.132512 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 312, 80, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.011139869689941406 	 56.61725974082947 	 2.3126602172851562e-05 	 0.00021529197692871094 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:39:11.833695 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 312, 85],"float32"), Tensor([385, 4],"int64"), ) 	 50919940 	 1000 	 0.010683059692382812 	 56.685386180877686 	 1.1920928955078125e-05 	 0.0002200603485107422 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:40:10.462529 test begin: paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), )
[Prof] paddle.Tensor.gather_nd 	 paddle.Tensor.gather_nd(Tensor([8, 3, 80, 80, 331],"float32"), Tensor([385, 4],"int64"), ) 	 50843140 	 1000 	 0.019377470016479492 	 70.95244240760803 	 2.5033950805664062e-05 	 0.0002300739288330078 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:41:22.621322 test begin: paddle.Tensor.gcd(x=Tensor([127008, 2, 4, 5],"int32"), y=Tensor([127008, 2, 4, 5],"int32"), )
W0730 20:41:35.412099 53587 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([127008, 2, 4, 5],"int32"), y=Tensor([127008, 2, 4, 5],"int32"), ) 	 10160640 	 1000 	 12.507677555084229 	 0.3857879638671875 	 5.5789947509765625e-05 	 0.14174795150756836 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:41:38.839708 test begin: paddle.Tensor.gcd(x=Tensor([2, 4, 635040],"int32"), y=Tensor([2, 4, 635040],"int32"), )
W0730 20:41:51.026831 53643 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([2, 4, 635040],"int32"), y=Tensor([2, 4, 635040],"int32"), ) 	 10160640 	 1000 	 12.018361806869507 	 0.16169309616088867 	 5.1975250244140625e-05 	 0.14803409576416016 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:41:51.222592 test begin: paddle.Tensor.gcd(x=Tensor([2, 508032, 5],"int32"), y=Tensor([2, 508032, 5],"int32"), )
W0730 20:42:03.414363 53684 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([2, 508032, 5],"int32"), y=Tensor([2, 508032, 5],"int32"), ) 	 10160640 	 1000 	 12.03177547454834 	 0.15893125534057617 	 5.125999450683594e-05 	 0.14788341522216797 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:42:03.600373 test begin: paddle.Tensor.gcd(x=Tensor([254016, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), )
W0730 20:42:25.760511 53719 backward.cc:462] While running Node (RemainderGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.Tensor.gcd 	 paddle.Tensor.gcd(x=Tensor([254016, 1, 4, 5],"int32"), y=Tensor([2, 1, 5],"int32"), ) 	 5080330 	 1000 	 21.985634565353394 	 0.4259305000305176 	 5.245208740234375e-05 	 0.4136080741882324 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:42:26.212041 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([13001],"int64"), ) 	 50816225 	 1000 	 0.009559392929077148 	 0.01367497444152832 	 1.430511474609375e-05 	 4.9114227294921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:42:27.570592 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50821425 	 1000 	 0.009150266647338867 	 0.013627052307128906 	 1.4781951904296875e-05 	 2.5987625122070312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:42:28.573322 test begin: paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([2116801, 24],"float32"), axis=0, index=Tensor([9101],"int64"), ) 	 50812325 	 1000 	 0.009231805801391602 	 0.013802289962768555 	 2.09808349609375e-05 	 4.8160552978515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:42:29.616054 test begin: paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 12689],"float32"), axis=0, index=Tensor([18201],"int64"), ) 	 50824957 	 1000 	 3.1398727893829346 	 2.7614591121673584 	 3.1306700706481934 	 2.724128246307373 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:42:43.177433 test begin: paddle.Tensor.index_select(Tensor([4004, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([4004, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), ) 	 25497697 	 1000 	 8.18102502822876 	 8.60060453414917 	 8.171674966812134 	 8.586025714874268 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:43:15.202169 test begin: paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([130],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([130],"int64"), ) 	 50803638 	 1000 	 0.18890643119812012 	 0.17050600051879883 	 0.17969179153442383 	 0.15674257278442383 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:43:16.947767 test begin: paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([91],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 111902],"float32"), axis=0, index=Tensor([91],"int64"), ) 	 50803599 	 1000 	 0.13348102569580078 	 0.12172436714172363 	 0.11713457107543945 	 0.10044002532958984 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:43:18.456813 test begin: paddle.Tensor.index_select(Tensor([454, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.index_select 	 paddle.Tensor.index_select(Tensor([454, 24],"float32"), axis=0, index=Tensor([25401601],"int64"), ) 	 25412497 	 1000 	 7.6511757373809814 	 7.146633863449097 	 7.634848356246948 	 7.122175216674805 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:43:48.503302 test begin: paddle.Tensor.inner(x=Tensor([2, 1058401, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 1058401, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401744 	 1000 	 1.9709937572479248 	 1.9625096321105957 	 0.2876400947570801 	 0.2864539623260498 	 3.368520498275757 	 3.2443926334381104 	 0.38259196281433105 	 0.36783552169799805 	 
2025-07-30 20:44:03.912719 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), ) 	 25401744 	 1000 	 1.460308313369751 	 1.459488868713379 	 0.21320271492004395 	 0.2129817008972168 	 4.071436166763306 	 4.078806638717651 	 0.46173977851867676 	 0.4631195068359375 	 
2025-07-30 20:44:19.691550 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), ) 	 25401780 	 1000 	 1.8553543090820312 	 1.8608973026275635 	 0.2708258628845215 	 0.2715744972229004 	 3.4006991386413574 	 3.66530179977417 	 0.38550257682800293 	 0.4163060188293457 	 
2025-07-30 20:44:35.252039 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), ) 	 25401760 	 1000 	 1.4586730003356934 	 1.458400011062622 	 0.21298599243164062 	 0.21288633346557617 	 4.0697057247161865 	 4.0779571533203125 	 0.46167731285095215 	 0.4630393981933594 	 
2025-07-30 20:44:50.955362 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), ) 	 50803260 	 1000 	 0.33408546447753906 	 0.33366942405700684 	 0.17062997817993164 	 0.17045068740844727 	 0.7123885154724121 	 0.7502493858337402 	 0.36391234397888184 	 0.383195161819458 	 
2025-07-30 20:44:54.157252 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 635041, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2, 5, 635041, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401760 	 1000 	 1.9818336963653564 	 1.9622955322265625 	 0.2893502712249756 	 0.2864212989807129 	 3.3656458854675293 	 3.243539333343506 	 0.3822605609893799 	 0.3678734302520752 	 
2025-07-30 20:45:09.403405 test begin: paddle.Tensor.inner(x=Tensor([2116801, 3, 4],"float64"), y=Tensor([2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([2116801, 3, 4],"float64"), y=Tensor([2, 5, 4],"float64"), ) 	 25401652 	 1000 	 1.8647806644439697 	 1.8525614738464355 	 0.27225804328918457 	 0.2704787254333496 	 2.2439582347869873 	 2.27685809135437 	 0.25479841232299805 	 0.2582247257232666 	 
2025-07-30 20:45:19.600798 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 1058401, 4],"float64"), ) 	 25401636 	 1000 	 1.36857008934021 	 1.36871337890625 	 0.19979572296142578 	 0.19965887069702148 	 2.653169631958008 	 2.636202573776245 	 0.3010222911834717 	 0.29923224449157715 	 
2025-07-30 20:45:28.632154 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 423361, 5, 4],"float64"), ) 	 25401672 	 1000 	 1.3833060264587402 	 1.3883795738220215 	 0.20194530487060547 	 0.2027263641357422 	 2.3693182468414307 	 2.453667163848877 	 0.2687649726867676 	 0.2785623073577881 	 
2025-07-30 20:45:37.188570 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([635041, 2, 5, 4],"float64"), ) 	 25401652 	 1000 	 1.3728506565093994 	 1.393111228942871 	 0.2004108428955078 	 0.20101714134216309 	 2.652815341949463 	 2.6363840103149414 	 0.300980806350708 	 0.2992551326751709 	 
2025-07-30 20:45:46.959941 test begin: paddle.Tensor.inner(x=Tensor([3, 8467201],"float64"), y=Tensor([3, 2, 5, 8467201],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 8467201],"float64"), y=Tensor([3, 2, 5, 8467201],"float64"), ) 	 279417633 	 1000 	 1.7812187671661377 	 1.7734348773956299 	 0.9101920127868652 	 0.9062213897705078 	 4.053764820098877 	 4.214154005050659 	 0.23009943962097168 	 0.23889660835266113 	 
2025-07-30 20:46:04.737934 test begin: paddle.Tensor.inner(x=Tensor([3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([3, 846721],"float64"), y=Tensor([3, 2, 5, 846721],"float64"), ) 	 27941793 	 1000 	 0.1933605670928955 	 0.19167304039001465 	 0.0987236499786377 	 0.09792566299438477 	 0.41490817070007324 	 0.42475104331970215 	 0.2119307518005371 	 0.21690654754638672 	 
2025-07-30 20:46:06.552101 test begin: paddle.Tensor.inner(x=Tensor([423361, 5, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([423361, 5, 3, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401780 	 1000 	 1.9815280437469482 	 1.9647953510284424 	 0.28920912742614746 	 0.2868320941925049 	 3.365948438644409 	 3.2431256771087646 	 0.3822300434112549 	 0.3677191734313965 	 
2025-07-30 20:46:21.820213 test begin: paddle.Tensor.inner(x=Tensor([5, 1270081, 4],"float64"), y=Tensor([2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 1270081, 4],"float64"), y=Tensor([2, 5, 4],"float64"), ) 	 25401660 	 1000 	 1.8645567893981934 	 1.8522396087646484 	 0.272197961807251 	 0.2704024314880371 	 2.2434945106506348 	 2.2769558429718018 	 0.2547485828399658 	 0.2582237720489502 	 
2025-07-30 20:46:31.964364 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 1693441],"float64"), y=Tensor([2, 5, 1693441],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 1693441],"float64"), y=Tensor([2, 5, 1693441],"float64"), ) 	 42336025 	 1000 	 0.2971160411834717 	 0.2876009941101074 	 0.15172934532165527 	 0.14693307876586914 	 0.8216242790222168 	 0.8667218685150146 	 0.2098376750946045 	 0.22136855125427246 	 
2025-07-30 20:46:37.445752 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 2540161],"float64"), y=Tensor([2, 5, 2540161],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 2540161],"float64"), y=Tensor([2, 5, 2540161],"float64"), ) 	 63504025 	 1000 	 0.4292628765106201 	 0.4248192310333252 	 0.21931934356689453 	 0.2170422077178955 	 1.2389743328094482 	 1.3229329586029053 	 0.21092653274536133 	 0.22522306442260742 	 
2025-07-30 20:46:42.222600 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([1270081, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([1270081, 5, 4],"float64"), ) 	 25401680 	 1000 	 1.5790925025939941 	 1.5709362030029297 	 0.2305309772491455 	 0.2272934913635254 	 2.473147392272949 	 2.679516315460205 	 0.28055334091186523 	 0.30420422554016113 	 
2025-07-30 20:46:54.733691 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 3175201, 4],"float64"), ) 	 25401668 	 1000 	 1.5745530128479004 	 1.5538175106048584 	 0.2298288345336914 	 0.22681331634521484 	 2.7923355102539062 	 2.795315742492676 	 0.31688475608825684 	 0.3173391819000244 	 
2025-07-30 20:47:05.986873 test begin: paddle.Tensor.inner(x=Tensor([6350401, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), )
[Prof] paddle.Tensor.inner 	 paddle.Tensor.inner(x=Tensor([6350401, 4],"float64"), y=Tensor([3, 2, 5, 4],"float64"), ) 	 25401724 	 1000 	 1.9689691066741943 	 1.964646339416504 	 0.2873876094818115 	 0.2868170738220215 	 3.3670132160186768 	 3.243638753890991 	 0.38248181343078613 	 0.367887020111084 	 
2025-07-30 20:47:21.163884 test begin: paddle.Tensor.inverse(Tensor([4, 39690, 4, 4],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([4, 39690, 4, 4],"float64"), ) 	 2540160 	 1000 	 7.587523698806763 	 0.36263132095336914 	 0.00011491775512695312 	 8.082389831542969e-05 	 5.392694711685181 	 1.9654157161712646 	 0.919588565826416 	 0.28693389892578125 	 
2025-07-30 20:47:37.136578 test begin: paddle.Tensor.inverse(Tensor([70560, 6, 6],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([70560, 6, 6],"float64"), ) 	 2540160 	 1000 	 3.6414122581481934 	 0.4045753479003906 	 5.2928924560546875e-05 	 8.177757263183594e-05 	 2.1985301971435547 	 1.6719427108764648 	 0.562462568283081 	 0.34113454818725586 	 
2025-07-30 20:47:45.154743 test begin: paddle.Tensor.inverse(Tensor([79380, 2, 4, 4],"float64"), )
[Prof] paddle.Tensor.inverse 	 paddle.Tensor.inverse(Tensor([79380, 2, 4, 4],"float64"), ) 	 2540160 	 1000 	 8.156898498535156 	 0.3370683193206787 	 0.00011515617370605469 	 8.368492126464844e-05 	 5.395230293273926 	 1.965338945388794 	 0.9200160503387451 	 0.28691577911376953 	 
2025-07-30 20:48:01.138569 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 100, 42337],"float64"), ) 	 2552921100 	 1000 	 0.0035886764526367188 	 0.0019028186798095703 	 7.152557373046875e-06 	 3.457069396972656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:53.620284 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 105841, 40],"float64"), ) 	 2552884920 	 1000 	 0.00360107421875 	 0.0017147064208984375 	 9.059906005859375e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:49:46.060567 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 40, 105841],"float64"), ) 	 2552884920 	 1000 	 0.003556489944458008 	 0.0016825199127197266 	 7.152557373046875e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:50:39.325276 test begin: paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3, 42337, 100],"float64"), ) 	 2552921100 	 1000 	 0.00449681282043457 	 0.004169464111328125 	 8.58306884765625e-06 	 6.341934204101562e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:51:31.828612 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 100, 40],"float64"), ) 	 2553504000 	 1000 	 0.0036182403564453125 	 0.0017189979553222656 	 8.821487426757812e-06 	 1.621246337890625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:52:26.239556 test begin: paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([201, 3176, 40, 100],"float64"), ) 	 2553504000 	 1000 	 0.003579854965209961 	 0.0017075538635253906 	 7.3909759521484375e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:53:18.857139 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 100, 40],"float64"), ) 	 2540412000 	 1000 	 0.0036160945892333984 	 0.0016913414001464844 	 9.059906005859375e-06 	 1.71661376953125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:54:11.279916 test begin: paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([211701, 3, 40, 100],"float64"), ) 	 2540412000 	 1000 	 0.006905794143676758 	 0.0016858577728271484 	 9.5367431640625e-06 	 1.6927719116210938e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:03.830296 test begin: paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 100, 84673],"float64"), ) 	 2548657300 	 1000 	 0.003568410873413086 	 0.0016961097717285156 	 1.0967254638671875e-05 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:55:56.498778 test begin: paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([301, 211681, 40],"float64"), ) 	 2548639240 	 1000 	 0.0036034584045410156 	 0.0016787052154541016 	 9.298324584960938e-06 	 1.6689300537109375e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:56:50.379953 test begin: paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), )
[Prof] paddle.Tensor.is_complex 	 paddle.Tensor.is_complex(Tensor([635101, 100, 40],"float64"), ) 	 2540404000 	 1000 	 0.0035665035247802734 	 0.002320528030395508 	 7.3909759521484375e-06 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:44.376295 test begin: paddle.Tensor.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([1270081, 4, 5],"float64"), y=Tensor([1270081, 4, 5],"float64"), ) 	 50803240 	 1000 	 0.36271023750305176 	 3.081528902053833 	 0.34296655654907227 	 0.24178576469421387 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:49.231606 test begin: paddle.Tensor.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([25401601],"float64"), y=Tensor([25401601],"float64"), ) 	 50803202 	 1000 	 0.36281871795654297 	 3.0828495025634766 	 0.34571337699890137 	 0.24178576469421387 	 None 	 None 	 None 	 None 	 
2025-07-30 20:57:55.680837 test begin: paddle.Tensor.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([3, 1693441, 5],"float64"), y=Tensor([3, 1693441, 5],"float64"), ) 	 50803230 	 1000 	 0.36280155181884766 	 3.0829858779907227 	 0.3501720428466797 	 0.24179530143737793 	 None 	 None 	 None 	 None 	 
2025-07-30 20:58:00.211065 test begin: paddle.Tensor.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([3, 4, 2116801],"float64"), y=Tensor([3, 4, 2116801],"float64"), ) 	 50803224 	 1000 	 0.3628873825073242 	 3.0828750133514404 	 0.3500983715057373 	 0.2418360710144043 	 None 	 None 	 None 	 None 	 
2025-07-30 20:58:04.732251 test begin: paddle.Tensor.isclose(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.isclose 	 paddle.Tensor.isclose(x=Tensor([50803201],"float32"), y=Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.42579221725463867 	 3.3130548000335693 	 0.4129140377044678 	 0.25998806953430176 	 None 	 None 	 None 	 None 	 
2025-07-30 20:58:10.104338 test begin: paddle.Tensor.isnan(Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.isnan 	 paddle.Tensor.isnan(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.18122386932373047 	 0.16884160041809082 	 0.17355632781982422 	 0.15669631958007812 	 None 	 None 	 None 	 None 	 
2025-07-30 20:58:11.023789 test begin: paddle.Tensor.isnan(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.isnan 	 paddle.Tensor.isnan(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.23429226875305176 	 0.18607568740844727 	 0.22673559188842773 	 0.17435288429260254 	 None 	 None 	 None 	 None 	 
2025-07-30 20:58:12.268166 test begin: paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 1, 12700801],"int64"), 0, ) 	 2552861001 	 1000 	 0.01934528350830078 	 0.027953386306762695 	 1.1682510375976562e-05 	 3.719329833984375e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:58:52.580085 test begin: paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([201, 12700801, 1],"int64"), 0, ) 	 2552861001 	 1000 	 0.019217729568481445 	 0.029433250427246094 	 1.1920928955078125e-05 	 3.8623809814453125e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 20:59:33.374085 test begin: paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, )
[Prof] paddle.Tensor.item 	 paddle.Tensor.item(Tensor([2540160101, 1, 1],"int64"), 0, ) 	 2540160101 	 1000 	 0.019188642501831055 	 0.027853727340698242 	 1.239776611328125e-05 	 2.9087066650390625e-05 	 None 	 None 	 None 	 None 	 combined
2025-07-30 21:00:13.662224 test begin: paddle.Tensor.kthvalue(Tensor([2, 200, 127009],"float32"), k=200, axis=1, )
[Prof] paddle.Tensor.kthvalue 	 paddle.Tensor.kthvalue(Tensor([2, 200, 127009],"float32"), k=200, axis=1, ) 	 50803600 	 1000 	 6.685836315155029 	 11.624112129211426 	 1.7059872150421143 	 11.603870868682861 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:00:37.392134 test begin: paddle.Tensor.kthvalue(Tensor([2, 2540161, 10],"float32"), k=200, axis=1, )
[Prof] paddle.Tensor.kthvalue 	 paddle.Tensor.kthvalue(Tensor([2, 2540161, 10],"float32"), k=200, axis=1, ) 	 50803220 	 1000 	 37.61453461647034 	 33.82179808616638 	 9.590194463729858 	 33.8019495010376 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:01:54.023583 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.0, ) 	 50803360 	 1000 	 0.45079660415649414 	 0.4450066089630127 	 0.23027443885803223 	 0.43175792694091797 	 0.48045969009399414 	 0.597203254699707 	 0.42030763626098633 	 0.30507564544677734 	 
2025-07-30 21:01:57.570812 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=0.5, ) 	 50803360 	 1000 	 0.4519186019897461 	 0.4480123519897461 	 0.2315504550933838 	 0.4315919876098633 	 0.4803805351257324 	 0.5971734523773193 	 0.4019627571105957 	 0.3051106929779053 	 
2025-07-30 21:02:01.163941 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 4, 317521],"float64"), y=Tensor([4, 5, 4, 317521],"float64"), weight=1.0, ) 	 50803360 	 1000 	 0.450850248336792 	 0.4450044631958008 	 0.2302718162536621 	 0.43181300163269043 	 0.4819042682647705 	 0.5973384380340576 	 0.42238545417785645 	 0.3052210807800293 	 
2025-07-30 21:02:04.719978 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.0, ) 	 50803320 	 1000 	 0.4510068893432617 	 0.4462888240814209 	 0.23041558265686035 	 0.4329335689544678 	 0.48128533363342285 	 0.5972626209259033 	 0.4208369255065918 	 0.3051731586456299 	 
2025-07-30 21:02:08.298246 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=0.5, ) 	 50803320 	 1000 	 0.4510626792907715 	 0.4449608325958252 	 0.2305140495300293 	 0.43175816535949707 	 0.4811546802520752 	 0.598630428314209 	 0.42132997512817383 	 0.30654358863830566 	 
2025-07-30 21:02:11.917000 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 5, 423361, 3],"float64"), y=Tensor([4, 5, 423361, 3],"float64"), weight=1.0, ) 	 50803320 	 1000 	 0.4509398937225342 	 0.44734787940979004 	 0.23041296005249023 	 0.4315962791442871 	 0.48126888275146484 	 0.5972323417663574 	 0.4216797351837158 	 0.3050534725189209 	 
2025-07-30 21:02:17.206183 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.0, ) 	 50803296 	 1000 	 0.4510478973388672 	 0.4449894428253174 	 0.230438232421875 	 0.43181705474853516 	 0.4811434745788574 	 0.5972380638122559 	 0.4213674068450928 	 0.30510711669921875 	 
2025-07-30 21:02:20.840958 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=0.5, ) 	 50803296 	 1000 	 0.4508383274078369 	 0.44504261016845703 	 0.2303600311279297 	 0.4318101406097412 	 0.4826319217681885 	 0.5972802639007568 	 0.42350006103515625 	 0.3051581382751465 	 
2025-07-30 21:02:24.380353 test begin: paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([4, 529201, 4, 3],"float64"), y=Tensor([4, 529201, 4, 3],"float64"), weight=1.0, ) 	 50803296 	 1000 	 0.4509003162384033 	 0.44498658180236816 	 0.23041272163391113 	 0.43137097358703613 	 0.48117494583129883 	 0.5985236167907715 	 0.4181344509124756 	 0.3064851760864258 	 
2025-07-30 21:02:27.956973 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.0, ) 	 50803320 	 1000 	 0.45095086097717285 	 0.4449450969696045 	 0.23041534423828125 	 0.4316849708557129 	 0.48115992546081543 	 0.5972678661346436 	 0.4209010601043701 	 0.3051333427429199 	 
2025-07-30 21:02:31.657007 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.5, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=0.5, ) 	 50803320 	 1000 	 0.4507277011871338 	 0.4489459991455078 	 0.23026418685913086 	 0.4248921871185303 	 0.4812028408050537 	 0.5972132682800293 	 0.42162203788757324 	 0.3051605224609375 	 
2025-07-30 21:02:37.170806 test begin: paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=1.0, )
[Prof] paddle.Tensor.lerp 	 paddle.Tensor.lerp(x=Tensor([423361, 5, 4, 3],"float64"), y=Tensor([423361, 5, 4, 3],"float64"), weight=1.0, ) 	 50803320 	 1000 	 0.45070791244506836 	 0.4495227336883545 	 0.23024988174438477 	 0.4326496124267578 	 0.48122072219848633 	 0.5971364974975586 	 0.4121255874633789 	 0.3050098419189453 	 
2025-07-30 21:02:40.878943 test begin: paddle.Tensor.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.less 	 paddle.Tensor.less(Tensor([10, 5080321],"float32"), Tensor([10, 5080321],"float32"), ) 	 101606420 	 1000 	 0.32662439346313477 	 0.32776737213134766 	 0.3174703121185303 	 0.31611037254333496 	 None 	 None 	 None 	 None 	 
2025-07-30 21:02:43.156904 test begin: paddle.Tensor.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), )
[Prof] paddle.Tensor.less 	 paddle.Tensor.less(Tensor([49613, 1024],"float32"), Tensor([49613, 1024],"float32"), ) 	 101607424 	 1000 	 0.3269767761230469 	 0.32779574394226074 	 0.31782007217407227 	 0.31609511375427246 	 None 	 None 	 None 	 None 	 
2025-07-30 21:02:45.416390 test begin: paddle.Tensor.lgamma(Tensor([100, 100, 2541],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([100, 100, 2541],"float64"), ) 	 25410000 	 1000 	 0.7131335735321045 	 0.6924171447753906 	 0.7047030925750732 	 0.6823554039001465 	 1.3867301940917969 	 1.5874204635620117 	 1.3355207443237305 	 0.8110916614532471 	 
2025-07-30 21:02:50.832209 test begin: paddle.Tensor.lgamma(Tensor([100, 2541, 100],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([100, 2541, 100],"float64"), ) 	 25410000 	 1000 	 0.7131736278533936 	 0.7073769569396973 	 0.6974198818206787 	 0.6802761554718018 	 1.3880410194396973 	 1.5874807834625244 	 1.328287124633789 	 0.8111152648925781 	 
2025-07-30 21:02:56.338718 test begin: paddle.Tensor.lgamma(Tensor([2541, 100, 100],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([2541, 100, 100],"float64"), ) 	 25410000 	 1000 	 0.7132189273834229 	 0.6910867691040039 	 0.704798698425293 	 0.6809475421905518 	 1.3867592811584473 	 1.5874841213226318 	 1.3360416889190674 	 0.8111233711242676 	 
2025-07-30 21:03:01.798991 test begin: paddle.Tensor.lgamma(Tensor([453601, 7, 8],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([453601, 7, 8],"float64"), ) 	 25401656 	 1000 	 0.7143087387084961 	 0.6927857398986816 	 0.7059326171875 	 0.6797690391540527 	 1.38193941116333 	 1.5884034633636475 	 1.3305683135986328 	 0.8123562335968018 	 
2025-07-30 21:03:07.261143 test begin: paddle.Tensor.lgamma(Tensor([45361, 7, 8, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([45361, 7, 8, 10],"float64"), ) 	 25402160 	 1000 	 0.7129547595977783 	 0.690805196762085 	 0.7044479846954346 	 0.6806824207305908 	 1.3815498352050781 	 1.5885045528411865 	 1.3302783966064453 	 0.8108887672424316 	 
2025-07-30 21:03:12.736081 test begin: paddle.Tensor.lgamma(Tensor([5, 635041, 8],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 635041, 8],"float64"), ) 	 25401640 	 1000 	 0.7129766941070557 	 0.692795991897583 	 0.704578161239624 	 0.6819024085998535 	 1.3820226192474365 	 1.5871472358703613 	 1.3120787143707275 	 0.8110299110412598 	 
2025-07-30 21:03:19.419421 test begin: paddle.Tensor.lgamma(Tensor([5, 63505, 8, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 63505, 8, 10],"float64"), ) 	 25402000 	 1000 	 0.712932825088501 	 0.6932229995727539 	 0.7044434547424316 	 0.6800065040588379 	 1.3821642398834229 	 1.5869464874267578 	 1.3308727741241455 	 0.8108673095703125 	 
2025-07-30 21:03:24.884108 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 725761],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 725761],"float64"), ) 	 25401635 	 1000 	 0.7128736972808838 	 0.6906337738037109 	 0.7044703960418701 	 0.6804897785186768 	 1.3830623626708984 	 1.5867364406585693 	 1.3321497440338135 	 0.8108012676239014 	 
2025-07-30 21:03:30.354317 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 72577, 10],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 72577, 10],"float64"), ) 	 25401950 	 1000 	 0.7129511833190918 	 0.6906418800354004 	 0.7045619487762451 	 0.6805622577667236 	 1.3834285736083984 	 1.5867886543273926 	 1.3327009677886963 	 0.8107566833496094 	 
2025-07-30 21:03:37.102577 test begin: paddle.Tensor.lgamma(Tensor([5, 7, 8, 90721],"float64"), )
[Prof] paddle.Tensor.lgamma 	 paddle.Tensor.lgamma(Tensor([5, 7, 8, 90721],"float64"), ) 	 25401880 	 1000 	 0.7128751277923584 	 0.6999974250793457 	 0.7044556140899658 	 0.6799559593200684 	 1.3832762241363525 	 1.5867335796356201 	 1.3325040340423584 	 0.8107690811157227 	 
2025-07-30 21:03:42.542095 test begin: paddle.Tensor.log(Tensor([100, 200, 1271],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([100, 200, 1271],"float64"), ) 	 25420000 	 1000 	 0.30568385124206543 	 0.31714439392089844 	 0.2973790168762207 	 0.29680657386779785 	 0.44771695137023926 	 0.4491422176361084 	 0.39499592781066895 	 0.3815915584564209 	 
2025-07-30 21:03:45.163636 test begin: paddle.Tensor.log(Tensor([100, 2541, 100],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([100, 2541, 100],"float64"), ) 	 25410000 	 1000 	 0.3053710460662842 	 0.3084402084350586 	 0.29718470573425293 	 0.29427170753479004 	 0.4474611282348633 	 0.4489858150482178 	 0.3948040008544922 	 0.381136417388916 	 
2025-07-30 21:03:47.760446 test begin: paddle.Tensor.log(Tensor([10000, 5, 509],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([10000, 5, 509],"float64"), ) 	 25450000 	 1000 	 0.3060629367828369 	 0.30875611305236816 	 0.2978086471557617 	 0.2955284118652344 	 0.4482851028442383 	 0.44962215423583984 	 0.39563441276550293 	 0.3820183277130127 	 
2025-07-30 21:03:50.501534 test begin: paddle.Tensor.log(Tensor([10000, 847, 3],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([10000, 847, 3],"float64"), ) 	 25410000 	 1000 	 0.3054673671722412 	 0.30645060539245605 	 0.2860679626464844 	 0.2893548011779785 	 0.4475092887878418 	 0.4489266872406006 	 0.38555192947387695 	 0.3807082176208496 	 
2025-07-30 21:03:53.145258 test begin: paddle.Tensor.log(Tensor([1271, 200, 100],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([1271, 200, 100],"float64"), ) 	 25420000 	 1000 	 0.30569982528686523 	 0.31244659423828125 	 0.2973768711090088 	 0.29677700996398926 	 0.44759488105773926 	 0.4491281509399414 	 0.3947482109069824 	 0.35982728004455566 	 
2025-07-30 21:03:55.721097 test begin: paddle.Tensor.log(Tensor([1693441, 5, 3],"float64"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([1693441, 5, 3],"float64"), ) 	 25401615 	 1000 	 0.3053407669067383 	 0.3064422607421875 	 0.2971303462982178 	 0.2953777313232422 	 0.4474754333496094 	 0.450364351272583 	 0.39467573165893555 	 0.3842580318450928 	 
2025-07-30 21:03:58.277495 test begin: paddle.Tensor.log(Tensor([4800, 10585],"float32"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([4800, 10585],"float32"), ) 	 50808000 	 1000 	 0.29559803009033203 	 0.2976415157318115 	 0.28722286224365234 	 0.2865638732910156 	 0.4502592086791992 	 0.44968652725219727 	 0.39716291427612305 	 0.38154053688049316 	 
2025-07-30 21:04:01.473122 test begin: paddle.Tensor.log(Tensor([503002, 101],"float32"), )
[Prof] paddle.Tensor.log 	 paddle.Tensor.log(Tensor([503002, 101],"float32"), ) 	 50803202 	 1000 	 0.29561710357666016 	 0.2975435256958008 	 0.28723740577697754 	 0.2866225242614746 	 0.4501814842224121 	 0.4510498046875 	 0.39759063720703125 	 0.383087158203125 	 
2025-07-30 21:04:04.601595 test begin: paddle.Tensor.log10(Tensor([101811, 499],"float32"), )
[Prof] paddle.Tensor.log10 	 paddle.Tensor.log10(Tensor([101811, 499],"float32"), ) 	 50803689 	 1000 	 0.2956573963165283 	 0.30416059494018555 	 0.28708624839782715 	 0.28797411918640137 	 0.44992494583129883 	 0.7457175254821777 	 0.39469313621520996 	 0.38097429275512695 	 
2025-07-30 21:04:08.093949 test begin: paddle.Tensor.log10(Tensor([80, 635041],"float32"), )
[Prof] paddle.Tensor.log10 	 paddle.Tensor.log10(Tensor([80, 635041],"float32"), ) 	 50803280 	 1000 	 0.29686665534973145 	 0.2975645065307617 	 0.28829503059387207 	 0.2865321636199951 	 0.4496493339538574 	 0.7457635402679443 	 0.39380931854248047 	 0.3810393810272217 	 
2025-07-30 21:04:11.666460 test begin: paddle.Tensor.log1p(Tensor([16934401, 3],"float32"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2956550121307373 	 0.29889941215515137 	 0.28684306144714355 	 0.28809690475463867 	 0.44983577728271484 	 0.7457616329193115 	 0.3969535827636719 	 0.3810439109802246 	 
2025-07-30 21:04:15.125644 test begin: paddle.Tensor.log1p(Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29689621925354004 	 0.29890966415405273 	 0.288055419921875 	 0.28800392150878906 	 0.44977402687072754 	 0.745903730392456 	 0.39691853523254395 	 0.3811202049255371 	 
2025-07-30 21:04:18.539603 test begin: paddle.Tensor.log1p(Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 3, 4233601],"float64"), ) 	 25401606 	 1000 	 0.30516672134399414 	 0.3373897075653076 	 0.29653453826904297 	 0.3264894485473633 	 0.4475419521331787 	 0.7448227405548096 	 0.3929905891418457 	 0.38051700592041016 	 
2025-07-30 21:04:21.490787 test begin: paddle.Tensor.log1p(Tensor([2, 6350401, 2],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([2, 6350401, 2],"float64"), ) 	 25401604 	 1000 	 0.30518364906311035 	 0.3429281711578369 	 0.29666805267333984 	 0.31893467903137207 	 0.4473843574523926 	 0.7448365688323975 	 0.39513707160949707 	 0.38051509857177734 	 
2025-07-30 21:04:26.987034 test begin: paddle.Tensor.log1p(Tensor([25401601],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 0.3051462173461914 	 0.3360586166381836 	 0.2896728515625 	 0.31914758682250977 	 0.44907140731811523 	 0.744858980178833 	 0.38776636123657227 	 0.3805959224700928 	 
2025-07-30 21:04:29.923662 test begin: paddle.Tensor.log1p(Tensor([4233601, 3, 2],"float64"), )
[Prof] paddle.Tensor.log1p 	 paddle.Tensor.log1p(Tensor([4233601, 3, 2],"float64"), ) 	 25401606 	 1000 	 0.30516505241394043 	 0.3417017459869385 	 0.2966141700744629 	 0.3264029026031494 	 0.44753336906433105 	 0.7448365688323975 	 0.39471006393432617 	 0.3805253505706787 	 
2025-07-30 21:04:32.834924 test begin: paddle.Tensor.logical_and(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_and 	 paddle.Tensor.logical_and(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11865663528442383 	 0.11970329284667969 	 0.10947084426879883 	 0.10265517234802246 	 None 	 None 	 None 	 None 	 
2025-07-30 21:04:34.492542 test begin: paddle.Tensor.logical_not(Tensor([508032010],"bool"), )
[Prof] paddle.Tensor.logical_not 	 paddle.Tensor.logical_not(Tensor([508032010],"bool"), ) 	 508032010 	 1000 	 0.7881636619567871 	 0.7493693828582764 	 0.7796409130096436 	 0.7335727214813232 	 None 	 None 	 None 	 None 	 
2025-07-30 21:04:43.011596 test begin: paddle.Tensor.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.logical_or 	 paddle.Tensor.logical_or(Tensor([50803201],"bool"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 0.11816167831420898 	 0.12292838096618652 	 0.10510063171386719 	 0.10243654251098633 	 None 	 None 	 None 	 None 	 
2025-07-30 21:04:44.694222 test begin: paddle.Tensor.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([4, 3, 423361, 5],"float64"), eps=0.2, ) 	 25401660 	 1000 	 0.3247096538543701 	 0.3029639720916748 	 0.3155336380004883 	 0.2901735305786133 	 0.44345569610595703 	 0.4488203525543213 	 0.3909873962402344 	 0.3817253112792969 	 
2025-07-30 21:04:47.256988 test begin: paddle.Tensor.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([4, 635041, 2, 5],"float64"), eps=0.2, ) 	 25401640 	 1000 	 0.3247182369232178 	 0.3028545379638672 	 0.31572413444519043 	 0.2901265621185303 	 0.4448733329772949 	 0.4501156806945801 	 0.3924984931945801 	 0.382305383682251 	 
2025-07-30 21:04:49.815227 test begin: paddle.Tensor.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, )
[Prof] paddle.Tensor.logit 	 paddle.Tensor.logit(x=Tensor([846721, 3, 2, 5],"float64"), eps=0.2, ) 	 25401630 	 1000 	 0.3247232437133789 	 0.3028898239135742 	 0.31546568870544434 	 0.28997015953063965 	 0.4444904327392578 	 0.44884610176086426 	 0.3905911445617676 	 0.38097453117370605 	 
2025-07-30 21:04:52.386449 test begin: paddle.Tensor.lu(Tensor([1693, 300],"float32"), )
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:924: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2055.)
  LU, pivots, infos = torch._lu_with_info(
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([1693, 300],"float32"), ) 	 507900 	 1000 	 2.9009037017822266 	 12.164302825927734 	 5.030632019042969e-05 	 0.000213623046875 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:05:08.279117 test begin: paddle.Tensor.lu(Tensor([216, 3, 2, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([216, 3, 2, 2],"float64"), ) 	 2592 	 1000 	 12.869272708892822 	 0.03725314140319824 	 0.00010704994201660156 	 5.1021575927734375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:05:26.316342 test begin: paddle.Tensor.lu(Tensor([3, 3, 422],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([3, 3, 422],"float64"), ) 	 3798 	 1000 	 0.1408226490020752 	 0.13243746757507324 	 4.744529724121094e-05 	 6.580352783203125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:05:26.975348 test begin: paddle.Tensor.lu(Tensor([301, 1193],"float32"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 1193],"float32"), ) 	 359093 	 1000 	 1.3679022789001465 	 12.075076818466187 	 7.867813110351562e-05 	 0.00021529197692871094 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:05:41.386345 test begin: paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([301, 422, 3],"float64"), ) 	 381066 	 1000 	 8.324045658111572 	 0.11628913879394531 	 0.00011420249938964844 	 5.817413330078125e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:05:54.339776 test begin: paddle.Tensor.lu(Tensor([4, 187, 2, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 187, 2, 2],"float64"), ) 	 2992 	 1000 	 14.735588073730469 	 0.04134774208068848 	 0.0001049041748046875 	 5.626678466796875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:06:15.090220 test begin: paddle.Tensor.lu(Tensor([4, 3, 158, 2],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 3, 158, 2],"float64"), ) 	 3792 	 1000 	 0.2857179641723633 	 0.10497307777404785 	 5.054473876953125e-05 	 6.198883056640625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:06:15.947188 test begin: paddle.Tensor.lu(Tensor([4, 3, 2, 158],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([4, 3, 2, 158],"float64"), ) 	 3792 	 1000 	 0.37969470024108887 	 0.13704371452331543 	 3.886222839355469e-05 	 6.008148193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:06:16.906926 test begin: paddle.Tensor.lu(Tensor([522, 3, 3],"float64"), )
[Prof] paddle.Tensor.lu 	 paddle.Tensor.lu(Tensor([522, 3, 3],"float64"), ) 	 4698 	 1000 	 11.009448766708374 	 0.03691291809082031 	 0.00010752677917480469 	 6.0558319091796875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:06:32.157777 test begin: paddle.Tensor.masked_fill(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 198451, 256],"float32"), Tensor([1, 198451, 1],"bool"), 0.0, ) 	 51001907 	 1000 	 0.14305615425109863 	 0.637871265411377 	 0.04871201515197754 	 0.21056342124938965 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:35.061682 test begin: paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1380],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1380],"bool"), 0.0, ) 	 101645280 	 1000 	 0.3822150230407715 	 0.6551303863525391 	 0.09776043891906738 	 0.22162127494812012 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:41.996106 test begin: paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 36828, 1380],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, ) 	 50859468 	 1000 	 0.14348363876342773 	 0.6206159591674805 	 0.04843449592590332 	 0.2112443447113037 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:44.553149 test begin: paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1325],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1325],"bool"), 0.0, ) 	 101672550 	 1000 	 0.3824272155761719 	 0.6546320915222168 	 0.09779548645019531 	 0.22187423706054688 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:48.290004 test begin: paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 38367, 1325],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, ) 	 50874642 	 1000 	 0.2497260570526123 	 0.6210381984710693 	 0.0851144790649414 	 0.21140408515930176 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:51.087408 test begin: paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, ) 	 50812650 	 1000 	 0.14198613166809082 	 0.6162548065185547 	 0.04835343360900879 	 0.20976734161376953 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:53.623649 test begin: paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 5942],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([1, 8550, 5942],"float32"), Tensor([1, 8550, 5942],"bool"), 0.0, ) 	 101608200 	 1000 	 0.38255977630615234 	 0.652099609375 	 0.09783458709716797 	 0.22295928001403809 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:06:57.309789 test begin: paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([1, 8550, 1],"bool"), 0.0, ) 	 52539750 	 1000 	 0.4623284339904785 	 0.6376469135284424 	 0.11830282211303711 	 0.3257267475128174 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:00.575731 test begin: paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([24, 8550, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([24, 8550, 256],"float32"), Tensor([24, 8550, 1],"bool"), 0.0, ) 	 52736400 	 1000 	 0.14871931076049805 	 0.636667013168335 	 0.05021500587463379 	 0.3252298831939697 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:03.208196 test begin: paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([1, 36828, 1],"bool"), 0.0, ) 	 56604636 	 1000 	 0.4964621067047119 	 0.7037336826324463 	 0.12702226638793945 	 0.3516099452972412 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:06.787366 test begin: paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([6, 36828, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 36828, 256],"float32"), Tensor([6, 36828, 1],"bool"), 0.0, ) 	 56788776 	 1000 	 0.1601862907409668 	 0.6867527961730957 	 0.056130170822143555 	 0.3499565124511719 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:09.663382 test begin: paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([1, 38367, 1],"bool"), 0.0, ) 	 58970079 	 1000 	 0.5177662372589111 	 0.7191569805145264 	 0.1324934959411621 	 0.24481415748596191 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:13.401404 test begin: paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([6, 38367, 1],"bool"), 0.0, )
[Prof] paddle.Tensor.masked_fill 	 paddle.Tensor.masked_fill(Tensor([6, 38367, 256],"float32"), Tensor([6, 38367, 1],"bool"), 0.0, ) 	 59161914 	 1000 	 0.16469359397888184 	 0.7156915664672852 	 0.05611395835876465 	 0.24360251426696777 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:16.428388 test begin: paddle.Tensor.masked_select(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([1016065, 50],"float32"), Tensor([1016065, 50],"bool"), ) 	 101606500 	 1000 	 2.6289262771606445 	 2.4543237686157227 	 0.0016448497772216797 	 0.0023543834686279297 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:26.477039 test begin: paddle.Tensor.masked_select(Tensor([15000, 3387],"float32"), Tensor([15000, 3387],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([15000, 3387],"float32"), Tensor([15000, 3387],"bool"), ) 	 101610000 	 1000 	 1.3889646530151367 	 2.458620309829712 	 0.0008585453033447266 	 0.0023658275604248047 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:34.148692 test begin: paddle.Tensor.masked_select(Tensor([50803201],"float32"), Tensor([50803201],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([50803201],"float32"), Tensor([50803201],"bool"), ) 	 101606402 	 1000 	 4.812017917633057 	 1.132666826248169 	 0.0029268264770507812 	 0.0010390281677246094 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:47.341167 test begin: paddle.Tensor.masked_select(Tensor([60000, 847],"float32"), Tensor([60000, 847],"bool"), )
[Prof] paddle.Tensor.masked_select 	 paddle.Tensor.masked_select(Tensor([60000, 847],"float32"), Tensor([60000, 847],"bool"), ) 	 101640000 	 1000 	 1.3896152973175049 	 2.4430630207061768 	 0.0008687973022460938 	 0.0023293495178222656 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:07:55.048927 test begin: paddle.Tensor.matmul(Tensor([110, 12, 197, 197],"float32"), Tensor([110, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([110, 12, 197, 197],"float32"), Tensor([110, 12, 197, 64],"float32"), ) 	 67870440 	 1000 	 1.030886173248291 	 1.0281569957733154 	 1.0098111629486084 	 0.9948713779449463 	 1.7537949085235596 	 1.7567307949066162 	 0.8960981369018555 	 0.8975982666015625 	 
2025-07-30 21:08:02.131890 test begin: paddle.Tensor.matmul(Tensor([124, 16, 100, 257],"float32"), Tensor([124, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 16, 100, 257],"float32"), Tensor([124, 16, 257, 64],"float32"), ) 	 83621632 	 1000 	 1.0263638496398926 	 1.026496410369873 	 1.0047621726989746 	 0.9928905963897705 	 2.059748649597168 	 2.0590007305145264 	 1.0523896217346191 	 1.0527334213256836 	 
2025-07-30 21:08:09.942259 test begin: paddle.Tensor.matmul(Tensor([124, 16, 257, 257],"float32"), Tensor([124, 16, 257, 100],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 16, 257, 257],"float32"), Tensor([124, 16, 257, 100],"float32"), ) 	 182030016 	 1000 	 3.0055294036865234 	 3.0054826736450195 	 2.984549045562744 	 2.980511426925659 	 6.689855337142944 	 6.694399833679199 	 3.41711688041687 	 3.4208312034606934 	 
2025-07-30 21:08:33.281129 test begin: paddle.Tensor.matmul(Tensor([124, 25, 257, 257],"float32"), Tensor([124, 25, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 25, 257, 257],"float32"), Tensor([124, 25, 257, 64],"float32"), ) 	 255740700 	 1000 	 4.656464099884033 	 4.671267747879028 	 4.6395041942596436 	 4.627784490585327 	 8.448498010635376 	 8.447123289108276 	 4.315463542938232 	 4.317403078079224 	 
2025-07-30 21:09:05.203013 test begin: paddle.Tensor.matmul(Tensor([124, 7, 257, 257],"float32"), Tensor([124, 7, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([124, 7, 257, 257],"float32"), Tensor([124, 7, 257, 64],"float32"), ) 	 71607396 	 1000 	 1.3437654972076416 	 1.3684682846069336 	 1.329847812652588 	 1.3198237419128418 	 2.4161736965179443 	 2.4140777587890625 	 1.235152006149292 	 1.233593225479126 	 
2025-07-30 21:09:14.236109 test begin: paddle.Tensor.matmul(Tensor([128, 11, 197, 197],"float32"), Tensor([128, 11, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 11, 197, 197],"float32"), Tensor([128, 11, 197, 64],"float32"), ) 	 72395136 	 1000 	 1.1077601909637451 	 1.1105444431304932 	 1.0951271057128906 	 1.0870463848114014 	 1.8805501461029053 	 1.8805737495422363 	 0.9609360694885254 	 0.9608054161071777 	 
2025-07-30 21:09:21.691962 test begin: paddle.Tensor.matmul(Tensor([128, 12, 168, 197],"float32"), Tensor([128, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 12, 168, 197],"float32"), Tensor([128, 12, 197, 64],"float32"), ) 	 70201344 	 1000 	 1.1908841133117676 	 1.1897737979888916 	 1.1762056350708008 	 1.1660394668579102 	 1.851827621459961 	 1.8548588752746582 	 0.9462122917175293 	 0.9477472305297852 	 
2025-07-30 21:09:29.235525 test begin: paddle.Tensor.matmul(Tensor([128, 12, 197, 197],"float32"), Tensor([128, 12, 197, 168],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 12, 197, 197],"float32"), Tensor([128, 12, 197, 168],"float32"), ) 	 110446080 	 1000 	 2.3323934078216553 	 2.335811138153076 	 2.3196444511413574 	 2.3093197345733643 	 4.306124687194824 	 4.308885097503662 	 2.200388193130493 	 2.2030599117279053 	 
2025-07-30 21:09:47.442188 test begin: paddle.Tensor.matmul(Tensor([128, 16, 257, 257],"float32"), Tensor([128, 16, 257, 97],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 16, 257, 257],"float32"), Tensor([128, 16, 257, 97],"float32"), ) 	 186322944 	 1000 	 3.0619595050811768 	 3.062161445617676 	 3.049142360687256 	 3.036648988723755 	 6.864289999008179 	 6.865504503250122 	 3.508866310119629 	 3.507474422454834 	 
2025-07-30 21:10:11.389415 test begin: paddle.Tensor.matmul(Tensor([128, 16, 97, 257],"float32"), Tensor([128, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 16, 97, 257],"float32"), Tensor([128, 16, 257, 64],"float32"), ) 	 84740096 	 1000 	 1.0267341136932373 	 1.0283195972442627 	 1.0139379501342773 	 1.001833438873291 	 2.108839988708496 	 2.107431173324585 	 1.0782911777496338 	 1.0768511295318604 	 
2025-07-30 21:10:19.364188 test begin: paddle.Tensor.matmul(Tensor([128, 25, 257, 257],"float32"), Tensor([128, 25, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 25, 257, 257],"float32"), Tensor([128, 25, 257, 64],"float32"), ) 	 263990400 	 1000 	 4.767198801040649 	 4.771460056304932 	 4.754379034042358 	 4.741636514663696 	 8.68326711654663 	 8.682406902313232 	 4.437148332595825 	 4.436518907546997 	 
2025-07-30 21:10:53.127180 test begin: paddle.Tensor.matmul(Tensor([128, 32, 197, 197],"float32"), Tensor([128, 32, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 32, 197, 197],"float32"), Tensor([128, 32, 197, 64],"float32"), ) 	 210604032 	 1000 	 3.1037397384643555 	 3.103778123855591 	 3.089285373687744 	 3.079989433288574 	 5.331090688705444 	 5.332467555999756 	 2.725461721420288 	 2.724611759185791 	 
2025-07-30 21:11:15.351272 test begin: paddle.Tensor.matmul(Tensor([128, 7, 257, 257],"float32"), Tensor([128, 7, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([128, 7, 257, 257],"float32"), Tensor([128, 7, 257, 64],"float32"), ) 	 73917312 	 1000 	 1.3456459045410156 	 1.3481078147888184 	 1.3328831195831299 	 1.3222196102142334 	 2.451960563659668 	 2.4519946575164795 	 1.2521073818206787 	 1.2520923614501953 	 
2025-07-30 21:11:24.439652 test begin: paddle.Tensor.matmul(Tensor([194, 16, 257, 257],"float32"), Tensor([194, 16, 257, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([194, 16, 257, 257],"float32"), Tensor([194, 16, 257, 64],"float32"), ) 	 256070688 	 1000 	 4.655925750732422 	 4.6554601192474365 	 4.6349663734436035 	 4.630154848098755 	 8.452616453170776 	 8.453736305236816 	 4.319774627685547 	 4.319623947143555 	 
2025-07-30 21:11:56.073633 test begin: paddle.Tensor.matmul(Tensor([336, 12, 197, 197],"float32"), Tensor([336, 12, 197, 64],"float32"), )
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([336, 12, 197, 197],"float32"), Tensor([336, 12, 197, 64],"float32"), ) 	 207313344 	 1000 	 3.0630810260772705 	 3.064727783203125 	 3.050295114517212 	 3.0411150455474854 	 5.255791902542114 	 5.255235433578491 	 2.6855387687683105 	 2.6854052543640137 	 

2025-07-30 19:24:43.740891 test begin: paddle.Tensor.matmul(Tensor([49, 16, 257, 257],"float32"), Tensor([49, 16, 257, 64],"float32"), )
W0730 19:24:44.896723 24309 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.2, Runtime API Version: 11.8
[Prof] paddle.Tensor.matmul 	 paddle.Tensor.matmul(Tensor([49, 16, 257, 257],"float32"), Tensor([49, 16, 257, 64],"float32"), ) 	 64677648 	 1000 	 1.186058759689331 	 1.1913340091705322 	 1.1721382141113281 	 1.1589581966400146 	 2.153837203979492 	 2.1535844802856445 	 1.1004855632781982 	 1.1003258228302002 	 
2025-07-30 19:24:52.479923 test begin: paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), -2, ) 	 50803600 	 1000 	 0.2616891860961914 	 0.19534850120544434 	 0.25020623207092285 	 0.17622590065002441 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:24:54.975874 test begin: paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 400, 127009],"float32"), axis=-1, keepdim=True, ) 	 50803600 	 1000 	 0.17893075942993164 	 0.15973782539367676 	 0.09142875671386719 	 0.14372658729553223 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:24:59.033748 test begin: paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), -2, ) 	 50840832 	 1000 	 0.308687686920166 	 0.16020417213439941 	 0.1577754020690918 	 0.1428050994873047 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:03.446232 test begin: paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([1, 772, 65856],"float32"), axis=-1, keepdim=True, ) 	 50840832 	 1000 	 0.16353845596313477 	 0.15741276741027832 	 0.08356833457946777 	 0.14169716835021973 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:05.699074 test begin: paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), -2, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), -2, ) 	 52684800 	 1000 	 0.25811338424682617 	 0.16815733909606934 	 0.24681544303894043 	 0.15123605728149414 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:08.203407 test begin: paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), axis=-1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([2, 400, 65856],"float32"), axis=-1, keepdim=True, ) 	 52684800 	 1000 	 0.16611480712890625 	 0.16209983825683594 	 0.0848691463470459 	 0.14627695083618164 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:10.460196 test begin: paddle.Tensor.max(Tensor([324000, 157],"float32"), axis=1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([324000, 157],"float32"), axis=1, keepdim=True, ) 	 50868000 	 1000 	 0.5786633491516113 	 0.4115269184112549 	 0.5665771961212158 	 0.3955111503601074 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:13.558265 test begin: paddle.Tensor.max(Tensor([635041, 80],"float32"), axis=1, keepdim=True, )
[Prof] paddle.Tensor.max 	 paddle.Tensor.max(Tensor([635041, 80],"float32"), axis=1, keepdim=True, ) 	 50803280 	 1000 	 0.5394463539123535 	 0.5397253036499023 	 0.527292013168335 	 0.524099588394165 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:16.727038 test begin: paddle.Tensor.mean(Tensor([124, 128, 34, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 128, 34, 96],"float32"), 1, keepdim=True, ) 	 51806208 	 1000 	 0.2034597396850586 	 0.15155816078186035 	 0.19177484512329102 	 0.13717222213745117 	 0.1429126262664795 	 0.19726920127868652 	 0.08805155754089355 	 0.12446928024291992 	 
2025-07-30 19:25:18.352193 test begin: paddle.Tensor.mean(Tensor([124, 128, 96, 34],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 128, 96, 34],"float32"), 1, keepdim=True, ) 	 51806208 	 1000 	 0.20348811149597168 	 0.1514132022857666 	 0.19147682189941406 	 0.13708186149597168 	 0.1429135799407959 	 0.19768762588500977 	 0.05736374855041504 	 0.13020658493041992 	 
2025-07-30 19:25:19.889275 test begin: paddle.Tensor.mean(Tensor([124, 45, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([124, 45, 96, 96],"float32"), 1, keepdim=True, ) 	 51425280 	 1000 	 0.16615891456604004 	 0.15726566314697266 	 0.15426945686340332 	 0.14320111274719238 	 0.14639973640441895 	 0.21270227432250977 	 0.08967137336730957 	 0.14359569549560547 	 
2025-07-30 19:25:21.424101 test begin: paddle.Tensor.mean(Tensor([128, 128, 33, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 128, 33, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.2051236629486084 	 0.1524825096130371 	 0.1930251121520996 	 0.13816308975219727 	 0.14313626289367676 	 0.19834232330322266 	 0.08773398399353027 	 0.13113117218017578 	 
2025-07-30 19:25:22.957436 test begin: paddle.Tensor.mean(Tensor([128, 128, 96, 33],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 128, 96, 33],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.205155611038208 	 0.15265202522277832 	 0.1932981014251709 	 0.13819384574890137 	 0.14324951171875 	 0.19840312004089355 	 0.0828089714050293 	 0.13086986541748047 	 
2025-07-30 19:25:24.533401 test begin: paddle.Tensor.mean(Tensor([128, 192, 22, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 192, 22, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.2181396484375 	 0.15036392211914062 	 0.20634245872497559 	 0.13605999946594238 	 0.14357662200927734 	 0.1967313289642334 	 0.08582639694213867 	 0.12900614738464355 	 
2025-07-30 19:25:26.112100 test begin: paddle.Tensor.mean(Tensor([128, 192, 96, 22],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 192, 96, 22],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.21814823150634766 	 0.150360107421875 	 0.20649313926696777 	 0.13639116287231445 	 0.143538236618042 	 0.19703102111816406 	 0.08722209930419922 	 0.12577342987060547 	 
2025-07-30 19:25:27.652395 test begin: paddle.Tensor.mean(Tensor([128, 44, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([128, 44, 96, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.16756844520568848 	 0.15724945068359375 	 0.1559741497039795 	 0.1431272029876709 	 0.14760828018188477 	 0.21546268463134766 	 0.0922081470489502 	 0.14797329902648926 	 
2025-07-30 19:25:29.183168 test begin: paddle.Tensor.mean(Tensor([29, 192, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([29, 192, 96, 96],"float32"), 1, keepdim=True, ) 	 51314688 	 1000 	 0.16569256782531738 	 0.14798307418823242 	 0.1541919708251953 	 0.13373279571533203 	 0.1409153938293457 	 0.1922006607055664 	 0.08370256423950195 	 0.12509965896606445 	 
2025-07-30 19:25:30.749203 test begin: paddle.Tensor.mean(Tensor([44, 128, 96, 96],"float32"), 1, keepdim=True, )
[Prof] paddle.Tensor.mean 	 paddle.Tensor.mean(Tensor([44, 128, 96, 96],"float32"), 1, keepdim=True, ) 	 51904512 	 1000 	 0.16777992248535156 	 0.15374255180358887 	 0.1559910774230957 	 0.13629674911499023 	 0.14214801788330078 	 0.2019639015197754 	 0.08688020706176758 	 0.1347484588623047 	 
2025-07-30 19:25:32.251509 test begin: paddle.Tensor.min(Tensor([1, 193, 65856, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 193, 65856, 4],"float32"), axis=-1, ) 	 50840832 	 1000 	 0.5389406681060791 	 1.0960397720336914 	 0.5269260406494141 	 0.8496608734130859 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:39.864544 test begin: paddle.Tensor.min(Tensor([1, 400, 31753, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 31753, 4],"float32"), axis=-1, ) 	 50804800 	 1000 	 0.5437173843383789 	 0.867241382598877 	 0.5266366004943848 	 0.8494365215301514 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:43.702208 test begin: paddle.Tensor.min(Tensor([1, 400, 65856, 2],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 65856, 2],"float32"), axis=-1, ) 	 52684800 	 1000 	 0.5201857089996338 	 0.821317195892334 	 0.5052454471588135 	 0.8009612560272217 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:47.930278 test begin: paddle.Tensor.min(Tensor([1, 400, 65856, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([1, 400, 65856, 4],"float32"), axis=-1, ) 	 105369600 	 1000 	 1.1123301982879639 	 1.7934000492095947 	 1.0995099544525146 	 1.7726106643676758 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:55.947907 test begin: paddle.Tensor.min(Tensor([15661, 4, 811],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([15661, 4, 811],"float32"), axis=1, ) 	 50804284 	 1000 	 0.21962785720825195 	 0.2984318733215332 	 0.20746326446533203 	 0.2806410789489746 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:25:58.863583 test begin: paddle.Tensor.min(Tensor([24565, 3, 811],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([24565, 3, 811],"float32"), axis=1, ) 	 59766645 	 1000 	 0.3050673007965088 	 0.40621185302734375 	 0.2932922840118408 	 0.3887944221496582 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:26:04.595197 test begin: paddle.Tensor.min(Tensor([24565, 4, 518],"float32"), axis=1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([24565, 4, 518],"float32"), axis=1, ) 	 50898680 	 1000 	 0.22635531425476074 	 0.2805769443511963 	 0.21448564529418945 	 0.24755644798278809 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:26:08.436530 test begin: paddle.Tensor.min(Tensor([3, 525, 12096, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([3, 525, 12096, 4],"float32"), axis=-1, ) 	 76204800 	 1000 	 0.8058180809020996 	 1.2974443435668945 	 0.7931756973266602 	 1.2796459197998047 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:26:14.181540 test begin: paddle.Tensor.min(Tensor([4, 263, 12096, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 263, 12096, 4],"float32"), axis=-1, ) 	 50899968 	 1000 	 0.5388267040252686 	 0.8687670230865479 	 0.526644229888916 	 0.8509886264801025 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:26:18.072905 test begin: paddle.Tensor.min(Tensor([4, 525, 12096, 3],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 525, 12096, 3],"float32"), axis=-1, ) 	 76204800 	 1000 	 0.5271928310394287 	 0.8884873390197754 	 0.5146956443786621 	 0.8704898357391357 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:26:23.152041 test begin: paddle.Tensor.min(Tensor([4, 525, 6049, 4],"float32"), axis=-1, )
[Prof] paddle.Tensor.min 	 paddle.Tensor.min(Tensor([4, 525, 6049, 4],"float32"), axis=-1, ) 	 50811600 	 1000 	 0.5379657745361328 	 0.8674631118774414 	 0.5252904891967773 	 0.8489663600921631 	 None 	 None 	 None 	 None 	 
[Error] got 2 tensors and 1 gradients
2025-07-30 19:26:27.018302 test begin: paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.mm 	 paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 5080321],"float32"), ) 	 50803310 	 1000 	 0.6539013385772705 	 0.6522848606109619 	 0.13353776931762695 	 0.13327288627624512 	 1.4447619915008545 	 1.4421613216400146 	 0.21087265014648438 	 0.21055030822753906 	 
2025-07-30 19:26:32.892483 test begin: paddle.Tensor.mm(Tensor([5080321, 10],"float32"), Tensor([10, 10],"float32"), )
[Prof] paddle.Tensor.mm 	 paddle.Tensor.mm(Tensor([5080321, 10],"float32"), Tensor([10, 10],"float32"), ) 	 50803310 	 1000 	 0.6511399745941162 	 0.6572070121765137 	 0.13295722007751465 	 0.13289880752563477 	 1.4135220050811768 	 1.4116950035095215 	 0.20634078979492188 	 0.20607352256774902 	 
2025-07-30 19:26:39.737692 test begin: paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), ) 	 25401606 	 1000 	 45.138174057006836 	 9.372679948806763 	 9.608268737792969e-05 	 0.0002472400665283203 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:27:37.279749 test begin: paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), axis=2, keepdim=True, )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2, 4233601],"float64"), axis=2, keepdim=True, ) 	 25401606 	 1000 	 46.25149726867676 	 9.362959861755371 	 0.00011205673217773438 	 0.00022983551025390625 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:28:38.637291 test begin: paddle.Tensor.mode(Tensor([3, 2822401, 3],"float64"), axis=1, keepdim=False, )
[Prof] paddle.Tensor.mode 	 paddle.Tensor.mode(Tensor([3, 2822401, 3],"float64"), axis=1, keepdim=False, ) 	 25401609 	 1000 	 53.70806527137756 	 10.71535325050354 	 9.632110595703125e-05 	 0.0002295970916748047 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:29:48.729144 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254018100 	 1000 	 0.0077092647552490234 	 0.004713296890258789 	 9.775161743164062e-06 	 2.1696090698242188e-05 	 0.03991842269897461 	 0.0537872314453125 	 3.170967102050781e-05 	 5.221366882324219e-05 	 
2025-07-30 19:29:59.237006 test begin: paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([1209610, 2, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018100 	 1000 	 0.0076122283935546875 	 0.005988359451293945 	 1.2159347534179688e-05 	 4.982948303222656e-05 	 0.04021167755126953 	 0.05353403091430664 	 2.6702880859375e-05 	 5.0067901611328125e-05 	 
2025-07-30 19:30:09.775430 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 1058401],"float64"), source=0, destination=2, ) 	 254016240 	 1000 	 0.006878852844238281 	 0.004634380340576172 	 6.9141387939453125e-06 	 2.3365020751953125e-05 	 0.03999209403991699 	 0.05263495445251465 	 3.123283386230469e-05 	 6.031990051269531e-05 	 
2025-07-30 19:30:20.277449 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=0, destination=2, ) 	 254017680 	 1000 	 0.007120609283447266 	 0.0047566890716552734 	 2.86102294921875e-05 	 2.765655517578125e-05 	 0.04923820495605469 	 0.054601430892944336 	 5.507469177246094e-05 	 6.031990051269531e-05 	 
2025-07-30 19:30:32.081265 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 151201, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017680 	 1000 	 0.007653951644897461 	 0.005738735198974609 	 1.2874603271484375e-05 	 2.3603439331054688e-05 	 0.040651559829711914 	 0.05308103561401367 	 4.00543212890625e-05 	 5.507469177246094e-05 	 
2025-07-30 19:30:42.684533 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=0, destination=2, ) 	 254017200 	 1000 	 0.006985187530517578 	 0.00467681884765625 	 7.62939453125e-06 	 2.3126602172851562e-05 	 0.04000735282897949 	 0.052959442138671875 	 2.86102294921875e-05 	 6.890296936035156e-05 	 
2025-07-30 19:30:53.244405 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 3, 5, 211681],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254017200 	 1000 	 0.007673501968383789 	 0.007815361022949219 	 8.58306884765625e-06 	 5.7220458984375e-05 	 0.04005551338195801 	 0.05243945121765137 	 3.170967102050781e-05 	 4.887580871582031e-05 	 
2025-07-30 19:31:03.761223 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 635041, 5],"float64"), source=0, destination=2, ) 	 254016400 	 1000 	 0.006984710693359375 	 0.004614830017089844 	 8.106231689453125e-06 	 2.193450927734375e-05 	 0.0451359748840332 	 0.05366349220275879 	 3.814697265625e-05 	 6.318092346191406e-05 	 
2025-07-30 19:31:14.448600 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=0, destination=2, ) 	 254018800 	 1000 	 0.0069732666015625 	 0.004707813262939453 	 1.2159347534179688e-05 	 2.288818359375e-05 	 0.04030203819274902 	 0.053246259689331055 	 4.76837158203125e-05 	 3.981590270996094e-05 	 
2025-07-30 19:31:25.202823 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 2, 90721, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254018800 	 1000 	 0.007601261138916016 	 0.005882740020751953 	 1.049041748046875e-05 	 2.5987625122070312e-05 	 0.03999471664428711 	 0.05309486389160156 	 3.910064697265625e-05 	 3.838539123535156e-05 	 
2025-07-30 19:31:38.034749 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 423361, 3, 5],"float64"), source=0, destination=2, ) 	 254016600 	 1000 	 0.0068683624267578125 	 0.004528999328613281 	 8.58306884765625e-06 	 2.2649765014648438e-05 	 0.04056429862976074 	 0.05312204360961914 	 4.363059997558594e-05 	 7.081031799316406e-05 	 
2025-07-30 19:31:48.579369 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=0, destination=2, ) 	 254020200 	 1000 	 0.006883144378662109 	 0.004791736602783203 	 1.1682510375976562e-05 	 4.363059997558594e-05 	 0.03994393348693848 	 0.05334115028381348 	 3.8623809814453125e-05 	 5.7697296142578125e-05 	 
2025-07-30 19:31:59.133648 test begin: paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([40, 60481, 3, 5, 7],"float64"), source=tuple(0,1,), destination=tuple(2,3,), ) 	 254020200 	 1000 	 0.007898807525634766 	 0.005806684494018555 	 3.0279159545898438e-05 	 2.09808349609375e-05 	 0.04089999198913574 	 0.052968502044677734 	 2.6464462280273438e-05 	 4.267692565917969e-05 	 
2025-07-30 19:32:09.725674 test begin: paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, )
[Prof] paddle.Tensor.moveaxis 	 paddle.Tensor.moveaxis(x=Tensor([8467210, 2, 3, 5],"float64"), source=0, destination=2, ) 	 254016300 	 1000 	 0.006968021392822266 	 0.0045375823974609375 	 1.0728836059570312e-05 	 2.4557113647460938e-05 	 0.040008544921875 	 0.05710864067077637 	 3.0517578125e-05 	 6.318092346191406e-05 	 
2025-07-30 19:32:20.343014 test begin: paddle.Tensor.multiply(Tensor([132301, 768],"float16"), Tensor([132301, 1],"float32"), )
W0730 19:32:22.205015 27591 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([132301, 768],"float16"), Tensor([132301, 1],"float32"), ) 	 101739469 	 1000 	 1.0662972927093506 	 0.7282931804656982 	 0.5449097156524658 	 0.7156069278717041 	 1.9064147472381592 	 2.1268203258514404 	 0.648841142654419 	 0.5430631637573242 	 
2025-07-30 19:32:29.947551 test begin: paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 1],"float32"), ) 	 50803520 	 1000 	 0.29625773429870605 	 0.3033618927001953 	 0.2859175205230713 	 0.29108619689941406 	 0.7711622714996338 	 0.9221951961517334 	 0.2623558044433594 	 0.23530316352844238 	 
2025-07-30 19:32:33.859659 test begin: paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 317521],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 317521],"float32"), Tensor([160, 317521],"float32"), ) 	 101606720 	 1000 	 0.45024919509887695 	 0.9011521339416504 	 0.4406778812408447 	 0.43445372581481934 	 1.0740554332733154 	 0.8934962749481201 	 1.0106825828552246 	 0.4562051296234131 	 
2025-07-30 19:32:42.351097 test begin: paddle.Tensor.multiply(Tensor([160, 635041],"float16"), Tensor([160, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([160, 635041],"float16"), Tensor([160, 1],"float32"), ) 	 101606720 	 1000 	 1.0677952766418457 	 0.6947307586669922 	 0.5456581115722656 	 0.6753702163696289 	 1.9208803176879883 	 2.1359803676605225 	 0.49025678634643555 	 0.43604564666748047 	 
2025-07-30 19:32:51.871692 test begin: paddle.Tensor.multiply(Tensor([16538, 3072],"float32"), Tensor([16538, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([16538, 3072],"float32"), Tensor([16538, 1],"float32"), ) 	 50821274 	 1000 	 0.29540157318115234 	 0.31018662452697754 	 0.27739620208740234 	 0.29537391662597656 	 0.7362127304077148 	 0.9001827239990234 	 0.37616491317749023 	 0.30647802352905273 	 
2025-07-30 19:32:55.795323 test begin: paddle.Tensor.multiply(Tensor([33076, 3072],"float16"), Tensor([33076, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([33076, 3072],"float16"), Tensor([33076, 1],"float32"), ) 	 101642548 	 1000 	 1.0676839351654053 	 0.7237465381622314 	 0.5455751419067383 	 0.7044601440429688 	 1.9016592502593994 	 2.1305007934570312 	 0.6472792625427246 	 0.5439379215240479 	 
2025-07-30 19:33:05.239497 test begin: paddle.Tensor.multiply(Tensor([512, 198451],"float16"), Tensor([512, 1],"float32"), )
[Prof] paddle.Tensor.multiply 	 paddle.Tensor.multiply(Tensor([512, 198451],"float16"), Tensor([512, 1],"float32"), ) 	 101607424 	 1000 	 1.0702552795410156 	 0.695631742477417 	 0.5468893051147461 	 0.6764223575592041 	 1.9447243213653564 	 2.1553895473480225 	 0.4963114261627197 	 0.5503344535827637 	 
2025-07-30 19:33:14.776380 test begin: paddle.Tensor.nansum(Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([105841, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0641365051269531 	 0.1894371509552002 	 0.2720808982849121 	 0.16658329963684082 	 0.527446985244751 	 0.4413769245147705 	 0.2694370746612549 	 0.15027236938476562 	 
2025-07-30 19:33:17.719411 test begin: paddle.Tensor.nansum(Tensor([2822401, 3, 3],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([2822401, 3, 3],"float64"), ) 	 25401609 	 1000 	 0.9349033832550049 	 0.15003108978271484 	 0.1908586025238037 	 0.07662796974182129 	 0.46475982666015625 	 0.41284775733947754 	 0.23743224143981934 	 0.14050793647766113 	 
2025-07-30 19:33:20.286426 test begin: paddle.Tensor.nansum(Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 105841, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401840 	 1000 	 1.0640664100646973 	 0.18946027755737305 	 0.27207112312316895 	 0.16668152809143066 	 0.5274538993835449 	 0.44136524200439453 	 0.26945066452026367 	 0.15032386779785156 	 
2025-07-30 19:33:23.231690 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 141121, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401780 	 1000 	 5.650736331939697 	 0.1720445156097412 	 1.1576244831085205 	 0.08791637420654297 	 0.4654526710510254 	 0.41731834411621094 	 0.23778104782104492 	 0.1420588493347168 	 
2025-07-30 19:33:30.533775 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 176401, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401744 	 1000 	 0.9735562801361084 	 0.1900475025177002 	 0.24885034561157227 	 0.16722345352172852 	 0.5112662315368652 	 0.44332242012023926 	 0.2611656188964844 	 0.15096688270568848 	 
2025-07-30 19:33:33.373264 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 70561],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 0.974785566329956 	 0.8663897514343262 	 0.24923920631408691 	 0.17433810234069824 	 0.5116415023803711 	 0.44394779205322266 	 0.26137208938598633 	 0.1511681079864502 	 
2025-07-30 19:33:40.617442 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 35281, 2],"float64"), axis=3, keepdim=True, ) 	 25402320 	 1000 	 0.9738552570343018 	 0.19611191749572754 	 0.24898576736450195 	 0.16727662086486816 	 0.511544942855835 	 0.4450352191925049 	 0.26134681701660156 	 0.15152478218078613 	 
2025-07-30 19:33:43.420706 test begin: paddle.Tensor.nansum(Tensor([3, 2822401, 3],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 2822401, 3],"float64"), ) 	 25401609 	 1000 	 0.934722900390625 	 0.14978456497192383 	 0.19078350067138672 	 0.0765233039855957 	 0.46481895446777344 	 0.4127955436706543 	 0.23743224143981934 	 0.1405344009399414 	 
2025-07-30 19:33:49.148518 test begin: paddle.Tensor.nansum(Tensor([3, 3, 2822401],"float64"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 3, 2822401],"float64"), ) 	 25401609 	 1000 	 0.9348483085632324 	 0.14973092079162598 	 0.19083714485168457 	 0.07647299766540527 	 0.4647328853607178 	 0.41281795501708984 	 0.23741626739501953 	 0.14054059982299805 	 
2025-07-30 19:33:53.791863 test begin: paddle.Tensor.nansum(Tensor([3, 3, 5644801],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 3, 5644801],"float32"), ) 	 50803209 	 1000 	 1.008974313735962 	 0.15245485305786133 	 0.20596981048583984 	 0.07786250114440918 	 0.5586943626403809 	 0.5894644260406494 	 0.2854161262512207 	 0.20076727867126465 	 
2025-07-30 19:33:56.964760 test begin: paddle.Tensor.nansum(Tensor([3, 5644801, 3],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 5644801, 3],"float32"), ) 	 50803209 	 1000 	 1.008878231048584 	 0.15255045890808105 	 0.20595383644104004 	 0.07794666290283203 	 0.55857253074646 	 0.5894944667816162 	 0.2853689193725586 	 0.20077085494995117 	 
2025-07-30 19:34:00.097856 test begin: paddle.Tensor.nansum(Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([3, 70561, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 	 25401960 	 1000 	 1.063537836074829 	 0.1894218921661377 	 0.27194833755493164 	 0.17357850074768066 	 0.5300252437591553 	 0.44158148765563965 	 0.27080512046813965 	 0.15037131309509277 	 
2025-07-30 19:34:03.019638 test begin: paddle.Tensor.nansum(Tensor([5644801, 3, 3],"float32"), )
[Prof] paddle.Tensor.nansum 	 paddle.Tensor.nansum(Tensor([5644801, 3, 3],"float32"), ) 	 50803209 	 1000 	 1.0087783336639404 	 0.15242719650268555 	 0.2059464454650879 	 0.07786750793457031 	 0.5586156845092773 	 0.5894808769226074 	 0.2853882312774658 	 0.20079469680786133 	 
2025-07-30 19:34:06.175162 test begin: paddle.Tensor.neg(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.neg 	 paddle.Tensor.neg(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.2956712245941162 	 0.29775500297546387 	 0.2861146926879883 	 0.28760814666748047 	 0.2958052158355713 	 0.2977147102355957 	 0.24358797073364258 	 0.2391057014465332 	 
2025-07-30 19:34:08.982586 test begin: paddle.Tensor.nonzero(Tensor([3628801, 14],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([3628801, 14],"bool"), ) 	 50803214 	 1000 	 5.931774616241455 	 1.4117391109466553 	 0.004047393798828125 	 0.0013163089752197266 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:17.057418 test begin: paddle.Tensor.nonzero(Tensor([3907939, 13],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([3907939, 13],"bool"), ) 	 50803207 	 1000 	 5.932727098464966 	 1.4121367931365967 	 0.0040357112884521484 	 0.0013148784637451172 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:25.133192 test begin: paddle.Tensor.nonzero(Tensor([4233601, 12],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([4233601, 12],"bool"), ) 	 50803212 	 1000 	 5.932479619979858 	 1.412940502166748 	 0.0040471553802490234 	 0.0013093948364257812 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:33.196308 test begin: paddle.Tensor.nonzero(Tensor([52640, 966],"bool"), )
[Prof] paddle.Tensor.nonzero 	 paddle.Tensor.nonzero(Tensor([52640, 966],"bool"), ) 	 50850240 	 1000 	 5.932496786117554 	 1.4197676181793213 	 0.0040700435638427734 	 0.0013074874877929688 	 None 	 None 	 None 	 None 	 
2025-07-30 19:34:41.916888 test begin: paddle.Tensor.norm(Tensor([100352, 507],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.1526165008544922 	 0.15224599838256836 	 0.05187106132507324 	 0.07772612571716309 	 0.9975249767303467 	 0.9118108749389648 	 0.9439656734466553 	 0.23309898376464844 	 
2025-07-30 19:34:45.473425 test begin: paddle.Tensor.norm(Tensor([507, 100352],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.15256500244140625 	 0.1521749496459961 	 0.051860809326171875 	 0.07772588729858398 	 0.9975454807281494 	 0.9115955829620361 	 0.9442324638366699 	 0.23302912712097168 	 
2025-07-30 19:34:48.517520 test begin: paddle.Tensor.norm(Tensor([6202, 8192],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.15219950675964355 	 0.15197515487670898 	 0.05173969268798828 	 0.07761025428771973 	 0.9966747760772705 	 0.9098663330078125 	 0.943528413772583 	 0.2326507568359375 	 
2025-07-30 19:34:51.558524 test begin: paddle.Tensor.norm(Tensor([8192, 6202],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.1522045135498047 	 0.1520233154296875 	 0.05173850059509277 	 0.07763171195983887 	 0.9966557025909424 	 0.9099798202514648 	 0.9434771537780762 	 0.232588529586792 	 
2025-07-30 19:34:59.251400 test begin: paddle.Tensor.norm(Tensor([886, 57344],"float32"), )
[Prof] paddle.Tensor.norm 	 paddle.Tensor.norm(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.15219831466674805 	 0.15201377868652344 	 0.05174374580383301 	 0.07760739326477051 	 0.9967710971832275 	 0.9098100662231445 	 0.9426991939544678 	 0.2325761318206787 	 
2025-07-30 19:35:02.285511 test begin: paddle.Tensor.not_equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([128, 198451],"int64"), Tensor([128, 198451],"int64"), ) 	 50803456 	 1000 	 0.30908799171447754 	 0.31308436393737793 	 0.3002464771270752 	 0.3017892837524414 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:03.742697 test begin: paddle.Tensor.not_equal(Tensor([13, 1953970],"int64"), Tensor([1],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([13, 1953970],"int64"), Tensor([1],"int64"), ) 	 25401611 	 1000 	 0.17609834671020508 	 0.18011021614074707 	 0.16649246215820312 	 0.1677708625793457 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:04.536203 test begin: paddle.Tensor.not_equal(Tensor([13, 3907939],"bool"), Tensor([1],"bool"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([13, 3907939],"bool"), Tensor([1],"bool"), ) 	 50803208 	 1000 	 0.13777661323547363 	 0.19829392433166504 	 0.127976655960083 	 0.18610262870788574 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:05.561049 test begin: paddle.Tensor.not_equal(Tensor([1814401, 14],"int64"), Tensor([1],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([1814401, 14],"int64"), Tensor([1],"int64"), ) 	 25401615 	 1000 	 0.17613887786865234 	 0.18346095085144043 	 0.1648271083831787 	 0.1660747528076172 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:06.363233 test begin: paddle.Tensor.not_equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([198451, 128],"int64"), Tensor([198451, 128],"int64"), ) 	 50803456 	 1000 	 0.3090355396270752 	 0.31308722496032715 	 0.3001518249511719 	 0.3017764091491699 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:07.851658 test begin: paddle.Tensor.not_equal(Tensor([3628801, 14],"bool"), Tensor([1],"bool"), )
[Prof] paddle.Tensor.not_equal 	 paddle.Tensor.not_equal(Tensor([3628801, 14],"bool"), Tensor([1],"bool"), ) 	 50803215 	 1000 	 0.137786865234375 	 0.21953392028808594 	 0.1280364990234375 	 0.18600869178771973 	 None 	 None 	 None 	 None 	 
2025-07-30 19:35:08.949227 test begin: paddle.Tensor.outer(x=Tensor([12700801, 2],"float64"), y=Tensor([2, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([12700801, 2],"float64"), y=Tensor([2, 3, 4],"float64"), ) 	 25401626 	 1000 	 3.874898672103882 	 3.816899299621582 	 0.158433198928833 	 0.9748528003692627 	 7.489072322845459 	 22.912503004074097 	 2.549546718597412 	 1.2189671993255615 	 
2025-07-30 19:36:02.009450 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3175201],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3175201],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401632 	 1000 	 4.424060344696045 	 3.8269734382629395 	 0.15833783149719238 	 0.9776830673217773 	 7.489195823669434 	 22.80972695350647 	 2.549863576889038 	 1.1642849445343018 	 
2025-07-30 19:36:54.477310 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3175201],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3175201],"float64"), ) 	 25401632 	 1000 	 4.04162859916687 	 7.109897136688232 	 0.16501498222351074 	 1.816352128982544 	 7.440745830535889 	 25.52871346473694 	 2.5337579250335693 	 1.3043694496154785 	 
2025-07-30 19:37:51.878782 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2116801, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2116801, 3],"float64"), ) 	 25401636 	 1000 	 4.032555341720581 	 7.083771228790283 	 0.16472268104553223 	 1.808462142944336 	 7.448960065841675 	 25.502670764923096 	 2.5364863872528076 	 1.302983283996582 	 
2025-07-30 19:38:50.126148 test begin: paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4233601, 2, 3],"float64"), ) 	 25401630 	 1000 	 4.179718255996704 	 7.123781442642212 	 0.17068052291870117 	 1.8199381828308105 	 7.448542594909668 	 25.541807413101196 	 2.5363011360168457 	 1.3048276901245117 	 
2025-07-30 19:39:47.958951 test begin: paddle.Tensor.outer(x=Tensor([4, 2116801, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2116801, 3],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401636 	 1000 	 3.877760410308838 	 3.8323073387145996 	 0.15837812423706055 	 0.978201150894165 	 7.487264633178711 	 22.82166028022766 	 2.5490570068359375 	 1.1647181510925293 	 
2025-07-30 19:40:41.058315 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4233601],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4233601],"float64"), ) 	 25401614 	 1000 	 1.5323636531829834 	 2.3671460151672363 	 0.06225228309631348 	 2.3524343967437744 	 2.7555596828460693 	 8.336304187774658 	 0.9381792545318604 	 1.7029457092285156 	 
2025-07-30 19:41:00.789445 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3175201, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3175201, 4],"float64"), ) 	 25401616 	 1000 	 1.5171360969543457 	 2.3690106868743896 	 0.061878204345703125 	 2.332862138748169 	 2.7509660720825195 	 8.332241535186768 	 0.9366507530212402 	 1.7022011280059814 	 
2025-07-30 19:41:22.631148 test begin: paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2116801, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2116801, 3, 4],"float64"), ) 	 25401620 	 1000 	 1.5107786655426025 	 2.3546249866485596 	 0.06163334846496582 	 2.3366570472717285 	 2.7528128623962402 	 8.329841375350952 	 0.9374070167541504 	 1.701681137084961 	 
2025-07-30 19:41:42.438733 test begin: paddle.Tensor.outer(x=Tensor([4, 6350401],"float64"), y=Tensor([2, 3, 4],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4, 6350401],"float64"), y=Tensor([2, 3, 4],"float64"), ) 	 25401628 	 1000 	 3.875217914581299 	 3.8302626609802246 	 0.15836429595947266 	 0.9783158302307129 	 7.487922668457031 	 22.782047748565674 	 2.5497210025787354 	 1.1628708839416504 	 
2025-07-30 19:42:33.727286 test begin: paddle.Tensor.outer(x=Tensor([4233601, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
[Prof] paddle.Tensor.outer 	 paddle.Tensor.outer(x=Tensor([4233601, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), ) 	 25401630 	 1000 	 4.66615891456604 	 3.8201534748077393 	 0.1585066318511963 	 0.9757771492004395 	 7.488140344619751 	 22.802178144454956 	 2.5493452548980713 	 1.1638197898864746 	 
2025-07-30 19:43:26.104836 test begin: paddle.Tensor.pow(Tensor([124, 128, 34, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 128, 34, 96],"float32"), 2, ) 	 51806208 	 1000 	 0.37596869468688965 	 0.3036177158355713 	 0.3664083480834961 	 0.2907426357269287 	 0.4609963893890381 	 1.0727522373199463 	 0.40701961517333984 	 0.3654768466949463 	 
2025-07-30 19:43:30.148933 test begin: paddle.Tensor.pow(Tensor([124, 128, 96, 34],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 128, 96, 34],"float32"), 2, ) 	 51806208 	 1000 	 0.37595534324645996 	 0.303483247756958 	 0.3667287826538086 	 0.29076719284057617 	 0.46085333824157715 	 1.0726735591888428 	 0.4069807529449463 	 0.3653993606567383 	 
2025-07-30 19:43:34.116385 test begin: paddle.Tensor.pow(Tensor([124, 45, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([124, 45, 96, 96],"float32"), 2, ) 	 51425280 	 1000 	 0.373746395111084 	 0.3158693313598633 	 0.3643631935119629 	 0.28124260902404785 	 0.45746827125549316 	 1.0648880004882812 	 0.40149831771850586 	 0.36278676986694336 	 
2025-07-30 19:43:40.507201 test begin: paddle.Tensor.pow(Tensor([128, 128, 33, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 128, 33, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.3762781620025635 	 0.3040628433227539 	 0.3669288158416748 	 0.29131054878234863 	 0.46172380447387695 	 1.074693202972412 	 0.40747976303100586 	 0.36616015434265137 	 
2025-07-30 19:43:46.624548 test begin: paddle.Tensor.pow(Tensor([128, 128, 96, 33],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 128, 96, 33],"float32"), 2, ) 	 51904512 	 1000 	 0.37618541717529297 	 0.31483960151672363 	 0.35949277877807617 	 0.2794821262359619 	 0.46179747581481934 	 1.0747182369232178 	 0.3987112045288086 	 0.3661181926727295 	 
2025-07-30 19:43:51.745255 test begin: paddle.Tensor.pow(Tensor([128, 192, 22, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 192, 22, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.37628626823425293 	 0.30677127838134766 	 0.35942983627319336 	 0.2894737720489502 	 0.46167707443237305 	 1.0746891498565674 	 0.39641499519348145 	 0.36609768867492676 	 
2025-07-30 19:43:55.707242 test begin: paddle.Tensor.pow(Tensor([128, 192, 96, 22],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 192, 96, 22],"float32"), 2, ) 	 51904512 	 1000 	 0.3761744499206543 	 0.3040812015533447 	 0.35947656631469727 	 0.2833538055419922 	 0.46182799339294434 	 1.0747699737548828 	 0.39851927757263184 	 0.3661830425262451 	 
2025-07-30 19:43:59.757224 test begin: paddle.Tensor.pow(Tensor([128, 44, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([128, 44, 96, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.37618565559387207 	 0.3040809631347656 	 0.36667513847351074 	 0.29140615463256836 	 0.46176838874816895 	 1.0748026371002197 	 0.40520310401916504 	 0.36617469787597656 	 
2025-07-30 19:44:03.736291 test begin: paddle.Tensor.pow(Tensor([29, 192, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([29, 192, 96, 96],"float32"), 2, ) 	 51314688 	 1000 	 0.37203335762023926 	 0.3007380962371826 	 0.36273193359375 	 0.2879197597503662 	 0.4567394256591797 	 1.062699556350708 	 0.40281081199645996 	 0.36203694343566895 	 
2025-07-30 19:44:07.667051 test begin: paddle.Tensor.pow(Tensor([44, 128, 96, 96],"float32"), 2, )
[Prof] paddle.Tensor.pow 	 paddle.Tensor.pow(Tensor([44, 128, 96, 96],"float32"), 2, ) 	 51904512 	 1000 	 0.3765387535095215 	 0.30402207374572754 	 0.36725568771362305 	 0.29133152961730957 	 0.4617619514465332 	 1.0746886730194092 	 0.40769028663635254 	 0.36609506607055664 	 
2025-07-30 19:44:11.604496 test begin: paddle.Tensor.prod(Tensor([1, 386, 65856, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 386, 65856, 2],"float32"), -1, ) 	 50840832 	 1000 	 0.3880195617675781 	 0.46863532066345215 	 0.3721003532409668 	 0.44887328147888184 	 1.6767268180847168 	 2.053966999053955 	 1.6208879947662354 	 0.0007152557373046875 	 
2025-07-30 19:44:17.444312 test begin: paddle.Tensor.prod(Tensor([1, 400, 63505, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 400, 63505, 2],"float32"), -1, ) 	 50804000 	 1000 	 0.3888847827911377 	 0.4678809642791748 	 0.37340474128723145 	 0.4535794258117676 	 1.6764428615570068 	 2.0552382469177246 	 1.6213550567626953 	 0.0007154941558837891 	 
2025-07-30 19:44:23.326790 test begin: paddle.Tensor.prod(Tensor([1, 400, 65856, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([1, 400, 65856, 2],"float32"), -1, ) 	 52684800 	 1000 	 0.4018213748931885 	 0.4847753047943115 	 0.3858182430267334 	 0.47042250633239746 	 1.7377195358276367 	 2.1259896755218506 	 1.6821174621582031 	 0.0007457733154296875 	 
2025-07-30 19:44:29.359465 test begin: paddle.Tensor.prod(Tensor([2100, 12096, 3],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2100, 12096, 3],"float32"), -1, ) 	 76204800 	 1000 	 0.4134039878845215 	 0.5126690864562988 	 0.3980443477630615 	 0.498821496963501 	 1.8901581764221191 	 2.719712495803833 	 1.8343980312347412 	 0.0010170936584472656 	 
2025-07-30 19:44:37.321991 test begin: paddle.Tensor.prod(Tensor([2100, 12097, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2100, 12097, 2],"float32"), -1, ) 	 50807400 	 1000 	 0.3877429962158203 	 0.47719788551330566 	 0.37236928939819336 	 0.4537513256072998 	 1.3265352249145508 	 2.0565884113311768 	 1.271226167678833 	 0.0007207393646240234 	 
2025-07-30 19:44:42.860562 test begin: paddle.Tensor.prod(Tensor([2101, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([2101, 12096, 2],"float32"), -1, ) 	 50827392 	 1000 	 0.3881189823150635 	 0.4726252555847168 	 0.37293457984924316 	 0.45374560356140137 	 1.266460657119751 	 2.056222677230835 	 1.2107939720153809 	 0.0007181167602539062 	 
2025-07-30 19:44:48.346655 test begin: paddle.Tensor.prod(Tensor([4, 525, 12096, 3],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 525, 12096, 3],"float32"), -1, ) 	 76204800 	 1000 	 0.4137299060821533 	 0.5191748142242432 	 0.3983027935028076 	 0.49663877487182617 	 2.505690097808838 	 2.7185840606689453 	 2.4505655765533447 	 0.0010170936584472656 	 
2025-07-30 19:44:58.105219 test begin: paddle.Tensor.prod(Tensor([4, 525, 12097, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 525, 12097, 2],"float32"), -1, ) 	 50807400 	 1000 	 0.38770532608032227 	 0.46906208992004395 	 0.3721458911895752 	 0.45307183265686035 	 1.6765406131744385 	 2.055475950241089 	 1.6200249195098877 	 0.0007157325744628906 	 
2025-07-30 19:45:04.478973 test begin: paddle.Tensor.prod(Tensor([4, 526, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([4, 526, 12096, 2],"float32"), -1, ) 	 50899968 	 1000 	 0.38838648796081543 	 0.4684464931488037 	 0.3729093074798584 	 0.4546196460723877 	 1.6794555187225342 	 2.0573971271514893 	 1.6236727237701416 	 0.000705718994140625 	 
2025-07-30 19:45:10.355707 test begin: paddle.Tensor.prod(Tensor([5, 525, 12096, 2],"float32"), -1, )
[Prof] paddle.Tensor.prod 	 paddle.Tensor.prod(Tensor([5, 525, 12096, 2],"float32"), -1, ) 	 63504000 	 1000 	 0.483306884765625 	 0.5834367275238037 	 0.46769070625305176 	 0.5695369243621826 	 2.0931882858276367 	 2.547245979309082 	 2.037752389907837 	 0.0008943080902099609 	 
2025-07-30 19:45:17.656639 test begin: paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 145800 	 1000 	 16.367976903915405 	 0.22222089767456055 	 0.4254744052886963 	 8.0108642578125e-05 	 0.20788311958312988 	 0.2440176010131836 	 3.0994415283203125e-05 	 7.081031799316406e-05 	 
2025-07-30 19:45:34.817885 test begin: paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 405, 3, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 145800 	 1000 	 13.10813593864441 	 0.20496463775634766 	 0.36835741996765137 	 7.319450378417969e-05 	 0.1795048713684082 	 0.20846867561340332 	 2.1696090698242188e-05 	 6.0558319091796875e-05 	 
2025-07-30 19:45:48.543427 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=3, keepdim=True, ) 	 124416 	 1000 	 13.975404500961304 	 0.21085429191589355 	 0.36324501037597656 	 4.267692565917969e-05 	 0.20121383666992188 	 0.23303842544555664 	 3.170967102050781e-05 	 4.100799560546875e-05 	 
2025-07-30 19:46:03.188769 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 288],"float64"), q=0.75, axis=5, ) 	 124416 	 1000 	 0.48067140579223633 	 0.19963431358337402 	 5.7220458984375e-05 	 4.57763671875e-05 	 0.17809438705444336 	 0.2120804786682129 	 2.0503997802734375e-05 	 7.009506225585938e-05 	 
2025-07-30 19:46:04.270086 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253800 	 1000 	 28.33728289604187 	 0.21435832977294922 	 0.736717700958252 	 7.867813110351562e-05 	 0.19525551795959473 	 0.23640084266662598 	 5.1021575927734375e-05 	 7.343292236328125e-05 	 
2025-07-30 19:46:33.298574 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 235, 5],"float64"), q=0.75, axis=5, ) 	 253800 	 1000 	 22.71020197868347 	 0.20558714866638184 	 0.6380751132965088 	 6.604194641113281e-05 	 0.1900930404663086 	 0.2121140956878662 	 4.0531158447265625e-05 	 7.009506225585938e-05 	 
2025-07-30 19:46:56.652513 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253800 	 1000 	 0.5574235916137695 	 0.20819640159606934 	 0.01441335678100586 	 7.152557373046875e-05 	 0.19634699821472168 	 0.2541029453277588 	 3.647804260253906e-05 	 7.796287536621094e-05 	 
2025-07-30 19:46:57.885668 test begin: paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 3, 470, 2, 5],"float64"), q=0.75, axis=5, ) 	 253800 	 1000 	 22.71172857284546 	 0.20771121978759766 	 0.6381409168243408 	 9.918212890625e-05 	 0.1820530891418457 	 0.2121601104736328 	 4.482269287109375e-05 	 5.173683166503906e-05 	 
2025-07-30 19:47:21.236125 test begin: paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253440 	 1000 	 28.321908712387085 	 0.21605873107910156 	 0.7363028526306152 	 6.794929504394531e-05 	 0.19966864585876465 	 0.23991107940673828 	 4.76837158203125e-05 	 5.364418029785156e-05 	 
2025-07-30 19:47:50.265112 test begin: paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([3, 6, 352, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 253440 	 1000 	 22.682480573654175 	 0.20256996154785156 	 0.6372978687286377 	 6.270408630371094e-05 	 0.17997193336486816 	 0.22679471969604492 	 3.9577484130859375e-05 	 6.031990051269531e-05 	 
2025-07-30 19:48:13.592751 test begin: paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=3, keepdim=True, ) 	 253440 	 1000 	 28.324360609054565 	 0.21062922477722168 	 0.73636794090271 	 6.937980651855469e-05 	 0.19182991981506348 	 0.2424170970916748 	 4.839897155761719e-05 	 5.8650970458984375e-05 	 
2025-07-30 19:48:42.605476 test begin: paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=5, )
[Prof] paddle.Tensor.quantile 	 paddle.Tensor.quantile(Tensor([352, 6, 3, 4, 2, 5],"float64"), q=0.75, axis=5, ) 	 253440 	 1000 	 22.683220863342285 	 0.19980192184448242 	 0.6373476982116699 	 7.748603820800781e-05 	 0.18675732612609863 	 0.2562997341156006 	 4.0531158447265625e-05 	 6.651878356933594e-05 	 
2025-07-30 19:49:05.967685 test begin: paddle.Tensor.rad2deg(x=Tensor([1587601, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([1587601, 4, 4],"float64"), ) 	 25401616 	 1000 	 0.2980461120605469 	 0.29832911491394043 	 0.28365230560302734 	 0.28436779975891113 	 0.29816293716430664 	 0.2982022762298584 	 0.24672889709472656 	 0.22882986068725586 	 
2025-07-30 19:49:08.210975 test begin: paddle.Tensor.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.29793262481689453 	 0.29829859733581543 	 0.2833395004272461 	 0.28421735763549805 	 0.29813408851623535 	 0.29829907417297363 	 0.24633502960205078 	 0.22582459449768066 	 
2025-07-30 19:49:10.451653 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 1587601, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 1587601, 4],"float64"), ) 	 25401616 	 1000 	 0.29805922508239746 	 0.9640321731567383 	 0.28346753120422363 	 0.27916526794433594 	 0.29813694953918457 	 0.2982022762298584 	 0.24654388427734375 	 0.22698569297790527 	 
2025-07-30 19:49:15.485600 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.2978954315185547 	 0.29833316802978516 	 0.27473926544189453 	 0.27739739418029785 	 0.29814624786376953 	 0.2982356548309326 	 0.2378101348876953 	 0.22170209884643555 	 
2025-07-30 19:49:17.771742 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 1587601],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 1587601],"float64"), ) 	 25401616 	 1000 	 0.2980315685272217 	 0.298328161239624 	 0.2749936580657959 	 0.2771787643432617 	 0.29815053939819336 	 0.2983062267303467 	 0.23759102821350098 	 0.22190594673156738 	 
2025-07-30 19:49:19.999501 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.2979304790496826 	 0.29842424392700195 	 0.27443695068359375 	 0.2772798538208008 	 0.2981400489807129 	 0.2982821464538574 	 0.2351236343383789 	 0.22630739212036133 	 
2025-07-30 19:49:22.240086 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.2979295253753662 	 0.29835987091064453 	 0.274871826171875 	 0.27742505073547363 	 0.29813218116760254 	 0.29822540283203125 	 0.23812413215637207 	 0.22379446029663086 	 
2025-07-30 19:49:24.497675 test begin: paddle.Tensor.rad2deg(x=Tensor([4, 6350401],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([4, 6350401],"float64"), ) 	 25401604 	 1000 	 0.2980358600616455 	 0.2982804775238037 	 0.275071382522583 	 0.2774677276611328 	 0.29816389083862305 	 0.2982141971588135 	 0.23770594596862793 	 0.22365331649780273 	 
2025-07-30 19:49:26.775872 test begin: paddle.Tensor.rad2deg(x=Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.rad2deg 	 paddle.Tensor.rad2deg(x=Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.29802775382995605 	 0.29834413528442383 	 0.2749607563018799 	 0.2773885726928711 	 0.2981686592102051 	 0.2982487678527832 	 0.23770689964294434 	 0.22297215461730957 	 
2025-07-30 19:49:29.025272 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 3, 44],"float32"), ) 	 519045120 	 1000 	 0.03989672660827637 	 0.02897357940673828 	 2.3126602172851562e-05 	 6.413459777832031e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:49:39.221431 test begin: paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 1536, 44, 3],"float32"), ) 	 519045120 	 1000 	 0.0392763614654541 	 0.028879404067993164 	 2.0503997802734375e-05 	 6.008148193359375e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:49:47.728097 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 3, 33],"float32"), ) 	 519045120 	 1000 	 0.039191484451293945 	 0.029233932495117188 	 2.86102294921875e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:49:56.067248 test begin: paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 2048, 33, 3],"float32"), ) 	 519045120 	 1000 	 0.03936958312988281 	 0.02935194969177246 	 1.7642974853515625e-05 	 3.790855407714844e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:04.315879 test begin: paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 22051, 3, 3],"float32"), ) 	 508055040 	 1000 	 0.04102611541748047 	 0.028776884078979492 	 2.4557113647460938e-05 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:12.483569 test begin: paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 3, 87],"float32"), ) 	 513146880 	 1000 	 0.041449785232543945 	 0.029000520706176758 	 2.0503997802734375e-05 	 4.57763671875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:20.945673 test begin: paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([2560, 768, 87, 3],"float32"), ) 	 513146880 	 1000 	 0.040212154388427734 	 0.028900146484375 	 2.5033950805664062e-05 	 3.4809112548828125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:29.145201 test begin: paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([27570, 2048, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.03981423377990723 	 0.029255390167236328 	 2.4318695068359375e-05 	 3.7670135498046875e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:39.361656 test begin: paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([36760, 1536, 3, 3],"float32"), ) 	 508170240 	 1000 	 0.04001951217651367 	 0.029068946838378906 	 2.6464462280273438e-05 	 4.315376281738281e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:47.552015 test begin: paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), )
[Prof] paddle.Tensor.rank 	 paddle.Tensor.rank(Tensor([73510, 768, 3, 3],"float32"), ) 	 508101120 	 1000 	 0.03992056846618652 	 0.034191131591796875 	 1.8835067749023438e-05 	 5.054473876953125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 19:50:55.671307 test begin: paddle.Tensor.reciprocal(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29554247856140137 	 0.3008425235748291 	 0.285825252532959 	 0.2877082824707031 	 0.45029568672180176 	 1.0405092239379883 	 0.39706873893737793 	 0.35449814796447754 	 
2025-07-30 19:50:59.473853 test begin: paddle.Tensor.reciprocal(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.295459508895874 	 0.29819273948669434 	 0.28688597679138184 	 0.28776979446411133 	 0.44994497299194336 	 1.0403435230255127 	 0.39676642417907715 	 0.35442471504211426 	 
2025-07-30 19:51:03.208901 test begin: paddle.Tensor.reciprocal(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2954721450805664 	 0.9740540981292725 	 0.2869386672973633 	 0.28759002685546875 	 0.45006537437438965 	 1.0403895378112793 	 0.39701366424560547 	 0.3544008731842041 	 
2025-07-30 19:51:10.669208 test begin: paddle.Tensor.reciprocal(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2954545021057129 	 0.29807448387145996 	 0.28681111335754395 	 0.28758740425109863 	 0.4500279426574707 	 1.0403368473052979 	 0.3969242572784424 	 0.35443663597106934 	 
2025-07-30 19:51:14.443273 test begin: paddle.Tensor.reciprocal(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2954719066619873 	 0.2980647087097168 	 0.2869150638580322 	 0.28770971298217773 	 0.45004892349243164 	 1.0403780937194824 	 0.3934648036956787 	 0.354447603225708 	 
2025-07-30 19:51:18.193206 test begin: paddle.Tensor.reciprocal(Tensor([4233601, 12],"float32"), )
[Prof] paddle.Tensor.reciprocal 	 paddle.Tensor.reciprocal(Tensor([4233601, 12],"float32"), ) 	 50803212 	 1000 	 0.2954421043395996 	 0.29810595512390137 	 0.2868359088897705 	 0.28774094581604004 	 0.4500410556793213 	 1.0403838157653809 	 0.3964865207672119 	 0.3544638156890869 	 
2025-07-30 19:51:22.622050 test begin: paddle.Tensor.remainder(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([2, 3, 8467201],"float32"), Tensor([2, 3, 8467201],"float32"), ) 	 101606412 	 1000 	 0.45065760612487793 	 0.4503636360168457 	 0.4411277770996094 	 0.4376795291900635 	 None 	 None 	 None 	 None 	 
2025-07-30 19:51:26.721504 test begin: paddle.Tensor.remainder(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([2, 6350401, 4],"float32"), Tensor([2, 6350401, 4],"float32"), ) 	 101606416 	 1000 	 0.4506535530090332 	 0.44937849044799805 	 0.4409961700439453 	 0.43810153007507324 	 None 	 None 	 None 	 None 	 
2025-07-30 19:51:29.271629 test begin: paddle.Tensor.remainder(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), )
[Prof] paddle.Tensor.remainder 	 paddle.Tensor.remainder(Tensor([4233601, 3, 4],"float32"), Tensor([4233601, 3, 4],"float32"), ) 	 101606424 	 1000 	 0.4508233070373535 	 0.4493257999420166 	 0.4411509037017822 	 0.43784141540527344 	 None 	 None 	 None 	 None 	 
2025-07-30 19:51:31.838825 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 1, 198451, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 1, 198451, 128],"float64"), 3, axis=1, ) 	 25401728 	 1000 	 0.8969428539276123 	 1.1206731796264648 	 0.45835018157958984 	 0.8658304214477539 	 1.4846856594085693 	 0.5879485607147217 	 0.5060703754425049 	 0.49197959899902344 	 
2025-07-30 19:51:40.441352 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 1, 64, 396901],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 1, 64, 396901],"float64"), 3, axis=1, ) 	 25401664 	 1000 	 0.8982067108154297 	 0.8828585147857666 	 0.4589419364929199 	 0.8506066799163818 	 1.4853696823120117 	 0.5877983570098877 	 0.5063323974609375 	 0.47492003440856934 	 
2025-07-30 19:51:46.469878 test begin: paddle.Tensor.repeat_interleave(Tensor([1, 3101, 64, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([1, 3101, 64, 128],"float64"), 3, axis=1, ) 	 25403392 	 1000 	 0.6951465606689453 	 0.6376140117645264 	 0.0736536979675293 	 0.6147825717926025 	 0.9170587062835693 	 0.5944385528564453 	 0.09430980682373047 	 0.4998927116394043 	 
2025-07-30 19:51:51.474519 test begin: paddle.Tensor.repeat_interleave(Tensor([3101, 1, 64, 128],"float64"), 3, axis=1, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(Tensor([3101, 1, 64, 128],"float64"), 3, axis=1, ) 	 25403392 	 1000 	 0.6185295581817627 	 0.6399943828582764 	 0.3161027431488037 	 0.6152081489562988 	 0.9168500900268555 	 0.5945045948028564 	 0.31249260902404785 	 0.5005834102630615 	 
2025-07-30 19:51:56.356852 test begin: paddle.Tensor.repeat_interleave(x=Tensor([158761, 2, 4, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([158761, 2, 4, 4, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 217.23025155067444 	 0.47624707221984863 	 0.00010204315185546875 	 0.4432692527770996 	 244.59200620651245 	 0.5450568199157715 	 8.916854858398438e-05 	 0.4458746910095215 	 
2025-07-30 19:59:41.365860 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 158761, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 158761, 4, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 215.98622512817383 	 0.466123104095459 	 9.512901306152344e-05 	 0.44347572326660156 	 243.10233807563782 	 0.5450584888458252 	 8.654594421386719e-05 	 0.44608163833618164 	 
2025-07-30 20:07:23.606178 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 158761, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 158761, 5],"float64"), repeats=2, ) 	 25401760 	 1000 	 217.2855303287506 	 0.4661288261413574 	 0.00010085105895996094 	 0.4433295726776123 	 249.2991247177124 	 0.5450613498687744 	 8.487701416015625e-05 	 0.4423635005950928 	 
2025-07-30 20:15:13.412611 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 198451],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 198451],"float64"), repeats=2, ) 	 25401728 	 1000 	 215.109610080719 	 0.4683725833892822 	 9.226799011230469e-05 	 0.44333982467651367 	 243.55310225486755 	 0.5450665950775146 	 8.153915405273438e-05 	 0.41568470001220703 	 
2025-07-30 20:22:55.254396 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 79381, 4, 4, 5],"float64"), repeats=2, )
[Prof] paddle.Tensor.repeat_interleave 	 paddle.Tensor.repeat_interleave(x=Tensor([4, 79381, 4, 4, 5],"float64"), repeats=2, ) 	 25401920 	 1000 	 219.28547143936157 	 0.46607327461242676 	 9.441375732421875e-05 	 0.4433472156524658 	 249.2378053665161 	 0.5450592041015625 	 8.344650268554688e-05 	 0.44699525833129883 	 
2025-07-30 20:30:46.975393 test begin: paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], )
[Prof] paddle.Tensor.reshape 	 paddle.Tensor.reshape(Tensor([124040, 8192],"bfloat16"), list[-1,8192,], ) 	 1016135680 	 1000 	 0.005425453186035156 	 0.0040740966796875 	 1.3589859008789062e-05 	 1.9311904907226562e-05 	 0.04602813720703125 	 4.496651887893677 	 3.0517578125e-05 	 2.297821521759033 	 
2025-07-30 20:31:26.307844 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.5138397216796875 	 0.303419828414917 	 0.4891965389251709 	 0.28794407844543457 	 0.8230125904083252 	 0.3037536144256592 	 0.42050814628601074 	 0.2212824821472168 	 
2025-07-30 20:31:29.521248 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.818568229675293 	 0.30431365966796875 	 0.4182722568511963 	 0.2862117290496826 	 0.5146145820617676 	 0.30330657958984375 	 0.45540642738342285 	 0.22887921333312988 	 
2025-07-30 20:31:32.559745 test begin: paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([396901, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8148572444915771 	 0.31183791160583496 	 0.41634106636047363 	 0.28631138801574707 	 0.514509916305542 	 0.3029358386993408 	 0.4551122188568115 	 0.23175954818725586 	 
2025-07-30 20:31:38.252488 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), ) 	 25401664 	 1000 	 0.515390157699585 	 0.31207704544067383 	 0.4919891357421875 	 0.28832149505615234 	 0.8231518268585205 	 0.30258679389953613 	 0.4205646514892578 	 0.2295513153076172 	 
2025-07-30 20:31:42.462408 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.9477550983428955 	 0.3040921688079834 	 0.48429107666015625 	 0.28698158264160156 	 0.5173232555389404 	 0.3041822910308838 	 0.45827484130859375 	 0.23277854919433594 	 
2025-07-30 20:31:45.674129 test begin: paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 396901, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8146913051605225 	 0.3033268451690674 	 0.41627001762390137 	 0.2864246368408203 	 0.5143492221832275 	 0.3029053211212158 	 0.4557178020477295 	 0.22855877876281738 	 
2025-07-30 20:31:48.689276 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), ) 	 25401664 	 1000 	 0.5164480209350586 	 0.30412960052490234 	 0.49274396896362305 	 0.28861188888549805 	 0.8245458602905273 	 0.30373477935791016 	 0.42130112648010254 	 0.22953009605407715 	 
2025-07-30 20:31:51.714587 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8306159973144531 	 0.3193979263305664 	 0.42441558837890625 	 0.28702402114868164 	 0.5146393775939941 	 0.30327582359313965 	 0.45606017112731934 	 0.23209905624389648 	 
2025-07-30 20:31:54.797793 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 396901, 4],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8179802894592285 	 0.30931687355041504 	 0.4179654121398926 	 0.2867238521575928 	 0.5169413089752197 	 0.30573439598083496 	 0.4581911563873291 	 0.2269895076751709 	 
2025-07-30 20:31:57.802112 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), ) 	 25401664 	 1000 	 0.5165042877197266 	 0.30414819717407227 	 0.4926941394805908 	 0.2833695411682129 	 0.8243846893310547 	 0.30376124382019043 	 0.4209885597229004 	 0.23204755783081055 	 
2025-07-30 20:32:00.805319 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=list[1,2,], ) 	 25401664 	 1000 	 0.8264236450195312 	 0.3041391372680664 	 0.4221334457397461 	 0.28577566146850586 	 0.5166730880737305 	 0.30603575706481934 	 0.4579005241394043 	 0.2349715232849121 	 
2025-07-30 20:32:03.833829 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), )
[Prof] paddle.Tensor.rot90 	 paddle.Tensor.rot90(x=Tensor([4, 4, 4, 396901],"float64"), k=-1, axes=tuple(2,3,), ) 	 25401664 	 1000 	 0.8098833560943604 	 0.3060910701751709 	 0.413820743560791 	 0.2893517017364502 	 0.5139482021331787 	 0.30292391777038574 	 0.4551832675933838 	 0.2301163673400879 	 
2025-07-30 20:32:06.877446 test begin: paddle.Tensor.round(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29563260078430176 	 0.29776811599731445 	 0.28676724433898926 	 0.28638195991516113 	 0.13386845588684082 	 0.13407516479492188 	 0.08294057846069336 	 0.06734728813171387 	 
2025-07-30 20:32:09.375516 test begin: paddle.Tensor.round(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.295590877532959 	 0.29782629013061523 	 0.28638195991516113 	 0.28528904914855957 	 0.13401246070861816 	 0.13411784172058105 	 0.08284854888916016 	 0.06756210327148438 	 
2025-07-30 20:32:11.884986 test begin: paddle.Tensor.round(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.2955746650695801 	 0.3122518062591553 	 0.28665971755981445 	 0.28597545623779297 	 0.1339569091796875 	 0.13411259651184082 	 0.08281826972961426 	 0.06831693649291992 	 
2025-07-30 20:32:14.469335 test begin: paddle.Tensor.round(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.29555797576904297 	 0.2977488040924072 	 0.2867586612701416 	 0.28659677505493164 	 0.13397622108459473 	 0.13414478302001953 	 0.08286666870117188 	 0.0677943229675293 	 
2025-07-30 20:32:16.954076 test begin: paddle.Tensor.round(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.round 	 paddle.Tensor.round(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.29552602767944336 	 0.297957181930542 	 0.2867584228515625 	 0.2865290641784668 	 0.13401412963867188 	 0.13420414924621582 	 0.08292150497436523 	 0.0676569938659668 	 
2025-07-30 20:32:22.148308 test begin: paddle.Tensor.rsqrt(Tensor([10, 20, 254017],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 20, 254017],"float32"), ) 	 50803400 	 1000 	 0.29567432403564453 	 0.7424085140228271 	 0.2869536876678467 	 0.28679823875427246 	 0.4501464366912842 	 1.0401341915130615 	 0.39479660987854004 	 0.35436582565307617 	 
2025-07-30 20:32:27.563537 test begin: paddle.Tensor.rsqrt(Tensor([10, 5080321, 1],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 5080321, 1],"float32"), ) 	 50803210 	 1000 	 0.2956728935241699 	 0.29980993270874023 	 0.2868037223815918 	 0.2872154712677002 	 0.4498608112335205 	 1.0401570796966553 	 0.3955714702606201 	 0.3543820381164551 	 
2025-07-30 20:32:31.359252 test begin: paddle.Tensor.rsqrt(Tensor([10, 5080321],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([10, 5080321],"float32"), ) 	 50803210 	 1000 	 0.29559826850891113 	 0.29779624938964844 	 0.28680419921875 	 0.28739023208618164 	 0.4498884677886963 	 1.0401477813720703 	 0.3949737548828125 	 0.35439276695251465 	 
2025-07-30 20:32:35.134501 test begin: paddle.Tensor.rsqrt(Tensor([2540161, 20, 1],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([2540161, 20, 1],"float32"), ) 	 50803220 	 1000 	 0.2956511974334717 	 0.31168079376220703 	 0.2868943214416504 	 0.2866232395172119 	 0.449845552444458 	 1.0403587818145752 	 0.396045446395874 	 0.3543262481689453 	 
2025-07-30 20:32:42.876838 test begin: paddle.Tensor.rsqrt(Tensor([2540161, 20],"float32"), )
[Prof] paddle.Tensor.rsqrt 	 paddle.Tensor.rsqrt(Tensor([2540161, 20],"float32"), ) 	 50803220 	 1000 	 0.2956066131591797 	 0.3016695976257324 	 0.28688645362854004 	 0.28716540336608887 	 0.4498481750488281 	 1.040113925933838 	 0.39589476585388184 	 0.35431671142578125 	 
2025-07-30 20:32:46.640989 test begin: paddle.Tensor.scale(Tensor([100352, 1013],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([100352, 1013],"bfloat16"), 0.006378560586546936, ) 	 101656576 	 1000 	 0.2981686592102051 	 0.5923547744750977 	 0.28903794288635254 	 0.3026614189147949 	 0.5881319046020508 	 0.7495534420013428 	 0.5322351455688477 	 0.3829374313354492 	 combined
2025-07-30 20:32:52.169896 test begin: paddle.Tensor.scale(Tensor([1013, 100352],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([1013, 100352],"bfloat16"), 0.006378560586546936, ) 	 101656576 	 1000 	 0.29816699028015137 	 0.5923495292663574 	 0.28896284103393555 	 0.30266809463500977 	 0.5880565643310547 	 0.7496681213378906 	 0.5325109958648682 	 0.383028507232666 	 combined
2025-07-30 20:32:57.678267 test begin: paddle.Tensor.scale(Tensor([12404, 8192],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([12404, 8192],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.29810166358947754 	 0.5920963287353516 	 0.2888307571411133 	 0.30253171920776367 	 0.588287353515625 	 0.7492389678955078 	 0.5308938026428223 	 0.3827807903289795 	 combined
2025-07-30 20:33:03.252431 test begin: paddle.Tensor.scale(Tensor([1772, 57344],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([1772, 57344],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.29807543754577637 	 0.5921382904052734 	 0.28831982612609863 	 0.30258846282958984 	 0.5883138179779053 	 0.7492749691009521 	 0.5309438705444336 	 0.38282108306884766 	 combined
2025-07-30 20:33:08.830693 test begin: paddle.Tensor.scale(Tensor([8192, 12404],"bfloat16"), 0.006378560586546936, )
[Prof] paddle.Tensor.scale 	 paddle.Tensor.scale(Tensor([8192, 12404],"bfloat16"), 0.006378560586546936, ) 	 101613568 	 1000 	 0.2980964183807373 	 0.5921375751495361 	 0.288250207901001 	 0.3025496006011963 	 0.5883162021636963 	 0.7493069171905518 	 0.5306434631347656 	 0.38280344009399414 	 combined
2025-07-30 20:33:14.440319 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([15, 3386881],"bool"), list[20,], list[2,], 0, ) 	 50805216 	 1000 	 0.09672379493713379 	 0.0022673606872558594 	 2.9802322387695312e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:33:15.272014 test begin: paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([2001],"bool"), Tensor([16934401, 3],"bool"), list[20,], list[2,], 0, ) 	 50805204 	 1000 	 0.0353550910949707 	 0.0022623538970947266 	 1.9788742065429688e-05 	 1.4543533325195312e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:33:16.062572 test begin: paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, )
[Prof] paddle.Tensor.set_ 	 paddle.Tensor.set_(Tensor([50803201],"bool"), Tensor([1501, 3],"bool"), list[20,], list[2,], 0, ) 	 50807704 	 1000 	 0.03576159477233887 	 0.00390625 	 1.6927719116210938e-05 	 5.0067901611328125e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 20:33:16.844906 test begin: paddle.Tensor.sigmoid(Tensor([1, 1100, 46185],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 1100, 46185],"float32"), ) 	 50803500 	 1000 	 0.2946958541870117 	 0.29833340644836426 	 0.2858157157897949 	 0.28790855407714844 	 0.44987010955810547 	 0.446425199508667 	 0.395770788192749 	 0.37874460220336914 	 
2025-07-30 20:33:19.979374 test begin: paddle.Tensor.sigmoid(Tensor([1, 12700801, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 12700801, 4],"float32"), ) 	 50803204 	 1000 	 0.2947204113006592 	 0.2982938289642334 	 0.2859809398651123 	 0.2872171401977539 	 0.449901819229126 	 0.4464142322540283 	 0.39573168754577637 	 0.3784806728363037 	 
2025-07-30 20:33:23.157555 test begin: paddle.Tensor.sigmoid(Tensor([1, 6380, 7963],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 6380, 7963],"float32"), ) 	 50803940 	 1000 	 0.29482483863830566 	 0.298311710357666 	 0.2824892997741699 	 0.287996768951416 	 0.4500772953033447 	 0.4464244842529297 	 0.3955378532409668 	 0.37836241722106934 	 
2025-07-30 20:33:26.289566 test begin: paddle.Tensor.sigmoid(Tensor([1, 8550, 5942],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1, 8550, 5942],"float32"), ) 	 50804100 	 1000 	 0.2947220802307129 	 0.314800500869751 	 0.28578782081604004 	 0.28777098655700684 	 0.4498860836029053 	 0.446429967880249 	 0.3939626216888428 	 0.3758077621459961 	 
2025-07-30 20:33:33.075946 test begin: paddle.Tensor.sigmoid(Tensor([11547, 1100, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([11547, 1100, 4],"float32"), ) 	 50806800 	 1000 	 0.2948620319366455 	 1.2239735126495361 	 0.2848525047302246 	 0.2877054214477539 	 0.44983434677124023 	 0.44648003578186035 	 0.39543843269348145 	 0.37992382049560547 	 
2025-07-30 20:33:39.471113 test begin: paddle.Tensor.sigmoid(Tensor([1486, 8550, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1486, 8550, 4],"float32"), ) 	 50821200 	 1000 	 0.29473114013671875 	 0.3040428161621094 	 0.28606104850769043 	 0.2878837585449219 	 0.4501004219055176 	 0.44658780097961426 	 0.39569902420043945 	 0.3785536289215088 	 
2025-07-30 20:33:42.597251 test begin: paddle.Tensor.sigmoid(Tensor([1991, 6380, 4],"float32"), )
[Prof] paddle.Tensor.sigmoid 	 paddle.Tensor.sigmoid(Tensor([1991, 6380, 4],"float32"), ) 	 50810320 	 1000 	 0.29483747482299805 	 0.2999081611633301 	 0.28606247901916504 	 0.2874171733856201 	 0.45023655891418457 	 0.44655632972717285 	 0.3959007263183594 	 0.3680105209350586 	 
2025-07-30 20:33:45.749918 test begin: paddle.Tensor.sign(Tensor([1016065, 5, 5],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1016065, 5, 5],"float64"), ) 	 25401625 	 1000 	 0.3084852695465088 	 0.29823732376098633 	 0.3003382682800293 	 0.2878077030181885 	 0.29787135124206543 	 0.1345076560974121 	 0.2467048168182373 	 0.0685577392578125 	 
2025-07-30 20:33:47.928279 test begin: paddle.Tensor.sign(Tensor([1124, 45199],"float32"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1124, 45199],"float32"), ) 	 50803676 	 1000 	 0.3456382751464844 	 0.2977321147918701 	 0.3374314308166504 	 0.2872152328491211 	 0.2957298755645752 	 0.13410401344299316 	 0.2408313751220703 	 0.06856179237365723 	 
2025-07-30 20:33:50.633990 test begin: paddle.Tensor.sign(Tensor([12700801, 2],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([12700801, 2],"float64"), ) 	 25401602 	 1000 	 0.3084883689880371 	 0.29821157455444336 	 0.3003876209259033 	 0.28790807723999023 	 0.297898530960083 	 0.13452959060668945 	 0.24615764617919922 	 0.06891870498657227 	 
2025-07-30 20:33:52.724555 test begin: paddle.Tensor.sign(Tensor([1587601, 32],"float32"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([1587601, 32],"float32"), ) 	 50803232 	 1000 	 0.3457627296447754 	 0.30063867568969727 	 0.3375227451324463 	 0.2873101234436035 	 0.29569363594055176 	 0.13405609130859375 	 0.2440800666809082 	 0.06861472129821777 	 
2025-07-30 20:33:55.450239 test begin: paddle.Tensor.sign(Tensor([50000, 102, 5],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 102, 5],"float64"), ) 	 25500000 	 1000 	 0.30976152420043945 	 0.29937243461608887 	 0.3016068935394287 	 0.2887287139892578 	 0.29929327964782715 	 0.13498210906982422 	 0.2475600242614746 	 0.06909298896789551 	 
2025-07-30 20:33:57.598614 test begin: paddle.Tensor.sign(Tensor([50000, 5, 102],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 5, 102],"float64"), ) 	 25500000 	 1000 	 0.3099048137664795 	 0.2994515895843506 	 0.3017086982727051 	 0.2887864112854004 	 0.29929590225219727 	 0.1349945068359375 	 0.24722528457641602 	 0.06759166717529297 	 
2025-07-30 20:33:59.723149 test begin: paddle.Tensor.sign(Tensor([50000, 509],"float64"), )
[Prof] paddle.Tensor.sign 	 paddle.Tensor.sign(Tensor([50000, 509],"float64"), ) 	 25450000 	 1000 	 0.3091278076171875 	 0.29884982109069824 	 0.30098605155944824 	 0.28816652297973633 	 0.29862260818481445 	 0.1346578598022461 	 0.24708867073059082 	 0.06863617897033691 	 
2025-07-30 20:34:01.843150 test begin: paddle.Tensor.signbit(Tensor([12, 10584, 2],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 10584, 2],"float64"), ) 	 254016 	 1000 	 10.218701362609863 	 0.009917974472045898 	 4.5299530029296875e-05 	 4.076957702636719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:34:12.124061 test begin: paddle.Tensor.signbit(Tensor([12, 20, 1058],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 1058],"float64"), ) 	 253920 	 1000 	 10.137606382369995 	 0.009753704071044922 	 4.458427429199219e-05 	 2.4557113647460938e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:34:22.318287 test begin: paddle.Tensor.signbit(Tensor([12, 20, 2116],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 2116],"float32"), ) 	 507840 	 1000 	 20.164803743362427 	 0.009822845458984375 	 4.673004150390625e-05 	 4.3392181396484375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:34:43.462141 test begin: paddle.Tensor.signbit(Tensor([12, 20, 4233],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 20, 4233],"int16"), ) 	 1015920 	 1000 	 39.65498232841492 	 0.010076045989990234 	 5.841255187988281e-05 	 3.814697265625e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:23.221754 test begin: paddle.Tensor.signbit(Tensor([12, 21168, 2],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 21168, 2],"float32"), ) 	 508032 	 1000 	 20.062951803207397 	 0.011515140533447266 	 4.887580871582031e-05 	 5.4836273193359375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:35:43.359815 test begin: paddle.Tensor.signbit(Tensor([12, 42336, 2],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12, 42336, 2],"int16"), ) 	 1016064 	 1000 	 39.904348850250244 	 0.010221242904663086 	 5.14984130859375e-05 	 3.5762786865234375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:36:23.370789 test begin: paddle.Tensor.signbit(Tensor([12700, 20, 2],"float32"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([12700, 20, 2],"float32"), ) 	 508000 	 1000 	 20.02325677871704 	 0.009798049926757812 	 5.0067901611328125e-05 	 2.5033950805664062e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:36:43.465529 test begin: paddle.Tensor.signbit(Tensor([25401, 20, 2],"int16"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([25401, 20, 2],"int16"), ) 	 1016040 	 1000 	 40.061726093292236 	 0.010015249252319336 	 5.245208740234375e-05 	 3.62396240234375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:37:23.624727 test begin: paddle.Tensor.signbit(Tensor([6350, 20, 2],"float64"), )
[Prof] paddle.Tensor.signbit 	 paddle.Tensor.signbit(Tensor([6350, 20, 2],"float64"), ) 	 254000 	 1000 	 10.183414220809937 	 0.010070085525512695 	 4.291534423828125e-05 	 4.839897155761719e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:37:33.867103 test begin: paddle.Tensor.sin(Tensor([131072, 388],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([131072, 388],"float32"), ) 	 50855936 	 1000 	 0.2956371307373047 	 0.5303258895874023 	 0.2856321334838867 	 0.28755736351013184 	 0.4507143497467041 	 0.7442290782928467 	 0.3973655700683594 	 0.38021397590637207 	 
2025-07-30 20:37:40.009715 test begin: paddle.Tensor.sin(Tensor([3175201, 16],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([3175201, 16],"float32"), ) 	 50803216 	 1000 	 0.29547595977783203 	 0.29804229736328125 	 0.2863128185272217 	 0.28770995140075684 	 0.4503214359283447 	 0.7434687614440918 	 0.3968009948730469 	 0.3798069953918457 	 
2025-07-30 20:37:43.435372 test begin: paddle.Tensor.sin(Tensor([32768, 1551],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([32768, 1551],"float32"), ) 	 50823168 	 1000 	 0.29541873931884766 	 0.29819536209106445 	 0.2793266773223877 	 0.2817223072052002 	 0.45044755935668945 	 0.7436504364013672 	 0.3844735622406006 	 0.3799302577972412 	 
2025-07-30 20:37:46.892471 test begin: paddle.Tensor.sin(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.sin 	 paddle.Tensor.sin(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.29533982276916504 	 0.29802870750427246 	 0.27924418449401855 	 0.2816436290740967 	 0.4501776695251465 	 0.7433493137359619 	 0.38732314109802246 	 0.37983202934265137 	 
2025-07-30 20:37:50.414794 test begin: paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([127008010, 4],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.007607460021972656 	 0.013210535049438477 	 1.2159347534179688e-05 	 3.0517578125e-05 	 4.8448262214660645 	 4.628387212753296 	 2.4753835201263428 	 2.36518931388855 	 combined
2025-07-30 20:38:11.086690 test begin: paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], )
[Prof] paddle.Tensor.slice 	 paddle.Tensor.slice(Tensor([40, 12700801],"float32"), list[1,], list[0,], list[1,], ) 	 508032040 	 1000 	 0.011738777160644531 	 0.013361454010009766 	 4.124641418457031e-05 	 2.2411346435546875e-05 	 1.5115511417388916 	 1.3169751167297363 	 0.7723791599273682 	 0.6728634834289551 	 combined
2025-07-30 20:38:22.175633 test begin: paddle.Tensor.slice_scatter(Tensor([4233601, 6],"float64"), Tensor([4233601, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([4233601, 6],"float64"), Tensor([4233601, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 38102409 	 1000 	 0.37652134895324707 	 0.6881284713745117 	 0.35333824157714844 	 0.23425936698913574 	 1.0700716972351074 	 0.7652161121368408 	 0.18221282958984375 	 0.19542241096496582 	 
2025-07-30 20:38:26.487461 test begin: paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([80, 3175201],"float64"), Tensor([80, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 254016320 	 1000 	 0.0147552490234375 	 3.069254159927368 	 1.1920928955078125e-05 	 1.042909860610962 	 3.0713329315185547 	 3.0686047077178955 	 0.5221030712127686 	 0.7824485301971436 	 
2025-07-30 20:38:47.876338 test begin: paddle.Tensor.slice_scatter(Tensor([8467201, 6],"float64"), Tensor([8467201, 3],"float64"), list[1,], list[0,], list[6,], list[2,], )
[Prof] paddle.Tensor.slice_scatter 	 paddle.Tensor.slice_scatter(Tensor([8467201, 6],"float64"), Tensor([8467201, 3],"float64"), list[1,], list[0,], list[6,], list[2,], ) 	 76204809 	 1000 	 0.7469158172607422 	 1.3625590801239014 	 0.7318823337554932 	 0.4639711380004883 	 2.108814001083374 	 1.5043294429779053 	 0.35896825790405273 	 0.38427066802978516 	 
2025-07-30 20:38:56.337197 test begin: paddle.Tensor.sqrt(Tensor([276, 80, 48, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([276, 80, 48, 48],"float32"), ) 	 50872320 	 1000 	 0.29530930519104004 	 0.2992250919342041 	 0.2866356372833252 	 0.2884519100189209 	 0.4513669013977051 	 0.7479705810546875 	 0.3972461223602295 	 0.38214969635009766 	 
2025-07-30 20:38:59.823062 test begin: paddle.Tensor.sqrt(Tensor([329, 80, 44, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([329, 80, 44, 44],"float32"), ) 	 50955520 	 1000 	 0.29549527168273926 	 0.540520429611206 	 0.28682494163513184 	 0.28880953788757324 	 0.4522082805633545 	 0.7491953372955322 	 0.3984646797180176 	 0.38276195526123047 	 
2025-07-30 20:39:06.249497 test begin: paddle.Tensor.sqrt(Tensor([397, 80, 40, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([397, 80, 40, 40],"float32"), ) 	 50816000 	 1000 	 0.29458022117614746 	 0.2988295555114746 	 0.28571510314941406 	 0.2883272171020508 	 0.4508852958679199 	 0.7472312450408936 	 0.3971104621887207 	 0.3817276954650879 	 
2025-07-30 20:39:09.725291 test begin: paddle.Tensor.sqrt(Tensor([64, 345, 48, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 345, 48, 48],"float32"), ) 	 50872320 	 1000 	 0.2952756881713867 	 0.29920196533203125 	 0.2794041633605957 	 0.28250789642333984 	 0.4513707160949707 	 0.7480700016021729 	 0.3855276107788086 	 0.38219380378723145 	 
2025-07-30 20:39:13.304912 test begin: paddle.Tensor.sqrt(Tensor([64, 411, 44, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 411, 44, 44],"float32"), ) 	 50924544 	 1000 	 0.29525303840637207 	 0.2995166778564453 	 0.2864975929260254 	 0.2888765335083008 	 0.4518105983734131 	 0.748793363571167 	 0.3955550193786621 	 0.38259243965148926 	 
2025-07-30 20:39:16.762109 test begin: paddle.Tensor.sqrt(Tensor([64, 497, 40, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 497, 40, 40],"float32"), ) 	 50892800 	 1000 	 0.29539060592651367 	 0.299330472946167 	 0.28673267364501953 	 0.2885432243347168 	 0.4515812397003174 	 0.7483088970184326 	 0.3974020481109619 	 0.38231825828552246 	 
2025-07-30 20:39:20.235768 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 207, 48],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 207, 48],"float32"), ) 	 50872320 	 1000 	 0.29529380798339844 	 0.30330753326416016 	 0.28268909454345703 	 0.2882866859436035 	 0.45134401321411133 	 0.7480411529541016 	 0.39742374420166016 	 0.38222551345825195 	 
2025-07-30 20:39:23.751632 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 226, 44],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 226, 44],"float32"), ) 	 50913280 	 1000 	 0.29545044898986816 	 0.2994260787963867 	 0.28682994842529297 	 0.2886519432067871 	 0.45159173011779785 	 0.7487344741821289 	 0.3977789878845215 	 0.3825075626373291 	 
2025-07-30 20:39:27.187720 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 249, 40],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 249, 40],"float32"), ) 	 50995200 	 1000 	 0.2958371639251709 	 0.2999083995819092 	 0.2871742248535156 	 0.2892031669616699 	 0.4523336887359619 	 0.7498197555541992 	 0.3983035087585449 	 0.38313841819763184 	 
2025-07-30 20:39:30.648987 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 40, 249],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 40, 249],"float32"), ) 	 50995200 	 1000 	 0.29579973220825195 	 0.2999396324157715 	 0.28705883026123047 	 0.2893240451812744 	 0.4522559642791748 	 0.749859094619751 	 0.3984072208404541 	 0.38311123847961426 	 
2025-07-30 20:39:34.148212 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 44, 226],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 44, 226],"float32"), ) 	 50913280 	 1000 	 0.295412540435791 	 1.1035175323486328 	 0.28679847717285156 	 0.2825300693511963 	 0.4516568183898926 	 0.7486755847930908 	 0.39800548553466797 	 0.38246726989746094 	 
2025-07-30 20:39:39.991798 test begin: paddle.Tensor.sqrt(Tensor([64, 80, 48, 207],"float32"), )
[Prof] paddle.Tensor.sqrt 	 paddle.Tensor.sqrt(Tensor([64, 80, 48, 207],"float32"), ) 	 50872320 	 1000 	 0.2952902317047119 	 0.29916977882385254 	 0.28655052185058594 	 0.28856492042541504 	 0.4512941837310791 	 0.7481119632720947 	 0.3973414897918701 	 0.3822612762451172 	 
2025-07-30 20:39:43.447104 test begin: paddle.Tensor.square(Tensor([2, 25401601],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.295764684677124 	 0.2977137565612793 	 0.28715085983276367 	 0.2864401340484619 	 0.45020341873168945 	 1.0553507804870605 	 0.39624547958374023 	 0.26986050605773926 	 
2025-07-30 20:39:47.228582 test begin: paddle.Tensor.square(Tensor([396901, 128],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([396901, 128],"float32"), ) 	 50803328 	 1000 	 0.2955293655395508 	 0.29776549339294434 	 0.28691673278808594 	 0.28643345832824707 	 0.449873685836792 	 1.0554299354553223 	 0.39681196212768555 	 0.26984691619873047 	 
2025-07-30 20:39:50.975586 test begin: paddle.Tensor.square(Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([50803201],"float32"), ) 	 50803201 	 1000 	 0.29567480087280273 	 0.29775166511535645 	 0.2870810031890869 	 0.2866358757019043 	 0.450040340423584 	 1.0553150177001953 	 0.3967154026031494 	 0.2697751522064209 	 
2025-07-30 20:39:54.699135 test begin: paddle.Tensor.square(Tensor([8, 6350401],"float32"), )
[Prof] paddle.Tensor.square 	 paddle.Tensor.square(Tensor([8, 6350401],"float32"), ) 	 50803208 	 1000 	 0.29569506645202637 	 0.29781365394592285 	 0.28701019287109375 	 0.2865760326385498 	 0.45012474060058594 	 1.0554132461547852 	 0.3966398239135742 	 0.26982545852661133 	 
2025-07-30 20:39:58.463990 test begin: paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 2, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.0046041011810302734 	 0.00469517707824707 	 1.1682510375976562e-05 	 6.461143493652344e-05 	 0.0419008731842041 	 0.05458569526672363 	 1.621246337890625e-05 	 4.553794860839844e-05 	 
2025-07-30 20:40:25.353511 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.0044019222259521484 	 0.004008054733276367 	 1.2874603271484375e-05 	 2.09808349609375e-05 	 0.042107582092285156 	 0.05652928352355957 	 2.765655517578125e-05 	 5.412101745605469e-05 	 
2025-07-30 20:40:41.723589 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 10240],"float32"), 0, ) 	 1179648000 	 1000 	 0.004579067230224609 	 0.004085540771484375 	 1.33514404296875e-05 	 2.9087066650390625e-05 	 0.044435977935791016 	 0.06996679306030273 	 5.078315734863281e-05 	 8.034706115722656e-05 	 
2025-07-30 20:41:21.731367 test begin: paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([10, 3, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004388570785522461 	 0.003992557525634766 	 8.821487426757812e-06 	 1.8596649169921875e-05 	 0.04216122627258301 	 0.0537724494934082 	 2.1457672119140625e-05 	 4.029273986816406e-05 	 
2025-07-30 20:41:40.261456 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 125, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.004503965377807617 	 0.004167318344116211 	 1.1205673217773438e-05 	 1.71661376953125e-05 	 0.042191505432128906 	 0.0635995864868164 	 2.0503997802734375e-05 	 5.7220458984375e-05 	 
2025-07-30 20:41:56.797197 test begin: paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 1, 80, 39691],"float32"), 1, ) 	 508044800 	 1000 	 0.004647731781005859 	 0.0041353702545166016 	 1.239776611328125e-05 	 2.288818359375e-05 	 0.04224109649658203 	 0.05717635154724121 	 2.09808349609375e-05 	 3.0517578125e-05 	 
2025-07-30 20:42:13.246356 test begin: paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([160, 2, 80, 25500],"float32"), 1, ) 	 652800000 	 1000 	 0.004406452178955078 	 0.004031181335449219 	 1.0728836059570312e-05 	 2.1457672119140625e-05 	 0.0420384407043457 	 0.05353999137878418 	 2.1457672119140625e-05 	 6.341934204101562e-05 	 
2025-07-30 20:42:33.975942 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 127009, 2],"float32"), 1, ) 	 508036000 	 1000 	 0.0045549869537353516 	 0.004096508026123047 	 1.0728836059570312e-05 	 1.9073486328125e-05 	 0.04240775108337402 	 0.058965444564819336 	 2.6226043701171875e-05 	 4.57763671875e-05 	 
2025-07-30 20:42:50.795437 test begin: paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 1, 37632, 7],"float32"), 1, ) 	 526848000 	 1000 	 0.004556179046630859 	 0.0040667057037353516 	 8.344650268554688e-06 	 2.1219253540039062e-05 	 0.044245243072509766 	 0.0603640079498291 	 1.9550323486328125e-05 	 5.698204040527344e-05 	 
2025-07-30 20:43:07.854493 test begin: paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([2000, 4, 37632, 2],"float32"), 1, ) 	 602112000 	 1000 	 0.004481077194213867 	 0.004091501235961914 	 6.67572021484375e-06 	 2.1457672119140625e-05 	 0.04172396659851074 	 0.05341958999633789 	 5.888938903808594e-05 	 5.340576171875e-05 	 
2025-07-30 20:43:29.808604 test begin: paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([250, 1, 80, 25500],"float32"), 1, ) 	 510000000 	 1000 	 0.0045013427734375 	 0.0041980743408203125 	 6.9141387939453125e-06 	 1.8835067749023438e-05 	 0.042227983474731445 	 0.057491302490234375 	 1.9073486328125e-05 	 5.507469177246094e-05 	 
2025-07-30 20:43:46.646834 test begin: paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, )
[Prof] paddle.Tensor.squeeze 	 paddle.Tensor.squeeze(Tensor([6760, 1, 37632, 2],"float32"), 1, ) 	 508784640 	 1000 	 0.004690647125244141 	 0.007938146591186523 	 1.9550323486328125e-05 	 2.2411346435546875e-05 	 0.04946422576904297 	 0.0643303394317627 	 2.9802322387695312e-05 	 5.7220458984375e-05 	 
2025-07-30 20:44:03.246864 test begin: paddle.Tensor.std(Tensor([1024, 1024, 25],"float64"), )
W0730 20:44:03.725582 54484 dygraph_functions.cc:88394] got different data type, run type promotion automatically, this may cause data type been changed.
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 1024, 25],"float64"), ) 	 26214400 	 1000 	 1.341310739517212 	 0.18372750282287598 	 2.765655517578125e-05 	 0.09388113021850586 	 1.5300965309143066 	 0.7901465892791748 	 0.1957862377166748 	 0.09001803398132324 	 
2025-07-30 20:44:07.680646 test begin: paddle.Tensor.std(Tensor([1024, 1024, 49],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 1024, 49],"float32"), ) 	 51380224 	 1000 	 1.1065163612365723 	 0.16794991493225098 	 1.8358230590820312e-05 	 0.08579349517822266 	 1.3535783290863037 	 0.78275465965271 	 0.1731867790222168 	 0.08916258811950684 	 
2025-07-30 20:44:11.917184 test begin: paddle.Tensor.std(Tensor([1024, 3101, 8],"float64"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 3101, 8],"float64"), ) 	 25403392 	 1000 	 1.3037476539611816 	 0.17914509773254395 	 2.9325485229492188e-05 	 0.09151959419250488 	 1.4834072589874268 	 0.7681920528411865 	 0.1897904872894287 	 0.08749270439147949 	 
2025-07-30 20:44:16.210335 test begin: paddle.Tensor.std(Tensor([1024, 6202, 8],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1024, 6202, 8],"float32"), ) 	 50806784 	 1000 	 1.0950744152069092 	 0.16628766059875488 	 3.0994415283203125e-05 	 0.0849614143371582 	 1.3390114307403564 	 0.7745609283447266 	 0.17132949829101562 	 0.08823490142822266 	 
2025-07-30 20:44:20.430891 test begin: paddle.Tensor.std(Tensor([1444, 35183],"float32"), axis=1, )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([1444, 35183],"float32"), axis=1, ) 	 50804252 	 1000 	 1.1311218738555908 	 0.17637133598327637 	 1.9788742065429688e-05 	 0.16026020050048828 	 1.360673427581787 	 0.7813513278961182 	 0.17412281036376953 	 0.0999460220336914 	 
2025-07-30 20:44:24.712909 test begin: paddle.Tensor.std(Tensor([3101, 1024, 8],"float64"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([3101, 1024, 8],"float64"), ) 	 25403392 	 1000 	 1.3076586723327637 	 0.1788346767425537 	 1.8835067749023438e-05 	 0.09137272834777832 	 1.4832143783569336 	 0.7668626308441162 	 0.1898040771484375 	 0.08737683296203613 	 
2025-07-30 20:44:28.992960 test begin: paddle.Tensor.std(Tensor([49613, 1024],"float32"), axis=1, )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([49613, 1024],"float32"), axis=1, ) 	 50803712 	 1000 	 1.0898358821868896 	 0.1679553985595703 	 3.361701965332031e-05 	 0.14396977424621582 	 1.348078966140747 	 0.7799131870269775 	 0.19687891006469727 	 0.09976387023925781 	 
2025-07-30 20:44:34.915426 test begin: paddle.Tensor.std(Tensor([6202, 1024, 8],"float32"), )
[Prof] paddle.Tensor.std 	 paddle.Tensor.std(Tensor([6202, 1024, 8],"float32"), ) 	 50806784 	 1000 	 1.0971324443817139 	 0.1662280559539795 	 2.47955322265625e-05 	 0.08493566513061523 	 1.339707612991333 	 0.775294303894043 	 0.17158246040344238 	 0.08840060234069824 	 
2025-07-30 20:44:40.713574 test begin: paddle.Tensor.subtract(Tensor([50803201],"float32"), Tensor([50803201],"float32"), )
[Prof] paddle.Tensor.subtract 	 paddle.Tensor.subtract(Tensor([50803201],"float32"), Tensor([50803201],"float32"), ) 	 101606402 	 1000 	 0.44977831840515137 	 0.4480562210083008 	 0.43998193740844727 	 0.4347672462463379 	 0.4762697219848633 	 0.2977149486541748 	 0.41812777519226074 	 0.22678923606872559 	 
2025-07-30 20:44:44.857616 test begin: paddle.Tensor.sum(Tensor([106496, 478],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([106496, 478],"float32"), axis=-1, ) 	 50905088 	 1000 	 0.1499793529510498 	 0.155106782913208 	 0.13801789283752441 	 0.14037322998046875 	 0.13818740844726562 	 0.0577242374420166 	 0.08232283592224121 	 3.7670135498046875e-05 	 
2025-07-30 20:44:46.180646 test begin: paddle.Tensor.sum(Tensor([108544, 469],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([108544, 469],"float32"), axis=-1, ) 	 50907136 	 1000 	 0.15004277229309082 	 0.1546649932861328 	 0.13808512687683105 	 0.13980722427368164 	 0.1379566192626953 	 0.057103633880615234 	 0.0820469856262207 	 3.886222839355469e-05 	 
2025-07-30 20:44:47.504496 test begin: paddle.Tensor.sum(Tensor([111616, 456],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([111616, 456],"float32"), axis=-1, ) 	 50896896 	 1000 	 0.15033912658691406 	 0.1526048183441162 	 0.13841462135314941 	 0.1378192901611328 	 0.13831663131713867 	 0.05656719207763672 	 0.08244490623474121 	 2.5272369384765625e-05 	 
2025-07-30 20:44:48.818856 test begin: paddle.Tensor.sum(Tensor([14176, 3584],"float32"), axis=-1, )
[Prof] paddle.Tensor.sum 	 paddle.Tensor.sum(Tensor([14176, 3584],"float32"), axis=-1, ) 	 50806784 	 1000 	 0.1460402011871338 	 0.1551651954650879 	 0.13411164283752441 	 0.14048051834106445 	 0.13705945014953613 	 0.06061291694641113 	 0.08083415031433105 	 4.172325134277344e-05 	 
2025-07-30 20:44:50.182576 test begin: paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, ) 	 50931328 	 1000 	 0.7749881744384766 	 0.47242069244384766 	 0.2639954090118408 	 0.45496630668640137 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:02.752200 test begin: paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, ) 	 50803456 	 1000 	 0.30246663093566895 	 0.01723170280456543 	 0.10311341285705566 	 3.552436828613281e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:04.386980 test begin: paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([128, 396901],"float32"), indices=Tensor([128, 396901],"int32"), axis=-1, ) 	 101606656 	 1000 	 1.403778314590454 	 0.7370913028717041 	 0.4784202575683594 	 0.710989236831665 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:14.396712 test begin: paddle.Tensor.take_along_axis(Tensor([50804, 1000],"float32"), indices=Tensor([50804, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([50804, 1000],"float32"), indices=Tensor([50804, 1],"int32"), axis=-1, ) 	 50854804 	 1000 	 0.3079380989074707 	 0.01705145835876465 	 0.1050100326538086 	 2.8848648071289062e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:16.084507 test begin: paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, ) 	 50883280 	 1000 	 0.7636218070983887 	 0.4705789089202881 	 0.2600867748260498 	 0.45311880111694336 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:28.946278 test begin: paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, ) 	 50803360 	 1000 	 0.30243754386901855 	 0.017169952392578125 	 0.10312461853027344 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:30.548407 test begin: paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, )
[Prof] paddle.Tensor.take_along_axis 	 paddle.Tensor.take_along_axis(Tensor([80, 635041],"float32"), indices=Tensor([80, 635041],"int32"), axis=-1, ) 	 101606560 	 1000 	 1.405968189239502 	 0.7513389587402344 	 0.47916197776794434 	 0.7267706394195557 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 20:45:41.891978 test begin: paddle.Tensor.tanh(Tensor([1, 16934401, 3],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 16934401, 3],"float32"), ) 	 50803203 	 1000 	 0.2953219413757324 	 0.3126833438873291 	 0.2853529453277588 	 0.2798583507537842 	 0.4496040344238281 	 0.4466514587402344 	 0.3952977657318115 	 0.3713192939758301 	 
2025-07-30 20:45:45.732716 test begin: paddle.Tensor.tanh(Tensor([1, 2, 12700801],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.29918336868286133 	 0.30022764205932617 	 0.2905116081237793 	 0.29007887840270996 	 0.4479100704193115 	 0.4444277286529541 	 0.39371252059936523 	 0.3742356300354004 	 
2025-07-30 20:45:48.316818 test begin: paddle.Tensor.tanh(Tensor([1, 2, 25401601],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 2, 25401601],"float32"), ) 	 50803202 	 1000 	 0.29523515701293945 	 0.29804420471191406 	 0.28635549545288086 	 0.2877833843231201 	 0.449660062789917 	 0.446519136428833 	 0.3955807685852051 	 0.3785743713378906 	 
2025-07-30 20:45:51.456616 test begin: paddle.Tensor.tanh(Tensor([1, 8467201, 3],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([1, 8467201, 3],"float64"), ) 	 25401603 	 1000 	 0.29915571212768555 	 0.3044893741607666 	 0.2904813289642334 	 0.28992676734924316 	 0.44804811477661133 	 0.44437527656555176 	 0.3942689895629883 	 0.3723146915435791 	 
2025-07-30 20:45:54.028127 test begin: paddle.Tensor.tanh(Tensor([2, 12700801],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([2, 12700801],"float64"), ) 	 25401602 	 1000 	 0.2991759777069092 	 0.30020618438720703 	 0.2905433177947998 	 0.29021120071411133 	 0.4479494094848633 	 0.44442057609558105 	 0.39319419860839844 	 0.37733983993530273 	 
2025-07-30 20:45:56.619098 test begin: paddle.Tensor.tanh(Tensor([4233601, 2, 3],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([4233601, 2, 3],"float64"), ) 	 25401606 	 1000 	 0.2991945743560791 	 0.3003077507019043 	 0.2904622554779053 	 0.28678154945373535 	 0.44801902770996094 	 0.44441843032836914 	 0.39427852630615234 	 0.37790513038635254 	 
2025-07-30 20:45:59.218357 test begin: paddle.Tensor.tanh(Tensor([6350401, 4],"float64"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([6350401, 4],"float64"), ) 	 25401604 	 1000 	 0.29917097091674805 	 0.30016160011291504 	 0.2896151542663574 	 0.2899141311645508 	 0.44806337356567383 	 0.44437241554260254 	 0.3945283889770508 	 0.37775754928588867 	 
2025-07-30 20:46:01.813688 test begin: paddle.Tensor.tanh(Tensor([8467201, 2, 3],"float32"), )
[Prof] paddle.Tensor.tanh 	 paddle.Tensor.tanh(Tensor([8467201, 2, 3],"float32"), ) 	 50803206 	 1000 	 0.29521751403808594 	 0.2980310916900635 	 0.286449670791626 	 0.28775858879089355 	 0.4496152400970459 	 0.4465165138244629 	 0.39504528045654297 	 0.3784773349761963 	 
2025-07-30 20:46:04.930061 test begin: paddle.Tensor.tile(Tensor([198451, 1, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([198451, 1, 256],"float32"), tuple(1,1,1,), ) 	 50803456 	 1000 	 0.296083927154541 	 0.3130362033843994 	 0.28455185890197754 	 0.15986275672912598 	 0.31462669372558594 	 0.052805185317993164 	 0.16069984436035156 	 2.9802322387695312e-05 	 
2025-07-30 20:46:07.614046 test begin: paddle.Tensor.tile(Tensor([36858, 1, 1379],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([36858, 1, 1379],"float32"), tuple(1,1,1,), ) 	 50827182 	 1000 	 0.29624438285827637 	 0.31325650215148926 	 0.284726619720459 	 0.15998053550720215 	 0.31653761863708496 	 0.05363941192626953 	 0.1616978645324707 	 6.961822509765625e-05 	 
2025-07-30 20:46:10.281373 test begin: paddle.Tensor.tile(Tensor([36858, 6, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([36858, 6, 256],"float32"), tuple(1,1,1,), ) 	 56613888 	 1000 	 0.3292961120605469 	 0.3450491428375244 	 0.31767773628234863 	 0.32503199577331543 	 0.3454434871673584 	 0.05309128761291504 	 0.28635096549987793 	 3.838539123535156e-05 	 
2025-07-30 20:46:13.157227 test begin: paddle.Tensor.tile(Tensor([38402, 1, 1323],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([38402, 1, 1323],"float32"), tuple(1,1,1,), ) 	 50805846 	 1000 	 0.2957174777984619 	 0.31276535987854004 	 0.2838573455810547 	 0.15969324111938477 	 0.3076436519622803 	 0.053247690200805664 	 0.1571652889251709 	 3.5762786865234375e-05 	 
2025-07-30 20:46:15.773782 test begin: paddle.Tensor.tile(Tensor([38402, 6, 256],"float32"), tuple(1,1,1,), )
[Prof] paddle.Tensor.tile 	 paddle.Tensor.tile(Tensor([38402, 6, 256],"float32"), tuple(1,1,1,), ) 	 58985472 	 1000 	 0.34304165840148926 	 0.35926103591918945 	 0.331531286239624 	 0.33350372314453125 	 0.35956501960754395 	 0.053076744079589844 	 0.3025217056274414 	 3.910064697265625e-05 	 
2025-07-30 20:46:18.831952 test begin: paddle.Tensor.tolist(Tensor([11, 16, 32, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 16, 32, 43],"int64"), ) 	 242176 	 1000 	 13.515822410583496 	 17.105303049087524 	 8.416175842285156e-05 	 0.00014090538024902344 	 None 	 None 	 None 	 None 	 
2025-07-30 20:46:49.494483 test begin: paddle.Tensor.tolist(Tensor([11, 25, 21, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 25, 21, 43],"int64"), ) 	 248325 	 1000 	 13.183698415756226 	 17.389728307724 	 8.344650268554688e-05 	 0.00013184547424316406 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:20.103795 test begin: paddle.Tensor.tolist(Tensor([11, 25, 32, 28],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([11, 25, 32, 28],"int64"), ) 	 246400 	 1000 	 13.77197003364563 	 21.02896809577942 	 9.489059448242188e-05 	 0.00012063980102539062 	 None 	 None 	 None 	 None 	 
2025-07-30 20:47:54.938259 test begin: paddle.Tensor.tolist(Tensor([7, 25, 32, 43],"int64"), )
[Prof] paddle.Tensor.tolist 	 paddle.Tensor.tolist(Tensor([7, 25, 32, 43],"int64"), ) 	 240800 	 1000 	 13.214685916900635 	 17.24323797225952 	 8.988380432128906e-05 	 0.00014734268188476562 	 None 	 None 	 None 	 None 	 
2025-07-30 20:48:25.430465 test begin: paddle.Tensor.topk(Tensor([1, 50803201],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1, 50803201],"float32"), 5, 1, True, True, ) 	 50803201 	 1000 	 178.1174671649933 	 5.9860827922821045 	 178.10688519477844 	 0.3408994674682617 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:52:00.299184 test begin: paddle.Tensor.topk(Tensor([1024, 1034, 48],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1024, 1034, 48],"float32"), 2, axis=-1, ) 	 50823168 	 1000 	 2.6680748462677 	 11.291762828826904 	 2.6576991081237793 	 5.830003499984741 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:52:19.728654 test begin: paddle.Tensor.topk(Tensor([1024, 8, 6202],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([1024, 8, 6202],"float32"), 2, axis=-1, ) 	 50806784 	 1000 	 0.3820037841796875 	 1.5396769046783447 	 0.37180662155151367 	 0.0875711441040039 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:52:26.923577 test begin: paddle.Tensor.topk(Tensor([128, 396901],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([128, 396901],"float32"), 5, 1, True, True, ) 	 50803328 	 1000 	 1.466752529144287 	 1.484166145324707 	 1.456718921661377 	 0.08427810668945312 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:52:35.015829 test begin: paddle.Tensor.topk(Tensor([132301, 8, 48],"float32"), 2, axis=-1, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([132301, 8, 48],"float32"), 2, axis=-1, ) 	 50803584 	 1000 	 2.662444591522217 	 11.161870002746582 	 2.6521220207214355 	 5.704406499862671 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:52:54.514015 test begin: paddle.Tensor.topk(Tensor([50804, 1000],"float32"), 5, 1, True, True, )
[Prof] paddle.Tensor.topk 	 paddle.Tensor.topk(Tensor([50804, 1000],"float32"), 5, 1, True, True, ) 	 50804000 	 1000 	 0.649724006652832 	 2.4084632396698 	 0.639817476272583 	 0.1382768154144287 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 20:53:02.700981 test begin: paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1064960, 955],"bfloat16"), list[1,0,], ) 	 1017036800 	 1000 	 0.0034520626068115234 	 0.00456547737121582 	 1.0251998901367188e-05 	 2.0742416381835938e-05 	 0.04402303695678711 	 4.500927448272705 	 3.457069396972656e-05 	 2.2998831272125244 	 
2025-07-30 20:53:41.362612 test begin: paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1085440, 937],"bfloat16"), list[1,0,], ) 	 1017057280 	 1000 	 0.003459930419921875 	 0.004432201385498047 	 1.0013580322265625e-05 	 1.7881393432617188e-05 	 0.043952226638793945 	 4.502316474914551 	 3.0279159545898438e-05 	 2.301271915435791 	 
2025-07-30 20:54:18.962440 test begin: paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([1116160, 911],"bfloat16"), list[1,0,], ) 	 1016821760 	 1000 	 0.003409862518310547 	 0.0045239925384521484 	 1.33514404296875e-05 	 1.9550323486328125e-05 	 0.04383420944213867 	 4.501952886581421 	 2.4557113647460938e-05 	 2.3011059761047363 	 
2025-07-30 20:54:56.391321 test begin: paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], )
[Prof] paddle.Tensor.transpose 	 paddle.Tensor.transpose(Tensor([141760, 7168],"bfloat16"), list[1,0,], ) 	 1016135680 	 1000 	 0.003410816192626953 	 0.004457712173461914 	 9.775161743164062e-06 	 2.1696090698242188e-05 	 0.044286251068115234 	 4.498440265655518 	 3.814697265625e-05 	 2.299359083175659 	 
2025-07-30 20:55:36.030659 test begin: paddle.Tensor.tril(Tensor([1, 2, 25401601],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([1, 2, 25401601],"float32"), -1, ) 	 50803202 	 1000 	 0.29939889907836914 	 0.2747154235839844 	 0.29131650924682617 	 0.25357770919799805 	 0.299487829208374 	 0.2670295238494873 	 0.2490525245666504 	 0.20185399055480957 	 
2025-07-30 20:55:40.028600 test begin: paddle.Tensor.tril(Tensor([1, 25401601, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([1, 25401601, 2],"float32"), -1, ) 	 50803202 	 1000 	 0.4216325283050537 	 0.32190489768981934 	 0.4135723114013672 	 0.31093430519104004 	 0.4189460277557373 	 0.32132625579833984 	 0.368741512298584 	 0.2553517818450928 	 
2025-07-30 20:55:43.136841 test begin: paddle.Tensor.tril(Tensor([12700801, 2, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([12700801, 2, 2],"float32"), -1, ) 	 50803204 	 1000 	 0.42116308212280273 	 0.3244955539703369 	 0.41309356689453125 	 0.31305599212646484 	 0.42119288444519043 	 0.32379150390625 	 0.3713798522949219 	 0.2585182189941406 	 
2025-07-30 20:55:46.259199 test begin: paddle.Tensor.tril(Tensor([2, 12700801, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 12700801, 2],"float32"), -1, ) 	 50803204 	 1000 	 0.4203941822052002 	 0.3221914768218994 	 0.41246581077575684 	 0.3109571933746338 	 0.41896963119506836 	 0.32159948348999023 	 0.3404111862182617 	 0.25343751907348633 	 
2025-07-30 20:55:49.619236 test begin: paddle.Tensor.tril(Tensor([2, 2, 12700801],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 2, 12700801],"float32"), -1, ) 	 50803204 	 1000 	 0.29944372177124023 	 0.2675752639770508 	 0.2895641326904297 	 0.256500244140625 	 0.2994852066040039 	 0.26739978790283203 	 0.24967074394226074 	 0.20093131065368652 	 
2025-07-30 20:55:52.440135 test begin: paddle.Tensor.tril(Tensor([2, 25401601],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([2, 25401601],"float32"), -1, ) 	 50803202 	 1000 	 0.2993638515472412 	 0.1834876537322998 	 0.29134202003479004 	 0.1724541187286377 	 0.3007385730743408 	 0.18338966369628906 	 0.24820733070373535 	 0.11652588844299316 	 
2025-07-30 20:55:55.051878 test begin: paddle.Tensor.tril(Tensor([25401601, 2],"float32"), -1, )
[Prof] paddle.Tensor.tril 	 paddle.Tensor.tril(Tensor([25401601, 2],"float32"), -1, ) 	 50803202 	 1000 	 0.420382022857666 	 0.3163156509399414 	 0.4123256206512451 	 0.29540061950683594 	 0.4189736843109131 	 0.3063323497772217 	 0.36881542205810547 	 0.2264862060546875 	 
2025-07-30 20:55:58.171392 test begin: paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([18144010, 28],"float32"), ) 	 508032280 	 1000 	 0.008446455001831055 	 2.928316116333008 	 2.5272369384765625e-05 	 2.912635087966919 	 0.04929757118225098 	 1.3126633167266846 	 2.8848648071289062e-05 	 1.2227654457092285 	 
2025-07-30 20:56:21.664152 test begin: paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 3175201, 8],"float32"), ) 	 508032160 	 1000 	 0.008413314819335938 	 4.678654909133911 	 2.1457672119140625e-05 	 2.912961959838867 	 0.04910635948181152 	 1.3113605976104736 	 4.1961669921875e-05 	 1.243990182876587 	 
2025-07-30 20:56:50.812312 test begin: paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([20, 8, 3175201],"float32"), ) 	 508032160 	 1000 	 0.008450031280517578 	 2.926569700241089 	 1.8835067749023438e-05 	 2.9155068397521973 	 0.04914355278015137 	 1.3110945224761963 	 3.337860107421875e-05 	 1.2447154521942139 	 
2025-07-30 20:57:14.362506 test begin: paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([280, 1814401],"float32"), ) 	 508032280 	 1000 	 0.008471965789794922 	 2.925053834915161 	 2.6702880859375e-05 	 2.914003849029541 	 0.04915189743041992 	 1.3110759258270264 	 4.220008850097656e-05 	 1.244046688079834 	 
2025-07-30 20:57:40.458955 test begin: paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([63504010, 8],"float32"), ) 	 508032080 	 1000 	 0.013001203536987305 	 2.926462411880493 	 3.7670135498046875e-05 	 2.908933401107788 	 0.05810809135437012 	 1.3111310005187988 	 2.86102294921875e-05 	 1.2372379302978516 	 
2025-07-30 20:58:06.736998 test begin: paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([7938010, 8, 8],"float32"), ) 	 508032640 	 1000 	 0.015465736389160156 	 2.926670789718628 	 5.340576171875e-05 	 2.909010648727417 	 0.05843949317932129 	 1.3111639022827148 	 3.266334533691406e-05 	 1.2136178016662598 	 
2025-07-30 20:58:33.477720 test begin: paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), )
[Prof] paddle.Tensor.trunc 	 paddle.Tensor.trunc(Tensor([80, 6350401],"float32"), ) 	 508032080 	 1000 	 0.010493993759155273 	 2.930996894836426 	 3.123283386230469e-05 	 2.9130759239196777 	 0.05272555351257324 	 1.3111345767974854 	 2.765655517578125e-05 	 1.2409186363220215 	 
2025-07-30 20:59:00.562234 test begin: paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 115, 2304, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.044718265533447266 	 0.03460884094238281 	 2.288818359375e-05 	 4.601478576660156e-05 	 3.5207901000976562 	 2.9732725620269775 	 3.4174294471740723 	 2.6559596061706543 	 
2025-07-30 20:59:25.305129 test begin: paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 1351, 196, 64],"float32"), 0, ) 	 508408320 	 1000 	 0.04489445686340332 	 0.04337263107299805 	 1.6689300537109375e-05 	 3.3855438232421875e-05 	 3.5215954780578613 	 2.9702985286712646 	 3.4075326919555664 	 2.652374029159546 	 
2025-07-30 20:59:50.606763 test begin: paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 2304, 123],"float32"), 0, ) 	 510105600 	 1000 	 0.03942441940307617 	 0.03566479682922363 	 1.52587890625e-05 	 5.698204040527344e-05 	 3.5400898456573486 	 2.979363441467285 	 3.4377360343933105 	 2.662372589111328 	 
2025-07-30 21:00:15.170340 test begin: paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 60, 4411, 64],"float32"), 0, ) 	 508147200 	 1000 	 0.039402008056640625 	 0.03524947166442871 	 2.384185791015625e-05 	 4.76837158203125e-05 	 3.5198514461517334 	 2.968982696533203 	 3.414240837097168 	 2.67246675491333 	 
2025-07-30 21:00:43.078295 test begin: paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 196, 101],"float32"), 0, ) 	 513112320 	 1000 	 0.03923511505126953 	 0.03524637222290039 	 2.574920654296875e-05 	 3.24249267578125e-05 	 3.5494937896728516 	 2.9975709915161133 	 3.4436917304992676 	 2.714322328567505 	 
2025-07-30 21:01:07.148203 test begin: paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 864, 307, 64],"float32"), 0, ) 	 509276160 	 1000 	 0.039276838302612305 	 0.03508162498474121 	 1.52587890625e-05 	 3.24249267578125e-05 	 3.5295395851135254 	 2.975778341293335 	 3.4287025928497314 	 2.690661907196045 	 
2025-07-30 21:01:30.410705 test begin: paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 196, 91],"float32"), 0, ) 	 513676800 	 1000 	 0.03925323486328125 	 0.03539156913757324 	 4.029273986816406e-05 	 4.482269287109375e-05 	 3.5550806522369385 	 3.000396728515625 	 3.4529521465301514 	 2.708557605743408 	 
2025-07-30 21:01:54.535441 test begin: paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([30, 960, 276, 64],"float32"), 0, ) 	 508723200 	 1000 	 0.046973466873168945 	 0.03604435920715332 	 3.838539123535156e-05 	 5.698204040527344e-05 	 3.5247201919555664 	 2.9733152389526367 	 3.4126274585723877 	 2.6675209999084473 	 
2025-07-30 21:02:20.906314 test begin: paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 864, 196, 64],"float32"), 0, ) 	 541900800 	 1000 	 0.06191730499267578 	 0.05869007110595703 	 1.6689300537109375e-05 	 9.059906005859375e-05 	 3.7532951831817627 	 3.1532139778137207 	 3.6167359352111816 	 2.718292474746704 	 
2025-07-30 21:02:49.004011 test begin: paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([50, 960, 196, 64],"float32"), 0, ) 	 602112000 	 1000 	 0.06252336502075195 	 0.0568852424621582 	 2.8133392333984375e-05 	 4.363059997558594e-05 	 4.172539472579956 	 3.5079047679901123 	 4.037590742111206 	 3.053053140640259 	 
2025-07-30 21:03:16.875745 test begin: paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, )
[Prof] paddle.Tensor.unbind 	 paddle.Tensor.unbind(Tensor([60, 60, 2304, 64],"float32"), 0, ) 	 530841600 	 1000 	 0.07439184188842773 	 0.06719112396240234 	 3.981590270996094e-05 	 4.1484832763671875e-05 	 3.677342176437378 	 3.0869669914245605 	 3.5289509296417236 	 2.5817911624908447 	 
2025-07-30 21:03:43.667136 test begin: paddle.Tensor.unique(Tensor([25401601],"int64"), )
[Prof] paddle.Tensor.unique 	 paddle.Tensor.unique(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 6.711848497390747 	 3.268676996231079 	 6.771087646484375e-05 	 9.250640869140625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:03:54.102931 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, )
Warning: The core code of paddle.Tensor.unsqueeze is too complex.
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 0, ) 	 509009920 	 1000 	 0.0041637420654296875 	 0.0038039684295654297 	 3.147125244140625e-05 	 5.435943603515625e-05 	 0.04235124588012695 	 0.05930805206298828 	 6.389617919921875e-05 	 8.058547973632812e-05 	 
2025-07-30 21:04:10.861404 test begin: paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([1720, 544, 544],"float32"), 1, ) 	 509009920 	 1000 	 0.004101991653442383 	 0.003650188446044922 	 1.1205673217773438e-05 	 1.6927719116210938e-05 	 0.042383670806884766 	 0.05868673324584961 	 2.47955322265625e-05 	 0.0001385211944580078 	 
2025-07-30 21:04:28.479280 test begin: paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([20, 3840, 10240],"float32"), 0, ) 	 786432000 	 1000 	 0.004144906997680664 	 0.0037310123443603516 	 1.0251998901367188e-05 	 2.002716064453125e-05 	 0.04238009452819824 	 0.05720019340515137 	 2.47955322265625e-05 	 3.5762786865234375e-05 	 
2025-07-30 21:04:53.853408 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 0, ) 	 508096000 	 1000 	 0.004278898239135742 	 0.005791425704956055 	 1.2874603271484375e-05 	 2.1457672119140625e-05 	 0.04244852066040039 	 0.05862069129943848 	 1.9073486328125e-05 	 4.76837158203125e-05 	 
2025-07-30 21:05:10.373960 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 467, 544],"float32"), 1, ) 	 508096000 	 1000 	 0.004072904586791992 	 0.0037136077880859375 	 1.239776611328125e-05 	 1.9788742065429688e-05 	 0.042621612548828125 	 0.05969047546386719 	 2.5033950805664062e-05 	 5.841255187988281e-05 	 
2025-07-30 21:05:26.943786 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 0, ) 	 508096000 	 1000 	 0.004077911376953125 	 0.003714323043823242 	 6.9141387939453125e-06 	 2.47955322265625e-05 	 0.042211055755615234 	 0.05856800079345703 	 1.9073486328125e-05 	 4.315376281738281e-05 	 
2025-07-30 21:05:43.505664 test begin: paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([2000, 544, 467],"float32"), 1, ) 	 508096000 	 1000 	 0.004218578338623047 	 0.0038368701934814453 	 1.0013580322265625e-05 	 2.3603439331054688e-05 	 0.042270660400390625 	 0.05837655067443848 	 3.218650817871094e-05 	 5.030632019042969e-05 	 
2025-07-30 21:06:00.037924 test begin: paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 1654, 10240],"float32"), 0, ) 	 508108800 	 1000 	 0.004165172576904297 	 0.0037050247192382812 	 1.2159347534179688e-05 	 2.0503997802734375e-05 	 0.042700767517089844 	 0.058624267578125 	 3.933906555175781e-05 	 4.410743713378906e-05 	 
2025-07-30 21:06:20.931466 test begin: paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, )
[Prof] paddle.Tensor.unsqueeze 	 paddle.Tensor.unsqueeze(Tensor([30, 3840, 4411],"float32"), 0, ) 	 508147200 	 1000 	 0.004158496856689453 	 0.0036728382110595703 	 1.0013580322265625e-05 	 2.0265579223632812e-05 	 0.0421757698059082 	 0.05690193176269531 	 4.172325134277344e-05 	 4.1961669921875e-05 	 
2025-07-30 21:06:39.550679 test begin: paddle.Tensor.var(Tensor([1000, 50804],"float32"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([1000, 50804],"float32"), axis=0, ) 	 50804000 	 1000 	 1.267261266708374 	 0.1748204231262207 	 2.3365020751953125e-05 	 0.15823149681091309 	 1.4334101676940918 	 0.7663888931274414 	 0.21035146713256836 	 0.1956346035003662 	 
2025-07-30 21:06:44.072862 test begin: paddle.Tensor.var(Tensor([100000, 255],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([100000, 255],"float64"), axis=0, ) 	 25500000 	 1000 	 1.7424969673156738 	 0.19479632377624512 	 1.8358230590820312e-05 	 0.09955859184265137 	 1.7088043689727783 	 0.7623310089111328 	 0.2503635883331299 	 0.15576767921447754 	 
2025-07-30 21:06:49.048180 test begin: paddle.Tensor.var(Tensor([1000000, 26],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([1000000, 26],"float64"), axis=0, ) 	 26000000 	 1000 	 6.1771461963653564 	 0.18908214569091797 	 3.1948089599609375e-05 	 0.09654450416564941 	 3.9370431900024414 	 0.7863121032714844 	 0.5743629932403564 	 0.16066479682922363 	 
2025-07-30 21:07:00.833401 test begin: paddle.Tensor.var(Tensor([6350401, 4],"float64"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([6350401, 4],"float64"), axis=0, ) 	 25401604 	 1000 	 11.529610395431519 	 0.25022006034851074 	 4.7206878662109375e-05 	 0.12782049179077148 	 6.607435703277588 	 0.7641148567199707 	 0.9654028415679932 	 0.15616321563720703 	 
2025-07-30 21:07:20.584797 test begin: paddle.Tensor.var(Tensor([64801, 784],"float32"), axis=0, )
[Prof] paddle.Tensor.var 	 paddle.Tensor.var(Tensor([64801, 784],"float32"), axis=0, ) 	 50803984 	 1000 	 1.4104371070861816 	 0.2592129707336426 	 1.8596649169921875e-05 	 0.13242053985595703 	 1.4991893768310547 	 0.7994654178619385 	 0.21981024742126465 	 0.1634068489074707 	 
2025-07-30 21:07:25.378474 test begin: paddle.Tensor.zero_(Tensor([100352, 507],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([100352, 507],"float32"), ) 	 50878464 	 1000 	 0.1452627182006836 	 0.1341557502746582 	 0.13172531127929688 	 0.12191081047058105 	 None 	 None 	 None 	 None 	 
2025-07-30 21:07:27.406232 test begin: paddle.Tensor.zero_(Tensor([507, 100352],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([507, 100352],"float32"), ) 	 50878464 	 1000 	 0.14669036865234375 	 0.13412117958068848 	 0.1332850456237793 	 0.12703752517700195 	 None 	 None 	 None 	 None 	 
2025-07-30 21:07:29.394164 test begin: paddle.Tensor.zero_(Tensor([6202, 8192],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([6202, 8192],"float32"), ) 	 50806784 	 1000 	 0.14662408828735352 	 0.13398051261901855 	 0.13308191299438477 	 0.12678885459899902 	 None 	 None 	 None 	 None 	 
2025-07-30 21:07:31.398712 test begin: paddle.Tensor.zero_(Tensor([8192, 6202],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([8192, 6202],"float32"), ) 	 50806784 	 1000 	 0.1465747356414795 	 0.13399934768676758 	 0.13307404518127441 	 0.12691760063171387 	 None 	 None 	 None 	 None 	 
2025-07-30 21:07:33.418227 test begin: paddle.Tensor.zero_(Tensor([886, 57344],"float32"), )
[Prof] paddle.Tensor.zero_ 	 paddle.Tensor.zero_(Tensor([886, 57344],"float32"), ) 	 50806784 	 1000 	 0.14663910865783691 	 0.134002685546875 	 0.13305997848510742 	 0.12153935432434082 	 None 	 None 	 None 	 None 	 
2025-07-30 21:07:39.327687 test begin: paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[0,], ) 	 101606500 	 1000 	 1.0813658237457275 	 0.8417763710021973 	 0.368288516998291 	 0.43007516860961914 	 1.5900375843048096 	 1.5943105220794678 	 0.8123629093170166 	 0.815192699432373 	 
2025-07-30 21:07:47.321865 test begin: paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([406426, 5, 5, 5],"float32"), Tensor([406426, 5, 5, 5],"float32"), list[3,0,], ) 	 101606500 	 1000 	 1.1603589057922363 	 3.590299367904663 	 0.29620361328125 	 0.9137988090515137 	 0.7911005020141602 	 0.7889957427978516 	 0.2028200626373291 	 0.20148062705993652 	 
2025-07-30 21:07:55.363955 test begin: paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.121103048324585 	 4.1337244510650635 	 0.4750206470489502 	 0.42191171646118164 	 11.539642333984375 	 10.644386053085327 	 0.9080483913421631 	 0.905531644821167 	 
2025-07-30 21:08:48.486716 test begin: paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 406426, 5, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 1.4236326217651367 	 0.7358019351959229 	 0.36344003677368164 	 0.18535351753234863 	 0.7869718074798584 	 0.7819740772247314 	 0.20032262802124023 	 0.19971871376037598 	 
2025-07-30 21:08:53.975566 test begin: paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.110573768615723 	 4.131055116653442 	 0.4735891819000244 	 0.42194342613220215 	 11.574021816253662 	 10.64314603805542 	 0.9112005233764648 	 0.9054148197174072 	 
2025-07-30 21:09:50.042151 test begin: paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 406426, 5],"float32"), Tensor([5, 5, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 1.4258754253387451 	 0.7345192432403564 	 0.3636050224304199 	 0.1854546070098877 	 0.7840554714202881 	 0.782006025314331 	 0.20031237602233887 	 0.19972515106201172 	 
2025-07-30 21:09:57.074721 test begin: paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[3,0,], ) 	 101606500 	 1000 	 2.094562292098999 	 2.522671699523926 	 0.5344247817993164 	 0.6415538787841797 	 0.794607400894165 	 0.793097734451294 	 0.20299744606018066 	 0.20275592803955078 	 
2025-07-30 21:10:05.073708 test begin: paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 406426],"float32"), Tensor([5, 5, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.108102798461914 	 4.13100266456604 	 0.4736614227294922 	 0.42186880111694336 	 11.544905424118042 	 10.644201278686523 	 0.9116737842559814 	 0.9048871994018555 	 
2025-07-30 21:10:59.914736 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.5377020835876465 	 4.567435026168823 	 0.4230992794036865 	 0.4654684066772461 	 12.361696243286133 	 12.212777376174927 	 0.06680011749267578 	 0.07311892509460449 	 
2025-07-30 21:11:59.196239 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 406426, 5, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 0.862499475479126 	 1.2764430046081543 	 0.2202455997467041 	 0.325286865234375 	 0.8003189563751221 	 0.8007931709289551 	 0.20438599586486816 	 0.2048964500427246 	 
2025-07-30 21:12:05.759273 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[0,], ) 	 50803875 	 1000 	 5.295611619949341 	 4.560626745223999 	 0.4230313301086426 	 0.4653959274291992 	 12.380490064620972 	 12.225301265716553 	 0.0668947696685791 	 0.07189011573791504 	 
2025-07-30 21:13:02.497359 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[3,0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 406426, 5],"float32"), list[3,0,], ) 	 50803875 	 1000 	 0.8653674125671387 	 1.2750754356384277 	 0.22063255310058594 	 0.32550716400146484 	 0.8007533550262451 	 0.8021862506866455 	 0.20453691482543945 	 0.2043743133544922 	 
2025-07-30 21:13:07.996834 test begin: paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[0,], )
[Prof] paddle.tensordot 	 paddle.tensordot(Tensor([5, 5, 5, 5],"float32"), Tensor([5, 5, 5, 406426],"float32"), list[0,], ) 	 50803875 	 1000 	 4.5525596141815186 	 4.566255807876587 	 0.4231891632080078 	 0.46561336517333984 	 12.38267970085144 	 12.224010467529297 	 0.06687355041503906 	 0.07179474830627441 	 
2025-07-30 21:14:03.337087 test begin: paddle.tensordot(x=Tensor([4, 105841, 3, 5, 4],"float64"), y=Tensor([105841, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 105841, 3, 5, 4],"float64"), y=Tensor([105841, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205520 	 1000 	 1.6920878887176514 	 1.3639800548553467 	 0.43154406547546387 	 0.46437740325927734 	 3.354849100112915 	 3.515362024307251 	 0.24604344367980957 	 0.26949167251586914 	 
2025-07-30 21:14:17.077167 test begin: paddle.tensordot(x=Tensor([4, 2, 158761, 5, 4],"float64"), y=Tensor([2, 4, 158761, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 158761, 5, 4],"float64"), y=Tensor([2, 4, 158761, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205280 	 1000 	 1.670001745223999 	 1.355130672454834 	 0.4266035556793213 	 0.4623129367828369 	 3.333510398864746 	 3.5755362510681152 	 0.24298644065856934 	 0.2613399028778076 	 
2025-07-30 21:14:28.746237 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 132301, 4],"float64"), y=Tensor([2, 4, 3, 132301, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 132301, 4],"float64"), y=Tensor([2, 4, 3, 132301, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38102688 	 1000 	 0.8403739929199219 	 0.6922645568847656 	 0.21434950828552246 	 0.23574542999267578 	 1.6696546077728271 	 1.7611579895019531 	 0.21299242973327637 	 0.22939753532409668 	 
2025-07-30 21:14:34.657682 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 264601, 4],"float64"), y=Tensor([2, 4, 3, 264601, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 264601, 4],"float64"), y=Tensor([2, 4, 3, 264601, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 76205088 	 1000 	 1.6718015670776367 	 1.36409592628479 	 0.42709922790527344 	 0.4622373580932617 	 3.3241958618164062 	 3.4151382446289062 	 0.24265074729919434 	 0.24921941757202148 	 
2025-07-30 21:14:46.075321 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 5, 211681],"float64"), y=Tensor([2, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 5, 211681],"float64"), y=Tensor([2, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 25402680 	 1000 	 0.5322778224945068 	 0.19937944412231445 	 0.18047881126403809 	 0.10163307189941406 	 0.3524019718170166 	 0.3783915042877197 	 0.11989855766296387 	 0.12870168685913086 	 
2025-07-30 21:14:48.117769 test begin: paddle.tensordot(x=Tensor([4, 2, 3, 5, 4],"float64"), y=Tensor([2, 4, 3, 5, 211681],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 3, 5, 4],"float64"), y=Tensor([2, 4, 3, 5, 211681],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 25402200 	 1000 	 0.4901247024536133 	 0.4843103885650635 	 0.16678500175476074 	 0.24732136726379395 	 0.3850870132446289 	 0.3714323043823242 	 0.1310882568359375 	 0.12636351585388184 	 
2025-07-30 21:14:50.465809 test begin: paddle.tensordot(x=Tensor([4, 2, 79381, 5, 4],"float64"), y=Tensor([2, 4, 79381, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 2, 79381, 5, 4],"float64"), y=Tensor([2, 4, 79381, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38102880 	 1000 	 0.843407154083252 	 0.6970627307891846 	 0.21478009223937988 	 0.23571467399597168 	 1.6699626445770264 	 1.7651557922363281 	 0.2132129669189453 	 0.22940492630004883 	 
2025-07-30 21:14:56.256316 test begin: paddle.tensordot(x=Tensor([4, 52921, 3, 5, 4],"float64"), y=Tensor([52921, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], )
[Prof] paddle.tensordot 	 paddle.tensordot(x=Tensor([4, 52921, 3, 5, 4],"float64"), y=Tensor([52921, 4, 3, 5, 8],"float64"), axes=list[list[0,1,2,3,],list[1,0,],], ) 	 38103120 	 1000 	 0.8495187759399414 	 0.6996917724609375 	 0.21703052520751953 	 0.23820972442626953 	 1.6822056770324707 	 1.7914929389953613 	 0.21477174758911133 	 0.2294142246246338 	 
2025-07-30 21:15:02.162147 test begin: paddle.tile(Tensor([102426, 248, 1, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([102426, 248, 1, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50803296 	 1000 	 0.2959918975830078 	 0.31297945976257324 	 0.27643322944641113 	 0.15981698036193848 	 0.3088102340698242 	 0.06746912002563477 	 0.15839362144470215 	 5.125999450683594e-05 	 
2025-07-30 21:15:04.835004 test begin: paddle.tile(Tensor([1511, 10, 1, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([1511, 10, 1, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 50830040 	 1000 	 1.9705281257629395 	 0.9390428066253662 	 1.0069234371185303 	 0.9165375232696533 	 1.8883318901062012 	 0.7327001094818115 	 1.8321270942687988 	 0.6571500301361084 	 
2025-07-30 21:15:14.654323 test begin: paddle.tile(Tensor([16, 1, 1, 3, 16538, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 3, 16538, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50804736 	 1000 	 6.073969841003418 	 2.75146484375 	 3.103095531463623 	 1.4030845165252686 	 3.3634982109069824 	 1.734708547592163 	 3.3081865310668945 	 0.8863570690155029 	 
2025-07-30 21:15:40.313749 test begin: paddle.tile(Tensor([16, 1, 1, 3, 64, 16538],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 3, 64, 16538],"float32"), list[1,11,1,1,1,1,], ) 	 50804736 	 1000 	 6.076498508453369 	 2.7501091957092285 	 3.105686902999878 	 1.4030356407165527 	 3.3698766231536865 	 1.7360646724700928 	 3.310380220413208 	 0.8862817287445068 	 
2025-07-30 21:16:04.342690 test begin: paddle.tile(Tensor([16, 1, 1, 776, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 1, 776, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50855936 	 1000 	 6.083901643753052 	 2.7547261714935303 	 3.109412431716919 	 1.4074304103851318 	 3.369725227355957 	 1.7368972301483154 	 3.313588857650757 	 0.8881683349609375 	 
2025-07-30 21:16:30.029597 test begin: paddle.tile(Tensor([16, 1, 259, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 1, 259, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50921472 	 1000 	 6.236660718917847 	 2.764270544052124 	 3.256793260574341 	 1.412165880203247 	 3.3743090629577637 	 1.7377636432647705 	 3.3184330463409424 	 0.8879361152648926 	 
2025-07-30 21:16:54.215645 test begin: paddle.tile(Tensor([16, 10, 1, 5475, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 1, 5475, 58],"float32"), list[1,1,4,1,1,], ) 	 50808000 	 1000 	 1.9472875595092773 	 0.8661162853240967 	 0.9943735599517822 	 0.843731164932251 	 1.8884177207946777 	 0.7453179359436035 	 1.8325445652008057 	 0.662909746170044 	 
2025-07-30 21:17:04.036205 test begin: paddle.tile(Tensor([16, 10, 1, 58, 5475],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 1, 58, 5475],"float32"), list[1,1,4,1,1,], ) 	 50808000 	 1000 	 1.9441063404083252 	 0.8681116104125977 	 0.9927701950073242 	 0.8420634269714355 	 1.8867268562316895 	 0.7481749057769775 	 1.8311455249786377 	 0.672858476638794 	 
2025-07-30 21:17:13.879049 test begin: paddle.tile(Tensor([16, 10, 95, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 10, 95, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 51132800 	 1000 	 1.9550487995147705 	 0.8753602504730225 	 0.9986221790313721 	 0.852677583694458 	 1.898885726928711 	 0.7399141788482666 	 1.8434126377105713 	 0.6651999950408936 	 
2025-07-30 21:17:23.723703 test begin: paddle.tile(Tensor([16, 259, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 259, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50921472 	 1000 	 6.095984697341919 	 2.7986834049224854 	 3.114893674850464 	 1.409355640411377 	 3.3658077716827393 	 1.7422337532043457 	 3.309925079345703 	 0.8923072814941406 	 
2025-07-30 21:17:48.918823 test begin: paddle.tile(Tensor([16, 944, 1, 58, 58],"float32"), list[1,1,4,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([16, 944, 1, 58, 58],"float32"), list[1,1,4,1,1,], ) 	 50809856 	 1000 	 1.9703385829925537 	 0.9427220821380615 	 1.0068566799163818 	 0.9151597023010254 	 1.8864495754241943 	 0.7322328090667725 	 1.830678939819336 	 0.6570925712585449 	 
2025-07-30 21:17:58.693285 test begin: paddle.tile(Tensor([216, 117601, 1, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 117601, 1, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50803632 	 1000 	 0.2960081100463867 	 0.3130192756652832 	 0.28380465507507324 	 0.15987586975097656 	 0.31594204902648926 	 0.05475974082946777 	 0.16140961647033691 	 7.82012939453125e-05 	 
2025-07-30 21:18:01.391827 test begin: paddle.tile(Tensor([216, 248, 1, 1, 949],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 1, 1, 949],"float32"), list[1,1,1,1,1,], ) 	 50836032 	 1000 	 0.2976222038269043 	 0.313321590423584 	 0.28586792945861816 	 0.1600170135498047 	 0.3160669803619385 	 0.055010318756103516 	 0.1614534854888916 	 7.534027099609375e-05 	 
2025-07-30 21:18:04.027808 test begin: paddle.tile(Tensor([216, 248, 1, 475, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 1, 475, 2],"float32"), list[1,1,1,1,1,], ) 	 50889600 	 1000 	 0.2962381839752197 	 0.31928515434265137 	 0.2767753601074219 	 0.16154837608337402 	 0.31026268005371094 	 0.06194663047790527 	 0.15920400619506836 	 7.152557373046875e-05 	 
2025-07-30 21:18:06.676337 test begin: paddle.tile(Tensor([216, 248, 475, 1, 2],"float32"), list[1,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([216, 248, 475, 1, 2],"float32"), list[1,1,1,1,1,], ) 	 50889600 	 1000 	 0.29753947257995605 	 0.31369519233703613 	 0.27835631370544434 	 0.16009879112243652 	 0.30878567695617676 	 0.06245136260986328 	 0.15773391723632812 	 6.318092346191406e-05 	 
2025-07-30 21:18:09.367665 test begin: paddle.tile(Tensor([4135, 1, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )
[Prof] paddle.tile 	 paddle.tile(Tensor([4135, 1, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], ) 	 50810880 	 1000 	 5.00549578666687 	 2.461252212524414 	 2.554905414581299 	 1.258864402770996 	 3.3654301166534424 	 1.7489562034606934 	 3.3086812496185303 	 0.8929667472839355 	 
2025-07-30 21:18:32.447023 test begin: paddle.tolist(Tensor([10160, 5],"float32"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([10160, 5],"float32"), ) 	 50800 	 1000 	 9.43556523323059 	 13.838624954223633 	 9.036064147949219e-05 	 0.00010943412780761719 	 None 	 None 	 None 	 None 	 
2025-07-30 21:18:55.732727 test begin: paddle.tolist(Tensor([2, 25400],"float32"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([2, 25400],"float32"), ) 	 50800 	 1000 	 0.9284942150115967 	 1.1555733680725098 	 5.650520324707031e-05 	 0.0002052783966064453 	 None 	 None 	 None 	 None 	 
2025-07-30 21:18:57.826275 test begin: paddle.tolist(Tensor([8467, 3],"int64"), )
[Prof] paddle.tolist 	 paddle.tolist(Tensor([8467, 3],"int64"), ) 	 25401 	 1000 	 6.048202753067017 	 10.580616235733032 	 0.00011754035949707031 	 0.00010800361633300781 	 None 	 None 	 None 	 None 	 
2025-07-30 21:19:14.467291 test begin: paddle.topk(Tensor([138, 369303],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([138, 369303],"float32"), k=1, axis=0, ) 	 50963814 	 1000 	 2.403369665145874 	 8.569926023483276 	 0.6136219501495361 	 8.554518699645996 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:19:37.421234 test begin: paddle.topk(Tensor([146, 349866],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([146, 349866],"float32"), k=1, axis=0, ) 	 51080436 	 1000 	 2.3469486236572266 	 11.110779523849487 	 0.5992529392242432 	 11.095593214035034 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:20:01.432217 test begin: paddle.topk(Tensor([148, 343728],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([148, 343728],"float32"), k=1, axis=0, ) 	 50871744 	 1000 	 2.0881640911102295 	 9.287871599197388 	 0.5322182178497314 	 9.270905494689941 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:20:23.228836 test begin: paddle.topk(Tensor([49, 1036801],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([49, 1036801],"float32"), k=1, axis=0, ) 	 50803249 	 1000 	 2.2144227027893066 	 4.117289066314697 	 0.5650684833526611 	 4.101167917251587 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:20:41.227642 test begin: paddle.topk(Tensor([53, 958551],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([53, 958551],"float32"), k=1, axis=0, ) 	 50803203 	 1000 	 2.21675181388855 	 4.125094652175903 	 0.5656073093414307 	 4.109987735748291 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:21:00.235400 test begin: paddle.topk(Tensor([55, 923695],"float32"), k=1, axis=0, )
[Prof] paddle.topk 	 paddle.topk(Tensor([55, 923695],"float32"), k=1, axis=0, ) 	 50803225 	 1000 	 2.164644241333008 	 4.296000003814697 	 0.5515079498291016 	 4.2807817459106445 	 None 	 None 	 None 	 None 	 
[Error] element 1 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:21:17.652079 test begin: paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 3, 4233601],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.24260902404785156 	 0.09577012062072754 	 9.369850158691406e-05 	 0.06037616729736328 	 0.758042573928833 	 0.24021458625793457 	 4.744529724121094e-05 	 0.12264418601989746 	 combined
2025-07-30 21:21:19.639503 test begin: paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([2, 6350401, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401604 	 1000 	 0.24239683151245117 	 0.11685967445373535 	 7.843971252441406e-05 	 0.0956573486328125 	 0.7737183570861816 	 0.3342156410217285 	 4.4345855712890625e-05 	 0.17073798179626465 	 combined
2025-07-30 21:21:21.838225 test begin: paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([20, 3, 42336],"float64"), offset=1, axis1=0, axis2=2, ) 	 2540160 	 1000 	 0.06626534461975098 	 0.020843982696533203 	 3.361701965332031e-05 	 5.173683166503906e-05 	 0.1706855297088623 	 0.08679842948913574 	 3.218650817871094e-05 	 5.340576171875e-05 	 combined
2025-07-30 21:21:22.232585 test begin: paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([30, 84672],"float64"), offset=0, axis1=0, axis2=1, ) 	 2540160 	 1000 	 0.06778287887573242 	 0.020072221755981445 	 3.4332275390625e-05 	 3.743171691894531e-05 	 0.13576841354370117 	 0.08444833755493164 	 3.457069396972656e-05 	 4.9591064453125e-05 	 combined
2025-07-30 21:21:22.579190 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=0, axis1=-3, axis2=-2, ) 	 25401606 	 1000 	 0.0688164234161377 	 0.02067875862121582 	 4.315376281738281e-05 	 3.743171691894531e-05 	 0.7663414478302002 	 0.13831090927124023 	 2.86102294921875e-05 	 0.05129671096801758 	 combined
2025-07-30 21:21:24.168128 test begin: paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([4233601, 3, 2],"float64"), offset=1, axis1=0, axis2=2, ) 	 25401606 	 1000 	 0.06524085998535156 	 0.020360946655273438 	 3.933906555175781e-05 	 4.2438507080078125e-05 	 0.7658243179321289 	 0.13834595680236816 	 3.0040740966796875e-05 	 0.05075216293334961 	 combined
2025-07-30 21:21:25.784129 test begin: paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, )
[Prof] paddle.trace 	 paddle.trace(x=Tensor([6350401, 4],"float64"), offset=0, axis1=0, axis2=1, ) 	 25401604 	 1000 	 0.06738448143005371 	 0.020020008087158203 	 2.4318695068359375e-05 	 3.790855407714844e-05 	 0.6039204597473145 	 0.1381990909576416 	 3.075599670410156e-05 	 0.05233001708984375 	 combined
2025-07-30 21:21:27.155998 test begin: paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 150, 512, 512],"float32"), list[0,2,3,1,], ) 	 786432000 	 1000 	 0.007294893264770508 	 0.004740476608276367 	 1.4066696166992188e-05 	 1.9073486328125e-05 	 0.039992332458496094 	 0.06029844284057617 	 2.6226043701171875e-05 	 6.389617919921875e-05 	 
2025-07-30 21:21:55.938639 test begin: paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([20, 7168, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.0033690929412841797 	 0.004573822021484375 	 1.0251998901367188e-05 	 1.9788742065429688e-05 	 0.04522085189819336 	 4.55106258392334 	 2.4318695068359375e-05 	 2.324655532836914 	 
2025-07-30 21:22:34.054660 test begin: paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 166, 512],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.0034422874450683594 	 0.0046689510345458984 	 1.0251998901367188e-05 	 1.9073486328125e-05 	 0.0400087833404541 	 0.05776166915893555 	 3.361701965332031e-05 	 5.221366882324219e-05 	 
2025-07-30 21:22:50.886494 test begin: paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 150, 512, 166],"float32"), list[0,2,3,1,], ) 	 509952000 	 1000 	 0.007342338562011719 	 0.004666328430175781 	 1.0967254638671875e-05 	 1.8835067749023438e-05 	 0.04164266586303711 	 0.05836033821105957 	 2.6702880859375e-05 	 6.628036499023438e-05 	 
2025-07-30 21:23:12.007337 test begin: paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 3584, 7168],"bfloat16"), list[0,2,1,], ) 	 1027604480 	 1000 	 0.003385305404663086 	 0.0045816898345947266 	 1.5020370483398438e-05 	 3.170967102050781e-05 	 0.04403233528137207 	 4.553325653076172 	 3.0994415283203125e-05 	 2.325124740600586 	 
2025-07-30 21:23:50.071656 test begin: paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([40, 49, 512, 512],"float32"), list[0,2,3,1,], ) 	 513802240 	 1000 	 0.0034112930297851562 	 0.004624605178833008 	 6.9141387939453125e-06 	 2.1696090698242188e-05 	 0.04048967361450195 	 0.05783438682556152 	 2.1696090698242188e-05 	 5.555152893066406e-05 	 
2025-07-30 21:24:06.807364 test begin: paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 2363, 7168],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.003411531448364258 	 0.0045773983001708984 	 1.2159347534179688e-05 	 2.3365020751953125e-05 	 0.0463719367980957 	 4.501525640487671 	 5.435943603515625e-05 	 2.2994163036346436 	 
2025-07-30 21:24:50.385995 test begin: paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 3584, 4726],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0034122467041015625 	 0.0046346187591552734 	 1.5020370483398438e-05 	 2.1219253540039062e-05 	 0.04412078857421875 	 4.503224611282349 	 3.409385681152344e-05 	 2.2996017932891846 	 
2025-07-30 21:25:28.347345 test begin: paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], )
[Prof] paddle.transpose 	 paddle.transpose(Tensor([60, 7168, 2363],"bfloat16"), list[0,2,1,], ) 	 1016279040 	 1000 	 0.0034041404724121094 	 0.004654645919799805 	 1.1920928955078125e-05 	 4.8160552978515625e-05 	 0.0442042350769043 	 4.502870082855225 	 2.7418136596679688e-05 	 2.303744316101074 	 
2025-07-30 21:26:06.359274 test begin: paddle.tril(Tensor([1, 1, 2048, 24807],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.30784082412719727 	 0.2590479850769043 	 0.29962921142578125 	 0.24656248092651367 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:26:08.865797 test begin: paddle.tril(Tensor([1, 1, 2048, 24807],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 2048, 24807],"float32"), ) 	 50804736 	 1000 	 0.3105940818786621 	 0.33283066749572754 	 0.30245161056518555 	 0.32172179222106934 	 0.31067943572998047 	 0.33280253410339355 	 0.26069092750549316 	 0.2568538188934326 	 
2025-07-30 21:26:11.919491 test begin: paddle.tril(Tensor([1, 1, 24807, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.3736999034881592 	 0.2449033260345459 	 0.36560630798339844 	 0.22362923622131348 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:26:14.528192 test begin: paddle.tril(Tensor([1, 1, 24807, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 1, 24807, 2048],"float32"), ) 	 50804736 	 1000 	 0.4139976501464844 	 0.37783360481262207 	 0.40589070320129395 	 0.366870641708374 	 0.4136028289794922 	 0.3773620128631592 	 0.363802433013916 	 0.3094370365142822 	 
2025-07-30 21:26:17.884437 test begin: paddle.tril(Tensor([1, 13, 2048, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 13, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.3836956024169922 	 0.47240471839904785 	 0.3756906986236572 	 0.2399122714996338 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:26:21.793844 test begin: paddle.tril(Tensor([1, 13, 2048, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([1, 13, 2048, 2048],"float32"), ) 	 54525952 	 1000 	 0.4149453639984131 	 0.3948047161102295 	 0.39998722076416016 	 0.3696095943450928 	 0.4148697853088379 	 0.38359999656677246 	 0.3536226749420166 	 0.3121201992034912 	 
2025-07-30 21:26:25.349974 test begin: paddle.tril(Tensor([13, 1, 2048, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([13, 1, 2048, 2048],"bool"), ) 	 54525952 	 1000 	 0.3822822570800781 	 0.2509784698486328 	 0.3741915225982666 	 0.2401268482208252 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:26:27.896444 test begin: paddle.tril(Tensor([13, 1, 2048, 2048],"float32"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([13, 1, 2048, 2048],"float32"), ) 	 54525952 	 1000 	 0.4149460792541504 	 0.38097429275512695 	 0.4068930149078369 	 0.3696630001068115 	 0.41773509979248047 	 0.3808250427246094 	 0.367800235748291 	 0.31355977058410645 	 
2025-07-30 21:26:31.311662 test begin: paddle.tril(Tensor([2048, 24807],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([2048, 24807],"bool"), ) 	 50804736 	 1000 	 0.3078312873840332 	 0.25827860832214355 	 0.29976749420166016 	 0.24732303619384766 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:26:33.611226 test begin: paddle.tril(Tensor([24807, 2048],"bool"), )
[Prof] paddle.tril 	 paddle.tril(Tensor([24807, 2048],"bool"), ) 	 50804736 	 1000 	 0.3749518394470215 	 0.9238300323486328 	 0.3669412136077881 	 0.22490739822387695 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:26:39.504859 test begin: paddle.triu(Tensor([1, 1, 1024, 99226],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 1024, 99226],"float16"), diagonal=1, ) 	 101607424 	 1000 	 0.7710163593292236 	 0.5278880596160889 	 0.7626254558563232 	 0.5163345336914062 	 0.7679224014282227 	 0.5279653072357178 	 0.7164855003356934 	 0.46097540855407715 	 
2025-07-30 21:26:46.053987 test begin: paddle.triu(Tensor([1, 1, 12404, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 12404, 4096],"float32"), diagonal=1, ) 	 50806784 	 1000 	 0.3246884346008301 	 0.3391561508178711 	 0.31633710861206055 	 0.3276689052581787 	 0.32471704483032227 	 0.33888959884643555 	 0.2751741409301758 	 0.2729334831237793 	 
2025-07-30 21:26:49.034370 test begin: paddle.triu(Tensor([1, 1, 2048, 49613],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 2048, 49613],"float16"), ) 	 101607424 	 1000 	 0.7706069946289062 	 0.5358319282531738 	 0.7625219821929932 	 0.5134072303771973 	 0.7676362991333008 	 0.5275852680206299 	 0.7178606986999512 	 0.46098756790161133 	 
2025-07-30 21:26:55.577365 test begin: paddle.triu(Tensor([1, 1, 4096, 12404],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 4096, 12404],"float32"), diagonal=1, ) 	 50806784 	 1000 	 0.40952610969543457 	 0.3714172840118408 	 0.40109920501708984 	 0.3599545955657959 	 0.409348726272583 	 0.37215137481689453 	 0.3598921298980713 	 0.29628515243530273 	 
2025-07-30 21:26:58.844371 test begin: paddle.triu(Tensor([1, 1, 49613, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 49613, 2048],"float16"), ) 	 101607424 	 1000 	 0.5886960029602051 	 0.3662266731262207 	 0.5805294513702393 	 0.3548853397369385 	 0.5887455940246582 	 0.3671839237213135 	 0.5297367572784424 	 0.2972707748413086 	 
2025-07-30 21:27:05.017490 test begin: paddle.triu(Tensor([1, 1, 99226, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 1, 99226, 1024],"float16"), diagonal=1, ) 	 101607424 	 1000 	 0.5848596096038818 	 0.36498403549194336 	 0.5765259265899658 	 0.35352039337158203 	 0.5863549709320068 	 0.3645303249359131 	 0.5366063117980957 	 0.29722046852111816 	 
2025-07-30 21:27:10.768532 test begin: paddle.triu(Tensor([1, 25, 2048, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 25, 2048, 2048],"float16"), ) 	 104857600 	 1000 	 0.7447395324707031 	 0.4370136260986328 	 0.7364909648895264 	 0.4256129264831543 	 0.742318868637085 	 0.4380838871002197 	 0.6925535202026367 	 0.3707554340362549 	 
2025-07-30 21:27:17.091908 test begin: paddle.triu(Tensor([1, 4, 4096, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 4, 4096, 4096],"float32"), diagonal=1, ) 	 67108864 	 1000 	 0.49608397483825684 	 0.46775364875793457 	 0.487579345703125 	 0.45625758171081543 	 0.49489879608154297 	 0.4671909809112549 	 0.4450695514678955 	 0.40047121047973633 	 
2025-07-30 21:27:21.231592 test begin: paddle.triu(Tensor([1, 97, 1024, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([1, 97, 1024, 1024],"float16"), diagonal=1, ) 	 101711872 	 1000 	 0.7426624298095703 	 0.4335215091705322 	 0.7341258525848389 	 0.4145209789276123 	 0.7391951084136963 	 0.42576098442077637 	 0.6892960071563721 	 0.3585371971130371 	 
2025-07-30 21:27:29.056924 test begin: paddle.triu(Tensor([25, 1, 2048, 2048],"float16"), )
[Prof] paddle.triu 	 paddle.triu(Tensor([25, 1, 2048, 2048],"float16"), ) 	 104857600 	 1000 	 0.7433457374572754 	 0.4426579475402832 	 0.7342703342437744 	 0.42700648307800293 	 0.74381422996521 	 0.4398939609527588 	 0.6928637027740479 	 0.3629007339477539 	 
2025-07-30 21:27:37.018171 test begin: paddle.triu(Tensor([4, 1, 4096, 4096],"float32"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([4, 1, 4096, 4096],"float32"), diagonal=1, ) 	 67108864 	 1000 	 0.4946286678314209 	 0.4703507423400879 	 0.4794647693634033 	 0.4499788284301758 	 0.49491214752197266 	 0.4688408374786377 	 0.42365431785583496 	 0.3805975914001465 	 
2025-07-30 21:27:41.658019 test begin: paddle.triu(Tensor([97, 1, 1024, 1024],"float16"), diagonal=1, )
[Prof] paddle.triu 	 paddle.triu(Tensor([97, 1, 1024, 1024],"float16"), diagonal=1, ) 	 101711872 	 1000 	 0.7398874759674072 	 0.4263191223144531 	 0.7247714996337891 	 0.4081404209136963 	 0.7405924797058105 	 0.4257965087890625 	 0.6816043853759766 	 0.3562290668487549 	 
2025-07-30 21:27:48.023270 test begin: paddle.trunc(Tensor([200, 2540161],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([200, 2540161],"float32"), ) 	 508032200 	 1000 	 0.008605003356933594 	 2.92931866645813 	 2.002716064453125e-05 	 2.9178383350372314 	 0.05034589767456055 	 1.3123342990875244 	 3.2901763916015625e-05 	 1.2415845394134521 	 
2025-07-30 21:28:11.340644 test begin: paddle.trunc(Tensor([25401610, 20],"float32"), )
[Prof] paddle.trunc 	 paddle.trunc(Tensor([25401610, 20],"float32"), ) 	 508032200 	 1000 	 0.008305788040161133 	 2.9622652530670166 	 1.9788742065429688e-05 	 2.946704149246216 	 0.05040478706359863 	 1.3122532367706299 	 3.409385681152344e-05 	 1.2463452816009521 	 
2025-07-30 21:28:36.061199 test begin: paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([1176010, 6, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.01583385467529297 	 2.915945291519165 	 4.673004150390625e-05 	 2.901390552520752 	 0.0490877628326416 	 1.3133511543273926 	 5.1021575927734375e-05 	 1.2230441570281982 	 
2025-07-30 21:28:53.950913 test begin: paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([196010, 6, 6, 6, 6],"float64"), ) 	 254028960 	 1000 	 0.008656978607177734 	 2.9220447540283203 	 2.1457672119140625e-05 	 2.9015307426452637 	 0.05286860466003418 	 1.3166704177856445 	 4.553794860839844e-05 	 1.2479736804962158 	 
2025-07-30 21:29:10.186891 test begin: paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 39201, 6, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.00860285758972168 	 2.917509078979492 	 2.574920654296875e-05 	 2.9053993225097656 	 0.05885648727416992 	 1.3135035037994385 	 4.792213439941406e-05 	 1.2442877292633057 	 
2025-07-30 21:29:28.739502 test begin: paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 39201, 6, 6],"float64"), ) 	 254022480 	 1000 	 0.008584976196289062 	 3.8502345085144043 	 2.09808349609375e-05 	 2.9045612812042236 	 0.04967021942138672 	 1.3141350746154785 	 4.220008850097656e-05 	 1.2352402210235596 	 
2025-07-30 21:29:47.538866 test begin: paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 39201, 6],"float64"), ) 	 254022480 	 1000 	 0.013300657272338867 	 2.916477918624878 	 2.384185791015625e-05 	 2.9039554595947266 	 0.04990792274475098 	 1.3132357597351074 	 4.0531158447265625e-05 	 1.2437629699707031 	 
2025-07-30 21:30:03.727907 test begin: paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([30, 6, 6, 6, 39201],"float64"), ) 	 254022480 	 1000 	 0.008638858795166016 	 2.9174818992614746 	 2.4318695068359375e-05 	 2.904960870742798 	 0.05853629112243652 	 1.314922571182251 	 3.337860107421875e-05 	 1.2267389297485352 	 
2025-07-30 21:30:20.442340 test begin: paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 117601, 6, 6],"float64"), ) 	 254018160 	 1000 	 0.010468244552612305 	 2.917424201965332 	 2.3365020751953125e-05 	 2.905331611633301 	 0.0494539737701416 	 1.3115668296813965 	 4.1961669921875e-05 	 1.2431426048278809 	 
2025-07-30 21:30:39.496642 test begin: paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 117601, 6],"float64"), ) 	 254018160 	 1000 	 0.009015560150146484 	 2.916989326477051 	 3.743171691894531e-05 	 2.9008595943450928 	 0.05879783630371094 	 1.3135364055633545 	 3.552436828613281e-05 	 1.2219245433807373 	 
2025-07-30 21:30:58.959701 test begin: paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), )
[Prof] paddle.trunc 	 paddle.trunc(input=Tensor([60, 6, 6, 117601],"float64"), ) 	 254018160 	 1000 	 0.011941194534301758 	 2.9286787509918213 	 2.5033950805664062e-05 	 2.9008231163024902 	 0.049733877182006836 	 1.3156306743621826 	 4.172325134277344e-05 	 1.2468605041503906 	 
2025-07-30 21:31:16.407543 test begin: paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 1058401, 8],"float32"), axis=0, ) 	 508032480 	 1000 	 0.02824091911315918 	 0.02417588233947754 	 1.5974044799804688e-05 	 3.0040740966796875e-05 	 3.6324684619903564 	 3.0501248836517334 	 3.543656826019287 	 2.827824831008911 	 
2025-07-30 21:31:42.868265 test begin: paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 3, 8, 1058401],"float32"), axis=0, ) 	 508032480 	 1000 	 0.028008460998535156 	 0.024113178253173828 	 1.8358230590820312e-05 	 2.47955322265625e-05 	 3.6315975189208984 	 3.044355869293213 	 3.54642391204834 	 2.8278255462646484 	 
2025-07-30 21:32:06.780097 test begin: paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([20, 396901, 8, 8],"float32"), axis=0, ) 	 508033280 	 1000 	 0.0285341739654541 	 0.024033546447753906 	 4.410743713378906e-05 	 2.9802322387695312e-05 	 3.5243937969207764 	 2.989419460296631 	 3.4086720943450928 	 2.769129753112793 	 
2025-07-30 21:32:30.431526 test begin: paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 3386881, 5],"float32"), axis=0, ) 	 508032150 	 1000 	 0.0376431941986084 	 0.034448862075805664 	 1.71661376953125e-05 	 3.147125244140625e-05 	 3.6741790771484375 	 3.0677945613861084 	 3.5715506076812744 	 2.797396183013916 	 
2025-07-30 21:32:59.356000 test begin: paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([30, 9, 1881601],"float32"), axis=0, ) 	 508032270 	 1000 	 0.040579795837402344 	 0.034449100494384766 	 5.555152893066406e-05 	 6.723403930664062e-05 	 3.674210548400879 	 3.0738062858581543 	 3.5705578327178955 	 2.7660694122314453 	 
2025-07-30 21:33:26.372368 test begin: paddle.unbind(Tensor([40, 2116801, 6],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 2116801, 6],"float32"), ) 	 508032240 	 1000 	 0.05833148956298828 	 0.055678606033325195 	 0.00016427040100097656 	 6.747245788574219e-05 	 3.671100616455078 	 3.049706220626831 	 3.554001569747925 	 2.675835371017456 	 
2025-07-30 21:33:50.790465 test begin: paddle.unbind(Tensor([40, 5, 2540161],"float32"), )
[Prof] paddle.unbind 	 paddle.unbind(Tensor([40, 5, 2540161],"float32"), ) 	 508032200 	 1000 	 0.04785275459289551 	 0.04508161544799805 	 3.0040740966796875e-05 	 5.1021575927734375e-05 	 3.6776552200317383 	 3.0561230182647705 	 3.5600035190582275 	 2.722710609436035 	 
2025-07-30 21:34:14.577278 test begin: paddle.unflatten(x=Tensor([4, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([4, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 50803266 	 1000 	 0.09387969970703125 	 0.008471012115478516 	 3.218650817871094e-05 	 7.867813110351562e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:34:16.473623 test begin: paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 6, 2116801],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032242 	 1000 	 0.09586858749389648 	 0.005341291427612305 	 3.504753112792969e-05 	 1.8358230590820312e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:34:33.209358 test begin: paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([40, 793801, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032642 	 1000 	 0.09328913688659668 	 0.008359193801879883 	 2.8133392333984375e-05 	 5.435943603515625e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:34:50.271595 test begin: paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[Prof] paddle.unflatten 	 paddle.unflatten(x=Tensor([5292010, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 	 508032962 	 1000 	 0.09312772750854492 	 0.005435466766357422 	 3.1948089599609375e-05 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:35:08.650975 test begin: paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, )
[Prof] paddle.unfold 	 paddle.unfold(Tensor([50, 20321281],"float16"), 0, 5, 1, ) 	 1016064050 	 1000 	 0.016251087188720703 	 0.004442930221557617 	 1.3113021850585938e-05 	 1.811981201171875e-05 	 41.14634943008423 	 40.96427845954895 	 41.08978533744812 	 13.96776294708252 	 
2025-07-30 21:38:23.231480 test begin: paddle.unique(Tensor([25401601],"int64"), )
[Prof] paddle.unique 	 paddle.unique(Tensor([25401601],"int64"), ) 	 25401601 	 1000 	 6.710679769515991 	 3.273054838180542 	 4.8160552978515625e-05 	 8.893013000488281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:38:33.698350 test begin: paddle.unique(Tensor([25401601],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", )
[Prof] paddle.unique 	 paddle.unique(Tensor([25401601],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", ) 	 25401601 	 1000 	 10.090121507644653 	 11.155999898910522 	 9.799003601074219e-05 	 0.00021386146545410156 	 None 	 None 	 None 	 None 	 
2025-07-30 21:38:55.546722 test begin: paddle.unique_consecutive(Tensor([25401601],"float64"), )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([25401601],"float64"), ) 	 25401601 	 1000 	 1.6146838665008545 	 0.3697547912597656 	 4.5299530029296875e-05 	 6.508827209472656e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:38:58.107663 test begin: paddle.unique_consecutive(Tensor([25401601],"float64"), return_inverse=True, return_counts=True, )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([25401601],"float64"), return_inverse=True, return_counts=True, ) 	 25401601 	 1000 	 3.2662081718444824 	 1.0247561931610107 	 8.249282836914062e-05 	 7.367134094238281e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:39:02.954722 test begin: paddle.unique_consecutive(Tensor([2540],"float64"), return_inverse=True, return_counts=True, axis=-1, )
[Prof] paddle.unique_consecutive 	 paddle.unique_consecutive(Tensor([2540],"float64"), return_inverse=True, return_counts=True, axis=-1, ) 	 2540 	 1000 	 1.3662679195404053 	 0.17647004127502441 	 3.528594970703125e-05 	 5.5789947509765625e-05 	 None 	 None 	 None 	 None 	 
2025-07-30 21:39:04.592401 test begin: paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, )
Warning: The core code of paddle.unsqueeze is too complex.
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([250, 1024, 1024],"int64"), 1, ) 	 262144000 	 1000 	 0.0042264461517333984 	 0.003744363784790039 	 7.152557373046875e-06 	 1.8596649169921875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:39:13.022921 test begin: paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([39700, 50, 256],"float32"), axis=2, ) 	 508160000 	 1000 	 0.004447460174560547 	 0.0037589073181152344 	 2.288818359375e-05 	 1.9073486328125e-05 	 0.04331493377685547 	 0.059267520904541016 	 3.3855438232421875e-05 	 6.246566772460938e-05 	 
2025-07-30 21:39:33.103912 test begin: paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 1024, 6202],"int64"), 1, ) 	 254033920 	 1000 	 0.004194736480712891 	 0.006911754608154297 	 1.0013580322265625e-05 	 2.09808349609375e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:39:43.456118 test begin: paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([40, 6202, 1024],"int64"), 1, ) 	 254033920 	 1000 	 0.0041387081146240234 	 0.003840208053588867 	 1.1205673217773438e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:39:51.775956 test begin: paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 478, 256],"float32"), axis=2, ) 	 509050880 	 1000 	 0.009406328201293945 	 0.0037975311279296875 	 3.9577484130859375e-05 	 1.9311904907226562e-05 	 0.042517900466918945 	 0.06001758575439453 	 2.7179718017578125e-05 	 6.842613220214844e-05 	 
2025-07-30 21:40:11.297168 test begin: paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([4160, 50, 2443],"float32"), axis=2, ) 	 508144000 	 1000 	 0.008715391159057617 	 0.003826618194580078 	 1.4543533325195312e-05 	 1.8596649169921875e-05 	 0.04273271560668945 	 0.05726003646850586 	 3.5762786865234375e-05 	 5.125999450683594e-05 	 
2025-07-30 21:40:28.219725 test begin: paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 388, 256],"float32"), axis=2, ) 	 508559360 	 1000 	 0.0041849613189697266 	 0.0037589073181152344 	 7.62939453125e-06 	 1.8835067749023438e-05 	 0.04316210746765137 	 0.06032061576843262 	 5.888938903808594e-05 	 8.130073547363281e-05 	 
2025-07-30 21:40:44.815354 test begin: paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, )
[Prof] paddle.unsqueeze 	 paddle.unsqueeze(Tensor([5120, 50, 1985],"float32"), axis=2, ) 	 508160000 	 1000 	 0.00426030158996582 	 0.0037012100219726562 	 8.58306884765625e-06 	 1.7881393432617188e-05 	 0.04287314414978027 	 0.05868101119995117 	 4.9591064453125e-05 	 6.198883056640625e-05 	 
2025-07-30 21:41:01.738968 test begin: paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-1, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-1, ) 	 50803350 	 1000 	 0.32669997215270996 	 0.019358158111572266 	 0.30147552490234375 	 2.288818359375e-05 	 0.4798600673675537 	 4.479134559631348 	 0.39694952964782715 	 4.289803743362427 	 
2025-07-30 21:41:11.157757 test begin: paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-2, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([338689, 10, 15],"float32"), axis=-2, ) 	 50803350 	 1000 	 0.4034402370452881 	 0.013956308364868164 	 0.3821828365325928 	 2.47955322265625e-05 	 0.35173463821411133 	 1.2635047435760498 	 0.28537845611572266 	 1.1194124221801758 	 
2025-07-30 21:41:14.746625 test begin: paddle.unstack(Tensor([5, 10, 1016065],"float32"), axis=-2, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([5, 10, 1016065],"float32"), axis=-2, ) 	 50803250 	 1000 	 0.3904571533203125 	 0.024092674255371094 	 0.3699831962585449 	 3.8623809814453125e-05 	 0.3308126926422119 	 0.30754542350769043 	 0.2637946605682373 	 0.16080999374389648 	 
2025-07-30 21:41:17.341999 test begin: paddle.unstack(Tensor([5, 677377, 15],"float32"), axis=-1, )
[Prof] paddle.unstack 	 paddle.unstack(Tensor([5, 677377, 15],"float32"), axis=-1, ) 	 50803275 	 1000 	 0.32826709747314453 	 0.0193789005279541 	 0.3024148941040039 	 2.3603439331054688e-05 	 0.47655630111694336 	 4.486084699630737 	 0.39757847785949707 	 4.29732608795166 	 
2025-07-30 21:41:24.135191 test begin: paddle.unstack(x=Tensor([2, 32, 793801],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([2, 32, 793801],"float32"), axis=0, ) 	 50803264 	 1000 	 0.38973402976989746 	 0.005352497100830078 	 0.37734341621398926 	 1.8835067749023438e-05 	 0.35082292556762695 	 0.3091568946838379 	 0.29439878463745117 	 0.22583746910095215 	 
2025-07-30 21:41:26.895230 test begin: paddle.unstack(x=Tensor([2, 49613, 512],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([2, 49613, 512],"float32"), axis=0, ) 	 50803712 	 1000 	 0.3845856189727783 	 0.00543522834777832 	 0.3719804286956787 	 1.8835067749023438e-05 	 0.35021543502807617 	 0.3053884506225586 	 0.29701709747314453 	 0.2205801010131836 	 
2025-07-30 21:41:29.730091 test begin: paddle.unstack(x=Tensor([3101, 32, 512],"float32"), axis=0, )
[Prof] paddle.unstack 	 paddle.unstack(x=Tensor([3101, 32, 512],"float32"), axis=0, ) 	 50806784 	 1000 	 3.707035779953003 	 5.863779544830322 	 0.00010275840759277344 	 0.00014734268188476562 	 5.368602275848389 	 21.023701429367065 	 6.270408630371094e-05 	 0.00021529197692871094 	 
2025-07-30 21:42:10.003701 test begin: paddle.var(Tensor([264601, 192, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([264601, 192, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803392 	 1000 	 1.3052749633789062 	 0.2761106491088867 	 0.11076164245605469 	 0.25975751876831055 	 1.5756287574768066 	 0.7779772281646729 	 0.2682051658630371 	 0.19827818870544434 	 
2025-07-30 21:42:14.802435 test begin: paddle.var(Tensor([384, 132301, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 132301, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803584 	 1000 	 1.0321242809295654 	 0.18556666374206543 	 0.07514405250549316 	 0.09482359886169434 	 13.771122455596924 	 0.7721285820007324 	 2.0095489025115967 	 0.15778708457946777 	 
2025-07-30 21:42:31.469147 test begin: paddle.var(Tensor([384, 192, 1, 690],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 192, 1, 690],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50872320 	 1000 	 1.0217394828796387 	 0.18003606796264648 	 0.07439923286437988 	 0.09119582176208496 	 1.3742632865905762 	 0.7723853588104248 	 0.20074701309204102 	 0.15756845474243164 	 
2025-07-30 21:42:39.479359 test begin: paddle.var(Tensor([384, 192, 690, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 192, 690, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50872320 	 1000 	 1.021702766418457 	 0.17978835105895996 	 0.0756227970123291 	 0.09120607376098633 	 13.517385005950928 	 0.7721986770629883 	 1.9747450351715088 	 0.1577892303466797 	 
2025-07-30 21:42:55.898477 test begin: paddle.var(Tensor([384, 96, 1, 1379],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 96, 1, 1379],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50835456 	 1000 	 1.0190715789794922 	 0.1823427677154541 	 0.07429337501525879 	 0.09384298324584961 	 1.3737199306488037 	 0.7758429050445557 	 0.20062541961669922 	 0.1579446792602539 	 
2025-07-30 21:43:00.111078 test begin: paddle.var(Tensor([384, 96, 1379, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([384, 96, 1379, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50835456 	 1000 	 1.0219976902008057 	 0.18085741996765137 	 0.07442307472229004 	 0.09238958358764648 	 13.7786386013031 	 0.7729713916778564 	 2.0107855796813965 	 0.15799331665039062 	 
2025-07-30 21:43:16.759630 test begin: paddle.var(Tensor([529201, 96, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([529201, 96, 1, 1],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50803296 	 1000 	 1.2864525318145752 	 0.45236754417419434 	 0.10903668403625488 	 0.4353199005126953 	 1.5894436836242676 	 0.8232965469360352 	 0.2705061435699463 	 0.2113666534423828 	 
2025-07-30 21:43:21.807241 test begin: paddle.var(Tensor([58801, 96, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([58801, 96, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50804064 	 1000 	 0.9794368743896484 	 0.17670679092407227 	 0.08293724060058594 	 0.16009736061096191 	 1.3589823246002197 	 0.7684342861175537 	 0.23137402534484863 	 0.1962270736694336 	 
2025-07-30 21:43:25.941699 test begin: paddle.var(Tensor([96, 58801, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 58801, 3, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50804064 	 1000 	 0.9942998886108398 	 0.2160358428955078 	 0.07227706909179688 	 0.11039900779724121 	 1.3451519012451172 	 0.785858154296875 	 0.19613933563232422 	 0.16058588027954102 	 
2025-07-30 21:43:30.177524 test begin: paddle.var(Tensor([96, 96, 1838, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 96, 1838, 3],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50817024 	 1000 	 0.9887673854827881 	 0.21310901641845703 	 0.07330918312072754 	 0.10822916030883789 	 1.3450911045074463 	 0.7854187488555908 	 0.19617557525634766 	 0.1605222225189209 	 
2025-07-30 21:43:34.443001 test begin: paddle.var(Tensor([96, 96, 3, 1838],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, )
[Prof] paddle.var 	 paddle.var(Tensor([96, 96, 3, 1838],"float32"), axis=list[1,2,3,], keepdim=True, unbiased=False, ) 	 50817024 	 1000 	 0.9883303642272949 	 0.21185731887817383 	 0.0720982551574707 	 0.10825157165527344 	 1.3444797992706299 	 0.7854804992675781 	 0.1963968276977539 	 0.1604766845703125 	 
2025-07-30 21:43:39.923357 test begin: paddle.vecdot(Tensor([12700801, 4],"float32"), Tensor([12700801, 4],"float32"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([12700801, 4],"float32"), Tensor([12700801, 4],"float32"), axis=-1, ) 	 101606408 	 1000 	 1.149055004119873 	 0.9474568367004395 	 0.3915243148803711 	 0.4771702289581299 	 1.5896215438842773 	 0.6860501766204834 	 0.5417144298553467 	 0.34917616844177246 	 combined
2025-07-30 21:43:46.265542 test begin: paddle.vecdot(Tensor([1270081, 4, 5],"float64"), Tensor([1270081, 4, 5],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([1270081, 4, 5],"float64"), Tensor([1270081, 4, 5],"float64"), axis=1, ) 	 50803240 	 1000 	 1.0294697284698486 	 0.63372802734375 	 0.35071516036987305 	 0.3231163024902344 	 1.2440989017486572 	 0.6755044460296631 	 0.4248807430267334 	 0.3451714515686035 	 combined
2025-07-30 21:43:51.055004 test begin: paddle.vecdot(Tensor([2, 3, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2, 3, 4233601],"float64"), Tensor([2, 3, 4233601],"float64"), axis=-1, ) 	 50803212 	 1000 	 0.9822192192077637 	 0.5961146354675293 	 0.25054931640625 	 0.20283174514770508 	 1.179347038269043 	 0.6020805835723877 	 0.402022123336792 	 0.3069272041320801 	 combined
2025-07-30 21:43:57.279007 test begin: paddle.vecdot(Tensor([2, 3175201, 4],"float64"), Tensor([2, 3175201, 4],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2, 3175201, 4],"float64"), Tensor([2, 3175201, 4],"float64"), axis=-1, ) 	 50803216 	 1000 	 0.9972610473632812 	 0.714277982711792 	 0.3397808074951172 	 0.3644216060638428 	 1.2441375255584717 	 0.6745395660400391 	 0.42499732971191406 	 0.3445916175842285 	 combined
2025-07-30 21:44:02.213291 test begin: paddle.vecdot(Tensor([2116801, 3, 4],"float64"), Tensor([2116801, 3, 4],"float64"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([2116801, 3, 4],"float64"), Tensor([2116801, 3, 4],"float64"), axis=-1, ) 	 50803224 	 1000 	 0.9971013069152832 	 0.7144968509674072 	 0.3397672176361084 	 0.3658120632171631 	 1.244070053100586 	 0.6732666492462158 	 0.42354369163513184 	 0.34326791763305664 	 combined
2025-07-30 21:44:07.000768 test begin: paddle.vecdot(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), axis=-1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 16934401],"float32"), Tensor([3, 16934401],"float32"), axis=-1, ) 	 101606406 	 1000 	 0.9641098976135254 	 0.6010961532592773 	 0.24569296836853027 	 0.20366716384887695 	 1.5239365100860596 	 0.6068394184112549 	 0.5204195976257324 	 0.31001925468444824 	 combined
2025-07-30 21:44:12.366715 test begin: paddle.vecdot(Tensor([3, 1693441, 5],"float64"), Tensor([3, 1693441, 5],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 1693441, 5],"float64"), Tensor([3, 1693441, 5],"float64"), axis=1, ) 	 50803230 	 1000 	 7.029834747314453 	 0.5995428562164307 	 1.7981736660003662 	 0.20395302772521973 	 1.1824042797088623 	 0.6012263298034668 	 0.40205955505371094 	 0.30715417861938477 	 combined
2025-07-30 21:44:22.905205 test begin: paddle.vecdot(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), axis=1, )
[Prof] paddle.vecdot 	 paddle.vecdot(Tensor([3, 4, 2116801],"float64"), Tensor([3, 4, 2116801],"float64"), axis=1, ) 	 50803224 	 1000 	 0.9323174953460693 	 0.6306338310241699 	 0.3184802532196045 	 0.32225608825683594 	 1.3408734798431396 	 0.8997950553894043 	 0.4559211730957031 	 0.4602193832397461 	 combined
2025-07-30 21:44:27.960062 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.01879429817199707 	 0.0039882659912109375 	 1.5020370483398438e-05 	 1.6927719116210938e-05 	 0.042181968688964844 	 0.05608654022216797 	 2.4557113647460938e-05 	 5.698204040527344e-05 	 
2025-07-30 21:44:47.329819 test begin: paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 10, 50804],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013433456420898438 	 0.0040171146392822266 	 1.1920928955078125e-05 	 1.7642974853515625e-05 	 0.042723655700683594 	 0.05642342567443848 	 5.2928924560546875e-05 	 3.4809112548828125e-05 	 
2025-07-30 21:45:05.329644 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.01851511001586914 	 0.003911018371582031 	 1.621246337890625e-05 	 1.71661376953125e-05 	 0.05001068115234375 	 0.0587005615234375 	 3.0040740966796875e-05 	 0.0001785755157470703 	 
2025-07-30 21:45:23.040321 test begin: paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 10, 25402, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013736724853515625 	 0.007570981979370117 	 1.0967254638671875e-05 	 2.002716064453125e-05 	 0.04963827133178711 	 0.06638026237487793 	 4.4345855712890625e-05 	 6.628036499023438e-05 	 
2025-07-30 21:45:41.101442 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013320684432983398 	 0.003943443298339844 	 1.4066696166992188e-05 	 1.6450881958007812e-05 	 0.04239082336425781 	 0.055730342864990234 	 2.7179718017578125e-05 	 5.5789947509765625e-05 	 
2025-07-30 21:45:57.695774 test begin: paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([100, 25402, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013564348220825195 	 0.003990650177001953 	 9.298324584960938e-06 	 1.7404556274414062e-05 	 0.042845726013183594 	 0.07504701614379883 	 4.553794860839844e-05 	 6.0558319091796875e-05 	 
2025-07-30 21:46:14.582904 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[-1,], ) 	 508040000 	 1000 	 0.013555049896240234 	 0.004564762115478516 	 1.0728836059570312e-05 	 5.316734313964844e-05 	 0.042292118072509766 	 0.05599784851074219 	 2.9325485229492188e-05 	 5.984306335449219e-05 	 
2025-07-30 21:46:31.383556 test begin: paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], )
[Prof] paddle.view 	 paddle.view(Tensor([254020, 10, 10, 20],"float32"), list[10,100,-1,], ) 	 508040000 	 1000 	 0.013718843460083008 	 0.0039823055267333984 	 9.5367431640625e-06 	 1.71661376953125e-05 	 0.042160749435424805 	 0.05724215507507324 	 3.409385681152344e-05 	 4.124641418457031e-05 	 
2025-07-30 21:46:48.173205 test begin: paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), )
[Prof] paddle.view_as 	 paddle.view_as(Tensor([10, 10, 10, 50804],"float32"), Tensor([10, 100, 50804],"float32"), ) 	 101608000 	 1000 	 0.022958040237426758 	 0.003389596939086914 	 1.3828277587890625e-05 	 1.5735626220703125e-05 	 None 	 None 	 None 	 None 	 combined
[Error] One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
2025-07-30 21:46:50.823679 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], )
W0730 21:47:01.461285 58410 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,1,3,], ) 	 254016120 	 1000 	 0.031308650970458984 	 0.009526729583740234 	 1.9550323486328125e-05 	 2.3126602172851562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:47:03.203779 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], )
W0730 21:47:10.243598 59583 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[-1,], ) 	 254016120 	 1000 	 0.016762495040893555 	 0.006967782974243164 	 1.0967254638671875e-05 	 1.811981201171875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:47:12.507632 test begin: paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], )
W0730 21:47:19.487886 60256 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([21168010, 4, 3],"int64"), list[2,4,], ) 	 254016120 	 1000 	 0.024007320404052734 	 0.010120391845703125 	 1.52587890625e-05 	 7.176399230957031e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:47:20.754888 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], )
W0730 21:47:31.098099 60671 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,1,3,], ) 	 254016180 	 1000 	 0.0308682918548584 	 0.009492874145507812 	 1.2636184692382812e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:47:32.756246 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], )
W0730 21:47:40.186880 61431 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[-1,], ) 	 254016180 	 1000 	 0.017457008361816406 	 0.011831045150756836 	 3.552436828613281e-05 	 2.3603439331054688e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:47:41.868456 test begin: paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], )
W0730 21:47:48.829764 61909 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 1411201, 3],"int64"), list[2,4,], ) 	 254016180 	 1000 	 0.023993968963623047 	 0.008326292037963867 	 1.9550323486328125e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:47:50.062196 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], )
W0730 21:48:00.461594 62501 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,1,3,], ) 	 254016240 	 1000 	 0.031230449676513672 	 0.009579181671142578 	 2.9087066650390625e-05 	 2.2411346435546875e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:48:02.095716 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], )
W0730 21:48:09.222965 63148 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[-1,], ) 	 254016240 	 1000 	 0.016931772232055664 	 0.007103681564331055 	 1.0251998901367188e-05 	 1.9311904907226562e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:48:10.353472 test begin: paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], )
W0730 21:48:17.544088 63765 backward.cc:462] While running Node (SliceGradNode) raises an EnforceNotMet exception
[Error] (Unimplemented) Gradient accumulation of data type (int64_t) on place (Place(gpu:0)) is not supported in imperative mode (at ../paddle/fluid/imperative/gradient_accumulator.cc:242)

[Prof] paddle.vsplit 	 paddle.vsplit(Tensor([60, 4, 1058401],"int64"), list[2,4,], ) 	 254016240 	 1000 	 0.023863554000854492 	 0.008150100708007812 	 1.049041748046875e-05 	 2.2649765014648438e-05 	 None 	 None 	 None 	 None 	 
[Error] element 0 of tensors does not require grad and does not have a grad_fn
2025-07-30 21:48:20.867068 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], ) 	 76204872 	 1000 	 0.9410932064056396 	 0.923804521560669 	 0.16029024124145508 	 0.9088630676269531 	 0.9542133808135986 	 0.08744072914123535 	 0.16342616081237793 	 7.963180541992188e-05 	 
2025-07-30 21:48:27.023763 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),Tensor([3, 4, 2, 1058401],"float64"),], name=None, ) 	 76204872 	 1000 	 0.9410183429718018 	 0.9238958358764648 	 0.1602950096130371 	 0.8998394012451172 	 0.9526081085205078 	 0.08707261085510254 	 0.16204071044921875 	 5.340576171875e-05 	 
2025-07-30 21:48:33.190084 test begin: paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 1058401],"float64"),], ) 	 25401624 	 1000 	 0.3148832321166992 	 0.3197610378265381 	 0.16089081764221191 	 0.1598355770111084 	 0.3172926902770996 	 0.05952000617980957 	 0.16133475303649902 	 6.794929504394531e-05 	 
2025-07-30 21:48:37.375952 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.31310510635375977 	 0.32950496673583984 	 0.08013463020324707 	 0.30820679664611816 	 0.32195138931274414 	 0.08062744140625 	 0.08237433433532715 	 8.106231689453125e-05 	 
2025-07-30 21:48:40.169347 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.31311941146850586 	 0.3233184814453125 	 0.0801384449005127 	 0.3088264465332031 	 0.32467198371887207 	 0.0782008171081543 	 0.0836648941040039 	 8.487701416015625e-05 	 
2025-07-30 21:48:42.270148 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3152589797973633 	 0.32232046127319336 	 0.08039116859436035 	 0.30599331855773926 	 0.3248176574707031 	 0.07828044891357422 	 0.08280825614929199 	 6.842613220214844e-05 	 
2025-07-30 21:48:44.397866 test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.3153080940246582 	 0.3229515552520752 	 0.08040714263916016 	 0.3071441650390625 	 0.3260939121246338 	 0.07700181007385254 	 0.08279538154602051 	 5.1975250244140625e-05 	 
2025-07-30 21:48:46.599170 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], ) 	 76204980 	 1000 	 0.9382772445678711 	 0.9184732437133789 	 0.1598513126373291 	 0.9035787582397461 	 0.9387590885162354 	 0.07953763008117676 	 0.16086626052856445 	 5.555152893066406e-05 	 
2025-07-30 21:48:52.823638 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),Tensor([3, 4, 423361, 5],"float64"),], name=None, ) 	 76204980 	 1000 	 0.9397118091583252 	 0.9202165603637695 	 0.15983319282531738 	 0.9051883220672607 	 0.93595290184021 	 0.07720398902893066 	 0.1593918800354004 	 5.507469177246094e-05 	 
2025-07-30 21:48:58.915964 test begin: paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 4, 423361, 5],"float64"),], ) 	 25401660 	 1000 	 0.30822110176086426 	 0.32947206497192383 	 0.15674209594726562 	 0.15987157821655273 	 0.3074953556060791 	 0.059748172760009766 	 0.1570734977722168 	 0.00014257431030273438 	 
2025-07-30 21:49:01.017959 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], ) 	 76204890 	 1000 	 0.9437224864959717 	 0.9344124794006348 	 0.1605079174041748 	 0.913644552230835 	 0.9493772983551025 	 0.07772326469421387 	 0.16149377822875977 	 6.246566772460938e-05 	 
2025-07-30 21:49:07.132326 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),Tensor([3, 846721, 2, 5],"float64"),], name=None, ) 	 76204890 	 1000 	 0.9435222148895264 	 0.9334328174591064 	 0.1604905128479004 	 0.9151160717010498 	 0.9481019973754883 	 0.08771014213562012 	 0.16148710250854492 	 7.796287536621094e-05 	 
2025-07-30 21:49:13.336302 test begin: paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([3, 846721, 2, 5],"float64"),], ) 	 25401630 	 1000 	 0.3149235248565674 	 0.315854549407959 	 0.16092252731323242 	 0.15984749794006348 	 0.3159208297729492 	 0.06593561172485352 	 0.1613752841949463 	 5.698204040527344e-05 	 
2025-07-30 21:49:15.555982 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 	 25401880 	 1000 	 0.3127002716064453 	 0.31122756004333496 	 0.07972908020019531 	 0.2965826988220215 	 0.32076430320739746 	 0.09604883193969727 	 0.08139538764953613 	 9.393692016601562e-05 	 
2025-07-30 21:49:17.724490 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 	 25401880 	 1000 	 0.3127291202545166 	 0.31102776527404785 	 0.07974028587341309 	 0.28973841667175293 	 0.3206653594970703 	 0.08749580383300781 	 0.0814201831817627 	 9.560585021972656e-05 	 
2025-07-30 21:49:19.824992 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], ) 	 76204920 	 1000 	 0.9375123977661133 	 0.9316577911376953 	 0.15966439247131348 	 0.9099266529083252 	 0.9421308040618896 	 0.07661056518554688 	 0.16045236587524414 	 5.888938903808594e-05 	 
2025-07-30 21:49:26.247230 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),Tensor([635041, 4, 2, 5],"float64"),], name=None, ) 	 76204920 	 1000 	 0.937497615814209 	 0.9222700595855713 	 0.15967464447021484 	 0.9073059558868408 	 0.9462339878082275 	 0.07683634757995605 	 0.16046452522277832 	 6.461143493652344e-05 	 
2025-07-30 21:49:32.365457 test begin: paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),], )
[Prof] paddle.vstack 	 paddle.vstack(list[Tensor([635041, 4, 2, 5],"float64"),], ) 	 25401640 	 1000 	 0.30684542655944824 	 0.317948579788208 	 0.15679931640625 	 0.15985941886901855 	 0.30750179290771484 	 0.06041693687438965 	 0.15707707405090332 	 8.511543273925781e-05 	 
2025-07-30 21:49:34.495305 test begin: paddle.where(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"float32"), Tensor([1, 400, 127009],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 127009],"bool"), Tensor([1, 400, 127009],"float32"), Tensor([1, 400, 127009],"float32"), ) 	 152410800 	 1000 	 0.48516368865966797 	 0.4913628101348877 	 0.4663381576538086 	 0.47164106369018555 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:49:40.468756 test begin: paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), ) 	 105369600 	 1000 	 0.9361166954040527 	 0.5166232585906982 	 0.31858181953430176 	 0.49593281745910645 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:49:45.275535 test begin: paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), ) 	 105369600 	 1000 	 0.9347612857818604 	 0.515887975692749 	 0.31859755516052246 	 0.5006158351898193 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:49:50.112590 test begin: paddle.where(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"float32"), Tensor([1, 772, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([1, 772, 65856],"bool"), Tensor([1, 772, 65856],"float32"), Tensor([1, 772, 65856],"float32"), ) 	 152522496 	 1000 	 0.4851255416870117 	 0.4869215488433838 	 0.46632981300354004 	 0.4617617130279541 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:49:54.804299 test begin: paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([1, 400, 65856],"float32"), Tensor([1, 400, 65856],"float32"), ) 	 105369600 	 1000 	 1.1158959865570068 	 0.517655611038208 	 0.38021063804626465 	 0.5023877620697021 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:00.115735 test begin: paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([2, 400, 65856],"bool"), Tensor([2, 400, 65856],"float32"), Tensor([2, 400, 65856],"float32"), ) 	 158054400 	 1000 	 0.5036337375640869 	 0.5090475082397461 	 0.4848473072052002 	 0.4883575439453125 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:04.963647 test begin: paddle.where(Tensor([4, 125, 320, 320],"bool"), Tensor([4, 125, 320, 320],"float32"), Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 125, 320, 320],"bool"), Tensor([4, 125, 320, 320],"float32"), Tensor([4, 125, 320, 320],"float32"), ) 	 153600000 	 1000 	 0.4893455505371094 	 0.48946499824523926 	 0.47000932693481445 	 0.47347497940063477 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:09.838006 test begin: paddle.where(Tensor([4, 280, 376, 25, 5],"bool"), Tensor([4, 280, 376, 25, 5],"float32"), Tensor([4, 280, 376, 25, 5],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 376, 25, 5],"bool"), Tensor([4, 280, 376, 25, 5],"float32"), Tensor([4, 280, 376, 25, 5],"float32"), ) 	 157920000 	 1000 	 0.5018987655639648 	 0.5042521953582764 	 0.4828639030456543 	 0.485245943069458 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:14.940488 test begin: paddle.where(Tensor([4, 280, 376, 41, 3],"bool"), Tensor([4, 280, 376, 41, 3],"float32"), Tensor([4, 280, 376, 41, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 376, 41, 3],"bool"), Tensor([4, 280, 376, 41, 3],"float32"), Tensor([4, 280, 376, 41, 3],"float32"), ) 	 155393280 	 1000 	 0.4939582347869873 	 0.5163824558258057 	 0.4749326705932617 	 0.4799814224243164 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:19.892215 test begin: paddle.where(Tensor([4, 280, 605, 25, 3],"bool"), Tensor([4, 280, 605, 25, 3],"float32"), Tensor([4, 280, 605, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 280, 605, 25, 3],"bool"), Tensor([4, 280, 605, 25, 3],"float32"), Tensor([4, 280, 605, 25, 3],"float32"), ) 	 152460000 	 1000 	 0.4852294921875 	 0.501899003982544 	 0.4533548355102539 	 0.47178030014038086 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:24.649519 test begin: paddle.where(Tensor([4, 451, 376, 25, 3],"bool"), Tensor([4, 451, 376, 25, 3],"float32"), Tensor([4, 451, 376, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 451, 376, 25, 3],"bool"), Tensor([4, 451, 376, 25, 3],"float32"), Tensor([4, 451, 376, 25, 3],"float32"), ) 	 152618400 	 1000 	 0.48513126373291016 	 0.4858121871948242 	 0.4659750461578369 	 0.4681234359741211 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:29.570875 test begin: paddle.where(Tensor([4, 64, 320, 621],"bool"), Tensor([4, 64, 320, 621],"float32"), Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 64, 320, 621],"bool"), Tensor([4, 64, 320, 621],"float32"), Tensor([4, 64, 320, 621],"float32"), ) 	 152616960 	 1000 	 0.4861149787902832 	 0.4854247570037842 	 0.46707820892333984 	 0.46869564056396484 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:34.461811 test begin: paddle.where(Tensor([4, 64, 621, 320],"bool"), Tensor([4, 64, 621, 320],"float32"), Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([4, 64, 621, 320],"bool"), Tensor([4, 64, 621, 320],"float32"), Tensor([4, 64, 621, 320],"float32"), ) 	 152616960 	 1000 	 0.4855685234069824 	 0.48528075218200684 	 0.46666812896728516 	 0.46746158599853516 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:40.116573 test begin: paddle.where(Tensor([7, 280, 376, 25, 3],"bool"), Tensor([7, 280, 376, 25, 3],"float32"), Tensor([7, 280, 376, 25, 3],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([7, 280, 376, 25, 3],"bool"), Tensor([7, 280, 376, 25, 3],"float32"), Tensor([7, 280, 376, 25, 3],"float32"), ) 	 165816000 	 1000 	 0.527137041091919 	 0.5270326137542725 	 0.508007287979126 	 0.5104284286499023 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:45.294815 test begin: paddle.where(Tensor([8, 64, 320, 320],"bool"), Tensor([8, 64, 320, 320],"float32"), Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.where 	 paddle.where(Tensor([8, 64, 320, 320],"bool"), Tensor([8, 64, 320, 320],"float32"), Tensor([8, 64, 320, 320],"float32"), ) 	 157286400 	 1000 	 0.5000700950622559 	 0.5029745101928711 	 0.48091912269592285 	 0.48494601249694824 	 None 	 None 	 None 	 None 	 
[Error] One of the differentiated Tensors does not require grad
2025-07-30 21:50:50.288804 test begin: paddle.zeros_like(Tensor([16, 64, 320, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([16, 64, 320, 320],"float16"), ) 	 104857600 	 1000 	 0.13791179656982422 	 0.13807940483093262 	 0.12727093696594238 	 0.1264796257019043 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:52.491497 test begin: paddle.zeros_like(Tensor([4, 1051, 12096],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 1051, 12096],"float32"), ) 	 50851584 	 1000 	 0.13397836685180664 	 0.1343247890472412 	 0.11976885795593262 	 0.12268877029418945 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:53.615157 test begin: paddle.zeros_like(Tensor([4, 125, 320, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 125, 320, 320],"float32"), ) 	 51200000 	 1000 	 0.13520002365112305 	 0.15781426429748535 	 0.12450337409973145 	 0.12500858306884766 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:54.940470 test begin: paddle.zeros_like(Tensor([4, 249, 320, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 249, 320, 320],"float16"), ) 	 101990400 	 1000 	 0.13428807258605957 	 0.13451218605041504 	 0.12358474731445312 	 0.1226205825805664 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:57.096620 test begin: paddle.zeros_like(Tensor([4, 525, 24193],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 525, 24193],"float32"), ) 	 50805300 	 1000 	 0.13396120071411133 	 0.13428711891174316 	 0.12308311462402344 	 0.11823463439941406 	 None 	 None 	 None 	 None 	 
2025-07-30 21:50:58.180199 test begin: paddle.zeros_like(Tensor([4, 64, 1241, 320],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 1241, 320],"float16"), ) 	 101662720 	 1000 	 0.13384008407592773 	 0.15651893615722656 	 0.12306427955627441 	 0.12247824668884277 	 None 	 None 	 None 	 None 	 
2025-07-30 21:51:00.481513 test begin: paddle.zeros_like(Tensor([4, 64, 320, 1241],"float16"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 320, 1241],"float16"), ) 	 101662720 	 1000 	 0.13382768630981445 	 0.1340796947479248 	 0.1230473518371582 	 0.12248063087463379 	 None 	 None 	 None 	 None 	 
2025-07-30 21:51:02.648861 test begin: paddle.zeros_like(Tensor([4, 64, 320, 621],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 320, 621],"float32"), ) 	 50872320 	 1000 	 0.13400888442993164 	 0.13437485694885254 	 0.12305283546447754 	 0.12224364280700684 	 None 	 None 	 None 	 None 	 
2025-07-30 21:51:03.760015 test begin: paddle.zeros_like(Tensor([4, 64, 621, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([4, 64, 621, 320],"float32"), ) 	 50872320 	 1000 	 0.13403868675231934 	 0.1345057487487793 	 0.12324094772338867 	 0.12254667282104492 	 None 	 None 	 None 	 None 	 
2025-07-30 21:51:05.036443 test begin: paddle.zeros_like(Tensor([8, 64, 320, 320],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([8, 64, 320, 320],"float32"), ) 	 52428800 	 1000 	 0.13802623748779297 	 0.5950407981872559 	 0.12220025062561035 	 0.12557244300842285 	 None 	 None 	 None 	 None 	 
2025-07-30 21:51:07.623826 test begin: paddle.zeros_like(Tensor([9, 525, 12096],"float32"), )
[Prof] paddle.zeros_like 	 paddle.zeros_like(Tensor([9, 525, 12096],"float32"), ) 	 57153600 	 1000 	 0.15027832984924316 	 0.17133092880249023 	 0.1395730972290039 	 0.1319575309753418 	 None 	 None 	 None 	 None 	 
