torch.Tensor.__and__(Tensor([1], "int64"), Tensor([1], "bool"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch.Tensor.__eq__(Tensor([1, 12], "int64"), 0)
torch.Tensor.__eq__(Tensor([], "int64"), 0)
torch.Tensor.__getitem__("<Unserializable: Parameter>", 0)
torch.Tensor.__getitem__(Tensor([1, 1, 103424], "float32"), tuple(slice(None, None, None), -1, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 1, 12, 128], "float32"), tuple(ellipsis(...), slice(None, 64, None)))
torch.Tensor.__getitem__(Tensor([1, 12, 1024], "float32"), tuple(slice(None, None, None), slice(-1, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 12], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 12], "int64"), tuple(slice(None, None, None), slice(-12, None, None)))
torch.Tensor.__getitem__(Tensor([1, 13], "int64"), 0)
torch.Tensor.__getitem__(Tensor([1, 13], "int64"), tuple(slice(None, None, None), -1))
torch.Tensor.__getitem__(Tensor([1, 16, 12, 128], "float32"), tuple(ellipsis(...), slice(0, None, 2)))
torch.Tensor.__getitem__(Tensor([1, 16, 12, 128], "float32"), tuple(ellipsis(...), slice(1, None, 2)))
torch.Tensor.__getitem__(Tensor([1, 2, 12, 128], "float32"), tuple(ellipsis(...), slice(0, None, 2)))
torch.Tensor.__getitem__(Tensor([1, 2, 12, 128], "float32"), tuple(ellipsis(...), slice(1, None, 2)))
torch.Tensor.__getitem__(Tensor([1, 50], "float32"), tuple(ellipsis(...), -1, None))
torch.Tensor.__getitem__(Tensor([1024, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([1024, 3072], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([1024], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([103424, 1024], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([12], "int64"), -1)
torch.Tensor.__getitem__(Tensor([12], "int64"), slice(-1, None, None))
torch.Tensor.__getitem__(Tensor([12], "int64"), slice(0, None, None))
torch.Tensor.__getitem__(Tensor([1], "int64"), tuple(slice(None, None, None), None))
torch.Tensor.__getitem__(Tensor([2048, 1024], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([256, 1024], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([3072, 1024], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([64], "float32"), tuple(None, slice(None, None, None), None))
torch.Tensor.__invert__(Tensor([1], "bool"))
torch.Tensor.__invert__(Tensor([], "bool"))
torch.Tensor.__len__(Tensor([1, 12], "int64"))
torch.Tensor.__or__(Tensor([1], "bool"), Tensor([1], "bool"))
torch.Tensor.__rpow__(Tensor([64], "float32"), 500000.0)
torch.Tensor.__rsub__(Tensor([1], "int64"), 1)
torch.Tensor.__rtruediv__(Tensor([64], "float32"), 1.0)
torch.Tensor.__setitem__(Tensor([1, 103424], "bool"), tuple(ellipsis(...), slice(-1, None, None)), 0)
torch.Tensor.add(Tensor([1, 12, 1024], "float32"), Tensor([1, 12, 1024], "float32"))
torch.Tensor.add(Tensor([1, 12, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([1, 12], "int64"), Tensor([1, 12], "int64"))
torch.Tensor.add(Tensor([1, 16, 12, 128], "float32"), Tensor([1, 16, 12, 128], "float32"))
torch.Tensor.add(Tensor([1, 2, 12, 128], "float32"), Tensor([1, 2, 12, 128], "float32"))
torch.Tensor.add(Tensor([1], "int64"), 1)
torch.Tensor.add(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.all(Tensor([1, 12], "bool"))
torch.Tensor.any(Tensor([1, 12], "bool"))
torch.Tensor.any(Tensor([1], "bool"))
torch.Tensor.clone(Tensor([1, 12], "int64"), memory_format="torch.contiguous_format")
torch.Tensor.contiguous(Tensor([1, 12, 16, 128], "float32"))
torch.Tensor.contiguous(Tensor([1, 12, 2048], "float32"))
torch.Tensor.contiguous(Tensor([1, 16, 12, 128], "float32"))
torch.Tensor.contiguous(Tensor([1, 2, 12, 128], "float32"))
torch.Tensor.contiguous(Tensor([1024, 2048], "float32"))
torch.Tensor.contiguous(Tensor([1024, 3072], "float32"))
torch.Tensor.contiguous(Tensor([1024], "float32"))
torch.Tensor.contiguous(Tensor([103424, 1024], "float32"))
torch.Tensor.contiguous(Tensor([2048, 1024], "float32"))
torch.Tensor.contiguous(Tensor([256, 1024], "float32"))
torch.Tensor.contiguous(Tensor([3072, 1024], "float32"))
torch.Tensor.cos(Tensor([1, 12, 128], "float32"))
torch.Tensor.cumsum(Tensor([1, 103424], "float32"), dim=-1)
torch.Tensor.cumsum(Tensor([1, 12], "int64"), -1)
torch.Tensor.cumsum(Tensor([12], "int64"), 0)
torch.Tensor.data.__set__("<Unserializable: Parameter>", "<Unserializable: Parameter>")
torch.Tensor.detach("<Unserializable: Parameter>")
torch.Tensor.device.__get__("<Unserializable: Parameter>")
torch.Tensor.device.__get__(Tensor([1, 12, 1024], "float32"))
torch.Tensor.device.__get__(Tensor([1, 12], "int64"))
torch.Tensor.device.__get__(Tensor([1, 13], "int64"))
torch.Tensor.device.__get__(Tensor([12], "int64"))
torch.Tensor.device.__get__(Tensor([1], "int64"))
torch.Tensor.div(Tensor([1, 103424], "float32"), 0.7)
torch.Tensor.div(Tensor([64], "float32"), 128)
torch.Tensor.dtype.__get__("<Unserializable: Parameter>")
torch.Tensor.dtype.__get__(Tensor([1, 12, 1024], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 12], "int64"))
torch.Tensor.dtype.__get__(Tensor([1, 16, 12, 128], "float32"))
torch.Tensor.dtype.__get__(Tensor([1024, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([1024, 3072], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([1024], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([103424, 1024], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2048, 1024], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([256, 1024], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([3072, 1024], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([64], "float32"))
torch.Tensor.element_size("<Unserializable: Parameter>")
torch.Tensor.expand(Tensor([1, 64, 1], "float32"), 1, -1, 1)
torch.Tensor.fill_(Tensor([1024], "float32"), 0)
torch.Tensor.flatten(Tensor([1, 16, 12, 64, 2], "float32"), -2)
torch.Tensor.flatten(Tensor([1, 2, 12, 64, 2], "float32"), -2)
torch.Tensor.float(Tensor([1, 1, 12], "float32"))
torch.Tensor.float(Tensor([1, 1, 12], "int64"))
torch.Tensor.float(Tensor([1, 16, 12, 128], "float32"))
torch.Tensor.float(Tensor([1, 2, 12, 128], "float32"))
torch.Tensor.float(Tensor([1, 64, 1], "float32"))
torch.Tensor.ge(Tensor([], "int64"), 12)
torch.Tensor.grad.__get__("<Unserializable: Parameter>")
torch.Tensor.grad_fn.__get__("<Unserializable: Parameter>")
torch.Tensor.is_contiguous("<Unserializable: Parameter>")
torch.Tensor.is_floating_point("<Unserializable: Parameter>")
torch.Tensor.is_floating_point(Tensor([64], "float32"))
torch.Tensor.is_meta.__get__("<Unserializable: Parameter>")
torch.Tensor.is_meta.__get__(Tensor([1024, 2048], "float32"))
torch.Tensor.is_meta.__get__(Tensor([1024, 3072], "float32"))
torch.Tensor.is_meta.__get__(Tensor([1024], "float32"))
torch.Tensor.is_meta.__get__(Tensor([103424, 1024], "float32"))
torch.Tensor.is_meta.__get__(Tensor([2048, 1024], "float32"))
torch.Tensor.is_meta.__get__(Tensor([256, 1024], "float32"))
torch.Tensor.is_meta.__get__(Tensor([3072, 1024], "float32"))
torch.Tensor.le(Tensor([1, 103424], "float32"), 0.19999999999999996)
torch.Tensor.long(Tensor([1, 12], "bool"))
torch.Tensor.long(Tensor([1, 12], "int64"))
torch.Tensor.lt(Tensor([1, 103424], "float32"), Tensor([1, 1], "float32"))
torch.Tensor.lt(Tensor([1], "int64"), 0)
torch.Tensor.masked_fill(Tensor([1, 103424], "float32"), Tensor([1, 103424], "bool"), -inf)
torch.Tensor.masked_fill_(Tensor([1, 12], "int64"), Tensor([1, 12], "bool"), 1)
torch.Tensor.matmul(Tensor([1, 64, 1], "float32"), Tensor([1, 1, 12], "float32"))
torch.Tensor.max(Tensor([1], "int64"))
torch.Tensor.mean(Tensor([1, 12, 1024], "float32"), -1, keepdim=True)
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([1, 12, 1024], "float32"))
torch.Tensor.mul(Tensor([1, 12, 1024], "float32"), Tensor([1, 12, 1], "float32"))
torch.Tensor.mul(Tensor([1, 12, 128], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 12, 3072], "float32"), Tensor([1, 12, 3072], "float32"))
torch.Tensor.mul(Tensor([1, 12], "int64"), Tensor([], "bool"))
torch.Tensor.mul(Tensor([1, 16, 12, 128], "float32"), Tensor([1, 1, 12, 128], "float32"))
torch.Tensor.mul(Tensor([1, 2, 12, 128], "float32"), Tensor([1, 1, 12, 128], "float32"))
torch.Tensor.mul(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.mul(Tensor([], "bool"), Tensor([], "bool"))
torch.Tensor.mul(Tensor([], "int64"), Tensor([1], "int64"))
torch.Tensor.ndim.__get__(Tensor([1, 12], "int64"))
torch.Tensor.ndim.__get__(Tensor([], "int64"))
torch.Tensor.ne(Tensor([1, 12], "int64"), Tensor([], "int64"))
torch.Tensor.neg(Tensor([1, 16, 12, 64], "float32"))
torch.Tensor.neg(Tensor([1, 2, 12, 64], "float32"))
torch.Tensor.numel("<Unserializable: Parameter>")
torch.Tensor.numel(Tensor([64], "float32"))
torch.Tensor.pow(Tensor([1, 12, 1024], "float32"), 2)
torch.Tensor.repeat_interleave(Tensor([1, 1, 12, 64], "float32"), 2, dim=-1)
torch.Tensor.requires_grad.__get__("<Unserializable: Parameter>")
torch.Tensor.reshape(Tensor([1, 12, 16, 128], "float32"), 1, 12, -1)
torch.Tensor.reshape(Tensor([1024], "bfloat16"), list[1024])
torch.Tensor.reshape(Tensor([105906176], "bfloat16"), list[103424, 1024])
torch.Tensor.reshape(Tensor([2097152], "bfloat16"), list[1024, 2048])
torch.Tensor.reshape(Tensor([2097152], "bfloat16"), list[2048, 1024])
torch.Tensor.reshape(Tensor([262144], "bfloat16"), list[256, 1024])
torch.Tensor.reshape(Tensor([3145728], "bfloat16"), list[1024, 3072])
torch.Tensor.reshape(Tensor([3145728], "bfloat16"), list[3072, 1024])
torch.Tensor.scatter(Tensor([1, 103424], "bool"), 1, Tensor([1, 103424], "int64"), Tensor([1, 103424], "bool"))
torch.Tensor.shape.__get__("<Unserializable: Parameter>")
torch.Tensor.shape.__get__(Tensor([1, 1, 12, 128], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 12, 1024], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 12], "bool"))
torch.Tensor.shape.__get__(Tensor([1, 12], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 13], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 16, 12, 128], "float32"))
torch.Tensor.shape.__get__(Tensor([1024, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1024, 3072], "float32"))
torch.Tensor.shape.__get__(Tensor([1024], "float32"))
torch.Tensor.shape.__get__(Tensor([103424, 1024], "float32"))
torch.Tensor.shape.__get__(Tensor([12], "int64"))
torch.Tensor.shape.__get__(Tensor([2048, 1024], "float32"))
torch.Tensor.shape.__get__(Tensor([256, 1024], "float32"))
torch.Tensor.shape.__get__(Tensor([3072, 1024], "float32"))
torch.Tensor.sin(Tensor([1, 12, 128], "float32"))
torch.Tensor.size(Tensor([1, 103424], "float32"), -1)
torch.Tensor.softmax(Tensor([1, 103424], "float32"), dim=-1)
torch.Tensor.squeeze(Tensor([1, 1], "int64"), 1)
torch.Tensor.sub(Tensor([1, 12], "int64"), 1)
torch.Tensor.sub(Tensor([12], "int64"), 1)
torch.Tensor.to("<Unserializable: Parameter>", "cuda:7", None, False)
torch.Tensor.to("<Unserializable: Parameter>", "meta")
torch.Tensor.to(Tensor([1, 103424], "float32"), copy=True, dtype="float32", device="cuda:7")
torch.Tensor.to(Tensor([1, 12, 1024], "float32"), "float32")
torch.Tensor.to(Tensor([1, 12], "int64"), device="cuda:7", dtype="bool")
torch.Tensor.to(Tensor([1, 12], "int64"), device="cuda:7", non_blocking=False)
torch.Tensor.to(Tensor([1, 16, 12, 128], "float32"), "float32")
torch.Tensor.to(Tensor([1, 2, 12, 128], "float32"), "float32")
torch.Tensor.to(Tensor([1, 64, 1], "float32"), "cuda:7")
torch.Tensor.to(Tensor([1024, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([1024, 2048], "bfloat16"), 7)
torch.Tensor.to(Tensor([1024, 2048], "float32"), 7)
torch.Tensor.to(Tensor([1024, 3072], "bfloat16"), "float32")
torch.Tensor.to(Tensor([1024, 3072], "bfloat16"), 7)
torch.Tensor.to(Tensor([1024, 3072], "float32"), 7)
torch.Tensor.to(Tensor([1024], "bfloat16"), "float32")
torch.Tensor.to(Tensor([1024], "bfloat16"), 7)
torch.Tensor.to(Tensor([1024], "float32"), 7)
torch.Tensor.to(Tensor([103424, 1024], "bfloat16"), "float32")
torch.Tensor.to(Tensor([103424, 1024], "bfloat16"), 7)
torch.Tensor.to(Tensor([103424, 1024], "float32"), 7)
torch.Tensor.to(Tensor([1], "int64"), "cuda:7")
torch.Tensor.to(Tensor([2048, 1024], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2048, 1024], "bfloat16"), 7)
torch.Tensor.to(Tensor([2048, 1024], "float32"), 7)
torch.Tensor.to(Tensor([256, 1024], "bfloat16"), "float32")
torch.Tensor.to(Tensor([256, 1024], "bfloat16"), 7)
torch.Tensor.to(Tensor([256, 1024], "float32"), 7)
torch.Tensor.to(Tensor([3072, 1024], "bfloat16"), "float32")
torch.Tensor.to(Tensor([3072, 1024], "bfloat16"), 7)
torch.Tensor.to(Tensor([3072, 1024], "float32"), 7)
torch.Tensor.to(Tensor([64], "float32"), "cuda:7", None, False)
torch.Tensor.to(Tensor([64], "int64"), device=None, dtype="float32")
torch.Tensor.tolist(Tensor([13], "int64"))
torch.Tensor.transpose(Tensor([1, 12, 16, 128], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 12, 2, 128], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 16, 12, 128], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 64, 12], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 12, 128], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([], "int64"), 0)
torch.Tensor.view(Tensor([1, 12, 2048], "float32"), tuple(1, 12, -1, 128))
torch.Tensor.view(Tensor([1, 12, 256], "float32"), tuple(1, 12, -1, 128))
torch.Tensor.view(Tensor([2048], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([211812352], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([4194304], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([524288], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([6291456], "uint8"), dtype="bfloat16")
torch._C._nn._parse_to(7)
torch._C._set_grad_enabled(False)
torch._C._set_grad_enabled(True)
torch._has_compatible_shallow_copy_type("<Unserializable: Parameter>", "<Unserializable: Parameter>")
torch.cat(list[Tensor([1, 12], "int64"), Tensor([1, 1], "int64")], dim=-1)
torch.cat(tuple(Tensor([1, 12, 64], "float32"), Tensor([1, 12, 64], "float32")), dim=-1)
torch.is_floating_point(Tensor([1], "int64"))
torch.isin(Tensor([1, 12], "int64"), Tensor([], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([1], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([], "int64"))
torch.multinomial(Tensor([1, 103424], "float32"), num_samples=1)
torch.nn.functional.embedding(Tensor([1, 12], "int64"), "<Unserializable: Parameter>", padding_idx=0, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.linear(Tensor([1, 1, 1024], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([1, 12, 1024], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([1, 12, 2048], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([1, 12, 3072], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 16, 12, 128], "float32"), Tensor([1, 2, 12, 128], "float32"), Tensor([1, 2, 12, 128], "float32"), attn_mask=None, dropout_p=0.0, scale=0.08838834764831845, is_causal=True, enable_gqa=True)
torch.nn.functional.silu(Tensor([1, 12, 3072], "float32"), inplace=False)
torch.nn.functional.softmax(Tensor([1, 103424], "float32"), dim=-1, _stacklevel=3, dtype=None)
torch.rsqrt(Tensor([1, 12, 1], "float32"))
torch.sort(Tensor([1, 103424], "float32"), descending=False)
torch.stack(tuple(Tensor([1, 16, 12, 64], "float32"), Tensor([1, 16, 12, 64], "float32")), dim=-1)
torch.stack(tuple(Tensor([1, 2, 12, 64], "float32"), Tensor([1, 2, 12, 64], "float32")), dim=-1)
torch.topk(Tensor([1, 103424], "float32"), 50)
torchvision._cuda_version()
