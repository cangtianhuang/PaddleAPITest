torch.Tensor.__and__(Tensor([1], "int64"), Tensor([1], "bool"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch.Tensor.__eq__(Tensor([1, 14], "int64"), 0)
torch.Tensor.__eq__(Tensor([], "int64"), 0)
torch.Tensor.__getitem__(Tensor([1, 1, 32000], "float32"), tuple(slice(None, None, None), -1, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 14, 2048], "float32"), tuple(slice(None, None, None), slice(-1, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 14], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 14], "int64"), tuple(slice(None, None, None), slice(-14, None, None)))
torch.Tensor.__getitem__(Tensor([1, 15], "int64"), 0)
torch.Tensor.__getitem__(Tensor([1, 15], "int64"), tuple(slice(None, None, None), -1))
torch.Tensor.__getitem__(Tensor([1, 32, 14, 64], "float32"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([1, 32, 14, 64], "float32"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([1, 4, 14, 64], "float32"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([1, 4, 14, 64], "float32"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([1, 50], "float32"), tuple(ellipsis(...), -1, None))
torch.Tensor.__getitem__(Tensor([14], "int64"), -1)
torch.Tensor.__getitem__(Tensor([14], "int64"), slice(-1, None, None))
torch.Tensor.__getitem__(Tensor([14], "int64"), slice(0, None, None))
torch.Tensor.__getitem__(Tensor([1], "int64"), tuple(slice(None, None, None), None))
torch.Tensor.__getitem__(Tensor([2048, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([2048, 5632], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([256, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([32000, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([32], "float32"), tuple(None, slice(None, None, None), None))
torch.Tensor.__getitem__(Tensor([5632, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__invert__(Tensor([1], "bool"))
torch.Tensor.__invert__(Tensor([], "bool"))
torch.Tensor.__len__(Tensor([1, 14], "int64"))
torch.Tensor.__or__(Tensor([1], "bool"), Tensor([1], "bool"))
torch.Tensor.__rpow__(Tensor([32], "float32"), 10000.0)
torch.Tensor.__rsub__(Tensor([1], "int64"), 1)
torch.Tensor.__rtruediv__(Tensor([32], "float32"), 1.0)
torch.Tensor.add(Tensor([1, 14, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([1, 14, 2048], "float32"), Tensor([1, 14, 2048], "float32"))
torch.Tensor.add(Tensor([1, 14], "int64"), Tensor([1, 14], "int64"))
torch.Tensor.add(Tensor([1, 32, 14, 64], "float32"), Tensor([1, 32, 14, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 14, 64], "float32"), Tensor([1, 4, 14, 64], "float32"))
torch.Tensor.add(Tensor([1], "int64"), 1)
torch.Tensor.add(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.all(Tensor([1, 14], "bool"))
torch.Tensor.any(Tensor([1, 14], "bool"))
torch.Tensor.any(Tensor([1], "bool"))
torch.Tensor.clone(Tensor([1, 14], "int64"), memory_format="torch.contiguous_format")
torch.Tensor.contiguous(Tensor([1, 14, 2048], "float32"))
torch.Tensor.contiguous(Tensor([1, 14, 32, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 14, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 14, 64], "float32"))
torch.Tensor.contiguous(Tensor([2048, 2048], "float32"))
torch.Tensor.contiguous(Tensor([2048, 5632], "float32"))
torch.Tensor.contiguous(Tensor([2048], "float32"))
torch.Tensor.contiguous(Tensor([256, 2048], "float32"))
torch.Tensor.contiguous(Tensor([32000, 2048], "float32"))
torch.Tensor.contiguous(Tensor([5632, 2048], "float32"))
torch.Tensor.cos(Tensor([1, 14, 64], "float32"))
torch.Tensor.cumsum(Tensor([1, 14], "int64"), -1)
torch.Tensor.cumsum(Tensor([14], "int64"), 0)
torch.Tensor.data_ptr("<Unserializable: Parameter>")
torch.Tensor.data_ptr(Tensor([32], "float32"))
torch.Tensor.detach("<Unserializable: Parameter>")
torch.Tensor.device.__get__("<Unserializable: Parameter>")
torch.Tensor.device.__get__(Tensor([1, 14, 2048], "float32"))
torch.Tensor.device.__get__(Tensor([1, 14], "int64"))
torch.Tensor.device.__get__(Tensor([1, 15], "int64"))
torch.Tensor.device.__get__(Tensor([14], "int64"))
torch.Tensor.device.__get__(Tensor([1], "int64"))
torch.Tensor.device.__get__(Tensor([32], "float32"))
torch.Tensor.div(Tensor([1, 32000], "float32"), 0.7)
torch.Tensor.div(Tensor([32], "float32"), 64)
torch.Tensor.dtype.__get__("<Unserializable: Parameter>")
torch.Tensor.dtype.__get__(Tensor([1, 14, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 14], "int64"))
torch.Tensor.dtype.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([32], "float32"))
torch.Tensor.dtype.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.element_size("<Unserializable: Parameter>")
torch.Tensor.expand(Tensor([1, 32, 1], "float32"), 1, -1, 1)
torch.Tensor.float(Tensor([1, 1, 14], "float32"))
torch.Tensor.float(Tensor([1, 1, 14], "int64"))
torch.Tensor.float(Tensor([1, 32, 1], "float32"))
torch.Tensor.ge(Tensor([], "int64"), 14)
torch.Tensor.grad_fn.__get__("<Unserializable: Parameter>")
torch.Tensor.is_contiguous("<Unserializable: Parameter>")
torch.Tensor.is_meta.__get__("<Unserializable: Parameter>")
torch.Tensor.is_meta.__get__(Tensor([2048, 2048], "float32"))
torch.Tensor.is_meta.__get__(Tensor([2048, 5632], "float32"))
torch.Tensor.is_meta.__get__(Tensor([2048], "float32"))
torch.Tensor.is_meta.__get__(Tensor([256, 2048], "float32"))
torch.Tensor.is_meta.__get__(Tensor([32000, 2048], "float32"))
torch.Tensor.is_meta.__get__(Tensor([5632, 2048], "float32"))
torch.Tensor.long(Tensor([1, 14], "bool"))
torch.Tensor.long(Tensor([1, 14], "int64"))
torch.Tensor.lt(Tensor([1, 32000], "float32"), Tensor([1, 1], "float32"))
torch.Tensor.lt(Tensor([1], "int64"), 0)
torch.Tensor.masked_fill(Tensor([1, 32000], "float32"), Tensor([1, 32000], "bool"), -inf)
torch.Tensor.masked_fill_(Tensor([1, 14], "int64"), Tensor([1, 14], "bool"), 1)
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 14], "float32"))
torch.Tensor.max(Tensor([1], "int64"))
torch.Tensor.mean(Tensor([1, 14, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([1, 14, 2048], "float32"))
torch.Tensor.mul(Tensor([1, 14, 2048], "float32"), Tensor([1, 14, 1], "float32"))
torch.Tensor.mul(Tensor([1, 14, 5632], "float32"), Tensor([1, 14, 5632], "float32"))
torch.Tensor.mul(Tensor([1, 14, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 14], "int64"), Tensor([], "bool"))
torch.Tensor.mul(Tensor([1, 32, 14, 64], "float32"), Tensor([1, 1, 14, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 14, 64], "float32"), Tensor([1, 1, 14, 64], "float32"))
torch.Tensor.mul(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.mul(Tensor([], "bool"), Tensor([], "bool"))
torch.Tensor.mul(Tensor([], "int64"), Tensor([1], "int64"))
torch.Tensor.ndim.__get__(Tensor([1, 14], "int64"))
torch.Tensor.ndim.__get__(Tensor([], "int64"))
torch.Tensor.ne(Tensor([1, 14], "int64"), Tensor([], "int64"))
torch.Tensor.neg(Tensor([1, 32, 14, 32], "float32"))
torch.Tensor.neg(Tensor([1, 4, 14, 32], "float32"))
torch.Tensor.numel("<Unserializable: Parameter>")
torch.Tensor.numel(Tensor([32], "float32"))
torch.Tensor.pow(Tensor([1, 14, 2048], "float32"), 2)
torch.Tensor.requires_grad.__get__("<Unserializable: Parameter>")
torch.Tensor.reshape(Tensor([1, 14, 32, 64], "float32"), 1, 14, -1)
torch.Tensor.reshape(Tensor([11534336], "bfloat16"), list[2048, 5632])
torch.Tensor.reshape(Tensor([11534336], "bfloat16"), list[5632, 2048])
torch.Tensor.reshape(Tensor([2048], "bfloat16"), list[2048])
torch.Tensor.reshape(Tensor([4194304], "bfloat16"), list[2048, 2048])
torch.Tensor.reshape(Tensor([524288], "bfloat16"), list[256, 2048])
torch.Tensor.reshape(Tensor([65536000], "bfloat16"), list[32000, 2048])
torch.Tensor.shape.__get__("<Unserializable: Parameter>")
torch.Tensor.shape.__get__(Tensor([1, 14, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 14], "bool"))
torch.Tensor.shape.__get__(Tensor([1, 14], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 15], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 32, 14, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 14, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([14], "int64"))
torch.Tensor.shape.__get__(Tensor([2048, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([2048, 5632], "float32"))
torch.Tensor.shape.__get__(Tensor([2048], "float32"))
torch.Tensor.shape.__get__(Tensor([256, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([32000, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([5632, 2048], "float32"))
torch.Tensor.sin(Tensor([1, 14, 64], "float32"))
torch.Tensor.size(Tensor([1, 32000], "float32"), -1)
torch.Tensor.squeeze(Tensor([1, 1], "int64"), 1)
torch.Tensor.sub(Tensor([1, 14], "int64"), 1)
torch.Tensor.sub(Tensor([14], "int64"), 1)
torch.Tensor.to("<Unserializable: Parameter>", "meta")
torch.Tensor.to("<Unserializable: Parameter>", 0, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 1, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 2, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 3, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 4, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 5, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 1, 2048], "float32"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 1, 32000], "float32"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), "float32")
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 2048], "float32"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 5632], "float32"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 14, 64], "float32"), dtype="float32")
torch.Tensor.to(Tensor([1, 14], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 14], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([1, 14], "int64"), device="cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([1, 32, 1], "float32"), "cuda:6")
torch.Tensor.to(Tensor([1, 32000], "float32"), copy=True, dtype="float32", device="cuda:0")
torch.Tensor.to(Tensor([14], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([14], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([14], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([14], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([14], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([14], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([14], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1], "int64"), "cuda:0")
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2048, 2048], "float32"), 0)
torch.Tensor.to(Tensor([2048, 2048], "float32"), 1)
torch.Tensor.to(Tensor([2048, 2048], "float32"), 2)
torch.Tensor.to(Tensor([2048, 2048], "float32"), 3)
torch.Tensor.to(Tensor([2048, 2048], "float32"), 4)
torch.Tensor.to(Tensor([2048, 2048], "float32"), 5)
torch.Tensor.to(Tensor([2048, 2048], "float32"), 6)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2048, 5632], "float32"), 0)
torch.Tensor.to(Tensor([2048, 5632], "float32"), 1)
torch.Tensor.to(Tensor([2048, 5632], "float32"), 2)
torch.Tensor.to(Tensor([2048, 5632], "float32"), 3)
torch.Tensor.to(Tensor([2048, 5632], "float32"), 4)
torch.Tensor.to(Tensor([2048, 5632], "float32"), 5)
torch.Tensor.to(Tensor([2048, 5632], "float32"), 6)
torch.Tensor.to(Tensor([2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2048], "float32"), 0)
torch.Tensor.to(Tensor([2048], "float32"), 1)
torch.Tensor.to(Tensor([2048], "float32"), 2)
torch.Tensor.to(Tensor([2048], "float32"), 3)
torch.Tensor.to(Tensor([2048], "float32"), 4)
torch.Tensor.to(Tensor([2048], "float32"), 5)
torch.Tensor.to(Tensor([2048], "float32"), 6)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([256, 2048], "float32"), 0)
torch.Tensor.to(Tensor([256, 2048], "float32"), 1)
torch.Tensor.to(Tensor([256, 2048], "float32"), 2)
torch.Tensor.to(Tensor([256, 2048], "float32"), 3)
torch.Tensor.to(Tensor([256, 2048], "float32"), 4)
torch.Tensor.to(Tensor([256, 2048], "float32"), 5)
torch.Tensor.to(Tensor([256, 2048], "float32"), 6)
torch.Tensor.to(Tensor([32000, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([32000, 2048], "float32"), 0)
torch.Tensor.to(Tensor([32000, 2048], "float32"), 6)
torch.Tensor.to(Tensor([32], "float32"), 6, non_blocking=False)
torch.Tensor.to(Tensor([32], "int64"), device=None, dtype="float32")
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([5632, 2048], "float32"), 0)
torch.Tensor.to(Tensor([5632, 2048], "float32"), 1)
torch.Tensor.to(Tensor([5632, 2048], "float32"), 2)
torch.Tensor.to(Tensor([5632, 2048], "float32"), 3)
torch.Tensor.to(Tensor([5632, 2048], "float32"), 4)
torch.Tensor.to(Tensor([5632, 2048], "float32"), 5)
torch.Tensor.to(Tensor([5632, 2048], "float32"), 6)
torch.Tensor.tolist(Tensor([15], "int64"))
torch.Tensor.transpose(Tensor([1, 14, 32, 64], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 14, 4, 64], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 14, 64], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 14], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 14, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([], "int64"), 0)
torch.Tensor.view(Tensor([1, 14, 2048], "float32"), tuple(1, 14, -1, 64))
torch.Tensor.view(Tensor([1, 14, 256], "float32"), tuple(1, 14, -1, 64))
torch.Tensor.view(Tensor([1048576], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([131072000], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([23068672], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([4096], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([8388608], "uint8"), dtype="bfloat16")
torch._C._set_grad_enabled(False)
torch._C._set_grad_enabled(True)
torch.cat(list[Tensor([1, 14], "int64"), Tensor([1, 1], "int64")], dim=-1)
torch.cat(tuple(Tensor([1, 14, 32], "float32"), Tensor([1, 14, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 32, 14, 32], "float32"), Tensor([1, 32, 14, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 4, 14, 32], "float32"), Tensor([1, 4, 14, 32], "float32")), dim=-1)
torch.is_floating_point(Tensor([1], "int64"))
torch.isin(Tensor([1, 14], "int64"), Tensor([], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([1], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([], "int64"))
torch.multinomial(Tensor([1, 32000], "float32"), num_samples=1)
torch.nn.functional.embedding(Tensor([1, 14], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.linear(Tensor([1, 1, 2048], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([1, 14, 2048], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([1, 14, 5632], "float32"), "<Unserializable: Parameter>", None)
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 14, 64], "float32"), Tensor([1, 4, 14, 64], "float32"), Tensor([1, 4, 14, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.nn.functional.silu(Tensor([1, 14, 5632], "float32"), inplace=False)
torch.nn.functional.softmax(Tensor([1, 32000], "float32"), dim=-1, _stacklevel=3, dtype=None)
torch.rsqrt(Tensor([1, 14, 1], "float32"))
torch.topk(Tensor([1, 32000], "float32"), 50)
torchvision._cuda_version()
