profiler._record_function_enter_new("Optimizer.step#AdamW.step", None)
profiler._record_function_enter_new("enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__", None)
profiler._record_function_exit._RecordFunction("<Unserializable: ScriptObject>")
torch.Tensor.__and__(Tensor([], "bool"), Tensor([], "bool"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch.Tensor.__eq__(Tensor([2, 102], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 154], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 156], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 172], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 173], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 179], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 182], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 231], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 285], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 299], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 302], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 314], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 324], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 331], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 345], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 356], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 358], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 407], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 408], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 409], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 434], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 438], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 449], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 478], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 50], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 512], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 52], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 55], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 58], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 60], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 64], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 80], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 91], "int64"), 2)
torch.Tensor.__eq__(Tensor([2, 99], "int64"), 2)
torch.Tensor.__getitem__(Tensor([1, 102], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 154], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 156], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 172], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 173], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 179], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 182], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 231], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 285], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 299], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 314], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 324], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 331], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 345], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 356], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 358], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 407], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 408], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 409], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 434], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 438], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 449], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 478], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 50], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 512], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 52], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 55], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 58], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 60], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 64], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 80], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 91], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([1, 99], "int64"), tuple(slice(None, None, None), None, slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 102, 102], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 102, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 154, 154], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 154, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 156, 156], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 156, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 172, 172], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 172, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 173, 173], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 173, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 179, 179], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 179, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 182, 182], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 182, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 231, 231], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 231, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 285, 285], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 285, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 299, 299], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 299, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 314, 314], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 314, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 324, 324], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 324, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 331, 331], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 331, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 345, 345], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 345, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 356, 356], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 356, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 358, 358], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 358, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 407, 407], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 407, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 408, 408], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 408, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 409, 409], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 409, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 434, 434], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 434, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 438, 438], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 438, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 449, 449], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 449, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 478, 478], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 478, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 50, 50], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 50, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 512, 512], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 512, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 52, 52], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 52, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 55, 55], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 55, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 58, 58], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 58, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 60, 60], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 60, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 64, 64], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 64, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 80, 80], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 80, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 91, 91], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 91, None)))
torch.Tensor.__getitem__(Tensor([2, 1, 99, 99], "bool"), tuple(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 99, None)))
torch.Tensor.__getitem__(Tensor([2, 100], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 102, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 102], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 103], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 154, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 154], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 155], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 156, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 156], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 157], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 172, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 172], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 173, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 173], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 173], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 174], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 179, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 179], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 180], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 182, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 182], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 183], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 231, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 231], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 232], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 285, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 285], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 286], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 299, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 299], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 300], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 314, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 314], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 315], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 102, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 102, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 154, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 154, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 156, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 156, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 172, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 172, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 173, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 173, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 179, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 179, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 182, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 182, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 231, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 231, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 285, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 285, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 299, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 299, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 314, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 314, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 324, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 324, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 331, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 331, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 345, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 345, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 356, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 356, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 358, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 358, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 407, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 407, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 408, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 408, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 409, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 409, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 434, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 434, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 438, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 438, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 449, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 449, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 478, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 478, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 50, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 50, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 512, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 512, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 52, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 52, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 55, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 55, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 58, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 58, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 60, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 60, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 64, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 64, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 80, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 80, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 91, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 91, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 99, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 32, 99, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 324, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 324], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 325], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 331, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 331], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 332], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 345, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 345], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 346], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 356, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 356], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 357], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 358, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 358], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 359], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 102, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 102, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 102, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 154, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 154, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 154, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 156, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 156, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 156, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 172, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 172, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 172, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 173, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 173, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 173, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 179, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 179, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 179, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 182, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 182, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 182, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 231, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 231, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 231, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 285, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 285, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 285, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 299, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 299, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 299, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 314, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 314, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 314, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 324, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 324, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 324, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 331, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 331, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 331, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 345, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 345, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 345, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 356, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 356, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 356, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 358, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 358, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 358, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 407, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 407, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 407, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 408, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 408, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 408, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 409, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 409, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 409, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 434, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 434, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 434, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 438, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 438, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 438, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 449, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 449, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 449, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 478, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 478, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 478, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 50, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 50, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 50, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 512, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 512, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 512, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 52, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 52, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 52, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 55, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 55, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 55, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 58, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 58, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 58, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 60, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 60, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 60, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 64, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 64, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 64, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 80, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 80, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 80, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 91, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 91, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 91, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 99, 64], "bfloat16"), tuple(ellipsis(...), slice(32, None, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 99, 64], "bfloat16"), tuple(ellipsis(...), slice(None, 32, None)))
torch.Tensor.__getitem__(Tensor([2, 4, 99, 64], "bfloat16"), tuple(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 407, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 407], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 408, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 408], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 408], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 409, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 409], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 409], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 410], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 434, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 434], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 435], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 438, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 438], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 439], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 449, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 449], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 450], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 478, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 478], "int64"), slice(0, 1, None))
torch.Tensor.__getitem__(Tensor([2, 478], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 479], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 50, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 50], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 512, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 512], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 513], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 51], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 52, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 52], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 53], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 55, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 55], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 56], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 58, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 58], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 59], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 60, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 60], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 61], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 64, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 64], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 65], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 80, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 80], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 81], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 91, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 91], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2, 92], "int64"), tuple(ellipsis(...), slice(1, None, None)))
torch.Tensor.__getitem__(Tensor([2, 99, 2048], "bfloat16"), tuple(slice(None, None, None), slice(0, None, None), slice(None, None, None)))
torch.Tensor.__getitem__(Tensor([2, 99], "int64"), slice(0, 2, None))
torch.Tensor.__getitem__(Tensor([2048, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([2048, 5632], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([256, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([32000, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__getitem__(Tensor([32], "float32"), tuple(None, slice(None, None, None), None))
torch.Tensor.__getitem__(Tensor([5632, 2048], "bfloat16"), ellipsis(...))
torch.Tensor.__int__(Tensor([], "int64"))
torch.Tensor.__rpow__(Tensor([32], "float32"), 10000.0)
torch.Tensor.__rsub__(Tensor([], "int64"), 0)
torch.Tensor.__rtruediv__(Tensor([32], "float32"), 1.0)
torch.Tensor.__rtruediv__(Tensor([], "bfloat16"), 1.0)
torch.Tensor.__setitem__(Tensor([2, 102], "int64"), Tensor([2, 102], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 154], "int64"), Tensor([2, 154], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 156], "int64"), Tensor([2, 156], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 172], "int64"), Tensor([2, 172], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 173], "int64"), Tensor([2, 173], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 179], "int64"), Tensor([2, 179], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 182], "int64"), Tensor([2, 182], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 231], "int64"), Tensor([2, 231], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 285], "int64"), Tensor([2, 285], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 299], "int64"), Tensor([2, 299], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 302], "int64"), Tensor([2, 302], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 314], "int64"), Tensor([2, 314], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 324], "int64"), Tensor([2, 324], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 331], "int64"), Tensor([2, 331], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 345], "int64"), Tensor([2, 345], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 356], "int64"), Tensor([2, 356], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 358], "int64"), Tensor([2, 358], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 407], "int64"), Tensor([2, 407], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 408], "int64"), Tensor([2, 408], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 409], "int64"), Tensor([2, 409], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 434], "int64"), Tensor([2, 434], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 438], "int64"), Tensor([2, 438], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 449], "int64"), Tensor([2, 449], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 478], "int64"), Tensor([2, 478], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 50], "int64"), Tensor([2, 50], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 512], "int64"), Tensor([2, 512], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 52], "int64"), Tensor([2, 52], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 55], "int64"), Tensor([2, 55], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 58], "int64"), Tensor([2, 58], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 60], "int64"), Tensor([2, 60], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 64], "int64"), Tensor([2, 64], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 80], "int64"), Tensor([2, 80], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 91], "int64"), Tensor([2, 91], "bool"), -100)
torch.Tensor.__setitem__(Tensor([2, 99], "int64"), Tensor([2, 99], "bool"), -100)
torch.Tensor._backward_hooks.__get__(Tensor([16], "uint8"))
torch.Tensor._backward_hooks.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor._backward_hooks.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor._backward_hooks.__get__(Tensor([2048], "bfloat16"))
torch.Tensor._backward_hooks.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor._backward_hooks.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor._backward_hooks.__get__(Tensor([5056], "uint8"))
torch.Tensor._backward_hooks.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor._backward_hooks.__get__(Tensor([], "float32"))
torch.Tensor.add(Tensor([2, 102, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 102, 2048], "bfloat16"), Tensor([2, 102, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 154, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 154, 2048], "bfloat16"), Tensor([2, 154, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 156, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 156, 2048], "bfloat16"), Tensor([2, 156, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 172, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 172, 2048], "bfloat16"), Tensor([2, 172, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 173, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 173, 2048], "bfloat16"), Tensor([2, 173, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 179, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 179, 2048], "bfloat16"), Tensor([2, 179, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 182, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 182, 2048], "bfloat16"), Tensor([2, 182, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 231, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 231, 2048], "bfloat16"), Tensor([2, 231, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 285, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 285, 2048], "bfloat16"), Tensor([2, 285, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 299, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 299, 2048], "bfloat16"), Tensor([2, 299, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 314, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 314, 2048], "bfloat16"), Tensor([2, 314, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 102, 64], "bfloat16"), Tensor([2, 32, 102, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 154, 64], "bfloat16"), Tensor([2, 32, 154, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 156, 64], "bfloat16"), Tensor([2, 32, 156, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 172, 64], "bfloat16"), Tensor([2, 32, 172, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 173, 64], "bfloat16"), Tensor([2, 32, 173, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 179, 64], "bfloat16"), Tensor([2, 32, 179, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 182, 64], "bfloat16"), Tensor([2, 32, 182, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 231, 64], "bfloat16"), Tensor([2, 32, 231, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 285, 64], "bfloat16"), Tensor([2, 32, 285, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 299, 64], "bfloat16"), Tensor([2, 32, 299, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 314, 64], "bfloat16"), Tensor([2, 32, 314, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 324, 64], "bfloat16"), Tensor([2, 32, 324, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 331, 64], "bfloat16"), Tensor([2, 32, 331, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 345, 64], "bfloat16"), Tensor([2, 32, 345, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 356, 64], "bfloat16"), Tensor([2, 32, 356, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 358, 64], "bfloat16"), Tensor([2, 32, 358, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 407, 64], "bfloat16"), Tensor([2, 32, 407, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 408, 64], "bfloat16"), Tensor([2, 32, 408, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 409, 64], "bfloat16"), Tensor([2, 32, 409, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 434, 64], "bfloat16"), Tensor([2, 32, 434, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 438, 64], "bfloat16"), Tensor([2, 32, 438, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 449, 64], "bfloat16"), Tensor([2, 32, 449, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 478, 64], "bfloat16"), Tensor([2, 32, 478, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 50, 64], "bfloat16"), Tensor([2, 32, 50, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 512, 64], "bfloat16"), Tensor([2, 32, 512, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 52, 64], "bfloat16"), Tensor([2, 32, 52, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 55, 64], "bfloat16"), Tensor([2, 32, 55, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 58, 64], "bfloat16"), Tensor([2, 32, 58, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 60, 64], "bfloat16"), Tensor([2, 32, 60, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 64, 64], "bfloat16"), Tensor([2, 32, 64, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 80, 64], "bfloat16"), Tensor([2, 32, 80, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 91, 64], "bfloat16"), Tensor([2, 32, 91, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 32, 99, 64], "bfloat16"), Tensor([2, 32, 99, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 324, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 324, 2048], "bfloat16"), Tensor([2, 324, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 331, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 331, 2048], "bfloat16"), Tensor([2, 331, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 345, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 345, 2048], "bfloat16"), Tensor([2, 345, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 356, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 356, 2048], "bfloat16"), Tensor([2, 356, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 358, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 358, 2048], "bfloat16"), Tensor([2, 358, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 102, 64], "bfloat16"), Tensor([2, 4, 102, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 154, 64], "bfloat16"), Tensor([2, 4, 154, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 156, 64], "bfloat16"), Tensor([2, 4, 156, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 172, 64], "bfloat16"), Tensor([2, 4, 172, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 173, 64], "bfloat16"), Tensor([2, 4, 173, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 179, 64], "bfloat16"), Tensor([2, 4, 179, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 182, 64], "bfloat16"), Tensor([2, 4, 182, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 231, 64], "bfloat16"), Tensor([2, 4, 231, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 285, 64], "bfloat16"), Tensor([2, 4, 285, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 299, 64], "bfloat16"), Tensor([2, 4, 299, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 314, 64], "bfloat16"), Tensor([2, 4, 314, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 324, 64], "bfloat16"), Tensor([2, 4, 324, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 331, 64], "bfloat16"), Tensor([2, 4, 331, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 345, 64], "bfloat16"), Tensor([2, 4, 345, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 356, 64], "bfloat16"), Tensor([2, 4, 356, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 358, 64], "bfloat16"), Tensor([2, 4, 358, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 407, 64], "bfloat16"), Tensor([2, 4, 407, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 408, 64], "bfloat16"), Tensor([2, 4, 408, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 409, 64], "bfloat16"), Tensor([2, 4, 409, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 434, 64], "bfloat16"), Tensor([2, 4, 434, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 438, 64], "bfloat16"), Tensor([2, 4, 438, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 449, 64], "bfloat16"), Tensor([2, 4, 449, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 478, 64], "bfloat16"), Tensor([2, 4, 478, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 50, 64], "bfloat16"), Tensor([2, 4, 50, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 512, 64], "bfloat16"), Tensor([2, 4, 512, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 52, 64], "bfloat16"), Tensor([2, 4, 52, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 55, 64], "bfloat16"), Tensor([2, 4, 55, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 58, 64], "bfloat16"), Tensor([2, 4, 58, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 60, 64], "bfloat16"), Tensor([2, 4, 60, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 64, 64], "bfloat16"), Tensor([2, 4, 64, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 80, 64], "bfloat16"), Tensor([2, 4, 80, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 91, 64], "bfloat16"), Tensor([2, 4, 91, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 4, 99, 64], "bfloat16"), Tensor([2, 4, 99, 64], "bfloat16"))
torch.Tensor.add(Tensor([2, 407, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 407, 2048], "bfloat16"), Tensor([2, 407, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 408, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 408, 2048], "bfloat16"), Tensor([2, 408, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 409, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 409, 2048], "bfloat16"), Tensor([2, 409, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 434, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 434, 2048], "bfloat16"), Tensor([2, 434, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 438, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 438, 2048], "bfloat16"), Tensor([2, 438, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 449, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 449, 2048], "bfloat16"), Tensor([2, 449, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 478, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 478, 2048], "bfloat16"), Tensor([2, 478, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 50, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 50, 2048], "bfloat16"), Tensor([2, 50, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 512, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 512, 2048], "bfloat16"), Tensor([2, 512, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 52, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 52, 2048], "bfloat16"), Tensor([2, 52, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 55, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 55, 2048], "bfloat16"), Tensor([2, 55, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 58, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 58, 2048], "bfloat16"), Tensor([2, 58, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 60, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 60, 2048], "bfloat16"), Tensor([2, 60, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 64, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 64, 2048], "bfloat16"), Tensor([2, 64, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 80, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 80, 2048], "bfloat16"), Tensor([2, 80, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 91, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 91, 2048], "bfloat16"), Tensor([2, 91, 2048], "bfloat16"))
torch.Tensor.add(Tensor([2, 99, 1], "float32"), 1e-05)
torch.Tensor.add(Tensor([2, 99, 2048], "bfloat16"), Tensor([2, 99, 2048], "bfloat16"))
torch.Tensor.add(Tensor([], "bfloat16"), 1e-06)
torch.Tensor.add(Tensor([], "float32"), Tensor([], "float32"))
torch.Tensor.add(Tensor([], "int64"), 0)
torch.Tensor.add(Tensor([], "int64"), Tensor([], "int64"))
torch.Tensor.add_(Tensor([102], "int64"), 0)
torch.Tensor.add_(Tensor([154], "int64"), 0)
torch.Tensor.add_(Tensor([156], "int64"), 0)
torch.Tensor.add_(Tensor([172], "int64"), 0)
torch.Tensor.add_(Tensor([173], "int64"), 0)
torch.Tensor.add_(Tensor([179], "int64"), 0)
torch.Tensor.add_(Tensor([182], "int64"), 0)
torch.Tensor.add_(Tensor([231], "int64"), 0)
torch.Tensor.add_(Tensor([285], "int64"), 0)
torch.Tensor.add_(Tensor([299], "int64"), 0)
torch.Tensor.add_(Tensor([314], "int64"), 0)
torch.Tensor.add_(Tensor([324], "int64"), 0)
torch.Tensor.add_(Tensor([331], "int64"), 0)
torch.Tensor.add_(Tensor([345], "int64"), 0)
torch.Tensor.add_(Tensor([356], "int64"), 0)
torch.Tensor.add_(Tensor([358], "int64"), 0)
torch.Tensor.add_(Tensor([407], "int64"), 0)
torch.Tensor.add_(Tensor([408], "int64"), 0)
torch.Tensor.add_(Tensor([409], "int64"), 0)
torch.Tensor.add_(Tensor([434], "int64"), 0)
torch.Tensor.add_(Tensor([438], "int64"), 0)
torch.Tensor.add_(Tensor([449], "int64"), 0)
torch.Tensor.add_(Tensor([478], "int64"), 0)
torch.Tensor.add_(Tensor([50], "int64"), 0)
torch.Tensor.add_(Tensor([512], "int64"), 0)
torch.Tensor.add_(Tensor([52], "int64"), 0)
torch.Tensor.add_(Tensor([55], "int64"), 0)
torch.Tensor.add_(Tensor([58], "int64"), 0)
torch.Tensor.add_(Tensor([60], "int64"), 0)
torch.Tensor.add_(Tensor([64], "int64"), 0)
torch.Tensor.add_(Tensor([80], "int64"), 0)
torch.Tensor.add_(Tensor([91], "int64"), 0)
torch.Tensor.add_(Tensor([99], "int64"), 0)
torch.Tensor.add_(Tensor([], "int64"), Tensor([], "int64"))
torch.Tensor.all(Tensor([2, 102], "bool"))
torch.Tensor.all(Tensor([2, 154], "bool"))
torch.Tensor.all(Tensor([2, 156], "bool"))
torch.Tensor.all(Tensor([2, 172], "bool"))
torch.Tensor.all(Tensor([2, 173], "bool"))
torch.Tensor.all(Tensor([2, 179], "bool"))
torch.Tensor.all(Tensor([2, 182], "bool"))
torch.Tensor.all(Tensor([2, 231], "bool"))
torch.Tensor.all(Tensor([2, 285], "bool"))
torch.Tensor.all(Tensor([2, 299], "bool"))
torch.Tensor.all(Tensor([2, 314], "bool"))
torch.Tensor.all(Tensor([2, 324], "bool"))
torch.Tensor.all(Tensor([2, 331], "bool"))
torch.Tensor.all(Tensor([2, 345], "bool"))
torch.Tensor.all(Tensor([2, 356], "bool"))
torch.Tensor.all(Tensor([2, 358], "bool"))
torch.Tensor.all(Tensor([2, 407], "bool"))
torch.Tensor.all(Tensor([2, 408], "bool"))
torch.Tensor.all(Tensor([2, 409], "bool"))
torch.Tensor.all(Tensor([2, 434], "bool"))
torch.Tensor.all(Tensor([2, 438], "bool"))
torch.Tensor.all(Tensor([2, 449], "bool"))
torch.Tensor.all(Tensor([2, 478], "bool"))
torch.Tensor.all(Tensor([2, 50], "bool"))
torch.Tensor.all(Tensor([2, 512], "bool"))
torch.Tensor.all(Tensor([2, 52], "bool"))
torch.Tensor.all(Tensor([2, 55], "bool"))
torch.Tensor.all(Tensor([2, 58], "bool"))
torch.Tensor.all(Tensor([2, 60], "bool"))
torch.Tensor.all(Tensor([2, 64], "bool"))
torch.Tensor.all(Tensor([2, 80], "bool"))
torch.Tensor.all(Tensor([2, 91], "bool"))
torch.Tensor.all(Tensor([2, 99], "bool"))
torch.Tensor.backward(Tensor([], "float32"), gradient=None, retain_graph=None, create_graph=False, inputs=None)
torch.Tensor.clone(Tensor([2, 102], "int64"))
torch.Tensor.clone(Tensor([2, 154], "int64"))
torch.Tensor.clone(Tensor([2, 156], "int64"))
torch.Tensor.clone(Tensor([2, 172], "int64"))
torch.Tensor.clone(Tensor([2, 173], "int64"))
torch.Tensor.clone(Tensor([2, 179], "int64"))
torch.Tensor.clone(Tensor([2, 182], "int64"))
torch.Tensor.clone(Tensor([2, 231], "int64"))
torch.Tensor.clone(Tensor([2, 285], "int64"))
torch.Tensor.clone(Tensor([2, 299], "int64"))
torch.Tensor.clone(Tensor([2, 302], "int64"))
torch.Tensor.clone(Tensor([2, 314], "int64"))
torch.Tensor.clone(Tensor([2, 324], "int64"))
torch.Tensor.clone(Tensor([2, 331], "int64"))
torch.Tensor.clone(Tensor([2, 345], "int64"))
torch.Tensor.clone(Tensor([2, 356], "int64"))
torch.Tensor.clone(Tensor([2, 358], "int64"))
torch.Tensor.clone(Tensor([2, 407], "int64"))
torch.Tensor.clone(Tensor([2, 408], "int64"))
torch.Tensor.clone(Tensor([2, 409], "int64"))
torch.Tensor.clone(Tensor([2, 434], "int64"))
torch.Tensor.clone(Tensor([2, 438], "int64"))
torch.Tensor.clone(Tensor([2, 449], "int64"))
torch.Tensor.clone(Tensor([2, 478], "int64"))
torch.Tensor.clone(Tensor([2, 50], "int64"))
torch.Tensor.clone(Tensor([2, 512], "int64"))
torch.Tensor.clone(Tensor([2, 52], "int64"))
torch.Tensor.clone(Tensor([2, 55], "int64"))
torch.Tensor.clone(Tensor([2, 58], "int64"))
torch.Tensor.clone(Tensor([2, 60], "int64"))
torch.Tensor.clone(Tensor([2, 64], "int64"))
torch.Tensor.clone(Tensor([2, 80], "int64"))
torch.Tensor.clone(Tensor([2, 91], "int64"))
torch.Tensor.clone(Tensor([2, 99], "int64"))
torch.Tensor.contiguous(Tensor([2, 102, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 102, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 102], "int64"))
torch.Tensor.contiguous(Tensor([2, 154, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 154, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 154], "int64"))
torch.Tensor.contiguous(Tensor([2, 156, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 156, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 156], "int64"))
torch.Tensor.contiguous(Tensor([2, 172, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 172, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 172], "int64"))
torch.Tensor.contiguous(Tensor([2, 173, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 173, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 173], "int64"))
torch.Tensor.contiguous(Tensor([2, 179, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 179, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 179], "int64"))
torch.Tensor.contiguous(Tensor([2, 182, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 182, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 182], "int64"))
torch.Tensor.contiguous(Tensor([2, 231, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 231, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 231], "int64"))
torch.Tensor.contiguous(Tensor([2, 285, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 285, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 285], "int64"))
torch.Tensor.contiguous(Tensor([2, 299, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 299, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 299], "int64"))
torch.Tensor.contiguous(Tensor([2, 314, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 314, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 314], "int64"))
torch.Tensor.contiguous(Tensor([2, 32, 102, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 154, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 156, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 172, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 173, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 179, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 182, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 231, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 285, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 299, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 314, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 324, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 331, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 345, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 356, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 358, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 407, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 408, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 409, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 434, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 438, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 449, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 478, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 50, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 512, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 52, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 55, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 58, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 60, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 64, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 80, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 91, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 32, 99, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 324, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 324, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 324], "int64"))
torch.Tensor.contiguous(Tensor([2, 331, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 331, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 331], "int64"))
torch.Tensor.contiguous(Tensor([2, 345, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 345, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 345], "int64"))
torch.Tensor.contiguous(Tensor([2, 356, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 356, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 356], "int64"))
torch.Tensor.contiguous(Tensor([2, 358, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 358, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 358], "int64"))
torch.Tensor.contiguous(Tensor([2, 4, 55, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 407, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 407, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 407], "int64"))
torch.Tensor.contiguous(Tensor([2, 408, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 408, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 408], "int64"))
torch.Tensor.contiguous(Tensor([2, 409, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 409, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 409], "int64"))
torch.Tensor.contiguous(Tensor([2, 434, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 434, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 434], "int64"))
torch.Tensor.contiguous(Tensor([2, 438, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 438, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 438], "int64"))
torch.Tensor.contiguous(Tensor([2, 449, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 449, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 449], "int64"))
torch.Tensor.contiguous(Tensor([2, 478, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 478, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 478], "int64"))
torch.Tensor.contiguous(Tensor([2, 50, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 50, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 50], "int64"))
torch.Tensor.contiguous(Tensor([2, 512, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 512, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 512], "int64"))
torch.Tensor.contiguous(Tensor([2, 52, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 52, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 52], "int64"))
torch.Tensor.contiguous(Tensor([2, 55, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 55, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 55], "int64"))
torch.Tensor.contiguous(Tensor([2, 58, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 58, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 58], "int64"))
torch.Tensor.contiguous(Tensor([2, 60, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 60, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 60], "int64"))
torch.Tensor.contiguous(Tensor([2, 64, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 64, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 64], "int64"))
torch.Tensor.contiguous(Tensor([2, 80, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 80, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 80], "int64"))
torch.Tensor.contiguous(Tensor([2, 91, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 91, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 91], "int64"))
torch.Tensor.contiguous(Tensor([2, 99, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 99, 32, 64], "bfloat16"))
torch.Tensor.contiguous(Tensor([2, 99], "int64"))
torch.Tensor.contiguous(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.contiguous(Tensor([2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([256, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.contiguous(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.cos(Tensor([1, 102, 64], "float32"))
torch.Tensor.cos(Tensor([1, 154, 64], "float32"))
torch.Tensor.cos(Tensor([1, 156, 64], "float32"))
torch.Tensor.cos(Tensor([1, 172, 64], "float32"))
torch.Tensor.cos(Tensor([1, 173, 64], "float32"))
torch.Tensor.cos(Tensor([1, 179, 64], "float32"))
torch.Tensor.cos(Tensor([1, 182, 64], "float32"))
torch.Tensor.cos(Tensor([1, 231, 64], "float32"))
torch.Tensor.cos(Tensor([1, 285, 64], "float32"))
torch.Tensor.cos(Tensor([1, 299, 64], "float32"))
torch.Tensor.cos(Tensor([1, 314, 64], "float32"))
torch.Tensor.cos(Tensor([1, 324, 64], "float32"))
torch.Tensor.cos(Tensor([1, 331, 64], "float32"))
torch.Tensor.cos(Tensor([1, 345, 64], "float32"))
torch.Tensor.cos(Tensor([1, 356, 64], "float32"))
torch.Tensor.cos(Tensor([1, 358, 64], "float32"))
torch.Tensor.cos(Tensor([1, 407, 64], "float32"))
torch.Tensor.cos(Tensor([1, 408, 64], "float32"))
torch.Tensor.cos(Tensor([1, 409, 64], "float32"))
torch.Tensor.cos(Tensor([1, 434, 64], "float32"))
torch.Tensor.cos(Tensor([1, 438, 64], "float32"))
torch.Tensor.cos(Tensor([1, 449, 64], "float32"))
torch.Tensor.cos(Tensor([1, 478, 64], "float32"))
torch.Tensor.cos(Tensor([1, 50, 64], "float32"))
torch.Tensor.cos(Tensor([1, 512, 64], "float32"))
torch.Tensor.cos(Tensor([1, 52, 64], "float32"))
torch.Tensor.cos(Tensor([1, 55, 64], "float32"))
torch.Tensor.cos(Tensor([1, 58, 64], "float32"))
torch.Tensor.cos(Tensor([1, 60, 64], "float32"))
torch.Tensor.cos(Tensor([1, 64, 64], "float32"))
torch.Tensor.cos(Tensor([1, 80, 64], "float32"))
torch.Tensor.cos(Tensor([1, 91, 64], "float32"))
torch.Tensor.cos(Tensor([1, 99, 64], "float32"))
torch.Tensor.data_ptr("<Unserializable: Parameter>")
torch.Tensor.data_ptr(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.data_ptr(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.data_ptr(Tensor([2048], "bfloat16"))
torch.Tensor.data_ptr(Tensor([256, 2048], "bfloat16"))
torch.Tensor.data_ptr(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.data_ptr(Tensor([32], "float32"))
torch.Tensor.data_ptr(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.detach("<Unserializable: Parameter>")
torch.Tensor.detach(Tensor([], "float32"))
torch.Tensor.device.__get__("<Unserializable: Parameter>")
torch.Tensor.device.__get__(Tensor([100, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([1024, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([102], "int64"))
torch.Tensor.device.__get__(Tensor([104, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([110, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([116, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([120, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([128, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([154], "int64"))
torch.Tensor.device.__get__(Tensor([156], "int64"))
torch.Tensor.device.__get__(Tensor([160, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([16], "uint8"))
torch.Tensor.device.__get__(Tensor([172], "int64"))
torch.Tensor.device.__get__(Tensor([173], "int64"))
torch.Tensor.device.__get__(Tensor([179], "int64"))
torch.Tensor.device.__get__(Tensor([182, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([182], "int64"))
torch.Tensor.device.__get__(Tensor([198, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([2, 102, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 102], "int64"))
torch.Tensor.device.__get__(Tensor([2, 154, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 154], "int64"))
torch.Tensor.device.__get__(Tensor([2, 156, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 156], "int64"))
torch.Tensor.device.__get__(Tensor([2, 172, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 172], "int64"))
torch.Tensor.device.__get__(Tensor([2, 173, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 173], "int64"))
torch.Tensor.device.__get__(Tensor([2, 179, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 179], "int64"))
torch.Tensor.device.__get__(Tensor([2, 182, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 182], "int64"))
torch.Tensor.device.__get__(Tensor([2, 231, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 231], "int64"))
torch.Tensor.device.__get__(Tensor([2, 285, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 285], "int64"))
torch.Tensor.device.__get__(Tensor([2, 299, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 299], "int64"))
torch.Tensor.device.__get__(Tensor([2, 314, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 314], "int64"))
torch.Tensor.device.__get__(Tensor([2, 324, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 324], "int64"))
torch.Tensor.device.__get__(Tensor([2, 331, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 331], "int64"))
torch.Tensor.device.__get__(Tensor([2, 345, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 345], "int64"))
torch.Tensor.device.__get__(Tensor([2, 356, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 356], "int64"))
torch.Tensor.device.__get__(Tensor([2, 358, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 358], "int64"))
torch.Tensor.device.__get__(Tensor([2, 407, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 407], "int64"))
torch.Tensor.device.__get__(Tensor([2, 408, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 408], "int64"))
torch.Tensor.device.__get__(Tensor([2, 409, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 409], "int64"))
torch.Tensor.device.__get__(Tensor([2, 434, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 434], "int64"))
torch.Tensor.device.__get__(Tensor([2, 438, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 438], "int64"))
torch.Tensor.device.__get__(Tensor([2, 449, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 449], "int64"))
torch.Tensor.device.__get__(Tensor([2, 478, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 478], "int64"))
torch.Tensor.device.__get__(Tensor([2, 50, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 50], "int64"))
torch.Tensor.device.__get__(Tensor([2, 512, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 512], "int64"))
torch.Tensor.device.__get__(Tensor([2, 52, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 52], "int64"))
torch.Tensor.device.__get__(Tensor([2, 55, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 55], "int64"))
torch.Tensor.device.__get__(Tensor([2, 58, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 58], "int64"))
torch.Tensor.device.__get__(Tensor([2, 60, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 60], "int64"))
torch.Tensor.device.__get__(Tensor([2, 64, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 64], "int64"))
torch.Tensor.device.__get__(Tensor([2, 80, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 80], "int64"))
torch.Tensor.device.__get__(Tensor([2, 91, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 91], "int64"))
torch.Tensor.device.__get__(Tensor([2, 99, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2, 99], "int64"))
torch.Tensor.device.__get__(Tensor([204, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.device.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([231], "int64"))
torch.Tensor.device.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([285], "int64"))
torch.Tensor.device.__get__(Tensor([299], "int64"))
torch.Tensor.device.__get__(Tensor([308, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([312, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([314], "int64"))
torch.Tensor.device.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([324], "int64"))
torch.Tensor.device.__get__(Tensor([32], "float32"))
torch.Tensor.device.__get__(Tensor([331], "int64"))
torch.Tensor.device.__get__(Tensor([344, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([345], "int64"))
torch.Tensor.device.__get__(Tensor([346, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([356], "int64"))
torch.Tensor.device.__get__(Tensor([358, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([358], "int64"))
torch.Tensor.device.__get__(Tensor([364, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([407], "int64"))
torch.Tensor.device.__get__(Tensor([408], "int64"))
torch.Tensor.device.__get__(Tensor([409], "int64"))
torch.Tensor.device.__get__(Tensor([434], "int64"))
torch.Tensor.device.__get__(Tensor([438], "int64"))
torch.Tensor.device.__get__(Tensor([449], "int64"))
torch.Tensor.device.__get__(Tensor([462, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([478], "int64"))
torch.Tensor.device.__get__(Tensor([5056], "uint8"))
torch.Tensor.device.__get__(Tensor([50], "int64"))
torch.Tensor.device.__get__(Tensor([512], "int64"))
torch.Tensor.device.__get__(Tensor([52], "int64"))
torch.Tensor.device.__get__(Tensor([55], "int64"))
torch.Tensor.device.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.device.__get__(Tensor([570, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([58], "int64"))
torch.Tensor.device.__get__(Tensor([598, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([60], "int64"))
torch.Tensor.device.__get__(Tensor([628, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([648, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([64], "int64"))
torch.Tensor.device.__get__(Tensor([662, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([690, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([712, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([716, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([80], "int64"))
torch.Tensor.device.__get__(Tensor([814, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([816, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([818, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([868, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([876, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([898, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([91], "int64"))
torch.Tensor.device.__get__(Tensor([956, 32000], "float32"))
torch.Tensor.device.__get__(Tensor([99], "int64"))
torch.Tensor.device.__get__(Tensor([], "float32"))
torch.Tensor.dim(Tensor([102], "int64"))
torch.Tensor.dim(Tensor([154], "int64"))
torch.Tensor.dim(Tensor([156], "int64"))
torch.Tensor.dim(Tensor([172], "int64"))
torch.Tensor.dim(Tensor([173], "int64"))
torch.Tensor.dim(Tensor([179], "int64"))
torch.Tensor.dim(Tensor([182], "int64"))
torch.Tensor.dim(Tensor([1], "int64"))
torch.Tensor.dim(Tensor([231], "int64"))
torch.Tensor.dim(Tensor([285], "int64"))
torch.Tensor.dim(Tensor([299], "int64"))
torch.Tensor.dim(Tensor([2], "int64"))
torch.Tensor.dim(Tensor([314], "int64"))
torch.Tensor.dim(Tensor([324], "int64"))
torch.Tensor.dim(Tensor([331], "int64"))
torch.Tensor.dim(Tensor([345], "int64"))
torch.Tensor.dim(Tensor([356], "int64"))
torch.Tensor.dim(Tensor([358], "int64"))
torch.Tensor.dim(Tensor([407], "int64"))
torch.Tensor.dim(Tensor([408], "int64"))
torch.Tensor.dim(Tensor([409], "int64"))
torch.Tensor.dim(Tensor([434], "int64"))
torch.Tensor.dim(Tensor([438], "int64"))
torch.Tensor.dim(Tensor([449], "int64"))
torch.Tensor.dim(Tensor([478], "int64"))
torch.Tensor.dim(Tensor([50], "int64"))
torch.Tensor.dim(Tensor([512], "int64"))
torch.Tensor.dim(Tensor([52], "int64"))
torch.Tensor.dim(Tensor([55], "int64"))
torch.Tensor.dim(Tensor([58], "int64"))
torch.Tensor.dim(Tensor([60], "int64"))
torch.Tensor.dim(Tensor([64], "int64"))
torch.Tensor.dim(Tensor([80], "int64"))
torch.Tensor.dim(Tensor([91], "int64"))
torch.Tensor.dim(Tensor([99], "int64"))
torch.Tensor.div(Tensor([32], "float32"), 64)
torch.Tensor.div(Tensor([], "float32"), 1)
torch.Tensor.div(Tensor([], "float32"), Tensor([], "int64"))
torch.Tensor.dtype.__get__("<Unserializable: Parameter>")
torch.Tensor.dtype.__get__(Tensor([16], "uint8"))
torch.Tensor.dtype.__get__(Tensor([2, 102, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 102, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 102], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 154, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 154, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 154], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 156, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 156, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 156], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 172, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 172, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 172], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 173, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 173, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 173], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 179, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 179, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 179], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 182, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 182, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 182], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 231, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 231, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 231], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 285, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 285, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 285], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 299, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 299, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 299], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 302], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 314, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 314, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 314], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 324, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 324, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 324], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 331, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 331, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 331], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 345, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 345, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 345], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 356, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 356, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 356], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 358, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 358, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 358], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 407, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 407, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 407], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 408, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 408, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 408], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 409, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 409, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 409], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 434, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 434, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 434], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 438, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 438, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 438], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 449, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 449, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 449], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 478, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 478, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 478], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 50, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 50, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 50], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 512, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 512, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 512], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 52, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 52, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 52], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 55, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 55, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 55], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 58, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 58, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 58], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 60, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 60, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 60], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 64, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 64, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 64], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 80, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 80, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 80], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 91, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 91, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 91], "int64"))
torch.Tensor.dtype.__get__(Tensor([2, 99, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 99, 32000], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2, 99], "int64"))
torch.Tensor.dtype.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([32], "float32"))
torch.Tensor.dtype.__get__(Tensor([5056], "uint8"))
torch.Tensor.dtype.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.dtype.__get__(Tensor([], "float32"))
torch.Tensor.element_size("<Unserializable: Parameter>")
torch.Tensor.expand(Tensor([1, 32, 1], "float32"), 1, -1, 1)
torch.Tensor.expand(Tensor([2, 4, 1, 102, 64], "bfloat16"), 2, 4, 8, 102, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 154, 64], "bfloat16"), 2, 4, 8, 154, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 156, 64], "bfloat16"), 2, 4, 8, 156, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 172, 64], "bfloat16"), 2, 4, 8, 172, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 173, 64], "bfloat16"), 2, 4, 8, 173, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 179, 64], "bfloat16"), 2, 4, 8, 179, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 182, 64], "bfloat16"), 2, 4, 8, 182, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 231, 64], "bfloat16"), 2, 4, 8, 231, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 285, 64], "bfloat16"), 2, 4, 8, 285, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 299, 64], "bfloat16"), 2, 4, 8, 299, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 314, 64], "bfloat16"), 2, 4, 8, 314, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 324, 64], "bfloat16"), 2, 4, 8, 324, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 331, 64], "bfloat16"), 2, 4, 8, 331, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 345, 64], "bfloat16"), 2, 4, 8, 345, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 356, 64], "bfloat16"), 2, 4, 8, 356, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 358, 64], "bfloat16"), 2, 4, 8, 358, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 407, 64], "bfloat16"), 2, 4, 8, 407, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 408, 64], "bfloat16"), 2, 4, 8, 408, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 409, 64], "bfloat16"), 2, 4, 8, 409, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 434, 64], "bfloat16"), 2, 4, 8, 434, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 438, 64], "bfloat16"), 2, 4, 8, 438, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 449, 64], "bfloat16"), 2, 4, 8, 449, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 478, 64], "bfloat16"), 2, 4, 8, 478, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 50, 64], "bfloat16"), 2, 4, 8, 50, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 512, 64], "bfloat16"), 2, 4, 8, 512, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 52, 64], "bfloat16"), 2, 4, 8, 52, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 55, 64], "bfloat16"), 2, 4, 8, 55, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 58, 64], "bfloat16"), 2, 4, 8, 58, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 60, 64], "bfloat16"), 2, 4, 8, 60, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 64, 64], "bfloat16"), 2, 4, 8, 64, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 80, 64], "bfloat16"), 2, 4, 8, 80, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 91, 64], "bfloat16"), 2, 4, 8, 91, 64)
torch.Tensor.expand(Tensor([2, 4, 1, 99, 64], "bfloat16"), 2, 4, 8, 99, 64)
torch.Tensor.float(Tensor([1, 1, 102], "float32"))
torch.Tensor.float(Tensor([1, 1, 102], "int64"))
torch.Tensor.float(Tensor([1, 1, 154], "float32"))
torch.Tensor.float(Tensor([1, 1, 154], "int64"))
torch.Tensor.float(Tensor([1, 1, 156], "float32"))
torch.Tensor.float(Tensor([1, 1, 156], "int64"))
torch.Tensor.float(Tensor([1, 1, 172], "float32"))
torch.Tensor.float(Tensor([1, 1, 172], "int64"))
torch.Tensor.float(Tensor([1, 1, 173], "float32"))
torch.Tensor.float(Tensor([1, 1, 173], "int64"))
torch.Tensor.float(Tensor([1, 1, 179], "float32"))
torch.Tensor.float(Tensor([1, 1, 179], "int64"))
torch.Tensor.float(Tensor([1, 1, 182], "float32"))
torch.Tensor.float(Tensor([1, 1, 182], "int64"))
torch.Tensor.float(Tensor([1, 1, 231], "float32"))
torch.Tensor.float(Tensor([1, 1, 231], "int64"))
torch.Tensor.float(Tensor([1, 1, 285], "float32"))
torch.Tensor.float(Tensor([1, 1, 285], "int64"))
torch.Tensor.float(Tensor([1, 1, 299], "float32"))
torch.Tensor.float(Tensor([1, 1, 299], "int64"))
torch.Tensor.float(Tensor([1, 1, 314], "float32"))
torch.Tensor.float(Tensor([1, 1, 314], "int64"))
torch.Tensor.float(Tensor([1, 1, 324], "float32"))
torch.Tensor.float(Tensor([1, 1, 324], "int64"))
torch.Tensor.float(Tensor([1, 1, 331], "float32"))
torch.Tensor.float(Tensor([1, 1, 331], "int64"))
torch.Tensor.float(Tensor([1, 1, 345], "float32"))
torch.Tensor.float(Tensor([1, 1, 345], "int64"))
torch.Tensor.float(Tensor([1, 1, 356], "float32"))
torch.Tensor.float(Tensor([1, 1, 356], "int64"))
torch.Tensor.float(Tensor([1, 1, 358], "float32"))
torch.Tensor.float(Tensor([1, 1, 358], "int64"))
torch.Tensor.float(Tensor([1, 1, 407], "float32"))
torch.Tensor.float(Tensor([1, 1, 407], "int64"))
torch.Tensor.float(Tensor([1, 1, 408], "float32"))
torch.Tensor.float(Tensor([1, 1, 408], "int64"))
torch.Tensor.float(Tensor([1, 1, 409], "float32"))
torch.Tensor.float(Tensor([1, 1, 409], "int64"))
torch.Tensor.float(Tensor([1, 1, 434], "float32"))
torch.Tensor.float(Tensor([1, 1, 434], "int64"))
torch.Tensor.float(Tensor([1, 1, 438], "float32"))
torch.Tensor.float(Tensor([1, 1, 438], "int64"))
torch.Tensor.float(Tensor([1, 1, 449], "float32"))
torch.Tensor.float(Tensor([1, 1, 449], "int64"))
torch.Tensor.float(Tensor([1, 1, 478], "float32"))
torch.Tensor.float(Tensor([1, 1, 478], "int64"))
torch.Tensor.float(Tensor([1, 1, 50], "float32"))
torch.Tensor.float(Tensor([1, 1, 50], "int64"))
torch.Tensor.float(Tensor([1, 1, 512], "float32"))
torch.Tensor.float(Tensor([1, 1, 512], "int64"))
torch.Tensor.float(Tensor([1, 1, 52], "float32"))
torch.Tensor.float(Tensor([1, 1, 52], "int64"))
torch.Tensor.float(Tensor([1, 1, 55], "float32"))
torch.Tensor.float(Tensor([1, 1, 55], "int64"))
torch.Tensor.float(Tensor([1, 1, 58], "float32"))
torch.Tensor.float(Tensor([1, 1, 58], "int64"))
torch.Tensor.float(Tensor([1, 1, 60], "float32"))
torch.Tensor.float(Tensor([1, 1, 60], "int64"))
torch.Tensor.float(Tensor([1, 1, 64], "float32"))
torch.Tensor.float(Tensor([1, 1, 64], "int64"))
torch.Tensor.float(Tensor([1, 1, 80], "float32"))
torch.Tensor.float(Tensor([1, 1, 80], "int64"))
torch.Tensor.float(Tensor([1, 1, 91], "float32"))
torch.Tensor.float(Tensor([1, 1, 91], "int64"))
torch.Tensor.float(Tensor([1, 1, 99], "float32"))
torch.Tensor.float(Tensor([1, 1, 99], "int64"))
torch.Tensor.float(Tensor([1, 32, 1], "float32"))
torch.Tensor.float(Tensor([2, 102, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 154, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 156, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 172, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 173, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 179, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 182, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 231, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 285, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 299, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 314, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 324, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 331, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 345, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 356, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 358, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 407, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 408, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 409, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 434, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 438, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 449, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 478, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 50, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 512, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 52, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 55, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 58, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 60, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 64, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 80, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 91, 32000], "bfloat16"))
torch.Tensor.float(Tensor([2, 99, 32000], "bfloat16"))
torch.Tensor.grad.__get__("<Unserializable: Parameter>")
torch.Tensor.grad.__set__("<Unserializable: Parameter>", None)
torch.Tensor.grad_fn.__get__("<Unserializable: Parameter>")
torch.Tensor.has_names(Tensor([16], "uint8"))
torch.Tensor.has_names(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.has_names(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.has_names(Tensor([2048], "bfloat16"))
torch.Tensor.has_names(Tensor([256, 2048], "bfloat16"))
torch.Tensor.has_names(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.has_names(Tensor([5056], "uint8"))
torch.Tensor.has_names(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.has_names(Tensor([], "float32"))
torch.Tensor.is_contiguous("<Unserializable: Parameter>")
torch.Tensor.is_contiguous(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.is_contiguous(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.is_contiguous(Tensor([2048], "bfloat16"))
torch.Tensor.is_contiguous(Tensor([256, 2048], "bfloat16"))
torch.Tensor.is_contiguous(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.is_contiguous(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.is_cpu.__get__(Tensor([], "float32"))
torch.Tensor.is_floating_point("<Unserializable: Parameter>")
torch.Tensor.is_leaf.__get__("<Unserializable: Parameter>")
torch.Tensor.is_meta.__get__("<Unserializable: Parameter>")
torch.Tensor.is_meta.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.is_meta.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.is_meta.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.is_meta.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.is_meta.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.is_meta.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([16], "uint8"))
torch.Tensor.is_nested.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([5056], "uint8"))
torch.Tensor.is_nested.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.is_nested.__get__(Tensor([], "float32"))
torch.Tensor.is_quantized.__get__(Tensor([16], "uint8"))
torch.Tensor.is_quantized.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.is_quantized.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.is_quantized.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.is_quantized.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.is_quantized.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.is_quantized.__get__(Tensor([5056], "uint8"))
torch.Tensor.is_quantized.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.is_quantized.__get__(Tensor([], "float32"))
torch.Tensor.is_sparse.__get__(Tensor([16], "uint8"))
torch.Tensor.is_sparse.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.is_sparse.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.is_sparse.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.is_sparse.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.is_sparse.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.is_sparse.__get__(Tensor([5056], "uint8"))
torch.Tensor.is_sparse.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.is_sparse.__get__(Tensor([], "float32"))
torch.Tensor.item(Tensor([], "float32"))
torch.Tensor.item(Tensor([], "int64"))
torch.Tensor.layout.__get__(Tensor([16], "uint8"))
torch.Tensor.layout.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.layout.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.layout.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.layout.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.layout.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.layout.__get__(Tensor([5056], "uint8"))
torch.Tensor.layout.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.layout.__get__(Tensor([], "float32"))
torch.Tensor.le(Tensor([], "int64"), Tensor([], "int64"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 102], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 154], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 156], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 172], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 173], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 179], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 182], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 231], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 285], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 299], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 314], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 324], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 331], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 345], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 356], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 358], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 407], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 408], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 409], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 434], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 438], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 449], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 478], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 50], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 512], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 52], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 55], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 58], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 60], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 64], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 80], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 91], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 99], "float32"))
torch.Tensor.mean(Tensor([2, 102, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 154, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 156, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 172, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 173, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 179, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 182, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 231, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 285, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 299, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 314, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 324, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 331, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 345, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 356, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 358, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 407, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 408, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 409, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 434, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 438, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 449, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 478, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 50, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 512, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 52, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 55, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 58, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 60, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 64, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 80, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 91, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mean(Tensor([2, 99, 2048], "float32"), -1, keepdim=True)
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 102, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 154, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 156, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 172, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 173, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 179, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 182, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 231, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 285, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 299, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 314, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 324, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 331, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 345, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 356, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 358, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 407, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 408, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 409, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 434, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 438, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 449, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 478, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 50, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 512, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 52, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 55, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 58, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 60, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 64, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 80, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 91, 2048], "bfloat16"))
torch.Tensor.mul("<Unserializable: Parameter>", Tensor([2, 99, 2048], "bfloat16"))
torch.Tensor.mul(Tensor([1, 102, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 154, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 156, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 172, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 173, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 179, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 182, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 231, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 285, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 299, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 314, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 324, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 331, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 345, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 356, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 358, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 407, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 408, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 409, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 434, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 438, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 449, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 478, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 50, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 512, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 52, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 55, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 58, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 60, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 64, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 80, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 91, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([1, 99, 64], "float32"), 1.0)
torch.Tensor.mul(Tensor([2, 102, 2048], "float32"), Tensor([2, 102, 1], "float32"))
torch.Tensor.mul(Tensor([2, 102, 5632], "bfloat16"), Tensor([2, 102, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 154, 2048], "float32"), Tensor([2, 154, 1], "float32"))
torch.Tensor.mul(Tensor([2, 154, 5632], "bfloat16"), Tensor([2, 154, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 156, 2048], "float32"), Tensor([2, 156, 1], "float32"))
torch.Tensor.mul(Tensor([2, 156, 5632], "bfloat16"), Tensor([2, 156, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 172, 2048], "float32"), Tensor([2, 172, 1], "float32"))
torch.Tensor.mul(Tensor([2, 172, 5632], "bfloat16"), Tensor([2, 172, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 173, 2048], "float32"), Tensor([2, 173, 1], "float32"))
torch.Tensor.mul(Tensor([2, 173, 5632], "bfloat16"), Tensor([2, 173, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 179, 2048], "float32"), Tensor([2, 179, 1], "float32"))
torch.Tensor.mul(Tensor([2, 179, 5632], "bfloat16"), Tensor([2, 179, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 182, 2048], "float32"), Tensor([2, 182, 1], "float32"))
torch.Tensor.mul(Tensor([2, 182, 5632], "bfloat16"), Tensor([2, 182, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 231, 2048], "float32"), Tensor([2, 231, 1], "float32"))
torch.Tensor.mul(Tensor([2, 231, 5632], "bfloat16"), Tensor([2, 231, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 285, 2048], "float32"), Tensor([2, 285, 1], "float32"))
torch.Tensor.mul(Tensor([2, 285, 5632], "bfloat16"), Tensor([2, 285, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 299, 2048], "float32"), Tensor([2, 299, 1], "float32"))
torch.Tensor.mul(Tensor([2, 299, 5632], "bfloat16"), Tensor([2, 299, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 314, 2048], "float32"), Tensor([2, 314, 1], "float32"))
torch.Tensor.mul(Tensor([2, 314, 5632], "bfloat16"), Tensor([2, 314, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 102, 64], "bfloat16"), Tensor([1, 1, 102, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 154, 64], "bfloat16"), Tensor([1, 1, 154, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 156, 64], "bfloat16"), Tensor([1, 1, 156, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 172, 64], "bfloat16"), Tensor([1, 1, 172, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 173, 64], "bfloat16"), Tensor([1, 1, 173, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 179, 64], "bfloat16"), Tensor([1, 1, 179, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 182, 64], "bfloat16"), Tensor([1, 1, 182, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 231, 64], "bfloat16"), Tensor([1, 1, 231, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 285, 64], "bfloat16"), Tensor([1, 1, 285, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 299, 64], "bfloat16"), Tensor([1, 1, 299, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 314, 64], "bfloat16"), Tensor([1, 1, 314, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 324, 64], "bfloat16"), Tensor([1, 1, 324, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 331, 64], "bfloat16"), Tensor([1, 1, 331, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 345, 64], "bfloat16"), Tensor([1, 1, 345, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 356, 64], "bfloat16"), Tensor([1, 1, 356, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 358, 64], "bfloat16"), Tensor([1, 1, 358, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 407, 64], "bfloat16"), Tensor([1, 1, 407, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 408, 64], "bfloat16"), Tensor([1, 1, 408, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 409, 64], "bfloat16"), Tensor([1, 1, 409, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 434, 64], "bfloat16"), Tensor([1, 1, 434, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 438, 64], "bfloat16"), Tensor([1, 1, 438, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 449, 64], "bfloat16"), Tensor([1, 1, 449, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 478, 64], "bfloat16"), Tensor([1, 1, 478, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 50, 64], "bfloat16"), Tensor([1, 1, 50, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 512, 64], "bfloat16"), Tensor([1, 1, 512, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 52, 64], "bfloat16"), Tensor([1, 1, 52, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 55, 64], "bfloat16"), Tensor([1, 1, 55, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 58, 64], "bfloat16"), Tensor([1, 1, 58, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 60, 64], "bfloat16"), Tensor([1, 1, 60, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 64, 64], "bfloat16"), Tensor([1, 1, 64, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 80, 64], "bfloat16"), Tensor([1, 1, 80, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 91, 64], "bfloat16"), Tensor([1, 1, 91, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 32, 99, 64], "bfloat16"), Tensor([1, 1, 99, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 324, 2048], "float32"), Tensor([2, 324, 1], "float32"))
torch.Tensor.mul(Tensor([2, 324, 5632], "bfloat16"), Tensor([2, 324, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 331, 2048], "float32"), Tensor([2, 331, 1], "float32"))
torch.Tensor.mul(Tensor([2, 331, 5632], "bfloat16"), Tensor([2, 331, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 345, 2048], "float32"), Tensor([2, 345, 1], "float32"))
torch.Tensor.mul(Tensor([2, 345, 5632], "bfloat16"), Tensor([2, 345, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 356, 2048], "float32"), Tensor([2, 356, 1], "float32"))
torch.Tensor.mul(Tensor([2, 356, 5632], "bfloat16"), Tensor([2, 356, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 358, 2048], "float32"), Tensor([2, 358, 1], "float32"))
torch.Tensor.mul(Tensor([2, 358, 5632], "bfloat16"), Tensor([2, 358, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 102, 64], "bfloat16"), Tensor([1, 1, 102, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 154, 64], "bfloat16"), Tensor([1, 1, 154, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 156, 64], "bfloat16"), Tensor([1, 1, 156, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 172, 64], "bfloat16"), Tensor([1, 1, 172, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 173, 64], "bfloat16"), Tensor([1, 1, 173, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 179, 64], "bfloat16"), Tensor([1, 1, 179, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 182, 64], "bfloat16"), Tensor([1, 1, 182, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 231, 64], "bfloat16"), Tensor([1, 1, 231, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 285, 64], "bfloat16"), Tensor([1, 1, 285, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 299, 64], "bfloat16"), Tensor([1, 1, 299, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 314, 64], "bfloat16"), Tensor([1, 1, 314, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 324, 64], "bfloat16"), Tensor([1, 1, 324, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 331, 64], "bfloat16"), Tensor([1, 1, 331, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 345, 64], "bfloat16"), Tensor([1, 1, 345, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 356, 64], "bfloat16"), Tensor([1, 1, 356, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 358, 64], "bfloat16"), Tensor([1, 1, 358, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 407, 64], "bfloat16"), Tensor([1, 1, 407, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 408, 64], "bfloat16"), Tensor([1, 1, 408, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 409, 64], "bfloat16"), Tensor([1, 1, 409, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 434, 64], "bfloat16"), Tensor([1, 1, 434, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 438, 64], "bfloat16"), Tensor([1, 1, 438, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 449, 64], "bfloat16"), Tensor([1, 1, 449, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 478, 64], "bfloat16"), Tensor([1, 1, 478, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 50, 64], "bfloat16"), Tensor([1, 1, 50, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 512, 64], "bfloat16"), Tensor([1, 1, 512, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 52, 64], "bfloat16"), Tensor([1, 1, 52, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 55, 64], "bfloat16"), Tensor([1, 1, 55, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 58, 64], "bfloat16"), Tensor([1, 1, 58, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 60, 64], "bfloat16"), Tensor([1, 1, 60, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 64, 64], "bfloat16"), Tensor([1, 1, 64, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 80, 64], "bfloat16"), Tensor([1, 1, 80, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 91, 64], "bfloat16"), Tensor([1, 1, 91, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 4, 99, 64], "bfloat16"), Tensor([1, 1, 99, 64], "bfloat16"))
torch.Tensor.mul(Tensor([2, 407, 2048], "float32"), Tensor([2, 407, 1], "float32"))
torch.Tensor.mul(Tensor([2, 407, 5632], "bfloat16"), Tensor([2, 407, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 408, 2048], "float32"), Tensor([2, 408, 1], "float32"))
torch.Tensor.mul(Tensor([2, 408, 5632], "bfloat16"), Tensor([2, 408, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 409, 2048], "float32"), Tensor([2, 409, 1], "float32"))
torch.Tensor.mul(Tensor([2, 409, 5632], "bfloat16"), Tensor([2, 409, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 434, 2048], "float32"), Tensor([2, 434, 1], "float32"))
torch.Tensor.mul(Tensor([2, 434, 5632], "bfloat16"), Tensor([2, 434, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 438, 2048], "float32"), Tensor([2, 438, 1], "float32"))
torch.Tensor.mul(Tensor([2, 438, 5632], "bfloat16"), Tensor([2, 438, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 449, 2048], "float32"), Tensor([2, 449, 1], "float32"))
torch.Tensor.mul(Tensor([2, 449, 5632], "bfloat16"), Tensor([2, 449, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 478, 2048], "float32"), Tensor([2, 478, 1], "float32"))
torch.Tensor.mul(Tensor([2, 478, 5632], "bfloat16"), Tensor([2, 478, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 50, 2048], "float32"), Tensor([2, 50, 1], "float32"))
torch.Tensor.mul(Tensor([2, 50, 5632], "bfloat16"), Tensor([2, 50, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 512, 2048], "float32"), Tensor([2, 512, 1], "float32"))
torch.Tensor.mul(Tensor([2, 512, 5632], "bfloat16"), Tensor([2, 512, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 52, 2048], "float32"), Tensor([2, 52, 1], "float32"))
torch.Tensor.mul(Tensor([2, 52, 5632], "bfloat16"), Tensor([2, 52, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 55, 2048], "float32"), Tensor([2, 55, 1], "float32"))
torch.Tensor.mul(Tensor([2, 55, 5632], "bfloat16"), Tensor([2, 55, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 58, 2048], "float32"), Tensor([2, 58, 1], "float32"))
torch.Tensor.mul(Tensor([2, 58, 5632], "bfloat16"), Tensor([2, 58, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 60, 2048], "float32"), Tensor([2, 60, 1], "float32"))
torch.Tensor.mul(Tensor([2, 60, 5632], "bfloat16"), Tensor([2, 60, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 64, 2048], "float32"), Tensor([2, 64, 1], "float32"))
torch.Tensor.mul(Tensor([2, 64, 5632], "bfloat16"), Tensor([2, 64, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 80, 2048], "float32"), Tensor([2, 80, 1], "float32"))
torch.Tensor.mul(Tensor([2, 80, 5632], "bfloat16"), Tensor([2, 80, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 91, 2048], "float32"), Tensor([2, 91, 1], "float32"))
torch.Tensor.mul(Tensor([2, 91, 5632], "bfloat16"), Tensor([2, 91, 5632], "bfloat16"))
torch.Tensor.mul(Tensor([2, 99, 2048], "float32"), Tensor([2, 99, 1], "float32"))
torch.Tensor.mul(Tensor([2, 99, 5632], "bfloat16"), Tensor([2, 99, 5632], "bfloat16"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 102, 102], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 154, 154], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 156, 156], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 172, 172], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 173, 173], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 179, 179], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 182, 182], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 231, 231], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 285, 285], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 299, 299], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 314, 314], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 324, 324], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 331, 331], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 345, 345], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 356, 356], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 358, 358], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 407, 407], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 408, 408], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 409, 409], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 434, 434], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 438, 438], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 449, 449], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 478, 478], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 50, 50], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 512, 512], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 52, 52], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 55, 55], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 58, 58], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 60, 60], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 64, 64], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 80, 80], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 91, 91], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 1, 99, 99], "bool"))
torch.Tensor.ndim.__get__(Tensor([2, 102], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 154], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 156], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 172], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 173], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 179], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 182], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 231], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 285], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 299], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 314], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 324], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 331], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 345], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 356], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 358], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 407], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 408], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 409], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 434], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 438], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 449], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 478], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 50], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 512], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 52], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 55], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 58], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 60], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 64], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 80], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 91], "int64"))
torch.Tensor.ndim.__get__(Tensor([2, 99], "int64"))
torch.Tensor.ne(Tensor([2, 102], "int64"), -100)
torch.Tensor.ne(Tensor([2, 154], "int64"), -100)
torch.Tensor.ne(Tensor([2, 156], "int64"), -100)
torch.Tensor.ne(Tensor([2, 172], "int64"), -100)
torch.Tensor.ne(Tensor([2, 173], "int64"), -100)
torch.Tensor.ne(Tensor([2, 179], "int64"), -100)
torch.Tensor.ne(Tensor([2, 182], "int64"), -100)
torch.Tensor.ne(Tensor([2, 231], "int64"), -100)
torch.Tensor.ne(Tensor([2, 285], "int64"), -100)
torch.Tensor.ne(Tensor([2, 299], "int64"), -100)
torch.Tensor.ne(Tensor([2, 314], "int64"), -100)
torch.Tensor.ne(Tensor([2, 324], "int64"), -100)
torch.Tensor.ne(Tensor([2, 331], "int64"), -100)
torch.Tensor.ne(Tensor([2, 345], "int64"), -100)
torch.Tensor.ne(Tensor([2, 356], "int64"), -100)
torch.Tensor.ne(Tensor([2, 358], "int64"), -100)
torch.Tensor.ne(Tensor([2, 407], "int64"), -100)
torch.Tensor.ne(Tensor([2, 408], "int64"), -100)
torch.Tensor.ne(Tensor([2, 409], "int64"), -100)
torch.Tensor.ne(Tensor([2, 434], "int64"), -100)
torch.Tensor.ne(Tensor([2, 438], "int64"), -100)
torch.Tensor.ne(Tensor([2, 449], "int64"), -100)
torch.Tensor.ne(Tensor([2, 478], "int64"), -100)
torch.Tensor.ne(Tensor([2, 50], "int64"), -100)
torch.Tensor.ne(Tensor([2, 512], "int64"), -100)
torch.Tensor.ne(Tensor([2, 52], "int64"), -100)
torch.Tensor.ne(Tensor([2, 55], "int64"), -100)
torch.Tensor.ne(Tensor([2, 58], "int64"), -100)
torch.Tensor.ne(Tensor([2, 60], "int64"), -100)
torch.Tensor.ne(Tensor([2, 64], "int64"), -100)
torch.Tensor.ne(Tensor([2, 80], "int64"), -100)
torch.Tensor.ne(Tensor([2, 91], "int64"), -100)
torch.Tensor.ne(Tensor([2, 99], "int64"), -100)
torch.Tensor.neg(Tensor([2, 32, 102, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 154, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 156, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 172, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 173, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 179, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 182, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 231, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 285, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 299, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 314, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 324, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 331, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 345, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 356, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 358, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 407, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 408, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 409, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 434, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 438, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 449, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 478, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 50, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 512, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 52, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 55, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 58, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 60, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 64, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 80, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 91, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 32, 99, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 102, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 154, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 156, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 172, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 173, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 179, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 182, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 231, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 285, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 299, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 314, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 324, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 331, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 345, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 356, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 358, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 407, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 408, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 409, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 434, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 438, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 449, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 478, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 50, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 512, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 52, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 55, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 58, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 60, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 64, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 80, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 91, 32], "bfloat16"))
torch.Tensor.neg(Tensor([2, 4, 99, 32], "bfloat16"))
torch.Tensor.numel("<Unserializable: Parameter>")
torch.Tensor.numel(Tensor([2, 102], "int64"))
torch.Tensor.numel(Tensor([2, 154], "int64"))
torch.Tensor.numel(Tensor([2, 156], "int64"))
torch.Tensor.numel(Tensor([2, 172], "int64"))
torch.Tensor.numel(Tensor([2, 173], "int64"))
torch.Tensor.numel(Tensor([2, 179], "int64"))
torch.Tensor.numel(Tensor([2, 182], "int64"))
torch.Tensor.numel(Tensor([2, 231], "int64"))
torch.Tensor.numel(Tensor([2, 285], "int64"))
torch.Tensor.numel(Tensor([2, 299], "int64"))
torch.Tensor.numel(Tensor([2, 314], "int64"))
torch.Tensor.numel(Tensor([2, 324], "int64"))
torch.Tensor.numel(Tensor([2, 331], "int64"))
torch.Tensor.numel(Tensor([2, 345], "int64"))
torch.Tensor.numel(Tensor([2, 356], "int64"))
torch.Tensor.numel(Tensor([2, 358], "int64"))
torch.Tensor.numel(Tensor([2, 407], "int64"))
torch.Tensor.numel(Tensor([2, 408], "int64"))
torch.Tensor.numel(Tensor([2, 409], "int64"))
torch.Tensor.numel(Tensor([2, 434], "int64"))
torch.Tensor.numel(Tensor([2, 438], "int64"))
torch.Tensor.numel(Tensor([2, 449], "int64"))
torch.Tensor.numel(Tensor([2, 478], "int64"))
torch.Tensor.numel(Tensor([2, 50], "int64"))
torch.Tensor.numel(Tensor([2, 512], "int64"))
torch.Tensor.numel(Tensor([2, 52], "int64"))
torch.Tensor.numel(Tensor([2, 55], "int64"))
torch.Tensor.numel(Tensor([2, 58], "int64"))
torch.Tensor.numel(Tensor([2, 60], "int64"))
torch.Tensor.numel(Tensor([2, 64], "int64"))
torch.Tensor.numel(Tensor([2, 80], "int64"))
torch.Tensor.numel(Tensor([2, 91], "int64"))
torch.Tensor.numel(Tensor([2, 99], "int64"))
torch.Tensor.numel(Tensor([32], "float32"))
torch.Tensor.pin_memory(Tensor([2, 102], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 154], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 156], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 172], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 173], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 179], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 182], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 231], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 285], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 299], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 302], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 314], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 324], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 331], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 345], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 356], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 358], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 407], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 408], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 409], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 434], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 438], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 449], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 478], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 50], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 512], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 52], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 55], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 58], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 60], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 64], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 80], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 91], "int64"), None)
torch.Tensor.pin_memory(Tensor([2, 99], "int64"), None)
torch.Tensor.pow(Tensor([2, 102, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 154, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 156, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 172, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 173, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 179, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 182, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 231, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 285, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 299, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 314, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 324, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 331, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 345, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 356, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 358, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 407, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 408, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 409, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 434, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 438, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 449, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 478, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 50, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 512, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 52, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 55, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 58, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 60, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 64, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 80, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 91, 2048], "float32"), 2)
torch.Tensor.pow(Tensor([2, 99, 2048], "float32"), 2)
torch.Tensor.random_(Tensor([], "int64"), generator=None)
torch.Tensor.requires_grad.__get__("<Unserializable: Parameter>")
torch.Tensor.requires_grad.__get__(Tensor([16], "uint8"))
torch.Tensor.requires_grad.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.requires_grad.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.requires_grad.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.requires_grad.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.requires_grad.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.requires_grad.__get__(Tensor([5056], "uint8"))
torch.Tensor.requires_grad.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.requires_grad.__get__(Tensor([], "float32"))
torch.Tensor.reshape(Tensor([11534336], "bfloat16"), list[2048, 5632])
torch.Tensor.reshape(Tensor([11534336], "bfloat16"), list[5632, 2048])
torch.Tensor.reshape(Tensor([2, 102, 32, 64], "bfloat16"), 2, 102, -1)
torch.Tensor.reshape(Tensor([2, 154, 32, 64], "bfloat16"), 2, 154, -1)
torch.Tensor.reshape(Tensor([2, 156, 32, 64], "bfloat16"), 2, 156, -1)
torch.Tensor.reshape(Tensor([2, 172, 32, 64], "bfloat16"), 2, 172, -1)
torch.Tensor.reshape(Tensor([2, 173, 32, 64], "bfloat16"), 2, 173, -1)
torch.Tensor.reshape(Tensor([2, 179, 32, 64], "bfloat16"), 2, 179, -1)
torch.Tensor.reshape(Tensor([2, 182, 32, 64], "bfloat16"), 2, 182, -1)
torch.Tensor.reshape(Tensor([2, 231, 32, 64], "bfloat16"), 2, 231, -1)
torch.Tensor.reshape(Tensor([2, 285, 32, 64], "bfloat16"), 2, 285, -1)
torch.Tensor.reshape(Tensor([2, 299, 32, 64], "bfloat16"), 2, 299, -1)
torch.Tensor.reshape(Tensor([2, 314, 32, 64], "bfloat16"), 2, 314, -1)
torch.Tensor.reshape(Tensor([2, 324, 32, 64], "bfloat16"), 2, 324, -1)
torch.Tensor.reshape(Tensor([2, 331, 32, 64], "bfloat16"), 2, 331, -1)
torch.Tensor.reshape(Tensor([2, 345, 32, 64], "bfloat16"), 2, 345, -1)
torch.Tensor.reshape(Tensor([2, 356, 32, 64], "bfloat16"), 2, 356, -1)
torch.Tensor.reshape(Tensor([2, 358, 32, 64], "bfloat16"), 2, 358, -1)
torch.Tensor.reshape(Tensor([2, 4, 8, 102, 64], "bfloat16"), 2, 32, 102, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 154, 64], "bfloat16"), 2, 32, 154, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 156, 64], "bfloat16"), 2, 32, 156, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 172, 64], "bfloat16"), 2, 32, 172, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 173, 64], "bfloat16"), 2, 32, 173, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 179, 64], "bfloat16"), 2, 32, 179, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 182, 64], "bfloat16"), 2, 32, 182, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 231, 64], "bfloat16"), 2, 32, 231, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 285, 64], "bfloat16"), 2, 32, 285, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 299, 64], "bfloat16"), 2, 32, 299, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 314, 64], "bfloat16"), 2, 32, 314, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 324, 64], "bfloat16"), 2, 32, 324, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 331, 64], "bfloat16"), 2, 32, 331, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 345, 64], "bfloat16"), 2, 32, 345, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 356, 64], "bfloat16"), 2, 32, 356, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 358, 64], "bfloat16"), 2, 32, 358, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 407, 64], "bfloat16"), 2, 32, 407, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 408, 64], "bfloat16"), 2, 32, 408, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 409, 64], "bfloat16"), 2, 32, 409, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 434, 64], "bfloat16"), 2, 32, 434, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 438, 64], "bfloat16"), 2, 32, 438, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 449, 64], "bfloat16"), 2, 32, 449, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 478, 64], "bfloat16"), 2, 32, 478, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 50, 64], "bfloat16"), 2, 32, 50, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 512, 64], "bfloat16"), 2, 32, 512, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 52, 64], "bfloat16"), 2, 32, 52, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 55, 64], "bfloat16"), 2, 32, 55, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 58, 64], "bfloat16"), 2, 32, 58, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 60, 64], "bfloat16"), 2, 32, 60, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 64, 64], "bfloat16"), 2, 32, 64, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 80, 64], "bfloat16"), 2, 32, 80, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 91, 64], "bfloat16"), 2, 32, 91, 64)
torch.Tensor.reshape(Tensor([2, 4, 8, 99, 64], "bfloat16"), 2, 32, 99, 64)
torch.Tensor.reshape(Tensor([2, 407, 32, 64], "bfloat16"), 2, 407, -1)
torch.Tensor.reshape(Tensor([2, 408, 32, 64], "bfloat16"), 2, 408, -1)
torch.Tensor.reshape(Tensor([2, 409, 32, 64], "bfloat16"), 2, 409, -1)
torch.Tensor.reshape(Tensor([2, 434, 32, 64], "bfloat16"), 2, 434, -1)
torch.Tensor.reshape(Tensor([2, 438, 32, 64], "bfloat16"), 2, 438, -1)
torch.Tensor.reshape(Tensor([2, 449, 32, 64], "bfloat16"), 2, 449, -1)
torch.Tensor.reshape(Tensor([2, 478, 32, 64], "bfloat16"), 2, 478, -1)
torch.Tensor.reshape(Tensor([2, 50, 32, 64], "bfloat16"), 2, 50, -1)
torch.Tensor.reshape(Tensor([2, 512, 32, 64], "bfloat16"), 2, 512, -1)
torch.Tensor.reshape(Tensor([2, 52, 32, 64], "bfloat16"), 2, 52, -1)
torch.Tensor.reshape(Tensor([2, 55, 32, 64], "bfloat16"), 2, 55, -1)
torch.Tensor.reshape(Tensor([2, 58, 32, 64], "bfloat16"), 2, 58, -1)
torch.Tensor.reshape(Tensor([2, 60, 32, 64], "bfloat16"), 2, 60, -1)
torch.Tensor.reshape(Tensor([2, 64, 32, 64], "bfloat16"), 2, 64, -1)
torch.Tensor.reshape(Tensor([2, 80, 32, 64], "bfloat16"), 2, 80, -1)
torch.Tensor.reshape(Tensor([2, 91, 32, 64], "bfloat16"), 2, 91, -1)
torch.Tensor.reshape(Tensor([2, 99, 32, 64], "bfloat16"), 2, 99, -1)
torch.Tensor.reshape(Tensor([2048], "bfloat16"), list[2048])
torch.Tensor.reshape(Tensor([4194304], "bfloat16"), list[2048, 2048])
torch.Tensor.reshape(Tensor([524288], "bfloat16"), list[256, 2048])
torch.Tensor.reshape(Tensor([65536000], "bfloat16"), list[32000, 2048])
torch.Tensor.shape.__get__("<Unserializable: Parameter>")
torch.Tensor.shape.__get__(Tensor([1, 102], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 154], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 156], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 172], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 173], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 179], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 182], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 231], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 285], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 299], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 314], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 324], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 331], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 345], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 356], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 358], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 407], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 408], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 409], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 434], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 438], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 449], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 478], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 50], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 512], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 52], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 55], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 58], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 60], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 64], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 80], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 91], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 99], "int64"))
torch.Tensor.shape.__get__(Tensor([102], "int64"))
torch.Tensor.shape.__get__(Tensor([154], "int64"))
torch.Tensor.shape.__get__(Tensor([156], "int64"))
torch.Tensor.shape.__get__(Tensor([172], "int64"))
torch.Tensor.shape.__get__(Tensor([173], "int64"))
torch.Tensor.shape.__get__(Tensor([179], "int64"))
torch.Tensor.shape.__get__(Tensor([182], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 102, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 102], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 102], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 154, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 154], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 154], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 156, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 156], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 156], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 172, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 172], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 172], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 173, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 173], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 173], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 179, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 179], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 179], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 182, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 182], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 182], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 231, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 231], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 231], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 285, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 285], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 285], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 299, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 299], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 299], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 302], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 314, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 314], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 314], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 32, 102, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 154, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 156, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 172, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 173, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 179, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 182, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 231, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 285, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 299, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 314, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 324, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 331, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 345, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 356, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 358, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 407, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 408, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 409, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 434, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 438, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 449, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 478, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 50, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 512, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 52, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 55, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 58, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 60, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 64, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 80, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 91, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 32, 99, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 324, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 324], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 324], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 331, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 331], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 331], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 345, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 345], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 345], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 356, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 356], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 356], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 358, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 358], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 358], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 4, 102, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 154, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 156, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 172, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 173, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 179, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 182, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 231, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 285, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 299, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 314, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 324, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 331, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 345, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 356, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 358, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 407, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 408, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 409, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 434, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 438, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 449, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 478, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 50, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 512, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 52, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 55, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 58, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 60, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 64, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 80, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 91, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 4, 99, 64], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 407, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 407], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 407], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 408, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 408], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 408], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 409, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 409], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 409], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 434, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 434], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 434], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 438, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 438], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 438], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 449, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 449], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 449], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 478, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 478], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 478], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 50, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 50], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 50], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 512, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 512], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 512], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 52, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 52], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 52], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 55, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 55], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 55], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 58, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 58], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 58], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 60, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 60], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 60], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 64, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 64], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 64], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 80, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 80], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 80], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 91, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 91], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 91], "int64"))
torch.Tensor.shape.__get__(Tensor([2, 99, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2, 99], "bool"))
torch.Tensor.shape.__get__(Tensor([2, 99], "int64"))
torch.Tensor.shape.__get__(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([231], "int64"))
torch.Tensor.shape.__get__(Tensor([256, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([285], "int64"))
torch.Tensor.shape.__get__(Tensor([299], "int64"))
torch.Tensor.shape.__get__(Tensor([314], "int64"))
torch.Tensor.shape.__get__(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([324], "int64"))
torch.Tensor.shape.__get__(Tensor([331], "int64"))
torch.Tensor.shape.__get__(Tensor([345], "int64"))
torch.Tensor.shape.__get__(Tensor([356], "int64"))
torch.Tensor.shape.__get__(Tensor([358], "int64"))
torch.Tensor.shape.__get__(Tensor([407], "int64"))
torch.Tensor.shape.__get__(Tensor([408], "int64"))
torch.Tensor.shape.__get__(Tensor([409], "int64"))
torch.Tensor.shape.__get__(Tensor([434], "int64"))
torch.Tensor.shape.__get__(Tensor([438], "int64"))
torch.Tensor.shape.__get__(Tensor([449], "int64"))
torch.Tensor.shape.__get__(Tensor([478], "int64"))
torch.Tensor.shape.__get__(Tensor([50], "int64"))
torch.Tensor.shape.__get__(Tensor([512], "int64"))
torch.Tensor.shape.__get__(Tensor([52], "int64"))
torch.Tensor.shape.__get__(Tensor([55], "int64"))
torch.Tensor.shape.__get__(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.shape.__get__(Tensor([58], "int64"))
torch.Tensor.shape.__get__(Tensor([60], "int64"))
torch.Tensor.shape.__get__(Tensor([64], "int64"))
torch.Tensor.shape.__get__(Tensor([80], "int64"))
torch.Tensor.shape.__get__(Tensor([91], "int64"))
torch.Tensor.shape.__get__(Tensor([99], "int64"))
torch.Tensor.share_memory_(Tensor([], "int64"))
torch.Tensor.sin(Tensor([1, 102, 64], "float32"))
torch.Tensor.sin(Tensor([1, 154, 64], "float32"))
torch.Tensor.sin(Tensor([1, 156, 64], "float32"))
torch.Tensor.sin(Tensor([1, 172, 64], "float32"))
torch.Tensor.sin(Tensor([1, 173, 64], "float32"))
torch.Tensor.sin(Tensor([1, 179, 64], "float32"))
torch.Tensor.sin(Tensor([1, 182, 64], "float32"))
torch.Tensor.sin(Tensor([1, 231, 64], "float32"))
torch.Tensor.sin(Tensor([1, 285, 64], "float32"))
torch.Tensor.sin(Tensor([1, 299, 64], "float32"))
torch.Tensor.sin(Tensor([1, 314, 64], "float32"))
torch.Tensor.sin(Tensor([1, 324, 64], "float32"))
torch.Tensor.sin(Tensor([1, 331, 64], "float32"))
torch.Tensor.sin(Tensor([1, 345, 64], "float32"))
torch.Tensor.sin(Tensor([1, 356, 64], "float32"))
torch.Tensor.sin(Tensor([1, 358, 64], "float32"))
torch.Tensor.sin(Tensor([1, 407, 64], "float32"))
torch.Tensor.sin(Tensor([1, 408, 64], "float32"))
torch.Tensor.sin(Tensor([1, 409, 64], "float32"))
torch.Tensor.sin(Tensor([1, 434, 64], "float32"))
torch.Tensor.sin(Tensor([1, 438, 64], "float32"))
torch.Tensor.sin(Tensor([1, 449, 64], "float32"))
torch.Tensor.sin(Tensor([1, 478, 64], "float32"))
torch.Tensor.sin(Tensor([1, 50, 64], "float32"))
torch.Tensor.sin(Tensor([1, 512, 64], "float32"))
torch.Tensor.sin(Tensor([1, 52, 64], "float32"))
torch.Tensor.sin(Tensor([1, 55, 64], "float32"))
torch.Tensor.sin(Tensor([1, 58, 64], "float32"))
torch.Tensor.sin(Tensor([1, 60, 64], "float32"))
torch.Tensor.sin(Tensor([1, 64, 64], "float32"))
torch.Tensor.sin(Tensor([1, 80, 64], "float32"))
torch.Tensor.sin(Tensor([1, 91, 64], "float32"))
torch.Tensor.sin(Tensor([1, 99, 64], "float32"))
torch.Tensor.size(Tensor([102], "int64"), 0)
torch.Tensor.size(Tensor([154], "int64"), 0)
torch.Tensor.size(Tensor([156], "int64"), 0)
torch.Tensor.size(Tensor([16], "uint8"))
torch.Tensor.size(Tensor([172], "int64"), 0)
torch.Tensor.size(Tensor([173], "int64"), 0)
torch.Tensor.size(Tensor([179], "int64"), 0)
torch.Tensor.size(Tensor([182], "int64"), 0)
torch.Tensor.size(Tensor([1], "int64"), 0)
torch.Tensor.size(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.size(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.size(Tensor([2048], "bfloat16"))
torch.Tensor.size(Tensor([231], "int64"), 0)
torch.Tensor.size(Tensor([256, 2048], "bfloat16"))
torch.Tensor.size(Tensor([285], "int64"), 0)
torch.Tensor.size(Tensor([299], "int64"), 0)
torch.Tensor.size(Tensor([2], "int64"), 0)
torch.Tensor.size(Tensor([314], "int64"), 0)
torch.Tensor.size(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.size(Tensor([324], "int64"), 0)
torch.Tensor.size(Tensor([331], "int64"), 0)
torch.Tensor.size(Tensor([345], "int64"), 0)
torch.Tensor.size(Tensor([356], "int64"), 0)
torch.Tensor.size(Tensor([358], "int64"), 0)
torch.Tensor.size(Tensor([407], "int64"), 0)
torch.Tensor.size(Tensor([408], "int64"), 0)
torch.Tensor.size(Tensor([409], "int64"), 0)
torch.Tensor.size(Tensor([434], "int64"), 0)
torch.Tensor.size(Tensor([438], "int64"), 0)
torch.Tensor.size(Tensor([449], "int64"), 0)
torch.Tensor.size(Tensor([478], "int64"), 0)
torch.Tensor.size(Tensor([5056], "uint8"))
torch.Tensor.size(Tensor([50], "int64"), 0)
torch.Tensor.size(Tensor([512], "int64"), 0)
torch.Tensor.size(Tensor([52], "int64"), 0)
torch.Tensor.size(Tensor([55], "int64"), 0)
torch.Tensor.size(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.size(Tensor([58], "int64"), 0)
torch.Tensor.size(Tensor([60], "int64"), 0)
torch.Tensor.size(Tensor([64], "int64"), 0)
torch.Tensor.size(Tensor([80], "int64"), 0)
torch.Tensor.size(Tensor([91], "int64"), 0)
torch.Tensor.size(Tensor([99], "int64"), 0)
torch.Tensor.size(Tensor([], "float32"))
torch.Tensor.storage_offset(Tensor([16], "uint8"))
torch.Tensor.storage_offset(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.storage_offset(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.storage_offset(Tensor([2048], "bfloat16"))
torch.Tensor.storage_offset(Tensor([256, 2048], "bfloat16"))
torch.Tensor.storage_offset(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.storage_offset(Tensor([5056], "uint8"))
torch.Tensor.storage_offset(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.storage_offset(Tensor([], "float32"))
torch.Tensor.sum(Tensor([2, 102], "bool"))
torch.Tensor.sum(Tensor([2, 154], "bool"))
torch.Tensor.sum(Tensor([2, 156], "bool"))
torch.Tensor.sum(Tensor([2, 172], "bool"))
torch.Tensor.sum(Tensor([2, 173], "bool"))
torch.Tensor.sum(Tensor([2, 179], "bool"))
torch.Tensor.sum(Tensor([2, 182], "bool"))
torch.Tensor.sum(Tensor([2, 231], "bool"))
torch.Tensor.sum(Tensor([2, 285], "bool"))
torch.Tensor.sum(Tensor([2, 299], "bool"))
torch.Tensor.sum(Tensor([2, 314], "bool"))
torch.Tensor.sum(Tensor([2, 324], "bool"))
torch.Tensor.sum(Tensor([2, 331], "bool"))
torch.Tensor.sum(Tensor([2, 345], "bool"))
torch.Tensor.sum(Tensor([2, 356], "bool"))
torch.Tensor.sum(Tensor([2, 358], "bool"))
torch.Tensor.sum(Tensor([2, 407], "bool"))
torch.Tensor.sum(Tensor([2, 408], "bool"))
torch.Tensor.sum(Tensor([2, 409], "bool"))
torch.Tensor.sum(Tensor([2, 434], "bool"))
torch.Tensor.sum(Tensor([2, 438], "bool"))
torch.Tensor.sum(Tensor([2, 449], "bool"))
torch.Tensor.sum(Tensor([2, 478], "bool"))
torch.Tensor.sum(Tensor([2, 50], "bool"))
torch.Tensor.sum(Tensor([2, 512], "bool"))
torch.Tensor.sum(Tensor([2, 52], "bool"))
torch.Tensor.sum(Tensor([2, 55], "bool"))
torch.Tensor.sum(Tensor([2, 58], "bool"))
torch.Tensor.sum(Tensor([2, 60], "bool"))
torch.Tensor.sum(Tensor([2, 64], "bool"))
torch.Tensor.sum(Tensor([2, 80], "bool"))
torch.Tensor.sum(Tensor([2, 91], "bool"))
torch.Tensor.sum(Tensor([2, 99], "bool"))
torch.Tensor.to("<Unserializable: Parameter>", "meta")
torch.Tensor.to("<Unserializable: Parameter>", 0, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 1, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 2, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 3, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 4, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 5, non_blocking=False)
torch.Tensor.to("<Unserializable: Parameter>", 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 102, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 102], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 102], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 102], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 102], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 102], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 102], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 102], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 154, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 154], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 154], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 154], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 154], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 154], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 154], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 154], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 156, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 156], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 156], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 156], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 156], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 156], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 156], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 156], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 172, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 172], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 172], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 172], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 172], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 172], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 172], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 172], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 173, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 173], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 173], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 173], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 173], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 173], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 173], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 173], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 179, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 179], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 179], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 179], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 179], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 179], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 179], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 179], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 182, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 182], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 182], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 182], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 182], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 182], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 182], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 182], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 231, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 231], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 231], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 231], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 231], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 231], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 231], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 231], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 285, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 285], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 285], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 285], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 285], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 285], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 285], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 285], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 299, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 299], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 299], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 299], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 299], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 299], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 299], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 299], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 314, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 314], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 314], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 314], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 314], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 314], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 314], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 314], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 32, 1], "float32"), "cuda:6")
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 324, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 324], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 324], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 324], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 324], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 324], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 324], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 324], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 331, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 331], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 331], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 331], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 331], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 331], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 331], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 331], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 345, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 345], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 345], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 345], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 345], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 345], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 345], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 345], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 356, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 356], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 356], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 356], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 356], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 356], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 356], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 356], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 358, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 358], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 358], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 358], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 358], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 358], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 358], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 358], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 407, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 407], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 407], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 407], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 407], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 407], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 407], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 407], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 408, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 408], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 408], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 408], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 408], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 408], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 408], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 408], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 409, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 409], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 409], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 409], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 409], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 409], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 409], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 409], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 434, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 434], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 434], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 434], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 434], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 434], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 434], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 434], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 438, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 438], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 438], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 438], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 438], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 438], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 438], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 438], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 449, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 449], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 449], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 449], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 449], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 449], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 449], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 449], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 478, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 478], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 478], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 478], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 478], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 478], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 478], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 478], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 50, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 50], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 50], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 50], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 50], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 50], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 50], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 50], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 512, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 512], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 512], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 512], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 512], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 512], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 512], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 512], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 52, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 52], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 52], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 52], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 52], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 52], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 52], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 52], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 55, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 55], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 55], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 55], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 55], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 55], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 55], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 55], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 58, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 58], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 58], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 58], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 58], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 58], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 58], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 58], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 60, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 60], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 60], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 60], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 60], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 60], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 60], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 60], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 64, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 64], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 64], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 64], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 64], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 64], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 64], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 64], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 80, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 80], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 80], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 80], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 80], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 80], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 80], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 80], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 91, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 91], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 91], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 91], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 91], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 91], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 91], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 91], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([1, 99, 64], "float32"), dtype="bfloat16")
torch.Tensor.to(Tensor([1, 99], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([1, 99], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([1, 99], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([1, 99], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([1, 99], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([1, 99], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([1, 99], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([100], "int64"), "cuda:6")
torch.Tensor.to(Tensor([1024], "int64"), "cuda:6")
torch.Tensor.to(Tensor([102], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([102], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([102], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([102], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([102], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([102], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([102], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([104], "int64"), "cuda:6")
torch.Tensor.to(Tensor([110], "int64"), "cuda:6")
torch.Tensor.to(Tensor([116], "int64"), "cuda:6")
torch.Tensor.to(Tensor([120], "int64"), "cuda:6")
torch.Tensor.to(Tensor([128], "int64"), "cuda:6")
torch.Tensor.to(Tensor([154], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([154], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([154], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([154], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([154], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([154], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([154], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([156], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([160], "int64"), "cuda:6")
torch.Tensor.to(Tensor([172], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([172], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([172], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([172], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([172], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([172], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([172], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([173], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([179], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), "cuda:6")
torch.Tensor.to(Tensor([182], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([182], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([198], "int64"), "cuda:6")
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 102, 102], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 154, 154], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 156, 156], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 172, 172], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 173, 173], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 179, 179], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 182, 182], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 231, 231], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 285, 285], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 299, 299], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 314, 314], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 324, 324], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 331, 331], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 345, 345], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 356, 356], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 358, 358], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 407, 407], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 408, 408], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 409, 409], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 434, 434], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 438, 438], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 449, 449], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 478, 478], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 50, 50], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 512, 512], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 52, 52], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 55, 55], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 58, 58], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 60, 60], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 64, 64], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 80, 80], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 91, 91], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 1, 99, 99], "bool"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 102, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 102, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 102], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 102], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 102], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 102], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 154, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 154, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 154], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 154], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 154], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 154], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 156, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 156, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 156], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 156], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 156], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 156], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 172, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 172, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 172], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 172], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 172], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 172], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 173, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 173, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 173], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 173], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 173], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 173], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 179, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 179, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 179], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 179], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 179], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 179], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 182, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 182, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 182], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 182], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 182], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 182], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 231, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 231, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 231], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 231], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 231], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 231], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 285, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 285, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 285], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 285], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 285], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 285], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 299, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 299, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 299], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 299], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 299], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 299], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 314, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 314, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 314], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 314], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 314], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 314], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 324, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 324, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 324], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 324], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 324], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 324], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 331, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 331, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 331], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 331], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 331], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 331], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 345, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 345, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 345], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 345], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 345], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 345], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 356, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 356, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 356], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 356], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 356], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 356], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 358, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 358, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 358], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 358], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 358], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 358], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 407, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 407, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 407], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 407], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 407], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 407], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 408, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 408, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 408], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 408], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 408], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 408], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 409, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 409, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 409], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 409], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 409], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 409], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 434, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 434, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 434], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 434], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 434], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 434], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 438, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 438, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 438], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 438], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 438], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 438], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 449, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 449, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 449], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 449], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 449], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 449], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 478, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 478, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 478], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 478], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 478], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 478], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 50, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 50, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 50], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 50], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 50], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 50], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 512, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 512, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 512], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 512], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 512], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 512], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 52, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 52, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 52], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 52], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 52], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 52], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 55, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 55, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 55], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 55], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 55], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 55], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 58, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 58, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 58], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 58], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 58], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 58], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 60, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 60, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 60], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 60], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 60], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 60], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 64, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 64, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 64], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 64], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 64], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 64], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 80, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 80, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 80], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 80], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 80], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 80], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 91, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 91, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 91], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 91], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 91], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 91], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), "float32")
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 2048], "float32"), "bfloat16")
torch.Tensor.to(Tensor([2, 99, 32000], "bfloat16"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 1, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 2, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 3, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 4, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 5, non_blocking=False)
torch.Tensor.to(Tensor([2, 99, 5632], "bfloat16"), 6, non_blocking=False)
torch.Tensor.to(Tensor([2, 99], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([2, 99], "int64"), device="cuda", non_blocking=False)
torch.Tensor.to(Tensor([2, 99], "int64"), device="cuda:0")
torch.Tensor.to(Tensor([2, 99], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), "bfloat16")
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), "cpu")
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 0)
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 1)
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 2)
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 3)
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 4)
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 5)
torch.Tensor.to(Tensor([2048, 2048], "bfloat16"), 6)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), "bfloat16")
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), "cpu")
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 0)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 1)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 2)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 3)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 4)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 5)
torch.Tensor.to(Tensor([2048, 5632], "bfloat16"), 6)
torch.Tensor.to(Tensor([2048], "bfloat16"), "bfloat16")
torch.Tensor.to(Tensor([2048], "bfloat16"), "cpu")
torch.Tensor.to(Tensor([2048], "bfloat16"), 0)
torch.Tensor.to(Tensor([2048], "bfloat16"), 1)
torch.Tensor.to(Tensor([2048], "bfloat16"), 2)
torch.Tensor.to(Tensor([2048], "bfloat16"), 3)
torch.Tensor.to(Tensor([2048], "bfloat16"), 4)
torch.Tensor.to(Tensor([2048], "bfloat16"), 5)
torch.Tensor.to(Tensor([2048], "bfloat16"), 6)
torch.Tensor.to(Tensor([204], "int64"), "cuda:6")
torch.Tensor.to(Tensor([231], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([231], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([231], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([231], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([231], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([231], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([231], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), "bfloat16")
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), "cpu")
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 0)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 1)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 2)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 3)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 4)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 5)
torch.Tensor.to(Tensor([256, 2048], "bfloat16"), 6)
torch.Tensor.to(Tensor([285], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([285], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([285], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([285], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([285], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([285], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([285], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([299], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([308], "int64"), "cuda:6")
torch.Tensor.to(Tensor([312], "int64"), "cuda:6")
torch.Tensor.to(Tensor([314], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([314], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([314], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([314], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([314], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([314], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([314], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([32000, 2048], "bfloat16"), "bfloat16")
torch.Tensor.to(Tensor([32000, 2048], "bfloat16"), "cpu")
torch.Tensor.to(Tensor([32000, 2048], "bfloat16"), 0)
torch.Tensor.to(Tensor([32000, 2048], "bfloat16"), 6)
torch.Tensor.to(Tensor([324], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([324], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([324], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([324], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([324], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([324], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([324], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([32], "float32"), 6, non_blocking=False)
torch.Tensor.to(Tensor([32], "int64"), device=None, dtype="float32")
torch.Tensor.to(Tensor([331], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([331], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([331], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([331], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([331], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([331], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([331], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([344], "int64"), "cuda:6")
torch.Tensor.to(Tensor([345], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([345], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([345], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([345], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([345], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([345], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([345], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([346], "int64"), "cuda:6")
torch.Tensor.to(Tensor([356], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([356], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([356], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([356], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([356], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([356], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([356], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), "cuda:6")
torch.Tensor.to(Tensor([358], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([358], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([364], "int64"), "cuda:6")
torch.Tensor.to(Tensor([407], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([407], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([407], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([407], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([407], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([407], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([407], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([408], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([409], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([434], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([438], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([449], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([462], "int64"), "cuda:6")
torch.Tensor.to(Tensor([478], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([478], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([478], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([478], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([478], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([478], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([478], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([50], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([512], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([52], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([55], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), "bfloat16")
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), "cpu")
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 0)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 1)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 2)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 3)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 4)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 5)
torch.Tensor.to(Tensor([5632, 2048], "bfloat16"), 6)
torch.Tensor.to(Tensor([570], "int64"), "cuda:6")
torch.Tensor.to(Tensor([58], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([58], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([58], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([58], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([58], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([58], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([58], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([598], "int64"), "cuda:6")
torch.Tensor.to(Tensor([60], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([60], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([60], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([60], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([60], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([60], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([60], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([628], "int64"), "cuda:6")
torch.Tensor.to(Tensor([648], "int64"), "cuda:6")
torch.Tensor.to(Tensor([64], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([64], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([64], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([64], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([64], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([64], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([64], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([662], "int64"), "cuda:6")
torch.Tensor.to(Tensor([690], "int64"), "cuda:6")
torch.Tensor.to(Tensor([712], "int64"), "cuda:6")
torch.Tensor.to(Tensor([716], "int64"), "cuda:6")
torch.Tensor.to(Tensor([80], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([80], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([80], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([80], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([80], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([80], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([80], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([814], "int64"), "cuda:6")
torch.Tensor.to(Tensor([816], "int64"), "cuda:6")
torch.Tensor.to(Tensor([818], "int64"), "cuda:6")
torch.Tensor.to(Tensor([868], "int64"), "cuda:6")
torch.Tensor.to(Tensor([876], "int64"), "cuda:6")
torch.Tensor.to(Tensor([898], "int64"), "cuda:6")
torch.Tensor.to(Tensor([91], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([91], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([91], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([91], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([91], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([91], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([91], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([956], "int64"), "cuda:6")
torch.Tensor.to(Tensor([99], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([99], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([99], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([99], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([99], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([99], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([99], "int64"), 6, non_blocking=False)
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:0")
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:1")
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:2")
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:3")
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:4")
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:5")
torch.Tensor.to(Tensor([], "bfloat16"), "cuda:6")
torch.Tensor.to(Tensor([], "float32"), "cuda:0", non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), "cuda:0")
torch.Tensor.to(Tensor([], "int64"), "cuda:6")
torch.Tensor.to(Tensor([], "int64"), 0, non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), 1, non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), 2, non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), 3, non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), 4, non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), 5, non_blocking=False)
torch.Tensor.to(Tensor([], "int64"), 6, non_blocking=False)
torch.Tensor.transpose(Tensor([1, 32, 102], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 154], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 156], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 172], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 173], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 179], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 182], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 231], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 285], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 299], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 314], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 324], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 331], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 345], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 356], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 358], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 407], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 408], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 409], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 434], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 438], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 449], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 478], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 50], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 512], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 52], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 55], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 58], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 60], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 64], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 80], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 91], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([1, 32, 99], "float32"), 1, 2)
torch.Tensor.transpose(Tensor([2, 102, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 102, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 154, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 154, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 156, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 156, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 172, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 172, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 173, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 173, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 179, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 179, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 182, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 182, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 231, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 231, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 285, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 285, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 299, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 299, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 314, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 314, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 102, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 154, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 156, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 172, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 173, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 179, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 182, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 231, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 285, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 299, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 314, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 324, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 331, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 345, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 356, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 358, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 407, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 408, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 409, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 434, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 438, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 449, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 478, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 50, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 512, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 52, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 55, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 58, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 60, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 64, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 80, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 91, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 32, 99, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 324, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 324, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 331, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 331, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 345, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 345, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 356, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 356, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 358, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 358, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 407, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 407, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 408, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 408, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 409, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 409, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 434, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 434, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 438, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 438, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 449, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 449, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 478, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 478, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 50, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 50, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 512, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 512, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 52, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 52, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 55, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 55, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 58, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 58, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 60, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 60, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 64, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 64, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 80, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 80, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 91, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 91, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 99, 32, 64], "bfloat16"), 1, 2)
torch.Tensor.transpose(Tensor([2, 99, 4, 64], "bfloat16"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 102, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 154, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 156, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 172, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 173, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 179, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 182, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 231, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 285, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 299, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 314, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 324, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 331, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 345, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 356, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 358, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 407, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 408, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 409, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 434, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 438, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 449, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 478, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 50, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 512, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 52, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 55, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 58, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 60, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 64, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 80, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 91, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([1, 99, 64], "bfloat16"), 1)
torch.Tensor.unsqueeze(Tensor([102], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([154], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([156], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([172], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([173], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([179], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([182], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([231], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([285], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([299], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([314], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([324], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([331], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([345], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([356], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([358], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([407], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([408], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([409], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([434], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([438], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([449], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([478], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([50], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([512], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([52], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([55], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([58], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([60], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([64], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([80], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([91], "int64"), 0)
torch.Tensor.unsqueeze(Tensor([99], "int64"), 0)
torch.Tensor.untyped_storage(Tensor([16], "uint8"))
torch.Tensor.untyped_storage(Tensor([2048, 2048], "bfloat16"))
torch.Tensor.untyped_storage(Tensor([2048, 5632], "bfloat16"))
torch.Tensor.untyped_storage(Tensor([2048], "bfloat16"))
torch.Tensor.untyped_storage(Tensor([256, 2048], "bfloat16"))
torch.Tensor.untyped_storage(Tensor([32000, 2048], "bfloat16"))
torch.Tensor.untyped_storage(Tensor([5056], "uint8"))
torch.Tensor.untyped_storage(Tensor([5632, 2048], "bfloat16"))
torch.Tensor.untyped_storage(Tensor([], "float32"))
torch.Tensor.view(Tensor([1048576], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([131072000], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([2, 102, 2048], "bfloat16"), tuple(2, 102, -1, 64))
torch.Tensor.view(Tensor([2, 102, 256], "bfloat16"), tuple(2, 102, -1, 64))
torch.Tensor.view(Tensor([2, 102, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 102], "int64"), -1)
torch.Tensor.view(Tensor([2, 154, 2048], "bfloat16"), tuple(2, 154, -1, 64))
torch.Tensor.view(Tensor([2, 154, 256], "bfloat16"), tuple(2, 154, -1, 64))
torch.Tensor.view(Tensor([2, 154, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 154], "int64"), -1)
torch.Tensor.view(Tensor([2, 156, 2048], "bfloat16"), tuple(2, 156, -1, 64))
torch.Tensor.view(Tensor([2, 156, 256], "bfloat16"), tuple(2, 156, -1, 64))
torch.Tensor.view(Tensor([2, 156, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 156], "int64"), -1)
torch.Tensor.view(Tensor([2, 172, 2048], "bfloat16"), tuple(2, 172, -1, 64))
torch.Tensor.view(Tensor([2, 172, 256], "bfloat16"), tuple(2, 172, -1, 64))
torch.Tensor.view(Tensor([2, 172, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 172], "int64"), -1)
torch.Tensor.view(Tensor([2, 173, 2048], "bfloat16"), tuple(2, 173, -1, 64))
torch.Tensor.view(Tensor([2, 173, 256], "bfloat16"), tuple(2, 173, -1, 64))
torch.Tensor.view(Tensor([2, 173, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 173], "int64"), -1)
torch.Tensor.view(Tensor([2, 179, 2048], "bfloat16"), tuple(2, 179, -1, 64))
torch.Tensor.view(Tensor([2, 179, 256], "bfloat16"), tuple(2, 179, -1, 64))
torch.Tensor.view(Tensor([2, 179, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 179], "int64"), -1)
torch.Tensor.view(Tensor([2, 182, 2048], "bfloat16"), tuple(2, 182, -1, 64))
torch.Tensor.view(Tensor([2, 182, 256], "bfloat16"), tuple(2, 182, -1, 64))
torch.Tensor.view(Tensor([2, 182, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 182], "int64"), -1)
torch.Tensor.view(Tensor([2, 231, 2048], "bfloat16"), tuple(2, 231, -1, 64))
torch.Tensor.view(Tensor([2, 231, 256], "bfloat16"), tuple(2, 231, -1, 64))
torch.Tensor.view(Tensor([2, 231, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 231], "int64"), -1)
torch.Tensor.view(Tensor([2, 285, 2048], "bfloat16"), tuple(2, 285, -1, 64))
torch.Tensor.view(Tensor([2, 285, 256], "bfloat16"), tuple(2, 285, -1, 64))
torch.Tensor.view(Tensor([2, 285, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 285], "int64"), -1)
torch.Tensor.view(Tensor([2, 299, 2048], "bfloat16"), tuple(2, 299, -1, 64))
torch.Tensor.view(Tensor([2, 299, 256], "bfloat16"), tuple(2, 299, -1, 64))
torch.Tensor.view(Tensor([2, 299, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 299], "int64"), -1)
torch.Tensor.view(Tensor([2, 314, 2048], "bfloat16"), tuple(2, 314, -1, 64))
torch.Tensor.view(Tensor([2, 314, 256], "bfloat16"), tuple(2, 314, -1, 64))
torch.Tensor.view(Tensor([2, 314, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 314], "int64"), -1)
torch.Tensor.view(Tensor([2, 324, 2048], "bfloat16"), tuple(2, 324, -1, 64))
torch.Tensor.view(Tensor([2, 324, 256], "bfloat16"), tuple(2, 324, -1, 64))
torch.Tensor.view(Tensor([2, 324, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 324], "int64"), -1)
torch.Tensor.view(Tensor([2, 331, 2048], "bfloat16"), tuple(2, 331, -1, 64))
torch.Tensor.view(Tensor([2, 331, 256], "bfloat16"), tuple(2, 331, -1, 64))
torch.Tensor.view(Tensor([2, 331, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 331], "int64"), -1)
torch.Tensor.view(Tensor([2, 345, 2048], "bfloat16"), tuple(2, 345, -1, 64))
torch.Tensor.view(Tensor([2, 345, 256], "bfloat16"), tuple(2, 345, -1, 64))
torch.Tensor.view(Tensor([2, 345, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 345], "int64"), -1)
torch.Tensor.view(Tensor([2, 356, 2048], "bfloat16"), tuple(2, 356, -1, 64))
torch.Tensor.view(Tensor([2, 356, 256], "bfloat16"), tuple(2, 356, -1, 64))
torch.Tensor.view(Tensor([2, 356, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 356], "int64"), -1)
torch.Tensor.view(Tensor([2, 358, 2048], "bfloat16"), tuple(2, 358, -1, 64))
torch.Tensor.view(Tensor([2, 358, 256], "bfloat16"), tuple(2, 358, -1, 64))
torch.Tensor.view(Tensor([2, 358, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 358], "int64"), -1)
torch.Tensor.view(Tensor([2, 407, 2048], "bfloat16"), tuple(2, 407, -1, 64))
torch.Tensor.view(Tensor([2, 407, 256], "bfloat16"), tuple(2, 407, -1, 64))
torch.Tensor.view(Tensor([2, 407, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 407], "int64"), -1)
torch.Tensor.view(Tensor([2, 408, 2048], "bfloat16"), tuple(2, 408, -1, 64))
torch.Tensor.view(Tensor([2, 408, 256], "bfloat16"), tuple(2, 408, -1, 64))
torch.Tensor.view(Tensor([2, 408, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 408], "int64"), -1)
torch.Tensor.view(Tensor([2, 409, 2048], "bfloat16"), tuple(2, 409, -1, 64))
torch.Tensor.view(Tensor([2, 409, 256], "bfloat16"), tuple(2, 409, -1, 64))
torch.Tensor.view(Tensor([2, 409, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 409], "int64"), -1)
torch.Tensor.view(Tensor([2, 434, 2048], "bfloat16"), tuple(2, 434, -1, 64))
torch.Tensor.view(Tensor([2, 434, 256], "bfloat16"), tuple(2, 434, -1, 64))
torch.Tensor.view(Tensor([2, 434, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 434], "int64"), -1)
torch.Tensor.view(Tensor([2, 438, 2048], "bfloat16"), tuple(2, 438, -1, 64))
torch.Tensor.view(Tensor([2, 438, 256], "bfloat16"), tuple(2, 438, -1, 64))
torch.Tensor.view(Tensor([2, 438, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 438], "int64"), -1)
torch.Tensor.view(Tensor([2, 449, 2048], "bfloat16"), tuple(2, 449, -1, 64))
torch.Tensor.view(Tensor([2, 449, 256], "bfloat16"), tuple(2, 449, -1, 64))
torch.Tensor.view(Tensor([2, 449, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 449], "int64"), -1)
torch.Tensor.view(Tensor([2, 478, 2048], "bfloat16"), tuple(2, 478, -1, 64))
torch.Tensor.view(Tensor([2, 478, 256], "bfloat16"), tuple(2, 478, -1, 64))
torch.Tensor.view(Tensor([2, 478, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 478], "int64"), -1)
torch.Tensor.view(Tensor([2, 50, 2048], "bfloat16"), tuple(2, 50, -1, 64))
torch.Tensor.view(Tensor([2, 50, 256], "bfloat16"), tuple(2, 50, -1, 64))
torch.Tensor.view(Tensor([2, 50, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 50], "int64"), -1)
torch.Tensor.view(Tensor([2, 512, 2048], "bfloat16"), tuple(2, 512, -1, 64))
torch.Tensor.view(Tensor([2, 512, 256], "bfloat16"), tuple(2, 512, -1, 64))
torch.Tensor.view(Tensor([2, 512, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 512], "int64"), -1)
torch.Tensor.view(Tensor([2, 52, 2048], "bfloat16"), tuple(2, 52, -1, 64))
torch.Tensor.view(Tensor([2, 52, 256], "bfloat16"), tuple(2, 52, -1, 64))
torch.Tensor.view(Tensor([2, 52, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 52], "int64"), -1)
torch.Tensor.view(Tensor([2, 55, 2048], "bfloat16"), tuple(2, 55, -1, 64))
torch.Tensor.view(Tensor([2, 55, 256], "bfloat16"), tuple(2, 55, -1, 64))
torch.Tensor.view(Tensor([2, 55, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 55], "int64"), -1)
torch.Tensor.view(Tensor([2, 58, 2048], "bfloat16"), tuple(2, 58, -1, 64))
torch.Tensor.view(Tensor([2, 58, 256], "bfloat16"), tuple(2, 58, -1, 64))
torch.Tensor.view(Tensor([2, 58, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 58], "int64"), -1)
torch.Tensor.view(Tensor([2, 60, 2048], "bfloat16"), tuple(2, 60, -1, 64))
torch.Tensor.view(Tensor([2, 60, 256], "bfloat16"), tuple(2, 60, -1, 64))
torch.Tensor.view(Tensor([2, 60, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 60], "int64"), -1)
torch.Tensor.view(Tensor([2, 64, 2048], "bfloat16"), tuple(2, 64, -1, 64))
torch.Tensor.view(Tensor([2, 64, 256], "bfloat16"), tuple(2, 64, -1, 64))
torch.Tensor.view(Tensor([2, 64, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 64], "int64"), -1)
torch.Tensor.view(Tensor([2, 80, 2048], "bfloat16"), tuple(2, 80, -1, 64))
torch.Tensor.view(Tensor([2, 80, 256], "bfloat16"), tuple(2, 80, -1, 64))
torch.Tensor.view(Tensor([2, 80, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 80], "int64"), -1)
torch.Tensor.view(Tensor([2, 91, 2048], "bfloat16"), tuple(2, 91, -1, 64))
torch.Tensor.view(Tensor([2, 91, 256], "bfloat16"), tuple(2, 91, -1, 64))
torch.Tensor.view(Tensor([2, 91, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 91], "int64"), -1)
torch.Tensor.view(Tensor([2, 99, 2048], "bfloat16"), tuple(2, 99, -1, 64))
torch.Tensor.view(Tensor([2, 99, 256], "bfloat16"), tuple(2, 99, -1, 64))
torch.Tensor.view(Tensor([2, 99, 32000], "float32"), -1, 32000)
torch.Tensor.view(Tensor([2, 99], "int64"), -1)
torch.Tensor.view(Tensor([23068672], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([4096], "uint8"), dtype="bfloat16")
torch.Tensor.view(Tensor([8388608], "uint8"), dtype="bfloat16")
torch._C._set_grad_enabled(False)
torch._C._set_grad_enabled(True)
torch._foreach_add_(list[Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32")], Tensor([], "float32"), alpha=1.0)
torch._foreach_add_(list[Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32")], Tensor([], "float32"), alpha=1.0)
torch._foreach_add_(list[Tensor([], "float32"), Tensor([], "float32"), Tensor([], "float32")], Tensor([], "float32"), alpha=1.0)
torch._foreach_add_(list[Tensor([], "float32"), Tensor([], "float32")], Tensor([], "float32"), alpha=1.0)
torch._foreach_add_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), 1e-08)
torch._foreach_add_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), 1e-08)
torch._foreach_add_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), 1e-08)
torch._foreach_add_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), 1e-08)
torch._foreach_add_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), 1e-08)
torch._foreach_add_(tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), 1e-08)
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[-0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[-2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[-4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[-8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[-9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[-9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-0.00020000000000000006, -0.00020000000000000006, -0.00020000000000000006])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-2.326257633032859e-05, -2.326257633032859e-05, -2.326257633032859e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-4.428044280442806e-05, -4.428044280442806e-05, -4.428044280442806e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-8.421052631578952e-05, -8.421052631578952e-05, -8.421052631578952e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-9.76777123879759e-06, -9.76777123879759e-06, -9.76777123879759e-06])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-0.00020000000000000006, -0.00020000000000000006])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-2.326257633032859e-05, -2.326257633032859e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-4.428044280442806e-05, -4.428044280442806e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-8.421052631578952e-05, -8.421052631578952e-05])
torch._foreach_addcdiv_(list["<Unserializable: Parameter>", "<Unserializable: Parameter>"], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[-9.76777123879759e-06, -9.76777123879759e-06])
torch._foreach_addcmul_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], 0.0010000000000000009)
torch._foreach_addcmul_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], 0.0010000000000000009)
torch._foreach_addcmul_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.0010000000000000009)
torch._foreach_addcmul_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.0010000000000000009)
torch._foreach_addcmul_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.0010000000000000009)
torch._foreach_addcmul_(list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], 0.0010000000000000009)
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004])
torch._foreach_div_(tuple(Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")), list[0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.031622776601683805, 0.031622776601683805])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.04471017781221601, 0.04471017781221601])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.05474487190596028, 0.05474487190596028])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.0631981328759004, 0.0631981328759004])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.0706400027958733, 0.0706400027958733])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.031622776601683805, 0.031622776601683805, 0.031622776601683805])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.04471017781221601, 0.04471017781221601, 0.04471017781221601])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.05474487190596028, 0.05474487190596028, 0.05474487190596028])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.0631981328759004, 0.0631981328759004, 0.0631981328759004])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.0706400027958733, 0.0706400027958733, 0.0706400027958733])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004])
torch._foreach_div_(tuple(Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")), list[0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733])
torch._foreach_div_(tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805, 0.031622776601683805])
torch._foreach_div_(tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601, 0.04471017781221601])
torch._foreach_div_(tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028, 0.05474487190596028])
torch._foreach_div_(tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004, 0.0631981328759004])
torch._foreach_div_(tuple(Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")), list[0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733, 0.0706400027958733])
torch._foreach_lerp_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], 0.09999999999999998)
torch._foreach_lerp_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], 0.09999999999999998)
torch._foreach_lerp_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.09999999999999998)
torch._foreach_lerp_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.09999999999999998)
torch._foreach_lerp_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.09999999999999998)
torch._foreach_lerp_(list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], 0.09999999999999998)
torch._foreach_mul_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], 0.999)
torch._foreach_mul_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], Tensor([], "bfloat16"))
torch._foreach_mul_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([32000, 2048], "bfloat16")], Tensor([], "bfloat16"))
torch._foreach_mul_(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")], 0.999)
torch._foreach_mul_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.999)
torch._foreach_mul_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.999)
torch._foreach_mul_(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 0.999)
torch._foreach_mul_(list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], Tensor([], "bfloat16"))
torch._foreach_mul_(list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")], 0.999)
torch._foreach_norm(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 2.0)
torch._foreach_norm(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([32000, 2048], "bfloat16")], 2.0)
torch._foreach_norm(list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")], 2.0)
torch._foreach_sqrt(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")])
torch._foreach_sqrt(list[Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16"), Tensor([32000, 2048], "bfloat16")])
torch._foreach_sqrt(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")])
torch._foreach_sqrt(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")])
torch._foreach_sqrt(list[Tensor([2048], "bfloat16"), Tensor([2048], "bfloat16")])
torch._foreach_sqrt(list[Tensor([32000, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([256, 2048], "bfloat16"), Tensor([2048, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([5632, 2048], "bfloat16"), Tensor([2048, 5632], "bfloat16")])
torch.cat(list[Tensor([2, 102], "int64")], dim=0)
torch.cat(list[Tensor([2, 154], "int64")], dim=0)
torch.cat(list[Tensor([2, 156], "int64")], dim=0)
torch.cat(list[Tensor([2, 172], "int64")], dim=0)
torch.cat(list[Tensor([2, 173], "int64")], dim=0)
torch.cat(list[Tensor([2, 179], "int64")], dim=0)
torch.cat(list[Tensor([2, 182], "int64")], dim=0)
torch.cat(list[Tensor([2, 231], "int64")], dim=0)
torch.cat(list[Tensor([2, 285], "int64")], dim=0)
torch.cat(list[Tensor([2, 299], "int64")], dim=0)
torch.cat(list[Tensor([2, 302], "int64")], dim=0)
torch.cat(list[Tensor([2, 314], "int64")], dim=0)
torch.cat(list[Tensor([2, 324], "int64")], dim=0)
torch.cat(list[Tensor([2, 331], "int64")], dim=0)
torch.cat(list[Tensor([2, 345], "int64")], dim=0)
torch.cat(list[Tensor([2, 356], "int64")], dim=0)
torch.cat(list[Tensor([2, 358], "int64")], dim=0)
torch.cat(list[Tensor([2, 407], "int64")], dim=0)
torch.cat(list[Tensor([2, 408], "int64")], dim=0)
torch.cat(list[Tensor([2, 409], "int64")], dim=0)
torch.cat(list[Tensor([2, 434], "int64")], dim=0)
torch.cat(list[Tensor([2, 438], "int64")], dim=0)
torch.cat(list[Tensor([2, 449], "int64")], dim=0)
torch.cat(list[Tensor([2, 478], "int64")], dim=0)
torch.cat(list[Tensor([2, 50], "int64")], dim=0)
torch.cat(list[Tensor([2, 512], "int64")], dim=0)
torch.cat(list[Tensor([2, 52], "int64")], dim=0)
torch.cat(list[Tensor([2, 55], "int64")], dim=0)
torch.cat(list[Tensor([2, 58], "int64")], dim=0)
torch.cat(list[Tensor([2, 60], "int64")], dim=0)
torch.cat(list[Tensor([2, 64], "int64")], dim=0)
torch.cat(list[Tensor([2, 80], "int64")], dim=0)
torch.cat(list[Tensor([2, 91], "int64")], dim=0)
torch.cat(list[Tensor([2, 99], "int64")], dim=0)
torch.cat(tuple(Tensor([1, 102, 32], "float32"), Tensor([1, 102, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 154, 32], "float32"), Tensor([1, 154, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 156, 32], "float32"), Tensor([1, 156, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 172, 32], "float32"), Tensor([1, 172, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 173, 32], "float32"), Tensor([1, 173, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 179, 32], "float32"), Tensor([1, 179, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 182, 32], "float32"), Tensor([1, 182, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 231, 32], "float32"), Tensor([1, 231, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 285, 32], "float32"), Tensor([1, 285, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 299, 32], "float32"), Tensor([1, 299, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 314, 32], "float32"), Tensor([1, 314, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 324, 32], "float32"), Tensor([1, 324, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 331, 32], "float32"), Tensor([1, 331, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 345, 32], "float32"), Tensor([1, 345, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 356, 32], "float32"), Tensor([1, 356, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 358, 32], "float32"), Tensor([1, 358, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 407, 32], "float32"), Tensor([1, 407, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 408, 32], "float32"), Tensor([1, 408, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 409, 32], "float32"), Tensor([1, 409, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 434, 32], "float32"), Tensor([1, 434, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 438, 32], "float32"), Tensor([1, 438, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 449, 32], "float32"), Tensor([1, 449, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 478, 32], "float32"), Tensor([1, 478, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 50, 32], "float32"), Tensor([1, 50, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 512, 32], "float32"), Tensor([1, 512, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 52, 32], "float32"), Tensor([1, 52, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 55, 32], "float32"), Tensor([1, 55, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 58, 32], "float32"), Tensor([1, 58, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 60, 32], "float32"), Tensor([1, 60, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 64, 32], "float32"), Tensor([1, 64, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 80, 32], "float32"), Tensor([1, 80, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 91, 32], "float32"), Tensor([1, 91, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([1, 99, 32], "float32"), Tensor([1, 99, 32], "float32")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 102, 32], "bfloat16"), Tensor([2, 32, 102, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 154, 32], "bfloat16"), Tensor([2, 32, 154, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 156, 32], "bfloat16"), Tensor([2, 32, 156, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 172, 32], "bfloat16"), Tensor([2, 32, 172, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 173, 32], "bfloat16"), Tensor([2, 32, 173, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 179, 32], "bfloat16"), Tensor([2, 32, 179, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 182, 32], "bfloat16"), Tensor([2, 32, 182, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 231, 32], "bfloat16"), Tensor([2, 32, 231, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 285, 32], "bfloat16"), Tensor([2, 32, 285, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 299, 32], "bfloat16"), Tensor([2, 32, 299, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 314, 32], "bfloat16"), Tensor([2, 32, 314, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 324, 32], "bfloat16"), Tensor([2, 32, 324, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 331, 32], "bfloat16"), Tensor([2, 32, 331, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 345, 32], "bfloat16"), Tensor([2, 32, 345, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 356, 32], "bfloat16"), Tensor([2, 32, 356, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 358, 32], "bfloat16"), Tensor([2, 32, 358, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 407, 32], "bfloat16"), Tensor([2, 32, 407, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 408, 32], "bfloat16"), Tensor([2, 32, 408, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 409, 32], "bfloat16"), Tensor([2, 32, 409, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 434, 32], "bfloat16"), Tensor([2, 32, 434, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 438, 32], "bfloat16"), Tensor([2, 32, 438, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 449, 32], "bfloat16"), Tensor([2, 32, 449, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 478, 32], "bfloat16"), Tensor([2, 32, 478, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 50, 32], "bfloat16"), Tensor([2, 32, 50, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 512, 32], "bfloat16"), Tensor([2, 32, 512, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 52, 32], "bfloat16"), Tensor([2, 32, 52, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 55, 32], "bfloat16"), Tensor([2, 32, 55, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 58, 32], "bfloat16"), Tensor([2, 32, 58, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 60, 32], "bfloat16"), Tensor([2, 32, 60, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 64, 32], "bfloat16"), Tensor([2, 32, 64, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 80, 32], "bfloat16"), Tensor([2, 32, 80, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 91, 32], "bfloat16"), Tensor([2, 32, 91, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 32, 99, 32], "bfloat16"), Tensor([2, 32, 99, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 102, 32], "bfloat16"), Tensor([2, 4, 102, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 154, 32], "bfloat16"), Tensor([2, 4, 154, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 156, 32], "bfloat16"), Tensor([2, 4, 156, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 172, 32], "bfloat16"), Tensor([2, 4, 172, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 173, 32], "bfloat16"), Tensor([2, 4, 173, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 179, 32], "bfloat16"), Tensor([2, 4, 179, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 182, 32], "bfloat16"), Tensor([2, 4, 182, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 231, 32], "bfloat16"), Tensor([2, 4, 231, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 285, 32], "bfloat16"), Tensor([2, 4, 285, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 299, 32], "bfloat16"), Tensor([2, 4, 299, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 314, 32], "bfloat16"), Tensor([2, 4, 314, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 324, 32], "bfloat16"), Tensor([2, 4, 324, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 331, 32], "bfloat16"), Tensor([2, 4, 331, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 345, 32], "bfloat16"), Tensor([2, 4, 345, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 356, 32], "bfloat16"), Tensor([2, 4, 356, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 358, 32], "bfloat16"), Tensor([2, 4, 358, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 407, 32], "bfloat16"), Tensor([2, 4, 407, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 408, 32], "bfloat16"), Tensor([2, 4, 408, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 409, 32], "bfloat16"), Tensor([2, 4, 409, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 434, 32], "bfloat16"), Tensor([2, 4, 434, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 438, 32], "bfloat16"), Tensor([2, 4, 438, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 449, 32], "bfloat16"), Tensor([2, 4, 449, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 478, 32], "bfloat16"), Tensor([2, 4, 478, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 50, 32], "bfloat16"), Tensor([2, 4, 50, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 512, 32], "bfloat16"), Tensor([2, 4, 512, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 52, 32], "bfloat16"), Tensor([2, 4, 52, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 55, 32], "bfloat16"), Tensor([2, 4, 55, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 58, 32], "bfloat16"), Tensor([2, 4, 58, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 60, 32], "bfloat16"), Tensor([2, 4, 60, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 64, 32], "bfloat16"), Tensor([2, 4, 64, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 80, 32], "bfloat16"), Tensor([2, 4, 80, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 91, 32], "bfloat16"), Tensor([2, 4, 91, 32], "bfloat16")), dim=-1)
torch.cat(tuple(Tensor([2, 4, 99, 32], "bfloat16"), Tensor([2, 4, 99, 32], "bfloat16")), dim=-1)
torch.clamp(Tensor([], "bfloat16"), max=1.0)
torch.is_complex("<Unserializable: Parameter>")
torch.isinf(Tensor([], "float32"))
torch.isnan(Tensor([], "float32"))
torch.linalg.vector_norm(Tensor([201], "bfloat16"), 2.0)
torch.nn.functional.cross_entropy(Tensor([100, 32000], "float32"), Tensor([100], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([1024, 32000], "float32"), Tensor([1024], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([104, 32000], "float32"), Tensor([104], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([110, 32000], "float32"), Tensor([110], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([116, 32000], "float32"), Tensor([116], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([120, 32000], "float32"), Tensor([120], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([128, 32000], "float32"), Tensor([128], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([160, 32000], "float32"), Tensor([160], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([182, 32000], "float32"), Tensor([182], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([198, 32000], "float32"), Tensor([198], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([204, 32000], "float32"), Tensor([204], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([308, 32000], "float32"), Tensor([308], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([312, 32000], "float32"), Tensor([312], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([344, 32000], "float32"), Tensor([344], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([346, 32000], "float32"), Tensor([346], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([358, 32000], "float32"), Tensor([358], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([364, 32000], "float32"), Tensor([364], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([462, 32000], "float32"), Tensor([462], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([570, 32000], "float32"), Tensor([570], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([598, 32000], "float32"), Tensor([598], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([628, 32000], "float32"), Tensor([628], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([648, 32000], "float32"), Tensor([648], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([662, 32000], "float32"), Tensor([662], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([690, 32000], "float32"), Tensor([690], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([712, 32000], "float32"), Tensor([712], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([716, 32000], "float32"), Tensor([716], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([814, 32000], "float32"), Tensor([814], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([816, 32000], "float32"), Tensor([816], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([818, 32000], "float32"), Tensor([818], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([868, 32000], "float32"), Tensor([868], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([876, 32000], "float32"), Tensor([876], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([898, 32000], "float32"), Tensor([898], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.cross_entropy(Tensor([956, 32000], "float32"), Tensor([956], "int64"), weight=None, size_average=None, ignore_index=-100, reduce=None, reduction="sum", label_smoothing=0.0)
torch.nn.functional.embedding(Tensor([2, 102], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 154], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 156], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 172], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 173], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 179], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 182], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 231], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 285], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 299], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 314], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 324], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 331], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 345], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 356], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 358], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 407], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 408], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 409], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 434], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 438], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 449], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 478], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 50], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 512], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 52], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 55], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 58], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 60], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 64], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 80], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 91], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding(Tensor([2, 99], "int64"), "<Unserializable: Parameter>", padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.linear(Tensor([2, 102, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 102, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 154, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 154, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 156, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 156, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 172, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 172, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 173, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 173, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 179, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 179, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 182, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 182, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 231, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 231, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 285, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 285, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 299, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 299, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 314, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 314, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 324, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 324, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 331, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 331, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 345, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 345, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 356, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 356, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 358, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 358, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 407, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 407, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 408, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 408, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 409, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 409, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 434, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 434, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 438, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 438, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 449, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 449, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 478, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 478, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 50, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 50, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 512, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 512, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 52, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 52, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 55, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 55, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 58, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 58, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 60, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 60, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 64, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 64, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 80, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 80, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 91, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 91, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 99, 2048], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.linear(Tensor([2, 99, 5632], "bfloat16"), "<Unserializable: Parameter>", None)
torch.nn.functional.pad(Tensor([2, 102], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 154], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 156], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 172], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 173], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 179], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 182], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 231], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 285], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 299], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 314], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 324], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 331], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 345], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 356], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 358], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 407], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 408], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 409], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 434], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 438], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 449], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 478], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 50], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 512], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 52], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 55], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 58], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 60], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 64], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 80], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 91], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.pad(Tensor([2, 99], "int64"), tuple(0, 1), mode="constant", value=-100)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 102, 64], "bfloat16"), Tensor([2, 32, 102, 64], "bfloat16"), Tensor([2, 32, 102, 64], "bfloat16"), attn_mask=Tensor([2, 1, 102, 102], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 154, 64], "bfloat16"), Tensor([2, 32, 154, 64], "bfloat16"), Tensor([2, 32, 154, 64], "bfloat16"), attn_mask=Tensor([2, 1, 154, 154], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 156, 64], "bfloat16"), Tensor([2, 32, 156, 64], "bfloat16"), Tensor([2, 32, 156, 64], "bfloat16"), attn_mask=Tensor([2, 1, 156, 156], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 172, 64], "bfloat16"), Tensor([2, 32, 172, 64], "bfloat16"), Tensor([2, 32, 172, 64], "bfloat16"), attn_mask=Tensor([2, 1, 172, 172], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 173, 64], "bfloat16"), Tensor([2, 32, 173, 64], "bfloat16"), Tensor([2, 32, 173, 64], "bfloat16"), attn_mask=Tensor([2, 1, 173, 173], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 179, 64], "bfloat16"), Tensor([2, 32, 179, 64], "bfloat16"), Tensor([2, 32, 179, 64], "bfloat16"), attn_mask=Tensor([2, 1, 179, 179], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 182, 64], "bfloat16"), Tensor([2, 32, 182, 64], "bfloat16"), Tensor([2, 32, 182, 64], "bfloat16"), attn_mask=Tensor([2, 1, 182, 182], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 231, 64], "bfloat16"), Tensor([2, 32, 231, 64], "bfloat16"), Tensor([2, 32, 231, 64], "bfloat16"), attn_mask=Tensor([2, 1, 231, 231], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 285, 64], "bfloat16"), Tensor([2, 32, 285, 64], "bfloat16"), Tensor([2, 32, 285, 64], "bfloat16"), attn_mask=Tensor([2, 1, 285, 285], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 299, 64], "bfloat16"), Tensor([2, 32, 299, 64], "bfloat16"), Tensor([2, 32, 299, 64], "bfloat16"), attn_mask=Tensor([2, 1, 299, 299], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 314, 64], "bfloat16"), Tensor([2, 32, 314, 64], "bfloat16"), Tensor([2, 32, 314, 64], "bfloat16"), attn_mask=Tensor([2, 1, 314, 314], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 324, 64], "bfloat16"), Tensor([2, 32, 324, 64], "bfloat16"), Tensor([2, 32, 324, 64], "bfloat16"), attn_mask=Tensor([2, 1, 324, 324], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 331, 64], "bfloat16"), Tensor([2, 32, 331, 64], "bfloat16"), Tensor([2, 32, 331, 64], "bfloat16"), attn_mask=Tensor([2, 1, 331, 331], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 345, 64], "bfloat16"), Tensor([2, 32, 345, 64], "bfloat16"), Tensor([2, 32, 345, 64], "bfloat16"), attn_mask=Tensor([2, 1, 345, 345], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 356, 64], "bfloat16"), Tensor([2, 32, 356, 64], "bfloat16"), Tensor([2, 32, 356, 64], "bfloat16"), attn_mask=Tensor([2, 1, 356, 356], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 358, 64], "bfloat16"), Tensor([2, 32, 358, 64], "bfloat16"), Tensor([2, 32, 358, 64], "bfloat16"), attn_mask=Tensor([2, 1, 358, 358], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 407, 64], "bfloat16"), Tensor([2, 32, 407, 64], "bfloat16"), Tensor([2, 32, 407, 64], "bfloat16"), attn_mask=Tensor([2, 1, 407, 407], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 408, 64], "bfloat16"), Tensor([2, 32, 408, 64], "bfloat16"), Tensor([2, 32, 408, 64], "bfloat16"), attn_mask=Tensor([2, 1, 408, 408], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 409, 64], "bfloat16"), Tensor([2, 32, 409, 64], "bfloat16"), Tensor([2, 32, 409, 64], "bfloat16"), attn_mask=Tensor([2, 1, 409, 409], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 434, 64], "bfloat16"), Tensor([2, 32, 434, 64], "bfloat16"), Tensor([2, 32, 434, 64], "bfloat16"), attn_mask=Tensor([2, 1, 434, 434], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 438, 64], "bfloat16"), Tensor([2, 32, 438, 64], "bfloat16"), Tensor([2, 32, 438, 64], "bfloat16"), attn_mask=Tensor([2, 1, 438, 438], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 449, 64], "bfloat16"), Tensor([2, 32, 449, 64], "bfloat16"), Tensor([2, 32, 449, 64], "bfloat16"), attn_mask=Tensor([2, 1, 449, 449], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 478, 64], "bfloat16"), Tensor([2, 32, 478, 64], "bfloat16"), Tensor([2, 32, 478, 64], "bfloat16"), attn_mask=Tensor([2, 1, 478, 478], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 50, 64], "bfloat16"), Tensor([2, 32, 50, 64], "bfloat16"), Tensor([2, 32, 50, 64], "bfloat16"), attn_mask=Tensor([2, 1, 50, 50], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 512, 64], "bfloat16"), Tensor([2, 32, 512, 64], "bfloat16"), Tensor([2, 32, 512, 64], "bfloat16"), attn_mask=Tensor([2, 1, 512, 512], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 52, 64], "bfloat16"), Tensor([2, 32, 52, 64], "bfloat16"), Tensor([2, 32, 52, 64], "bfloat16"), attn_mask=Tensor([2, 1, 52, 52], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 55, 64], "bfloat16"), Tensor([2, 32, 55, 64], "bfloat16"), Tensor([2, 32, 55, 64], "bfloat16"), attn_mask=Tensor([2, 1, 55, 55], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 55, 64], "bfloat16"), Tensor([2, 4, 55, 64], "bfloat16"), Tensor([2, 4, 55, 64], "bfloat16"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 58, 64], "bfloat16"), Tensor([2, 32, 58, 64], "bfloat16"), Tensor([2, 32, 58, 64], "bfloat16"), attn_mask=Tensor([2, 1, 58, 58], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 60, 64], "bfloat16"), Tensor([2, 32, 60, 64], "bfloat16"), Tensor([2, 32, 60, 64], "bfloat16"), attn_mask=Tensor([2, 1, 60, 60], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 64, 64], "bfloat16"), Tensor([2, 32, 64, 64], "bfloat16"), Tensor([2, 32, 64, 64], "bfloat16"), attn_mask=Tensor([2, 1, 64, 64], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 80, 64], "bfloat16"), Tensor([2, 32, 80, 64], "bfloat16"), Tensor([2, 32, 80, 64], "bfloat16"), attn_mask=Tensor([2, 1, 80, 80], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 91, 64], "bfloat16"), Tensor([2, 32, 91, 64], "bfloat16"), Tensor([2, 32, 91, 64], "bfloat16"), attn_mask=Tensor([2, 1, 91, 91], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.scaled_dot_product_attention(Tensor([2, 32, 99, 64], "bfloat16"), Tensor([2, 32, 99, 64], "bfloat16"), Tensor([2, 32, 99, 64], "bfloat16"), attn_mask=Tensor([2, 1, 99, 99], "bool"), dropout_p=0.0, scale=0.125, is_causal=False)
torch.nn.functional.silu(Tensor([2, 102, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 154, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 156, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 172, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 173, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 179, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 182, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 231, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 285, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 299, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 314, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 324, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 331, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 345, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 356, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 358, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 407, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 408, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 409, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 434, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 438, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 449, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 478, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 50, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 512, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 52, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 55, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 58, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 60, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 64, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 80, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 91, 5632], "bfloat16"), inplace=False)
torch.nn.functional.silu(Tensor([2, 99, 5632], "bfloat16"), inplace=False)
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 102], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 154], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 156], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 172], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 173], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 179], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 182], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 231], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 285], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 299], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 314], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 324], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 331], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 345], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 356], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 358], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 407], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 408], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 409], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 434], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 438], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 449], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 478], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 50], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 512], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 52], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 55], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 58], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 60], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 64], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 80], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 91], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.ops.higher_order.custom_function_call("<Unserializable: FunctionMeta>", Tensor([2, 99], "bool"), list[Tensor([], "int64"), Tensor([], "int64")])
torch.rsqrt(Tensor([2, 102, 1], "float32"))
torch.rsqrt(Tensor([2, 154, 1], "float32"))
torch.rsqrt(Tensor([2, 156, 1], "float32"))
torch.rsqrt(Tensor([2, 172, 1], "float32"))
torch.rsqrt(Tensor([2, 173, 1], "float32"))
torch.rsqrt(Tensor([2, 179, 1], "float32"))
torch.rsqrt(Tensor([2, 182, 1], "float32"))
torch.rsqrt(Tensor([2, 231, 1], "float32"))
torch.rsqrt(Tensor([2, 285, 1], "float32"))
torch.rsqrt(Tensor([2, 299, 1], "float32"))
torch.rsqrt(Tensor([2, 314, 1], "float32"))
torch.rsqrt(Tensor([2, 324, 1], "float32"))
torch.rsqrt(Tensor([2, 331, 1], "float32"))
torch.rsqrt(Tensor([2, 345, 1], "float32"))
torch.rsqrt(Tensor([2, 356, 1], "float32"))
torch.rsqrt(Tensor([2, 358, 1], "float32"))
torch.rsqrt(Tensor([2, 407, 1], "float32"))
torch.rsqrt(Tensor([2, 408, 1], "float32"))
torch.rsqrt(Tensor([2, 409, 1], "float32"))
torch.rsqrt(Tensor([2, 434, 1], "float32"))
torch.rsqrt(Tensor([2, 438, 1], "float32"))
torch.rsqrt(Tensor([2, 449, 1], "float32"))
torch.rsqrt(Tensor([2, 478, 1], "float32"))
torch.rsqrt(Tensor([2, 50, 1], "float32"))
torch.rsqrt(Tensor([2, 512, 1], "float32"))
torch.rsqrt(Tensor([2, 52, 1], "float32"))
torch.rsqrt(Tensor([2, 55, 1], "float32"))
torch.rsqrt(Tensor([2, 58, 1], "float32"))
torch.rsqrt(Tensor([2, 60, 1], "float32"))
torch.rsqrt(Tensor([2, 64, 1], "float32"))
torch.rsqrt(Tensor([2, 80, 1], "float32"))
torch.rsqrt(Tensor([2, 91, 1], "float32"))
torch.rsqrt(Tensor([2, 99, 1], "float32"))
torch.stack(list[Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16"), Tensor([], "bfloat16")])
torch.zeros_like("<Unserializable: Parameter>", memory_format="torch.preserve_format")
